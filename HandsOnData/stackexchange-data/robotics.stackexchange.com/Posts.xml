<?xml version="1.0" encoding="utf-8"?>
<posts>
  <row Id="1" PostTypeId="1" CreationDate="2012-10-23T19:38:18.867" Score="11" ViewCount="134" Body="&lt;p&gt;Imagine programming a 3 wheel soccer robot. What type of controller would you use for spinning it? P? PID?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The goal for this controller is that it should make the robot stand in a defined angle ( 0 degree ) and turn back if rotated by hand or other robot. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I use stepper motors for my robot and not servos so I need to implement this in my software!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have written a sample P type controller already and the movement is fairly good. But I would like to make it better if possible. The code is as follows:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;void spinSpeed(int devidedValue, int addedValue, int correction) {&#xA;&#xA;    if(degree&amp;lt;correction &amp;amp;&amp;amp; degree&amp;gt;-correction) {&#xA;        motorSpeed = 0;&#xA;    } else {&#xA;        if(degree &amp;gt; 0) {&#xA;            motorSpeed = ((degree)/(devidedValue) + (addedValue));&#xA;        } else {&#xA;            motorSpeed = ((degree)/(devidedValue) - (addedValue));  &#xA;        }&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;correction&lt;/code&gt; is a range , in which robot has no movement. &#xA;&lt;code&gt;degree&lt;/code&gt; is a number between -127 and 128 which is returned from the compass.&#xA;&lt;code&gt;motorSpeed&lt;/code&gt; is a number between 0 and 255 which is applied to the PWM.&lt;/p&gt;&#xA;" OwnerUserId="21" LastEditorUserId="177" LastEditDate="2012-11-12T03:17:16.247" LastActivityDate="2012-11-12T03:17:16.247" Title="What is the right approach to write the spin controller for a soccer robot?" Tags="&lt;soccer&gt;&lt;control&gt;" AnswerCount="2" CommentCount="6" />
  <row Id="2" PostTypeId="1" AcceptedAnswerId="50" CreationDate="2012-10-23T19:42:56.030" Score="10" ViewCount="558" Body="&lt;p&gt;I've got some hobby servos (&lt;a href=&quot;http://www.servodatabase.com/servo/power-hd/hd-1501mg&quot; rel=&quot;nofollow&quot;&gt;Power HD 1501MGs&lt;/a&gt;) and I'd like to be able to control them (via an Arduino) so they will either go to the angle I set, or put them in a 'free running' mode, where the load will take them wherever it goes.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is this even possible, or am I just going to end up stripping the gears?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My first thought is to simply kill the power to the servo, but the force required to move them in that state is more than I'd like.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If it is possible, am I looking at a hardware change, or could I do it in software?&lt;/p&gt;&#xA;" OwnerUserId="12" LastEditorUserId="37" LastEditDate="2013-05-20T14:52:48.300" LastActivityDate="2013-05-20T14:52:48.300" Title="How can I modify a low cost hobby servo to run 'freely'?" Tags="&lt;control&gt;&lt;rcservo&gt;" AnswerCount="4" CommentCount="2" FavoriteCount="1" />
  <row Id="3" PostTypeId="1" CreationDate="2012-10-23T19:43:37.690" Score="19" ViewCount="223" Body="&lt;p&gt;&lt;a href=&quot;http://www.oricomtech.com/projects/leg-time.htm&quot;&gt;http://www.oricomtech.com/projects/leg-time.htm&lt;/a&gt; lists three gaits, including the tripod, wave, and ripple. Can these be improved, or can their relative pros and cons be altered, and are there other gaits worth considering?&lt;/p&gt;&#xA;" OwnerUserId="34" LastActivityDate="2012-10-23T21:11:04.363" Title="What useful gaits exist for a six legged robot, and what are their pros and cons?" Tags="&lt;gait&gt;&lt;walk&gt;" AnswerCount="2" CommentCount="1" FavoriteCount="3" />
  <row Id="4" PostTypeId="1" AcceptedAnswerId="52" CreationDate="2012-10-23T19:43:47.140" Score="0" ViewCount="686" Body="&lt;p&gt;I am looking for a starting point for my project, preferably using popular systems (ones there is a lot of support for). I have an Arduino Uno, a Raspberry Pi, and a lot of willpower :) Anyone here built a project using the systems above?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Observation: I'd like to start with a simple line-following vehicle and build up afterwards.&lt;/p&gt;&#xA;" OwnerUserId="32" LastEditorUserId="37" LastEditDate="2012-11-14T15:00:39.723" LastActivityDate="2012-11-14T15:00:39.723" Title="Good Microcontrollers/SOCs for a Robotics Project" Tags="&lt;microcontroller&gt;&lt;arduino&gt;&lt;raspberry-pi&gt;" AnswerCount="7" CommentCount="2" FavoriteCount="1" ClosedDate="2012-10-24T15:28:52.117" />
  <row Id="5" PostTypeId="1" AcceptedAnswerId="12" CreationDate="2012-10-23T19:43:48.463" Score="11" ViewCount="143" Body="&lt;p&gt;I'm trying to implement a nearest-neighbor structure for use in an RRT motion planner. In order to do better than a linear brute-force nearest-neighbor search, I'd like to implement something like a kd-tree. However, it seems like the classical implementation of the kd-tree assumes that each dimension of the space can be split into &quot;left&quot; and &quot;right&quot;. This notion doesn't seem to apply to non-Euclidean spaces like SO(2), for instance.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm working with a serial manipulator arm with fully rotational links, meaning that each dimension of the robot's configuration space is SO(2), and therefore non-Euclidean. Can the kd-tree algorithm be modified to handle these kinds of subspaces? If not, is there another nearest-neighbor structure that can handle these non-Euclidean subspaces while still being easy to update and query? I also took a look at &lt;a href=&quot;http://www.cs.ubc.ca/~mariusm/index.php/FLANN/FLANN&quot;&gt;FLANN&lt;/a&gt;, but it wasn't clear to me from their documentation whether they can handle non-Euclidean subspaces.&lt;/p&gt;&#xA;" OwnerUserId="13" LastEditorUserId="42" LastEditDate="2012-11-15T06:58:20.917" LastActivityDate="2012-11-15T06:58:20.917" Title="Nearest-neighbor data structure for non-Euclidean configuration space" Tags="&lt;motion-planning&gt;&lt;rrt&gt;" AnswerCount="1" CommentCount="3" />
  <row Id="6" PostTypeId="1" CreationDate="2012-10-23T19:48:55.993" Score="13" ViewCount="516" Body="&lt;p&gt;My company will soon be starting a brand new robotics project, and we are still trying to decide whether we should design and code a robotics software platform from scratch, or if there are any good existing ones.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It would be very useful if there was a software platform which was commonly used among both academics and industry so that our robotic system was generally compatible with others, and so that people were already familiar with it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We would like the software platform to be able to:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Integrate new robotic hardware components easily.&lt;/li&gt;&#xA;&lt;li&gt;Already contain a wide array of useful data processing and visualisation tools&lt;/li&gt;&#xA;&lt;li&gt;Make efficient use of computing hardware&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-10-26T06:37:43.207" Title="What good robotics software platforms / operating systems are available?" Tags="&lt;software&gt;&lt;platform&gt;" AnswerCount="7" CommentCount="12" FavoriteCount="10" ClosedDate="2012-10-26T06:56:58.157" />
  <row Id="7" PostTypeId="2" ParentId="4" CreationDate="2012-10-23T19:53:49.917" Score="4" Body="&lt;p&gt;It really depends on the project.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For a line follower robot ( in your case ), using the Atmel's AVR series is the best choice. Specially ATMEGA16 or even ATMEGA32. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Because the line-follower is a small project and the Arduino is too much for it. And the other advantage of Atmega16 is that it is cheap. If it is broken or faulty then you can change it easily. and it also provides PWM for controlling the speed of motors. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So with atmega series you can build the most powerful line-follower . No need to spend money on getting prebuilt boards and ...&lt;/p&gt;&#xA;" OwnerUserId="21" LastActivityDate="2012-10-23T19:53:49.917" />
  <row Id="8" PostTypeId="2" ParentId="2" CreationDate="2012-10-23T19:55:58.673" Score="7" Body="&lt;p&gt;Interesting question. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The first option I'd investigate would be cutting the power as you suggested (perhaps control a MOSFET in software to switch the power).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another more complicated approach might be to monitor the current consumption of the servo to detect when it is under a heavy load. When you want to go into &quot;free running&quot; mode, have your software attempt to continuously move the servo into a position that results in the least current consumption. This will not entirely result in a &quot;free running&quot; servo, since there will be some jittery movements from the servo as the software attempts to find the &quot;right&quot; position, but it might work depending on your application.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You would not need to modify your servos to monitor current consumption. A board such as &lt;a href=&quot;https://www.sparkfun.com/products/8882&quot; rel=&quot;nofollow&quot;&gt;this one from SparkFun&lt;/a&gt; will sit in between the servo and its power source (you need one of these per servo) and will output an analog voltage (that you can read on a microcontroller ADC pin) that corresponds to the current:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/tUZOG.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Image from SparkFun&lt;/p&gt;&#xA;" OwnerUserId="16" LastEditorUserId="16" LastEditDate="2012-10-24T00:04:16.653" LastActivityDate="2012-10-24T00:04:16.653" CommentCount="8" />
  <row Id="9" PostTypeId="2" ParentId="6" CreationDate="2012-10-23T19:56:39.780" Score="17" Body="&lt;p&gt;&lt;a href=&quot;http://www.ros.org/wiki/&quot;&gt;ROS&lt;/a&gt; is quickly becoming the new standard for both industrial and research robotics. Most research groups I know of are adopting ROS for their work and then pushing their results back into the open for everyone to use and improve. Willow Garage is developing a suite of hardware and software platforms which are all centered around ROS at their core. ROS is a good place to start your search.&lt;/p&gt;&#xA;" OwnerUserId="13" LastActivityDate="2012-10-23T19:56:39.780" CommentCount="2" />
  <row Id="11" PostTypeId="1" CreationDate="2012-10-23T20:03:27.800" Score="-4" ViewCount="103" Body="&lt;p&gt;What is the best software (despite the price) for designing the circuits and PCB boards for robots?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I mean having lots of components, different designing methods, best accuracy, ...&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I myself use the Altium Designer which I think answers my needs, but maybe there are better ones in the market i don't know about!&lt;/p&gt;&#xA;" OwnerUserId="21" LastEditorUserId="21" LastEditDate="2012-10-23T20:09:52.143" LastActivityDate="2012-10-23T20:11:13.610" Title="What software do you use to design your PCB in the robotics field?" Tags="&lt;software&gt;&lt;circuit&gt;" AnswerCount="1" CommentCount="6" FavoriteCount="1" ClosedDate="2012-10-23T21:14:57.730" />
  <row Id="12" PostTypeId="2" ParentId="5" CreationDate="2012-10-23T20:05:55.033" Score="5" Body="&lt;p&gt;You are correct that kd-trees typically only work in small, Euclidean metric spaces. But, there is lots of work for general nearest neighbor applications in metric spaces (anywhere you can define a distance function essentially).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The classic work is on &lt;a href=&quot;http://en.wikipedia.org/wiki/Ball_tree&quot;&gt;ball trees&lt;/a&gt;, which then were generalized to &lt;a href=&quot;http://en.wikipedia.org/wiki/Metric_tree&quot;&gt;metric trees&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is some newer work called &lt;a href=&quot;http://hunch.net/~jl/projects/cover_tree/cover_tree.html&quot;&gt;cover trees&lt;/a&gt; which even has GPL'ed code. I have wanted to look into the performance characteristics between these trees and kd-trees for more than two years now.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Hopefully, that fits your application. &lt;/p&gt;&#xA;" OwnerUserId="42" LastActivityDate="2012-10-23T20:05:55.033" CommentCount="2" />
  <row Id="13" PostTypeId="2" ParentId="3" CreationDate="2012-10-23T20:08:02.520" Score="11" Body="&lt;p&gt;&lt;strong&gt;Tripod&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have never been a big fan of the traditional tripod gait. It usually looks clumsy, and doesn't really take into account the delicacy of walking over uneven terrain. Walking this way tends to be jerky since one tripod is reaching the end of its travel just as the next tripod is touching down. Exactly how smooth you can make the walk depends on the implementation of your robot. If you have 3 degrees of freedom on each leg, then you have great freedom bring one set of legs forward quickly, bring them carefully into contact with the ground, matching the motion of the ground, and gently taking the robot's weight on them before lifting the other tripod. Alternatively, if you have two fixed tripods, the robot is going to just clunk along like a toy. It also has the lowest payload carrying capacity, since only three legs are on the ground. However, it can be pretty fast, since you're moving three legs at once.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Ripple&lt;/strong&gt;&#xA;This is by far my preferred gait. What I like about this gait is that it's easier to make the walk smoother. At any one time, you have three legs taking the weight, one in flight, one touching down, and one lifting off. It also makes it easier to cope with rough terrain. When the terrain is rough, you may need a moment longer to touch the leg down carefully on the ground, begin to apply weight and see if it's stable. If so, take the weight fully, and continue walking. If not, then it's not a disaster to delay lifting another leg so that you can try to get this one stable.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-10-23T20:08:02.520" CommentCount="1" />
  <row Id="14" PostTypeId="2" ParentId="1" CreationDate="2012-10-23T20:10:06.217" Score="8" Body="&lt;p&gt;A PID controller would be the best, Using a compass then it is a relatively straight forward task of getting the bearing of your robot and comparing it to the bearing you want to achieve, and using some &lt;a href=&quot;http://en.wikipedia.org/wiki/PID_controller#Overview_of_methods&quot;&gt;PID tuning techniques&lt;/a&gt; to achieve a smooth turning motion to your desired heading. This approach can also be applied to rotating by a given amount accurately.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have already done some robotics in this field, &lt;a href=&quot;http://team759.blogspot.co.uk/2011/11/adding-compass.html&quot;&gt;this&lt;/a&gt; is what we used in our robot, doing a not too dissimilar task to yours...&lt;/p&gt;&#xA;" OwnerUserId="46" LastActivityDate="2012-10-23T20:10:06.217" CommentCount="1" />
  <row Id="15" PostTypeId="2" ParentId="11" CreationDate="2012-10-23T20:11:13.610" Score="3" Body="&lt;p&gt;We evaluated a variety of options and settled on Altium Designer at our shop.  We build nothing but robots with a team of 9 engineers.  I am not sure there is a ton of stuff that is robotic specific in a PCB design, but Altium allows us to interface directly with our Pick and Place machine, easily generate 3D models, and the integration of the library with Subversion makes teamwork easy.&lt;/p&gt;&#xA;" OwnerUserId="39" LastActivityDate="2012-10-23T20:11:13.610" CommentCount="1" />
  <row Id="16" PostTypeId="2" ParentId="6" CreationDate="2012-10-23T20:13:06.233" Score="4" Body="&lt;p&gt;&lt;a href=&quot;http://rock-robotics.org&quot; rel=&quot;nofollow&quot;&gt;The Robot Construction Kit&lt;/a&gt; is an alternative to ROS. It is driven towards model-driven engineering and design/management of complex systems. It also is driven towards &quot;not being tightly dependent on Rock&quot;. Most of the algorithms / drivers in Rock are independent of the component layer. See also &lt;a href=&quot;http://www.rock-robotics.org/stable/documentation/about/others.html&quot; rel=&quot;nofollow&quot;&gt;this page&lt;/a&gt; for a quick summary of the differences between Rock and ROS.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As a previous answer points out, ROS is mainly used as a thin communication library. Rock's component layer is thicker, to provide the tools necessary to scale to complex systems. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What you have to understand is this: in this day and age, the only open-source robotic software worth looking at is framework-independent (OpenCV, PCL, OpenRave, Gazebo, ...). Even Willow Garage finally understood this. Therefore, it can be integrated with a minimal amount of work in any framework.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now: your best pick also depends on your aim. If what you want is sell hardware, then it is well possible that having a ROS node is your best choice (even though having a good driver &lt;em&gt;library&lt;/em&gt; that is then integrated into a ROS node is even better).&lt;/p&gt;&#xA;" OwnerUserId="56" LastEditorUserId="56" LastEditDate="2012-10-23T20:18:09.783" LastActivityDate="2012-10-23T20:18:09.783" CommentCount="1" />
  <row Id="17" PostTypeId="2" ParentId="6" CreationDate="2012-10-23T20:15:12.140" Score="3" Body="&lt;p&gt;My preferred platform is ROS. However, there is another strong contender from... dare I say it... Microsoft. It is called Robotics Developer Studio (RDS). Begin your search here: &lt;a href=&quot;http://www.microsoft.com/robotics/&quot; rel=&quot;nofollow&quot;&gt;http://www.microsoft.com/robotics/&lt;/a&gt; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;They have many videos of impressive applications. To me, the largest benefit is the built-in support for Kinect via Microsoft's Kinect SDK. Technically, the one which ROS uses from OpenNI has the same capabilities but it seems comforting to know the SDK which RDS uses is written by the same company which produced the hardware. &lt;/p&gt;&#xA;" OwnerUserId="45" LastActivityDate="2012-10-23T20:15:12.140" />
  <row Id="18" PostTypeId="1" CreationDate="2012-10-23T20:18:45.580" Score="10" ViewCount="748" Body="&lt;p&gt;Most often tuning the Kalman filter noise matrices is done by trial and error or domain knowledge. Are there more principled ways for tuning all the Kalman filter parameters?&lt;/p&gt;&#xA;" OwnerUserId="42" LastActivityDate="2013-10-24T10:01:13.187" Title="What are good methods for tuning the process noise on Kalman filters?" Tags="&lt;odometry&gt;&lt;localization&gt;&lt;kalman-filter&gt;" AnswerCount="2" FavoriteCount="1" />
  <row Id="19" PostTypeId="1" CreationDate="2012-10-23T20:20:54.537" Score="6" ViewCount="42" Body="&lt;p&gt;I'm working with a Wild Thumper 6 wheel chasis that is designed for use with an RC controller. However I'd like to have a mapping to a keyboard for control as well. Can you suggest a set of keys and behaviors that you've used to deal with the continuous value control normally offered by a joystick or pair of joysticks? The standard wasd keys + an accelerate/decelerate pair? I'd also take a pointer to a videogame that you think does this well.&lt;/p&gt;&#xA;" OwnerUserId="54" LastEditorUserId="158" LastEditDate="2014-01-10T10:47:21.380" LastActivityDate="2014-01-10T10:47:21.380" Title="Keyboard control map for scalar based movement?" Tags="&lt;keyboard&gt;" AnswerCount="1" CommentCount="2" FavoriteCount="1" />
  <row Id="20" PostTypeId="1" CreationDate="2012-10-23T20:21:40.533" Score="0" ViewCount="445" Body="&lt;p&gt;What is the best option to use for the shooting system of a soccer robot?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have already implemented a solenoid-based system for shooting and it works perfectly. &#xA;However, I'd like some other methods to check if they are better than mine. &lt;/p&gt;&#xA;" OwnerUserId="21" LastEditorUserId="74" LastEditDate="2012-10-24T03:37:32.520" LastActivityDate="2012-10-24T03:37:32.520" Title="Ideas for shooting the ball in a soccer robot" Tags="&lt;soccer&gt;&lt;mechanism&gt;" AnswerCount="1" CommentCount="1" ClosedDate="2012-12-05T21:15:21.677" />
  <row Id="21" PostTypeId="2" ParentId="4" CreationDate="2012-10-23T20:24:49.663" Score="3" Body="&lt;p&gt;If you want a line-following robot, then something similar to an &lt;a href=&quot;http://mbed.org/cookbook/m3pi&quot; rel=&quot;nofollow&quot;&gt;m3pi&lt;/a&gt; would be achievable. Photo-transistors seem to be very effective with a black-on-white track.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As for a microcontroller, Mario Markarian is probably right, it is down to personal preference and the project you are working on. The m3pi uses an &lt;a href=&quot;http://mbed.org/handbook/mbed-Microcontrollers&quot; rel=&quot;nofollow&quot;&gt;mbed&lt;/a&gt; and has a lot of IO's to play with. For more advanced robots a raspberry pi or &lt;a href=&quot;http://mbed.org/handbook/mbed-Microcontrollers&quot; rel=&quot;nofollow&quot;&gt;beagleboard&lt;/a&gt; work, interfaced with slave microcontroller(s) to provide sensor data and offloading any repetitive computations that could otherwise slow down the pi. &lt;/p&gt;&#xA;" OwnerUserId="46" LastEditorUserId="29" LastEditDate="2012-10-23T21:15:16.773" LastActivityDate="2012-10-23T21:15:16.773" CommentCount="1" />
  <row Id="22" PostTypeId="2" ParentId="4" CreationDate="2012-10-23T20:25:31.350" Score="3" Body="&lt;p&gt;I would suggest using lower end Atmel AVRs for beginning robotics projects.  An AVR can take a lot of abuse and can sink and source more current without burning out than the PIC microcontrollers I have used.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are going to be building multiple projects, you should consider investing in building your own breakout boards.  You can design your own PCB with standard power circuitry, a bunch of headers for I/O and whatever microcontroller you choose.  You can get your cost down to around $15 per board for the PCB and then a couple bucks worth of components.  This way, you can leave your project intact, instead of having to harvest out the microcontroller for your next project.  As a bonus, you will gain valuable experience in PCB design and soldering.&lt;/p&gt;&#xA;" OwnerUserId="39" LastActivityDate="2012-10-23T20:25:31.350" />
  <row Id="23" PostTypeId="1" CreationDate="2012-10-23T20:28:18.767" Score="3" ViewCount="99" Body="&lt;p&gt;I am beginning work on a larger scale, 250-350 lbs wheeled robot and looking to use both optical and other means of object avoidance. I am concerned with a robot this large causing issues with running into things, including people as it has a top speed of 15mph and that would cause issues with safety. I am starting out with a remote control but am looking to have the robot become self contained. I have been loosely following the DARPA driver-less car project but will not have anywhere near the fiscal or power budget that they do for sensors and computers. Am I thinking to far afield with my idea of having a self-contained robot in the 250-300 lbs range that does not break the bank on optical object avoidance? Any comments or experiences will be greatly appreciated.&lt;/p&gt;&#xA;" OwnerUserId="63" LastEditorUserId="131" LastEditDate="2012-11-25T22:50:18.367" LastActivityDate="2012-11-25T22:50:18.367" Title="F/OSS Optical Object Avoidance" Tags="&lt;computer-vision&gt;&lt;wheeled-robot&gt;" AnswerCount="3" CommentCount="1" FavoriteCount="1" />
  <row Id="24" PostTypeId="2" ParentId="1" CreationDate="2012-10-23T20:30:44.960" Score="7" Body="&lt;p&gt;The important thing to remember about a &lt;a href=&quot;http://en.wikipedia.org/wiki/PID_controller&quot; rel=&quot;nofollow&quot;&gt;PID&lt;/a&gt; control loop is that each term is intended to dominate control at different times during a move.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The proportional term is intended to dominate and provide a larger torque (or in your case speed) the further you are away from your target position.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The derivative term is intended to dominate during the 'cruise' phase of your typical trapezoidal move. It helps to reign back a very high proportional term and limit runaway acceleration when you are far from your destination, but it can also help increase the speed at which you converge on your destination when you get close to it and the proportional term contributes much less.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are using a velocity controller rather than a torque controller then the derivative term may actually be hidden inside your speed controller and not directly accessible to your PID loop. This can make control simpler (typically it will just accelerate as quickly as it can up to the desired speed or maximum speed, whichever is lower) but it can also make it less predictable. Often an overly aggressive D (or P) term can result in getting into a &lt;a href=&quot;http://en.wikipedia.org/wiki/Limit_cycle&quot; rel=&quot;nofollow&quot;&gt;limit cycle&lt;/a&gt; (often incorrectly called &lt;a href=&quot;http://en.wikipedia.org/wiki/Mechanical_resonance&quot; rel=&quot;nofollow&quot;&gt;resonance&lt;/a&gt; or &lt;a href=&quot;http://en.wikipedia.org/wiki/Oscillation&quot; rel=&quot;nofollow&quot;&gt;oscillation&lt;/a&gt; due to the sound of the motors humming or even screaming in this state, though &lt;em&gt;limit-cycle&lt;/em&gt; is a much more accurate description).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The integral term is there to correct for residual &lt;a href=&quot;http://en.wikipedia.org/wiki/PID_controller#Integral_term&quot; rel=&quot;nofollow&quot;&gt;steady-state error&lt;/a&gt;, that is where there is a persistent, long term difference between where you are being asked to go and where you actually are. Your current &lt;code&gt;correction&lt;/code&gt; (really just tolerance) value works like the opposite of an integral term, it cuts the motor entirely when you are within a &lt;a href=&quot;http://en.wikipedia.org/wiki/Deadband&quot; rel=&quot;nofollow&quot;&gt;deadband&lt;/a&gt; around the desired position.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Due to these factors, you will gain little from implementing a full PID loop unless you also plan in a velocity profile with a distinct accelerate, cruise &amp;amp; decelerate phases.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also bear in mind that the deadband and lack of I term will mean that the final position will always be somewhat random and will most likely differ depending on which direction you approach the desired position. As such, your bi-directional repeatability could be much worse than your standard repeatability.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For more information on the difference between accuracy, repeatability and resolution, see &lt;a href=&quot;http://www.me.mtu.edu/~microweb/chap2/ch2-1.htm&quot; rel=&quot;nofollow&quot;&gt;this excellent description&lt;/a&gt;. In your case, your resolution is your compass sensor, while both accuracy, repeatability are most likely limited by your &lt;code&gt;correction&lt;/code&gt; value, since if the &lt;code&gt;correction&lt;/code&gt; value is larger than your compass resolution, you are throwing away some of your positional accuracy in return for being able to turn off your motor when you are close.&lt;/p&gt;&#xA;" OwnerUserId="37" LastEditorUserId="37" LastEditDate="2012-11-06T20:30:34.777" LastActivityDate="2012-11-06T20:30:34.777" />
  <row Id="25" PostTypeId="1" CreationDate="2012-10-23T20:34:39.070" Score="23" ViewCount="18934" Body="&lt;p&gt;There are many sites which explain briefly this problem and even propose combinations. I however would like a much more detailed explanation. What is going to give my quad the most agility? Do I need bigger motors/props in a heavy quad to achieve the same level of agility than in a lighter quad?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;EDIT:&lt;/strong&gt;&#xA;Here is what I have understood on the subject:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A quadcopter doesn't need high revving motors as there are 4 propellers providing thrust and high revving motors require more battery power.&lt;/li&gt;&#xA;&lt;li&gt;Larger propellers give more thrust per revolution from the motor.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The question is focused more on the general characteristics of various combinations but some specific questions do spring to mind: &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;For a given combination what would be the effect of upgrading propeller size in comparison to installing higher revving motors?&lt;/li&gt;&#xA;&lt;li&gt;What changes would need to be made to lift a heavier quad?&lt;/li&gt;&#xA;&lt;li&gt;How can I achieve more agility in my quad?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="49" LastEditorUserId="50" LastEditDate="2012-10-23T22:15:52.707" LastActivityDate="2012-11-07T19:52:08.770" Title="How to choose the right propeller/motor combination for a quadcopter?" Tags="&lt;quadrotor&gt;" AnswerCount="3" CommentCount="4" FavoriteCount="4" />
  <row Id="26" PostTypeId="1" AcceptedAnswerId="29" CreationDate="2012-10-23T20:41:21.887" Score="-10" ViewCount="93" Body="&lt;p&gt;I love computer programming, and if I can interact with the world programming, it's even better. I used to steal them from school, and make little robots that bounce when collided with a wall, but I want to go further, but I don't have the needed pieces, and I don't know any good place to buy pieces , like servos, etc. either.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, I'm Spanish, so if the page can sell to places in Spain, even better.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would highly appreciate your help,&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Aritzh&lt;/p&gt;&#xA;" OwnerUserId="66" LastEditorUserId="53" LastEditDate="2012-10-24T13:08:39.603" LastActivityDate="2012-10-24T13:08:39.603" Title="Cheap web to buy robotic pieces from" Tags="&lt;servos&gt;" AnswerCount="1" CommentCount="6" ClosedDate="2012-10-23T21:14:40.070" />
  <row Id="27" PostTypeId="2" ParentId="2" CreationDate="2012-10-23T20:45:15.613" Score="5" Body="&lt;p&gt;Usually, these types of hobby servos are not made for continuous rotation, and will often include a mechanical stop.  Beware, what I outline below is a surefire way to never get actual closed-loop operation, but will instead make the servo continuous-only.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Most of the time, you can do a quick search online for &quot;Continuous modification for x servo&quot;, but I will outline the general process here.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Determine if the servo has a physical stop.  If it does, you will have to open the servo and remove it (I recommend the Dremel tool).&lt;/li&gt;&#xA;&lt;li&gt;You then want to find the &quot;center&quot; of the feedback mechanism.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Connect the servo to your Arduino and send a &quot;center&quot; command (usually PWM 127).&lt;/li&gt;&#xA;&lt;li&gt;Find the feedback mechanism (typically a potentiometer), and trim it until the servo does not move at all.&lt;/li&gt;&#xA;&lt;li&gt;Either glue the potentiometer in place, or measure the resistance and replace the potentiometer with a set value resistor.&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;Reassemble the servo.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Now sending a &quot;center&quot; command to the servo should stop it from moving, while sending it a positive or negative command should cause it to rotate continuously in one direction or the other.  The rotation speed should be proportional to the &quot;distance&quot; from center of the command sent.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you want to restore servo operation to your newly-modified servo, you can add some sort of encoder to re-close the loop.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Alternatively, you may want to look at the &lt;a href=&quot;http://www.robotis.com/xe/dynamixel_en&quot;&gt;Dynamixel series&lt;/a&gt; servo, which allows for both continuous and servo'ed operation, and includes some Arduino support.&lt;/p&gt;&#xA;" OwnerUserId="22" LastActivityDate="2012-10-23T20:45:15.613" CommentCount="4" />
  <row Id="28" PostTypeId="2" ParentId="19" CreationDate="2012-10-23T20:46:39.947" Score="4" Body="&lt;p&gt;Assuming you don't have other functionality that would take precedence, I would use WASD for movement and Left/Right arrows or mouse buttons for accelerating. Having the controls be divided that way mimics the conventional movement/action interface seen in many video games, while letting the user control the speed in parallel to motion.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, ultimately, the right answer is whatever is most comfortable/intuitive. The above is what I'd try first, but the real best answer is getting user feedback.&lt;/p&gt;&#xA;" OwnerUserId="31" LastActivityDate="2012-10-23T20:46:39.947" CommentCount="1" />
  <row Id="29" PostTypeId="2" ParentId="26" CreationDate="2012-10-23T20:47:18.293" Score="2" Body="&lt;p&gt;I've bought plenty of pieces off &lt;a href=&quot;http://ebay.com/&quot; rel=&quot;nofollow&quot;&gt;Ebay&lt;/a&gt;. I'f you don't care about long shipping lots of stuff can be had for a few dollars.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You could also try &lt;a href=&quot;http://dx.com/&quot; rel=&quot;nofollow&quot;&gt;Deal Extreme&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.seeedstudio.com/depot/&quot; rel=&quot;nofollow&quot;&gt;Seedstudio&lt;/a&gt; also has a lot of nice Open Source hardware.&lt;/p&gt;&#xA;" OwnerUserId="61" LastActivityDate="2012-10-23T20:47:18.293" CommentCount="4" />
  <row Id="30" PostTypeId="2" ParentId="23" CreationDate="2012-10-23T20:49:31.223" Score="8" Body="&lt;p&gt;Optical avoidance of people in an every-day (like) environment would be difficult, your best bet would be with sensing the range of things from the robot, rather than if it is a person or not. An Xbox Kinect could do the job if mounted in the right place. Alternatively you could use range finders, either the light or acoustic variety. I have used Ultrasonic sensors from &lt;a href=&quot;http://www.seeedstudio.com/depot/ultra-sonic-range-measurement-module-p-626.html?cPath=144_149&quot;&gt;these people&lt;/a&gt; before, and they are good at ranges from about 5cm to around 3 meters, although they have an unfortunately small field of view, but they work. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Alternatively, if you are able to have a controlled environment, such as an arena or room, you can use &lt;a href=&quot;https://www.studentrobotics.org/docs/programming/sr/vision/markers&quot;&gt;libkoki&lt;/a&gt; markers (or an alteration thereof) to define the edges or your arena and anything the robot must not go near. The libkoki libraries can be found &lt;a href=&quot;https://github.com/chrisjameskirkham/libkoki&quot;&gt;here&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="46" LastActivityDate="2012-10-23T20:49:31.223" CommentCount="1" />
  <row Id="31" PostTypeId="2" ParentId="4" CreationDate="2012-10-23T20:49:35.573" Score="1" Body="&lt;p&gt;If you want to go further than using microcontrollers you could run ROS on you &lt;a href=&quot;http://www.ros.org/wiki/ROSberryPi/Setting%20up%20ROS%20on%20RaspberryPi&quot; rel=&quot;nofollow&quot;&gt;Raspberry Pi&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have build several robots and a couple of other projects using a &lt;a href=&quot;http://robocard.dk/&quot; rel=&quot;nofollow&quot;&gt;RoboCard&lt;/a&gt; (site in Danish, but can &lt;a href=&quot;http://translate.google.com/translate?js=y&amp;amp;prev=_t&amp;amp;hl=en&amp;amp;ie=UTF-8&amp;amp;layout=1&amp;amp;eotf=1&amp;amp;u=http://robocard.dk/pages/home.php&amp;amp;sl=da&amp;amp;tl=en&quot; rel=&quot;nofollow&quot;&gt;be translated&lt;/a&gt;). The RoboCard is build around an ATMega, so that certainly is a viable route.&lt;/p&gt;&#xA;" OwnerUserId="61" LastActivityDate="2012-10-23T20:49:35.573" />
  <row Id="32" PostTypeId="5" CreationDate="2012-10-23T20:50:20.863" Score="0" ViewCount="2" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2012-10-23T20:50:20.863" LastActivityDate="2012-10-23T20:50:20.863" />
  <row Id="33" PostTypeId="4" CreationDate="2012-10-23T20:50:20.863" Score="0" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2012-10-23T20:50:20.863" LastActivityDate="2012-10-23T20:50:20.863" />
  <row Id="34" PostTypeId="5" CreationDate="2012-10-23T20:51:36.573" Score="0" ViewCount="2" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2012-10-23T20:51:36.573" LastActivityDate="2012-10-23T20:51:36.573" />
  <row Id="35" PostTypeId="4" CreationDate="2012-10-23T20:51:36.573" Score="0" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2012-10-23T20:51:36.573" LastActivityDate="2012-10-23T20:51:36.573" />
  <row Id="36" PostTypeId="2" ParentId="6" CreationDate="2012-10-23T20:55:24.760" Score="1" Body="&lt;p&gt;MOOS is Oxford's ROS analog. &lt;a href=&quot;http://www.robots.ox.ac.uk/~mobile/MOOS/wiki/pmwiki.php&quot; rel=&quot;nofollow&quot;&gt;http://www.robots.ox.ac.uk/~mobile/MOOS/wiki/pmwiki.php&lt;/a&gt; It's used for a number of naval applications, from harbor-sweeping to low-power, UUVs that surface to report in intervals counted in months.&lt;/p&gt;&#xA;" OwnerUserId="31" LastActivityDate="2012-10-23T20:55:24.760" />
  <row Id="37" PostTypeId="1" CreationDate="2012-10-23T21:04:59.783" Score="-2" ViewCount="174" Body="&lt;p&gt;I want to localize a mobile robot equipped with a 2D laser scanner in a known indoor environment.  The map is a 2D occupancy grid, but is not perfect.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What algorithms are appropriate for mobile robot localization?&lt;/p&gt;&#xA;" OwnerUserId="73" LastEditorUserId="73" LastEditDate="2012-10-24T18:25:16.983" LastActivityDate="2012-10-24T18:25:16.983" Title="Mobile robot localization in a known map" Tags="&lt;localization&gt;&lt;mobile-robot&gt;" AnswerCount="2" CommentCount="2" ClosedDate="2012-10-24T23:25:13.167" />
  <row Id="38" PostTypeId="2" ParentId="3" CreationDate="2012-10-23T21:11:04.363" Score="16" Body="&lt;p&gt;Discrete gaits are a very limited way of implementing hexapod motion.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Imagine trying to limit a person to two speeds, walk and run.  In reality we spend a lot of time meandering around with no defined gait or in transitions between various gaits.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is a reasonable amount of research on insect gaits and the common discrete gaits you read about are essentially what insects settle upon as the optimal solution when spending a long time at a single speed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A gait can be fully defined by the timings of its return strokes.  In general, going faster requires performing more return strokes in a given amount of time (which is why a tripod gate will be faster than a tetrapod gait which will be faster than a wave/ripple).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am not an expert in insect locomotion, but my understanding is that each leg independently decides when to return based on a set of simple rules.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As an example, a leg must return when it approaches the end of its stroke.  To avoid having all the legs retract at once, legs are discouraged from performing their return stroke when its neighbours are retracting, or if the leg directly opposite is retracting.&lt;br&gt;&#xA;As well, legs are mildly discouraged from retracting when any other leg is retracting so as many legs are on the ground as possible.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It is easy to see that both the tripod and ripple gait obey the above rules but you also get additional gaits and transitions as speed and direction changes.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;TL;DR An insect will never use a single gait so if you want optimal creepyness (or efficiency since evolution is pretty good at that) there are a lot of books/papers on how insects walk.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT: There are also a lot of per-leg rules that help traverse rough terrain.  As an example, legs will always try to stand in a spot where a leg has already been (since it knows that place is solid).  A typical insect will place its front legs in areas it knows are secure and all the subsequent legs will only use those locations.&lt;/p&gt;&#xA;" OwnerUserId="65" LastActivityDate="2012-10-23T21:11:04.363" />
  <row Id="39" PostTypeId="1" AcceptedAnswerId="45" CreationDate="2012-10-23T21:12:46.500" Score="3" ViewCount="177" Body="&lt;p&gt;As in the title, I'd like to implement gesture recognition on my robot and I'm looking for the pros and cons between the Kinect and the Xtion - and also if there are any other sensible options available.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm thinking of the following, but open to other suggestions:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Accuracy&lt;/li&gt;&#xA;&lt;li&gt;Price&lt;/li&gt;&#xA;&lt;li&gt;Driver quality&lt;/li&gt;&#xA;&lt;li&gt;Power draw&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="74" LastActivityDate="2013-12-02T18:00:12.543" Title="I'd like to use gesture based input for my robot. What are the pros and cons between the Xtion Live and the Kinect?" Tags="&lt;kinect&gt;&lt;input&gt;" AnswerCount="5" CommentCount="5" />
  <row Id="40" PostTypeId="2" ParentId="37" CreationDate="2012-10-23T21:14:50.640" Score="2" Body="&lt;p&gt;As i have mentioned in &lt;a href=&quot;http://robotics.stackexchange.com/questions/23/f-oss-optical-object-avoidance/&quot;&gt;this&lt;/a&gt; post, it can be achieved with a camera and some markers in known locations on/in the environment as demonstrated &lt;a href=&quot;http://team759.blogspot.co.uk/2012/02/more-intelligent-cube-finding.html&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt; by the robotics team I am in. We use the location of the markers on the desks, which have a known height and width, and the center we can get from the libkoki library. It is then a simple task of using some trigonometry to find out where we are, as demonstrated in &lt;a href=&quot;http://team759.blogspot.co.uk/2012/03/getting-position-of-robot.html&quot; rel=&quot;nofollow&quot;&gt;this blog post&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Although by &lt;code&gt;Given sensors&lt;/code&gt; I assume you don't know what method you are going to use... I'm sure there are other ways of getting your position to varying degrees of accuracy.&lt;/p&gt;&#xA;" OwnerUserId="46" LastActivityDate="2012-10-23T21:14:50.640" />
  <row Id="41" PostTypeId="2" ParentId="37" CreationDate="2012-10-23T21:15:20.300" Score="8" Body="&lt;p&gt;Particle filters or &lt;a href=&quot;http://en.wikipedia.org/wiki/Monte_Carlo_localization&quot;&gt;Monte Carlo localization&lt;/a&gt; can be used. Basically you distribute a set of points at random across the maps and see which points would have sensor readings most similar to the reading from your map. The best points survive and you create new points and so forth. After some iterations you have a group of points, hopefully, all in the same place on the map as your robot. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I believe there is a few methods explained in &lt;a href=&quot;http://www.udacity.com/overview/Course/cs373/CourseRev/apr2012&quot;&gt;this course&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="61" LastActivityDate="2012-10-23T21:15:20.300" />
  <row Id="42" PostTypeId="1" AcceptedAnswerId="103" CreationDate="2012-10-23T21:18:17.723" Score="8" ViewCount="119" Body="&lt;p&gt;I'm looking to potentially build an autonomous robot that will frequently venture off road, and remain autonomous for up to 6 hours at a time. I've found limited information however about the best tyre tread for this purpose, what could be most suitable?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm especially looking for a tread pattern that won't need regular cleaning, to save setting this up automatically (a tread that gets &quot;clogged&quot; very quickly clearly won't be that effective at tackling tough terrain autonomously.)&lt;/p&gt;&#xA;" OwnerUserId="74" LastActivityDate="2012-10-24T15:33:59.000" Title="What tyre tread would be best suited to an off road robot expected to deal with frequently muddy conditions?" Tags="&lt;wheel&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="43" PostTypeId="1" AcceptedAnswerId="96" CreationDate="2012-10-23T21:22:09.763" Score="18" ViewCount="351" Body="&lt;p&gt;Is there a good, popular and reliable algorithm I can use by taking input from a gyroscope and using this to control two independant wheels to keep such a balanced robot reliably upright? I'm looking for an algorithm that will let me use it to drive a robot around as well as keep it upright when stationary. The ability to deal with inclines and people &lt;em&gt;nudging&lt;/em&gt; it would also be a bonus, but not essential.&lt;/p&gt;&#xA;" OwnerUserId="74" LastEditorUserId="50" LastEditDate="2012-10-23T21:25:20.583" LastActivityDate="2012-10-25T05:34:54.000" Title="What algorithm should I use for balancing a two wheeled robot using a gyroscope?" Tags="&lt;control&gt;&lt;gyroscope&gt;&lt;balance&gt;&lt;two-wheeled&gt;" AnswerCount="3" FavoriteCount="6" />
  <row Id="44" PostTypeId="1" CreationDate="2012-10-23T21:25:49.197" Score="7" ViewCount="278" Body="&lt;p&gt;I'm looking to potentially build an &lt;a href=&quot;http://en.wikipedia.org/wiki/Underwater_glider&quot;&gt;underwater glider&lt;/a&gt;, a type of submarine that's slow but can operate on extremely low power draw. However, in order for it to work effectively I've found several sources hinting that the dimensions of the components, especially the wings, are critical to its success.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, I've found very sparse information about what these dimensions should be! I'm happy to do a bit of trial and error if it comes down to it, but to save some work does anyone have any information on what the critical dimensions should be?&lt;/p&gt;&#xA;" OwnerUserId="74" LastEditorUserId="350" LastEditDate="2012-11-15T14:59:30.737" LastActivityDate="2012-11-15T14:59:30.737" Title="Choosing the right dimensions for an underwater glider" Tags="&lt;design&gt;&lt;underwater&gt;&lt;auv&gt;" AnswerCount="1" CommentCount="1" FavoriteCount="2" />
  <row Id="45" PostTypeId="2" ParentId="39" CreationDate="2012-10-23T21:28:21.570" Score="8" Body="&lt;p&gt;I know the Xtion is smaller and powered by USB where as the Kinect requires to use a wall power socket to operate. In terms of depth perception they are very similar in terms of accuracy. Depending on whether your robot needs to be portable (i.e not attatched to the mains) and small should probably be the deciding factor.&lt;/p&gt;&#xA;" OwnerUserId="80" LastActivityDate="2012-10-23T21:28:21.570" CommentCount="2" />
  <row Id="46" PostTypeId="1" AcceptedAnswerId="66" CreationDate="2012-10-23T21:31:31.177" Score="14" ViewCount="298" Body="&lt;p&gt;I'm looking to build an underwater glider robot that will need to remain autonomous for long periods of time, perhaps even months. Power draw should be minimal, and I'm thinking of including some form of charging device (such as a solar charger) however I'd also like the battery capacity to be large enough so I don't hugely need to worry about this. Large current draw isn't really needed, but the battery does need to hold its charge effectively for long periods of time. Considering this is an underwater vehicle, weight and size are also a concern.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cost isn't too much of an issue, as long as it's within reason of a hobbyist project.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am looking to understand the pros and cons of each technology (Lead acid, LiPo, NiCad, fuel cell?), so I can decide what type of battery would be best suited to my purpose. As such, I'm looking at battery technology rather than looking for a specific shopping recommendation.&lt;/p&gt;&#xA;" OwnerUserId="74" LastEditorUserId="350" LastEditDate="2012-11-15T14:59:25.663" LastActivityDate="2012-11-21T17:02:53.280" Title="What's the most effective type of rechargeable battery when taking into account size / weight / Ah?" Tags="&lt;underwater&gt;&lt;batteries&gt;&lt;auv&gt;" AnswerCount="3" CommentCount="7" FavoriteCount="2" />
  <row Id="47" PostTypeId="2" ParentId="20" CreationDate="2012-10-23T21:38:26.130" Score="3" Body="&lt;p&gt;This can depend very much on your requirements - how far away do you need to shoot? How accurately do you need to shoot? Does power draw matter in the shot?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, some of the following may be of use:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Pneumatic system: If you want unrivalled shot power, this is probably the way to go - you can blast the ball pretty much as hard as you like. It also has minimal electrical current draw because it'd be mainly powered by a compressed tank filled beforehand. However, in a lot of situations this wouldn't be allowed, and it can be bulky and expensive.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Spring based system: You could have a motor which winds a spring up to the desired tension, then releases it. This can be powerful given a powerful enough spring and motor, and relatively cheap to implement. Downsides though are time taken to wind the spring up (so successive rapid shots are difficult) and this could draw quite a lot of power.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Multiple spring based system: As above, but bypasses much of the speed issue by using multiple springs and firing each one when necessary. More expensive and complicated to implement though.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Sheer speed: If you build a very quick robot, and design a &quot;ram&quot; on the front of it, sometimes simply ramming into the ball can be enough to shoot it into the goal. Very simple to implement, and can be effective with a good driver, but makes it much harder to use. A version of this involves putting a flipper on one side of the robot and then spinning the robot around quickly to shoot the ball. Accuracy also suffers with this approach however.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="74" LastActivityDate="2012-10-23T21:38:26.130" />
  <row Id="48" PostTypeId="1" AcceptedAnswerId="59" CreationDate="2012-10-23T21:46:04.840" Score="8" ViewCount="160" Body="&lt;p&gt;It's common for components on some types of robots to experience large environmental stresses, one key one being vibration. Is this something I need to worry about with typical electronics and other sensitive components, or not really? If it is, then how do I secure such components? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've heard of two main philosophies behind this, the first being that you should use a damping system such as with springs to absorb the shock. The second is that you should keep everything rigidly in place so it can't move, and therefore can't hit against anything else and break.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Which one should I follow, or if the answer is &quot;it depends&quot; what should I use as a guide as to best protect sensitive components?&lt;/p&gt;&#xA;" OwnerUserId="74" LastEditorUserId="350" LastEditDate="2012-11-30T14:32:28.130" LastActivityDate="2012-11-30T14:32:28.130" Title="How can I best protect sensitive components against damage through vibration?" Tags="&lt;electronics&gt;&lt;protection&gt;" AnswerCount="4" FavoriteCount="1" />
  <row Id="49" PostTypeId="1" AcceptedAnswerId="62" CreationDate="2012-10-23T22:01:52.997" Score="7" ViewCount="130" Body="&lt;p&gt;Obviously GPS is the most obvious and accessible technology for obtaining a locational &quot;fix&quot; for a robot at any particular time. However, while it's great sometimes, in other locations and situations it's not as accurate as I'd like, so I'm investigating whether there's a relatively easy way to improve on this accuracy (or not, if that turns out to be the case.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've considered the following options, but found limited information online:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Would using a much better antenna help, especially for low signal areas? I'm thinking yes to this, but if so how would I construct such an antenna and know that it's an improvement? Are there any good guides on how to do this? I could use a ready made antenna if they're not too expensive.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Would using multiple separate receivers in tandem help, or would they likely all be off by a similar amount, or would I not be able to extract a meaningful average with this approach?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;What sort of characteristics should I look for when choosing a good GPS receiver to help accuracy?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Is there anything else I should consider which I've missed?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="74" LastEditorUserId="50" LastEditDate="2012-10-23T22:04:11.473" LastActivityDate="2012-10-24T10:58:55.750" Title="What's the most accurate way to obtain a locational fix using GPS?" Tags="&lt;localization&gt;&lt;gps&gt;" AnswerCount="4" />
  <row Id="50" PostTypeId="2" ParentId="2" CreationDate="2012-10-23T22:29:05.897" Score="10" Body="&lt;p&gt;What you're asking isn't going to be very easy with a standard RC servo.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What you're asking for is a back-drivable servo. I.E. one which you can freely rotate by applying an external torque. It is certainly possible to create these, and they are used on many robots, but most RC servos require considerable torque to back drive them. I would call them semi-backdrivable.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What prevents you back driving them? Two things:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Friction:&lt;/strong&gt; Firstly, friction in the gear chain and motor. RC servos are always geared down; the output spins slower than the motor. Of course this means that when you try to back drive it, you have to spin the motor very quickly. Any friction or cogging in the motor will be felt dozens of time over at the output.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/KFZwV.jpg&quot; alt=&quot;backdrivability&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Current:&lt;/strong&gt; something surprising about electric motors is that, if you short the terminals, they become harder to turn. The rotation of the motor generates an electric current which works against your rotation. The electronics inside the servo might well allow enough current to flow, even when off, that it noticeably prevents backdrivability. In the past I have noticed that some large stepper motors, even when ungeared, are almost impossible to back drive when plugged in to unpowered equipment. But when you unplug them, they can be spun freely.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, one way you can improve the back-drivability is to prevent current flowing. The obvious way to do this is to fully disconnect the motor from its electronics. But this is hard to do, even using FETs, because the diodes inside the FETs might well allow current to flow. However, you could use a relay, which really would disconnect the motor. You'd only have to use it on one of the motor's terminals.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/9Yv1Y.jpg&quot; alt=&quot;Maxon's ESCON&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;'Proper' servo controllers (like the &lt;a href=&quot;http://escon.maxonmotor.com/&quot;&gt;ESCON&lt;/a&gt; from Maxon) actually contain a current controller which can actively prevent current flowing by applying the correct voltage at the motor terminals. Replacing the electronics in the servo with something capable of current control might really help.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What you should do:&lt;/strong&gt; Open up the servo, unsolder the motor, and re-assemble it. How easy is it to back-drive now? If it's easy, then it may be possible to do what you want. If it's still too hard for your application, then you're going to have to choose a different servo, or make your own. Make one with a single gear stage so that the gear friction is reduced as much as possible, and use drive electronics with a current control loop to guarantee zero current flow.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-10-23T22:29:05.897" CommentCount="1" />
  <row Id="51" PostTypeId="2" ParentId="43" CreationDate="2012-10-23T22:33:02.217" Score="8" Body="&lt;p&gt;I believe the most popular solution to this problem is an &lt;a href=&quot;http://en.wikipedia.org/wiki/Linear-quadratic_regulator&quot;&gt;LQR&lt;/a&gt; controller. The problem you are trying to solve is the &lt;a href=&quot;http://en.wikipedia.org/wiki/Inverted_pendulum&quot;&gt;inverted pendulum problem&lt;/a&gt;. Using those keywords, you should be able to Google someone's open-source code. The next problem will be mapping most of the relevant physics quantities to your application (weight, motor torque, etc...)&lt;/p&gt;&#xA;" OwnerUserId="42" LastActivityDate="2012-10-23T22:33:02.217" />
  <row Id="52" PostTypeId="2" ParentId="4" CreationDate="2012-10-23T22:37:29.867" Score="7" Body="&lt;p&gt;The Arduino is really an AVR Atmega328p. The Arduino is a fine off-the-shelf implementation of this microcontroller, but if you make many of them, you can buy the chip for less than $3 each in bulk, and it requires very little circuitry to run on its own -- a crystal and a couple of capacitors to run at 20 Mhz, or not even that if you can run at the built-in 8 MHz resonant oscillator frequency.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It's fine for generating control signals: Servo PWM, step/direction, control for H-bridges, etc.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It's also OK for running sensors: Ultrasonic time measurement, IR voltage conversion measurement, on/off contactors, etc -- this includes whatever optical sensor you'd use for &quot;line sensing.&quot;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There will be a little code space left over after doing these tasks, so the simple control loop of &quot;is the line to the right, left, or center of me -&gt; do the appropriate turn&quot; can be built into that system. However, as soon as you want to do something bigger, like path planning, environmental awareness, memory, SLAM, etc, you will not be able to fit that into the Arduino.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thus, the best system for your requirements probably includes tying all the physical hardware to the Arduino, and then talking to the Arduino from the Raspberry Pi. The RPi has a modicum of CPU power (700 MHz ARM) and RAM (256-512 MB RAM) and thus can run higher-level control algorithms like path planning, localization, SLAM, etc.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you go with a bare AVR controller, there are UART outputs on the Raspberry Pi, but the problem is that the RPi is 3.3V and the Arduino Uno is 5V. Either go with a 3.3V Arduino version, or use a voltage divider to step down 5.0V output from the Arduino to the 3.3V input of the Raspberry Pi. I use a 2.2 kOhm high and 3.3 kOhm low resistor and it works fine. You can feed the 3V output from the Raspberry Pi directly into the RXD of the AVR, because it will treat anything at 1.2V or up as &quot;high.&quot;&lt;/p&gt;&#xA;" OwnerUserId="88" LastActivityDate="2012-10-23T22:37:29.867" />
  <row Id="53" PostTypeId="1" AcceptedAnswerId="73" CreationDate="2012-10-23T22:44:20.217" Score="4" ViewCount="184" Body="&lt;p&gt;Ultrasound sensors are incredibly cheap these days which makes them a popular choice for many hobbyist robotic applications, and I'd like to use a bunch of them (say 10) around a robot with an algorithm to build a rough map of an area (as the robot explores it.) I'm not interested in dealing with moving objects at this stage, just pinpointing stationary ones, and I'll be using GPS for location. I realise that other components such as a laser scanner would produce much more accurate results, however such devices are also astronomically more expensive.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Does an algorithm exist for this purpose?&lt;/p&gt;&#xA;" OwnerUserId="74" LastEditorUserId="350" LastEditDate="2012-11-30T14:06:04.743" LastActivityDate="2012-11-30T14:06:04.743" Title="What algorithm can I use for constructing a map of an explored area using a number of ultrasound sensors?" Tags="&lt;slam&gt;&lt;localization&gt;&lt;gps&gt;&lt;mapping&gt;&lt;acoustic-rangefinder&gt;" AnswerCount="3" />
  <row Id="55" PostTypeId="1" AcceptedAnswerId="211" CreationDate="2012-10-23T22:49:37.247" Score="6" ViewCount="219" Body="&lt;p&gt;Hobby servos are generally not sufficient for real robotics for a number of reasons: Quality, precision, range of motion, torque, etc.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Meanwhile, industrial servos, such as ABB, Emerson, GE, etc, are generally both heavy and expensive, and not suitable for small-humanoid scale actuation. Similarly, building your own servo from motors, gearboxes, and encoders, is akin to trying to design your own CPU just to control a motor -- too much detail getting in the way of real work.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There exists an in-between level of servos -- reasonably priced, reasonable performance, and reasonably controllable -- in the form of the competing brands of Dynamixel and HerculeX servos.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The smallest offerings in those lines generally are not strong enough for real-world interaction, but the next step up hold a lot of promise. For the Robotis Dynamixel line, this is the RX-24F servo (priced between the cheap AX-12F and the next step up the MX-28R.) Asking around, it seems that the specs and interface on that servo is great, but that it shuts down from thermal overload if you actually try to run it at rated load -- something that I'd expect from a hobby servo, but not a robotics servo.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now, stepping up to the MX-28R doubles the price. Thus, if the RX-24F heat flaw could be fixed, it would be positioned at a nice price/performance point.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Does anyone have experience in providing additional cooling for this servo? Anything from thermal-gluing heat sinks to the case, to drilling holes and running cooling fluid tubing to any hot parts on the interior would be reasonable approaches. However, before I spend significant time and effort investigating this, I'd like a second opinion -- is it possible, does anyone have experience doing this, is it worth it?&lt;/p&gt;&#xA;" OwnerUserId="88" LastActivityDate="2012-10-28T20:31:46.073" Title="Adding external heat sinking to a Dynamixel RX-24F servo?" Tags="&lt;servos&gt;&lt;heat-management&gt;&lt;cooling&gt;" AnswerCount="2" />
  <row Id="56" PostTypeId="2" ParentId="43" CreationDate="2012-10-23T22:49:43.470" Score="4" Body="&lt;p&gt;Since I don't know your skills in control engineering/theory, I recommend you to start with a &lt;a href=&quot;http://en.wikipedia.org/wiki/PID_controller&quot; rel=&quot;nofollow&quot;&gt;PID controller&lt;/a&gt;. It is a simple controller and you will find many code implementations of it. The drawback of the PID is that you probably will end up spending some time tuning the parameters by hand.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some years ago I used it to control a two wheeled Lego Mindstorm robot based on its odometry and it worked well enough.&#xA;To make it move around, you will need to play with the set points.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Of course, later on you can improve the the quality of your controller (stability, robustness etc.) by using more advanced control laws like the LQR mentioned before.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Good luck!&lt;/p&gt;&#xA;" OwnerUserId="90" LastActivityDate="2012-10-23T22:49:43.470" />
  <row Id="57" PostTypeId="1" AcceptedAnswerId="64" CreationDate="2012-10-23T22:51:07.573" Score="9" ViewCount="163" Body="&lt;p&gt;What characteristics can I look for which could be reliable early warning signs that a DC motor on my robot, say one used for the drive, could be failing? I'm looking for an answer that deals in terms of sensors rather than manual inspection, so a circuit could be constructed to warn of a potential failure before it happens.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have a few ideas such as an increase in current draw or decrease in rotation speed / voltage, but I want to guard against false warnings caused by reasonable wear and tear, or just the robot struggling on tough terrain.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Obviously such a system will never be foolproof, but are there any points I can look out for?&lt;/p&gt;&#xA;" OwnerUserId="74" LastActivityDate="2012-10-25T07:11:24.653" Title="How can I detect if a DC motor on a robot is starting to fail?" Tags="&lt;sensors&gt;&lt;failure&gt;&lt;motor&gt;" AnswerCount="2" FavoriteCount="1" />
  <row Id="58" PostTypeId="2" ParentId="6" CreationDate="2012-10-23T22:56:22.340" Score="5" Body="&lt;h1&gt;&lt;a href=&quot;http://www.orocos.org&quot; rel=&quot;nofollow&quot;&gt;Orocos&lt;/a&gt;&lt;/h1&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;It is one of the oldest open source framework in robotics, under development since 2001, and with professional industrial applications and products using it since about 2005. The focus of Orocos has always been to provide a hard real- time capable component framework — the so-called Real-Time Toolkit (RTT) implemented in C++ — and as independent as possible from any communication middleware and operating system.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;As @BarretAmes said there are integrations which allows the implementation of hybrid systems, where Orocos and other Software Framework work together. &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.ros.org/wiki/orocos_toolchain_ros&quot; rel=&quot;nofollow&quot;&gt;ROS Orocos Integration&lt;/a&gt; for ROS and Orocos integration&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://github.com/Robotics-UniBG/JOrocos/wiki&quot; rel=&quot;nofollow&quot;&gt;JOrocos&lt;/a&gt; for Java and ROS integration&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="87" LastEditorUserId="87" LastEditDate="2012-10-25T21:58:35.593" LastActivityDate="2012-10-25T21:58:35.593" CommentCount="2" />
  <row Id="59" PostTypeId="2" ParentId="48" CreationDate="2012-10-23T22:58:12.087" Score="6" Body="&lt;p&gt;Partly this depends on where the vibration is coming from.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;While the two techniques you describe are very valuable, if the vibration is from your own actuators then you may be able to significantly improve things by simply using a different velocity profile for your moves.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Traditional trapezoidal velocity profiles are a constant &lt;a href=&quot;http://en.wikipedia.org/wiki/Acceleration&quot;&gt;acceleration&lt;/a&gt; up to a fixed maximum &lt;a href=&quot;http://en.wikipedia.org/wiki/Velocity&quot;&gt;velocity&lt;/a&gt; followed a constant velocity cruise, followed by a constant deceleration back to zero velocity. This creates a high instantaneous &lt;a href=&quot;http://en.wikipedia.org/wiki/Jerk_%28physics%29&quot;&gt;jolt (or jerk)&lt;/a&gt; - the third derivative of position over time. It is this high &lt;em&gt;jolt&lt;/em&gt; which often causes vibration damage.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Many motion controllers offer an &lt;a href=&quot;http://cdn.intechweb.org/pdfs/4267.pdf&quot;&gt;S-curve&lt;/a&gt; velocity profile which is jolt constrained, this can reduce those high jolt impulses significantly. Also, since you are ramping up your acceleration you can often tune your PID loop more aggressively and actually gain point-to-point performance increases. Unfortunately this is at the cost of adding complexity to your move synchronisation and planning.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have also worked on systems which use pure &lt;a href=&quot;http://en.wikipedia.org/wiki/Spline_%28mathematics%29&quot;&gt;cubic splines&lt;/a&gt; for the whole move. These created silky smooth move profiles where adjacent moves merged seamlessly into each other with no perceptible jolt. These systems are even more difficult to synchronise moves with however and the maths at the planning step gets even more complex than with S-curves.&lt;/p&gt;&#xA;" OwnerUserId="37" LastActivityDate="2012-10-23T22:58:12.087" />
  <row Id="60" PostTypeId="1" AcceptedAnswerId="71" CreationDate="2012-10-23T23:02:36.980" Score="11" ViewCount="144" Body="&lt;p&gt;With two wheeled robot &lt;a href=&quot;http://www.pages.drexel.edu/~dml46/Tutorials/BalancingBot/files/nxt_icon.jpg&quot;&gt;like this one&lt;/a&gt;, I have managed to stabilize it while keeping it stationary. This was done using a digital feedback control system by reading the position of the wheels to determine position, and the natural back electromotive force from the wheel motors was used in the feedback loop to determine velocity. It was kept stable with a PID controller, which was designed using a root locus algorithm to keep it stable and modulate the performance parameters (such as percent overshoot, settling time, etc.). I wanted to attempt to keep it stable while simultaneously propelling it forward, but I couldn't figure out how to go about designing a linear controller that could do that. Is it possible to both propel the robot forward &lt;strong&gt;and&lt;/strong&gt; keep it stable using a feedback controller on the wheels, or is a gyroscope necessary?&lt;/p&gt;&#xA;" OwnerUserId="30" LastEditorUserId="141" LastEditDate="2012-10-24T13:19:15.430" LastActivityDate="2012-10-24T14:57:47.143" Title="Is it possible to both move and stabilize a two wheeled robot with no gyroscopes?" Tags="&lt;two-wheeled&gt;&lt;stability&gt;" AnswerCount="4" CommentCount="2" />
  <row Id="61" PostTypeId="2" ParentId="49" CreationDate="2012-10-23T23:05:47.447" Score="5" Body="&lt;p&gt;A traditional approach is to use an error correcting algorithm like a &lt;a href=&quot;http://en.wikipedia.org/wiki/Kalman_filter&quot;&gt;Kalman filter&lt;/a&gt;. By combining dead reckoning from wheel encoders and heading commands with GPS you can smooth out GPS jitter. This is not an instantaneous improvement as it requires a series of measurements to estimate the error inherent in the GPS signal.&lt;/p&gt;&#xA;" OwnerUserId="54" LastActivityDate="2012-10-23T23:05:47.447" CommentCount="1" />
  <row Id="62" PostTypeId="2" ParentId="49" CreationDate="2012-10-23T23:06:27.880" Score="6" Body="&lt;p&gt;Can't answer all your questions, but based on your use case &lt;a href=&quot;http://en.wikipedia.org/wiki/Differential_GPS&quot;&gt;Differential-GPS&lt;/a&gt; might help you.&#xA;Modern tractors are using this for precisely navigating on fields (in autonomous mode).&#xA;Here fixed ground stations are used, which know their exact position and calculate the error in the current signal. This adjustment is then used by the other GPS receiver in the area.&lt;/p&gt;&#xA;" OwnerUserId="90" LastActivityDate="2012-10-23T23:06:27.880" CommentCount="1" />
  <row Id="63" PostTypeId="2" ParentId="6" CreationDate="2012-10-23T23:07:44.853" Score="0" Body="&lt;h1&gt;&lt;a href=&quot;http://www.openrtm.org/openrtm/en/node/629&quot; rel=&quot;nofollow&quot;&gt;OpenRTM&lt;/a&gt;&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;OpenRTM-aist is developed by Japanese National Institute of Advanced Industrial Science and Technology which also contributes to definition of the RT-middleware standard.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It is an open-source component-based framework, which provides real-time capabilities.&#xA;Beside the framework some tools are available:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;RTC Builder: a tool for skeleton-code generation. It is launched in the eclipse developmental environment. OpenRTM-aist also supports RTC-template which is a command-line type skeleton-code generation tool.&lt;/li&gt;&#xA;&lt;li&gt;RT System Editor: an Eclipse based toolchain for designing components and component-based systems.&lt;/li&gt;&#xA;&lt;li&gt;rtshell is a command-line tool which provides following services&lt;/li&gt;&#xA;&lt;li&gt;RTC debugger: a debugging tool for RTCs. RTC debugger is an Eclipse plug-in.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="87" LastActivityDate="2012-10-23T23:07:44.853" />
  <row Id="64" PostTypeId="2" ParentId="57" CreationDate="2012-10-23T23:19:47.083" Score="7" Body="&lt;p&gt;There are two key things to look for from a control system point of view. The first is the root mean square of the torque applied and the second is the following error on moves.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As motors degrade over time they require more torque to be applied for the same acceleration, so if you have tuned your PID loop for a new, low loss motor then as it ages and the losses increase the motor will drift out of tune. At some point the motor will become worn enough that you will be unable to tune the PID parameters to give you the performance you need.Before this happens though you may already have started tripping a torque limit in your motion controller (it may not allow 100% toque for more than n ms for instance).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The problem with looking just at torque is that it can be difficult to keep track of, just looking at the max value will tell you nothing because many situations can cause 100% torque for short periods, especially with an aggressively tuned PID controller.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As it is constantly changing, setting up monitoring could easily be too lenient (resulting in &lt;a href=&quot;http://en.wikipedia.org/wiki/Type_I_and_type_II_errors#False_negative_error&quot;&gt;false negatives&lt;/a&gt;) or too strict (resulting in &lt;a href=&quot;http://en.wikipedia.org/wiki/Type_I_and_type_II_errors#False_positive_error&quot;&gt;false positives&lt;/a&gt;). This is why you probably want something closer to an &lt;a href=&quot;http://en.wikipedia.org/wiki/Root_mean_square&quot;&gt;RMS&lt;/a&gt; of the torque which you monitor over a long period and look at the trends.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another tool to look for failing motors is somewhat easier to use and that's the maximum &lt;a href=&quot;http://www.newport.com/Control-Theory-Terminology/178319/1033/content.aspx&quot;&gt;following error&lt;/a&gt; over a move. This is the maximum difference between where the motor was supposed to be and where it actually was at any point during the move. It is a single value for the whole move and is something that many motion controllers keep track of for their own use. In fact, many have soft limits on maximum following error and error if you exceed them.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Again, tripping a max follow error can just be an indication that you just need to retune your PID loop, but the frequency with which you need to retune your PID and the difficulty you have in achieving your desired performance can be valuable tools in determining when a motor is getting to the end of it's life.&lt;/p&gt;&#xA;" OwnerUserId="37" LastActivityDate="2012-10-23T23:19:47.083" />
  <row Id="65" PostTypeId="1" AcceptedAnswerId="107" CreationDate="2012-10-24T00:17:07.893" Score="9" ViewCount="870" Body="&lt;p&gt;I'm part of a &lt;a href=&quot;http://usfirst.org&quot;&gt;FIRST Robotics&lt;/a&gt; team, and we're looking into using &lt;a href=&quot;http://en.wikipedia.org/wiki/Mecanum_wheel&quot;&gt;Mecanum wheels&lt;/a&gt; for our robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What are the advantages and disadvantages of using Mecanum wheel versus regular ones? From looking through Google, it looks like Mecanum wheels give more mobility but don't have as much traction. Are there any other advantages or disadvantages?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Compared to regular wheels, are Mecanum wheels less efficient or more efficient in any way? And if so, is there a quantifiable way to determine by how much?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Are there equations I can use to calculate efficiency (or inefficiency) and/or speed of moving forwards, sideways, or at arbitrary angles?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;A picture of a robot with mecanum wheels:&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/kLSuG.png&quot; alt=&quot;robot using mecanum wheels&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="79" LastActivityDate="2012-10-24T15:56:30.673" Title="Calculating the efficiency of Mecanum wheels" Tags="&lt;mobile-robot&gt;&lt;wheel&gt;&lt;design&gt;&lt;movement&gt;" AnswerCount="2" CommentCount="1" FavoriteCount="3" />
  <row Id="66" PostTypeId="2" ParentId="46" CreationDate="2012-10-24T00:41:41.147" Score="13" Body="&lt;p&gt;The best commonly available battery technology when it comes to power density versus weight, and at reasonable cost, is LiPo.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would prbably recommend LiFePO4 batteries. LiFePO4 are somewhat more expensive than LiPo for the same watt-hours, and weigh somewhat more, but they hold the charge better, they age much better, and they can be re-charged five to ten times more than LiPo batteries before they lose their capacity.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For both of those kinds of batteries, if weight matters, you can design the &quot;battery enclosure&quot; as part of your robot, and buy cells that are just the chemistry enclosed in thin insulating plastic, and build your own battery pack from those cells to fit a custom-shaped cavity in your robot. Make sure to protect the battery against over-charge / over-discharge, though, because it will ruin the battery if you don't. LiPo may even catch fire when you do, whereas LiFePO4 will not.&lt;/p&gt;&#xA;" OwnerUserId="88" LastActivityDate="2012-10-24T00:41:41.147" CommentCount="6" />
  <row Id="67" PostTypeId="2" ParentId="4" CreationDate="2012-10-24T01:14:12.137" Score="4" Body="&lt;p&gt;I built a line following robot with an Arduino before.  It was really simple to do and all we used were color sensors on the bottom inputted in the Arduino, and then of course some motors for the wheels.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;But using an Arduino allowed us to have plenty of room for other components we wanted to add on to make our robot do more things.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, if you want to see some line following code we used just ask in a comment, but it obviously depends on your setup with the sensors and how you want it to turn at intersections and things like that.&lt;/p&gt;&#xA;" OwnerUserId="99" LastActivityDate="2012-10-24T01:14:12.137" CommentCount="2" />
  <row Id="68" PostTypeId="2" ParentId="4" CreationDate="2012-10-24T01:37:25.863" Score="3" Body="&lt;p&gt;You should use an ARM. Then you can run full linux or android and have access to powerful libraries, high-level functional languages, and a package manager and community. You can use gcc or LLVM, and a modern debugger like gdb.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;ARMs used to be too expensive and/or too big, but nowadays you can get an ARM for $5 that's only 13x13 mm. You have to use reflow soldering, but you will anyways if you want to make a professional-quality robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.eetimes.com/electronics-products/electronic-product-reviews/processors/4230227/TI-debuts--5-Sitara-AM335x-ARM-processors&quot; rel=&quot;nofollow&quot;&gt;http://www.eetimes.com/electronics-products/electronic-product-reviews/processors/4230227/TI-debuts--5-Sitara-AM335x-ARM-processors&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;All other instructions sets have lost the competition. If you  pick something like AVR, you will be forever stuck with inferior toolchains, weaker MIPS/dollar, and a much smaller community.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you don't want to engineer the whole motherboard, then Gumstix, BeagleBone, BeagleBoard, and Raspberry Pi are all excellent pre-existing ARM-based devkits, and processor vendors also offer a devkit for every processor they make, bringing out at least a display bus and some serial busses.&lt;/p&gt;&#xA;" OwnerUserId="106" LastEditorUserId="106" LastEditDate="2012-10-24T01:42:37.603" LastActivityDate="2012-10-24T01:42:37.603" CommentCount="3" />
  <row Id="69" PostTypeId="5" CreationDate="2012-10-24T01:54:52.113" Score="0" ViewCount="4" Body="&lt;p&gt;Localization is the problem of estimating a robot's pose relative to a map of its environment. There are a number of types of robot localization. The easiest is position tracking, where the initial pose of the robot is known and the localization system must correct for small errors generated by the robot's &lt;a href=&quot;http://robotics.stackexchange.com/questions/tagged/odometry&quot;&gt;odometry&lt;/a&gt;. A more difficult problem is the global localization problem, where the robot is not told its initial position and must determine it. Localization is a sub-problem of the more complex field of Simultaneous Localization and Mapping (&lt;a href=&quot;http://robotics.stackexchange.com/questions/tagged/slam&quot;&gt;SLAM&lt;/a&gt;), where the localization system must build the map and locate the robot in the map at the same time. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;One of the key sub-problems is the kidnapped robot problem. After the robot has localized, the robot is transported to a different location without being informed of the transition. This problem tests the localization system's ability to recover from complete failure. &lt;/p&gt;&#xA;" OwnerUserId="42" LastEditorUserId="42" LastEditDate="2012-10-24T13:09:59.680" LastActivityDate="2012-10-24T13:09:59.680" />
  <row Id="70" PostTypeId="4" CreationDate="2012-10-24T01:54:52.113" Score="0" Body="Localization is the problem of estimating a robot's pose relative to a map of its environment." OwnerUserId="42" LastEditorUserId="42" LastEditDate="2012-10-24T13:10:18.697" LastActivityDate="2012-10-24T13:10:18.697" />
  <row Id="71" PostTypeId="2" ParentId="60" CreationDate="2012-10-24T02:15:22.920" Score="3" Body="&lt;p&gt;You could use other ways of measuring orientation, such as an accelerometer, optical tracking of markers, or a depth sensor pointed at the floor.&lt;/p&gt;&#xA;" OwnerUserId="106" LastActivityDate="2012-10-24T02:15:22.920" CommentCount="1" />
  <row Id="72" PostTypeId="2" ParentId="53" CreationDate="2012-10-24T02:15:30.750" Score="5" Body="&lt;p&gt;There is a whole area of literature on this topic. The most general idea is that of Simultaneous Localization and Mapping (&lt;a href=&quot;http://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping&quot;&gt;SLAM&lt;/a&gt;), where the robot must build a map at the same time as it locating itself in that map. Depending on how accurate you want your maps to be, you can attempt a simpler problem of creating an &lt;a href=&quot;http://en.wikipedia.org/wiki/Occupancy_grid_mapping&quot;&gt;occupancy grid map&lt;/a&gt;, which assumes you know the location of the robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In general, GPS is pretty horrible, so generating an occupancy grid just using GPS as your primary location source will generate pretty fuzzy maps. However, it is possible to integrate GPS with acceleration, gyroscopes, compasses, cameras, wheel encoders and other sensors to approximate a good position in the world. Otherwise, you will need to look into a simple SLAM system to handle your problems. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;A nice open-source package &lt;a href=&quot;http://openslam.org/g2o.html&quot;&gt;g2o&lt;/a&gt;, for so-called GraphSLAM, allows you to put in constraints like GPS and relative position to walls. It may not be an exact fit, but it is pretty general.&lt;/p&gt;&#xA;" OwnerUserId="42" LastActivityDate="2012-10-24T02:15:30.750" CommentCount="1" />
  <row Id="73" PostTypeId="2" ParentId="53" CreationDate="2012-10-24T03:35:28.810" Score="4" Body="&lt;p&gt;The algorithms are essentially the same regardless of what sensors you are using.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The real issue, which &lt;a href=&quot;http://robotics.stackexchange.com/a/72/37&quot;&gt;Chris touched upon&lt;/a&gt;, is that SLAM is hard even with very good sensors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would consider GPS, wheel odometry, and an IMU to be necessary to even attempt slam with ultrasound.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are just looking for cheap localization I recommend taking a look at vision/kinect based slam as well.  Both webcams and the kinect are very cheap and visual slam has come a long way.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The kinect is pretty much the holy grail in terms of sensor performance/cost as long as you are indoors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here is an example of a kinect on a robot plus a lot of math: &lt;a href=&quot;http://www.youtube.com/watch?v=9Y4RQVpp-BY&quot; rel=&quot;nofollow&quot;&gt;http://www.youtube.com/watch?v=9Y4RQVpp-BY&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="65" LastEditorUserId="37" LastEditDate="2012-10-24T13:10:14.563" LastActivityDate="2012-10-24T13:10:14.563" />
  <row Id="74" PostTypeId="2" ParentId="65" CreationDate="2012-10-24T03:52:26.840" Score="6" Body="&lt;p&gt;I have some experience with using mecanum wheels, both indoors and outdoors (on grass, sand and dirt no less).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Obvious advantage is holonomic movement.  Disadvantages are weight (commercially available wheels are ridiculously heavy) and cost.  For a given tread material traction will be along the lines of 65-70% that of a regular wheel due to the smaller contact area and 45% rollers.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Compared to skid steer, mecanum wheels have no additional friction when turning which is an advantage.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Mecanum wheels will be simpler and perhaps more reliable than a swerve/crab drive system.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Everything is always about tradeoffs.  If I compared an ideal mecanum system to an ideal swerve drive system (full 360 degree rotation, extremely fast wheel orientation) the swerve wins in performance because it has full traction.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;An ideal swerve system will be expensive and difficult to implement compared to mecanum wheels though.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Efficiency is a loaded question.  An ideal mecannum wheel will be equivalent to any other system when moving in any direction, and will turn better than a skid steer system.&#xA;In reality the rollers have reasonable friction so going sideways will be less efficient than going forwards.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Getting exact numbers would require a lot of fairly accurate measurements which isn't practical.&lt;/p&gt;&#xA;" OwnerUserId="65" LastActivityDate="2012-10-24T03:52:26.840" />
  <row Id="75" PostTypeId="1" AcceptedAnswerId="76" CreationDate="2012-10-24T04:13:21.397" Score="6" ViewCount="241" Body="&lt;p&gt;I've got this driver: &lt;a href=&quot;http://www.pololu.com/catalog/product/1182&quot; rel=&quot;nofollow&quot;&gt;http://www.pololu.com/catalog/product/1182&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;... a A4988 stepper motor driver carrier&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/MPEI5.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm attempting to control a connection between the RESET and SLEEP pins with logic ( code ) running on my Arduino. The motor runs perfectly when these two pins are connected however I'd like to control when the stepper is powered off from my Arduino ( and thus not generating extra heat )&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'd like to:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;designate a pin to control the connection between these two pins&lt;/li&gt;&#xA;&lt;li&gt;use a &quot;digitalWrite&quot; to the above pin with a HIGH or LOW to&#xA;switch power on and off from the stepper&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;NOTE: The &lt;a href=&quot;http://www.pololu.com/file/0J450/a4988_DMOS_microstepping_driver_with_translator.pdf&quot; rel=&quot;nofollow&quot;&gt;data sheet&lt;/a&gt; mentioned that for the driver to be powering the stepper both RESET and SLEEP needed to be in switched on ( HIGH )&lt;/p&gt;&#xA;" OwnerUserId="111" LastEditorUserId="111" LastEditDate="2012-12-01T09:10:46.850" LastActivityDate="2012-12-01T09:10:46.850" Title="Using an Arduino to control an ON / OFF connection between two pins" Tags="&lt;arduino&gt;&lt;logic-control&gt;&lt;stepper-motor&gt;&lt;stepper-driver&gt;" AnswerCount="1" />
  <row Id="76" PostTypeId="2" ParentId="75" CreationDate="2012-10-24T04:30:19.350" Score="14" Body="&lt;p&gt;You are going about this incorrectly.  The reason why pololu is telling you to connect the two pins is because the sleep pin has a pullup resistor on their breakout board.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Connecting reset to the sleep pin is equivalent to connecting the reset pin to high.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can achieve your goal by connecting reset pin to high (5V through pullup resistor) and connect the sleep pin directly to your arduino just like the step/dir pins.&lt;/p&gt;&#xA;" OwnerUserId="65" LastActivityDate="2012-10-24T04:30:19.350" CommentCount="1" />
  <row Id="77" PostTypeId="2" ParentId="48" CreationDate="2012-10-24T04:42:05.623" Score="6" Body="&lt;p&gt;Components should have vibration ratings somewhere.  Pretty much anything without moving parts will be fine.  Some sensors such as accelerometers and gyroscopes are affected.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As an example, quadrotors are an application that is dramatically affected by vibration.  The four props produce an absolutely ridiculous amount of vibration and a quadrotor requires accurate sensor data from the accelerometers/gyros.  If you look at the accelerometer plots you will see an unbelievable amount of noise.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Despite this, very few quads have any form of vibration damping, a kalman filter is enough to get good data.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is a lot of literature of vibration damping and several possible approaches (both active and passive).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have found that memory foam is ideal for damping vibrations to electronics and small sensors such as accel/gyro.  Memory foam is very soft but more importantly is designed to dampen extremely well.  I have cut down accelerometer noise on UAVs by ~80% by using memory foam in the past.&lt;/p&gt;&#xA;" OwnerUserId="65" LastActivityDate="2012-10-24T04:42:05.623" />
  <row Id="79" PostTypeId="2" ParentId="48" CreationDate="2012-10-24T08:29:57.937" Score="6" Body="&lt;p&gt;On the &lt;a href=&quot;http://robotik.dfki-bremen.de/en/research/robotsystems/asguard-iii.html&quot;&gt;Asguard&lt;/a&gt; system that we have been working on, we have a lot of shocks due to the wheel geometry. On this system we were also able to reduce the vibrations on the control side as &lt;a href=&quot;http://robotics.stackexchange.com/a/59/37&quot;&gt;Mark suggested&lt;/a&gt;. This was done through synchronising the wheels in optimal patterns. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The system also has some mechanical design features that reduces the vibrations. Flexible wheels, elestic couplings between the gears and the wheel and locking mechanisms for most of the screws. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The electronics are not rigidly connected to the structure, but use a combination of foam and rubbers to hold them in place. This has worked well so far. We had a lot of problems with connecters however, where we frequently would get micro-fractures on the board connectors, especially on the heavier connectors like firewire. In these cases we had to create mechanical structures to hold the connectors in place, or replace the connectors by lightweight alternatives where possible.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Sensitive components, like for example the IMU and the cameras we have rigidly connected to the system. It is true that this improves the noise on the accelerometers, but the Kalman Filter never had a big problem with it for estimating the orientation. When using short exposure times on the camera, the vibrations are also not much of a problem. From a sensor point of view we really expected much more problems than we actually had.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So I guess the answer to your question is that it really depends on your system, and as we have seen in our case that often you do not even need to protect your components from vibration too much.&lt;/p&gt;&#xA;" OwnerUserId="127" LastEditorUserId="37" LastEditDate="2012-10-24T11:30:16.270" LastActivityDate="2012-10-24T11:30:16.270" />
  <row Id="80" PostTypeId="2" ParentId="6" CreationDate="2012-10-24T09:17:28.110" Score="1" Body="&lt;p&gt;&lt;a href=&quot;http://playerstage.sourceforge.net/&quot; rel=&quot;nofollow&quot;&gt;Player/Stage&lt;/a&gt; is still one of the most popular open source robotics projects out there. It's been around for a long time and some of its developers have moved on to start ROS, but that doesn't detract from Player's usefulness. Indeed, all three main components, Player (the framework), Stage (the 2D simulator), and Gazebo (the 3D simulator), have been made to be somewhat &lt;a href=&quot;https://www.willowgarage.com/pages/software/player&quot; rel=&quot;nofollow&quot;&gt;compatible with ROS&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="131" LastActivityDate="2012-10-24T09:17:28.110" />
  <row Id="81" PostTypeId="2" ParentId="60" CreationDate="2012-10-24T09:57:21.070" Score="2" Body="&lt;p&gt;If you managed to get it stable in a stationary configuration, I don't really see how it would be much more difficult to get it stable for a constant velocity. From a system model point of view it would effectively be the same thing bar some velocity offsets. If the transitions between velocities are not very large it should fall within the range of the natural system perturbations. &lt;/p&gt;&#xA;" OwnerUserId="127" LastActivityDate="2012-10-24T09:57:21.070" />
  <row Id="82" PostTypeId="2" ParentId="49" CreationDate="2012-10-24T10:11:55.067" Score="1" Body="&lt;p&gt;If you want to be really clever, you could consider &lt;a href=&quot;http://en.wikipedia.org/wiki/Assisted_GPS&quot; rel=&quot;nofollow&quot;&gt;Assisted GPS (see Wikipedia for full details)&lt;/a&gt; which uses the phone network to provide a better initial fix, by using the cell towers fixed positions as a basis.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note, however, that A-GPS uses your data stream, so if you have to pay for data, you may not want to use this!!!&lt;/p&gt;&#xA;" OwnerUserId="134" LastActivityDate="2012-10-24T10:11:55.067" CommentCount="1" />
  <row Id="83" PostTypeId="5" CreationDate="2012-10-24T10:15:28.807" Score="0" ViewCount="9" Body="&lt;p&gt;SLAM (Simultaneous Localization And Mapping) refers to a robot building a map of its environment through it's sensor data (mapping) and keeping track of its own position in that map (localization) at the same time.&lt;/p&gt;&#xA;" OwnerUserId="131" LastEditorUserId="131" LastEditDate="2012-10-24T13:09:15.720" LastActivityDate="2012-10-24T13:09:15.720" />
  <row Id="84" PostTypeId="4" CreationDate="2012-10-24T10:15:28.807" Score="0" Body="SLAM (Simultaneous Localization And Mapping) refers to a robot building a map of its environment through it's sensor data (mapping) and keeping track of its own position in that map (localization) at the same time." OwnerUserId="131" LastEditorUserId="131" LastEditDate="2012-10-24T13:10:03.877" LastActivityDate="2012-10-24T13:10:03.877" />
  <row Id="85" PostTypeId="1" AcceptedAnswerId="98" CreationDate="2012-10-24T10:21:01.003" Score="6" ViewCount="716" Body="&lt;p&gt;For a robotic gripper arm we are designing for factory floor use on very small components, we propose to use electrically activated Shape Memory Alloy (SMA) wire harnesses for actuation. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The device being designed is akin to Pick &amp;amp; Place machines used for circuit assembly, but moves over an aircraft-hanger sized work surface on wheels. It manipulates irregular shaped and porous objects between 0.5 cu.cm and 8 cu.cm each - hence the traditional vacuum P&amp;amp;P mechanism does not appeal. Also, individual objects in the assembly line have varying hardness and weights.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Our design constraints are: &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Ensuring minimal to zero vibration and sound &lt;/li&gt;&#xA;&lt;li&gt;Using minimal volume within the mechanism (batteries are at the wheelbase, providing stability, so their weight is not a concern)&lt;/li&gt;&#xA;&lt;li&gt;Fine variation of gripper pressure&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;We believe SMA meets the first two constraints well, but need some guidance on achieving constraint 3, i.e. different levels of pressure of the gripper controlled electronically.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My questions:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Can PWM of a current above the activation threshold (320 mA for &lt;a href=&quot;http://www.dynalloy.com/TechDataWire.php&quot; rel=&quot;nofollow&quot;&gt;0.005 inch Flexinol HT&lt;/a&gt;) provide variable, repeatable actuation force? &lt;/li&gt;&#xA;&lt;li&gt;Would we need pressure sensors on each fingertip and a closed loop control for grip, or can the gripper be calibrated periodically and maintain repeatable force?&lt;/li&gt;&#xA;&lt;li&gt;Is there any well-documented precedent or study we should be referring to?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="109" LastEditorUserId="50" LastEditDate="2012-10-24T10:51:06.493" LastActivityDate="2012-10-24T15:00:53.547" Title="Shape Memory Alloy wire for robot gripper arm actuation: How to vary grip pressure?" Tags="&lt;mobile-robot&gt;" AnswerCount="2" />
  <row Id="86" PostTypeId="5" CreationDate="2012-10-24T10:25:37.390" Score="0" ViewCount="3" Body="&lt;p&gt;GPS (Global Positioning System) is an outdoor localization system that measures time of flight of a radio signal from a number of satellites in earth orbit. Each satellite sends a very precisely time-stamped signal that also includes its current location in earth orbit. By comparing the time difference in when signals from multiple satellites arrive with the time stamp and location, the position of the receiver can be worked out using triangulation. As GPS necessitates a line of sight to the satellites (although it works through clouds and rain), it is not suitable for indoor localization. It is usually accurate to about 10-15m. Using Differential GPS, which also takes into account signals from earth-based ground stations, accuracy can be improved to about 10cm.&lt;/p&gt;&#xA;" OwnerUserId="131" LastEditorUserId="131" LastEditDate="2012-10-24T13:09:50.647" LastActivityDate="2012-10-24T13:09:50.647" />
  <row Id="87" PostTypeId="4" CreationDate="2012-10-24T10:25:37.390" Score="0" Body="GPS (Global Positioning System) is an outdoor localization system that measures time of flight of a radio signal from a number of satellites in earth orbit." OwnerUserId="131" LastEditorUserId="131" LastEditDate="2012-10-24T13:10:09.010" LastActivityDate="2012-10-24T13:10:09.010" />
  <row Id="88" PostTypeId="1" AcceptedAnswerId="111" CreationDate="2012-10-24T10:41:24.373" Score="3" ViewCount="590" Body="&lt;p&gt;Design goal is to have a mobile robot that operates on 3 large casters, essentially 2 to 4 inch diameter steel ball bearings, that are motorized. No other mechanism would touch the surface. The robot should thus be able to move in any XY direction on a flat surface, with steering being achieved by varying the speed and rolling direction of these wheels. The robot has no designated &quot;front&quot; side, so it does not need to (and should not have to) bodily turn, in order to move off in any given direction. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Conventional wheels or tracks are not the preferred approach. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Looking for suggested mechanical layouts of multiple rubber wheels, pressing down onto the steel ball from within the castor housing, to drive the ball in any direction. A single wheel on a stepper, rotated around the vertical axis using a sail-winch servo, is one approach under consideration. Would this be ideal, or are there any serious flaws in this approach?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Alternatively, is there any other suggested method of driving such a steel ball in any arbitrary direction under electronic control?&lt;/p&gt;&#xA;" OwnerUserId="109" LastActivityDate="2012-10-24T23:25:24.897" Title="Mechanical design for motorized spherical caster wheels" Tags="&lt;servos&gt;&lt;mobile-robot&gt;&lt;stepper-motor&gt;" AnswerCount="2" />
  <row Id="89" PostTypeId="2" ParentId="49" CreationDate="2012-10-24T10:58:55.750" Score="3" Body="&lt;p&gt;As other posters have pointed out, using some form of differential GPS will give you large improvements in precision. We have used the Magelan mb500 commercial platform and it claims an accuracy of around 2-3 cm when in RTK fix mode. However, in areas of bad satellite coverage it would sometimes not even provide a solution at all, where cheap GPS receivers in a phone could. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is an open source library called &lt;a href=&quot;http://www.rtklib.com/&quot; rel=&quot;nofollow&quot;&gt;RTKLib&lt;/a&gt; which looks very promising for using cheap GPS equipment with a number of different methods for improving the precision. &lt;/p&gt;&#xA;" OwnerUserId="127" LastActivityDate="2012-10-24T10:58:55.750" CommentCount="1" />
  <row Id="90" PostTypeId="2" ParentId="85" CreationDate="2012-10-24T12:17:45.737" Score="2" Body="&lt;p&gt;&lt;strong&gt;Why you shouldn't use SMA&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Firstly, I have to wonder why you have chosen to use shape memory alloys in a robotic application. If you look at any of the application lists for SMAs, you'll almost never see a robotic application on the list.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Most SMA applications are non-actuated, and include things like glasses frames and golf clubs.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some applications do use the SMA as an actuator, but usually only once or twice. These are applications like medical stents, which need to be inserted into an artery small, but open up once inside.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The reason there are no robotic applications where the SMA needs to act as an actuator and exert a force cause something to move, is that it's subject to fatigue. According to the &lt;a href=&quot;http://en.wikipedia.org/wiki/Shape-memory_alloy#Fatigue_and_functional_fatigue&quot; rel=&quot;nofollow&quot;&gt;Wikipedia&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;SMA is subject to fatigue; a failure mode by which cyclic loading results in the initiation and propagation of a crack that eventually results in catastrophic loss of function by fracture.&#xA;  in addition to this failure mode, which is not exclusively observed in smart materials. SMA are also subject to Functional Fatigue, whereby the SMA does not fail structurally, but, due to a combination of applied stress, and/or temperature, loses (to some degree) its ability to undergo a reversible phase transformation.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;But if you insist&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Because SMA undergoes creep and fatigue, you will &lt;em&gt;have&lt;/em&gt; to have some kind of force transducer and control system to make sure you're applying a known force.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What I would suggest&lt;/strong&gt;&#xA;Rather than SMAs, there are many small actuators which can satisfy your constraints without the huge drawbacks of SMA.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Voice Coils:&lt;/strong&gt; These simply consist of a permanent magnet and a coil. Adjusting the flow of current directly affects the force applied to the magnet. Ungeared, these are totally silent, and more power efficient than SMAs. The force applied is quite repeatable, as long as the ambient temperature doesn't vary enormously. You can buy these as ready made components from &lt;a href=&quot;http://www.pwr-con.com/voice-coil-motor.htm&quot; rel=&quot;nofollow&quot;&gt;Moticont&lt;/a&gt;. Or open up a hard drive, look there's a ready made robotic finger!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/gpAZf.jpg&quot; alt=&quot;Voice coil robotic finger&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Piezo actuators:&lt;/strong&gt; There's a range of different motors based on piezo ceramics. These are usually very tiny, but expensive motors. Try the Squiggle motors from &lt;a href=&quot;http://www.newscaletech.com/squiggle_overview.html&quot; rel=&quot;nofollow&quot;&gt;Newscale Tech&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/Xr2Xe.jpg&quot; alt=&quot;Squiggle Motor&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There's a company called &lt;a href=&quot;http://www.flxsys.com/Applications/Advanced%20Actuators/&quot; rel=&quot;nofollow&quot;&gt;Flexsys&lt;/a&gt; who make actuators using both technologies.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/Ajcus.jpg&quot; alt=&quot;Voice Coil actuator&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-10-24T12:17:45.737" CommentCount="7" />
  <row Id="91" PostTypeId="1" AcceptedAnswerId="104" CreationDate="2012-10-24T13:42:36.257" Score="9" ViewCount="142" Body="&lt;p&gt;&lt;a href=&quot;http://www.youtube.com/watch?v=ZHJf365p_zw&quot;&gt;Many robots&lt;/a&gt; and other mechanical devices produce the signature whirring noise as they move, &lt;a href=&quot;http://www.youtube.com/watch?v=67CUudkjEG4&quot;&gt;some&lt;/a&gt; produce less. What makes the difference? What restrictions a silence requirement places on a robot?&lt;/p&gt;&#xA;" OwnerUserId="141" LastActivityDate="2012-10-24T19:21:43.483" Title="What determines the amount of noise an actuator produces?" Tags="&lt;motor&gt;&lt;actuator&gt;&lt;noise&gt;" AnswerCount="3" FavoriteCount="1" />
  <row Id="92" PostTypeId="2" ParentId="60" CreationDate="2012-10-24T14:43:06.310" Score="2" Body="&lt;p&gt;You need some sensors to detect the state of the system.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;First linearize the system into a state space form, then consider what sensors you do have. Then check if it is observable. If it is observable, then you can feed the estimated states into your controller.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Currently, it sounds like you are using the wheel position and back EMF (for velocity) as direct measurements. Without checking the observability matrix, I am unsure if the system is observable.&lt;/p&gt;&#xA;" OwnerUserId="145" LastActivityDate="2012-10-24T14:43:06.310" />
  <row Id="93" PostTypeId="1" CreationDate="2012-10-24T14:49:20.000" Score="2" ViewCount="106" Body="&lt;p&gt;I am looking for a servo drive to control a brushless DC motor, with at least 10A, 30V rating. However, I want to know if any exist which take sinusoidal hall sensor signals directly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I already know there are servo drives taking hall sensor pulses (with 6 different phases), but that is trapezoidal control.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note: a servo drive includes the driving electronics (no additional transistors required).&lt;/p&gt;&#xA;" OwnerUserId="145" LastEditorUserId="158" LastEditDate="2014-01-10T10:48:14.477" LastActivityDate="2014-01-10T10:48:14.477" Title="What BLDC servo drive takes sinusoidal hall sensor signals?" Tags="&lt;brushless-motor&gt;&lt;hall-sensor&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="94" PostTypeId="1" CreationDate="2012-10-24T14:49:39.577" Score="-5" ViewCount="106" Body="&lt;p&gt;I would be very interested to ask for a list of repos of free open code, applicable to 8-bit avr-s and having relation to robotics - object avoidance, process controllers, battery management, etc. This would be of huge help for me, preventing me from wasting weeks and months to invent the wheel.&lt;/p&gt;&#xA;" OwnerUserId="125" LastEditorUserId="50" LastEditDate="2012-10-24T15:00:17.430" LastActivityDate="2013-12-30T10:33:36.290" Title="Developing for 8-bit AVR-s, what are the current, open and free libraries out there?" Tags="&lt;software&gt;&lt;microcontroller&gt;" AnswerCount="2" CommentCount="5" FavoriteCount="0" ClosedDate="2012-12-05T21:13:56.780" />
  <row Id="95" PostTypeId="2" ParentId="94" CreationDate="2012-10-24T14:51:31.870" Score="1" Body="&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.fourwalledcubicle.com/LUFA.php&quot; rel=&quot;nofollow&quot;&gt;Lightweight USB Framework for AVRs&lt;/a&gt; — this seems to be a giant in its field. I have not used it, however, and cannot comment on it. &lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.atmel.com/Images/doc2558.pdf&quot; rel=&quot;nofollow&quot;&gt;Atmel's PID implementation&lt;/a&gt; — I can't seem to find the source files at the moment. This is a small and fast integer-arithmetic module, really simple to use. However, choosing the P, I and D coefficients is the real challenge. &lt;/li&gt;&#xA;&lt;li&gt;Modules from &lt;a href=&quot;http://www.siwawi.arubi.uni-kl.de/avr_projects/tempsensor/index.html&quot; rel=&quot;nofollow&quot;&gt;this project&lt;/a&gt; can be used for USART and for Dallas &lt;a href=&quot;http://www.atmel.com/dyn/resources/prod_documents/doc2579.pdf&quot; rel=&quot;nofollow&quot;&gt;one-wire&lt;/a&gt; communication. I am not sure about the license&amp;nbsp;— the authors do not apper to claim anything.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://github.com/H2CO3/libavrutil&quot; rel=&quot;nofollow&quot;&gt;libavrutil&lt;/a&gt; — haven't used this. Copileft license. Covers all basic hardware: ADC-s, PWM-s, USART etc. C and C++ interface.&lt;/li&gt;&#xA;&lt;li&gt;Arduino libraries for &lt;a href=&quot;http://www.arduino.cc/en/Reference/Servo&quot; rel=&quot;nofollow&quot;&gt;RC servos&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://github.com/rickygu/openBMS&quot; rel=&quot;nofollow&quot;&gt;openBMS&lt;/a&gt; Lithium ion Battery Management System for Electric Vehicle&lt;/li&gt;&#xA;&lt;li&gt;The &lt;a href=&quot;http://reprap.org&quot; rel=&quot;nofollow&quot;&gt;RepRap project&lt;/a&gt; has a bunch of open-source stepper-motor-control code that runs on an AVR&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="125" LastEditorUserId="1177" LastEditDate="2013-12-30T10:33:36.290" LastActivityDate="2013-12-30T10:33:36.290" CommentCount="4" CommunityOwnedDate="2012-10-24T14:51:31.870" />
  <row Id="96" PostTypeId="2" ParentId="43" CreationDate="2012-10-24T14:55:48.137" Score="11" Body="&lt;p&gt;The simplest controller is a linear state feedback controller. There are essentially 4 different states that you need a gain for. These are tilt angle, tilt rate, speed and position.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;LQR&lt;/strong&gt; (linear quadratic regulator) is a method to design these gains (after obtaining a linearized state-space representation of your system). If you do not have a state space representation (you probably don't), you can get equations of motion and measure the parameters. If you do not have a state space representation, you should just tune the gains manually (without LQR or other methods such as &lt;strong&gt;pole placement&lt;/strong&gt;).&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;h1&gt;Tuning gains manually:&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;Assuming tilt angle, position/speed and wheel torques are all directed forwards (if positive), you want a positive gain on your tilt angle and tilt rate, as well as a positive gain on position and speed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Start with a gain on tilt angle, and tilt rate. This will get it to balance initially. Once it remains balanced, you can control position and speed by adding a gain to them. If it is unstable, increase the gain on tilt rate (which helps to damp the system).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The position/speed control will control both states to zero. To control to some other value, you just need a reference tracking controller, by replacing the states with their errors before feeding it into your controller (eg. current speed - speed reference).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Yaw control can be done independently (with the differences in wheel torques added to the main balance/speed/position controller).&lt;/p&gt;&#xA;" OwnerUserId="145" LastEditorUserId="145" LastEditDate="2012-10-25T05:34:54.000" LastActivityDate="2012-10-25T05:34:54.000" />
  <row Id="97" PostTypeId="2" ParentId="60" CreationDate="2012-10-24T14:57:47.143" Score="2" Body="&lt;p&gt;Mathematically, the fact that you now have rotation (mostly) eliminates that parameter as a possible control parameter.  Basically you'd have to redesign your algorithm to accept a large and variable angular velocity component while still using angular velocity in your feedback.  The less noisy this is, the better the probable outcome simply because you're likely going to apply a differential of position to derive another control parameter.  Or rather that is one way.  So it does look like you need another control input, but it need not be an accelerometer.  You could do a horizon, fixed marker location or even tilt sensors.&lt;/p&gt;&#xA;" OwnerUserId="93" LastActivityDate="2012-10-24T14:57:47.143" />
  <row Id="98" PostTypeId="2" ParentId="85" CreationDate="2012-10-24T15:00:53.547" Score="5" Body="&lt;p&gt;Have a look at the paper &lt;a href=&quot;http://www.dynalloy.com/pdfs/TCF1140.pdf&quot;&gt;Technical Characteristics of Flexinol Actuator Wires&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What you'll want to do is devise a structure that leverages the available contraction of the nitinol wire to achieve the desired stroke and force for your application. The paper give a couple of example structures:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/i1giv.png&quot; alt=&quot;structures 1&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/jKiFI.png&quot; alt=&quot;structures 2&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/i6vwx.png&quot; alt=&quot;stroke and force&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The percentage of contraction of nitinol is related to it's temperature. However, the relationship is non-linear and differs between the heating phase and the cooling phase. These differences will need to be taken into account.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/dPrWV.png&quot; alt=&quot;temp vs. contraction&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the article &lt;a href=&quot;http://robotics.hobbizine.com/flexinolresist.html&quot;&gt;precision flexinol position control using arduino&lt;/a&gt; the author describes how to use the properties of nitinol so that the wire can act as it's own feedback sensor:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Flexinol, also known as Muscle Wire, is a strong, lightweight wire&#xA;  made from Nitinol that can be made to contract when conducting&#xA;  electricity. In this article I'll present an approach to precision&#xA;  control of this effect based on controlling the voltage in the&#xA;  Flexinol circuit. In addition, taking advantage of the fact that the&#xA;  resistance of Flexinol drops predictably as it contracts, the&#xA;  mechanism described here uses the wire itself as a sensor in a&#xA;  feedback control loop. Some advantages of eliminating the need for a&#xA;  separate sensor are reduced parts count and reduced mechanical&#xA;  complexity.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;So by using PWM to vary the voltage across the wire and using an ADC to read that voltage drop, you can design closed loop control of the percentage of contraction of the nitinol wire. Then, using an appropriate mechanical structure, you can translate that contraction into the desired stroke and force needed for your application.&lt;/p&gt;&#xA;" OwnerUserId="142" LastActivityDate="2012-10-24T15:00:53.547" CommentCount="3" />
  <row Id="99" PostTypeId="1" AcceptedAnswerId="224" CreationDate="2012-10-24T15:07:52.240" Score="4" ViewCount="933" Body="&lt;p&gt;I have a number of interrupt service routines on an AVR. These include interrupts for usart serial communication, timers, and SPI communication.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For all of these, I use circular queues (using a start and end pointer, without boundary checking).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some problems start to occur if the AVR starts to get overloaded. The circular queues will lose chunks of data. To solve this, I can reduce the load on the AVR (eg. by skipping some cycles in the timer). However, this is a manual process, where it is reduced if the AVR appears to have problems. This is partly because I do want relatively consistent timer periods.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, even at 70% average processor load, the queues can fill up randomly by chance.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In case of spurious overloading at times, how can I make this more adaptive to avoid queue overflows?&lt;/p&gt;&#xA;" OwnerUserId="145" LastEditorUserId="50" LastEditDate="2012-10-24T15:08:46.380" LastActivityDate="2012-11-06T20:39:34.383" Title="How to manage interrupts on an AVR?" Tags="&lt;microcontroller&gt;&lt;avr&gt;&lt;interrupts&gt;" AnswerCount="3" CommentCount="9" />
  <row Id="100" PostTypeId="1" AcceptedAnswerId="180" CreationDate="2012-10-24T15:17:21.853" Score="6" ViewCount="316" Body="&lt;p&gt;If you have used connectors for signal wiring for any length of time, you may find that they are unreliable.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Specifically, I find these to be unreliable when used for a long time, with a number of disconnections and re-connections:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/RDJQV.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is due to the loss of springy-ness of the crimped metal end on the wire, which causes contact problems.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Which connectors (with rapid connection time) are reliable for multiple re-connections for simple signal wiring?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This excludes screw terminals and connectors with screws (eg. D-subminiature connectors), because they are not simple plug-in connectors.&lt;/p&gt;&#xA;" OwnerUserId="145" LastActivityDate="2012-11-07T20:26:31.823" Title="What connectors are most reliable?" Tags="&lt;wiring&gt;" AnswerCount="4" CommentCount="5" FavoriteCount="2" />
  <row Id="101" PostTypeId="2" ParentId="48" CreationDate="2012-10-24T15:19:02.577" Score="2" Body="&lt;p&gt;It will take a lot to shake components off of a PCB/PWB so for the most part it should be safe if you make sure that the mounting is correct.  One thing that people forget is that if there is vibration then there may also be flex, and even tiny amounts of flex transmitted into a PWB can be damaging.  FR4 is stiff and in the wrong location will take a lot of the stress loads.  But this is easily fixed with the right kind of mounting that doesn't allow the force to transfer through the board - anchored on one side, semi-rigid on the other side.&lt;/p&gt;&#xA;" OwnerUserId="93" LastActivityDate="2012-10-24T15:19:02.577" />
  <row Id="102" PostTypeId="2" ParentId="53" CreationDate="2012-10-24T15:29:09.373" Score="2" Body="&lt;p&gt;To do SLAM, you will need a relatively good estimate of position.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Robots that use laser scanners can make do with just odometry, because the data is relatively accurate, and the scanner data can be used to help localize in subsequent time steps.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ultrasound sensors are very fuzzy, they generally have a direction fuzziness of 20+ degrees, and anything in the general direction will be detected.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thus, they are of negligible help in helping to localize (except in very structured environments).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A GPS/IMU combination can be used to get reasonable localization. Of course, this depends on the scale of the robot, and if it is indoors, GPS may not be practical.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are able to carefully control wheel slippage, wheel odometry can significantly improve localization in the short term (although an absolute method of localization is preferred). Without an absolute reference (eg. GPS), even with a laser scanner, you will need to be able to solve the problem of &quot;closing the loop&quot;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Structured environments may have a lower accuracy requirement. For example, a maze-like environment with walls at regular square grid distances, where it is simple to detect the presence of a wall in each direction of a grid cell.&lt;/p&gt;&#xA;" OwnerUserId="145" LastActivityDate="2012-10-24T15:29:09.373" />
  <row Id="103" PostTypeId="2" ParentId="42" CreationDate="2012-10-24T15:33:59.000" Score="3" Body="&lt;p&gt;There is very little difference between a robotic off road vehicle and a normal vehicle with a driver. What kind of vehicles are suitable for off-road conditions?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Why - tractors of course!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/ho71x.jpg&quot; alt=&quot;Tractor&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Look at those bad boys! Great for all around the farm. Nobody seems to talk about the importance of cleaning the mud off them, except to read the part number to order replacements.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In fact, why not other off-road vehicles? Like Land Rovers:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/3WOAg.jpg&quot; alt=&quot;Land Rover&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;They seem to be able to undertake long expeditions without requiring cleaning.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Or Monster trucks:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/tW98e.jpg&quot; alt=&quot;Monster Truck&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What you'll notice about the treads on these types of tyres is the alternating half-chevron patterns. They point in such a way that the mud sliding on the tyre is always pushed towards the outside of the tyre, eventually falling off. In a way they're self cleaning.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-10-24T15:33:59.000" CommentCount="1" />
  <row Id="104" PostTypeId="2" ParentId="91" CreationDate="2012-10-24T15:41:57.073" Score="5" Body="&lt;p&gt;Many parts of the actuation system create noise. One important noise generator is the gear train between the motor and the effector. All of those toothed wheels rattle slightly against each other, each contributing slightly to the orchestra of noise. This is one of the reasons behind the development of Maxon's &lt;a href=&quot;http://www.maxonmotor.co.uk/maxon/view/news/MEDIENMITTEILUNG-Koax-Drive&quot;&gt;Koaxdrive&lt;/a&gt; gear, which is targeted at low noise applications:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/osdLC.jpg&quot; alt=&quot;Maxon Koaxdrive cear&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-10-24T15:41:57.073" CommentCount="1" />
  <row Id="105" PostTypeId="2" ParentId="18" CreationDate="2012-10-24T15:42:36.533" Score="5" Body="&lt;p&gt;You can get experimental data, and perform some statistical analysis to determine the process noise (noise between time steps), and sensor noise (compared to a ground truth).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To get the ground truth for sensor noise, you either need a more accurate sensor, or else experimentally test while keeping the state of interest at a known (usually fixed) value.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you do not have experimental data, you can use the datasheets or specifications for each sensor to determine its noise. The process noise would be more difficult in this instance, but you may be able to guess at its value by assuming a certain amount of noise due to, for example, an actuator, if the actuator is the primary source of process noise.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Another way is to consider the maximum settling time allowed for estimation. This will determine the ratio between the process noise and sensor noise. This allows you to have the maximum filtering effect while meeting your settling time requirements.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note that this does not provide a good way to tune the ratio between different sensors, or between different states, so is not perfect.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Basically, if you have experimental data, you can obtain optimal performance. Otherwise, you can only calculate process noise based by assuming the likely noise of the dominant contributor to process noise, or by determining what minimum performance is required (which is not optimal, but at least gets what is needed).&lt;/p&gt;&#xA;" OwnerUserId="145" LastActivityDate="2012-10-24T15:42:36.533" />
  <row Id="106" PostTypeId="1" CreationDate="2012-10-24T15:53:23.727" Score="7" ViewCount="474" Body="&lt;p&gt;What is a suitable model for two-wheeled robots? That is, what equations of motion describe the dynamics of a two-wheeled robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Model of varying fidelity are welcome. This includes non-linear models, as well as linearized models.&lt;/p&gt;&#xA;" OwnerUserId="145" LastEditorUserId="53" LastEditDate="2012-10-24T23:24:32.067" LastActivityDate="2012-11-25T09:40:10.533" Title="What is a suitable model for two-wheeled robots?" Tags="&lt;mobile-robot&gt;&lt;two-wheeled&gt;" AnswerCount="2" CommentCount="1" FavoriteCount="2" />
  <row Id="107" PostTypeId="2" ParentId="65" CreationDate="2012-10-24T15:56:30.673" Score="6" Body="&lt;p&gt;Efficiency isn't the right thing to compare due to various advantages and disadvantages of each type of wheel. Comparing the efficiency of the different types of wheels is like comparing apples and oranges.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, comparing speed and force can give a good comparison of the different types of wheels. Here is a table that offers a quick and simple comparison (&lt;strong&gt;&lt;em&gt;Note that this assumes fictionless bearings and equal traction!&lt;/em&gt;&lt;/strong&gt;):&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/FBWEI.gif&quot; alt=&quot;wheel comparison chart&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Trying to take into account slipage gets hairy. From the paper &quot;Kinematic Analysis of Four-Wheel Mecanum Vehicle&quot; which is at the top of &lt;a href=&quot;http://www.chiefdelphi.com/media/papers/2390&quot;&gt;this list of papers&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;This problem, in general, has no solution, since it represents an &#xA;  overdetermined system of simultaneous linear equations. The  physical&#xA;  meaning of this is: if four arbitrary rotational  velocities are&#xA;  chosen for the four wheels, there is in general no  vehicle motion&#xA;  which does not involve some wheel &quot;scrubbing&quot;  (slipping) on the&#xA;  floor. However, a matrix [F] which generates a  &quot;best fit&quot; least&#xA;  squares solution can be found&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="142" LastActivityDate="2012-10-24T15:56:30.673" CommentCount="1" />
  <row Id="108" PostTypeId="2" ParentId="91" CreationDate="2012-10-24T16:44:17.600" Score="4" Body="&lt;p&gt;There is the motor with its mechanical balancing, and its bearings, and all associated rotary parts, with their respective vibrations, adding up. If a brushed DC motor is used, the brushes have an inherent commutation &quot;whirring&quot;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also friction noise of all moving parts, though this last is much damped as a side-effect of lubricants used, hence usually not a big factor. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;A parallel would be the ancient floppy disk drives, which rotated much slower than a blue-ray drive, but made quite a racket, compared to the near-silent, excellently mechanically balanced, modern Brushless DC motors running blue-ray drives and hard disks.&lt;/p&gt;&#xA;" OwnerUserId="109" LastActivityDate="2012-10-24T16:44:17.600" />
  <row Id="109" PostTypeId="2" ParentId="88" CreationDate="2012-10-24T19:13:56.563" Score="2" Body="&lt;p&gt;What about two perpendicular rubber sheathed shafts? This would have the benefit of neatly separating out the x and y directions into two components.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This could be thought of as an inversion of the function of an old &lt;a href=&quot;http://en.wikipedia.org/wiki/Mouse_%28computing%29#Mechanical_mice&quot; rel=&quot;nofollow&quot;&gt;analogue mouse&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From the comments, it is clear that in order to rotate the steel balls in 100% x or y, the rollers on the opposing axis must be removed from contact with the balls.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is also the assumption that the castor housing has bearings to keep the steel ball in position.&lt;/p&gt;&#xA;" OwnerUserId="101" LastEditorUserId="101" LastEditDate="2012-10-24T23:25:24.897" LastActivityDate="2012-10-24T23:25:24.897" CommentCount="6" />
  <row Id="110" PostTypeId="2" ParentId="91" CreationDate="2012-10-24T19:21:43.483" Score="3" Body="&lt;p&gt;Whilst the two answers in place focus on mechanical noise (which is what I think you are asking about) there is also, of course, electrical noise which manifests itself as Electro-Magnetic Interference (EMI or also known as EMC)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Anything that contains a motor is likely to generate a level of EMI... normally a small level that you don't notice it, but with bigger motors and/or high switching speeds it will become noticeable.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Symptoms include picture breakthrough on your TV (etc) with the motor running.&lt;/p&gt;&#xA;" OwnerUserId="134" LastActivityDate="2012-10-24T19:21:43.483" />
  <row Id="111" PostTypeId="2" ParentId="88" CreationDate="2012-10-24T21:35:33.263" Score="3" Body="&lt;p&gt;How about Omnidirectional wheels?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/DMSs2.jpg&quot; alt=&quot;Omnidirectional wheel&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You could drive the sphere on two pairs of such wheels, with each pair driven by one motor. This would give you two axis control of the sphere. I.E. you can drive forwards or sideways.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Or you could use three wheels and three motors just like this robot:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/sjYFw.jpg&quot; alt=&quot;Bowling ball robot&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/npENu.jpg&quot; alt=&quot;Bowling ball robot&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This allows you to spin the sphere about the vertical axis, if that's helpful.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The good thing about this solution is that the wheels both drive the sphere, and bear the weight.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-10-24T21:35:33.263" CommentCount="8" />
  <row Id="112" PostTypeId="1" AcceptedAnswerId="114" CreationDate="2012-10-24T22:08:20.767" Score="16" ViewCount="1421" Body="&lt;p&gt;Emergency stops are obviously a good idea on most robots, how should they be wired?  What systems should be killed immediately, and what should stay working?&lt;/p&gt;&#xA;" OwnerUserId="73" LastEditorUserId="145" LastEditDate="2012-10-25T14:21:31.763" LastActivityDate="2012-11-08T17:06:45.933" Title="How should emergency stops be wired?" Tags="&lt;mobile-robot&gt;&lt;errors&gt;" AnswerCount="4" />
  <row Id="113" PostTypeId="1" AcceptedAnswerId="161" CreationDate="2012-10-24T22:10:07.020" Score="7" ViewCount="74" Body="&lt;p&gt;Range sensors (for example sonar, infrared, and lidar) are notoriously noisy.  How can I characterize the noise characteristics to include these in a probabilistic localization sensor model?&lt;/p&gt;&#xA;" OwnerUserId="73" LastActivityDate="2012-10-27T17:29:48.033" Title="How to model the noise in a range sensor's return?" Tags="&lt;sensors&gt;&lt;noise&gt;" AnswerCount="2" />
  <row Id="114" PostTypeId="2" ParentId="112" CreationDate="2012-10-24T23:19:12.377" Score="15" Body="&lt;p&gt;Emergency stops are a safety feature, normally found on industrial equipment.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;They should be used when the robot has a potential to hurt humans or cause harm to other assets. This generally depends on the weight of the robot, and the power of the motors (speed at which the robot moves).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, a 1kg robot is too light to cause much damage. Conversely if it is 50kg, it could cause some damage. Similarly, a 5kg flying robot which moves very quickly could be dangerous.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You will want to mount an emergency stop on the robot, and possibly also another one off the robot (although this is a more difficult configuration). The safe way of wiring an emergency stop is in a normally closed manner. That means that the switch is normally closed, and the two terminals are connected. By connecting one end to logical 1, and pulling the other end to logical 0 through a resistor, it can be used to determine the state of the emergency stop.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If the emergency stop is triggered, the switch will open, and the signal will be pulled to logical 0 (0 volts).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This will normally feed into a relay controlling the power to the robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note that another safety requirement of emergency stops is that resetting an emergency stop should not start up the robot again. Turning it back on should require both resetting the emergency stop, and subsequently pressing the on switch.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EHow has a diagram showing how this should be wired:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.ehow.com/how-does_5151421_do-emergency-stop-buttons-work.html&quot;&gt;http://www.ehow.com/how-does_5151421_do-emergency-stop-buttons-work.html&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;As &lt;a href=&quot;http://robotics.stackexchange.com/a/116/145&quot;&gt;Mark Booth&lt;/a&gt; pointed out, to further increase robustness, you should use the normally open switch as well. To do this, connect this signal (with a pull down resistor), to the STOP signal of a relay (&lt;a href=&quot;http://en.wikipedia.org/wiki/Relay_logic&quot;&gt;http://en.wikipedia.org/wiki/Relay_logic&lt;/a&gt;).&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;The systems that should be killed should include all actuators. This means anything that can move. If you have a computer on board, you may be able to separate its power to another system to avoid sudden loss of power. However, you will want to ensure that it is not powering any actuators directly (eg. USB).&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;For low power applications, you might try to save on space by skipping the relay, and wire the emergency stop in series with your main power source (batteries). &lt;strong&gt;Don't do this.&lt;/strong&gt; There are two problems:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;This would violate the safety principle that resetting the emergency stop should &lt;strong&gt;not&lt;/strong&gt; by itself turn on the power again.&lt;/li&gt;&#xA;&lt;li&gt;All the current will be flow through your emergency stop. There are emergency stops rated up to 10A (others are rated only 5A). Your application will probably require more current&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;If an emergency stop is required on your robot, it is probably large enough to have the space for relays.&lt;/p&gt;&#xA;" OwnerUserId="145" LastEditorUserId="145" LastEditDate="2012-10-25T00:06:43.403" LastActivityDate="2012-10-25T00:06:43.403" CommentCount="1" />
  <row Id="115" PostTypeId="2" ParentId="55" CreationDate="2012-10-24T23:43:28.400" Score="5" Body="&lt;p&gt;To determine how much cooling you need, you will want to calculate the thermal resistance, and how fast heat is being generated.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To do this, you can start using it for a period of time (at maximum load), then stop using it. During this time, measure how temperature rises and falls.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This will allow you to calculate the amount of heat generated, as well as thermal resistance to the case (as multiples of thermal capacity). You can also measure the difference in power in versus power out to measure heat dissipated inside ($power = voltage \times current$).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Measuring air temperature you also get the thermal resistance between the case and the ambient air temperature.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;After that, you can treat thermal resistance like an electrical network (see &lt;a href=&quot;http://en.wikipedia.org/wiki/Thermal_resistance&quot;&gt;http://en.wikipedia.org/wiki/Thermal_resistance&lt;/a&gt;). Adding heat sinks of heat pipes simply adds another route for the heat, with lower resistance.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can find the resistance of any heat sink or heat pipe from its datasheets. Then you can estimate how the addition of it will affect the overall thermal resistance of the network. By looking at the rate of heat dissipation, the thermal resistance and the maximum rated temperature, you will know whether it is enough.&lt;/p&gt;&#xA;" OwnerUserId="145" LastActivityDate="2012-10-24T23:43:28.400" />
  <row Id="116" PostTypeId="2" ParentId="112" CreationDate="2012-10-24T23:50:55.943" Score="11" Body="&lt;p&gt;In addition to the points that &lt;a href=&quot;http://robotics.stackexchange.com/a/114/37&quot;&gt;ronalchn&lt;/a&gt; makes, if you have a &lt;em&gt;safety critical system&lt;/em&gt;, the E-Stop selected should use at least a 4-wire interface rather than a simpler two wire interface.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The E-Stop should then have two internal switches, one normally closed, the other normally open (&lt;a href=&quot;http://www.ia.omron.com/products/family/1111/download/catalog.html&quot;&gt;like one of these OMRON options&lt;/a&gt;, see &lt;code&gt;A22E-M-11-EMO&lt;/code&gt;&#xA; and &lt;code&gt;A22E-M-11-EMS&lt;/code&gt; on p2 of the &lt;a href=&quot;http://www.ia.omron.com/data_pdf/cat/a22e_ca_csm206513-9703.pdf?id=1111&quot;&gt;datasheet&lt;/a&gt;). Activating the E-Stop both opens the &lt;a href=&quot;http://en.wikipedia.org/wiki/Switch#Contact_terminology&quot;&gt;NC&lt;sup&gt;(Normally closed)&lt;/sup&gt; switch&lt;/a&gt; and closes the NO&lt;sup&gt;(Normally open)&lt;/sup&gt; switch.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The reason for this is redundancy.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One failure mode of a two wire normally closed e-stop circuit is that the wires get shorted, thus opening the NC switch would do nothing. This could happen in a situation where a cable is crushed, the insulation displaced and the now bare wires touch each other.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you decide to wire your E-stop in the opposite way though, with a normally open circuit then one of &lt;em&gt;its&lt;/em&gt; failure mode is that the e-stop wire gets cut, thus closing the NO switch would do nothing. This could happen in a situation where a cable is caught between two surfaces or where movement pulls a cable out of it's socket.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The risk of these failure modes means that neither on their own are sufficient.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;By including both NC and NO E-Stop circuits, you virtually eliminate this risk, since either E-Stop circuit registering an E-Stop condition would cause an overall E-Stop condition. There &lt;em&gt;is&lt;/em&gt; an exceedingly small chance that the NC circuit could be shorted &lt;em&gt;at the same time&lt;/em&gt; as the NO circuit is disconnected, but any safety system worth its salt would make the window of opportunity for this vanishingly small (i.e. transistor switching rates).&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;On the subject of what to kill on an E-Stop, in my opinion &lt;strong&gt;you should kill everything which can move&lt;/strong&gt; and everything which could cause damage (such as a laser).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My experience is with &lt;em&gt;industrial robotics&lt;/em&gt; though, where the mechanics are typically designed so that it is inherently safe to kill the power at any time. Axes are designed such that motors aren't acting against gravity without significant gearing (for example &lt;a href=&quot;http://en.wikipedia.org/wiki/SCARA&quot;&gt;SCARA robots&lt;/a&gt;, where most of the axes are in a horizontal plane) or are designed such that  in an E-Stop condition the &lt;a href=&quot;http://en.wikipedia.org/wiki/Dynamic_braking#Principle_of_operation&quot;&gt;motors are shorted, bringing them to an abrupt stop&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="37" LastEditorUserId="37" LastEditDate="2012-11-08T11:05:23.530" LastActivityDate="2012-11-08T11:05:23.530" />
  <row Id="117" PostTypeId="1" AcceptedAnswerId="122" CreationDate="2012-10-25T02:01:30.993" Score="3" ViewCount="131" Body="&lt;p&gt;In graph-based planning (say, A*), states are connected to their neighbors.  How should one decide whether to connect to the 4 neighbors or the 8 neighbors?  What are the pros and cons of each approach?&lt;/p&gt;&#xA;" OwnerUserId="73" LastEditorUserId="350" LastEditDate="2012-11-30T14:23:47.963" LastActivityDate="2012-11-30T14:23:47.963" Title="What is the difference between 4-point and 8-point connectivity in graph based planning?" Tags="&lt;motion-planning&gt;&lt;artificial-intelligence&gt;&lt;planning&gt;" AnswerCount="4" CommentCount="2" />
  <row Id="118" PostTypeId="1" AcceptedAnswerId="250" CreationDate="2012-10-25T02:41:22.373" Score="7" ViewCount="192" Body="&lt;p&gt;I am attempting to upload a custom firmware to a Lego Mindstorms NXT and am having issues.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;First of all, I'm attempting to use &lt;a href=&quot;http://lejos-osek.sourceforge.net/&quot;&gt;nxtOSEK&lt;/a&gt;, which would let me run C++ programs on it.  The problem is, everytime I put it into firmware update mode, the download doesn't seem to actually occur.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What I mean by this is that, according to the output in my terminal (both Mac and Windows), the download was successful, however when the NXT reboots, I still see the normal logo (not nxtOSEK).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, what I'm doing is first holding down the &lt;code&gt;Reset&lt;/code&gt; button for a few seconds, then hitting the orange button, giving me that tic-tic-tic sound.  Then I run the firmware update (either using the Windows NextTool or Mac OSX GUI NextTool) and attempt the download.  I get a success message, yet the robot is still using the old firmware.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What could be the cause of this problem and how can I solve it?&lt;/p&gt;&#xA;" OwnerUserId="47" LastEditorUserId="47" LastEditDate="2012-10-25T14:58:49.250" LastActivityDate="2012-11-01T04:08:45.253" Title="Properly flashing the firmware on a Lego Mindstorms NXT" Tags="&lt;mindstorms&gt;&lt;nxt&gt;" AnswerCount="1" CommentCount="5" FavoriteCount="3" />
  <row Id="119" PostTypeId="1" AcceptedAnswerId="120" CreationDate="2012-10-25T04:45:29.487" Score="8" ViewCount="221" Body="&lt;p&gt;When designing a standard 4 or 6 wheel robot, is it better to have the weight distributed primarily in the center of the robot, or over the wheels, or is there no difference?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Specifically, which weight distribution will make the robot less likely to tip over?&lt;/p&gt;&#xA;" OwnerUserId="79" LastActivityDate="2012-10-26T16:19:50.753" Title="Is it better to have weight distributed over the wheels or the center of the robot?" Tags="&lt;mobile-robot&gt;&lt;design&gt;&lt;stability&gt;&lt;wheeled-robot&gt;" AnswerCount="2" CommentCount="1" />
  <row Id="120" PostTypeId="2" ParentId="119" CreationDate="2012-10-25T05:32:55.577" Score="13" Body="&lt;p&gt;Assuming it is a rigid robot, then the only weight properties of interest is:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;the total mass&lt;/li&gt;&#xA;&lt;li&gt;the centre of mass&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;In terms of tipping over, the robot is more stable if the angle required before tipping over is maximized. This is achieved by having a low centre of mass, and a centre of mass as far away from the edges of the &lt;a href=&quot;http://en.wikipedia.org/wiki/Support_polygon&quot;&gt;support polygon&lt;/a&gt; as possible.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Intuitively, you can see that if the centre of mass is near the centre of the robot, it is more stable. More formally, if you consider each wheel to be the vertex of a polygon (from a top view), then you will see a support polygon. You can designate the centre to be the point furtherest away from an edge.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another way to increase stability is to increase the size of the support polygon - that is, place the wheels further out to form a wide base. Adding more wheels can also increase the size of the support polygon, although this mostly impacts three wheeled robots, which have quite a small support polygon relative to the distance between the wheels.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The angle required for the robot to tip may depend on the direction of tipping. If there is movement along that direction, then disturbances are more likely in that direction. That is why cars are more stable forward/backwards, compared to sideways (roll axis), with front wheels further from the rear wheels as compared to the distance between left and right wheels.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The total mass of the robot is also a factor. If the robot is heavier, then a larger disturbing force is required to tip the robot to the required angle before it will continue to tip over. Having said that, you are unlikely to want to simply increase robot mass, so you will:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;try to place heavier components lower (batteries can be quite heavy)&lt;/li&gt;&#xA;&lt;li&gt;increase the size of the support polygon (wheels further out, or 4 wheels instead of 3).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="145" LastEditorUserId="145" LastEditDate="2012-10-25T05:38:03.217" LastActivityDate="2012-10-25T05:38:03.217" />
  <row Id="121" PostTypeId="2" ParentId="117" CreationDate="2012-10-25T06:06:53.957" Score="0" Body="&lt;p&gt;Assuming that (1) you are representing your environment as a grid (which is the only case where the 4-neighbor vs. 8-neighbor question makes sense) and (2) you are planning for navigation (which is the most common use case for grid-based representations)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I personally would not make much a case for 4-neighbour makes not much sense. What you would do by connecting only 4 neighbour per cell is force the robot to go only in &quot;straight&quot; directions. It is already a problem as it is with 8 neighbours, as one usually already has to &quot;smooth&quot; the result or use other approaches to interpret the resulting path.&lt;/p&gt;&#xA;" OwnerUserId="56" LastActivityDate="2012-10-25T06:06:53.957" />
  <row Id="122" PostTypeId="2" ParentId="117" CreationDate="2012-10-25T06:07:19.763" Score="1" Body="&lt;p&gt;Graph-based planning algorithms are typically performed for high level planning, for example getting a robot across an office. But, the actual actuator planning for the robot is planned completely differently. This means it completely depends on your application and your desired level of complexity. If you have a grid in which cells are either occupied or not occupied, you may not want your robot transitioning diagonally for fear of collision with the neighboring cells. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In technical terms, it doesn't matter at all if you use 4 or 8 way connectivity for algorithms like A*.&lt;/p&gt;&#xA;" OwnerUserId="42" LastActivityDate="2012-10-25T06:07:19.763" />
  <row Id="123" PostTypeId="2" ParentId="113" CreationDate="2012-10-25T06:22:54.963" Score="3" Body="&lt;p&gt;Almost everybody just assumes the noise is gaussian because that way the math is relatively easy.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you really wanted, you could experimentally determine the distribution of sensor noise, fit a model to it, and use that but it would be a lot of work for potentially no gain.&lt;/p&gt;&#xA;" OwnerUserId="65" LastActivityDate="2012-10-25T06:22:54.963" />
  <row Id="124" PostTypeId="2" ParentId="100" CreationDate="2012-10-25T06:34:11.813" Score="2" Body="&lt;p&gt;Depends a lot on what the connectors are being used for.  Do they need to be panel mounted? pcb mounted?  Just hanging out?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I see anderson power poles all over the place in robotics because they lock reliably and can be snapped together to make connectors of any size.  Normally they are used for power, not signals.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;IDC connectors are also very common for signals/low power.  They also lock reliably and use standard .1 header spacing which is nice for prototyping/testing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The locking headers you mentioned are also very common, but never where repeated disconnects/reconnects are expected.  Mostly just indicator lights and such.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In weight/space restricted applications RC connectors are great.  A lot of the RC connectors have extremely high current capacity and are very reliable under vibration.  My favourite is the XT60.&lt;/p&gt;&#xA;" OwnerUserId="65" LastActivityDate="2012-10-25T06:34:11.813" CommentCount="1" />
  <row Id="125" PostTypeId="2" ParentId="25" CreationDate="2012-10-25T06:55:11.320" Score="13" Body="&lt;p&gt;Choosing the correct prop/motor combination can be challenging.  Even worse, the vast majority of RC motors will have vague or non-existant specifications.  This makes it very hard to do &quot;real&quot; math.  Instead you will have to rely on prop thrust ratings or use a known combination that other people have tested.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Propellers:&#xA;Manueverability of a quad is dependent on how quickly you can change the thrust (how fast you can change the RPM of the props). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;A smaller prop is easier to speed up and slow down whereas a large prop takes a very long time to change speeds.  Beyond a certain size you essentially are unable to fly.  This is why you see hexacoptors and octocopters that use more, smaller props instead of giant quadrotors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On the flipside, propeller efficiency is related to the area of a prop (or radius squared) so a small increase in prop diameter will make the quad vastly more efficient.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The faster you want to go, the more aggressive a pitch you want.  Since quadrotors are generally hovering this means you want the lowest pitch available.  If you want to go somewhere fast a higher pitch might be apropriate.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Motors:&#xA;Generally you just choose a motor that matches the given prop.  Having a motor that is too large will be heavy, and a motor that is too small will perform poorly or burn up.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A smaller prop requires a higher RPM motor because they must spin faster to generate equivalent lift.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you put everything together, an efficient quad will have properly sized, low RPM motors with very large props.&lt;br&gt;&#xA;An acrobatic quad will want smaller, more aggressive props, faster motors, and you might even overvolt the motors for faster response.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;While you will be hard pressed to find torque curves for Rc motors, you will have thrust and current ratings for a given prop which makes it fairly straightforward to determine how much you can lift and approximately how long you can fly once you have chosen a combinatoin.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As a general rule you want a 2:1 thrust/weight ratio for a standard quad and 3:1 or higher for something acrobatic.  1.5:1 has been known to fly.&lt;/p&gt;&#xA;" OwnerUserId="65" LastEditorUserId="65" LastEditDate="2012-10-25T07:01:33.607" LastActivityDate="2012-10-25T07:01:33.607" />
  <row Id="126" PostTypeId="2" ParentId="57" CreationDate="2012-10-25T07:11:24.653" Score="5" Body="&lt;p&gt;Temperature is a very simple number to measure and is a good aggregation of all the other factors since a weakening motor will be driven harder.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Generally a motor that is about to fail will be significantly hotter than the rest of the motors.&lt;/p&gt;&#xA;" OwnerUserId="65" LastActivityDate="2012-10-25T07:11:24.653" />
  <row Id="127" PostTypeId="2" ParentId="117" CreationDate="2012-10-25T09:33:40.157" Score="4" Body="&lt;p&gt;I believe it simply boils down to what your robot can do.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are for some reason restricted to moving only in 4 directions, then you connect each grid cell to 4.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you can go in 8 directions, you connect each grid cell to 8.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you can go in 6 directions, you use a honeycomb grid and connect each grid cell to 6.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is no generic answer. If you plan to go diagonally with a robot that can't perform the action, that's bad planning. If you plan to only go horizontally and vertically while your robot can take shortcuts, that's also bad planning.&lt;/p&gt;&#xA;" OwnerUserId="158" LastActivityDate="2012-10-25T09:33:40.157" />
  <row Id="128" PostTypeId="1" AcceptedAnswerId="140" CreationDate="2012-10-25T09:49:05.213" Score="12" ViewCount="749" Body="&lt;p&gt;&lt;strong&gt;Edit:&lt;/strong&gt; I don't know why, but this question seems to be confusing many people. I am aware of when/where/why/how to use real-time. I am interested in knowing whether people who have a real-time task would actually care enough to implement it in real-time or not.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There's no need to mention why real-time operations are important for a robot. My question is however, how much is it actually used in robotics?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Take &lt;a href=&quot;http://robotics.stackexchange.com/q/6/158&quot;&gt;this question&lt;/a&gt; for example. Only one answer mentions any platform with real-time capabilities, and it is far from the top too. ROS apparently, being a very popular platform which is not real-time.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the real-time world however, RTAI&lt;sup&gt;1&lt;/sup&gt; seems to be the only workable &lt;em&gt;free&lt;/em&gt; real-time platform of use. It is however, limited to Linux (no problem), badly documented and slowly developed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;del&gt;So, how much is real-time behavior sought after among robotics developers?&lt;/del&gt; The question is, how much are developers inclined to write real-time applications when real-time behavior is actually needed? If not much, why?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, reflexive behavior based on tactile data, cannot go through ROS because it would lose its real-time property. But do people really come up with a real-time solution or use ROS anyway, ignoring the real-time property?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt; or similarly Xenomai&lt;/p&gt;&#xA;" OwnerUserId="158" LastEditorUserId="158" LastEditDate="2012-11-08T13:29:57.420" LastActivityDate="2012-11-19T22:52:43.610" Title="How mature is real-time programming in robotics?" Tags="&lt;software&gt;&lt;platform&gt;&lt;real-time&gt;" AnswerCount="9" CommentCount="6" FavoriteCount="2" />
  <row Id="129" PostTypeId="2" ParentId="128" CreationDate="2012-10-25T10:27:00.837" Score="4" Body="&lt;p&gt;The purpose of the software determines whether it needs to be strictly real-time.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Where the purpose is path planning or localization, often a low frequency is sufficent, for example, 10Hz. In these cases, a player/stage setup running on Linux is fine. We can see that there are few problems if one time step is a bit longer or shorter.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Strictly real-time behaviour is required if the robot dynamics are fast. For example, moving a robotic arm to track a position, or to handle/grip objects, and move them. If a time step is missed, the position may overshoot undesirably, and we may want more predictable behaviour. In this case, we may have a frequency up to 1kHz or more. If an operating system is used, we want a real-time operating system.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Real-time behaviour can be accomplished in embedded applications, by using timers and interrupts (compiled C code on a microcontroller). In this case, we must ensure that the processing load is not too high so that a regular sampling frequency can be maintained.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Robots using computers/microprocessors (because more processing power is required), will need to use a real-time operating system to guarantee high sampling rates.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Therefore, whether real-time behaviour is required depends on what the developer intends to use it for.&lt;/p&gt;&#xA;" OwnerUserId="145" LastActivityDate="2012-10-25T10:27:00.837" CommentCount="2" />
  <row Id="130" PostTypeId="2" ParentId="128" CreationDate="2012-10-25T13:38:40.087" Score="6" Body="&lt;p&gt;A real time system is not really required for many (most?) robotic control systems. As long as you have a control loop that runs fast enough, with low enough jitter, and doesn't miss too many cycles, then this is quite adequate for robotic control and servoing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As evidence of this, let me present the PR2 and the Shadow  Robot Hand:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/72drV.jpg&quot; alt=&quot;PR2&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This robot has about 20 degrees of freedom, all of which are servoed through ROS's main loop. Or how about the Shadow Robot Hand, which also has 20 DOFs, plus an array of tactile and other sensors, and is also servoed through ROS's main loop.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The ROS main loop suffers from a little jitter, sometimes as much as 100us, and even sometimes misses cycles altogether. But it doesn't matter if 99.9% of cycles are executed successfully. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The use of many cores within the host PCs means that one whole core is dedicated to running the main loop, and so it is very rarely delayed by other tasks.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The main reason for using a really real-time OS for a robotic system is for safety. If the robot is working in a safety critical situation, then it is your responsibility to guarantee 100% control up-time, and part of this is guaranteeing the real time nature of it. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Whether you use a real-time OS or not, your servos should do something safe in the event that the control loop dies entirely. This safety system would also be helpful on the rare occasion your non-real-time OS skips more than a cycle. For example, on the Shadow Hand, the motors are halted if the control loop misses more than 20 cycles (20ms). I have never seen this happen though.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Added&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another way to think about it is this: What update rate does your servo system actually need? If it's a largish arm, and doesn't need super high performance, high speed positioning, then 500Hz might be sufficient. For driving around, 200Hz is probably sufficient. In both of these cases, if your loop is actually running at 1000Hz, then a late or missing cycle really is no problem at all, as long as your control algorithm takes into account the actual elapsed time between loops.&lt;/p&gt;&#xA;" OwnerUserId="40" LastEditorUserId="40" LastEditDate="2012-10-25T20:49:55.183" LastActivityDate="2012-10-25T20:49:55.183" CommentCount="8" />
  <row Id="131" PostTypeId="1" AcceptedAnswerId="133" CreationDate="2012-10-25T14:06:19.100" Score="2" ViewCount="187" Body="&lt;p&gt;I Have an ATmega16 mc which is master on the i2c and a ATMega8 mc which is slave on the i2c.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have connected the two mcs' sda and scl ports to each other alongside a pullup resistor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now I want to read a register from the ATMega8 using the ATMega16. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The problem is that I don't want to assign all the variables manually. Is there any libs or headers that will do this thing for me?&lt;/p&gt;&#xA;" OwnerUserId="21" LastEditorUserId="50" LastEditDate="2012-10-25T14:39:11.960" LastActivityDate="2012-10-26T07:36:48.440" Title="Connecting two microcontrollers using I2C" Tags="&lt;software&gt;&lt;microcontroller&gt;&lt;i2c&gt;" AnswerCount="3" CommentCount="4" ClosedDate="2012-10-26T07:48:04.523" />
  <row Id="132" PostTypeId="2" ParentId="112" CreationDate="2012-10-25T15:29:23.513" Score="3" Body="&lt;p&gt;&lt;strong&gt;What to cut out is not always a simple matter&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One complication arises when the actuators actually need power in order to remain safe. For example: a back-drivable or compliant robot arm had picked up a heavy object, and is using motor power to hold the object in the air. If you kill the power, the weight of the object will bring the arms crashing down, and either breaking the object, the robot, or a person.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;One way to implement cut out&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the above case, rather than cutting actuator power, it might be wise to send a message to all actuators to go into a safe mode. Exactly what that means depends on the nature of the robot and the particular actuator. They might stop, or simply go into a lower power mode where they fall down slowly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Another way to implement cut out&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the &lt;a href=&quot;http://www.shadowrobot.com&quot; rel=&quot;nofollow&quot;&gt;Shadow Robot Hand&lt;/a&gt;, the sensing system, bus and actuators are all powered from the same 48v supply line. The sensors and actuators each have their own regulators, each with their own Unver-Voltage Lockout setting. The actuators cut out at 25v, while the sensors cut out at 9v. When an emergency stop happens, the power supply line is taken down to 18v, which causes the actuators' power supply to cut out, while maintaining the power to the sensors and communication bus.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-10-25T15:29:23.513" CommentCount="2" />
  <row Id="133" PostTypeId="2" ParentId="131" CreationDate="2012-10-25T15:43:20.873" Score="1" Body="&lt;p&gt;I've not used the ATMega family, but have lots of experience of configuring many other devices - setting up the control registers for I2C is usually pretty straight forward, with appropriate reference to the datasheet/user-manual and will help you understand what's going on.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For such tasks, a library is (a) inefficient (b) overkill and (c) doesn't help you learn. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I don't know if there is one, but wouldn't recommend you use it, if there was...&lt;/p&gt;&#xA;" OwnerUserId="134" LastActivityDate="2012-10-25T15:43:20.873" CommentCount="3" />
  <row Id="134" PostTypeId="2" ParentId="106" CreationDate="2012-10-25T17:30:39.397" Score="4" Body="&lt;p&gt;There isn't a lot of information here. Let's fix the wheels as separated by distance $b$, and each wheel has orientation $\theta_i$ with respect to the line joining them.  Then assume each wheel can be independently driven with an angular velocity $v_i$. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If the wheels are independently driven, but fixed in direction, $\theta_1=\theta_2=90^\circ$, you have something like a differential drive (tank treads). &#xA;It's worth noting that, assuming the wheels do not slip perpandicular to their orientation, you can solve for the motion of the robot base in closed form given velocity commands which are fixed over a small time duration (as is usually the case with robots under software control). The iCreate is such a platform, as are the smaller pioneers, and the Husky by Clearpath.&#xA;Then the change in orientation of the base, labelled $\theta$ below, can be found in closed form.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://rossum.sourceforge.net/papers/DiffSteer/Image47.gif&quot; alt=&quot;...&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The usual model for these things, where $v_b$ is the base velocity and $\omega_b$ is the angular velocity of the base, is:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$v_b = \frac{1}{2}\cdot(v_1+v_2)$$&#xA;$$\omega_b=\frac{1}{b}(v_2-v_1)$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For a fixed time increment, $\delta t$, you can find the change in orientation, and linear distance traveled using these. Note that the robot travels along a circle in this time window. The distance along the circle is exactly $\delta t\cdot v_b$, and the radius of the circle is  $R=\frac{b}{2}\cdot\frac{v_1+v_2}{v_2-v_1}$.  That's enough to plug into these equations: &lt;a href=&quot;http://mathworld.wolfram.com/CircularSegment.html&quot; rel=&quot;nofollow&quot;&gt;circular segments&lt;/a&gt; -- particularly the chord length equation, which describes the distance the robot displaces from its original location. We know $R$ and $\theta$, solve for $a$. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So assuming the robot starts with orientation $0$, and position $(0,0)$, and moves along time window $\delta t$ with velocities $v_1$ (left wheel) and $v_2$ (right wheel), it's orientation will be: $$\theta_1=\frac{\delta t}{b}(v_2-v_1)$$ with position:&#xA;$$p_x=\cos(\frac{\theta_1}{2})\cdot\left(2 R \sin(\frac{\theta_1}{2})\right)$$&#xA;$$p_y=\sin(\frac{\theta_1}{2})\cdot\left(2 R \sin(\frac{\theta_1}{2})\right)$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note that as $v_1\to v_2=v$ the limit is&#xA;$$p_x=\delta t \cdot v$$&#xA;$$p_y=0$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;as expected.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is covered all over the internet, but you might start here: &lt;a href=&quot;http://rossum.sourceforge.net/papers/DiffSteer/&quot; rel=&quot;nofollow&quot;&gt;http://rossum.sourceforge.net/papers/DiffSteer/&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If the wheels are not fixed in direction, as in you can vary the speed and orientation, it gets more complicated. In that sense, a robot can become essentially holonomic (it can move in arbitrary directions and orientations on the plane). However, I bet for fixed orientation, you end up with the same model.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are other models for two wheels, such as a bicycle model, which is easy to imagine as setting the velocities, and only varying one orientation.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;That's the best I can do for now.&lt;/p&gt;&#xA;" OwnerUserId="163" LastEditorUserId="163" LastEditDate="2012-10-25T17:45:09.523" LastActivityDate="2012-10-25T17:45:09.523" />
  <row Id="135" PostTypeId="2" ParentId="128" CreationDate="2012-10-25T18:26:13.887" Score="2" Body="&lt;p&gt;Our company builds robots using FreeRTOS running on PIC microcontrollers.  For us, the main reasons to use FreeRTOS is the ease of rearranging priorities on tasks, handling multiple communication lines simultaneously, and easy communication between interrupt handlers and main tasks.  Microcontrollers are far cheaper than putting a full linux machine into each robot we produce as well.&lt;/p&gt;&#xA;" OwnerUserId="39" LastActivityDate="2012-10-25T18:26:13.887" />
  <row Id="137" PostTypeId="2" ParentId="23" CreationDate="2012-10-25T19:19:03.403" Score="2" Body="&lt;p&gt;Yes, you are thinking too far afield. This is an open research problem (especially where people are concerned). Don't even think about the DARPA grand challenge, that's way out of a single person's league. However, there are some good starting points I can recommend.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A labmate has had good success tracking people using a Kinect with OpenNI. The kinect has range information, which makes it better than pure vision or binocular vision. Typically a vision-based solution uses &lt;a href=&quot;http://en.wikipedia.org/wiki/Structure_from_motion&quot; rel=&quot;nofollow&quot;&gt;Structure From Motion&lt;/a&gt;. Because this can be terribly sensitive to moving scenes, vision is probably NOT the way to go for this task. A more reliable method is laser scanner for close-in obstacle avoidance. However, Vision-based &lt;a href=&quot;http://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping&quot; rel=&quot;nofollow&quot;&gt;SLAM&lt;/a&gt; is possible, and can be implemented using the Robot Operating System.  The task becomes &lt;em&gt;significantly&lt;/em&gt; easier if you have detailed maps before you deploy. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Start with ROS, aka the &lt;a href=&quot;http://ros.org/wiki&quot; rel=&quot;nofollow&quot;&gt;Robot Operating System&lt;/a&gt;, it will be much more helpful than implementing these things yourself. I can assure you from personal experience.&lt;/p&gt;&#xA;" OwnerUserId="163" LastActivityDate="2012-10-25T19:19:03.403" />
  <row Id="138" PostTypeId="1" CreationDate="2012-10-25T20:43:48.660" Score="9" ViewCount="434" Body="&lt;p&gt;A beginning graduate student in robotics asked me the areas of mathematics that he should brush up on (prerequisites) to begin a masters research program in robotics. What are some good materials/books that are indispensable for a research student? Which ones should we suggest in order that the student develops a solid foundation in robotics?&lt;/p&gt;&#xA;" OwnerUserId="166" LastEditorUserId="126" LastEditDate="2012-11-26T06:37:00.120" LastActivityDate="2012-12-05T18:10:51.037" Title="Mathematical prerequisites for beginning graduate student in robotics" Tags="&lt;research&gt;" AnswerCount="5" FavoriteCount="1" />
  <row Id="139" PostTypeId="2" ParentId="23" CreationDate="2012-10-25T20:44:47.153" Score="0" Body="&lt;p&gt;If what you are looking at is a research topic, not a ready-to-use solution, then maybe visual servoing techniques with occlusion handling, or path planning in the image, might be of some use. (Never tested, but know the names behind it: &lt;a href=&quot;http://www.irisa.fr/lagadic/visp/visp.html&quot; rel=&quot;nofollow&quot;&gt;http://www.irisa.fr/lagadic/visp/visp.html&lt;/a&gt;)&lt;/p&gt;&#xA;" OwnerUserId="56" LastActivityDate="2012-10-25T20:44:47.153" />
  <row Id="140" PostTypeId="2" ParentId="128" CreationDate="2012-10-25T20:45:14.690" Score="8" Body="&lt;p&gt;Remember that there's &lt;em&gt;Real Time&lt;/em&gt; and there's &lt;strong&gt;&lt;em&gt;Real Time&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Real-time_computing#Criteria_for_real-time_computing&quot;&gt;Hard Real time&lt;/a&gt; is difficult to achieve without hardware support or low level software support, but you often don't need everything to be &lt;em&gt;Hard Real Time&lt;/em&gt; capable. &lt;a href=&quot;http://en.wikipedia.org/wiki/Real-time_computing#Criteria_for_real-time_computing&quot;&gt;Soft &amp;amp; Firm Real Time&lt;/a&gt; response is much easier to achieve and is often more than adequate for many applications.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, different parts of a system can have very different &lt;em&gt;real time&lt;/em&gt; requirements. If you are running software PID loops, they really should have a &lt;em&gt;hard real time&lt;/em&gt; response (you really don't want to have to choose between soft tuning your PIDs or tuning them hard and having them occasionally go unstable, for instance). A vision system might have &lt;em&gt;firm real time&lt;/em&gt; response requirements, performance will degrade if you can't process the image in time for the next decision but it need not prevent the system running, in this case if you can't process it in time you are better off throwing away the partial results and not loosing time starting analysis on the next frame. Finally your overall planning and coordination (probably the most &lt;em&gt;complex&lt;/em&gt; part of your robotic system) can often remain firmly in the domain of &lt;em&gt;soft real time&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Even in the realm of Windows PCs you can get &lt;em&gt;hard real time&lt;/em&gt; performance, you just need the right software with the right hooks into the kernel. &lt;a href=&quot;http://en.wikipedia.org/wiki/Beckhoff&quot;&gt;Beckhoff&lt;/a&gt;'s TwinCat soft PLC quite happily ran a high scan rate PLC by slicing half of a Pentium's machine cycles, giving the other half to Windows NT, and this was over a decade ago. Even modern control systems like some options in &lt;a href=&quot;http://www.aerotech.com/product-catalog/motion-controllers/automation-3200.aspx&quot;&gt;Aerotech's A3200 range&lt;/a&gt; do the grunt work on the host PC, with the low level kernel taking as much CPU time as it needs for the &lt;em&gt;hard real time&lt;/em&gt; requirements and leaving the rest of the CPU cycles for Windows 7 to use!&lt;/p&gt;&#xA;" OwnerUserId="37" LastActivityDate="2012-10-25T20:45:14.690" CommentCount="4" />
  <row Id="141" PostTypeId="2" ParentId="138" CreationDate="2012-10-25T20:57:00.993" Score="1" Body="&lt;p&gt;A good approach would just be to research robotics programs and see what books they have for different classes that could help build a foundation.  Personally I've used this book for a robotics/mechatronics class but it was for undergrad&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://rads.stackoverflow.com/amzn/click/0071254072&quot; rel=&quot;nofollow&quot;&gt;http://www.amazon.com/Introduction-Mechatronics-Measurement-Systems-Alciatore/dp/0071254072&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you want to build more than a foundation, it would be wise to look up top schools in robotics and find out what books they use.  Most would be in syllabus that can be found by searching the school, class title and maybe a current professors name.&lt;/p&gt;&#xA;" OwnerUserId="99" LastActivityDate="2012-10-25T20:57:00.993" />
  <row Id="142" PostTypeId="1" AcceptedAnswerId="152" CreationDate="2012-10-25T21:02:12.810" Score="3" ViewCount="176" Body="&lt;p&gt;What kind of sensors and algorithms are the mobile robots of &lt;a href=&quot;http://www.kivasystems.com/&quot; rel=&quot;nofollow&quot;&gt;Kiva Systems&lt;/a&gt; equipped with? &lt;/p&gt;&#xA;" OwnerUserId="166" LastActivityDate="2012-10-26T08:43:24.673" Title="Technology behind Kiva Systems mobile robots" Tags="&lt;mobile-robot&gt;&lt;industrial-robot&gt;" AnswerCount="1" FavoriteCount="1" />
  <row Id="143" PostTypeId="1" CreationDate="2012-10-25T21:12:55.900" Score="5" ViewCount="536" Body="&lt;p&gt;I have a motor which drives a string connected to a load cell. I would like to implement a closed loop controller to control the load applied by the motor to the string.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/wWerj.png&quot; alt=&quot;Motor driving string connected to a load cell&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How do I go about determining the required loop frequency in order to create a stable control system? Is it something like the Nyquist frequency, where the loop speed should be at least twice the highest frequency inherent in the mechanical system?&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2013-07-06T00:49:22.970" Title="How do I calculate the required loop frequency for a servo controller?" Tags="&lt;control&gt;&lt;motor&gt;&lt;force&gt;" AnswerCount="2" FavoriteCount="1" />
  <row Id="144" PostTypeId="2" ParentId="138" CreationDate="2012-10-25T21:56:57.673" Score="6" Body="&lt;p&gt;This depends heavily on what the research topic will be on. For example, is it:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;image processing, machine vision...&lt;/li&gt;&#xA;&lt;li&gt;SLAM&lt;/li&gt;&#xA;&lt;li&gt;path planning&lt;/li&gt;&#xA;&lt;li&gt;control&lt;/li&gt;&#xA;&lt;li&gt;robotic manipulators?&lt;/li&gt;&#xA;&lt;li&gt;...&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Without knowing the area of research, it is not simple to know what mathematics will be required. Having said that, any mathematics required is taught during undergraduate studies anyways, so there are no real requirements. Any domain-specific mathematics generally just needs basic knowledge of matrix algebra to build on top of.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some programming experience is likely to be required as well.&lt;/p&gt;&#xA;" OwnerUserId="145" LastActivityDate="2012-10-25T21:56:57.673" />
  <row Id="145" PostTypeId="2" ParentId="131" CreationDate="2012-10-25T22:07:54.153" Score="2" Body="&lt;p&gt;AVR publishes a set of guides for every microcontroller they make. See &lt;a href=&quot;http://www.atmel.com/devices/atmega16.aspx?tab=documents&quot; rel=&quot;nofollow&quot;&gt;http://www.atmel.com/devices/atmega16.aspx?tab=documents&lt;/a&gt;, and obtain the &lt;strong&gt;ATmega16(L) Complete&lt;/strong&gt; document.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You will find a chapter dedicated to I2C (it is named &lt;strong&gt;2-wire Serial Interface (TWI)&lt;/strong&gt;). While there may be libraries, the general practice is to set the appropriate registers manually.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Each register is given a name (all caps, like a constant) - an 8-bit integer you can set in C. Specific bits will be used to set one microcontroller as a master or slave. For example, the following registers are relevant to the two-wire interface.&lt;/p&gt;&#xA;&#xA;&lt;h1&gt;TWI Register Description&lt;/h1&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;TWI Bit Rate Register – TWBR&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Bits 7...0 – TWI Bit Rate Register&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;TWI Control Register – TWCR&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Bit 7 – TWINT: TWI Interrupt Flag&lt;/li&gt;&#xA;&lt;li&gt;Bit 6 – TWEA: TWI Enable Acknowledge Bit&lt;/li&gt;&#xA;&lt;li&gt;Bit 5 – TWSTA: TWI START Condition Bit&lt;/li&gt;&#xA;&lt;li&gt;Bit 4 – TWSTO: TWI STOP Condition Bit&lt;/li&gt;&#xA;&lt;li&gt;Bit 3 – TWWC: TWI Write Collision Flag&lt;/li&gt;&#xA;&lt;li&gt;Bit 2 – TWEN: TWI Enable Bit&lt;/li&gt;&#xA;&lt;li&gt;Bit 1 – Res: Reserved Bit&lt;/li&gt;&#xA;&lt;li&gt;Bit 0 – TWIE: TWI Interrupt Enable&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;TWI Status Register – TWSR&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;TWI Data Register – TWDR&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;TWI (Slave) Address Register – TWAR&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Note that you set certain bits to specify bit rate, the data to transfer, the address a slave responds to, and when to start/stop transfers (the control register). You can also obtain the status of transmissions from the status register.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The document will also walk you through the steps to use it:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/rS9Ns.png&quot; alt=&quot;enter image description here&quot;&gt;&#xA;&lt;em&gt;Obtained from the AVR &quot;ATmega16(L) Complete&quot; document&lt;/em&gt;&lt;/p&gt;&#xA;" OwnerUserId="145" LastActivityDate="2012-10-25T22:07:54.153" />
  <row Id="146" PostTypeId="1" AcceptedAnswerId="170" CreationDate="2012-10-26T00:30:03.880" Score="5" ViewCount="204" Body="&lt;p&gt;For the 3d printer &lt;a href=&quot;http://www.reprap.org/wiki/Prusa_Mendel_Assembly&quot;&gt;RepRap Prusa&lt;/a&gt; there are several rails (smooth rods) that guide the printer head on the different axises. The printer head uses several linear bearings to glide along the rails. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;There isn't any specification on what kind of material would be best suited for this purpose with the linear bearings. My first assumption would be for stainless steel because it won't corrode (rust) on the surface, but I'm not sure if this is true for all printers (whether they are 3D printers or not) as a different material may allow the linear bearings to glide more easily. Aluminum would have been my second choice but I have the same reservations of which grade would be least resistant. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;This &lt;a href=&quot;http://www.lm76.com/linear_shaft_selector.htm&quot;&gt;resource&lt;/a&gt; has some limited information but does not help with which would be best suited for this particular application.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What material is best suited for this purpose?&lt;/p&gt;&#xA;" OwnerUserId="168" LastEditorUserId="350" LastEditDate="2012-11-30T14:11:53.523" LastActivityDate="2012-11-30T14:11:53.523" Title="What rail material is best used for linear bearings?" Tags="&lt;reprap&gt;&lt;3d-printing&gt;&lt;linear-bearing&gt;" AnswerCount="2" CommentCount="1" />
  <row Id="147" PostTypeId="2" ParentId="146" CreationDate="2012-10-26T00:39:26.080" Score="1" Body="&lt;p&gt;Well, I got proper industrial linear bearings recently, along with stainless steel rails.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The properties of interest is that the material is smooth and hard to minimise friction. In fact, the stainless steel rails I obtained was both hardened and polished.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Aluminium could be dented by stainless steel bearings affecting performance.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Having said this, for a printer, which has very little weight/force, materials of differing hardness is probably fine. If you just want to reduce friction, just get polished material, or else polish it yourself (although stainless steel would probably maintain smoothness better since it is harder).&lt;/p&gt;&#xA;" OwnerUserId="145" LastActivityDate="2012-10-26T00:39:26.080" CommentCount="1" />
  <row Id="148" PostTypeId="1" AcceptedAnswerId="181" CreationDate="2012-10-26T04:48:02.503" Score="6" ViewCount="142" Body="&lt;p&gt;I am not sure if this has been tried before but I am trying to use &lt;a href=&quot;http://en.wikipedia.org/wiki/Kinect&quot; rel=&quot;nofollow&quot;&gt;Kinect&lt;/a&gt; and detect gestures made by the &lt;a href=&quot;http://en.wikipedia.org/wiki/Nao_%28robot%29&quot; rel=&quot;nofollow&quot;&gt;Nao robot&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have made a Kinect application, &lt;a href=&quot;http://youtu.be/v8SumS-I1qo&quot; rel=&quot;nofollow&quot;&gt;a gesture based picture viewer&lt;/a&gt; and it detects humans fine(Obviously it does!) What I wanted to try was (lazy as I am), to see if I could use some (say, voice) command to tell the Nao to do a Swipe Right gesture and have my application identify that gesture. The Nao can easily identify my command and do some gesture. The problem however is, when I put the Nao in front of the Kinect sensor, the Kinect does not track it. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What I want to know is, are there some basics behind Kinect's human body motion tracking that essentially fails when a robot is placed in front of it instead of a human?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;PS: I have kept the Nao at the right distance from the sensor. I have also checked if the entire robot is in the field of view of the sensor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT: This has been posted &lt;a href=&quot;http://stackoverflow.com/q/13068945/1473556&quot;&gt;on stackoverflow&lt;/a&gt; and &lt;a href=&quot;http://social.msdn.microsoft.com/Forums/en-US/kinectsdk/thread/723a1072-f637-466f-a721-196984e7763a/#723a1072-f637-466f-a721-196984e7763a&quot; rel=&quot;nofollow&quot;&gt;on msdn&lt;/a&gt; by me so as to target a large audience as this problem has not been encountered by anyone in the past.&lt;/p&gt;&#xA;" OwnerUserId="117" LastEditorUserId="37" LastEditDate="2012-10-27T21:46:59.970" LastActivityDate="2012-10-27T21:46:59.970" Title="Detect Nao robot in Kinect" Tags="&lt;kinect&gt;" AnswerCount="1" CommentCount="4" />
  <row Id="150" PostTypeId="1" AcceptedAnswerId="168" CreationDate="2012-10-26T07:23:58.103" Score="22" ViewCount="2561" Body="&lt;p&gt;Whenever building an aquatic bot, we always have to take care to prevent leakages, for obvious reasons. Now, holes for wires can be made watertight easily--but what about motors? We can easily seal the casing in place (and fill in any holes in the casing), but the part where the axle meets the casing is still left unprotected. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/xahVT.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Water leaking into the motor is still quite bad. I doubt there's any way to seal up this area properly, since any solid seal will not let the axle move, and any liquid seal (or something like grease) will rub off eventually.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I was thinking of putting a second casing around the motor, maybe with a custom rubber orifice for the shaft. Something like (forgive the bad drawing, not used to GIMP):&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/z0E4K.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This would probably stop leakage, but would reduce the torque/rpm significantly via friction.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, how does one prevent water from leaking into a motor without significantly affecting the motor's performance?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(To clarify, I don't want to buy a special underwater motor, I'd prefer a way to make my own motors watertight)&lt;/p&gt;&#xA;" OwnerUserId="126" LastEditorUserId="350" LastEditDate="2012-11-30T14:23:20.117" LastActivityDate="2013-10-06T16:24:37.993" Title="Preventing leaks in motor shafts for underwater bots" Tags="&lt;motor&gt;&lt;underwater&gt;&lt;auv&gt;&lt;protection&gt;" AnswerCount="8" CommentCount="1" FavoriteCount="2" />
  <row Id="151" PostTypeId="2" ParentId="131" CreationDate="2012-10-26T07:36:48.440" Score="3" Body="&lt;p&gt;It's been a while since I've used the AVR, but there where two libraries which would do what you are looking for. Unfortunately ATMEL doesn't provide proper firmware libraries themselves (as e.g. STM does).&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://www.procyonengineering.com/embedded/avr/avrlib/&quot; rel=&quot;nofollow&quot;&gt;Procyon AVRlib&lt;/a&gt; is quite outdated, but also very lightweight. You can just use the parts that you are interested in.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://www.nongnu.org/avr-libc/&quot; rel=&quot;nofollow&quot;&gt;AVR Libc&lt;/a&gt; is another library which is slightly more recent and in my experience quite comprehensive. I think it is actually bundled with a lot of toolchains.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="127" LastActivityDate="2012-10-26T07:36:48.440" CommentCount="1" />
  <row Id="152" PostTypeId="2" ParentId="142" CreationDate="2012-10-26T08:43:24.673" Score="5" Body="&lt;p&gt;Kiva uses a multi-agent system to control its fleet of robots and movable shells. Their website provides a &lt;a href=&quot;http://www.kivasystems.com/solutions/software/&quot;&gt;high-level overview of their system architecture&lt;/a&gt; and there's also a &lt;a href=&quot;http://www.slideshare.net/devbp/kiva-system&quot;&gt;presentation&lt;/a&gt; online that goes into more detail. The A* algorithm is used for wayfinding and a heuristic algorithm decides on the order of things to pick up (travelling salesman problem) and which shelves to move where (more frequently used shelves are put nearer the packing stations to reduce travel time).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;According to &lt;a href=&quot;https://www.aaai.org/ojs/index.php/aimagazine/article/viewArticle/2082&quot;&gt;this paper&lt;/a&gt;, the whole system is implemented in Java and MySQL.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I couldn't find any direct quote about the sensors in their mobile platforms, but from the picture I'd be guessing a number of sonars and IRs&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/MQhwO.png&quot; alt=&quot;Kiva Systems Robot&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="131" LastActivityDate="2012-10-26T08:43:24.673" />
  <row Id="153" PostTypeId="2" ParentId="138" CreationDate="2012-10-26T08:52:45.753" Score="4" Body="&lt;p&gt;Since robotics is a combination of Electrical, Mechanical and Software Engineering the maths for those fields is obviously relevant. On top of that I would argue that in robotics it is very helpful to have good knowledge of linear algebra, probability and control theory. A good grasp of mechanics obviously helps as well. &lt;/p&gt;&#xA;" OwnerUserId="127" LastActivityDate="2012-10-26T08:52:45.753" />
  <row Id="154" PostTypeId="1" AcceptedAnswerId="248" CreationDate="2012-10-26T09:45:37.170" Score="7" ViewCount="1431" Body="&lt;p&gt;Often we use microcontrollers to do things in our robots, but need to make some calculations in decimal. Using floating point variables is &lt;strong&gt;very&lt;/strong&gt; slow, because a software floating point library is automatically included (unless you have a high-end microcontroller). Therefore, we generally use fixed point arithmetic.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Whenever I do this, I just use an integer, and remember where the decimal place is. However, it does take some care to ensure that everything is consistent, especially when calculations involve variables where the decimal point is in a different place.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have implemented a fixed point atan2 function, but because I was trying to squeeze every last drop of limited precision (16 bits), I would often change the definition of where the decimal point is, and it would change as I tweaked it. In addition, I would have some constants, as a quasi look-up table, which themselves have an implied decimal point somewhere.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I want to know if there is a better way. Is there a library, or set of macros, that can simplify the use of fixed point variables, making multiplication and division between mixed variables easier, and allowing declaration of decimal numbers or constant expressions, but automatically converting to the desired fixed point representation at compile time?&lt;/p&gt;&#xA;" OwnerUserId="145" LastActivityDate="2013-04-14T18:11:12.667" Title="Fixed point arithmetic on microcontrollers" Tags="&lt;microcontroller&gt;&lt;c&gt;" AnswerCount="4" CommentCount="12" FavoriteCount="2" />
  <row Id="155" PostTypeId="1" AcceptedAnswerId="157" CreationDate="2012-10-26T09:58:11.633" Score="9" ViewCount="443" Body="&lt;p&gt;At our lab, we have a several &quot;Kurt&quot; type robots (about the size of a Pioneer, six wheels, differential drive). The built-in gyroscopes are by now really outdated; the main problem is that the gyroscopes have a large drift that increases as the gyro heats up (the error is up to 3°/s). We mainly use the IMU to get initial pose estimates that are later corrected by some localization algorithm, but even so the large initial pose error caused by the IMU is often annoying.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We've temporarily used an Android phone (Galaxy S2) as a replacement IMU, and the results are so much better compared to the old IMUs. However, I don't like depending on a WiFi connection between IMU and the control computer (a laptop running ROS/Ubuntu), so we're looking to buy a new IMU.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What IMU should we choose? What criteria are important to consider for our application? Please share your experiences! :-)&lt;/p&gt;&#xA;" OwnerUserId="132" LastEditorUserId="37" LastEditDate="2012-11-18T01:03:57.833" LastActivityDate="2012-11-18T01:03:57.833" Title="How to choose a good IMU for a wheeled robot?" Tags="&lt;ros&gt;&lt;imu&gt;&lt;odometry&gt;&lt;gyroscope&gt;&lt;ugv&gt;" AnswerCount="2" CommentCount="1" />
  <row Id="156" PostTypeId="2" ParentId="154" CreationDate="2012-10-26T10:03:07.797" Score="0" Body="&lt;p&gt;If you use an integer to remember where the &quot;point&quot; is, they are &lt;em&gt;kind of&lt;/em&gt; using floating point arithmetic. Fixed point, really has &lt;strong&gt;fixed&lt;/strong&gt; point.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I suspect that for every function there would be a different &quot;preprocessing&quot; to make your &quot;floating&quot; point number suitable for the function. For example, for &lt;code&gt;atan&lt;/code&gt;, you would want to shift the number so that it's decimal point matches that of your fixed-point function. For &lt;code&gt;cos&lt;/code&gt;, you may want to get it in the range of $\pi$ and $-\pi$ and then shift it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This depends on the range of values your application needs, but you may want to completely move to a fixed point representation. That is, for example, instead of keeping a number like this:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;struct num&#xA;{&#xA;    uint16_t number;&#xA;    uint16_t decimal_point;&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;where &lt;code&gt;number&lt;/code&gt; is the whole number and &lt;code&gt;decimal_point&lt;/code&gt; says where the decimal point is, you can store it like this:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;struct num&#xA;{&#xA;    uint16_t integer;&#xA;    uint16_t fraction;&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;where the whole number is &lt;code&gt;integer.fraction&lt;/code&gt;, which has the same memory usage, higher range of values and in general simpler to use.&lt;/p&gt;&#xA;" OwnerUserId="158" LastActivityDate="2012-10-26T10:03:07.797" CommentCount="4" />
  <row Id="157" PostTypeId="2" ParentId="155" CreationDate="2012-10-26T10:31:24.353" Score="5" Body="&lt;p&gt;I have used a &lt;a href=&quot;http://www.vectornav.com/products/vn100-rug&quot;&gt;VN-100&lt;/a&gt; IMU to replace an old one (which could be quite inaccurate).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My experience with the VN-100 is quite good. It includes an internal Kalman filter to estimate pitch, roll and yaw (using magnetic sensors), and you can tune the gains on the Kalman filter yourself. How they should be tuned will depend on your application (eg. vibration, usual rates of rotation and acceleration).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My experience is that it is easily within 1 degree accuracy, and if tuned well, can be almost 0.1 degree accuracy. Having said that, it requires the use of the active tuning parameter (depending on how far acceleration differs from gravity). While I have looked closely at the angular position data, I have not specifically investigated the accuracy of the acceleration or angular rate data (although I have some data, but I used encoders as a ground truth, and differentiation makes the encoder data too noisy to compare).&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Things you might want to consider:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It is definitely a bonus to be able to tune the Kalman filter gains. If the gains are not well tuned, even good raw data can result in inferior filtered data.&lt;/li&gt;&#xA;&lt;li&gt;Other than that, sampling time may be important (if you want samples at a high frequency - the VN-100 has a maximum frequency of 200Hz).&lt;/li&gt;&#xA;&lt;li&gt;Consider the communication protocol (the VN-100 supports RS-232, or SPI with the SMD package). With RS-232, you will want to consider the maximum rate available on your DAQ system, eg. 460kHz baud rate is required to get data at 200Hz, otherwise you will not get all the data at such a high frequency&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Size&lt;/strong&gt;? Our old IMU was quite large (5cm), but the VN-100 is tiny.&lt;/li&gt;&#xA;&lt;li&gt;Magnetic sensors - if you want yaw position data, but be aware that motors in close proximity (depends on the size of motors, but perhaps within 10cm or more) will stop them working.&lt;/li&gt;&#xA;&lt;li&gt;Kalman filter - unless you want to process the data yourself&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="145" LastActivityDate="2012-10-26T10:31:24.353" CommentCount="2" />
  <row Id="158" PostTypeId="5" CreationDate="2012-10-26T10:55:06.860" Score="0" ViewCount="8" Body="&lt;p&gt;ROS (Robot Operating System) is a free, open-source robot software framework for robot software development, providing operating system-like functionality on a heterogeneous computer cluster.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;ROS provides standard operating system services such as hardware abstraction, low-level device control, implementation of commonly used functionality, message-passing between processes, and package management.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It was developed by &lt;a href=&quot;http://willowgarage.com&quot; rel=&quot;nofollow&quot;&gt;Willow Garage&lt;/a&gt; and is licensed under the BSD license.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.ros.org/wiki/&quot; rel=&quot;nofollow&quot;&gt;Website (API documentation)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Robot_Operating_System&quot; rel=&quot;nofollow&quot;&gt;Wikipedia Article&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="131" LastEditorUserId="40" LastEditDate="2013-09-02T04:38:24.530" LastActivityDate="2013-09-02T04:38:24.530" />
  <row Id="159" PostTypeId="4" CreationDate="2012-10-26T10:55:06.860" Score="0" Body="ROS (Robot Operating System) is a free, open-source robot software framework developed by Willow Garage." OwnerUserId="131" LastEditorUserId="18" LastEditDate="2012-10-26T15:09:54.797" LastActivityDate="2012-10-26T15:09:54.797" />
  <row Id="160" PostTypeId="2" ParentId="155" CreationDate="2012-10-26T11:30:21.933" Score="3" Body="&lt;p&gt;I assume that you are looking for an IMU that provides you with an orientation estimation. The complete package is usually called an Attitude and Heading Reference System (AHRS). What really is the most defining criteria is your budget. Getting above 3 degrees/s should be within reach though. &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;We have been working with the &lt;a href=&quot;http://www.xsens.com/en/general/mti&quot; rel=&quot;nofollow&quot;&gt;XSens MTi&lt;/a&gt; and had good enough results for navigation of ground vehicles. They have a new line out, which has improved on the accuracy quite a bit. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Budget options are also available, &lt;a href=&quot;https://www.sparkfun.com/products/11028&quot; rel=&quot;nofollow&quot;&gt;this one&lt;/a&gt; looks quite promising as it is a single chip solution. There is also an &lt;a href=&quot;https://www.sparkfun.com/pages/accel_gyro_guide&quot; rel=&quot;nofollow&quot;&gt;IMU buyers guide&lt;/a&gt; at Sparkfun. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Usually pitch and roll are fine with most IMUs for ground vehicles, as the gravity vector can be used to compensate the drift. Not so with the yaw axis, which is often a problem even when compensated with a magnetometer. For that reason we often use a single &lt;a href=&quot;http://www.kvh.com/dsp3000comm&quot; rel=&quot;nofollow&quot;&gt;fibre optic gyro&lt;/a&gt; to minimize the heading drift.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="127" LastActivityDate="2012-10-26T11:30:21.933" />
  <row Id="161" PostTypeId="2" ParentId="113" CreationDate="2012-10-26T11:49:48.540" Score="7" Body="&lt;p&gt;This subject is covered quite nicely in the &lt;a href=&quot;http://www.probabilistic-robotics.org/&quot;&gt;Probabilistic Robotics&lt;/a&gt; book by Thrun et. al. I don't have a direct reference, but there are some of his papers (such as &lt;a href=&quot;http://www.cs.cmu.edu/~thrun/papers/thrun.robust-mcl.ps.gz&quot;&gt;Robust Monte Carlo Localization for Mobile Robots&lt;/a&gt;, &lt;a href=&quot;http://www.cs.cmu.edu/~thrun/papers/thrun.robust-mcl.pdf&quot;&gt;pdf&lt;/a&gt;) essentially include the same information. Usually what is used is a mixed error model, where the probability density function consists of different parts&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A Gaussian error around the true distance reading&lt;/li&gt;&#xA;&lt;li&gt;A part which accounts for false positives like dynamic obstacles and so on. This is larger with smaller distances.&lt;/li&gt;&#xA;&lt;li&gt;A constant part which accounts for false negative readings, where the sensor gives an out of range reading.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The model needs to be fitted to your sensor and application.&lt;/p&gt;&#xA;" OwnerUserId="127" LastEditorUserId="37" LastEditDate="2012-10-27T17:29:48.033" LastActivityDate="2012-10-27T17:29:48.033" />
  <row Id="162" PostTypeId="2" ParentId="154" CreationDate="2012-10-26T13:44:35.147" Score="1" Body="&lt;p&gt;There are a number of implementations (no libraries that I'm immediately aware of) of &lt;a href=&quot;http://en.wikipedia.org/wiki/Binary_scaling&quot; rel=&quot;nofollow&quot;&gt;Binary Scaling&lt;/a&gt; (aka B-scaling)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In this, you keep a mental note (or even better, document the code...) of where the decimal point is, using shifts to move the decimal point up or down.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've used B-scaling in assembler on defence projects, on even the smallest CPUs so can vouch for its suitability for anything else...&lt;/p&gt;&#xA;" OwnerUserId="134" LastActivityDate="2012-10-26T13:44:35.147" CommentCount="1" />
  <row Id="163" PostTypeId="2" ParentId="154" CreationDate="2012-10-26T14:17:58.907" Score="2" Body="&lt;p&gt;I've used the &lt;a href=&quot;http://www.ti.com/tool/sprc542&quot; rel=&quot;nofollow&quot;&gt;TI IQMath Library&lt;/a&gt; to implement virtual floating-point on their fixed-point DSPs.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Texas Instruments TMS320C28x IQmath Library is collection of highly&#xA;  optimized and high  precision mathematical functions for C/C++&#xA;  programmers to seamlessly port a floating-point  algorithm into fixed&#xA;  point code on TMS320C28x devices. These routines are typically used in&#xA;  computationally intensive real-time applications where optimal&#xA;  execution speed and high  accuracy is critical. By using these&#xA;  routines you can achieve execution speeds considerable  faster than&#xA;  equivalent code written in standard ANSI C language. In addition, by&#xA;  providing readyto-use high precision functions, TI IQmath library can&#xA;  shorten significantly your DSP application development time.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;That uses some TI specific stuff but I've also used that code as a base to implement virtual floating-point math on other microcontrollers. It takes a bit of work to port but it's a lot easier than starting from scratch.&lt;/p&gt;&#xA;" OwnerUserId="142" LastEditorUserId="142" LastEditDate="2012-11-08T13:03:52.193" LastActivityDate="2012-11-08T13:03:52.193" CommentCount="5" />
  <row Id="164" PostTypeId="2" ParentId="143" CreationDate="2012-10-26T15:38:04.407" Score="4" Body="&lt;p&gt;The loop frequency is a parameter that needs to be tuned just like your proportional, integral, and/or derivative terms. Varying it has a similar affect on your output as varying your other parameters. Too low a frequency and you'll never reach your desired steady state. Too high and the output will oscillate.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To determine the optimal loop frequency, you will first need to construct &lt;a href=&quot;https://controls.engin.umich.edu/wiki/index.php/PID_Frequency_Response_w/_Bode_Plots&quot;&gt;Bode plots&lt;/a&gt; from real world test or simulation data:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Bode plots concisely display all relevant frequency input and output&#xA;  information on two plots: amplitude ratio as a functions of frequency&#xA;  and phase shift as a function of frequency. The amplitude ratio plot&#xA;  is a log-log plot while the phase angle plot is a semilog (or&#xA;  log-linear) plot.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;To construct a Bode plot, an engineer would have&#xA;  empirical data showing input and output values that vary as sinusoidal&#xA;  functions of time. For instance, there might be inlet temperature data&#xA;  that varies sinusoidally and the outlet temperature data that also&#xA;  varies sinusoidally.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;The amplitude ratio, AR, is the ratio of the amplitude of the output&#xA;  sinusoidal curve divided by the amplitude of the input sinusoidal&#xA;  curve.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;$$AR = \dfrac{outputamplitude}{inputamplitude}$$&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;To find the phase shift, the periods of the input and output sine&#xA;  curves need to be found. Recall that the period, P, is the length of&#xA;  time from one peak to the next.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;$$P = \dfrac{1}{f} = \dfrac{2\pi}{\omega}$$&#xA;  $$f = frequency$$&#xA;  $$\omega = frequency(rad/sec)$$&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/p5iqK.jpg&quot; alt=&quot;AR vs. freq&quot;&gt;&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/reXBG.jpg&quot; alt=&quot;phase vs. freq&quot;&gt;&lt;/p&gt;&#xA;  &#xA;  &lt;h1&gt;Rules of Thumb when analyzing Bode plots&lt;/h1&gt;&#xA;  &#xA;  &lt;p&gt;Generally speaking, a gain change shifts the amplitude ratio up or&#xA;  down, but does not affect the phase angle. A change in the time delay&#xA;  affects the phase angle, but not the amplitude ratio. For example, an&#xA;  increase in the time delay makes the phase shift more negative for any&#xA;  given frequency. A change in the time constant changes both the&#xA;  amplitude ratio and the phase angle. For example, an increase in the&#xA;  time constant will decrease the amplitude ratio and make the phase lag&#xA;  more negative at any given frequency.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Then you will need to determine the &lt;a href=&quot;http://www.goddardconsulting.ca/pid-control.html&quot;&gt;cross-over frequency&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The proportional term moves the magnitude of the frequency response of&#xA;  the open loop up or down and hence is used to set the cross-over&#xA;  frequency of the open loop. The cross-over frequency is the frequency&#xA;  at which the magnitude has a gain of 1 (or 0dB). This frequency is&#xA;  important as it is closely related to bandwidth of the closed loop&#xA;  response.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;In an ideal system the proportional gain could be made (almost)&#xA;  infinitely large leading to an infinitely fast, yet still stable,&#xA;  closed loop. In practice that is not the case. Rather, two design&#xA;  rules of thumb come into play.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Firstly the sample rate of the digital hardware on which the&#xA;  controller is going to be executed needs to be considered. &lt;strong&gt;A typical&#xA;  rule of thumb is that the cross-over frequency should be set to be at&#xA;  least 10 times lower than the sample rate of the controller.&lt;/strong&gt;&#xA;  Conceptually this ensures that the controller is running at a fast&#xA;  enough rate that it can adequately handle changes in the signal being&#xA;  controlled.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;The second rule of thumb is related to the slope of the frequency&#xA;  response at the cross-over frequency. If the roll-off of the open-loop&#xA;  magnitude response at cross-over can be made to be close to&#xA;  -20dB/decade then the closed-loop bandwidth can be expected to be close to the cross-over frequency. Note that the integral and&#xA;  derivative terms, not just the proportional term, are used to control&#xA;  the slope at cross-over.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/yU7CW.jpg&quot; alt=&quot;bode cross-over graph&quot;&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;(emphasis mine)&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So the optimal control loop frequency should be around 10 times that of the cross-over frequency of your system's phase delay which can be obtained through empirical test data or, ideally, computer simulation.&lt;/p&gt;&#xA;" OwnerUserId="142" LastActivityDate="2012-10-26T15:38:04.407" CommentCount="7" />
  <row Id="165" PostTypeId="2" ParentId="119" CreationDate="2012-10-26T15:39:58.707" Score="2" Body="&lt;p&gt;Just to add a little to &lt;a href=&quot;http://robotics.stackexchange.com/a/120/37&quot;&gt;ronalchn's excellent answer&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Changing the weight distribution in the robot in a way that doesn't change the position of the centre of mass will affect the &lt;a href=&quot;http://en.wikipedia.org/wiki/Moment_of_inertia&quot; rel=&quot;nofollow&quot;&gt;Moment of Inertia&lt;/a&gt;, which in turn will affect the robot's ability to accelerate its rate of rotation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For most robots that trundle along, this is unlikely to be a problem. However, I could imagine that for an &lt;em&gt;extremely&lt;/em&gt; dynamic robot, that travels very quickly and takes tight turns, being able to rotate its body rapidly might be an advantage, and might even be able to save itself from tipping in some extreme cases.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Therefore concentrating the mass near the centre would be best for this type of robot.&lt;/p&gt;&#xA;" OwnerUserId="40" LastEditorUserId="37" LastEditDate="2012-10-26T16:19:50.753" LastActivityDate="2012-10-26T16:19:50.753" CommentCount="2" />
  <row Id="166" PostTypeId="2" ParentId="138" CreationDate="2012-10-26T16:55:14.853" Score="10" Body="&lt;p&gt;Other answers are correct: It depends on where you are focusing, and what your topic will be. However, there are some common themes. I would say that a minor in mathematics from a decent university should cover the bases.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would strongly recommend the following, based on my experience:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Linear Algebra, at least one or two semesters. Plan on taking refresher courses and specializing if necessary. Because robots operate in the world, and the world is defined by coordinate frames, knowing something about matrix multiplication, inverses, rank, affine and projective transformations, etc is extremely helpful. &lt;/li&gt;&#xA;&lt;li&gt;Calculus, at least 3 semesters.&lt;/li&gt;&#xA;&lt;li&gt;Some numerical analysis, because robots use computers.&lt;/li&gt;&#xA;&lt;li&gt;Probabilities and Statistics, at least 1 semester, though this is becoming increasingly important&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;For my subfield (Algorithmic Robotics), the following things are very helpful:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Algorithms and Data Structures, at least 2 semesters&lt;/li&gt;&#xA;&lt;li&gt;Formal Theory of Computation (Hardness and mappings of problems), at least one semester&lt;/li&gt;&#xA;&lt;li&gt;Matrix Theory, (another semester of a specialized linear algebra)&lt;/li&gt;&#xA;&lt;li&gt;Discrete Math (graphs, counting and enumueration), at least 1 semester, &lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="163" LastEditorUserId="163" LastEditDate="2012-10-26T17:36:34.550" LastActivityDate="2012-10-26T17:36:34.550" />
  <row Id="167" PostTypeId="1" AcceptedAnswerId="174" CreationDate="2012-10-26T19:11:31.040" Score="13" ViewCount="2368" Body="&lt;p&gt;Tuning controller gains can be difficult, what &lt;strong&gt;general&lt;/strong&gt; strategies work well to get a stable system that converges to the right solution?&lt;/p&gt;&#xA;" OwnerUserId="73" LastEditorUserId="350" LastEditDate="2012-11-30T14:32:38.397" LastActivityDate="2013-07-05T19:52:50.117" Title="What are good strategies for tuning PID loops?" Tags="&lt;control&gt;&lt;pid&gt;&lt;tuning&gt;" AnswerCount="9" CommentCount="2" FavoriteCount="5" />
  <row Id="168" PostTypeId="2" ParentId="150" CreationDate="2012-10-26T21:12:04.797" Score="13" Body="&lt;p&gt;I'm not sure if an 'aquabot' is a fully submersible vehicle, or a surface one.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If it's a surface vehicle, then you just need to look at RC boats. They've got this solved pretty well.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/W7zXO.gif&quot; alt=&quot;Boat propeller shaft&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The seal that prevents water entering the boat is called a stuffing box (4 on the diagram). It's simply a tube stuffed with grease. The grease prevents any water leaking into the boat between the tube and the propeller shaft. Usually there's about a 1mm or so gap between the shaft and the inside of the tube, so that it can hold plenty of grease. The ends of the tube have loose bushings fitted which hardly contribute any friction, but prevent the grease escaping.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This will probably work well even for fully submersible vehicles, as long as they don't go too deep. As you go deeper, the pressure will begin to force water up the tube, pushing the grease out, and eventually letting water into the boat.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One way to combat this is to simply push back. Increase the air pressure at the other end of the stuffing box so that things stay balanced. One way to do this is to enclose the motor and the inside end of the tube inside a small sealed box. Use a tiny pump to pressurize the box to match the water pressure.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Alternatively, why not let the water do the work for you? Seal the motor inside a rubber bladder and house it outside the boat. The water pressure will compress the bladder so that the air pressure inside always matches the pressure outside perfectly.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;My final suggestion is similar to &lt;a href=&quot;http://robotics.stackexchange.com/a/275/37&quot;&gt;Mark Booth&lt;/a&gt;'s. Why not build a motor which can cross the hull of the vehicle. Put the magnets of the motor outside, and keep the windings inside where it's dry. What you will be making here is basically a Brushless Motor:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/Y26Lk.jpg&quot; alt=&quot;Brushless motor&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You could maybe build this into something like a ducted fan.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/6OCz4.jpg&quot; alt=&quot;Ducted Fan&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="40" LastEditorUserId="37" LastEditDate="2012-11-05T13:02:51.943" LastActivityDate="2012-11-05T13:02:51.943" CommentCount="4" />
  <row Id="169" PostTypeId="2" ParentId="99" CreationDate="2012-10-26T22:12:08.123" Score="3" Body="&lt;p&gt;I can't answer specifically for the AVR, but I can offer some more general advice.&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Low level&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;I think you are going to have to &lt;strong&gt;prioritise&lt;/strong&gt;. Look at what you can afford to throw away and what you can afford to process when your system starts to get overloaded. Also, profile your usage to see what data you have coming in when.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For instance, if you have a higher level retry protocol on your serial comms, then when you are overloaded perhaps you could drop incoming serial bytes, leaving it to the retry mechanism to catch up when the CPU has the time.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you can do this then you are going to want to fail early. When your serial buffer is full, there is no point reading the data from the uart, writing it into your buffer, overwriting existing data - that's just wasting cycles which could be used elsewhere (you are going to have to throw away the partial serial stream anyway). When you experience a serial buffer overrun, just clear the uart without reading it, leave the buffer in it's old state and return, letting the CPU get on with things it can complete successfully.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Alternatively, you could disable interrupts entirely for low priority events.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Profiling your usage can also be very valuable. Lets say you have four 16 byte buffers where one is constantly going into an overrun condition because you are sending 36 byte packets to it, but where the other 3 never have more than 5 or 6 bytes in them at once. In this case it is worth rewriting your buffer code to allow different sized buffers. That way you could allocate 8 bytes each to three streams and 40 bytes for the final stream.&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;High level&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;You need to analyse &lt;em&gt;why&lt;/em&gt; your buffers &lt;em&gt;randomly fill up by chance&lt;/em&gt;. Are you trying to do too much with the data in one go? Could you split that processing up and do several shorter processes rather than one long process.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For instance, if your interrupts normally take up 70% of your CPU and another routine takes up 20% &lt;em&gt;on average&lt;/em&gt;, but only needs 10% some of the time and runs out of CPU at others, then breaking up that processing into more predictable, repeatable blocks could be worthwhile, even if it takes more processing power power overall.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, if you don't have a higher level retry mechanism, consider implementing one, this would enable low level prioritisation which might otherwise not be possible.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Finally, learn how to optimise for your hardware. Again, profiling can help here. If your ISRs are taking up a significant proportion of your CPU time, every cycle you save is a cycle you can use elsewhere. Don't blindly 'optimise' everywhere, chose your battles. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Profiling will tell you where in your code is most critical so you can put your efforts where it will count (See &lt;a href=&quot;http://programmers.stackexchange.com/a/99463/22493&quot;&gt;Is micro-optimisation important when coding?&lt;/a&gt;).&lt;/p&gt;&#xA;" OwnerUserId="37" LastEditorUserId="37" LastEditDate="2012-11-06T20:39:34.383" LastActivityDate="2012-11-06T20:39:34.383" />
  <row Id="170" PostTypeId="2" ParentId="146" CreationDate="2012-10-26T22:18:28.410" Score="2" Body="&lt;p&gt;For ball bearings, you almost always want to use the hardest, smoothest material you can find. Stainless steel would do nicely. Aluminium will be far too soft, and will simply be worn down the the steel ball bearings.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Plastic bearings like these &lt;a href=&quot;http://www.igus.com/wpck/default.aspx?Pagename=drylin_w&amp;amp;C=US&amp;amp;L=en&quot; rel=&quot;nofollow&quot;&gt;Drylin&lt;/a&gt; from Igus can use aluminium rails:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/oqeAN.jpg&quot; alt=&quot;Igus DryLin&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-10-26T22:18:28.410" />
  <row Id="171" PostTypeId="2" ParentId="167" CreationDate="2012-10-27T04:37:37.783" Score="6" Body="&lt;p&gt;Sebastian Thrun presented a simple algorithm for tuning PID in his &quot;How to Program a Robotic Car&quot; class. It's called &quot;twiddle&quot;, he describes it here: &lt;a href=&quot;https://www.youtube.com/watch?v=2uQ2BSzDvXs&quot;&gt;https://www.youtube.com/watch?v=2uQ2BSzDvXs&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Twiddle is very prone to finding local minima--this means that you could come up with a set of three constants that are okay, but not &lt;em&gt;optimal&lt;/em&gt; for the situation. The problem of tuning PID constants is a subset of a more general search problem to find certain parameters to maximize utility (in this case, minimizing error of the PID algorithm). You can look into other general solutions to this problem, like hill-climbing, simulated annealing, genetic algorithms, etc. that might end up finding more optimal solutions.&lt;/p&gt;&#xA;" OwnerUserId="181" LastActivityDate="2012-10-27T04:37:37.783" />
  <row Id="172" PostTypeId="1" AcceptedAnswerId="173" CreationDate="2012-10-27T05:11:23.017" Score="9" ViewCount="618" Body="&lt;p&gt;Using an IMU a robot can estimate its current position relative to its starting position, but this incurs error over time. GPS is especially useful for providing position information not biased by local error accumulation. But GPS cannot be used indoors, and even outdoors it can be spotty.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So what are some methods or sensors that a robot can use to localize (relative to some frame of reference) without using GPS? &lt;/p&gt;&#xA;" OwnerUserId="181" LastEditorUserId="181" LastEditDate="2012-10-29T05:09:49.703" LastActivityDate="2012-11-08T20:34:35.127" Title="Absolute positioning without GPS" Tags="&lt;localization&gt;&lt;gps&gt;&lt;sensors&gt;&lt;slam&gt;" AnswerCount="5" CommentCount="1" FavoriteCount="1" />
  <row Id="173" PostTypeId="2" ParentId="172" CreationDate="2012-10-27T06:31:55.223" Score="8" Body="&lt;p&gt;Primarily, dead reckoning is used along with some other technique, generally SLAM-like. The robot builds a map, and then tries to localize within that map. For example, using laser range scanners, and based on dead reckoning, the robot has an idea of where it is. By comparing the laser range data to the map, it can improve its estimate.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Relevant resources are:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Indoor_positioning_system&quot;&gt;Indoor positioning system&lt;/a&gt; on Wikipedia.&lt;/li&gt;&#xA;&lt;li&gt;H. Liu, H. Darabi, P. Banerjee and J. Liu. &lt;a href=&quot;http://www.sis.pitt.edu/~dtipper/2011/Survey1.pdf&quot;&gt;Survey of Wireless Indoor Positioning Techniques and Systems&lt;/a&gt;. IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS, page 1067.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.sensorplatforms.com/tracking-position-indoors-moving-from-hype-to-reality&quot;&gt;Tracking Position Indoors: moving from Hype to Reality&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Methods include:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;SLAM (or at least localization) with&#xA;&lt;ul&gt;&#xA;&lt;li&gt;laser&lt;/li&gt;&#xA;&lt;li&gt;vision (cameras, stereo-vision)&lt;/li&gt;&#xA;&lt;li&gt;structured environments&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;cellular signals&lt;/li&gt;&#xA;&lt;li&gt;wifi signals&lt;/li&gt;&#xA;&lt;li&gt;RF (radio frequency) beacons and triangulation (more information at &lt;a href=&quot;http://www.wpi.edu/Images/CMS/PPL/ITT.pdf&quot;&gt;http://www.wpi.edu/Images/CMS/PPL/ITT.pdf&lt;/a&gt;).&lt;/li&gt;&#xA;&lt;li&gt;camera tracking systems (optical tracking of markers within a space)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="145" LastActivityDate="2012-10-27T06:31:55.223" CommentCount="1" />
  <row Id="174" PostTypeId="2" ParentId="167" CreationDate="2012-10-27T08:07:31.183" Score="13" Body="&lt;p&gt;For small, low torque motors with little or no gearing, one procedure you can use to get a good baseline tune is to probe it's response to a disturbance.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To tune a PID use the following steps:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Set all gains to zero. &lt;/li&gt;&#xA;&lt;li&gt;Increase the P gain until the response to a disturbance is steady oscillation. &lt;/li&gt;&#xA;&lt;li&gt;Increase the D gain until the the oscillations go away (i.e. it's critically damped). &lt;/li&gt;&#xA;&lt;li&gt;Repeat steps 2 and 3 until increasing the D gain does not stop the oscillations.&lt;/li&gt;&#xA;&lt;li&gt;Set P and D to the last stable values. &lt;/li&gt;&#xA;&lt;li&gt;Increase the I gain until it brings you to the setpoint with the number of oscillations desired (normally zero but a quicker response can be had if you don't mind a couple oscillations of overshoot)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;What disturbance you use depends on the mechanism the controller is attached to. Normally moving the mechanism by hand away from the setpoint and letting go is enough. If the oscillations grow bigger and bigger then you need to reduce the P gain.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you set the D gain too high the system will begin to chatter (vibrate at a higher frequency than the P gain oscillations). If this happens, reduce the D gain until it stops. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I believe this technique has a name. I'll put it here when I find it.&lt;/p&gt;&#xA;" OwnerUserId="184" LastEditorUserId="37" LastEditDate="2012-10-29T16:13:27.070" LastActivityDate="2012-10-29T16:13:27.070" CommentCount="2" />
  <row Id="175" PostTypeId="2" ParentId="150" CreationDate="2012-10-27T08:15:32.077" Score="1" Body="&lt;p&gt;All seals leak. If you are able to enclose the motor so that the shaft is the only exit point, fill the motor with a low viscosity non conductive oil such as mineral oil. This greatly reduces the pressure difference across the seal.&lt;/p&gt;&#xA;" OwnerUserId="184" LastActivityDate="2012-10-27T08:15:32.077" CommentCount="1" />
  <row Id="176" PostTypeId="2" ParentId="172" CreationDate="2012-10-27T09:10:56.807" Score="2" Body="&lt;p&gt;If your goal is to have a georeferenced localization, you &lt;em&gt;will&lt;/em&gt; have to use GPS at some point. The other techniques (dead reckoning, SLAM, ...) will only be useful to &quot;bridge&quot; spotty GPS/indoor absolute positioning reception.&lt;/p&gt;&#xA;" OwnerUserId="56" LastActivityDate="2012-10-27T09:10:56.807" />
  <row Id="177" PostTypeId="2" ParentId="128" CreationDate="2012-10-27T09:29:52.167" Score="2" Body="&lt;p&gt;If you actually need real-time, then you use a real-time operating system. Safety monitoring, data acquisition, and constant sample rate control loops are common subsystems that use real-time scheduling.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The real-time portion of the programming is usually as small as possible, because it's more difficult to debug and less code is easier to check for correctness. Documentation on real-time OS's is usually pretty good (including RTAI/Xenomai).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've used QNX and RTAI-&gt;Xenomai in different &lt;em&gt;real&lt;/em&gt; robotics projects. I preferred QNX but Xenomai was just as effective.&lt;/p&gt;&#xA;" OwnerUserId="184" LastActivityDate="2012-10-27T09:29:52.167" />
  <row Id="178" PostTypeId="1" CreationDate="2012-10-27T13:22:19.930" Score="5" ViewCount="95" Body="&lt;p&gt;I have a time-series of force data of robots interacting with environment objects with various textures. I would like to develop models of various textures using the time-series data to classify textures into smooth, rough, moderate, etc. categories. For this purpose, will Hidden Markov Models be sufficient or should i use Conditional Random Fields? If I decide to classify into more categories and the distinction between each of are categories are very subtle, in that case what would be a good choice? Will force-data be sufficient to capture all the information I need to classify textures into these categories?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks for your replies :)&lt;/p&gt;&#xA;" OwnerUserId="190" LastEditorUserId="158" LastEditDate="2014-01-10T10:49:22.280" LastActivityDate="2014-01-10T10:49:22.280" Title="HMMs vs. CRFs to model time-series force data of robots interacting with environment?" Tags="&lt;artificial-intelligence&gt;&lt;texture-detection&gt;" AnswerCount="1" FavoriteCount="2" />
  <row Id="179" PostTypeId="2" ParentId="99" CreationDate="2012-10-27T15:58:01.473" Score="2" Body="&lt;p&gt;First all processors have limited performance. So the effect could be that the performance is just not good enough for the amount of work you have to do.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The average load is pretty uninteresting for diagnosing lost interrupts. The interesting thing is how many interrupt and therefore how much load on the interrupt service routines are there in peak situations. If the interrupts cause to much calculation that is needed to be done in a fixed amount of time then you need a faster CPU.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;With little computing in the ISR and a big buffer these peaks can be flattened out, but this introduces delay. If you can decrease the amount of data written into the buffer than a bit more processing in the ISR could pay of.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If your solution is to skip the unimportant(?) processing in the main routine, then you should put more processing into the ISRs. This way the CPU load will go to the ISRs and the main routine will get less. Problem here is that if the processing of one Interrupt is ongoing the next Interrupt will be delayed, as its ISR can only run after finishing the other ISR. If this delay is too long then Interrupt will get lost.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So choose the the way that is best fitted for your solution. But be aware that:&quot;The only replacement for CPU Power is CPU Power&quot;&lt;/p&gt;&#xA;" OwnerUserId="140" LastActivityDate="2012-10-27T15:58:01.473" CommentCount="2" />
  <row Id="180" PostTypeId="2" ParentId="100" CreationDate="2012-10-27T16:31:03.253" Score="3" Body="&lt;p&gt;There are lots of very reliable connectors out there. Here are a few of my favorites:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Harwin Datamate&lt;/strong&gt; These come in a few varieties. The ones shown here are fantastic and have both high current power connections, and many signal connections. They are extremely reliable, and I know that they are used on several robots I know of, including the &lt;a href=&quot;http://www.shadowrobot.com/hand/motorhand.shtml&quot; rel=&quot;nofollow&quot;&gt;Shadow Robot Hand&lt;/a&gt;, &lt;a href=&quot;http://robonaut.jsc.nasa.gov/&quot; rel=&quot;nofollow&quot;&gt;Robonaut&lt;/a&gt; and the latest &lt;a href=&quot;http://www.dlr.de/rm/en/desktopdefault.aspx/tabid-3802/&quot; rel=&quot;nofollow&quot;&gt;DLR space qualified hand&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/7gmmT.jpg&quot; alt=&quot;Harwin Datamate&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The ones you see here are a little on the expensive side, up to $30 each! But the simpler connectors with only signal pins are much more reasonable, just a couple of dollars each. They are extremely reliable. The pins are gold plated and have several contact points. The latching and screw mechanisms on them mean they can even survive the vibration of a rocket launch.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Check out Harwin's other connectors, especially the M30 range. They're pretty small and, if you crimp the wires properly, then they are extremely reliable. I have never seen one of the &lt;a href=&quot;http://www.harwin.com/M30-610-family.html&quot; rel=&quot;nofollow&quot;&gt;M30&lt;/a&gt; connectors fail due to repeated mating.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Consumer Connectors:&lt;/strong&gt; Generally, connectors intended for the consumer market should be able to survive quite a while. These include &lt;a href=&quot;http://en.wikipedia.org/wiki/Universal_Serial_Bus&quot; rel=&quot;nofollow&quot;&gt;USB&lt;/a&gt;, &lt;a href=&quot;http://en.wikipedia.org/wiki/Firewire&quot; rel=&quot;nofollow&quot;&gt;Firewire&lt;/a&gt;, &lt;a href=&quot;http://en.wikipedia.org/wiki/HDMI&quot; rel=&quot;nofollow&quot;&gt;HDMI&lt;/a&gt;, &lt;a href=&quot;http://en.wikipedia.org/wiki/VGA&quot; rel=&quot;nofollow&quot;&gt;VGA&lt;/a&gt;, &lt;a href=&quot;http://en.wikipedia.org/wiki/D-Sub&quot; rel=&quot;nofollow&quot;&gt;D-Sub&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/rqNNw.jpg&quot; alt=&quot;USB&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/cRq2H.jpg&quot; alt=&quot;HDMI&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The other good thing about these connectors is that they are suitable for high speed data, like EtherCAT's LVDS physical layer. The downside of USB, HDMI and Firewire is that they aren't vibration proof, and may fall out if not strapped down. Make sure you get gold plated ones.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Omnetics:&lt;/strong&gt; The cream of the crop come from &lt;a href=&quot;http://www.omnetics.com/&quot; rel=&quot;nofollow&quot;&gt;Omnetics&lt;/a&gt;. They have the double benefits of being both super reliable, and also very small.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/6wbc5.jpg&quot; alt=&quot;Omnetics Connectors&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/B9m4o.jpg&quot; alt=&quot;Omnetics Connectors&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;They have all kinds of wire-wire, and wire-board connectors. But be warned, they are &lt;em&gt;very&lt;/em&gt; expensive.&lt;/p&gt;&#xA;" OwnerUserId="40" LastEditorUserId="40" LastEditDate="2012-10-27T16:36:42.510" LastActivityDate="2012-10-27T16:36:42.510" />
  <row Id="181" PostTypeId="2" ParentId="148" CreationDate="2012-10-27T17:42:21.580" Score="5" Body="&lt;p&gt;You should read the paper published by Microsoft research on the actual algorithm behind the human motion tracking.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Real-Time Human Pose Recognition in Parts from a Single Depth Image, Shotton et. al,&#xA;&lt;a href=&quot;http://research.microsoft.com/apps/pubs/default.aspx?id=145347&quot;&gt;http://research.microsoft.com/apps/pubs/default.aspx?id=145347&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It relies on large labeled training data from the human body. That is why the Nao cannot just be tracked with the same method out of the box. To achieve that, you would need to re-train the algorithm with labeled data from the Nao in different poses.&lt;/p&gt;&#xA;" OwnerUserId="191" LastActivityDate="2012-10-27T17:42:21.580" />
  <row Id="182" PostTypeId="1" CreationDate="2012-10-27T19:26:10.347" Score="2" ViewCount="163" Body="&lt;p&gt;I have a joint actuated by an antagonistic pair of Pneumatic Muscles.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/7FNlN.png&quot; alt=&quot;Pneumatic Muscle Joint&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are two valves per muscle, one to fill and one to empty each muscle. The joint has an angle sensor, and each muscle also contain an air pressure sensor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What is a suitable control algorithm set up?&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A PID controller controlling the valve orifice sizes?&lt;/li&gt;&#xA;&lt;li&gt;A PID controller controlling the mass flow rate?&lt;/li&gt;&#xA;&lt;li&gt;A PID controller controlling the pressure using two PID pressure controllers?&lt;/li&gt;&#xA;&lt;li&gt;A Fuzzy Logic controller?&lt;/li&gt;&#xA;&lt;li&gt;A Neural Network?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-10-29T15:32:55.293" Title="Suitable control algorithm for Air Muscle based joint?" Tags="&lt;control&gt;&lt;pid&gt;&lt;air-muscle&gt;" AnswerCount="1" CommentCount="4" />
  <row Id="183" PostTypeId="2" ParentId="25" CreationDate="2012-10-27T19:44:03.587" Score="7" Body="&lt;p&gt;Just to add to &lt;a href=&quot;http://robotics.stackexchange.com/a/125/40&quot;&gt;user65's good answer&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Rapid rotation about a horizontal axis will come from a large difference between the thrust produced by opposite motors. The larger the difference, the greater the rotation rate. So motors that can produce much more thrust than is needed to simply hold the 'copter in the air will help to achieve fast rotations.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Rapid rotation about the vertical axis comes from a large difference in torque between one opposite pair and the other. So now you need not only plenty of spare thrust, but also a lot of propeller drag.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Sadly, both of these requirements (spare thrust, and prop drag) imply lower efficiency.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-10-27T19:44:03.587" />
  <row Id="184" PostTypeId="1" AcceptedAnswerId="523" CreationDate="2012-10-27T21:47:42.403" Score="4" ViewCount="224" Body="&lt;p&gt;Robotics has always been one of those engineering fields which has promised so much, but is taking a long time to deliver all the things that people imagine.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When someone asks: &quot;How long before we have [X] type of robots?&quot; Are there any resources we can call upon to try to calculate a rough answer. These resources might include:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Rate of progress of computational power, and some estimate of how much will be needed for various types of AI.&lt;/li&gt;&#xA;&lt;li&gt;Rate of progress of electrical energy storage density, and some estimate of how much will be needed for various types of robot.&lt;/li&gt;&#xA;&lt;li&gt;Rate of progress of actuation systems, and some estimate of what would be needed for various types of robot.&lt;/li&gt;&#xA;&lt;li&gt;Lists of milestones towards various types of robot, and which ones have been achieved and when.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Are these types of studies performed, and are the results published?&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Added:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In response to Jakob's comment, I am not looking for opinions or discussions on this subject. What I am looking for are published studies which might shed light on this question.&lt;/p&gt;&#xA;" OwnerUserId="40" LastEditorUserId="126" LastEditDate="2012-11-26T06:37:51.400" LastActivityDate="2012-11-26T21:14:26.653" Title="Robotics Trends" Tags="&lt;research&gt;" AnswerCount="3" CommentCount="2" />
  <row Id="185" PostTypeId="5" CreationDate="2012-10-27T21:57:11.377" Score="0" ViewCount="8" Body="&lt;p&gt;Most &lt;a href=&quot;/questions/tagged/servos&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'servos'&quot; rel=&quot;tag&quot;&gt;servos&lt;/a&gt; questions should fall into the subcategories of either industrial &lt;a href=&quot;/questions/tagged/servomotor&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'servomotor'&quot; rel=&quot;tag&quot;&gt;servomotor&lt;/a&gt; or &lt;a href=&quot;/questions/tagged/rcservo&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'rcservo'&quot; rel=&quot;tag&quot;&gt;rcservo&lt;/a&gt; (with the synonym &lt;a href=&quot;/questions/tagged/hobbyservo&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'hobbyservo'&quot; rel=&quot;tag&quot;&gt;hobbyservo&lt;/a&gt;). Only questions which do not fall into these two sub-categories should use this tag.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Servos, in Robotics, are almost always motors that include a position sensor and a control circuit. A position demand is sent to the control circuit, which in turn drives the motor to the demanded position and holds that position even when outside forces try to move it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The motor would normally be a brushed or brushless DC electric motor, but might also be a pneumatic muscle, hydraulic ram, voice coil, etc.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The control circuit might be implemented using a micro controller, a PLC, a decicated motion controller (possibly with an external power amplifier), or bespoke circuit (possibly with an Application Specific IC).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;sub&gt; See &lt;a href=&quot;http://meta.robotics.stackexchange.com/q/170/37&quot;&gt;What should we do about servo questions?&lt;/a&gt; &lt;/sub&gt;&lt;/p&gt;&#xA;" OwnerUserId="40" LastEditorUserId="37" LastEditDate="2013-05-20T15:31:32.790" LastActivityDate="2013-05-20T15:31:32.790" />
  <row Id="186" PostTypeId="4" CreationDate="2012-10-27T21:57:11.377" Score="0" Body="The servos tag should only be used for questions which do not fall into the servomotor or rcservo (hobbyservo) tags." OwnerUserId="40" LastEditorUserId="37" LastEditDate="2013-05-20T16:23:21.113" LastActivityDate="2013-05-20T16:23:21.113" />
  <row Id="187" PostTypeId="5" CreationDate="2012-10-27T21:59:43.823" Score="0" ViewCount="2" Body="&lt;p&gt;The wheel is one of the main components of the wheel and axle which is one of the six simple machines. Wheels are used on many robots for the purpose of locomotion. However, they can also be used in many other mechanical parts of a robot.&lt;/p&gt;&#xA;" OwnerUserId="40" LastEditorUserId="40" LastEditDate="2012-10-29T17:25:13.607" LastActivityDate="2012-10-29T17:25:13.607" />
  <row Id="188" PostTypeId="4" CreationDate="2012-10-27T21:59:43.823" Score="0" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2012-10-27T21:59:43.823" LastActivityDate="2012-10-27T21:59:43.823" />
  <row Id="189" PostTypeId="5" CreationDate="2012-10-27T22:05:15.000" Score="0" ViewCount="5" Body="&lt;p&gt;Without qualification 'motor' is usually taken to mean a rotary electromechanical motor, typically either a brushed or brushless design.&lt;/p&gt;&#xA;" OwnerUserId="40" LastEditorUserId="37" LastEditDate="2013-07-09T13:07:16.920" LastActivityDate="2013-07-09T13:07:16.920" />
  <row Id="190" PostTypeId="4" CreationDate="2012-10-27T22:05:15.000" Score="0" Body="Without qualification 'motor' is usually taken to mean a rotary electromechanical motor, typically either a brushed or brushless design." OwnerUserId="1309" LastEditorUserId="37" LastEditDate="2013-07-09T13:06:34.230" LastActivityDate="2013-07-09T13:06:34.230" />
  <row Id="191" PostTypeId="5" CreationDate="2012-10-27T22:11:46.413" Score="0" ViewCount="3" Body="&lt;p&gt;Control in the context of robotics may refer to:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The functions which allow a servo to maintain its position.&lt;/li&gt;&#xA;&lt;li&gt;The theory or mathematics that govern the control of a robot.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="40" LastEditorUserId="40" LastEditDate="2012-10-29T16:12:19.227" LastActivityDate="2012-10-29T16:12:19.227" />
  <row Id="192" PostTypeId="4" CreationDate="2012-10-27T22:11:46.413" Score="0" Body="A method or device to manage, command or regulate some part of a system." OwnerUserId="40" LastEditorUserId="40" LastEditDate="2012-10-29T17:24:36.353" LastActivityDate="2012-10-29T17:24:36.353" />
  <row Id="193" PostTypeId="5" CreationDate="2012-10-27T22:13:01.777" Score="0" ViewCount="6" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2012-10-27T22:13:01.777" LastActivityDate="2012-10-27T22:13:01.777" />
  <row Id="194" PostTypeId="4" CreationDate="2012-10-27T22:13:01.777" Score="0" Body="A robot which is capable of moving from one place to another, usually of its own volition." OwnerUserId="40" LastEditorUserId="40" LastEditDate="2012-10-29T16:12:53.470" LastActivityDate="2012-10-29T16:12:53.470" />
  <row Id="195" PostTypeId="5" CreationDate="2012-10-27T22:16:19.323" Score="0" ViewCount="11" Body="&lt;p&gt;Microcontrollers are frequently used in many parts of a robot. A single microcontroller may implement one single function of a robot, (servo control, data collection), or may implement many functions. Some robots contain only one microcontroller which carries out all of the robot's sensing, computational and data handling tasks.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Most robotics enthusiasts use one &quot;prototyping platform&quot; PCB that includes a microcontroller, connected to one or more &quot;breakout board&quot; PCBs that include some kind of motor driver, which is in turn connected to the actual motors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://en.wikibooks.org/wiki/Robotics/Computer_Control/The_Interface/Microcontrollers&quot; rel=&quot;nofollow&quot;&gt;Robotics: Microcontrollers&lt;/a&gt; has a few more words about microcontrollers that are popular in robotics.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://en.wikibooks.org/wiki/Robotics/Computer_Control/The_Interface/SBC_and_multichip_modules&quot; rel=&quot;nofollow&quot;&gt;Robotics: Computer control&lt;/a&gt; has a few words comparing boards -- &quot;protyping platform&quot;, &quot;SBC&quot;, &quot;multichip module&quot;, etc. -- that are popular in robotics, each one supporting one of the above microcontrollers.&lt;/p&gt;&#xA;" OwnerUserId="40" LastEditorUserId="187" LastEditDate="2014-01-03T03:28:18.857" LastActivityDate="2014-01-03T03:28:18.857" />
  <row Id="196" PostTypeId="4" CreationDate="2012-10-27T22:16:19.323" Score="0" Body="A small computer on a single integrated circuit containing a processor core, memory, and programmable input/output peripherals." OwnerUserId="40" LastEditorUserId="40" LastEditDate="2012-10-29T16:13:31.747" LastActivityDate="2012-10-29T16:13:31.747" />
  <row Id="197" PostTypeId="5" CreationDate="2012-10-27T22:17:35.033" Score="0" ViewCount="3" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2012-10-27T22:17:35.033" LastActivityDate="2012-10-27T22:17:35.033" />
  <row Id="198" PostTypeId="4" CreationDate="2012-10-27T22:17:35.033" Score="0" Body="A type of sensor which measures rate of rotation." OwnerUserId="40" LastEditorUserId="40" LastEditDate="2012-10-29T16:13:46.027" LastActivityDate="2012-10-29T16:13:46.027" />
  <row Id="199" PostTypeId="5" CreationDate="2012-10-27T22:19:49.303" Score="0" ViewCount="10" Body="&lt;p&gt;Questions about using an existing PID implementation connected to a device.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Possible topics include:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&quot;loop tuning&quot; -- ways of tuning and tweaking the Kp, Kd, Ki &quot;constants&quot;,&#xA;and the horrible things that go wrong when they aren't tuned right&lt;/li&gt;&#xA;&lt;li&gt;how to deal with the fact that a PID for the elbow motor tuned perfectly when the shoulder is &quot;down&quot; isn't so perfect when the shoulder is &quot;horizontal&quot; or &quot;up&quot;, or when the hand is empty vs. when the hand is holding a bowling ball, and ways to compensate.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Questions about implementing a PID controller itself are best asked on &lt;a href=&quot;http://electronics.stackexchange.com/questions/tagged/pid-controller&quot;&gt;Electrical Engineering Stack Exchange&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="187" LastEditorUserId="51" LastEditDate="2012-12-05T18:18:22.743" LastActivityDate="2012-12-05T18:18:22.743" />
  <row Id="200" PostTypeId="4" CreationDate="2012-10-27T22:19:49.303" Score="0" Body="Proportional Integral Derivative Controller. A type of control algorithm used in many control situations, especially servo systems." OwnerUserId="40" LastEditorUserId="40" LastEditDate="2012-10-29T16:13:05.313" LastActivityDate="2012-10-29T16:13:05.313" />
  <row Id="201" PostTypeId="5" CreationDate="2012-10-27T22:23:42.263" Score="0" ViewCount="17" Body="&lt;p&gt;This tag should be used with any questions relating to the use of an Arduino in robotics applications.  It should not be used for general programming questions (which are off-topic of this site).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.arduino.cc/&quot; rel=&quot;nofollow&quot;&gt;Arduino&lt;/a&gt; is an open-source electronics prototyping platform based on flexible, easy-to-use hardware and software. It's intended for artists, designers, hobbyists, and anyone interested in creating interactive objects or environments.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.arduino.cc/&quot; rel=&quot;nofollow&quot;&gt;Arduino&lt;/a&gt; can sense the environment by receiving input from a variety of sensors and can affect its surroundings by controlling lights, motors, and other actuators. Perfect for home appliances, prototyping, robotics, and more.  The microcontroller on the board is programmed using the &lt;a href=&quot;http://arduino.cc/en/Reference/HomePage&quot; rel=&quot;nofollow&quot;&gt;Arduino programming language&lt;/a&gt; (based on &lt;a href=&quot;http://wiring.org.co/&quot; rel=&quot;nofollow&quot;&gt;Wiring&lt;/a&gt;) and the &lt;a href=&quot;http://arduino.cc/en/Main/Software&quot; rel=&quot;nofollow&quot;&gt;Arduino development environment&lt;/a&gt; (based on &lt;a href=&quot;http://processing.org/&quot; rel=&quot;nofollow&quot;&gt;Processing&lt;/a&gt;). Arduino projects can be stand-alone or they can communicate with software on running on a computer (e.g. Flash, Processing, MaxMSP). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;(This text based on the summary at &lt;a href=&quot;http://www.arduino.cc/&quot; rel=&quot;nofollow&quot;&gt;www.arduino.cc&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The &lt;a href=&quot;http://ruggedcircuits.com/html/ruggeduino.html&quot; rel=&quot;nofollow&quot;&gt;Ruggeduino&lt;/a&gt; is a ruggedized Arduino-compatible microcontroller board.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;related tags:&lt;a href=&quot;/questions/tagged/atmega&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'atmega'&quot; rel=&quot;tag&quot;&gt;atmega&lt;/a&gt;&lt;a href=&quot;/questions/tagged/avr&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'avr'&quot; rel=&quot;tag&quot;&gt;avr&lt;/a&gt;&lt;a href=&quot;/questions/tagged/lilypad&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'lilypad'&quot; rel=&quot;tag&quot;&gt;lilypad&lt;/a&gt;&lt;a href=&quot;/questions/tagged/microcontroller&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'microcontroller'&quot; rel=&quot;tag&quot;&gt;microcontroller&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="40" LastEditorUserId="134" LastEditDate="2013-09-10T08:01:37.127" LastActivityDate="2013-09-10T08:01:37.127" />
  <row Id="202" PostTypeId="4" CreationDate="2012-10-27T22:23:42.263" Score="0" Body="Arduino is an open-source electronics prototyping platform based on flexible, easy-to-use hardware and software. It's intended for artists, designers, hobbyists, and anyone interested in creating interactive objects or environments. " OwnerUserId="40" LastEditorUserId="40" LastEditDate="2012-10-29T16:13:02.423" LastActivityDate="2012-10-29T16:13:02.423" />
  <row Id="203" PostTypeId="5" CreationDate="2012-10-27T22:26:28.657" Score="0" ViewCount="3" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2012-10-27T22:26:28.657" LastActivityDate="2012-10-27T22:26:28.657" />
  <row Id="204" PostTypeId="4" CreationDate="2012-10-27T22:26:28.657" Score="0" Body="The act of using a computer to study, model or predict the behaviour of a system or the outcome of an experiment." OwnerUserId="40" LastEditorUserId="40" LastEditDate="2012-10-29T16:12:26.863" LastActivityDate="2012-10-29T16:12:26.863" />
  <row Id="205" PostTypeId="1" CreationDate="2012-10-28T01:43:50.040" Score="8" ViewCount="730" Body="&lt;p&gt;Most of the linear actuators I've seen are nonuniform and/or slow. Those using a cam or crankshaft-like mechanism (and nearly anything hydraulic/pneumatic) cannot be moved at a constant speed without some programming. Those using a screw-like mechanism are uniform, but slow. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Aside from a rack and pinion/rope wound around a stick, what other fast, uniform linear actuators exist? By uniform, I mean that the speed is uniform (Or the distance moved is linearly dependant on the angle rotated by the motor)&lt;/p&gt;&#xA;" OwnerUserId="126" LastActivityDate="2012-10-28T11:23:34.773" Title="Creating a fast, uniform, linear actuator" Tags="&lt;actuator&gt;" AnswerCount="2" CommentCount="4" FavoriteCount="1" />
  <row Id="206" PostTypeId="2" ParentId="205" CreationDate="2012-10-28T08:52:28.760" Score="6" Body="&lt;p&gt;I don't know if this qualifies as a rack &amp;amp; pinion, or rope wound round a stick, but a simple belt drive actuator is very fast and smooth. I'm using one for a SMD pick and place machine where I need very good speed and smoothness of movement.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/era9I.jpg&quot; alt=&quot;Belt drive actuator&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Linear actuators based on screws don't need to be slow at all, it just depends on the pitch of the screw you use. Use a long pitch screw, and you get a lot more travel per revolution of the motor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/aaz7j.jpg&quot; alt=&quot;Long pitch ballscrew&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-10-28T08:52:28.760" />
  <row Id="207" PostTypeId="2" ParentId="172" CreationDate="2012-10-28T09:37:48.470" Score="5" Body="&lt;p&gt;I understand you problem is to find different means to GPS to find your position within a given reference frame. This problem in isolation is called localization, and there are many ways to perform that. Firstly you will have to differentiate between relative methods, so measurements which provide a change in position to a previously known position. This method has the problem, that any errors are obviously accumulated, and will grow unbounded. &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Dead reckoning is likely one of the oldest ways of relative localization. If you use heading, speed and time (so estimating the distance traveled) you can sum up you position changes from a starting position. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;In addition to using dead reckoning you can also not landmarks and track them in a map. Finding those landmarks again will allow you to reduce your relative position error. This is the Simultaneous Localization and Mapping (SLAM) problem. It is still relative navigation.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Now coming to your actual question on absolute navigation. All that GPS does is provide you with distance estimations to Landmarks with a known position information in your reference frame (in this case geocentric). GPS receivers will take these information and generate a position solution, which also has an error. The good thing though is that this error is bounded within your frame of reference. This it what makes it an absolute positioning system. So whether its indoors or outdoors and regardless of your desired reference frame, all you need for absolute positioning systems are measurements that put you in relation to some known landmark position within your reference frames. Some of those methods have been given in a &lt;a href=&quot;http://robotics.stackexchange.com/a/173/127&quot;&gt;previous answer&lt;/a&gt;. Although, as I said, SLAM is not an absolute method. &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;The simplest form is direct landmark recognition. If you see an Eiffel-Tower you should have a good notion of your absolute position (at least with an absolute error bound) within the earth fixed frame (if you know the position of the Eiffel-Tower). You may have to do some &lt;a href=&quot;http://en.wikipedia.org/wiki/Paris_Las_Vegas&quot; rel=&quot;nofollow&quot;&gt;disambiguation&lt;/a&gt;, though.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;If you want to improve your absolute position error, you can use multiple landmarks at the same time. Classical &lt;a href=&quot;http://en.wikipedia.org/wiki/Triangulation&quot; rel=&quot;nofollow&quot;&gt;Triangulation&lt;/a&gt; is such an example. Another one is using craters for a lunar descent vehicle. Landmarks don't have to be visual, and you can use things like RF signal strength for known signals like in WiFi or Cellular localization. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;All of the above methods needed landmarks, which need to be identified and uniquely associated. If this is a problem, you can also use different methods, like the &lt;a href=&quot;http://www.control.isy.liu.se/research/reports/2001/2333.pdf&quot; rel=&quot;nofollow&quot;&gt;terrain profile&lt;/a&gt;. This have for example been applied for early &lt;a href=&quot;http://adsabs.harvard.edu/abs/1982guco.conf...71L&quot; rel=&quot;nofollow&quot;&gt;cruise missile navigation&lt;/a&gt;. I've also used this method for localization on an elevation map &lt;a href=&quot;http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;amp;arnumber=6181273&amp;amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D6181273&quot; rel=&quot;nofollow&quot;&gt;without visual&lt;/a&gt; or range sensing. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;With all of the above methods: as long as any of your map material has Geo-referenced information associated, you can obviously Geo-reference yourself without the use of GPS. The most important factor to differentiate the methods is their error characteristics. &lt;/p&gt;&#xA;" OwnerUserId="127" LastEditorUserId="127" LastEditDate="2012-10-28T10:12:11.407" LastActivityDate="2012-10-28T10:12:11.407" />
  <row Id="208" PostTypeId="2" ParentId="205" CreationDate="2012-10-28T11:23:34.773" Score="8" Body="&lt;p&gt;It would be easier to give an answer if we knew what you want to use this for. That would give an idea of your requirements in terms of speed, cost, and space requirements.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As Rocketmagnet has pointed out, you can use a belt drive, or long pitch screw. And you have already mentioned a rack and pinion system. These are all involve a &lt;strong&gt;conventional (DC) motor&lt;/strong&gt; along with a mechanical system to convert angular motion into linear motion:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;belt drive&lt;/li&gt;&#xA;&lt;li&gt;screw&lt;/li&gt;&#xA;&lt;li&gt;rack &amp;amp; pinion&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;rigid chain actuator (this is also cool, it can be folded into a small space)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/IT2q0.gif&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Other methods include:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Linear_motor&quot;&gt;Linear motor&lt;/a&gt; - This is quite cool, it involves a line of magnetic poles, which accelerate the &lt;em&gt;rotor&lt;/em&gt; in a linear direction. &lt;strong&gt;These can be very fast and precise!&lt;/strong&gt; This can also be controlled in open-loop (like a stepper motor).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/OBfLO.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Above is a cross-section of a linear motor&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;Pneumatic cylinder - the speed can be controlled using a control valve, pneumatic actuators are also quite popular for robotics applications because of its compliance.&lt;/li&gt;&#xA;&lt;li&gt;Hydraulic cylinder&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Wikipedia has an article on &lt;a href=&quot;http://en.wikipedia.org/wiki/Linear_actuator&quot;&gt;linear actuators&lt;/a&gt;, and also a &lt;a href=&quot;http://en.wikipedia.org/wiki/Linear_actuator#Advantages_and_disadvantages&quot;&gt;comparison table&lt;/a&gt; with advantages and disadvantages!&lt;/strong&gt;&lt;/p&gt;&#xA;" OwnerUserId="145" LastActivityDate="2012-10-28T11:23:34.773" CommentCount="3" />
  <row Id="209" PostTypeId="1" CreationDate="2012-10-28T18:01:45.553" Score="8" ViewCount="159" Body="&lt;p&gt;In &lt;a href=&quot;http://ais.informatik.uni-freiburg.de/teaching/ws11/robotics2/pdfs/rob2-13-frontends.pdf&quot; rel=&quot;nofollow&quot;&gt;SLAM frontends&lt;/a&gt; which use the Iterative Closest Point (ICP) algorithm for identifying the association between two matching point clouds, how can you determine if the algorithm is stuck in a local minimum and returns a wrong result? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The problem is defined as matching two pointclouds which are both samples of some arbitrary surface structure, and the sampled areas have an overlap of 0-100% which is unknown. I know the &lt;a href=&quot;http://glorfindel.mavrinac.com/~aaron/school/pdf/chetverikov02_tricp.pdf&quot; rel=&quot;nofollow&quot;&gt;Trimmed ICP&lt;/a&gt; variant works by iteratively trying to determine the overlap, but even this one can be stuck in a local minimum. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;A naive approach would be to look a the mean square error of the identified point pairs. But without some estimate of the sampling this seems a risky thresholding. In the manual for the &lt;a href=&quot;http://hds.leica-geosystems.com/en/Leica-Cyclone_6515.htm&quot; rel=&quot;nofollow&quot;&gt;Leica Cyclone&lt;/a&gt; they suggest manual inspection of the pair error histogram. If it has a Gaussian shape the fit is good. If there is a linear fall-off the match is probably bad. This seems plausible for me, but I've never seen it used in an algorithm.&lt;/p&gt;&#xA;" OwnerUserId="127" LastEditorUserId="127" LastEditDate="2012-11-04T20:48:57.723" LastActivityDate="2012-11-08T04:35:06.483" Title="How to determine quality of ICP matches?" Tags="&lt;slam&gt;" AnswerCount="2" FavoriteCount="0" />
  <row Id="210" PostTypeId="1" CreationDate="2012-10-28T19:03:57.037" Score="7" ViewCount="378" Body="&lt;p&gt;I have a simple servo system that uses a PID controller implemented in an MCU to perform the feedback. However, the properties of the system change dynamically, and so the PID parameters can never be tuned for all circumstances.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My robot is a light weight arm with back-drivable electric motors, similar to this one:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/sp7VH.jpg&quot; alt=&quot;Lightweight robot arm&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The arm performs several tasks, including picking up heavy weights, pushing and pulling objects across the desk. Each of these tasks requires different PID tuning parameters which I cannot easily predict.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What I would really like is for some higher level function which can carefully adjust the parameters in response to the arm's behaviour. For example, if it notices that the arm is oscillating, it might reduce P and increase D. Or if it noticed that the arm wasn't reaching its target, it might increase I.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Do such algorithms exist? I would be happy even if the algorithm didn't perfect the parameters immediately. E.G. the arm could oscillate a few times before the parameters were adjusted to their new values. &lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-10-31T04:08:38.747" Title="How can I automatically adjust PID parameters on the fly?" Tags="&lt;control&gt;&lt;pid&gt;&lt;automatic&gt;&lt;tuning&gt;" AnswerCount="3" FavoriteCount="3" />
  <row Id="211" PostTypeId="2" ParentId="55" CreationDate="2012-10-28T20:31:46.073" Score="6" Body="&lt;p&gt;The problem with the Dynamixel servos is that they're trapped in an insulating plastic jacket. There is no convection, and no good thermally conductive material to let heat out efficiently.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The first thing I'd suggest is to get some air flow. Moving air has a surprising ability to cool something hot. You hardly need any movement to get good results. If you're willing to hack the servo, then hack away at the plastic casing. First dismantle it, removing the PCB and motor too if you can get the screws undone. Place the gears somewhere clean and safe in such a way you can remember which order they go back in.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now get your Dremmel out and carefully remove some of the casing around the motor (green areas). You're aiming to remove enough so that air can flow &lt;em&gt;through&lt;/em&gt; the casing. In one side, out the other. Note the plastic surface under the gears, there's no point cutting through to the gear cavity. In fact doing this will allow debris to enter the gear chain and stall it, so keep your cutting behind this plastic surface.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/ZfKBE.jpg&quot; alt=&quot;Cut the casing of a Dynamixel servo&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also be careful not to remove any of the material around the screws (red areas). You'll want that when you re-assemble the motor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Just doing this should give you some extra power margin before it overheats, especially if you can mount the motor so that the cool air enters at the bottom and warm air leaves at the top. It will be even better if you can blow air through the casing using a small fan. If you have several motors close together, you might be able to blow air through all of them in series with a single fan. &lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-10-28T20:31:46.073" />
  <row Id="212" PostTypeId="2" ParentId="210" CreationDate="2012-10-29T03:15:16.110" Score="2" Body="&lt;p&gt;The process you are describing is known as adaptive PID.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It seems kind of overkill though.  I have found PID to be quite robust when dealing with external disturbances and the tasks you describe do not seem beyond the capabilities of a single set of gains.&lt;/p&gt;&#xA;" OwnerUserId="65" LastActivityDate="2012-10-29T03:15:16.110" CommentCount="1" />
  <row Id="213" PostTypeId="1" AcceptedAnswerId="223" CreationDate="2012-10-29T05:30:30.627" Score="15" ViewCount="975" Body="&lt;p&gt;Smart phones these days typically come with a gyroscope, accelerometer, compass, camera, and GPS sensor all on board. They also usually have a connection to the internet with Wifi and mobile data networks. I've seen many cases of using a phone as a remote control for a robot, but to me, it seems like the phone itself is a perfect lightweight computing and sensing platform for an autonomous robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The main obstacle I see is interfacing with actuators. Being able to control motors to steer even a table-top robot, or control servos, for example. Connecting and communicating to a microcontroller could be an obstacle as well. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;As a robot hobbyist, I'd like to know how I can overcome these and other obstacles to be able to harness the power of my smart phone with my robotics projects.&lt;/p&gt;&#xA;" OwnerUserId="181" LastEditorUserId="37" LastEditDate="2013-12-18T00:03:27.247" LastActivityDate="2013-12-18T00:19:12.427" Title="How can I integrate a smart phone with my robotics project?" Tags="&lt;actuator&gt;" AnswerCount="5" FavoriteCount="12" ClosedDate="2013-12-17T15:40:47.243" />
  <row Id="214" PostTypeId="2" ParentId="213" CreationDate="2012-10-29T06:48:28.460" Score="5" Body="&lt;p&gt;The main problem as I see it isn't really interfacing with actuators-- if you have a good way to wirelessly transfer digital (even better would be analog, or a channel good enough to do PWM) signals, you can just interface that with a motor driver chip (e.g. L293D) and be good to go. For servos, you need good response time so that you can handle the pulses. If you have a PWM-capable channel, this shouldn't be hard as the channel has a high baud already. If you have a slow channel, servos may not be possible since you require accurate pulse timing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The first option I see (though it's rather bulky) is to take a Raspberry Pi, connect it via ethernet to a wireless router, and connect the phone to the same wirelessly. Now just write a basic app for your phone that sends requests  to the Pi based on  input, and write another server like app for the Pi that handles these. Might be bulky and somewhat hard, but it's quite extensible, IMO. You can also put the router offboard and stick &lt;a href=&quot;http://wolfpaulus.com/journal/embedded/raspberrypi_wifi&quot;&gt;this&lt;/a&gt; into the Pi (or use hotspot and eliminate the router entirely).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another option is to use a bluetooth controller like the one shown &lt;a href=&quot;http://blog.sigfpe.com/2011/02/build-yourself-bluetooth-controlled-six.html&quot;&gt;here&lt;/a&gt;. I've not used this before, but it looks like you'll still need a microcontroller to handle this. I guess you can connect its RX/TX pins directly to the TX/RX on an arduino, though I'm not too sure of this.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you've used XBee/ZigBee before, you may want to try out the &lt;a href=&quot;http://www.seeedstudio.com/wiki/Bluetooth_Bee&quot;&gt;bluetooth bee&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A final option is to use the phone USB port with a conventional wireless control setup (XBee/whatever)--but this will require one to write drivers and all.&lt;/p&gt;&#xA;" OwnerUserId="126" LastActivityDate="2012-10-29T06:48:28.460" />
  <row Id="215" PostTypeId="1" AcceptedAnswerId="218" CreationDate="2012-10-29T08:02:34.200" Score="10" ViewCount="933" Body="&lt;p&gt;I'd like to start making robots and tinkering with microcontrollers. Where do I start, and what do I need?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'd like to make my own robots. I'm comfortable with programming (assembly and C) so I've got that part covered, but my electronics/circuits knowledge is a little weak. I have no idea what material to start with and which tools I need, nor how to put stuff together.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For the microcontroller, I'm thinking about going with the Pololu Orangutan LV-168 or the Arduino Duemilanove, although I'm leaning more towards the Orangutan because of the built-in LCD and pushbuttons (which I would expect to use, especially for debugging and user interaction). Am I on the right track? It seems to me like the number of I/O ports is small, but is that the case in practice?&lt;/p&gt;&#xA;" OwnerUserId="119" LastEditorUserId="37" LastEditDate="2013-04-06T00:02:09.990" LastActivityDate="2013-04-06T00:02:09.990" Title="Starting out advice on making robots and tinkering with microcontrollers" Tags="&lt;arduino&gt;&lt;microcontroller&gt;&lt;beginner&gt;" AnswerCount="5" CommentCount="3" FavoriteCount="5" ClosedDate="2013-09-18T06:32:43.577" />
  <row Id="217" PostTypeId="2" ParentId="213" CreationDate="2012-10-29T09:26:01.497" Score="4" Body="&lt;p&gt;Yes, the lack of GPIO pins on smartphones is a shame. If you already have ROS running on the robot you could use &lt;a href=&quot;https://play.google.com/store/apps/details?id=org.ros.android.sensors_driver&amp;amp;hl=da&quot; rel=&quot;nofollow&quot;&gt;this app&lt;/a&gt; on an Android phone to get access to the sensor suite on the phone.&lt;/p&gt;&#xA;" OwnerUserId="61" LastActivityDate="2012-10-29T09:26:01.497" />
  <row Id="218" PostTypeId="2" ParentId="215" CreationDate="2012-10-29T09:29:49.547" Score="7" Body="&lt;p&gt;I'd recommend getting your hands on a &lt;code&gt;3pi&lt;/code&gt; and an &lt;code&gt;Arduino&lt;/code&gt;. They both use the same chip, and are a great place to start.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Get yourself some tools.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A soldering iron with a sharp point.&lt;/li&gt;&#xA;&lt;li&gt;A multimeter.&lt;/li&gt;&#xA;&lt;li&gt;Some breadboards and some wire.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Actually, just look here:&#xA;&lt;a href=&quot;http://www.ladyada.net/library/equipt/&quot;&gt;Ladyada's Equipment List&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="118" LastEditorUserId="145" LastEditDate="2012-10-29T10:03:25.110" LastActivityDate="2012-10-29T10:03:25.110" CommentCount="1" />
  <row Id="219" PostTypeId="2" ParentId="178" CreationDate="2012-10-29T14:13:20.547" Score="3" Body="&lt;p&gt;Based on your problem description, both HMM (generative model) and CRF (discriminative model) will work. See this discussion for a more in-depth explanation of the two approaches:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://stackoverflow.com/questions/879432/what-is-the-difference-between-a-generative-and-discriminative-algorithm&quot;&gt;What is the difference between a Generative and Discriminative Algorithm?&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A suggestion: before choosing an algorithm, start by carefully looking at your numerical data, with MATLAB plots or similar. If the information is multi-dimensional (e.g. force values from multiple sensors), it might be the case that some dimensions (e.g. sensor reads) do not contain useful discriminative information; in this case, compress the data with Principal Component Analysis so that you will have more compact features during training and classification.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now, with regard to your question:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The difference is that HMMs can represent each of your texture classes with several hidden variables/states, thus capturing the internal temporal evolution of each contact. We can say that HMM better model the &quot;low-level&quot; (intra-class) dynamics of your data. For example, in your case HMMs will permit you to explicitly model three different phases of each data acquisition: (1) start of contact between robot and object; (2) stable part of the contact; (3) end of contact and release. These phases could have different values in time, even for the same object texture, and it could make sense to separate them to improve classification results.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On the other hand, CRFs are more suited for capturing the &quot;high-level&quot; (inter-class) relations of your data distribution, which are sometimes important when the spatio-temporal variability is high, or when the observation features are very similar between two samples belonging to different classes.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Personally I find HMMs easier to use and I would start with those, but your mileage may vary.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;If I decide to classify into more categories and the distinction between each of are categories are very subtle, in that case what would be a good choice?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;In that case, CRFs can be a more robust choice (see above).&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Will force-data be sufficient to capture all the information I need to classify textures into these categories?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Adding visual features (object appearance), especially if captured with high-resolution cameras, could help determine if the object has a rough texture or not.&lt;/p&gt;&#xA;" OwnerUserId="197" LastActivityDate="2012-10-29T14:13:20.547" CommentCount="2" />
  <row Id="220" PostTypeId="2" ParentId="182" CreationDate="2012-10-29T15:32:55.293" Score="1" Body="&lt;p&gt;According to the Wikipedia page on &lt;a href=&quot;http://en.wikipedia.org/wiki/Pneumatic_artificial_muscles&quot; rel=&quot;nofollow&quot;&gt;Pneumatic artificial muscles&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;This is one of the major advantages; the mathematical model that supports the PAMs functionality is a non-linear system, which makes them much easier [citation needed] then conventional pneumatic cylinder actuators to control precisely. The relationship between force and extension in PAMs mirrors what is seen in the length-tension relationship in biological muscle systems.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;I'm not convinced that non-linear functionality would make them easier to control, in fact in my experienced, non-linear systems are &lt;em&gt;substantially less easy&lt;/em&gt; to control than linear systems.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This article references a number of papers which may form the basis of useful research into the kinematics of these devices. In particular &lt;a href=&quot;http://lucy.vub.ac.be/publications/Daerden_Lefeber_EJMEE.pdf&quot; rel=&quot;nofollow&quot;&gt;Pneumatic Artificial Muscles: actuators for robotics and automation&lt;/a&gt; look slike it would be quite useful as a review of the research, including plenty of citations for following up.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would guess that these air muscles suffer many of the same myths and prejudices that &lt;a href=&quot;http://hydraulicspneumatics.com/other-technologies/5-myths-pneumatic-motion-control&quot; rel=&quot;nofollow&quot;&gt;Proportional Pneumatic Motion Control&lt;/a&gt; system have, so reading up on these systems might be useful too.&lt;/p&gt;&#xA;" OwnerUserId="37" LastActivityDate="2012-10-29T15:32:55.293" />
  <row Id="221" PostTypeId="2" ParentId="210" CreationDate="2012-10-29T16:42:01.693" Score="3" Body="&lt;p&gt;A good approach for such a problem is called adaptive control. In short it is a control methodology that presumes the model is known but the parameters of the model (mass, inertia, etc.) are not. It's job is to estimate the unknown parameters. A brief introduction can be found on &lt;a href=&quot;http://en.wikipedia.org/wiki/Adaptive_control&quot; rel=&quot;nofollow&quot;&gt;wikipedia&lt;/a&gt;. The text Robotics: Modelling, Planning and Control by Siciliano et al. cover the topic more thoroughly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Edit in response to @Rocketmagnets query:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In short you must have a mathematical model of your system, i.e. the equations that describe how your system evolves over time when forced or otherwise, but you do not need to know dynamical parameters such as the mass of the various components, their inertia, etc.. It is the job of the adaptive controller to estimate these parameters. You do have to give it an initial guess for each of the unknown parameters however. Then as the system runs it uses the control signals, the output signals, and a method like linear regression or gradient descent to update the unknown parameter values. Over time the parameters will converge to values that will result in a steady-state though they may not match the real parameters, i.e. it may get the mass wrong, but the value will still work.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From here I would advise referring to a text that discusses the method. I just noticed for example that Dr. Marc Bodson is offering a copy of his text Adaptive Control: Stability, Robustness, and Convergence in PDF form on his &lt;a href=&quot;http://www.ece.utah.edu/~bodson/acscr/&quot; rel=&quot;nofollow&quot;&gt;website&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="177" LastEditorUserId="177" LastEditDate="2012-10-31T04:08:38.747" LastActivityDate="2012-10-31T04:08:38.747" CommentCount="2" />
  <row Id="222" PostTypeId="1" CreationDate="2012-10-29T17:23:11.143" Score="6" ViewCount="95" Body="&lt;p&gt;In my application, my robot has the following physical setup:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Differential drive mechanics with feedback (wheel encoders)&lt;/li&gt;&#xA;&lt;li&gt;Commercially available webcam mounted with a known transform to the base of the robot (RGB, no depth)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The robot will be navigating through a structured, indoor type environment (think office, home, or university), and I would like to be able to determine the navigable paths through the environment using my vision sensor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What is the best way to approach the problem of finding safe paths to travel when given a single vision sensor?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Edit:&lt;/strong&gt;  I think that I am more interested in the vision processing techniques than the actual path-planning mechanics.&lt;/p&gt;&#xA;" OwnerUserId="22" LastEditorUserId="22" LastEditDate="2012-10-29T20:51:53.350" LastActivityDate="2012-11-08T04:26:43.200" Title="Floor Segmentation to Determine Navigable Paths" Tags="&lt;computer-vision&gt;" AnswerCount="2" FavoriteCount="1" />
  <row Id="223" PostTypeId="2" ParentId="213" CreationDate="2012-10-29T17:44:27.130" Score="15" Body="&lt;p&gt;The &lt;a href=&quot;https://developer.android.com/tools/adk/adk2.html&quot;&gt;Android Accessory Development Kit (ADK)&lt;/a&gt; should do everything you need.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://www.xda-developers.com/wp-content/uploads/2012/05/hardwaresoftware.jpg?f39ce1&quot; alt=&quot;ADK&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It's an Arduino board that is specifically designed to interact with Android. You can connect the two over Bluetooth or USB (or WiFi/Ethernet, I think).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Since the whole architecture is open, you can use each part for what it's best at. You write the Android code to get data from the phone's built-in sensors and control the display. And you write the Arduino code to control actuators, servo's and other sensors that phone's don't come. The code to communicate between the two is provided open source via Google.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From the &lt;a href=&quot;http://arduino.cc/blog/2011/05/10/google-launches-android-open-accessory-development-kit-based-on-arduino/&quot;&gt;Arduino Blog&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The Android Open Accessory Development Kit (ADK) provides an&#xA;  implementation of an Android USB accessory that is based on the&#xA;  Arduino open source electronics prototyping platform, the accessory’s&#xA;  hardware design files, code that implements the accessory’s firmware,&#xA;  and the Android application that interacts with the accessory. The&#xA;  hardware design files and code are contained in the ADK package&#xA;  download.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Most of the examples are designed around using the phone as a graphical interface for some sort of hardware accessory like a clock. But there's no reason you couldn't access the phone's sensors as well and pass data back and forth.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Adafruit even mentions using it to make robots on their &lt;a href=&quot;https://www.adafruit.com/products/563&quot;&gt;store's page&lt;/a&gt; for the ADK:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Fast track your Android phone hardware development or just design&#xA;  &lt;strong&gt;cell-phone robots&lt;/strong&gt; with the Arduino ADK! The Arduino ADK is a&#xA;  microcontroller board based on the powerful ATmega2560 (datasheet). It&#xA;  has a USB host interface to connect with Android based phones, and a&#xA;  power supply boost converter to charge up the phone from DC power&#xA;  while its plugged into the ADK&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;(emphasis mine)&lt;/em&gt;&lt;/p&gt;&#xA;" OwnerUserId="142" LastActivityDate="2012-10-29T17:44:27.130" />
  <row Id="224" PostTypeId="2" ParentId="99" CreationDate="2012-10-29T18:10:04.630" Score="4" Body="&lt;p&gt;It sounds like you're observing the symptom of &quot;lost bytes&quot;.&#xA;There are several different things that can cause an AVR to lose bytes.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It sounds like you are &lt;em&gt;guessing&lt;/em&gt; that it's losing bytes when new bytes are coming in while the buffer is full.&#xA;While there are several remedies to fix or at least ameliorate that particular problem,&#xA;those approaches are useless and counter-productive if the real cause of the &quot;lost bytes&quot; is something else.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The first thing I would do in your shoes is to set up some sort of &quot;status debug&quot; port that gives me a clue of why exactly bytes have been lost -- at least a status LED.&#xA;Once you know why bytes are being lost,&#xA;you can apply the appropriate remedy.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Most modern protocols have some sort of check value at the end of each packet.&#xA;It's nice if your status debug system can report on the packet goodput rate and the packet error rate -- at least blink a green LED for each validated packet and a red LED for each failed packet check.&#xA;Since (especially with radio connections) the occasional corrupted byte is pretty much inevitable, most modern protocols are carefully designed such that if &lt;em&gt;any&lt;/em&gt; byte is corrupted or lost,&#xA;the system will eventually discard that packet,&#xA;and eventually re-sync and correctly handle future packets.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;bytes lost because the interrupt handler somehow never put them into the buffer&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Often bytes are lost because the interrupt handler somehow never put them into the buffer.&#xA;There are several causes, each with a different remedy:&#xA;external problems, and internal interrupts turned off too long.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;external problems&lt;/strong&gt;:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;line noise causing errors&lt;/li&gt;&#xA;&lt;li&gt;physical wired connections accidentally getting temporarily unplugged&lt;/li&gt;&#xA;&lt;li&gt;loss of signal on radio connections&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Typically we clip an o'scope to the input pin and -- if we're lucky -- we can see the problem and try various techniques to see if that cleans up the signal.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Even when the signal at the input pin looks perfect, we can still have data loss issues.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Immediately after the last bit of a byte comes in a USART or SPI port,&#xA;normally the interrupt handler for that port is triggered,&#xA;and that interrupt handler pulls that byte and sticks it into a circular buffer.&#xA;However, if the &lt;strong&gt;interrupts are turned off too long&lt;/strong&gt;,&#xA;the next byte to come in that port will inevitably overwriting and losing the first byte --&#xA;the interrupt handler for that port never sees that first byte.&#xA;The 4 &quot;ways an interrupt handler can be turned off too long&quot; are listed at &lt;a href=&quot;http://electronics.stackexchange.com/questions/35835/what-can-be-the-cause-of-an-exceptionally-large-latency-for-the-uart-receive-int/44779#44779&quot;&gt;&quot;What can be the cause of an exceptionally large latency for the UART receive interrupt?&quot;&lt;/a&gt; .&#xA;To fix this problem, you need to get the longest time an interrupt handler is ever turned off to be less than the time to transfer 1 character. So you must either&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;reduce the amount of time interrupts are turned off; or&lt;/li&gt;&#xA;&lt;li&gt;slow down the communication bit rate to increase the time to transfer 1 character;&lt;/li&gt;&#xA;&lt;li&gt;or both.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;It's very tempting to write the interrupt routine such that, immediately after it puts a byte into the circular buffer, the same interrupt routine then checks to see if it's a complete packet and, if so, completely parse and handle it.&#xA;Alas, parsing usually takes so long that any further bytes coming in the same or any other port are lost.&#xA;We typically fix this by reducing each interrupt handler (and therefore the time interrupts are disabled while processing this handler) to the minimum possible to grab a byte and stick it in the circular buffer and return from interrupt.&#xA;All the the packet-parsing and packet-handling stuff executes with interrupts enabled.&#xA;The simplest way is for the main loop (aka the &quot;background task&quot;) to periodically&#xA;call a function that checks if there is a complete packet in the circular buffer,&#xA;and if so parse and handle it.&#xA;Other more complex approaches involve second-level interrupt handlers, &lt;a href=&quot;http://www.nongnu.org/avr-libc/user-manual/group__avr__interrupts.html&quot; rel=&quot;nofollow&quot;&gt;nested interrupts&lt;/a&gt;, etc.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, even when the interrupt handler perfectly receives every byte and correctly puts it into the buffer, sometimes a system can still lose bytes from buffer overflow:&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;bytes lost from buffer overflow&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Many people write packet handlers that don't do anything until the handler sees a complete packet in the buffer -- then the handler processes the entire packet as a whole.&#xA;That approach overflows the buffer and data is lost if any incoming packet is larger than you are expecting, too big to fit in the buffer -- &lt;strong&gt;single-packet overflow&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Even if your buffer is plenty big enough to hold the largest possible packet, sometimes during the time you're processing &lt;em&gt;that&lt;/em&gt; packet, the next packet is so large that it overflows the circular queue before your packet-handler gets around to removing the first packet from the queue to make room for future packets -- &lt;strong&gt;two-packet overflow&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there some way your status debug system could detect and signal if a byte comes in and it has to be thrown away because there's no more room in the queue?&#xA;The simple solution to both these problems is to increase the size of the buffer to hold at least 2 maximum-size packets, or somehow change the thing that's sending the packets to send smaller packets -- so 2 packets will fit in the space you have now.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Sometimes incoming data fills the buffers faster than the packet handler can pull data out of the buffer. Increasing the size of the buffer only briefly delays the problem, and sending smaller packets (but more of them) will probably only make things worse.&#xA;A real-time system &lt;em&gt;must&lt;/em&gt; process incoming data at least as fast as that data can come in;&#xA;otherwise the &lt;strong&gt;processor overload&lt;/strong&gt; will only make the processor get further and further behind.&#xA;Is there some way your status debug system could detect and signal this sort of overflow?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If this overflow only happens rarely, perhaps the simplest &quot;solution&quot; (arguably merely a hack) is to handle it in more-or-less the same way you would handle a (hopefully rare) power glitch or loss-of-signal on a radio connection: when an overflow is detected, have the AVR erase the entire buffer and pretend it never received those bytes. Most modern protocols are carefully designed such that, if any packet is lost, the system will eventually re-sync and correctly handle future packets.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To really fix this problem requires somehow making the &quot;time to process a packet&quot; less than &quot;time from the end of one packet to the end of the next packet&quot;.&#xA;so you must either&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;reduce the bit rate.&lt;/li&gt;&#xA;&lt;li&gt;modify the sender to give the AVR more time to process a packet -- perhaps unconditionally send 50 additional &quot;dummy bytes&quot; in the packet preamble -- or however many is needed to give the AVR more than enough time to completely process the last packet and get ready for the next packet.&lt;/li&gt;&#xA;&lt;li&gt;decrease the time to process a packet&lt;/li&gt;&#xA;&lt;li&gt;or some combination.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The wall-clock time to process a packet involves both the time the AVR spends in actually processing the packet,&#xA;and also the time the AVR spends doing &quot;other stuff&quot; such as dealing with all the &lt;em&gt;other&lt;/em&gt; I/O ports and interrupt handlers.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some methods of decreasing the time to actually process a packet are:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Sometimes it's faster to copy the packet out of the queue into some other buffer for further processing, removing it from the circular queue. It makes the packet-handler simpler if the packet starts at the beginning of that other buffer, so key parts of the packet are a fixed constant offset from the beginning of that buffer. (This has the advantage of making it impossible for the serial interrupt handler, which only writes into the circular queue, to accidentally corrupt that packet after it's been copied to that other buffer.)(This approach lets you use tested and &quot;optimized&quot; and known-good functions that handle numbers represented as ASCII strings of hex digits or decimal digits in consecutive order, which may run faster operating on that linear buffer than &quot;equivalent&quot; functions that also have to deal with the wrap-around split of a circular buffer). This requires both the queue and the other buffer to each be at least the size of the maximum possible packet.&lt;/li&gt;&#xA;&lt;li&gt;Sometimes it's faster to leave the packet in the queue while parsing it and remove it from the queue only after the packet handler is completely done with it.&lt;/li&gt;&#xA;&lt;li&gt;Sometimes a pair of &quot;ping-pong&quot; buffers is faster than a circular queue.&lt;/li&gt;&#xA;&lt;li&gt;Many systems use only a single buffer large enough for the largest possible valid packet, and completely disable interrupts from that port until the interrupt handler has finished with the last packet and is ready for the next packet.&lt;/li&gt;&#xA;&lt;li&gt;somehow actually do less work per packet.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;More general approaches to dealing with situations where &quot;other stuff&quot; is eating so much time that there's not enough time to deal with the packet in the buffer (and may also help reduce the time to actually process the packet):&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;if you're lucky, you can find some algorithmic tweaks to effectively do the same work in fewer cycles.&lt;/li&gt;&#xA;&lt;li&gt;load-shedding: do less important stuff less often; or perhaps don't do them at all in times of heavy load. (As implemented in the &lt;a href=&quot;http://en.wikipedia.org/wiki/Apollo_Guidance_Computer#PGNCS_trouble&quot; rel=&quot;nofollow&quot;&gt;Apollo 11 AGC&lt;/a&gt; ).&lt;/li&gt;&#xA;&lt;li&gt;yield() more often: if your main loop does fair round-robin cycling between &quot;if we have a complete packet from port 1, handle it&quot; and &quot;if we have a complete packet from port 2, handle it&quot;, and the packet parser for either one takes so long that the buffer for the &lt;em&gt;other&lt;/em&gt; port overflows, it may help to break the packet parser up into shorter pieces and do only a little processing each time through the main loop, giving the &lt;em&gt;other&lt;/em&gt; packet parser a chance to deal with packets before its buffer overflows. Perhaps even consider switching to a pre-emptive task scheduler or a full-up RTOS.&lt;/li&gt;&#xA;&lt;li&gt;yield() less often: sometimes a processor spends more time in &quot;task switching&quot; or &quot;multitasking overhead&quot; than actually doing anything productive.&lt;/li&gt;&#xA;&lt;li&gt;Reduce the time spent processing interrupt handlers. (&lt;a href=&quot;http://www.cs.utah.edu/~regehr/papers/lctes05/regehr-lctes05.pdf&quot; rel=&quot;nofollow&quot;&gt;Preventing Interrupt Overload&lt;/a&gt; ). High-frequency pulses on one interrupt line can pause main loop tasks indefinitely. It may be necessary to program each low-priority interrupt handler to recognize high-load situations and completely disable its own particular interrupt before re-enabling global interrupts at its return-from-interrupt instruction, and have the main loop recognize low-load situations and re-enable those interrupts.&lt;/li&gt;&#xA;&lt;li&gt;increase the clock rate of the processor.&lt;/li&gt;&#xA;&lt;li&gt;switch to a more powerful processor. A &quot;more powerful&quot; processor is &lt;em&gt;not&lt;/em&gt; the same as &quot;a processor with a faster clock rate&quot;. You might be able to find a processor that does the same work in &lt;em&gt;fewer&lt;/em&gt; cycles than your particular 8-bit AVR -- perhaps some other AVR with specialized peripherals that do work in hardware that you're currently doing in software, freeing up software cycles for other things; or perhaps a 32-bit processor that can do certain tasks in software in fewer cycles than any 8-bit processor.&lt;/li&gt;&#xA;&lt;li&gt;Occasionally in robotics &quot;one big fast processor&quot; is better than lots of little processors: the amount of code and the communication latency to copy a message from one task to another task on the same processor is always much less than to copy that same message from one task to another task on some other processor.&lt;/li&gt;&#xA;&lt;li&gt;Often in robotics it makes things simpler and more &quot;provably correct&quot; to add more processors, perhaps one processor per leg or even &lt;a href=&quot;http://openservo.com&quot; rel=&quot;nofollow&quot;&gt;one processor per servo&lt;/a&gt;. If you have one task per processor, then many of the above potential problems can't ever happen.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="187" LastActivityDate="2012-10-29T18:10:04.630" CommentCount="2" />
  <row Id="225" PostTypeId="2" ParentId="210" CreationDate="2012-10-29T18:42:50.343" Score="7" Body="&lt;p&gt;A co-worker and I once implemented a &lt;a href=&quot;https://en.wikipedia.org/wiki/Simplex_algorithm&quot;&gt;simplex algorithm&lt;/a&gt; for on-the-fly tuning of the PID parameters of a current control loop for a motor. Essentially the algorithm would modify one parameter at a time and then collect data on some feedback parameter that was our measure of goodness. Ours was percent deviation from a current target setpoint. Based on whether the feedback parameter got better or worse, the next parameter was modified accordingly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Or, in Wikipedia speak:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Let a linear program be given by a canonical tableau. The simplex&#xA;  algorithm proceeds by performing successive pivot operations which&#xA;  each give an improved basic feasible solution; the choice of pivot&#xA;  element at each step is largely determined by the requirement that&#xA;  this pivot does improve the solution.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Technically we used the &lt;a href=&quot;https://en.wikipedia.org/wiki/Nelder%E2%80%93Mead_method&quot;&gt;Nelder-Mead method&lt;/a&gt; which is a type of simplex. It could also be described as a &lt;a href=&quot;https://en.wikipedia.org/wiki/Hill_climbing&quot;&gt;hill climbing algorithm&lt;/a&gt; as well if you watch how it modifies it's input parameters as it searches for an optimum output parameter.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/FdWKc.gif&quot; alt=&quot;Nelder-Mead animation&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Nedler-Mead worked best in our case because it can chase a setpoint. This was important because our current target setpoint changed as torque demand increased.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;the Nelder–Mead technique is a heuristic search method that can&#xA;  converge to non-stationary points&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="142" LastActivityDate="2012-10-29T18:42:50.343" />
  <row Id="226" PostTypeId="2" ParentId="184" CreationDate="2012-10-29T19:36:27.907" Score="6" Body="&lt;p&gt;In my opinion, the question &quot;How long before we have [X] type of robots?&quot; is flawed. It assumes some kind of linear progress towards a goal that we already know, but scientific progress doesn't work that way. One cannot honestly say &quot;if we had 100x of today's computing power, we could achieve human-level AI&quot; (although it sounds like something Ray Kurzweil &lt;em&gt;might&lt;/em&gt; say). Also, we cannot predict today what robots 50 years from now will look like.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you had asked anybody in the sixties about the future of computers, they wouldn't have predicted that all of us carry around a super computer in our pockets which we use to publicly answer a question asked by somebody on the other side of the planet.&lt;/p&gt;&#xA;" OwnerUserId="132" LastActivityDate="2012-10-29T19:36:27.907" CommentCount="3" />
  <row Id="227" PostTypeId="2" ParentId="222" CreationDate="2012-10-29T19:43:25.863" Score="2" Body="&lt;p&gt;Have a look at the &lt;a href=&quot;http://scholar.google.de/scholar?q=monocular+vision+obstacle+avoidance&quot; rel=&quot;nofollow&quot;&gt;literature&lt;/a&gt; that is available on this subject. &#xA;In principle you can go two different ways: behavior based or sense/plan/act.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;for the behavior based approach there are a lot of ways you could achieve your goal, and it also depends on your environment. One very simple and elegant solution that I saw (don't have reference at hand) was to assume pixels that are just in front of you to be ground, and extend the pattern through some sort of flooding algorithm. The projection of this onto the ground plane is traversable. Optical flow could be another possible solution, which takes a little more processing power, but might be more robust on textured environments. Have a look at the literature around, I am sure there a plenty more ways.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;more complicated, but more robust would be some sort of structure from motion to get a model of your environment. This is not so trivial with a monocular camera, but possible. You could then generate a traversability map and perform path planning (some sort of A* or D*) and then path following on it. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="127" LastActivityDate="2012-10-29T19:43:25.863" />
  <row Id="228" PostTypeId="2" ParentId="222" CreationDate="2012-10-30T05:56:26.977" Score="1" Body="&lt;p&gt;You could have a look at visual servoing techniques with occlusion. Namely: try to reach &quot;waypoints&quot; on the floor or walls (e.g. doors, ...) using &lt;a href=&quot;http://en.wikipedia.org/wiki/visual_servoing&quot; rel=&quot;nofollow&quot;&gt;visual servoing&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="56" LastEditorUserId="187" LastEditDate="2012-11-08T04:26:43.200" LastActivityDate="2012-11-08T04:26:43.200" CommentCount="1" />
  <row Id="229" PostTypeId="1" AcceptedAnswerId="247" CreationDate="2012-10-30T12:59:16.537" Score="6" ViewCount="112" Body="&lt;p&gt;In ROS, I cannot get [ERROR] logs to print in red when I use python. How can I make them appear in red instead of black?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, the following Python:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;rospy.logerr(&quot;No analog input received.&quot;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;produces this output in &lt;strong&gt;black&lt;/strong&gt;:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;[ERROR] [WallTime: 135601422.876123] No analog input received.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;whereas the following C++:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;ROS_ERROR(&quot;No analog input received.&quot;);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;produces the following output in &lt;strong&gt;red&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;[ERROR] [135601551.192412]: No analog input received.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="40" LastActivityDate="2013-02-20T10:03:24.740" Title="Red [ERROR] output in python in ROS" Tags="&lt;ros&gt;&lt;python&gt;" AnswerCount="2" />
  <row Id="230" PostTypeId="1" AcceptedAnswerId="232" CreationDate="2012-10-30T14:09:21.773" Score="13" ViewCount="1480" Body="&lt;p&gt;Can &lt;a href=&quot;http://www.ros.org/wiki/&quot;&gt;ROS&lt;/a&gt; run on a Raspberry Pi?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;ROS is resigned to run on a network of machines, with different machines, even different cores on the same machine doing different jobs. Can one of those machines be a Raspberry Pi?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am considering using an R-Pi as the &lt;a href=&quot;http://en.wikipedia.org/wiki/EtherCAT&quot;&gt;EtherCAT&lt;/a&gt; master on a mobile robot, communicating with the main PC over WiFi, using a dongle.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Can an R-Pi even run ROS at all?&lt;/li&gt;&#xA;&lt;li&gt;Would an R-Pi have enough processing power to do some 1kHz servoing?&lt;/li&gt;&#xA;&lt;li&gt;Would it be possible to run some servoing on the host through the WiFi connecion?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="40" LastEditorUserId="272" LastEditDate="2012-11-11T21:30:50.410" LastActivityDate="2013-04-11T12:38:43.890" Title="Can ROS run on a Raspberry Pi?" Tags="&lt;ros&gt;&lt;raspberry-pi&gt;&lt;wifi&gt;" AnswerCount="6" FavoriteCount="3" />
  <row Id="231" PostTypeId="1" CreationDate="2012-10-30T15:01:28.793" Score="11" ViewCount="459" Body="&lt;p&gt;With a 600 mm (2 foot) motor-to-motor quadcopter, what frequency does my output-sense-calculate-output update loop need to stay stable?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm estimating a total takeoff weight of very roughly 2 pounds ( 0.9 kg ),&#xA;which I expect to be mostly motors and batteries.&lt;/p&gt;&#xA;" OwnerUserId="187" LastActivityDate="2012-11-01T04:03:10.037" Title="What frequency does my quadcopter output-sense-calculate-output update loop need to stay stable?" Tags="&lt;stability&gt;&lt;quadrotor&gt;" AnswerCount="2" CommentCount="1" FavoriteCount="2" />
  <row Id="232" PostTypeId="2" ParentId="230" CreationDate="2012-10-30T15:12:46.763" Score="12" Body="&lt;p&gt;The official RaspberryPi operating system is a version of Debian, but there's also an ArchLinux version on &lt;a href=&quot;http://www.raspberrypi.org/downloads&quot; rel=&quot;nofollow&quot;&gt;their website&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Despite ROS's claim of being cross-platform, they only officially support Ubuntu at the moment. However, experimental installations have been made for the following OSes, according to &lt;a href=&quot;http://www.ros.org/wiki/ROS/Installation&quot; rel=&quot;nofollow&quot;&gt;ros.org&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;OS X (Homebrew)&lt;/li&gt;&#xA;&lt;li&gt;Fedora&lt;/li&gt;&#xA;&lt;li&gt;Gentoo&lt;/li&gt;&#xA;&lt;li&gt;OpenSUSE&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Debian&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Arch Linux&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;Windows&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;While I don't have any first-hand experience (my two Pis are shamefully sitting in the corner), ros.org has a quick and dirty &lt;a href=&quot;http://www.ros.org/wiki/ROSberryPi/Setting%20up%20ROS%20on%20RaspberryPi&quot; rel=&quot;nofollow&quot;&gt;setup guide&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are similar instructions on &lt;a href=&quot;http://answers.ros.org/question/34501/how-to-setting-up-ros-on-raspberrypi/&quot; rel=&quot;nofollow&quot;&gt;answers.ros.org&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In case you run into any problems, the &lt;a href=&quot;http://www.raspberrypi.org/phpBB3/viewtopic.php?f=37&amp;amp;t=6552&quot; rel=&quot;nofollow&quot;&gt;RaspberryPi forums&lt;/a&gt; might also be of some help. And, of course, SE's got it's very own &lt;a href=&quot;http://raspberrypi.stackexchange.com/&quot;&gt;PI.SE&lt;/a&gt; (Thanks to @Jivings and @ppumkin for the reminder).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Otherwise, just google &quot;ros raspberry pi&quot; and you should find plenty more information.&lt;/p&gt;&#xA;" OwnerUserId="131" LastEditorUserId="131" LastEditDate="2012-11-12T16:33:30.737" LastActivityDate="2012-11-12T16:33:30.737" CommentCount="5" />
  <row Id="233" PostTypeId="5" CreationDate="2012-10-30T15:28:25.577" Score="0" ViewCount="2" Body="&lt;p&gt;The Kinect is a combined camera and infrared depth sensor mounted on a motorized pivot and was originally developed for the Microsoft XBox 360. Because of its comparatively low cost (vs a laser range finder) and high accuracy (vs sonar or infrared sensors), it was quickly hacked and garnered widespread adaptation in the robotics community, which prompted Microsoft to release drivers and libraries for the Kinect from its Windows 7 platform onwards. Unofficial open-source libraries and drivers are also available for Linux-based operating systems, with Ubuntu 12.04 supporting the Kinect out-of-the-box.&lt;/p&gt;&#xA;" OwnerUserId="131" LastEditorUserId="131" LastEditDate="2012-10-30T15:45:50.047" LastActivityDate="2012-10-30T15:45:50.047" />
  <row Id="234" PostTypeId="4" CreationDate="2012-10-30T15:28:25.577" Score="0" Body="The Kinect is a combined camera and infrared depth sensor mounted on a motorized pivot and was originally developed for the Microsoft XBox 360. " OwnerUserId="131" LastEditorUserId="131" LastEditDate="2012-10-30T15:45:46.363" LastActivityDate="2012-10-30T15:45:46.363" />
  <row Id="235" PostTypeId="1" CreationDate="2012-10-30T15:29:36.713" Score="13" ViewCount="253" Body="&lt;p&gt;I've seen 3 approaches to mounting batteries on a multicopter:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;All the batteries rigidly mounted near the center of the airframe&lt;/li&gt;&#xA;&lt;li&gt;All the batteries in a bag hanging under the center of the airframe&lt;/li&gt;&#xA;&lt;li&gt;Each rotor has its share of the batteries rigidly mounted near/under it. (For example, a quadcopter with 1/4 of all the batteries mounted underneath each motor).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Which design is the best, and why?&#xA;If there is no one best design, what are the advantages/tradeoffs between the designs?&#xA;Is there some other design I'm overlooking that is better in some way?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(This question focuses on multirotor flying machines.&#xA;For ground vehicles, see &quot; &lt;a href=&quot;http://robotics.stackexchange.com/questions/119/is-it-better-to-have-weight-distributed-over-the-wheels-or-the-center-of-the-rob&quot;&gt;Is it better to have weight distributed over the wheels or the center of the robot?&lt;/a&gt; &quot;).&lt;/p&gt;&#xA;" OwnerUserId="187" LastActivityDate="2013-07-22T14:55:05.883" Title="Is it better to have batteries distributed at the rotors or the center of the multicopter?" Tags="&lt;design&gt;&lt;stability&gt;&lt;quadrotor&gt;" AnswerCount="4" FavoriteCount="1" />
  <row Id="236" PostTypeId="2" ParentId="230" CreationDate="2012-10-30T17:29:54.867" Score="5" Body="&lt;p&gt;This question was &lt;a href=&quot;http://robotics.stackexchange.com/a/232/37&quot;&gt;well-answered by ThomasH&lt;/a&gt;, but in addition I just want to suggest the possibility of &lt;em&gt;wireless tethering&lt;/em&gt; the quadcopter to a laptop. That is, just write a nice-and-fast wireless (wifi?, bluetooth?) communication protocol for the quadcopter, then do the heavy CPU stuff on a laptop, while transmitting the instructions and sensor queries to the R-PI. We tried many implementations, and settled on a similar setup for all our small robots. Also almost every jaw-dropping quadcopter implementation is set up in this way. It makes life easy, and allows you to use the big-hitter libraries without sacrificing speed. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Let's be honest here, that quadcopter is very likely not going to get outside wireless range of your laptop anyway.&lt;/p&gt;&#xA;" OwnerUserId="163" LastEditorUserId="37" LastEditDate="2013-04-11T12:38:43.890" LastActivityDate="2013-04-11T12:38:43.890" CommentCount="2" />
  <row Id="237" PostTypeId="1" AcceptedAnswerId="376" CreationDate="2012-10-30T17:41:41.563" Score="4" ViewCount="498" Body="&lt;p&gt;A common scenario is to have a PC that sends commands to a microcontroller via RS232.  My PC program is sending commands (each of which are composed of multiple bytes) as fast as it can to a small robot.  The microcontroller on the robot is a Parallax Propellor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have noticed that if I don't process bytes quickly enough on the microcontroller side of things, it can very quickly overflow the default buffers in the popular serial port drivers that are available for the Propellor. (The buffers are generally anywhere from 16 to 256 bytes).  I can arbitrarily increase these buffers or create my own larger circular buffer, but I would like to have a more methodical approach to determining appropriate size requirements and/or the minimal amount of time I can wait before pulling bytes out of the serial port driver buffer.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;At 1st glance:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;115200 == 115.2 bits per millisecond == ~12.8 bytes per millisecond (assuming 1 stop bit)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;1) Is that a valid way to calculate timing for serial transmissions?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, given my specific setup:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;PC Program &amp;lt;--&gt; Bluetooth Serial Profile Driver &amp;lt;--&gt; Bluetooth Transceiver &amp;lt;-&lt;em&gt;*&lt;/em&gt;-&gt; BlueSMIRF Wireless Modem &amp;lt;--&gt; Parallax Propellor Program&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;2) What is the maximum amount of data I can send for a given period of time consistently without eventually running in to problems?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Maybe I'm over complicating things, but it seems like there are potentially multiple buffers involved in the transmission chain above.  How do others commonly deal with this? Do they throttle the PC sending to a known safe rate? Implement flow control?  If implementing flow control, how does that affect bandwidth and response times?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(If it matters, my experiment is to use a joystick on the PC to control multiple servos with instant reaction to the joystick movements. So every small movement of the joystick results in multiple commands being sent to the microcontroller. The commands are not just simple positional commands though, they also involve acceleration/deacceleration of servos over time and this is the reason that the microcontroller spends a significant amount of clock cycles before processing new bytes.)&lt;/p&gt;&#xA;" OwnerUserId="167" LastActivityDate="2012-11-21T17:41:00.177" Title="How to calculate serial speed and buffer requirements for PC to microcontroller communications?" Tags="&lt;microcontroller&gt;&lt;serial&gt;&lt;rs232&gt;" AnswerCount="5" />
  <row Id="238" PostTypeId="2" ParentId="237" CreationDate="2012-10-30T22:05:47.807" Score="2" Body="&lt;p&gt;There is no right answer to this, and I'm sure you already know (or can guess) all you need to solve this problem. However&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The first obvious thing to say is that downstream devices must be capable of dealing with the flow of data, both in the long term and in the short term. In the short term, devices use buffering to cope with the flow. In the long term, the need processing power to act on the data.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One problem you have is that you don't control all of the steps in your chain, so if one of them is causing delays, there might not be much you can do about it, short of replacing it. Hoever, I'd have thought that the Bluetooth serial driver would have a nice big buffer, and would play nice with the transceiver and BlueSMIRF, so it's probably safe to ignore them. I guess the real problem is between the Propeller and the PC.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What seems to be happening in your case is that the interaction between the data producer and the consumer is producing unpredictable queue lengths, and you would like to apply some proper theory to that.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Interestingly, studies have been done on exactly this problem with regards to queuing at restaurants, E.G. &lt;a href=&quot;http://www.ipedr.com/vol6/11-A00030.pdf&quot; rel=&quot;nofollow&quot;&gt;Case Study for Restaurant Queuing Model&lt;/a&gt; and &lt;a href=&quot;http://faculty.chicagobooth.edu/laurens.debo/Research/Papers/Debo-Veeraraghavan-Sputtering-Equilibria-July-2012.pdf&quot; rel=&quot;nofollow&quot;&gt;Equilibrium in Queues under Unknown Service Times and Service Value&lt;/a&gt;. But there are easier to understand resources online, like &lt;a href=&quot;http://www.win.tue.nl/~iadan/queueing.pdf&quot; rel=&quot;nofollow&quot;&gt;Queueing Theory&lt;/a&gt; &lt;a href=&quot;http://www.embedded.com/design/connectivity/4023310/Queueing-Theory-for-Dummies&quot; rel=&quot;nofollow&quot;&gt;Queueing Theory for Dummies&lt;/a&gt;. But the one you really want is probably &lt;a href=&quot;http://www.embedded.com/design/other/4024545/How-to-size-message-queues&quot; rel=&quot;nofollow&quot;&gt;&lt;strong&gt;How to size message queues&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You have a few options:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Just make sure that the PC sends data at an orderly rate. Decide exactly what rate you really need, and don't go above that.&lt;/li&gt;&#xA;&lt;li&gt;Use a &lt;a href=&quot;http://en.wikipedia.org/wiki/Real-time_operating_system&quot; rel=&quot;nofollow&quot;&gt;Realtime Operating System&lt;/a&gt; on the MCU to make sure that the bytes are being dealt with in a timely manner.&lt;/li&gt;&#xA;&lt;li&gt;Implement flow control.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;But here's my preferred solution. &lt;a href=&quot;http://en.wikipedia.org/wiki/IEEE_1355&quot; rel=&quot;nofollow&quot;&gt;&lt;strong&gt;Spacewire&lt;/strong&gt;&lt;/a&gt;! Or at least use the flow control system from it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Essentially the downstream device sends bytes to the upstream device stating the number of empty places in its FIFO. This way the data producer only sends what the consumer can cope with.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you're interested, you can read the full Spacewire standard: &lt;a href=&quot;http://ams.cern.ch/AMS/Electronics/Docs/1355-1995.pdf&quot; rel=&quot;nofollow&quot;&gt;IEEE 1355&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-10-30T22:05:47.807" />
  <row Id="239" PostTypeId="2" ParentId="235" CreationDate="2012-10-30T23:51:23.823" Score="5" Body="&lt;p&gt;Center, you want the moment of inertia to be as small as possible.&lt;/p&gt;&#xA;" OwnerUserId="65" LastActivityDate="2012-10-30T23:51:23.823" CommentCount="1" />
  <row Id="240" PostTypeId="2" ParentId="231" CreationDate="2012-10-30T23:54:30.983" Score="1" Body="&lt;p&gt;50-200Hz is pretty normal as we can see in the open source projects.  You have to consider that in most cases the inertia of the motors and communication with the ESCs is the limiting factor.&lt;/p&gt;&#xA;" OwnerUserId="65" LastEditorUserId="158" LastEditDate="2012-10-31T16:04:47.520" LastActivityDate="2012-10-31T16:04:47.520" CommentCount="2" />
  <row Id="241" PostTypeId="2" ParentId="230" CreationDate="2012-10-31T03:45:50.937" Score="3" Body="&lt;p&gt;I would check out the &lt;a href=&quot;http://www.ros.org/wiki/rosserial&quot; rel=&quot;nofollow&quot;&gt;rosserial&lt;/a&gt; project. Basically, it generates some code for Arduino for communicating over serial to a ROS node on the computer. I bet you can convert it to the Raspberry Pi, so that you can use some other protocol to communicate between the Pi and the host computer. &lt;/p&gt;&#xA;" OwnerUserId="42" LastActivityDate="2012-10-31T03:45:50.937" />
  <row Id="242" PostTypeId="5" CreationDate="2012-10-31T06:39:35.803" Score="0" ViewCount="5" Body="&lt;p&gt;Mindstorms is a popular robotics line launched by LEGO. The kits include software and hardware to create small, customizable, and programmable robots. Each kit includes a programmable 'Brick' computer that controls the system, a set of modular sensors and motors, and LEGO parts from the Technics line to create the mechanical systems.&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;External links&lt;/h3&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://mindstorms.lego.com&quot; rel=&quot;nofollow&quot;&gt;Official Website&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://wikipedia.org/wiki/Lego_Mindstorms&quot; rel=&quot;nofollow&quot;&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="38" LastEditorUserId="38" LastEditDate="2012-10-31T16:04:51.127" LastActivityDate="2012-10-31T16:04:51.127" />
  <row Id="243" PostTypeId="4" CreationDate="2012-10-31T06:39:35.803" Score="0" Body="Mindstorms is a popular robotics line launched by LEGO. The kits include software and hardware to create small, customizable, and programmable robots. Each kit includes a programmable 'Brick' computer that controls the system, a set of modular sensors and motors, and LEGO parts from the Technics line to create the mechanical systems." OwnerUserId="38" LastEditorUserId="38" LastEditDate="2012-10-31T16:04:38.100" LastActivityDate="2012-10-31T16:04:38.100" />
  <row Id="244" PostTypeId="5" CreationDate="2012-10-31T06:47:40.060" Score="0" ViewCount="2" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2012-10-31T06:47:40.060" LastActivityDate="2012-10-31T06:47:40.060" />
  <row Id="245" PostTypeId="4" CreationDate="2012-10-31T06:47:40.060" Score="0" Body="NXT is the latest installation in the [Mindstorms](http://robotics.stackexchange.com/tags/mindstorms) line launched by LEGO. The NXT includes many improvements over the old RXC line, including a smarter 'NXT Brick', powerful sensors, and an easy-to-use graphical programming language." OwnerUserId="38" LastEditorUserId="38" LastEditDate="2012-10-31T16:04:43.590" LastActivityDate="2012-10-31T16:04:43.590" />
  <row Id="246" PostTypeId="2" ParentId="231" CreationDate="2012-10-31T08:02:57.093" Score="8" Body="&lt;p&gt;As Rocketmagnet suggests, what frequency you &quot;need&quot; will depend on a lot of things. The more responsive your rotors are, the more sensitive your craft will be to random spikes in motor commands. These random spikes may be caused by noisy sensor readings caused by physical imperfections, which means you would need to lower your controller gains, which in turn might mean your quadrotor may become more unstable. Some other factors include the rotational inertias of the quadrotor, the propellers' blade pitch, the location of the center of mass, and the motor-to-motor distance.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I programmed a flight controller from scratch for my 2 kg tricopter running on an ATmega1280 and found that at:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;50 Hz: It will stay in the air but is nigh impossible to control.&lt;/li&gt;&#xA;&lt;li&gt;100 Hz: It will at least avoid immediately tipping to one side.&lt;/li&gt;&#xA;&lt;li&gt;200 Hz: I can let it loose indoors at hover throttle and it will stay more or less in one spot.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;It may be of interest to note that the higher the control frequency, the more effective your rotor inertias become at being physical dampers, which helps nullify IMU noise and improve flight stability.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But if I &lt;em&gt;had&lt;/em&gt; to give a hard number for a minimum flight controller update frequency for a quadrotor of that size suitable for indoor navigation, based on personal experience...&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'd say 80 Hz.&lt;/p&gt;&#xA;" OwnerUserId="148" LastEditorUserId="148" LastEditDate="2012-11-01T04:03:10.037" LastActivityDate="2012-11-01T04:03:10.037" />
  <row Id="247" PostTypeId="2" ParentId="229" CreationDate="2012-10-31T12:04:09.617" Score="6" Body="&lt;p&gt;Please see this bug ticket: &lt;a href=&quot;https://code.ros.org/trac/ros/ticket/3691&quot;&gt;https://code.ros.org/trac/ros/ticket/3691&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I filed this bug report (with patch to fix) 13 months ago and am pretty disappointed in the ROS team that they have not put this in trunk.&lt;/p&gt;&#xA;" OwnerUserId="110" LastActivityDate="2012-10-31T12:04:09.617" CommentCount="1" />
  <row Id="248" PostTypeId="2" ParentId="154" CreationDate="2012-10-31T14:59:03.000" Score="6" Body="&lt;p&gt;It would be nice if we could tell the compiler the range and precision of each fixed-point input variable (perhaps no two having the radix point in the same location), and it would automagically -- at compile time -- use the correct range and precision and rescaling operations for the intermediate values and final values in a series of calculations.&#xA;I've heard rumors that it may be possible to do that in &lt;a href=&quot;http://en.wikibooks.org/wiki/Ada_Programming/Types/delta&quot; rel=&quot;nofollow&quot;&gt;the Ada programming language&lt;/a&gt; or in C++ templates.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Alas, the closest I've seen is fixed-point arithmetic libraries that require you, the programmer, to manually choose the correct representation and manually verify that each operation maintains adequate range and precision.&#xA;Sometimes they make multiplication and division between mixed variables easier.&#xA;Such as:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://sourceforge.net/projects/avrfix/&quot; rel=&quot;nofollow&quot;&gt;AVRfix&lt;/a&gt;: a library for fixed point calculation in s15.16, s7.24 and s7.8 format, entirely written in ANSI C&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://en.wikibooks.org/wiki/Embedded_Systems/Floating_Point_Unit&quot; rel=&quot;nofollow&quot;&gt;Embedded Systems: fixed point FFT&lt;/a&gt; lists some libraries for fixed-point FFT calculation&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.microchip.com/stellent/idcplg?IdcService=SS_GET_PAGE&amp;amp;nodeId=1824&amp;amp;appnote=en010962&quot; rel=&quot;nofollow&quot;&gt;AN617: fixed point routines for the Microchip PICmicro&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://sourceforge.net/directory/?q=%22fixed%20point%22&quot; rel=&quot;nofollow&quot;&gt;&quot;fixed point&quot;&lt;/a&gt; projects on SourceForge.&lt;/li&gt;&#xA;&lt;li&gt;gcc has built-in fixed-point libraries &lt;a href=&quot;http://gcc.gnu.org/onlinedocs/gcc/Fixed_002dPoint.html&quot; rel=&quot;nofollow&quot;&gt;a&lt;/a&gt; &lt;a href=&quot;http://gcc.gnu.org/wiki/FixedPointArithmetic&quot; rel=&quot;nofollow&quot;&gt;b&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.ti.com/tool/SPRC087&quot; rel=&quot;nofollow&quot;&gt;TI IQMath Library&lt;/a&gt; ( and &lt;a href=&quot;http://www.ti.com/tool/sprc542&quot; rel=&quot;nofollow&quot;&gt;source&lt;/a&gt; -- Thank you, &lt;a href=&quot;http://robotics.stackexchange.com/a/163/37&quot;&gt;embedded.kyle&lt;/a&gt; ).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="187" LastEditorUserId="187" LastEditDate="2013-04-14T18:11:12.667" LastActivityDate="2013-04-14T18:11:12.667" CommentCount="3" />
  <row Id="249" PostTypeId="1" CreationDate="2012-10-31T22:24:11.043" Score="10" ViewCount="333" Body="&lt;p&gt;I would really like a six-axis force sensor for my robot, but I just can't afford one. I was thinking about making one of my own.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have experience using strain gauges, but I can't work out how to arrange them so as to create a six-axis force-torque sensor.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Is this something I could feasibly make myself?&lt;/li&gt;&#xA;&lt;li&gt;How do they work / what is the theory behind them?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;I'm curious to know how they work, even if it's not feasible to make one myself.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Added:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Just to be clear, I'm talking about &lt;em&gt;force / torque&lt;/em&gt; sensors, like this &lt;a href=&quot;http://www.ati-ia.com/products/ft/ft_models.aspx?id=Nano17&quot;&gt;ATI Nano 17&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/QwUvX.jpg&quot; alt=&quot;ATI Nano&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am not talking about accelerometers or gyros, or MEMS IMUs.&lt;/p&gt;&#xA;" OwnerUserId="40" LastEditorUserId="40" LastEditDate="2012-11-01T08:18:10.253" LastActivityDate="2012-11-01T17:51:26.820" Title="How does a six-axis force sensor work?" Tags="&lt;sensors&gt;&lt;force-sensor&gt;" AnswerCount="1" CommentCount="1" FavoriteCount="2" />
  <row Id="250" PostTypeId="2" ParentId="118" CreationDate="2012-11-01T02:55:59.297" Score="2" Body="&lt;p&gt;The reason why you can't see the nxtOSEK logo, is that the enhanced firmware looks the same as the regular firmware, but with several performance and feature enhancements. It isn't specific to nxtOSEK.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To check if the firmware installed properly, visit the &lt;strong&gt;Settings&lt;/strong&gt; menu on the NXT, and then the &lt;strong&gt;NXT Version&lt;/strong&gt; submenu. The top line should read: &lt;code&gt;FW NBC/NXC x.xx&lt;/code&gt;, where &lt;code&gt;x.xx&lt;/code&gt; is the version number of the firmware.&lt;/p&gt;&#xA;" OwnerUserId="38" LastEditorUserId="38" LastEditDate="2012-11-01T04:08:45.253" LastActivityDate="2012-11-01T04:08:45.253" CommentCount="3" />
  <row Id="251" PostTypeId="2" ParentId="235" CreationDate="2012-11-01T05:11:29.567" Score="11" Body="&lt;p&gt;You almost definitely want to have the battery rigidly mounted to the center of the airframe.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Mounting a battery underneath each motor (though I have never seen this) will increase the multicopter's moments of inertia, which will make it more &quot;stable&quot; in that it will more sluggishly lose its balance and thus give a controller more time to react. This, however, is a rather bruteforce way to go about flight stabilization.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Hanging the battery from a bag will make the flight characteristics needlessly complicated. Imagine that the &quot;bag&quot; is instead a rope with a weight attached to the end. What happens to the flight characteristics as the length of the rope increases?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Depending on the particular chassis design, mounting the battery rigidly can also dampen the motor vibrations, which reduces the need for heavy filtering of inertial measurements.&lt;/p&gt;&#xA;" OwnerUserId="148" LastActivityDate="2012-11-01T05:11:29.567" />
  <row Id="252" PostTypeId="2" ParentId="100" CreationDate="2012-11-01T15:01:02.197" Score="2" Body="&lt;p&gt;As you pointed out, on a robot with high vibration,&#xA;you want connectors that have &quot;spring&quot; (elasticity).&#xA;Even when momentarily jostled slightly out of position,&#xA;the spring pushes everything back into place.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Alas, there is a tradeoff -- the higher the vibration that a connector can tolerate without getting accidentally disconnected, the more difficult it is to deliberately connect and disconnect the connector.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some connectors you might look at:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.stefanv.com/rcstuff/qf200001.html&quot; rel=&quot;nofollow&quot;&gt;Stefan Vorkoetter&lt;/a&gt; has a nice review of connectors suitable for mid-size RC aircraft (easily handling 20 A), including &lt;a href=&quot;http://en.wikipedia.org/wiki/DC_connector#Anderson_Powerpole_connectors&quot; rel=&quot;nofollow&quot;&gt;Anderson Powerpole connectors&lt;/a&gt; which are the standard 12VDC connector in ham radio.&lt;/li&gt;&#xA;&lt;li&gt;cage clamp terminal strips (also known as spring clamp terminal strips)&lt;/li&gt;&#xA;&lt;li&gt;some kinds of twist-lock bi-pin connector and bayonet connectors&lt;/li&gt;&#xA;&lt;li&gt;some kinds of 8P8C &quot;RJ45&quot; &quot;Ethernet&quot; connectors. &lt;a href=&quot;http://reprap.org/wiki/list_of_electronics&quot; rel=&quot;nofollow&quot;&gt;Many RepRaps&lt;/a&gt; use these connectors to carry power over CAT5 cable to the stepper motors, in a way completely incompatible with any power-over-Ethernet standard or any Ethernet data standard.&lt;/li&gt;&#xA;&lt;li&gt;a few barrel connectors have a retaining groove that lets it snap into place&lt;/li&gt;&#xA;&lt;li&gt;The kind of IDC ribbon cable connector that has a &quot;latch&quot;&lt;/li&gt;&#xA;&lt;li&gt;USB connectors are becoming the standard 5VDC connector&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;(Too many connectors allow parts to gradually slip further and further out of place, until the connection falls apart. This includes most screw connectors, barrel connectors, etc.).&lt;/p&gt;&#xA;" OwnerUserId="187" LastActivityDate="2012-11-01T15:01:02.197" />
  <row Id="253" PostTypeId="2" ParentId="249" CreationDate="2012-11-01T16:54:58.570" Score="7" Body="&lt;p&gt;I don't think its entirely impossible to build something like this, especially if you already have some experience with strain gauges. I think the most common way is to arrange the sensor in a &lt;a href=&quot;http://en.wikipedia.org/wiki/Stewart_platform&quot;&gt;Stewart Configuration&lt;/a&gt;. There are a lot of articles on this, e.g. &quot;Closed-form force sensing of a 6-axis force transducer based on the Stewart platform&quot;. &lt;/p&gt;&#xA;" OwnerUserId="127" LastEditorUserId="40" LastEditDate="2012-11-01T17:51:26.820" LastActivityDate="2012-11-01T17:51:26.820" CommentCount="2" />
  <row Id="254" PostTypeId="1" AcceptedAnswerId="260" CreationDate="2012-11-01T21:00:11.233" Score="10" ViewCount="247" Body="&lt;p&gt;I have a robot that uses brushed motors in its servo system. These are Maxon 3W motors, with 131:1 planetary gearboxes. The motors are controlled by a PIC microcontroller, running a 1kHz PID controller. The servos are for a low speed high torque application. There is significant backlash between the sensor and the motor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Maxon offer 12W brushless motors which are the same size. These are better in many ways: double the torque, better heat dissipation, higher efficiency.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The problem, obviously, is that they require more complex drive electronics. Also, I have heard a couple of people mention that brushed motors are better for servo applications, though they never explained why.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Has anyone else implemented this kind of system?&lt;/li&gt;&#xA;&lt;li&gt;Are there any gotchas when using brushed motors for servos?&lt;/li&gt;&#xA;&lt;li&gt;Is it possible to servo it at low speeds if I only have the 3 integral digital Hall sensors, and no encoder? (I would prefer not to add an encoder because of the money and space cost)&lt;/li&gt;&#xA;&lt;li&gt;It torque ripple likely to be a problem?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="40" LastEditorUserId="37" LastEditDate="2013-05-20T15:45:43.733" LastActivityDate="2013-05-23T14:52:32.803" Title="Should I switch my servo system from brushed to brushless motors?" Tags="&lt;brushless-motor&gt;&lt;servomotor&gt;" AnswerCount="2" FavoriteCount="2" />
  <row Id="255" PostTypeId="1" AcceptedAnswerId="257" CreationDate="2012-11-01T22:47:12.250" Score="10" ViewCount="616" Body="&lt;p&gt;I'm really new to robotics, however I am a programmer familiar with several different languages. I don't have a ton of money to spend and I was wondering what is a really good starter kit. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;My criteria is for the kit to be inexpensive and &lt;strong&gt;powerful&lt;/strong&gt;, in that its functionality is extensible -- something that would allow the builder to be creative and possibly invent new ways to use it, not just a glorified model kit.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Being extendable to smartphones is a plus.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm not looking for something easy or introductory, just something powerful, flexible, and cost effective.&lt;/p&gt;&#xA;" OwnerUserId="216" LastEditorUserId="126" LastEditDate="2012-11-14T15:02:20.127" LastActivityDate="2012-11-14T15:02:20.127" Title="What UAV kit(s) would be suitable for a beginner roboticist with programming experience?" Tags="&lt;uav&gt;&lt;kit&gt;" AnswerCount="6" CommentCount="4" FavoriteCount="1" ClosedDate="2012-11-21T06:42:04.067" />
  <row Id="256" PostTypeId="1" AcceptedAnswerId="273" CreationDate="2012-11-02T00:19:32.710" Score="12" ViewCount="807" Body="&lt;p&gt;I want to use an RF beacon to localize my quadcopter for autolanding, when GPS is not precise enough, for example, when my driveway is only 10 feet wide, and the GPS is only showing 20-30 ft. accuracy (with a proverbial lake of lava on either side). The quadcopter would use the GPS to fly to the rough location until it had a strong enough signal off the beacon, when it would begin to use that signal to come to a landing in a precise location, referenced off said beacon. Can someone please explain to me the concepts and theories behind building the beacon and it's accompanying receiver (suitable for connection to an Arduino via any digital or analog method) and achieving, say, a 4&quot; or better horizontal and vertical accuracy within a 50' sphere? Minimally, the quad should have range and altitude, i.e. &quot;I am 10 feet away from the beacon and 2 feet above it&quot;. How much added complexity would it take to make the robot fully position aware about the beacon, i.e. &quot;x ft. South, y ft. West and z ft. above it&quot;, where the coordinate system is determined by the beacon and not linked to any sort of geographic coordinate system? If the beacon is mounted on a, say, 10 ft pole, are there any changes to be made versus having it on the ground and presuming that all activity takes place above it's x-y plane?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Last note-&#xA;This thing would prefferably operate in the 72MHz band, please presume that where I'm operating, there are not other devices operating on the same band.&lt;/p&gt;&#xA;" OwnerUserId="176" LastEditorUserId="350" LastEditDate="2012-11-30T21:19:59.263" LastActivityDate="2012-11-30T21:19:59.263" Title="Quadcopter Localization Beacon" Tags="&lt;quadrotor&gt;&lt;gps&gt;" AnswerCount="3" CommentCount="5" FavoriteCount="1" />
  <row Id="257" PostTypeId="2" ParentId="255" CreationDate="2012-11-02T00:49:32.530" Score="7" Body="&lt;p&gt;I think your question is a bit too open-ended.  To get more specific recommendations, I think you'd have to provide some idea of what facet of robotics you want to get involved in.  The mechanical buildling aspect?  Motor control? Microcontroller programming? Use of various sensors?  As an example, I can ask what do you mean by &lt;em&gt;powerful&lt;/em&gt; in your question ... motor torque or onboard computing capabilities?  &lt;strong&gt;Robotics is a broad field.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If very new to robotics, I would suggest you start out by buying the latest issue of &lt;strong&gt;&lt;a href=&quot;http://www.servomagazine.com/&quot;&gt;Servo&lt;/a&gt; and/or &lt;a href=&quot;http://find.botmag.com/&quot;&gt;Robot&lt;/a&gt; magazines&lt;/strong&gt; (and then possibly subscribing).  Just glancing through these magazines will give you a lot of information regarding the current hobbiest/enthusiast robotics market, and in the magazines there are many advertisers for kits of all types.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A popular, lower cost, easy-to-learn, yet flexible, microcontroller that can be used for robotics is the &lt;a href=&quot;http://www.arduino.cc/&quot;&gt;Arduino&lt;/a&gt;.  There are prebuilt kits for integrating with smartphones. Check out the information here:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://robotics.stackexchange.com/questions/213/ways-to-integrate-a-smart-phone-with-robotics&quot;&gt;Ways to integrate a smart phone with robotics&lt;/a&gt;. &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="167" LastActivityDate="2012-11-02T00:49:32.530" CommentCount="2" />
  <row Id="258" PostTypeId="2" ParentId="213" CreationDate="2012-11-02T03:23:55.967" Score="10" Body="&lt;p&gt;Another option is the &lt;a href=&quot;https://www.sparkfun.com/products/11343&quot; rel=&quot;nofollow&quot;&gt;IOIO-OTG board&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://www.sparkfun.com/products/11343&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/Kqz3W.jpg&quot; alt=&quot;IOIO-OTG board&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The &lt;a href=&quot;https://www.sparkfun.com/products/11343&quot; rel=&quot;nofollow&quot;&gt;Sparkfun product description&lt;/a&gt; describes its functionality:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;It features a PIC microcontroller which acts like a bridge that connects an app on your PC or Android device to low-level peripherals like GPIO, PWM, ADC, I2C, SPI, and UART. An app-level library helps you write control code for these low level peripherals in the same way you'd write any other Java app!&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;This board should do everything you wish and it even has a &lt;a href=&quot;http://www.sparkfun.com/tutorials/280&quot; rel=&quot;nofollow&quot;&gt;nice tutorial&lt;/a&gt; to help you get started.&lt;/p&gt;&#xA;" OwnerUserId="1125" LastEditorUserId="37" LastEditDate="2013-12-18T00:19:12.427" LastActivityDate="2013-12-18T00:19:12.427" />
  <row Id="259" PostTypeId="2" ParentId="256" CreationDate="2012-11-02T05:35:19.683" Score="0" Body="&lt;p&gt;I would start here, I know someone who did this on a quadrotor with some 50$ gps modules and said it worked very well.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.rtklib.com/&quot; rel=&quot;nofollow&quot;&gt;http://www.rtklib.com/&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Real_Time_Kinematic&quot; rel=&quot;nofollow&quot;&gt;http://en.wikipedia.org/wiki/Real_Time_Kinematic&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="65" LastActivityDate="2012-11-02T05:35:19.683" CommentCount="2" />
  <row Id="260" PostTypeId="2" ParentId="254" CreationDate="2012-11-02T05:49:00.100" Score="6" Body="&lt;p&gt;Brushed motors are easier for servo systems, but are not better.  Many high end servo systems are brushless/AC.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It is possible to control the motors at low speeds with only 3 hall sensors.  You really don't want trapezoidal commutation, especially at low speeds so could add an encoder or estimate the rotor position if necessary.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It is possible to estimate the rotor position with only hall/current sensors but if there are a lot of external disturbances it won't work very well.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Torque ripple is unlikely to be a problem, of course it depends on your application.  More advanced commutation methods (sinusoidal or flux vector) essentially eliminate torque ripple.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You say that your application is low speed, but you are also using a 131:1 gearbox.  What RPM does the motor normally see?  Its not really a low speed application if the motor is running at 30%+ of its rated RPM.  Even hall sensors are very high resolution after going through that much reduction so you might not really need low speed performance at the motor itself.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;IMHO Given that your current system has significant backlash between the sensor and the motors, I can't imagine a brushless system doing any worse even with halls/trapezoidal commutation.&lt;/p&gt;&#xA;" OwnerUserId="65" LastEditorUserId="65" LastEditDate="2012-11-02T05:54:07.710" LastActivityDate="2012-11-02T05:54:07.710" CommentCount="1" />
  <row Id="261" PostTypeId="1" AcceptedAnswerId="281" CreationDate="2012-11-03T00:56:08.123" Score="5" ViewCount="1696" Body="&lt;p&gt;I have seen waveforms for driving a brushless motor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/UHO04.jpg&quot; alt=&quot;Brushless motor waveform&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I guess this is the waveform used for the simpler block commutation. But if I want to do sinusoidal waveforms, what does the PWM signal look like now? Is there a need to carefully synchronise the edges on the three phases?&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-11-06T21:00:00.027" Title="What do the commutation waveforms look like for a brushless motor?" Tags="&lt;brushless-motor&gt;&lt;pwm&gt;" AnswerCount="2" />
  <row Id="262" PostTypeId="1" AcceptedAnswerId="266" CreationDate="2012-11-03T06:16:39.650" Score="3" ViewCount="242" Body="&lt;p&gt;Do mobile and/or autonomous robots become more or less effective the bigger they get? For example, a bigger robot has bigger batteries, and thus bigger motors, whereas a smaller robot has the exact opposite, making it need less energy, but also have smaller motors. Is there any known theorem that models this?&lt;/p&gt;&#xA;" OwnerUserId="216" LastEditorUserId="350" LastEditDate="2012-11-30T13:59:44.310" LastActivityDate="2012-11-30T13:59:44.310" Title="Effectiveness of a Mobile Robot In Relation To Mass" Tags="&lt;mobile-robot&gt;&lt;design&gt;&lt;dynamics&gt;" AnswerCount="6" />
  <row Id="263" PostTypeId="2" ParentId="262" CreationDate="2012-11-03T07:54:58.887" Score="4" Body="&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Square-cube_law&quot; rel=&quot;nofollow&quot;&gt;http://en.wikipedia.org/wiki/Square-cube_law&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The square-cube law essentially states that larger robots are more fragile.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;&quot;You can drop a mouse down a thousand-yard mine shaft and, on arriving&#xA;  at the bottom, it gets a slight shock and walks away. A rat is killed,&#xA;  a man is broken, a horse splashes.&quot; — J.B.S. Haldane, biologist&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Note that this only applies in a very generic mechanical sense.  You can't really make rules involving robot size since robots are so diverse.  &lt;/p&gt;&#xA;" OwnerUserId="65" LastActivityDate="2012-11-03T07:54:58.887" CommentCount="1" />
  <row Id="264" PostTypeId="2" ParentId="261" CreationDate="2012-11-03T08:43:55.930" Score="9" Body="&lt;p&gt;There is a fair deal of literature on the implementation of brushless motor control but here is an overview.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To understand the differences between commutation waveforms it is important to understand how brushless motors operate.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/1qCuF.jpg&quot; alt=&quot;Brushless Motor&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A three phase (two pole) motor will have three coils around a single magnet in the center.  The goal is to energize the coils in sequence so that the shaft of the motor (and its magnet) rotates.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are two magnetic fields that are important here, the field of the rotor (rotating magnet) and the field of the stator (static coils):&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/NahC8.jpg&quot; alt=&quot;field vectors&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We refer to the direction of the magnetic field as its &quot;flux vector&quot; because it sounds super cool.  The most important thing to learn from this image is that you want the two magnetic fields to be at right angles to each other.  This maximizes efficiency and torque.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The dumbest commutation scheme is trapezoidal.  Using either hall sensors or back EMF from the motor, it is possible to determine if the motor is in one of a discrete number of positions and perform on/off control on one or two coils to lead the magnetic field around the motor:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/TyG7F.jpg&quot; alt=&quot;trapezoid&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Because there might only be six separate orientations for the stator field, the flux vector of the motor could be anywhere from 60-120 degrees (instead of the desired 90) and therefore you get torque ripple and poor efficiency.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;An obvious solution here is to switch to sinusoidal commutation and just smooth out the waveform:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/OzDz0.jpg&quot; alt=&quot;sin&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you know the exact orientation of the rotor you can just do some trig to calculate the exact PWM duty cycle to apply to each coil in order to keep the flux vector at 90 degrees and bam you have a beautiful 90 degree flux vector.  (The rotor orientation can be determined via encoder, interpolation or more advanced estimation such as a kalman filter).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So right now you might be wondering how you can do better than sinusoidal commutation.  The key flaw of sinusoidal commutation is that the outputs are sent straight to PWM.  Because of coil inductance, the current (and therefore flux vector) will lag behind the commanded values and as the motor approaches its top speed the flux vector will be at 80 or 70 degrees instead of 90.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is why sinusoidal commutation has poor high speed performance.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This finally brings us to flux-vector control which is a name given to (often proprietary) control algorithms that attempt to ensure the magnetic flux stays at 90 degrees even at high speeds.  The simplest way to do this would be to lead the field by, for example, 90-120 degrees depending on how fast you are going, knowing that the actual magnetic flux will lag.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;More robust solutions involve PID/feedforward to accurately control the current going through each phase.  Every servo manufacturer has their own in-house algorithm so I am sure there is some pretty complicated stuff at the bleeding edge.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To put it in simplest terms, flux vector control is sinusoidal control of the current going to each phase (instead of just the PWM duty cycle).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The line between sinusoidal/flux vector is pretty vague since some companies perform advanced control on their &quot;sinusoidal&quot; drives (which essentially makes them flux vector).  Also, since you can technically call almost anything flux vector control the quality of implementations can vary.&lt;/p&gt;&#xA;" OwnerUserId="65" LastEditorUserId="65" LastEditDate="2012-11-03T08:49:25.587" LastActivityDate="2012-11-03T08:49:25.587" CommentCount="3" />
  <row Id="265" PostTypeId="2" ParentId="262" CreationDate="2012-11-03T16:26:31.010" Score="4" Body="&lt;p&gt;This is a sweeping generalization that I'd be very cautious about. Engineering is about tradeoffs. But there are two things that I'd be comfortable generalizing, from my own personal biases.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm 99% serious when I say robots become more effective as the amount of money you are willing to invest becomes higher. This is because you can eventually custom-make all components and algorithms, and get the best possible solution for your job. But this significantly increases the engineering &lt;em&gt;time&lt;/em&gt; ...&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Second, I'd say increases in power storage translate directly to increasing capabilities for autonomous, mobile robots. The power is almost always the bottleneck for long-term autonomy. (notice: My lab works on long term-autonomy from a power-efficiency standpoint, so I'm biased).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;That's about all. Other than that, the size of the robot is dependent on the task it is required to do. A larger robot is awful for invasive surgery, and a smaller robot is a terrible long-range terrestrial rover: It'd get stuck on the first tree root. Consider this: What's the best size for a flying robot? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Answer: The size that allows the perfect tradeoff of fuel capacity, lift capacity, processing power, speed, stability, and all other factors, subject to the task, cost, material, policy, and time constraints imposed.&lt;/p&gt;&#xA;" OwnerUserId="163" LastActivityDate="2012-11-03T16:26:31.010" CommentCount="1" />
  <row Id="266" PostTypeId="2" ParentId="262" CreationDate="2012-11-03T16:42:52.827" Score="3" Body="&lt;p&gt;Aside from the square-cube law for measuring the strength of the bot &lt;a href=&quot;http://robotics.stackexchange.com/a/263/126&quot;&gt;mentioned by user65&lt;/a&gt;, you have a few more effects. I don't know of any theorem for this, though.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Firstly, note that &quot;bigger batteries&quot; doesn't mean &quot;bigger motors&quot;. And &quot;bigger motors&quot; doesn't mean &quot;stronger motors&quot; or &quot;more powerful motors&quot;. If we're talking about the same type of battery, then we &lt;em&gt;can&lt;/em&gt; say that a bigger battery is generally more powerful{*}. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;One thing the weight of the bot changes a lot is the friction. See, with a heavy bot, friction increases proportionately. This means we need proportionally stronger motor to be able to climb inclines (otherwise the bot just gets stuck, or starts rolling down). The friction doesn't really make a difference while moving on a flat surface, though. This is an easy principle to put down on paper--for a given weight increase, we need a proportional increase in torque. To obtain that, we may either use a motorwith a proportionately lower rpm (but that reduces the speed), or use a proportionately more powerful battery.  So in the end, this evens out nicely, since the power of a battery depends upon its size, keeping the type fixed. When the bot is moving on a flat surface, its inertia needs to be counteracted whenever one wants to turn. For this, we need high friction (which we already have), and a proportionately stronger motor. Again, this evens out nicely, So really, we should look at the power requirements of the &lt;em&gt;other&lt;/em&gt; components and choose size/power, and the motors will take care of themselves (I don't mean you neglect the motors entirely, I'm just saying that the motor issue is easily straightened out after the bot size has been decided. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another thing a larger size gives you is more capacity to store energy. You can always stuff some extra Li-Po's on a large (autonomous or RC) bot , and increase its lifetime. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Due to all this, it's really saner to just say that the size/weight of the bot has no direct relation to its effectiveness. It really depends on what the bot is supposed to &lt;em&gt;do&lt;/em&gt;.  There are just too many other factors to decide--you need to know what strength you want, what power auxiliary mechanisms need, if the auxiliary mechanisms need couterbalancing, the maximum angle incline the bot is subject to, required stability, required response time, lifetime, etc. Choosing a size/weight requires one take all these factors into account while designing the bot. Some bots are better designed small, some bots are better designed large. No formula to it :)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;sup&gt;*On the other hand, one can replace a Pb-acid battery with a bunch of Li-Po batteries of the same net weight and size, and get a much powerful &quot;battery&quot;. &lt;/sup&gt;&lt;/p&gt;&#xA;" OwnerUserId="126" LastActivityDate="2012-11-03T16:42:52.827" />
  <row Id="267" PostTypeId="1" AcceptedAnswerId="272" CreationDate="2012-11-03T16:58:44.830" Score="11" ViewCount="5322" Body="&lt;p&gt;I've seen many motors having capacitors attached in parallel in bots. Apparently, this is for the &quot;safety&quot; of the motor. As I understand it, all these will do is smoothen any fluctuations--and I doubt that fluctuations can have any adverse effects on a motor. Apparently these protect the motor if the shaft is being slowed/blocked, but I fail to see how.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What exactly is the function of such a capacitor? What does it prevent, and how?&lt;/p&gt;&#xA;" OwnerUserId="126" LastEditorUserId="350" LastEditDate="2012-11-13T16:53:37.537" LastActivityDate="2012-11-13T16:53:37.537" Title="Why are capacitors added to motors (in parallel); what is their purpose?" Tags="&lt;motor&gt;&lt;protection&gt;" AnswerCount="2" FavoriteCount="2" />
  <row Id="268" PostTypeId="2" ParentId="46" CreationDate="2012-11-03T17:36:17.997" Score="6" Body="&lt;p&gt;When taking into account size / weight / Ah,&#xA;fuel cells and micro power turbines have an energy per kilogram and (with liquid fuels) an energy per liter that is an order of magnitude better than any battery.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In particular, I keep hearing that liquid methanol fuel cells are &quot;relatively practical&quot;.&#xA;&lt;a href=&quot;http://www.infoworld.com/d/hardware/toshiba-prototypes-methanol-fuel-cell-laptops-955&quot;&gt;a&lt;/a&gt; &lt;a href=&quot;http://www.powerstream.com/methanol-fuel-cell.htm&quot;&gt;b&lt;/a&gt; &lt;a href=&quot;http://miter.mit.edu/articleenabling-liquid-fuels-high-efficiency-fuel-cells/&quot;&gt;c&lt;/a&gt; &lt;a href=&quot;http://www1.eere.energy.gov/hydrogenandfuelcells/fuelcells/fc_types.html&quot;&gt;d&lt;/a&gt; &lt;a href=&quot;http://en.wikipedia.org/wiki/Direct_methanol_fuel_cell&quot;&gt;e&lt;/a&gt;.&#xA;And I've heard that Hyuk Kim and Seungdoo Park built a prototype &lt;a href=&quot;http://www.sciencedaily.com/releases/2001/09/010905072008.htm&quot;&gt;diesel fuel cell&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Prototype microturbines also show promise.&lt;a href=&quot;http://www.powermems.be/gasturbine.html&quot;&gt;a&lt;/a&gt; &lt;a href=&quot;http://en.wikipedia.org/wiki/microturbine&quot;&gt;b&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Alas, fuel cells and micro power turbines (as well as some high-energy density batteries such as zinc-air) are not really designed for underwater vehicles -- they are designed to breathe air.&lt;/p&gt;&#xA;" OwnerUserId="187" LastActivityDate="2012-11-03T17:36:17.997" />
  <row Id="269" PostTypeId="2" ParentId="267" CreationDate="2012-11-03T23:05:34.510" Score="5" Body="&lt;p&gt;The capacitor seen on a lot of brushed motors is there to absorb RF noise due to the arcing as the brushes commutate. You often see these on the motors used in RC cars, where the motors are  fairly powerful and spinning fast.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The problem comes when you are using PWM to drive the motor. At the beginning of the duty cycle, when the current is switched on, you'll see a current spike as the current rushes into the capacitor from the H-Bridge. This inrush current can sometimes cause noticeable voltage ripple at the power supply, adding noise into any sensitive analogue sensors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To prevent the inrush current, you can add a pair of inductors between the H-Bridge and the capacitor. This will hold the current fairly steady. Actually, you'll often see inductors on motor drive circuits anyway. Even though the motor itself is an inductor, it's often quite a low inductance, so extra inductance is added to help smooth out any current fluctuations when using PWM drive.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The capacitors have nothing to do with protecting the motor in the case of a stall. When the motor stalls, the current increases and you risk overheating the motor.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-11-03T23:05:34.510" CommentCount="1" />
  <row Id="270" PostTypeId="2" ParentId="262" CreationDate="2012-11-03T23:11:10.513" Score="1" Body="&lt;p&gt;The square cube law mentioned by user65 is a good one. In fact, these kind of laws are fundamental when looking at machines of various sizes. For mobile robots, as Josh mentioned, power is a serious problem, and so I'd say that one of the most important laws regarding mobile robots is that the energy storage capacity goes up with the cube of the length of the robot (assuming roughly equal proportions). Thus larger robots benefit enormously from longer battery life.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-11-03T23:11:10.513" />
  <row Id="271" PostTypeId="1" CreationDate="2012-11-03T23:24:38.043" Score="4" ViewCount="254" Body="&lt;p&gt;I have two Unmanned Aerial Vehicles (planes) which work well. They can fly to various waypoints automatically using GPS.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now I would like them to fly together in formation. I would like them to fly side-by-side fairly close. This is too close to reliably use GPS to guarantee that they keep the correct relative positions safely, and so I am looking for another way.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Somehow the UAVs need to be able to measure their position and orientation in space relative to the other one. How can I do this? Is there some kind of sensor which can do this? It would need to have the following properties:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;6 axes (position and orientation)&lt;/li&gt;&#xA;&lt;li&gt;Range 0m - 5m, (from between plane centres, but planes won't actually ever touch wingtips)&lt;/li&gt;&#xA;&lt;li&gt;Works in day or night and all weather conditions&lt;/li&gt;&#xA;&lt;li&gt;Light weight (This is for 1.5m wingspan RC planes, so max extra weight of about 100g)&lt;/li&gt;&#xA;&lt;li&gt;Probably need about 50Hz - 100Hz refresh rate, but might get away with less, using the IMU to fill in the gaps&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="40" LastEditorUserId="350" LastEditDate="2012-11-30T14:32:57.723" LastActivityDate="2012-11-30T17:22:30.420" Title="Spatial tracking between two UAVs" Tags="&lt;sensors&gt;&lt;uav&gt;&lt;multi-agent&gt;" AnswerCount="6" />
  <row Id="272" PostTypeId="2" ParentId="267" CreationDate="2012-11-04T00:54:14.993" Score="14" Body="&lt;p&gt;Capacitors are used with motors in two different ways. Sometimes the same motor will have both techniques applied, and be associated with two significantly different-looking capacitors.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;When motors with brushes are running normally, the motor brushes produce sparks, which cause noise &quot;from DC to daylight&quot;. This has nothing to do with PWM -- it happens even when these motors are connected directly across a battery, without any PWM.&#xA;If we did nothing, the cable running from the electronics board (or directly from the battery) to the motor would act like an antenna, radiating TV and other radio interference.&#xA;One way people fix that problem is to attach small ceramic capacitors directly to the motor to absorb much of that noise. &lt;a href=&quot;http://www.beam-wiki.org/wiki/Reducing_Motor_Noise&quot;&gt;b&lt;/a&gt; &lt;a href=&quot;http://www.pololu.com/docs/0J15/9&quot;&gt;c&lt;/a&gt; &lt;a href=&quot;http://www.mabuchi-motor.co.jp/en_US/technic/t_0203.html&quot;&gt;d&lt;/a&gt; &lt;a href=&quot;http://www.robotshop.com/PDF/motor-noise-reduction.pdf&quot;&gt;e&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;When using PWM to drive the motor, when the transistors turn &quot;on&quot;, the motor may pull a current spike / surge current -- the above noise-filtering capacitors make that current spike worse. When the transistors turn &quot;off&quot;, the motor inductance may cause voltage spikes from the motor inductance -- the above noise-filtering capacitors help a little. More complex filters attached directly to the motor can help these two problems. &lt;a href=&quot;http://hydraraptor.blogspot.com/2007/09/dc-to-daylight.html&quot;&gt;a&lt;/a&gt; &lt;a href=&quot;http://www.stefanv.com/rcstuff/qf200005.html&quot;&gt;b&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;When a motor -- even a motor that doesn't have brushes -- is first turned on at a dead stop, and also when the robot hits an obstruction and stalls the motor, the motor pulls much higher currents than it does in normal operation -- currents that may last for several seconds. This high current may pull down the battery power rail enough to reset all the digital electronics in the system (or perhaps reset just &lt;em&gt;some&lt;/em&gt; of the digital electronics, causing half-brain syndrome).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One work-around has 2 parts:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;add large electrolytic capacitors directly across the battery (or across the battery input to the PWM motor driver, or across the battery input to the digital electronics, or often capacitors in all three locations) -- these capacitors work better at supplying high currents for a few milliseconds than the battery does.&lt;/li&gt;&#xA;&lt;li&gt;In the few milliseconds we have before the stalled motor pulls all the energy from those big capacitors and then pulls the power rails low enough to start resetting things, program the digital system to somehow recognize that the motor has stalled and kill the power to that motor. Then that motor no longer drags down the power rail, and the digital electronics and all the other motors continue to operate normally. (&quot;soft-start&quot;, &quot;current-limiting&quot;, &quot;torque-limiting&quot;, etc. are more sophisticated forms of this idea). (Those big capacitors, also absorb some of the energy that comes out of the motor when the PWM turns &quot;off&quot;, and later put that energy back into the motor when the PWM turns &quot;on&quot;).&lt;/li&gt;&#xA;&lt;/ol&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The above capacitors protect other things &lt;em&gt;from&lt;/em&gt; the motor's electrical interference.&#xA;I suppose one could argue that step (2) above prevents a stalled motor from eventually, after many seconds, overheating and failing -- but that's not really its primary purpose.&lt;/p&gt;&#xA;" OwnerUserId="187" LastEditorUserId="158" LastEditDate="2012-11-06T13:58:52.793" LastActivityDate="2012-11-06T13:58:52.793" CommentCount="2" />
  <row Id="273" PostTypeId="2" ParentId="256" CreationDate="2012-11-04T16:56:04.347" Score="5" Body="&lt;p&gt;You might be able to do this using inductive coupling to give the quad copter some indication as to which direction it should move to approach the landing pad.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/xTJyT.png&quot; alt=&quot;Quad copter landing pad&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On the landing pad is a single coil on the vertical axis (this is the transmitter). On the quad-copter are two coils, 90º apart and on the horizontal axis (these are the receivers). An alternating current is passing through the coil on the handing pad, creating an alternating magnetic field around it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If the quad-copter is centred directly above the landing pad, then no current will be induced in the receivers. If the quad-copter is to one side, then a current will be induced in the receivers. Which receiver is seeing the current will tell the quad-copter which axis to move in, but not whether to move one way or the other. You can use a band-pass filter to distinguish between the signal from the landing pad, and noise from the motors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Deciding which direction to move in is tricky, and I'm not sure of the best solution yet.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One way would be to correlate the change in signal with velocity information inferred from the accelerometers. If the quad-copter is moving one way, and sees the induced current reduce at the same time, then it knows that it should continue moving that way.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another way would be to pulse a DC current through the coil. Pulse it forwards for 10ms, then backwards for 30ms. Use a low-pass filter on the receivers to distinguish between this signal and background noise. By looking at the pulse widths, the quad-copter can now tell the difference between the forward and backwards directions.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;You can probably make the receivers smaller than I have drawn here, and the transmitter as large as the landing pad.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-11-04T16:56:04.347" />
  <row Id="274" PostTypeId="1" AcceptedAnswerId="290" CreationDate="2012-11-05T08:29:56.787" Score="2" ViewCount="210" Body="&lt;p&gt;Some years ago, there where some projects that provided hardware and software to perform modifications on standard hobby servos to convert them to digital servos, with all the advantages that come with it. &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://openservo.com/&quot; rel=&quot;nofollow&quot;&gt;OpenServo&lt;/a&gt; is a little outdated, and does not seem to be worked on anymore, and there is no hardware to buy.&lt;/li&gt;&#xA;&lt;li&gt;Sparkfun has its &lt;a href=&quot;https://www.sparkfun.com/products/9014&quot; rel=&quot;nofollow&quot;&gt;own version&lt;/a&gt; of the OpenServo, which at least is available for buying.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Do you know if there are other mods, or even complete low cost digital servos? I am mostly interested in position feedback, and servo chaining.&lt;/p&gt;&#xA;" OwnerUserId="127" LastActivityDate="2013-02-25T11:19:59.490" Title="Low-cost servo with digital control interfaces?" Tags="&lt;servos&gt;&lt;i2c&gt;" AnswerCount="2" CommentCount="0" ClosedDate="2013-05-20T15:48:08.447" />
  <row Id="275" PostTypeId="2" ParentId="150" CreationDate="2012-11-05T11:34:25.977" Score="13" Body="&lt;p&gt;You may want to consider a &lt;a href=&quot;http://openrov.com/forum/topics/magnetically-coupled-drive&quot;&gt;Magnetically Coupled Drive&lt;/a&gt;. Use a standard motor with a magnetic coupling to transmit the torque to your prop.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This would allow your motor to be completely sealed inside your vehicle:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/3AVt1.png&quot; alt=&quot;Magnetically Coupled Drive&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;sup&gt;From &lt;a href=&quot;http://openrov.com/profile/1gupl83kvnk8f&quot;&gt;Eric Stackpole&lt;/a&gt;'s &lt;a href=&quot;http://openrov.com/forum/topics/magnetically-coupled-drive&quot;&gt;article&lt;/a&gt; mentioned above. Image used without permission, but with attribution.&lt;/sup&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This solution may or may not be suitable however, depending on the torque you need to transmit, but for open water use has the distinct advantage that it &lt;em&gt;is&lt;/em&gt; torque limited. In other words, if your prop gets jammed and you have selected suitable motor and coupling torques then the coupling will &lt;em&gt;slip&lt;/em&gt; before your motor burns out.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I particularly like Erics solution as it simultaneously transmits torque to the prop, centers the prop on the shaft and centers the prop along the shaft. An elegant piece of design which solves several problems simultaneously.&lt;/p&gt;&#xA;" OwnerUserId="37" LastEditorUserId="37" LastEditDate="2012-11-05T11:51:24.060" LastActivityDate="2012-11-05T11:51:24.060" CommentCount="1" />
  <row Id="276" PostTypeId="2" ParentId="271" CreationDate="2012-11-05T16:00:40.880" Score="5" Body="&lt;p&gt;How close together?  If they use the same make and model GPS unit, you MIGHT be able to use the relative positions calculated via GPS.  A lot of the sources of GPS error would be the same for both vehicles in that case (e.g., atmospherics, any built-in GPS filtering).  Each vehicle could broadcast it's state vector to the other one.  &lt;/p&gt;&#xA;" OwnerUserId="58" LastEditorUserId="58" LastEditDate="2012-11-05T20:26:50.883" LastActivityDate="2012-11-05T20:26:50.883" CommentCount="0" />
  <row Id="277" PostTypeId="1" AcceptedAnswerId="285" CreationDate="2012-11-05T23:18:26.770" Score="28" ViewCount="1258" Body="&lt;p&gt;I am designing an unmanned aerial vehicle, which will include several types of sensors: &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;3-axis accelerometer&lt;/li&gt;&#xA;&lt;li&gt;3-axis gyroscope &lt;/li&gt;&#xA;&lt;li&gt;3-axis magnetometer&lt;/li&gt;&#xA;&lt;li&gt;horizon sensor&lt;/li&gt;&#xA;&lt;li&gt;GPS &lt;/li&gt;&#xA;&lt;li&gt;downward facing ultrasound.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;A friend of mine told me that I will need to put all of this sensor data through a Kalman filter, but I don't understand why. Why can't I just put this straight into my micro controller. How does the Kalman filter help me about my sensor data?&lt;/p&gt;&#xA;" OwnerUserId="40" LastEditorUserId="399" LastEditDate="2012-11-11T16:14:42.297" LastActivityDate="2014-01-09T00:20:48.943" Title="Why do I need a Kalman filter?" Tags="&lt;kalman-filter&gt;&lt;uav&gt;" AnswerCount="5" FavoriteCount="5" />
  <row Id="278" PostTypeId="2" ParentId="277" CreationDate="2012-11-06T06:03:23.243" Score="13" Body="&lt;p&gt;Sensor data is noisy. If you do not filter it, then your vehicle would at least act erratically if it were even stable enough to fly. Filtering, via a Kalman filter or otherwise, can reduce the noise when done correctly, improving stability in turn.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A &lt;a href=&quot;http://en.wikipedia.org/wiki/Kalman_filter&quot;&gt;Kalman filter&lt;/a&gt; is a particularly powerful filter. It takes a model of the system and noise models for both the system and your sensors. It then estimates the state of the vehicle based on a provided state estimate and the controls applied at any moment in time. This estimated state will be more accurate than what the sensors report.&lt;/p&gt;&#xA;" OwnerUserId="177" LastEditorUserId="37" LastEditDate="2012-11-07T17:09:17.303" LastActivityDate="2012-11-07T17:09:17.303" />
  <row Id="279" PostTypeId="2" ParentId="277" CreationDate="2012-11-06T12:40:39.940" Score="14" Body="&lt;p&gt;The short, snide answer is &quot;try it without one.&quot;  The better answer is an example: When your accellerometers say you are 10 degrees from vertical, but your gyro says you haven't rotated away from vertical, and your magnetometers are reporting a 30 deg offset from north but your gyro says 32 degree ... what is the current heading and tilt?  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;You'll probably come up with a million ad-hoc ways which seem to work in one example, but fail in others. The Kalman Filter (Extended Kalman Filter (EKF) for this task!) will provide for you a rigorous way to answer these questions. The quality of the answers is still being researched--though the EKF's track record is very good--but at least everyone will agree what the answers &lt;em&gt;are&lt;/em&gt;. &lt;/p&gt;&#xA;" OwnerUserId="163" LastActivityDate="2012-11-06T12:40:39.940" />
  <row Id="280" PostTypeId="2" ParentId="271" CreationDate="2012-11-06T13:49:45.197" Score="4" Body="&lt;p&gt;It is possible that two independent GPS units might be accurate enough (as &lt;a href=&quot;http://robotics.stackexchange.com/a/276/37&quot;&gt;ViennaMike suggests&lt;/a&gt;) if both are sufficiently similar, get a lock from the same location, follow roughly the same paths (so the accumulated differential GPS errors are roughly the same) and are re-synchronised at regular intervals.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This might be significantly assisted though if you also had some sort of proximity measure between the two devices.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Start them off a fixed distance from each other, sync both their differential GPS locks &amp;amp; calibrate the proximity thresholds (starting distance, too close threshold and too far threshold). You can then use the proximity sensor distance to say if the gps locks are drifting too much (they are getting closer than they should be or further apart).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One option which I believe could provide both rough proximity information and data communication between the two UAVs would be Bluetooth. Once the two devices are paired, you may be able to get both intra-device communication and rough proximity information from one pair of radios.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Searching on Bluetooth Proximity led me to see the use of RSSI (Received Signal Strength Indicator) as a measure of proximity and thus onto &lt;a href=&quot;http://www.google.co.uk/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=5&amp;amp;cad=rja&amp;amp;ved=0CEsQFjAE&amp;amp;url=http://202.175.25.24/papers/2010/fcc2010yapeng.pdf&amp;amp;ei=9RSZUIXvEsLg4QTHu4CABw&amp;amp;usg=AFQjCNHiYc5HPC3gUX6zyw1aJGaqcOL_tw&quot; rel=&quot;nofollow&quot;&gt;&lt;strong&gt;&lt;em&gt;Bluetooth Indoor Positioning using RSSI and Least Square Estimation&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt; &lt;sup&gt;#&lt;/sup&gt; which may be able to give you some interesting ideas for this.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;sup&gt;# Stack Exchange thinks that the original link &lt;code&gt;http://202.175.25.24/papers/2010/fcc2010yapeng.pdf&lt;/code&gt; is invalid, so won't let me use it &lt;a href=&quot;http://meta.stackoverflow.com/questions/131639/are-ip-address-links-valid-in-posts&quot;&gt;as a link&lt;/a&gt;, so I have used the google wrapped link.&lt;/sup&gt;&lt;/p&gt;&#xA;" OwnerUserId="37" LastEditorUserId="37" LastEditDate="2012-11-07T13:50:37.737" LastActivityDate="2012-11-07T13:50:37.737" CommentCount="1" />
  <row Id="281" PostTypeId="2" ParentId="261" CreationDate="2012-11-06T14:49:16.757" Score="5" Body="&lt;p&gt;The diagram you show looks like it would produce a pretty rough trapezoidal Back-EMF. I'm assuming that the gates that are at 100% are the lower legs of the motor drive bridge. I can't think of a reason you would want to do this. In general you want the gate voltage of the return leg to be the complement of the gate voltage of the supply leg.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In six-step trapezoidal commutation, you typically ramp the PWM up to 100%, leave it there for a while (~30 electrical degrees of rotation), and then ramp it back down again.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.dian-deng.com/index_motor_3phase_6step.htm&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/5EHWn.png&quot; alt=&quot;six-step trapezoidal&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In sinusoidal commutation, the PWM duty cycle is continuously varied in sinusoidal values. Here is a good diagram showing the difference between sinusoidal drive and trapezoidal drive PWM and phase signals:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.embedded.com/design/embedded/4006783/Implementing-Embedded-Speed-Control-for-Brushless-DC-Motors-Part-4&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/9FvgT.jpg&quot; alt=&quot;sine versus trapezoidal&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This Fairchild app note shows the PWM though a full 360° rotation:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.fairchildsemi.com/ds/FC/FCM8202.pdf&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/4FmHz.png&quot; alt=&quot;360 sine rotation&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.imakenews.com/eletra/mod_print_view.cfm?this_id=287045&amp;amp;u=getoshiba_mve-news&amp;amp;issue_id=000057909&amp;amp;show=F,T,T,T,F,Article,F,F,F,F,T,T,F,F,T,T&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/sVmnF.jpg&quot; alt=&quot;sine drive single&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It's useful to look at what's going on in the signal up close. What you're really doing is gradually varying the current in a triangular wave so that it slowly builds up in the stator of the motor. You have more control over this buildup if you drive the supply and return gates in a complementary fashion rather than holding the lower leg open.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.screenlightandgrip.com/html/emailnewsletter_generators.html&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/JsxNP.jpg&quot; alt=&quot;current variance&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Computing a sine wave is more computationally intensive (unless you use a lookup table) than a simple ramp up, hold, ramp down. But it produces a much smoother drive.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Space-vector commutation is even more computationally intensive. And while it has more torque ripple than a sinusoidal drive, it makes higher utilization of the bus voltage and is therefore more efficient in terms of power.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The phase voltage in space vector drive ends up looking like this:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.powerlab-tr.com/?p=693&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/FZVFU.png&quot; alt=&quot;space vector voltage&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is done by varying the PWM duty cycle in all three phases at the same time. This is opposed to having just a single phase driven as in two-quadrant drive or having two phases driven in complementary pairs as in four-quadrant drive.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S037877960900056X&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/UXgZ2.jpg&quot; alt=&quot;space-vector PWM&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="142" LastEditorUserId="142" LastEditDate="2012-11-06T21:00:00.027" LastActivityDate="2012-11-06T21:00:00.027" CommentCount="5" />
  <row Id="282" PostTypeId="2" ParentId="271" CreationDate="2012-11-07T10:30:29.820" Score="2" Body="&lt;p&gt;6-DOF is kind of difficult.. You could do vision but that is hard to implement robustly. You say the UAVs are localizing themselves using GPS; are you using an IMU+Kalman filtering as well? For proximity detection you could try infrared/ultrasonic sensors, e.g. &lt;a href=&quot;https://www.sparkfun.com/products/242&quot; rel=&quot;nofollow&quot;&gt;https://www.sparkfun.com/products/242&lt;/a&gt;. You could combine this with the Kalman filter to get a relative position estimate and get orientation from the Kalman filter directly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Although I reckon if you are using GPS+IMU+Kalman then broadcasting the estimated state to each other (XBee?) would probably suffice, given that the GPS units are calibrated similarly. You could easily calculate the relative orientation by subtracting their orientation in the inertial frame.&lt;/p&gt;&#xA;" OwnerUserId="229" LastEditorUserId="229" LastEditDate="2012-11-07T11:05:33.803" LastActivityDate="2012-11-07T11:05:33.803" />
  <row Id="283" PostTypeId="2" ParentId="256" CreationDate="2012-11-07T11:14:45.560" Score="1" Body="&lt;p&gt;As other people mentioned, an RF beacon will probably be difficult and vision is definitely a viable option. The common difficulty with vision-based solutions is that they are computationally expensive, making it difficult to be done on-board. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can try using the PixArt IR tracking sensor from a Nintendo Wii remote, which communicates through I2C and can thus be easily connected to for example an Arduino and place a few active IR beacons on the ground which are then picked up by the sensor. Using a simple clever pose estimation algorithm will get you an accurate estimate of your position.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A regular colour camera could also be used but unless you have something like a Beagleboard or Gumstix on-board it would be difficult to process the images in real-time. (although there is nothing stopping you from doing calculations on the ground, of course).&lt;/p&gt;&#xA;" OwnerUserId="229" LastActivityDate="2012-11-07T11:14:45.560" />
  <row Id="284" PostTypeId="1" CreationDate="2012-11-07T13:46:20.493" Score="8" ViewCount="2102" Body="&lt;p&gt;I wish to build a robotic arm that can lift a useful amount of weight (such as 3-6kg on an arm that can extend to approx 1.25 meters). What actuators are available to accomplish this. The main factors and design points are:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Not Expensive&lt;/li&gt;&#xA;&lt;li&gt;5 to 6 d.o.f.&lt;/li&gt;&#xA;&lt;li&gt;to be mounted on a yet to be designed mobile platform&lt;/li&gt;&#xA;&lt;li&gt;battery powered&lt;/li&gt;&#xA;&lt;li&gt;stronger than hobby servos (at least for the 'shoulder' and 'elbow' joints)&lt;/li&gt;&#xA;&lt;li&gt;not slow to actuate&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="234" LastActivityDate="2014-01-11T08:09:50.823" Title="Which type of actuator will be suitable for a very strong robot arm" Tags="&lt;mobile-robot&gt;&lt;actuator&gt;" AnswerCount="4" CommentCount="1" FavoriteCount="1" />
  <row Id="285" PostTypeId="2" ParentId="277" CreationDate="2012-11-07T13:56:06.577" Score="20" Body="&lt;p&gt;You &lt;em&gt;do&lt;/em&gt; connect all these sensors directly to a microcontroller.&#xA;The Kalman filter is not an electronic filter like a LRC filter that goes between the sensors and the microcontroller. The Kalman filter is a mathematical filter implemented as software routine inside the microcontroller.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The sensors you have listed give the microcontroller 14 or 15 raw numbers each time they are all updated.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When I fly a little aircraft, what I really want to know is its position and orientation&#xA;and how far it is above the ground -- 7 numbers.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I need &lt;em&gt;something&lt;/em&gt; that gives me those 7 numbers.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ideally I want a new estimate of those 7 numbers every time through my control loop.&#xA;The once-per-second updates I get from my cheap GPS aren't nearly fast enough.&#xA;(People at &lt;a href=&quot;http://robotics.stackexchange.com/questions/231/what-frequency-does-my-quadcopter-output-sense-calculate-output-update-loop-need&quot;&gt;What frequency does my quadcopter output-sense-calculate-output update loop need to stay stable?&lt;/a&gt; are telling me even 50-times-per-second isn't going to be fast enough).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Somehow I'm going to have to reduce those 14 or 15 raw numbers that I have, some of which only occasionally get updated, into (estimates of) the 7 numbers that I really want.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As Josh pointed out, there are many ad-hoc ways to convert those raw numbers into usable data.&#xA;Any routine that converts 15 numbers into 7 numbers can be described as a &quot;filter&quot;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You don't &lt;em&gt;have&lt;/em&gt; to use the optimum filter.&#xA;But you will use some kind of filter -- i.e., something that converts from the 15 numbers of raw data you have into (estimates of) the 7 numbers you really want.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The &lt;a href=&quot;http://en.wikipedia.org/wiki/Kalman_filter&quot; rel=&quot;nofollow&quot;&gt;Kalman Filter&lt;/a&gt; is, in some conditions, the &quot;optimum&quot; filter, the best way of converting that raw data into the 7 numbers I really want.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It may take less work on your part to use a Kalman filter that someone else has already written and debugged,&#xA;than to write some other filter from scratch, debug it, and keep adding stuff to it until it is usable -- a filter that will inevitably turn out to be sub-optimum.&lt;/p&gt;&#xA;" OwnerUserId="187" LastEditorUserId="2447" LastEditDate="2014-01-09T00:20:48.943" LastActivityDate="2014-01-09T00:20:48.943" />
  <row Id="286" PostTypeId="2" ParentId="284" CreationDate="2012-11-07T16:53:17.127" Score="7" Body="&lt;p&gt;Which &lt;a href=&quot;http://en.wikipedia.org/wiki/Robotics#Actuation&quot; rel=&quot;nofollow&quot;&gt;actuators&lt;/a&gt; are suitable for your application depends very much on what kind of robot arm you want to build. Once you have decided on what kind of arm you want you can decide on a suitable actuator &lt;em&gt;for each axis&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;The Arm&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Assuming from your description that a &lt;a href=&quot;http://en.wikipedia.org/wiki/Gantry_robot&quot; rel=&quot;nofollow&quot;&gt;gantry robot&lt;/a&gt; wouldn't be viable, then depending on your specific application, you may want to consider a &lt;a href=&quot;http://en.wikipedia.org/wiki/SCARA&quot; rel=&quot;nofollow&quot;&gt;SCARA arm&lt;/a&gt; over an &lt;a href=&quot;http://en.wikipedia.org/wiki/Articulated_robot&quot; rel=&quot;nofollow&quot;&gt;Articulated arm&lt;/a&gt;, which is what most people think of when they think &lt;a href=&quot;http://en.wikipedia.org/wiki/Robotic_arm&quot; rel=&quot;nofollow&quot;&gt;Robot arm&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The big advantage of a SCARA arm is that most of it's lifting strength is in it's bearings. The main shoulder, elbow and wrist (yaw) joints are in a flat plane, which means that the motors only need to be strong enough to produce the lateral forces required, they don't need to support the weight of the remaining axes.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The Z axis, pitch and roll (and grip obviously) all have to work against gravity, but the Z axis is easy to gear highly enough to be able to support plenty of weight, and the pitch, roll and grip axes only have to support the payload weight, not the weight of other axes.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/0gOBM.jpg&quot; alt=&quot;6 UMI RTX robot + gripper&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Compare this to an articulated arm, where many of the axes have to support the weight of all axes further down the &lt;a href=&quot;http://en.wikipedia.org/wiki/Kinematic_chain&quot; rel=&quot;nofollow&quot;&gt;kinematic chain&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/XSXku.gif&quot; alt=&quot;6 Axis Articulated Robots from KUKA&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;The actuators&lt;/h2&gt;&#xA;&#xA;&lt;h3&gt;Gantry robots&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Typically a gantry robot will use &lt;a href=&quot;http://en.wikipedia.org/wiki/Linear_actuator#Advantages_and_disadvantages&quot; rel=&quot;nofollow&quot;&gt;linear actuators&lt;/a&gt; for the main X, Y &amp;amp; Z axes. These could be low performance, low accuracy, high force actuators such as a lead screw with a servo or stepper drive (force and performance can be traded but accuracy will always be limited by backlash), all the way up to high performance, high accuracy direct drive linear motors with precision encoders.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The remaining 3DOF manipulator will usually require precision rotational motion for pitch, roll and yaw, so usually an electric motor (either stepper or servo), will be most suitable. Even a small motor with a reasonably high gearing can resist gravity against quite high loads.&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;An aside on servo motors vs. stepper motors&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;The difference between servo&lt;sup&gt;#&lt;/sup&gt; and stepper is a tradeoff between complexity and certainty in control.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;sup&gt;# Note that my experience is with industrial &lt;a href=&quot;http://en.wikipedia.org/wiki/Servomechanism#Servomotor&quot; rel=&quot;nofollow&quot;&gt;servos&lt;/a&gt;, typically a brushed or brushless DC motors with a rotary encoder, so this may or may not apply with hobby &lt;a href=&quot;http://en.wikipedia.org/wiki/Servomechanism#RC_servos&quot; rel=&quot;nofollow&quot;&gt;RC servos&lt;/a&gt;.&lt;/sup&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A servo motor requires an encoder for position feedback, whereas a stepper doesn't. This means that a stepper is electrically &lt;em&gt;much simpler&lt;/em&gt;, and from a control point of view simpler if you want low performance.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you want to get the most out of your motor though (pushing it close to it's limit), then steppers get &lt;em&gt;much&lt;/em&gt; more difficult to control predictably. With position feedback on a servo you can tune performance &lt;em&gt;much&lt;/em&gt; more aggressively and since you know if it fails to reach it's target position or velocity then your servo loop will get to find out about it and correct it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;With a stepper you have to tune the system so that you can &lt;em&gt;guarantee&lt;/em&gt; that it can &lt;em&gt;always&lt;/em&gt; make the step, irrespective of the desired speed of move or weight of the payload. Note that some people will suggest adding an encoder to detect missed steps on a stepper motor, but if you are going to do that then you might as well have used a servo motor in the first place!&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;SCARA arm&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;With a SCARA arm, the Z axis is probably the only linear axis, while the remaining axes can all be done with rotational motor, so again stepper or servo motor. Sizing these motors is relatively easy because the weight carried is less important to many of them. The motor required to overcome the inertia of a load is rather less than sizing it to overcome gravity.&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Articulated arm&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;With an articulated arm the calculations are more tricky, because most axes will need actuators sized depending on both moving the load and lifting it, but again an electric motor is the easiest to control and use.&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;The gripper&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Finally there is the gripper. This is where I have seen the most variety in actuators. Depending on your applications you could easily use any number of different actuators.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've used systems with traditional motor driven grippers, linear actuated grippers, &lt;a href=&quot;http://en.wikipedia.org/wiki/Amplified_piezoelectric_actuator&quot; rel=&quot;nofollow&quot;&gt;piezo flexture&lt;/a&gt; grips, pneumatically actuated grippers, vacuum pickups and simple slots or hooks amongst others, many of which were specific to the application. What your typical payload it could significantly change the actuator which is best for you. &lt;sup&gt;I would suggest posting another question on this.&lt;/sup&gt;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Doing your calcs&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;As &lt;a href=&quot;http://robotics.stackexchange.com/a/296/37&quot;&gt;Rocketmagnet suggests&lt;/a&gt; ultimately you are going to have to break out your calculator.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You will need to take into account kinematics of your system, the maximum load on each motor (taking into account the worst case with arm fully extended if you are using an articulate arm design), the speed (a smaller motor with higher gearing might give the force you need without the speed, but a beefier motor might give you a higher torque with lower gearing and a higher speed etc.) and the positional accuracy you need.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ultimately, the more money you throw at the problem, the better performance (speed, accuracy, power consumption) you will get. But analysing specifications and making smart purchasing decisions can help optimise the price/performance of your robot.&lt;/p&gt;&#xA;" OwnerUserId="37" LastEditorUserId="2447" LastEditDate="2014-01-11T08:09:50.823" LastActivityDate="2014-01-11T08:09:50.823" CommentCount="2" />
  <row Id="287" PostTypeId="1" CreationDate="2012-11-07T19:29:50.063" Score="27" ViewCount="1762" Body="&lt;p&gt;As somebody who is spending the majority of his time programming in JavaScript, what's the best route to get into small-robotics without needing to deviate too much from my current language focus?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Are there any project kits or tools that make use of the JavaScript language that might make the field more approachable for developers like myself? I would even be interested in virtual environments where all code is executed in a simulation.&lt;/p&gt;&#xA;" OwnerUserId="250" LastEditorUserId="126" LastEditDate="2012-11-14T15:02:03.340" LastActivityDate="2013-08-21T19:02:07.687" Title="Programming Robots with JavaScript" Tags="&lt;software&gt;&lt;programming-languages&gt;" AnswerCount="8" CommentCount="4" FavoriteCount="5" />
  <row Id="288" PostTypeId="2" ParentId="287" CreationDate="2012-11-07T19:38:33.743" Score="9" Body="&lt;p&gt;Hmm, interesting question! I personally would suggest that you take a look at the Arduino platform. It's programmed in C, so the syntax is going to be... familiar, to a JavaScript writer. In my humble opinion, knowing how the syntax (while loops, if/than blocks, etc) is laid out is 70% of the battle, once you're familiar with that, you can plug and play. You can pick up a starter kit for around $30 online from the good folks at SparkFun.com or adafruit.com, you can program it on a PC, Mac or Linux machine, and it comes pre-loaded with enough examples to ease you into the language quickly. I'm not saying that you're just gonna drop some JavaScript code into it and be on your way, but I was a JavaScript programmer when I started out with Arduino, and I found it quite easy to pick up and run with. Good luck, as a part time teacher in robotics it's always awesome to see people getting into the field!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;P.S. - you should also be familiar/comfortable with building electronic circuits (lights, motors and the like), but any good Arduino introduction kit worth its salt will get you started if you don't have any experience.&lt;/p&gt;&#xA;" OwnerUserId="176" LastActivityDate="2012-11-07T19:38:33.743" CommentCount="3" />
  <row Id="289" PostTypeId="2" ParentId="25" CreationDate="2012-11-07T19:52:08.770" Score="5" Body="&lt;p&gt;Save your calculator fingers! &lt;/p&gt;&#xA;&#xA;&lt;p&gt;go here &lt;a href=&quot;http://www.ecalc.ch/xcoptercalc_e.htm&quot;&gt;http://www.ecalc.ch/xcoptercalc_e.htm&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I hear it is not 100% accurate, but darned close enough.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can 'tune' your components - and observe run-time and/or power until you get the efficiency you want. I also use it (most of the time) when I can not find the props I want, to verify a substitute prop is reasonable.  I just wish you could save configurations, I would have about 5 in there now :|&lt;/p&gt;&#xA;" OwnerUserId="274" LastActivityDate="2012-11-07T19:52:08.770" CommentCount="2" />
  <row Id="290" PostTypeId="2" ParentId="274" CreationDate="2012-11-07T20:25:31.203" Score="1" Body="&lt;p&gt;Yes, the v3 OpenServo is out of stock.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In fact we are working on a new version 4 of OpenServo that will modernise the codebase.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are no timelines for the v4 as yet, but work has only just started.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would recommend the SparkFun board for now.&lt;/p&gt;&#xA;" OwnerUserId="283" LastActivityDate="2012-11-07T20:25:31.203" CommentCount="1" />
  <row Id="291" PostTypeId="2" ParentId="100" CreationDate="2012-11-07T20:26:31.823" Score="0" Body="&lt;p&gt;Maybe too expensive for a home project, but the MIL-DTL-38999 series connector (available from &lt;a href=&quot;http://www.glenair.com/interconnects/mildtl38999/&quot; rel=&quot;nofollow&quot;&gt;Glenair&lt;/a&gt; and many other suppliers) is the connectro of choice for military equipment&lt;/p&gt;&#xA;&#xA;&lt;p&gt;OK, it fails your &quot;they are not simple plug-in connectors&quot; requirement but are ideal for disconnect/reconnect in all kinds of environments.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;ANd no I don't work for Glenair :)&lt;/p&gt;&#xA;" OwnerUserId="134" LastActivityDate="2012-11-07T20:26:31.823" />
  <row Id="292" PostTypeId="2" ParentId="209" CreationDate="2012-11-07T20:27:22.420" Score="0" Body="&lt;p&gt;I think the best approach would be to use a data set which contains a ground truth. The data set which is most often cited in the literature is described in the paper &quot;A benchmark for the evaluation of RGB-D SLAM systems.&quot; They also describe a few metrics to compare your pose estimation result with the ground truth. Hope this helps. Happy coding.  &lt;/p&gt;&#xA;" OwnerUserId="45" LastActivityDate="2012-11-07T20:27:22.420" CommentCount="1" />
  <row Id="293" PostTypeId="2" ParentId="128" CreationDate="2012-11-07T20:34:33.870" Score="2" Body="&lt;p&gt;&lt;a href=&quot;http://www.orocos.org/&quot; rel=&quot;nofollow&quot;&gt;Orocos&lt;/a&gt; is a mature real time robotics control software framework.  I have seen it used to successfully control high speed robotic manipulators with hard real time requirements.  It has many of the same framework level components as ROS, communications, configuration, serialization, and component based packaging.&lt;/p&gt;&#xA;" OwnerUserId="20" LastActivityDate="2012-11-07T20:34:33.870" />
  <row Id="294" PostTypeId="2" ParentId="287" CreationDate="2012-11-07T20:43:57.540" Score="14" Body="&lt;p&gt;There are a couple of projects out there that mate the Arduino platform to the NodeJS javascript execution engine.  Take a look at Johnny-Five, &lt;a href=&quot;https://github.com/rwldrn/johnny-five&quot;&gt;https://github.com/rwldrn/johnny-five&lt;/a&gt;, which is a library on top of the Arduino Firmata remote control protocol or node-reflecta, &lt;a href=&quot;https://github.com/JayBeavers/node-reflecta&quot;&gt;https://github.com/JayBeavers/node-reflecta&lt;/a&gt;, which is a nodejs interface for the Arduino Reflecta remote control protocol.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've personally built a nodejs controlled robot called RocketBot, &lt;a href=&quot;https://github.com/JayBeavers/RocketBot&quot;&gt;https://github.com/JayBeavers/RocketBot&lt;/a&gt;, that combines node-reflecta with node-joystick on top of a Beaglebone and an Arduino so I can attest this approach works well.&lt;/p&gt;&#xA;" OwnerUserId="35" LastEditorUserId="117" LastEditDate="2012-11-24T03:56:51.623" LastActivityDate="2012-11-24T03:56:51.623" />
  <row Id="295" PostTypeId="2" ParentId="284" CreationDate="2012-11-07T20:58:23.420" Score="4" Body="&lt;p&gt;Mobile platform: An &lt;a href=&quot;http://en.wikipedia.org/wiki/Linear_actuator#Advantages_and_disadvantages&quot; rel=&quot;nofollow&quot;&gt;electro-mechanical linear actuator&lt;/a&gt; can be a good choice for light weight actuator which can be mounted on mobile platform. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Battery powered: An electro-mechanical linear actuator is good choice over servo motors, as linear actuators draw power only when it is moving, and it does not need power to hold its position.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;5-6 DoF: It might be difficult to achieve this using electro-mechanical linear actuator, as they are mechanical complicated and have limited range of motion&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can try linear actuators from www.firgelli.com. They have miniature linear actuators as well, which are good for small scale application.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Mechanical design concept for arm using linear actuator: Most of earth moving equipment have hydraulic linear actuator. Some of the joints for linear actuator can be implemented in this line.&lt;/p&gt;&#xA;" OwnerUserId="289" LastEditorUserId="37" LastEditDate="2012-11-08T15:30:38.133" LastActivityDate="2012-11-08T15:30:38.133" CommentCount="0" />
  <row Id="296" PostTypeId="2" ParentId="284" CreationDate="2012-11-07T21:25:55.483" Score="3" Body="&lt;p&gt;When you're choosing actuators, it's instructive to start by calculating how much power you need at the end effector. When you say 'not too slow' you should have some idea what this means, especially under different load conditions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, you might say: 6kg at 0.2m/s and  0kg at 0.5m/s&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now add in the estimated weight of the arm: 10kg at 0.2m/s and  4kg at 0.5m/s&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now calculate the power: 100N * 0.2m/s = 20W  and 40N * 0.5m/s = 20W&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So the peak power output at the end effector is &lt;strong&gt;20W&lt;/strong&gt;. You're going to need an actuator which can comfortably produce more than 20W. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm going to make assume that you end up deciding to use an electric motor as your actuator. These are still the actuator of choice for powerful electric robots systems. (If you successfully get this robot working with muscle wire without burning down your workshop, I'll eat my mouse).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Since you're using an electric motor, you'll almost certainly be using some kind of gears. Assume the gear train on the motor is about 50% efficient. This means you'll need an electric motor rated for at least 40W. If you want this to be a reliable arm, I'd spec a motor rated for at least 60W.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Next you need to spec the gear train. What's the torque needed? 100N*1.25m = 125Nm. But as usual, you need to spec more torque than this for the gear train, not least because you'll need some spare torque to be able to accelerate the load upwards. Select a gear train which can take more than the rated load.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Lastly, make sure that the motor's torque multiplied by the gear ratio multiplied by the efficiency exceeds your torque requirement, but not the maximum gear load.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-11-07T21:25:55.483" CommentCount="2" />
  <row Id="297" PostTypeId="2" ParentId="271" CreationDate="2012-11-07T22:11:43.653" Score="3" Body="&lt;p&gt;How close together is important. I saw the range of 0-5m, but if you're suggesting that they might touch, or just barely not touch, then you're going to have difficulties. Lightweight is also a vague term which will need to be defined better in order to adequately answer your question. Still, there are some things to keep in mind:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Augmented GPS can get you sub-inch accuracy. This will likely involve an extra antenna, so space and weight might be a concern. You also have to make sure you don't lose GPS accuracy at the wrong time, which I've seen with some systems.&lt;/li&gt;&#xA;&lt;li&gt;As geez suggests, IMU is very useful for the 6-DOF tracking.&lt;/li&gt;&#xA;&lt;li&gt;You almost certainly know this, but 3D movement makes this a tricky problem. Avoiding collisions is &lt;em&gt;relatively&lt;/em&gt; easy, but ensuring the proper formation between the two means sensing the other vehicle will require a wide range of detection.&lt;/li&gt;&#xA;&lt;li&gt;A sensor such as MS's Kinect will get you some around .6m to 3m 3D sensing, but in a relatively narrow cone, so you'd need several to cover the all around the planes. Also, they're not all &lt;em&gt;that&lt;/em&gt; fast and will have trouble in difficult weather. Most weather, really. I don't know of any variants that are outdoor rated, especially in cold/damp (condensation on a lens would kill that sensor).&lt;/li&gt;&#xA;&lt;li&gt;Which also brings me to another question: speed. Planes are all reasonably fast, but there's glider fast and there's supersonic jet fast and all ranges in between. Refresh rate vs. distance between UAVs will be a very important consideration. Is 30-60hz enough time for your UAVs to correct when they're a few meters apart, or do they need something close to 100hz?&lt;/li&gt;&#xA;&lt;li&gt;If 30-60Hz is enough, you could potentially mark your UAVs with a distinctive pattern and use optics to detect that pattern and, combined with GPS etc, use that for close-range stuff. The problem with straight image detection is that it's computationally intensive and sometimes tricky to do, especially depending on your math skills. You'd have to have a way to keep the lens clear of condensation, like the Kinect, but I don't believe that's an intractable problem in this case, because you have a lot of options on cameras. Not saying it'd be easy, but easier than with a Kinect-style sensor.&lt;/li&gt;&#xA;&lt;li&gt;XBee is cool, but it's all packet based, so there's a maximum refresh rate on transmitting between units. You'd probably need some tolerance on lost packets, as well.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;So, no sure answers yet, but possibly with some domain narrowing we could help you more. Size, weight, minimum distance, and maximum speed limits will all wildly affect what solution you might go with.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;UPDATE based on additional information:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Hmmm. I don't think there's an ideal solution. An array of ultrasonics could get you collision avoidance, but there's no high-refresh rate 3D sensor that I know of that could make a bubble around your plane in the 0-5m range. If you were scaling up, you could use something like a Velodyne laser to do something like the equivalent, but environmental conditions would make that less than ideal without work on the software end.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Think hard about tolerances. Is it vital they be able to fly within X cm of wingtip to wingtip? Do they need to be coplanar, or would it be okay if one were, for example, +/- a meter above the other as long as they don't collide? You might also see if you have options on the navigational smarts of the planes, so that, as long as they're following their flight plans within tolerance, they are quiet, but if they are blown off course (or whatever), then they send out an alert to the other UAVs with what they know to be wrong. A differential system might be enough, though I imagine the test cycle for that will be exciting.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, do a check on Augmented GPS systems to see if someone makes a lightweight version. Most of the ones I've seen are for agricultural use, so they're more keen to make it ideal for putting on a tractor, but it's worth checking.&lt;/p&gt;&#xA;" OwnerUserId="300" LastEditorUserId="300" LastEditDate="2012-11-08T15:38:18.260" LastActivityDate="2012-11-08T15:38:18.260" CommentCount="3" />
  <row Id="298" PostTypeId="2" ParentId="128" CreationDate="2012-11-08T00:44:45.050" Score="0" Body="&lt;p&gt;In response to &quot;when/in which case&quot; real-time systems are used:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In my experience, motion control is the main application for real-time systems. For controlling motors a high frequency (100hz, 1000hz and more) and low jitter (time variations) are important. Safety is a big point here. Consider a robot among humans: For example, you want/need to ensure that the robot (arm) stops in a specific time frame/distance.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For other tasks such as path planning, vision processing and reasoning real-time system are not that important and often avoided due to the overhead in development time and hardware costs.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Nowadays, big robots such as the PR2 combine both worlds. In the real-time context of the RT enabled operating system (e.g. Linux + Xenomai) motion control is happening and in the non-real-time part (user land), vision processing and planning are embedded in systems like ROS. Both can run on the same computer.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm happy to edit this answer, once the question has been clarified. :-)&lt;/p&gt;&#xA;" OwnerUserId="90" LastActivityDate="2012-11-08T00:44:45.050" />
  <row Id="299" PostTypeId="1" AcceptedAnswerId="308" CreationDate="2012-11-08T00:59:40.857" Score="9" ViewCount="829" Body="&lt;p&gt;The forward kinematics of a robot arm can be solved easily. We can represent each joint using &lt;a href=&quot;http://en.wikipedia.org/wiki/Denavit%E2%80%93Hartenberg_parameters&quot;&gt;Denavit–Hartenberg&lt;/a&gt; transformation matrices.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, if the $i^{th}$ joint is a linear actuator, it may have the transformation matrix:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$T_i = \left[\begin{matrix}&#xA;1&amp;amp;0&amp;amp;0&amp;amp;0\\&#xA;0&amp;amp;1&amp;amp;0&amp;amp;0\\&#xA;0&amp;amp;0&amp;amp;1&amp;amp;d_i\\&#xA;0&amp;amp;0&amp;amp;0&amp;amp;1&#xA;\end{matrix} \right]$&#xA;where the extension length is defined by $d_i$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;whereas, a rotating link may be:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$T_i = \left[\begin{matrix}&#xA;1&amp;amp;0&amp;amp;0&amp;amp;L\\&#xA;0&amp;amp;\cos\alpha_i&amp;amp;-\sin\alpha_i&amp;amp;0\\&#xA;0&amp;amp;\sin\alpha_i&amp;amp;\cos\alpha_i&amp;amp;0\\&#xA;0&amp;amp;0&amp;amp;0&amp;amp;1&#xA;\end{matrix} \right]$ where $\alpha$ is the angle, and $L$ is the length of the link.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We can then find the position and orientation of the end effector by multiplying all the transformation matrices: $\prod{T_i}$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The question is, how do we solve the inverse problem?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Mathematically, for a desired end effector position $M$, find the parameters $d_i$, $\alpha_i$ such that $\prod{T_i} = M$. What methods exist to solve this equation?&lt;/p&gt;&#xA;" OwnerUserId="145" LastActivityDate="2012-11-12T03:17:31.833" Title="How can the inverse kinematics problem be solved?" Tags="&lt;inverse-kinematics&gt;&lt;kinematics&gt;&lt;joint&gt;&lt;arm&gt;" AnswerCount="2" CommentCount="1" FavoriteCount="5" />
  <row Id="300" PostTypeId="2" ParentId="271" CreationDate="2012-11-08T01:27:02.223" Score="1" Body="&lt;p&gt;You could use the gps system for long-range co-ordination, an altimeter for height, and ultra-sonic sensors for close-range co-ordination. When the planes get in to close proximity the ultrasonic sensors would work for collision prevention. The only extra weight would be ultrasonic sensors, and an altimeter.&lt;/p&gt;&#xA;" OwnerUserId="216" LastActivityDate="2012-11-08T01:27:02.223" />
  <row Id="301" PostTypeId="1" CreationDate="2012-11-08T02:30:43.450" Score="7" ViewCount="113" Body="&lt;p&gt;What's the best kind of spline that can be used for generating trajectory that can be adapted during execution time?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The use case is having a differential drive which has to move towards a point (x,y,theta) without stopping during the movement (e.g. no, turn toward the goal, straight move to the goal position, turn to the goal orientation). The robot is provided with a laser scanner for detecting dynamic obstacles which have to be avoided.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What's the best kind of controller in this case?&lt;/p&gt;&#xA;" OwnerUserId="87" LastEditorUserId="350" LastEditDate="2012-11-13T21:00:11.800" LastActivityDate="2012-11-13T21:00:11.800" Title="Which spline function would be best suited for the trajectory of a differential drive" Tags="&lt;control&gt;&lt;motion-planning&gt;" AnswerCount="1" FavoriteCount="2" />
  <row Id="302" PostTypeId="2" ParentId="255" CreationDate="2012-11-08T02:59:09.417" Score="2" Body="&lt;p&gt;Personally I feel that Parallax has a good set of offerings in this area.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For wheeled/ground prototyping, I would choose a &lt;a href=&quot;http://www.parallax.com/Store/Robots/AllRobots/tabid/755/ProductID/666/List/0/Default.aspx?SortField=ProductName,ProductName&quot; rel=&quot;nofollow&quot;&gt;Madeusa&lt;/a&gt; ($880) chassis.  This is a very good starting chassis that can carry a decent payload and is very extensible.  I've seen security guard robot prototypes and autonomous camera man robots made on top of this platform that were very impressive.  Madeusa is basically the same chassis as the Parallax Eddie but without the Propeller and PC/Kinect parts.  By removing these parts, you can substitute back in your own control system such as an Arduino based solution.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The &lt;a href=&quot;http://www.parallax.com/Store/Robots/FlyingPlatforms/tabid/964/ProductID/799/List/0/Default.aspx?SortField=ProductName,ProductName&quot; rel=&quot;nofollow&quot;&gt;ELEV-8&lt;/a&gt; ($600) chassis is a good flying platform.  I haven't tried this one myself but it has good reviews as hitting a sweet spot of cost, performance, complexity, and capability.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In all cases I'd suggest learning Arduino as your microcontroller platform for sensor and actuator integration.  Great community, low costs, high capabilities.&lt;/p&gt;&#xA;" OwnerUserId="35" LastActivityDate="2012-11-08T02:59:09.417" CommentCount="1" />
  <row Id="303" PostTypeId="2" ParentId="150" CreationDate="2012-11-08T03:04:21.043" Score="1" Body="&lt;p&gt;Take it for what it's worth, I was next to the OpenROV booth at Maker Faire and their answer was 'let it leak and dry it off later'.  They said they were surprised that water getting into the motor didn't cause issues for them.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;'course I haven't tried this myself and I may have misheard them -- or perhaps nothing had failed for them &lt;em&gt;yet&lt;/em&gt; :-)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It may be worthwhile though to start with cheap motors and see if your experience matches theirs...&lt;/p&gt;&#xA;" OwnerUserId="35" LastActivityDate="2012-11-08T03:04:21.043" />
  <row Id="304" PostTypeId="2" ParentId="209" CreationDate="2012-11-08T04:35:06.483" Score="1" Body="&lt;p&gt;Most of the straightforward ICP methods use a Least-Squares type approach. It is common and easiest to model when assuming a Gaussian error model corrupts the point cloud data. In this case the least squared fitting component of the ICP algorithm produces a Gaussian error model for its solution parameters with estimated variance. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;That is, if you have access to the error's after matching, then you can estimate a Gaussian error on your transform's parameters in the same way you'd estimate the error in any other linear regression.&lt;/p&gt;&#xA;" OwnerUserId="323" LastActivityDate="2012-11-08T04:35:06.483" CommentCount="1" />
  <row Id="305" PostTypeId="2" ParentId="262" CreationDate="2012-11-08T05:10:26.443" Score="1" Body="&lt;p&gt;Many rules of thumb and other scaling laws applicable to robots involve the mass of all or some part of the robot.&#xA;I look forward to other answers pointing out more of them.&#xA;One of the most surprising rules I've seen:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;The batteries should weigh roughly the same as everything else on the airframe combined.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;With a given aircraft -- everything known except for the mass of the batteries --&#xA;the absolute maximum flight time occurs when the weight of the batteries is twice as much as the weight of everything else on the airframe combined.&#xA;Reference: Andres 2011. &lt;a href=&quot;http://api.ning.com/files/aFMLPsgnHmZXdNMAY8PM0KekqE4uAQSMx2C%2ausF6KDpKiqpO4L9-hrUKYBsS-xtRMqo-K4GR5TPsM2Isq56oMw__/battery_capacity.pdf&quot; rel=&quot;nofollow&quot;&gt;Optimal Battery Capacity&lt;/a&gt;.&#xA;via &lt;a href=&quot;http://www.heino.com/?page_id=24443&quot; rel=&quot;nofollow&quot;&gt;Heino R. Pull&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This rule of thumb applies to all kinds of battery-powered aircraft -- fixed-wing, quadcopters, helicopters etc.&lt;/p&gt;&#xA;" OwnerUserId="187" LastActivityDate="2012-11-08T05:10:26.443" />
  <row Id="306" PostTypeId="5" CreationDate="2012-11-08T07:18:06.113" Score="0" ViewCount="5" Body="&lt;p&gt;The Raspberry Pi is a credit-card sized computer, based around a Broadcom BCM2835 (containing an ARM1176JZFS core), with floating point, running at 700Mhz, and a Videocore 4 GPU.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Currently two models are available:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Model A has 256Mb RAM, one USB port and no Ethernet (network connection).&lt;/li&gt;&#xA;&lt;li&gt;Model B  has 512Mb RAM, 2 USB port and an Ethernet port.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;There are a range of supported operating systems, which run from an SD card.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;StackExchange users may also be interested in the &lt;a href=&quot;http://raspberrypi.stackexchange.com&quot;&gt;Raspberry Pi StackExchange&lt;/a&gt; site&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Raspberry Pi is a trademark of the &lt;a href=&quot;http://www.raspberrypi.org/&quot; rel=&quot;nofollow&quot;&gt;Raspberry Pi Foundation&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="134" LastEditorUserId="134" LastEditDate="2012-11-12T03:26:01.343" LastActivityDate="2012-11-12T03:26:01.343" />
  <row Id="307" PostTypeId="4" CreationDate="2012-11-08T07:18:06.113" Score="0" Body="The Raspberry Pi is a credit-card sized general purpose computer." OwnerUserId="134" LastEditorUserId="134" LastEditDate="2012-11-12T03:26:06.647" LastActivityDate="2012-11-12T03:26:06.647" />
  <row Id="308" PostTypeId="2" ParentId="299" CreationDate="2012-11-08T10:08:15.363" Score="7" Body="&lt;p&gt;Back in the day, when I was learning, making this up as I went along, I used simple gradient following to solve the IK problem.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In your model, you try rotating each joint each joint a tiny amount, see how much difference that makes to the end point position error. Having done that, you then rotate each joint by an amount proportional to the benefit it gives. Then you do that over and over again until you're close enough.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Generally, this is known as gradient following, or hill following. Imagine a robot arm with two degrees of freedom:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/TTFq5.gif&quot; alt=&quot;IK&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Rotating joint &lt;strong&gt;A&lt;/strong&gt; a tiny bit moves the end point in direction &lt;strong&gt;a&lt;/strong&gt;. Rotating joint &lt;strong&gt;B&lt;/strong&gt; a tiny bit moves the end point in direction &lt;strong&gt;b&lt;/strong&gt;.  Both of these move us closer to the target by about the same amount, so we should rotate both joints at about the same speed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If we were to plot a graph of the distance to the target versus joint angles, it would look like this:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/t2Nv5.gif&quot; alt=&quot;IK&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have coloured in some contours just to help. We can see the path this algorithm takes. What you'll notice is that in joint space, the path taken does not look optimal. It takes a curve. However, in real space, you would see the end point taking a fairly straight line to the target. You can also see that there are actually two solutions to the problem, and the algorithm has just found the closest one.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is not the only way to solve the inverse kinematics problem. It's certainly not the best way either.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pros:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It's conceptually simple, so great if you're just learnig this.&lt;/li&gt;&#xA;&lt;li&gt;It's easy to implement, even if the sight of Denavit–Hartenberg transformation matrices gives you the frights.&lt;/li&gt;&#xA;&lt;li&gt;It's very general, allowing you to use all kinds of joints: rotary, linear, something else, as long as you can estimate how they cause the end point to move.&lt;/li&gt;&#xA;&lt;li&gt;It copes well, even when there are zero or an infinite number of solutions. &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Cons:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It's slow, taking many iterations to find the solution. However, it's fine if you can just have the real arm follow the progress of the algorithm as it's calculated.&lt;/li&gt;&#xA;&lt;li&gt;It can get stuck in local minima. I.E. It might not find the best possible solution, if it finds a good enough one.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;There are more details about it on my very old web site: &lt;a href=&quot;http://freespace.virgin.net/hugo.elias/models/m_ik2.htm&quot;&gt;The good-looking textured light-sourced bouncy fun smart and stretchy page&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-11-08T10:08:15.363" />
  <row Id="309" PostTypeId="1" CreationDate="2012-11-08T12:07:23.013" Score="8" ViewCount="492" Body="&lt;p&gt;I've been doing a lot of reading lately about &lt;a href=&quot;http://en.wikipedia.org/wiki/Subsumption_architecture&quot; rel=&quot;nofollow&quot;&gt;Subsumption Architecture&lt;/a&gt; and there are a few different ways people seem to advocate. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;For instance some people use a global &quot;flag&quot; variable to have a task take control. Others use the &lt;code&gt;endTimeSlice()&lt;/code&gt; and allow the arbiter to really choose. And I think this is correct. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have this small section of &lt;a href=&quot;http://en.wikipedia.org/wiki/Robotc&quot; rel=&quot;nofollow&quot;&gt;RobotC&lt;/a&gt; code that I'm working on for a line following robot but am not sure I am doing it right as currently the track method will always take over the find method. The correct flow should be that find should guide the robot to the line using a spiral path to find the line. Once the line is found track should take over. &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;task evade(){&#xA;    if(SensorValue(forwardSonarSensor) &amp;gt; threshold){&#xA;            //box the obstruction&#xA;    }&#xA;}&#xA;&#xA;task find(){&#xA;    if(SensorValue(lightSensor) &amp;gt; threshold){&#xA;            //spiral the robot&#xA;    }&#xA;}&#xA;&#xA;task track(){&#xA;&#xA;    if(SensorValue(lightSensor) &amp;lt; threshold){&#xA;            //go straight&#xA;    }else{&#xA;                //execute turns to follow the line&#xA;    }&#xA;}&#xA;&#xA;task main(){&#xA;    while(true){&#xA;        StartTask(evade,9);&#xA;        StartTask(track,8);&#xA;        StartTask(find,7);&#xA;        wait1Msec(250);&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I've just used some comments here rather than the actual code to keep it brief. Are my if statements not good enough as conditions because when the robot is off the line, &lt;code&gt;track()&lt;/code&gt; takes over. Is this due to the else statement within track? If so, how to have &lt;code&gt;track()&lt;/code&gt; perform turns when it looses the line without taking over from forage at the start of the program? &lt;/p&gt;&#xA;" OwnerUserId="349" LastEditorUserId="132" LastEditDate="2012-11-13T19:00:50.403" LastActivityDate="2012-11-13T19:00:50.403" Title="Correct way to use Subsumption Architecture with Robot C" Tags="&lt;mobile-robot&gt;&lt;software&gt;&lt;two-wheeled&gt;&lt;robotc&gt;" AnswerCount="2" CommentCount="1" FavoriteCount="1" />
  <row Id="310" PostTypeId="2" ParentId="213" CreationDate="2012-11-08T12:26:42.660" Score="3" Body="&lt;p&gt;Many recent Android devices, such as the Nexus 7, support USB On The Go (OTG) which is a fancy way of saying that 'USB Host Mode' is supported.  In these cases, with the right cable which can be had for less than $1, any compatible USB device can be used.  You don't need a specialty version of the Arduino that has hardware for USB Host mode.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've experimented with this enough to know that a 'normal' Arduino such as the Leonardo or Teensy 2 appears to an Android phone as a TTY (e.g. serial port) device when connected with an OTG cable.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://android.serverbox.ch/?p=549&quot; rel=&quot;nofollow&quot;&gt;This article&lt;/a&gt; goes into depth on how to use the Android USB Host API to communicate to the Arduino from an Android app.  It requires Android 3.1+ and does not require you to root the device.&lt;/p&gt;&#xA;" OwnerUserId="35" LastActivityDate="2012-11-08T12:26:42.660" />
  <row Id="311" PostTypeId="2" ParentId="128" CreationDate="2012-11-08T12:46:30.213" Score="2" Body="&lt;p&gt;Start thinking about your robot in terms of multiple CPUs and the real time question shifts.  If you have an algorithm that needs high speed reliable feedback such as a two wheel balancer or a quad-copter stabilizer or a servo pulse out, real time is extremely important, but the task is also very constrained.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can offload a control loop like this to a dedicated real time CPU such as the cheap 8 bit AVR or low end 32 bit ARMs found in the Arduino class of devices.  There's nothing preventing you from adding many dozens of these small MCUs running dedicated control loops, USB device enumeration even makes this easy.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now that you have the timing sensitive control loops handled by a dedicated CPU, you can relax the real time needs of the 'brain' of the robot which can run higher end logic using components such as ROS on Linux or Kinect for Windows.&lt;/p&gt;&#xA;" OwnerUserId="35" LastActivityDate="2012-11-08T12:46:30.213" />
  <row Id="312" PostTypeId="2" ParentId="237" CreationDate="2012-11-08T12:55:36.627" Score="4" Body="&lt;p&gt;I'd suggest two possible approaches.&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;Use a 'heartbeat' to transfer a well known state packet at a fixed frequency that fits within your 'speed budget'.  In this case, you never send ad hoc messages directly from the PC or MCU, all you can do is update the state packet which will be sent at the scheduled time.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Put a hard limit on your 'transmission budget' and enforce it.  E.g. you can only send one packet every 100 ms and if a 2nd packet is submitted before 100 ms has expired, its transmission is delayed until the 100 ms timeout (e.g. quantum) has expired.  This requires you to add messages to a queue and then send from the queue at a fixed rate.  Similar in approach to the heartbeat in #1 but a bit more efficient since data isn't sent when it hasn't changed.  The downside of this design is if you are oversending, you build higher and higher latencies into your communications and if you have variable bursty communication the communications latency can vary widely.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;I tend to work with #1 to send data from the MCU since the algorithm is simple and small.&lt;/p&gt;&#xA;" OwnerUserId="35" LastActivityDate="2012-11-08T12:55:36.627" />
  <row Id="313" PostTypeId="2" ParentId="150" CreationDate="2012-11-08T13:15:23.520" Score="6" Body="&lt;p&gt;If you're looking for a very cheap way to do it (as in, educational budget cheap), check out the &lt;a href=&quot;http://seaperch.mit.edu/docs/seaperch-build-october2011.pdf&quot; rel=&quot;nofollow&quot;&gt;Sea Perch ROV build manual&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Full disclosure, I used to work at the MIT lab that heads up this educational program.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On page 9 of that PDF it starts talking about how to waterproof a hobby motor with a film canister and toilet bowl wax.  The entire housing remains submerged and we've taken it to 20 or 30 foot depths in some cases.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.flickr.com/photos/mitauvlab/5489472176/sizes/l/in/set-72157626049644099/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://farm6.staticflickr.com/5212/5489472176_8dd00b928b_b.jpg&quot; alt=&quot;Potted Hobby Motor&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The build is actually pretty straightforward; we help a lot of junior high and high school kids make these and I can't remember an incident where the seal turned out to be unreliable.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="37" LastEditDate="2013-05-30T17:35:25.643" LastActivityDate="2013-05-30T17:35:25.643" CommentCount="1" />
  <row Id="314" PostTypeId="2" ParentId="230" CreationDate="2012-11-08T13:17:03.553" Score="5" Body="&lt;p&gt;Robotics is hard enough as it is when all your dependencies are working.  The last thing you need are additional problems coming from incompatible components or unsupported combinations.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I looked into this a little and here was my progression:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Raspberry Pi doesn't support Ubuntu because it's ARM CPU uses an older instruction set (ARM v6 I believe?) and the Ubuntu team dropped support for this back in like 2009.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Beaglebone is similar to a Raspberry Pi in many ways and has a newer instruction set so it will run Ubuntu.  However the 'best' Ubuntu ARM distribution is coming out of the Linaro project and they dropped support for the Beaglebone a few revisions back (last was Linaro 12.03) because it's using an older TI OMAP 3 processor (welcome to the wonderful world of rapid smartphone progress).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My next step was to look at the TI Pandaboard which uses the newer OMAP 4 processor that is currently supported, but it costs closer to the $200 range.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But now Ubuntu officially released for the Nexus 7.  At 200 dollars, the Nexus 7 gets you everything a Raspberry Pi offers plus a lot more.  Keep in mind that even with a Raspberry Pi, once you add in the charger, wifi adapter, storage card, and cables you're creeping up closer to 100 dollars than 35 dollars so imho the Nexus 7 is a much better deal.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Lastly, don't try and output a 1 khz signal out of a non real time OS.  Attach yourself a cheap microcontroller like the PJRC Teensy (Arduino clone) and let it handle the simple real time tasks for you.  This way you dedicate the inexpensive CPU to these simple time sensitive tasks.  At 16 MHz with support for multiple timers, a little AVR MCU can handle a half dozen tasks like this without issue.&lt;/p&gt;&#xA;" OwnerUserId="35" LastActivityDate="2012-11-08T13:17:03.553" CommentCount="1" />
  <row Id="315" PostTypeId="2" ParentId="172" CreationDate="2012-11-08T13:27:13.290" Score="1" Body="&lt;p&gt;You're asking how to use an acceleration sensor to make better position measurements.  As you've correctly pointed out, these accumulate error over time.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One way to improve this is to have periodic absolute-position updates, like from GPS, or from the techniques in many of the answers here.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, don't overlook any abilities you may have to get absolute-velocity updates.  Any speed-over-ground sensor, or just the raw position/velocity data from the wheels (if you have wheels) can improve your dead reckoning accuracy.  &lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2012-11-08T13:27:13.290" />
  <row Id="316" PostTypeId="2" ParentId="215" CreationDate="2012-11-08T13:36:39.213" Score="3" Body="&lt;p&gt;I'd suggest using kits to get you started.  There are excellent resources today that will quickly get you enough confidence and knowledge to built great robots.  I'd stick with as 'mainstream' technologies as you can in order to maximize what you can learn from others.  The most mainstream microcontroller you could choose is the Arduino Uno, perhaps its newer replacement the Arduino Leonardo.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.makershed.com/Getting_Started_with_Arduino_Kit_V3_0_p/msgsa.htm&quot; rel=&quot;nofollow&quot;&gt;Make's Getting Started with Arduino&lt;/a&gt; plus &lt;a href=&quot;http://www.makershed.com/MakerShield_p/msms01.htm&quot; rel=&quot;nofollow&quot;&gt;Maker Shield&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This gets you the documentation, microcontroller, electronics, and your first few projects to get started with.  The documentation is excellent and takes you from very beginning to enough knowledge to do your own projects.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Add some electronics background by getting the &lt;a href=&quot;http://www.makershed.com/product_p/9780596153748.htm&quot; rel=&quot;nofollow&quot;&gt;Make Electronics&lt;/a&gt; book with the matching &lt;a href=&quot;http://www.makershed.com/Make_Electronics_Components_Pack_1_p/mecp1.htm&quot; rel=&quot;nofollow&quot;&gt;Components Pack 1&lt;/a&gt; so you can do the projects in the book.  This will get you familiar enough to add blinky lights and simple sensors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then get your tooklit basics, such as the &lt;a href=&quot;http://www.adafruit.com/products/136&quot; rel=&quot;nofollow&quot;&gt;Ladyada's Electronics Toolkit&lt;/a&gt;.  Your first step up from this should be a better soldering iron such as the &lt;a href=&quot;http://rads.stackoverflow.com/amzn/click/B000BRC2XU&quot; rel=&quot;nofollow&quot;&gt;Weller WES51&lt;/a&gt; once you've done enough projects to know why you need it :-)&lt;/p&gt;&#xA;" OwnerUserId="35" LastActivityDate="2012-11-08T13:36:39.213" />
  <row Id="317" PostTypeId="1" CreationDate="2012-11-08T13:41:39.337" Score="3" ViewCount="118" Body="&lt;p&gt;I have built a few simple X/Y/Z CNC machines.  I've learned about G-Code, motor control, firmware and open loop systems.  I see machines like rovers, big dog and factory arms that seem incredibly complex by comparison, yet they don't seem that magical any more.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What are the important skills to pick up from working with CNC machines?  What's the next logical thing to learn?  What things would CNC machines never teach me?&lt;/p&gt;&#xA;" OwnerUserId="208" LastEditorUserId="350" LastEditDate="2012-11-30T14:24:45.093" LastActivityDate="2012-11-30T14:24:45.093" Title="How much can working with CNC machines teach you about robotics?" Tags="&lt;control&gt;" AnswerCount="2" CommentCount="2" />
  <row Id="318" PostTypeId="2" ParentId="46" CreationDate="2012-11-08T13:44:14.723" Score="5" Body="&lt;p&gt;Lithium Ion Polymer batteries are probably your best bet.  &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;They will present the least amount of magnetic interference (followed by Alkaline... NiCD interferes the most).  &lt;/li&gt;&#xA;&lt;li&gt;Unlike the regular lithium ion cells (which are usually round), these ones will stack nicely.  &lt;/li&gt;&#xA;&lt;li&gt;I hope you'll check the manual before trying this -- many of them are pressure tolerant.  I know of some AUV labs that just put stacks of cellphone-sized batteries into rectangular boxes filled with oil (for pressure compensation) and go with it.  For example, Autosub 6000's battery packs -- depth-rated to 6000 meters, without the aid of a cylindrical or spherical pressure housing:&#xA;&lt;img src=&quot;http://i.stack.imgur.com/dxHKf.jpg&quot; alt=&quot;Pressure Compensated Battery Pack&quot;&gt;&#xA;(http://www.thesearethevoyages.net/jc44/autosub6000_page1.html).&#xA;For other battery technologies, you'll have to decide how to pack them into your pressure housing, which may be a bit more complicated.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2012-11-21T17:02:53.280" LastActivityDate="2012-11-21T17:02:53.280" />
  <row Id="319" PostTypeId="2" ParentId="317" CreationDate="2012-11-08T14:33:27.223" Score="9" Body="&lt;p&gt;Building CNC equipment may teach you:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Motor control&lt;/li&gt;&#xA;&lt;li&gt;Kinematics and coordinated movement&lt;/li&gt;&#xA;&lt;li&gt;How to choose motors for a given load&lt;/li&gt;&#xA;&lt;li&gt;Mechanical movement (torque, moment, etc)&lt;/li&gt;&#xA;&lt;li&gt;Simple electronics&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Running CNC equipment may teach you:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Software control of hardware&lt;/li&gt;&#xA;&lt;li&gt;Timing (at least on the gross level)&lt;/li&gt;&#xA;&lt;li&gt;Feedback&lt;/li&gt;&#xA;&lt;li&gt;Hardware error detection and recovery&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;While the fields are different, very broadly speaking CNC machines are merely robots.  The reverse is true.  Due to their specific use there's different terminology and typically different control and usage schemes and scenarios, but at the end of the day you are moving things under electronic, and often autonomous, control.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Even today's high speed circuit board assembly machines use computer vision in complex ways similar to today's advanced robotics.  You'll find that the two fields share most things in common such that everything you learn in one will apply to the other in some way.&lt;/p&gt;&#xA;" OwnerUserId="356" LastActivityDate="2012-11-08T14:33:27.223" />
  <row Id="320" PostTypeId="2" ParentId="262" CreationDate="2012-11-08T15:28:38.840" Score="1" Body="&lt;p&gt;Practical point of view: Traction of wheel&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Traction of the wheel (friction between wheel and surface) is proportional to the mass of the robot. Small mobile robots with low mass can have low wheel traction, and can easily slip on the surface, friction co-efficient of the wheel and surface area of contact between wheel and surface. Even if the wheel slippage is not too much, even small slippage can make big difference in accumulating odometer error.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Summarizing, higher the mass of the robot, better is the traction of wheel with surface.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The type of wheel/tire will be one of the important design consideration as the mass of robot varies. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I wasted lots of time trying to make a mobile robot (differential drive with 2 driven wheels + caster wheel, size around 10x15cm, mass &amp;lt; 1 kg) follow specified trajectory, and get proper odometer data. It had hard plastic wheel with rubber band tire. In normal operation slippage was barely noticeable and used slip at every small variation on floor. It also used to get stuck easily at small obstacles. Even though the motor had lots of torque, wheels used to just spin in place, due to lack of sufficient traction. At one point I added lots of deadweight to improve the traction.  &lt;/p&gt;&#xA;" OwnerUserId="289" LastEditorUserId="289" LastEditDate="2012-11-08T15:34:41.243" LastActivityDate="2012-11-08T15:34:41.243" />
  <row Id="321" PostTypeId="2" ParentId="112" CreationDate="2012-11-08T17:06:45.933" Score="0" Body="&lt;p&gt;If you are not near the robot but require an e-stop, you'll want to consider a watchdog circuit watching a remote signal. The circuit keeps an eye out for a pulsing signal and, if the signal stops pulsing, activates the e-stop circuitry. You want to have this as close to a physical circuit as you can, which means the pulse can't be interpreted by a computer nor a microcontroller, because either of those are likely to have failure states that will prevent them from adequately actuating the e-stop.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As many of the other answers are stating, the ideal e-stop is one in which any failure mode will cause an emergency stop, which means that the laws of physics are doing most of the work of the e-stopping, rather than something resembling software. Of course, trying to interpret that stop correctly depends greatly on what the robot is meant to do and the consequences of it stopping that action, but failure of an e-stop system should not ensure that your robot keeps running.&lt;/p&gt;&#xA;" OwnerUserId="300" LastActivityDate="2012-11-08T17:06:45.933" />
  <row Id="322" PostTypeId="2" ParentId="299" CreationDate="2012-11-08T18:25:05.147" Score="3" Body="&lt;p&gt;There a number of solutions to this problem that center around the Jacobian Matrix. This &lt;a href=&quot;http://billbaxter.com/courses/290/html/img0.htm&quot; rel=&quot;nofollow&quot;&gt;slideshow&lt;/a&gt; covers the Jacobian methods and also mentions a Cyclic Coordinate Descent method, which I am unfamiliar with. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are a plethora of resources on the subject - if you ask google for &lt;a href=&quot;https://www.google.com/search?q=%22inverse%20kinematics%20Jacobian%22&quot; rel=&quot;nofollow&quot;&gt;&quot;inverse kinematics Jacobian&quot;&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, check out Chapter 5.3 of the lecture notes from M&lt;a href=&quot;http://ocw.mit.edu/courses/mechanical-engineering/2-12-introduction-to-robotics-fall-2005/&quot; rel=&quot;nofollow&quot;&gt;IT's Open Course on Introductory Robotics&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="366" LastEditorUserId="37" LastEditDate="2012-11-12T03:17:31.833" LastActivityDate="2012-11-12T03:17:31.833" />
  <row Id="323" PostTypeId="1" AcceptedAnswerId="326" CreationDate="2012-11-08T19:23:49.510" Score="3" ViewCount="93" Body="&lt;p&gt;Is anyone able to help me out getting IPC-bridge working on my ubuntu lucid installation (with matlab 2012a)? I'm not being able to finish the last step on here (Compiling the messages folders): &lt;a href=&quot;https://alliance.seas.upenn.edu/~meam620/wiki/index.php?n=Roslab.IpcBridge#Installation&quot; rel=&quot;nofollow&quot;&gt;https://alliance.seas.upenn.edu/~meam620/wiki/index.php?n=Roslab.IpcBridge#Installation&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm able to rosmake the ipc_bridge_ros, however when i enter this &quot;roscd ipc_roslib &amp;amp;&amp;amp; make&quot;, it seems meX does not recognize the commands. Here is what i get (screen shot): &lt;a href=&quot;http://img13.imageshack.us/img13/6031/screenshot20121108at191.png&quot; rel=&quot;nofollow&quot;&gt;http://img13.imageshack.us/img13/6031/screenshot20121108at191.png&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;NOTE: i'm going to use IPC-bridge so that i can control a pioneer 3DX and implement a Fast-slam algorithm in matlab.&lt;/p&gt;&#xA;" OwnerUserId="370" LastActivityDate="2012-11-08T20:37:15.223" Title="IPC-Bridge problem" Tags="&lt;mobile-robot&gt;&lt;software&gt;&lt;slam&gt;&lt;ros&gt;" AnswerCount="1" FavoriteCount="1" />
  <row Id="324" PostTypeId="2" ParentId="255" CreationDate="2012-11-08T19:41:14.950" Score="0" Body="&lt;p&gt;&lt;a href=&quot;http://www.parallax.com/&quot; rel=&quot;nofollow&quot;&gt;Parralax&lt;/a&gt; offers a number of kits that are relatively cheap and extensible.&lt;/p&gt;&#xA;" OwnerUserId="366" LastActivityDate="2012-11-08T19:41:14.950" />
  <row Id="325" PostTypeId="2" ParentId="172" CreationDate="2012-11-08T20:34:35.127" Score="2" Body="&lt;p&gt;&lt;a href=&quot;http://www.locatacorp.com/&quot; rel=&quot;nofollow&quot;&gt;http://www.locatacorp.com/&lt;/a&gt; might be the solution you are looking for. They offer technology  to create a local constellation indoor. It emulates the satellites for indoor GPS applications. I believe it can use GPS receivers indoor without the need for additional hardware on the robots.&lt;/p&gt;&#xA;" OwnerUserId="272" LastActivityDate="2012-11-08T20:34:35.127" />
  <row Id="326" PostTypeId="2" ParentId="323" CreationDate="2012-11-08T20:37:15.223" Score="2" Body="&lt;p&gt;That script is calling &quot;mex&quot; but it's getting pdfTex &quot;mex&quot; tool instead of the Matlab compiler.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Before running that script you need to adjust your &lt;code&gt;PATH&lt;/code&gt; environment variable to put the Matlab binaries before your system ones.  Assuming your Matlab binaries are located in &lt;code&gt;/opt/matlab/bin&lt;/code&gt; that would look something like this:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;export PATH=/opt/matlab/bin:$PATH&#xA;roscd ipc_roslib &amp;amp;&amp;amp; make&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="20" LastActivityDate="2012-11-08T20:37:15.223" CommentCount="1" />
  <row Id="327" PostTypeId="1" AcceptedAnswerId="333" CreationDate="2012-11-08T23:07:14.817" Score="5" ViewCount="513" Body="&lt;p&gt;I'm building a 4 legged robot (quadruped) with 3 Degrees of freedom per leg.&#xA;The goal of my project is to make this robot able to learn how to walk.&#xA;What learning algorithms will I need to implement for it to work?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm using an &lt;a href=&quot;http://www.arduino.cc/&quot; rel=&quot;nofollow&quot;&gt;Arduino Uno&lt;/a&gt; for the microcontroller.&lt;/p&gt;&#xA;" OwnerUserId="374" LastEditorUserId="177" LastEditDate="2012-11-13T20:59:50.960" LastActivityDate="2013-06-12T17:54:05.187" Title="Learning Algorithms for Walking Quadruped" Tags="&lt;microcontroller&gt;&lt;arduino&gt;&lt;machine-learning&gt;" AnswerCount="5" CommentCount="3" FavoriteCount="5" />
  <row Id="328" PostTypeId="2" ParentId="327" CreationDate="2012-11-09T01:57:37.823" Score="5" Body="&lt;p&gt;Here's a paper that seems relevant: &lt;a href=&quot;http://www.cs.utexas.edu/~pstone/Papers/bib2html/b2hd-icra04.html&quot; rel=&quot;nofollow&quot;&gt;Policy Gradient Reinforcement Learning for Fast Quadrupedal Locomotion&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;This paper presents a machine learning approach to optimizing a quadrupedal trot gait for forward speed. Given a parameterized walk designed for a specific robot, we propose using a form of policy gradient reinforcement learning to automatically search the set of possible parameters with the goal of finding the fastest possible walk. We implement and test our approach on a commercially available quadrupedal robot platform, namely the Sony Aibo robot. After about three hours of learning, all on the physical robots and with no human intervention other than to change the batteries, the robots achieved the fastest walk known for the Aibo, significantly outperforming a variety of existing hand-coded and learned solutions.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="36" LastEditorUserId="36" LastEditDate="2013-06-12T17:54:05.187" LastActivityDate="2013-06-12T17:54:05.187" CommentCount="2" />
  <row Id="329" PostTypeId="2" ParentId="230" CreationDate="2012-11-09T02:08:29.410" Score="2" Body="&lt;p&gt;&lt;a href=&quot;http://www.ros.org/wiki/ROSberryPi/Setting%20up%20ROS%20on%20RaspberryPi&quot; rel=&quot;nofollow&quot;&gt;Yes it does&lt;/a&gt;, but installing ROS on Debian is do-able, yet not trivial.&lt;/p&gt;&#xA;" OwnerUserId="36" LastActivityDate="2012-11-09T02:08:29.410" />
  <row Id="330" PostTypeId="2" ParentId="39" CreationDate="2012-11-09T02:22:33.050" Score="1" Body="&lt;p&gt;There may be software differences, depending on how you connect to the device. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;On Linux, &lt;code&gt;freenect&lt;/code&gt; seems to work better with Kinect than Xtion, while &lt;code&gt;openni&lt;/code&gt; tries to support both, but seems rather buggy, lately.&lt;/p&gt;&#xA;" OwnerUserId="36" LastActivityDate="2012-11-09T02:22:33.050" />
  <row Id="331" PostTypeId="1" CreationDate="2012-11-09T02:34:15.060" Score="2" ViewCount="120" Body="&lt;p&gt;We are using a Koro robot for our PC based automation solution. But sometimes the robot is getting the command but refuses to respond. Then I get a serial communication timeout error. The error is happening for a random type of commands and it is also not happening all the time making the troubleshooting difficult.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I doubt the driver problem. How do you approach this problem.?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks&lt;/p&gt;&#xA;" OwnerUserId="377" LastActivityDate="2012-11-20T00:59:16.667" Title="Robot Serial Communication Error" Tags="&lt;logic-control&gt;" AnswerCount="2" CommentCount="4" />
  <row Id="332" PostTypeId="2" ParentId="331" CreationDate="2012-11-09T06:34:56.977" Score="4" Body="&lt;p&gt;Welcome to Robotics... Hopefully, this will give you some pointers, although your situation is not easy to debug remotely :)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Things to consider (and I appreciate its a non-repeatable problem):&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Does it only happen when battery levels are low, or also with full charge (voltage low)&lt;/li&gt;&#xA;&lt;li&gt;Does it only happen when the robot is active, or also from stationary (processor overload)&lt;/li&gt;&#xA;&lt;li&gt;What else is the control PC doing? (PC overload)&lt;/li&gt;&#xA;&lt;li&gt;Have you checked that the comms link is correct (voltage levels, numbers of bits, protocol etc) - Check with an oscilloscope.&lt;/li&gt;&#xA;&lt;li&gt;Noise interference (EMC) if the motors are active&lt;/li&gt;&#xA;&lt;li&gt;Can you log what is received at the robot?&lt;/li&gt;&#xA;&lt;li&gt;Is the receive buffer on the robot big enough for the biggest command sequence? (buffer overflow)&lt;/li&gt;&#xA;&lt;li&gt;Have you checked the cable, both for continuity and that it isn't loose.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;As things stand, it is difficult to be able to determine...&lt;/p&gt;&#xA;" OwnerUserId="134" LastEditorUserId="134" LastEditDate="2012-11-09T07:34:28.567" LastActivityDate="2012-11-09T07:34:28.567" CommentCount="3" />
  <row Id="333" PostTypeId="2" ParentId="327" CreationDate="2012-11-09T07:42:09.500" Score="8" Body="&lt;p&gt;There are a number of things to consider for your project. Since you are asking for the learning algorithms, I asume your hardware is or will be up and running. When getting your robot to learn, you should differentiate between on-line and off-line learning. Further, there is on-system and off-sytem learning, which can be combined with the previous category. Since your system only has a micro-controller attached to it, your method of choice would be off-system. You learn (be it on-line or off-line) on your connected PC, but not on the system. The system will just execute your current learned policy. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;All gait movements have some sort of cyclic nature, and can generally be described as functions that provide an angular value over time for each of the joints. The trick is to parametrize these functions that you come out with as little parameters as possible. Then you perform optimization on these functions. In order to do that you need to know what to optimize for. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Most learning approaches will require some sort of reward function, so effectively some feedback to the algorithm to tell it how well it does perform (e.g. maximise distance travelled/energy required). The algorithm will then want to see the reward for a given set of parameters (single episode). Depending on the complexity of your problem, the number of episodes might be quite large. This is where the destinction between on-line and off-line learning comes in. In off-line learning you use a simulation to perform the learning and then later move it to the system. In on-line learning you learn directly on the system. This is generally more difficult, since you will have to spend a lot of time performing evaluations for the learning algorithm. &lt;/p&gt;&#xA;" OwnerUserId="127" LastActivityDate="2012-11-09T07:42:09.500" CommentCount="1" />
  <row Id="334" PostTypeId="2" ParentId="274" CreationDate="2012-11-09T09:06:23.637" Score="1" Body="&lt;p&gt;With a bit of additional research I have found one other project very similar to the OpenServo project. They are called supermodified servos. Some of the web sources are not available anymore, but there is the source for the project, which is quite advanced on google code and on github:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://code.google.com/p/zosupermodified/&quot; rel=&quot;nofollow&quot;&gt;zosupermodified&lt;/a&gt; - source code for the controller&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://github.com/jandetlefsen/Supermodified-Servo&quot; rel=&quot;nofollow&quot;&gt;Supermodified-Servo&lt;/a&gt; - eagle files&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="127" LastActivityDate="2012-11-09T09:06:23.637" />
  <row Id="335" PostTypeId="2" ParentId="39" CreationDate="2012-11-09T10:06:13.563" Score="7" Body="&lt;p&gt;You might also consider the &lt;a href=&quot;https://leapmotion.com/&quot;&gt;Leap Motion&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/U52Ny.jpg&quot; alt=&quot;Leap Motion&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It's got amazing resolution, and the ability to pick out individual fingers at an amazing update rate.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/8fNK7.jpg&quot; alt=&quot;Leap Motion&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And is even fine enough to allow you to write in the air with a pencil:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/yQI9B.jpg&quot; alt=&quot;Leap Motion Pencil&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can't buy one yet, but they'll be available soon.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-11-09T10:06:13.563" CommentCount="1" />
  <row Id="337" PostTypeId="2" ParentId="309" CreationDate="2012-11-09T14:36:48.600" Score="5" Body="&lt;p&gt;With Subsumption Architecture, you should carefully design your behaviors in such a way that if you assign task &lt;code&gt;T&lt;/code&gt; priority &lt;code&gt;n&lt;/code&gt;, then &lt;code&gt;T&lt;/code&gt; should be what the robot should do if all tasks with higher priority than &lt;code&gt;n&lt;/code&gt; are ignored.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Let's order your example tasks, then figure out a way to implement it. Your tasks are &lt;code&gt;evade&lt;/code&gt;, &lt;code&gt;find&lt;/code&gt; and &lt;code&gt;track&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In general you would want the robot to track a line. However, if it couldn't detect the line, then it should try to find it. Above all, it should evade obstacles. This gives us the following ordering:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Highest priority: &lt;code&gt;evade&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Then: &lt;code&gt;find&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Then: &lt;code&gt;track&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The reason &lt;code&gt;find&lt;/code&gt; has higher priority than &lt;code&gt;track&lt;/code&gt; is that, as I mentioned above, you would &lt;code&gt;track&lt;/code&gt; only if &lt;code&gt;evade&lt;/code&gt; and &lt;code&gt;find&lt;/code&gt; are unnecessary. If you put &lt;code&gt;find&lt;/code&gt; below &lt;code&gt;track&lt;/code&gt;, that means you start tracking if there is no obstacle, even if you are not on the line.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now let's look at your implementation:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;task find(){&#xA;    if(SensorValue(lightSensor) &amp;gt; threshold){&#xA;            //spiral the robot&#xA;    }&#xA;}&#xA;&#xA;task track(){&#xA;&#xA;    if(SensorValue(lightSensor) &amp;lt; threshold){&#xA;            //go straight&#xA;    }else{&#xA;                //execute turns to follow the line&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Remember that we gave &lt;code&gt;find&lt;/code&gt; a higher priority. Therefore, if the robot cannot sense the &lt;code&gt;lightSensor&lt;/code&gt;, it will go in spiral trying to find the line. Once it does, &lt;code&gt;track&lt;/code&gt; kicks in. As you can see, the &lt;code&gt;else&lt;/code&gt; condition of &lt;code&gt;track&lt;/code&gt; never happens.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;While this works, the robot would move very awkwardly. There is not much you can do about it in fact, given the current build of your robot.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Although I already answered your question, but here is a simple improvement to your line tracking:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Instead of one light sensor, use two; &lt;code&gt;ls_left&lt;/code&gt; and &lt;code&gt;ls_right&lt;/code&gt;. Using (at least) two sensors, you can understand whether you are totally out of the track, or about to go out of the track. In the second case, you can easily turn to the proper direction and get back on track.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Your &lt;code&gt;find&lt;/code&gt; task is similar:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;task find(){&#xA;    if (SensorValue(ls_left) &amp;gt; threshold&#xA;        &amp;amp;&amp;amp; Sensorvalue(ls_right) &amp;gt; threshold){&#xA;            //spiral the robot&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;That is, you go in spiral only if you don't sense anything at all&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Your &lt;code&gt;track&lt;/code&gt; task now becomes more efficient:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;task track(){&#xA;&#xA;    if (SensorValue(ls_left) &amp;lt; threshold&#xA;        &amp;amp;&amp;amp; SensorValue(ls_right) &amp;lt; threshold){&#xA;            //go straight&#xA;    } else if (SensorValue(ls_left) &amp;lt; threshold&#xA;        &amp;amp;&amp;amp; SensorValue(ls_right) &amp;gt; threshold){&#xA;            //turn left&#xA;    } else if (SensorValue(ls_left) &amp;gt; threshold&#xA;        &amp;amp;&amp;amp; SensorValue(ls_right) &amp;lt; threshold){&#xA;            //turn right&#xA;    } else {&#xA;            // shouldn't happen, but go on spiral anyway&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Obviously, with a matrix of light sensors, you can better judge how badly you are going out of track (i.e. with what angle) and better decide how to get back on track (i.e. with what angular speed).&lt;/p&gt;&#xA;" OwnerUserId="158" LastActivityDate="2012-11-09T14:36:48.600" />
  <row Id="338" PostTypeId="1" CreationDate="2012-11-09T20:28:01.317" Score="0" ViewCount="46" Body="&lt;p&gt;I have a platform with two tracks and two motors. Each one uses an electronic speed control with &quot;double tap to reverse&quot;. Each ESC takes an input pulse train frequency from at 1500 neutral +/-700.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;I'm interested in learning if there are algorithms or a list of commands I can use to control how such platform executes maneuvers.&lt;/strong&gt; For example:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Lock one thread and have the platform rotate by using the other one&lt;/li&gt;&#xA;&lt;li&gt;Have two treads rotate in opposite directions&lt;/li&gt;&#xA;&lt;li&gt;Execute a U turn&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;I'm struggling with expressing in code how such maneuvers should be executed. There's a &quot;dead&quot; zone around the 1500 pulse train frequency where the ESC output is too weak to cause the platform to move. The double tap to reverse also makes it tough to understand for how long each track should be turned off.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thank you for your input&lt;/p&gt;&#xA;" OwnerUserId="390" LastEditorUserId="350" LastEditDate="2012-11-30T14:21:48.713" LastActivityDate="2012-11-30T14:21:48.713" Title="Is there a list of maneuvers related to control of a tracked platform?" Tags="&lt;control&gt;&lt;motion-planning&gt;&lt;tracks&gt;" AnswerCount="1" CommentCount="3" />
  <row Id="339" PostTypeId="2" ParentId="44" CreationDate="2012-11-09T21:54:41.913" Score="6" Body="&lt;h1&gt;There is no right answer.&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;However, I think I can clarify what you've read so far.  You need a buoyancy engine to supply the thrust, wings to direct that thrust, and some ability to change your pitch angle when you change the buoyancy.  So, you'll need to balance the strength of your engine with the drag created by your wings.  At the same time, your wings need to be big enough to convert vertical forces of buoyancy into horizontal motion.  (Generally, the shallower depths you work with, the less power your buoyancy engine will require.)  &lt;/p&gt;&#xA;&#xA;&lt;h1&gt;Existing Gliders&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;This is a complex problem, and the existing solutions to it vary wildly.  &lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Seaglider&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;The Seaglider AUV (built at the University of Washington, now owned by iRobot) is shaped to achieve laminar flow.  The antenna attaches at the back, allowing the vehicle to communicate while pointing nose-down at the surface.  It has no external moving parts; all control is done by shifting weight internally.&#xA;&lt;img src=&quot;http://www.seaglider.washington.edu/graphics/glider-inpieces.jpg&quot; alt=&quot;Seaglider, in pieces&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Spray&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;The Spray Glider (built at Scripps Institute of Oceanography, now owned by Bluefin) is a more cylindrical shape.  The antenna is located in one of the wings, and the vehicle lays on its side on the surface to communicate.&lt;br&gt;&#xA;&lt;img src=&quot;http://auvac.org/uploads/configuration/spray.jpg&quot; alt=&quot;Spray Glider&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Slocum Gliders&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Slocum gliders go for a cylindrical shape that's more suited to the pressure housing.  They have an electric powered version, but the real magic is in their more modern &quot;thermal glider&quot; -- they take advantage of the fact that pressure increases with depth but temperature decreases with depth to make an engine that requires no (or very little) electrical input.  Like Seaglider, the antenna is in the tail.&#xA;&lt;img src=&quot;http://marine.rutgers.edu/cool/glider/webpage/PartsOfGlider.jpg&quot; alt=&quot;Slocum Glider&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Liberdade XRAY&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;The Liberdade XRAY is shaped like a flying wing and (to my knowledge) is actually the fastest autonomous underwater glider ever made.  It's more for naval use than scientific use -- it tracks submarines.&#xA;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/commons/3/38/Liberdade_XRay_underwater_glider.jpg&quot; alt=&quot;Liberdade XRAY&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;h1&gt;Approaching the problem (from scratch)&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;If you can't find a hydrodynamics expert to help (which would be the best option), I would suggest starting with your buoyancy engine and working outward.&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Figure out how much buoyancy your engine can create&lt;/li&gt;&#xA;&lt;li&gt;Figure out how much power your engine requires&lt;/li&gt;&#xA;&lt;li&gt;Decide how large of a battery you'll need -- this will be a significant proportion of total weight&lt;/li&gt;&#xA;&lt;li&gt;Explore your ability to trim your vehicle (likely by moving the battery fore and aft) and calculate the pitch angles you'll be able to produce&lt;/li&gt;&#xA;&lt;li&gt;Repeat steps 1-4 as necessary&lt;/li&gt;&#xA;&lt;li&gt;Make a prototype shape, make its buoyancy half of what the engine can produce (minus a little for safety).  Then drag it to the bottom of a pool and see what happens.&lt;/li&gt;&#xA;&lt;li&gt;Repeat steps 1-6 as necessary&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2012-11-10T17:26:36.283" LastActivityDate="2012-11-10T17:26:36.283" CommentCount="3" />
  <row Id="340" PostTypeId="2" ParentId="167" CreationDate="2012-11-09T22:31:56.087" Score="4" Body="&lt;p&gt;A similar experimental method to hauptmech's answer that I was taught in college:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Set all gains to 0.&lt;/li&gt;&#xA;&lt;li&gt;Increase &lt;i&gt;K&lt;sub&gt;d&lt;/sub&gt;&lt;/i&gt; until the system oscillates.&lt;/li&gt;&#xA;&lt;li&gt;Reduce &lt;i&gt;K&lt;sub&gt;d&lt;/sub&gt;&lt;/i&gt; by a factor of 2-4.&lt;/li&gt;&#xA;&lt;li&gt;Set &lt;i&gt;K&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt; to about 1% of &lt;i&gt;K&lt;sub&gt;d&lt;/sub&gt;&lt;/i&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Increase &lt;i&gt;K&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt; until oscillations start.&lt;/li&gt;&#xA;&lt;li&gt;Decrease &lt;i&gt;K&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt; by a factor of 2-4.&lt;/li&gt;&#xA;&lt;li&gt;Set &lt;i&gt;K&lt;sub&gt;i&lt;/sub&gt;&lt;/i&gt; to about 1% of &lt;i&gt;K&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Increase &lt;i&gt;K&lt;sub&gt;i&lt;/sub&gt;&lt;/i&gt; until oscillations start.&lt;/li&gt;&#xA;&lt;li&gt;Decrease &lt;i&gt;K&lt;sub&gt;i&lt;/sub&gt;&lt;/i&gt; by a factor of 2-4.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;The &lt;a href=&quot;http://en.wikipedia.org/wiki/Ziegler%E2%80%93Nichols_method&quot; rel=&quot;nofollow&quot;&gt;Ziegler-Nichols method&lt;/a&gt; is more precise if you can get an accurate number for the oscillation period. It does generally cause oscillations using the &quot;classic PID&quot; numbers given, so it's not always optimal.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For general rules on the effect of each term on rise time, overshoot, settling time, steady-state error, and stability, see Table 1 of &lt;a href=&quot;http://eprints.gla.ac.uk/3815/1/IEEE_CS_PID_01580152.pdf&quot; rel=&quot;nofollow&quot;&gt;&quot;PID Control System Analysis and Design&quot;&lt;/a&gt;, by Li, Ang, and Chong in IEEE Control Systems Magazine.&lt;/p&gt;&#xA;" OwnerUserId="308" LastEditorUserId="308" LastEditDate="2012-11-10T00:29:22.887" LastActivityDate="2012-11-10T00:29:22.887" CommentCount="3" />
  <row Id="341" PostTypeId="1" CreationDate="2012-11-10T00:02:42.607" Score="4" ViewCount="58" Body="&lt;p&gt;I am thinking of developing a tendon driven robot manipulator for an industrial application that requires a high level of reliability. However, I am aware that tendons in a robot are prone to wear and tear, and failure.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How can I go about selecting a suitable tendon material (steel, kevlar, spectra, etc.) and use it appropriately?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Have any studies been undertaken to examine longevity and failure patterns in robotic tendon materials?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If I were to perform tests on materials myself, how can I perform those tests efficiently, and make best use of the testing time (learn as much as possible about tendon failure in a reasonable length of time).&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-11-15T06:43:47.260" Title="Tendon longevity" Tags="&lt;failure&gt;&lt;reliability&gt;" AnswerCount="1" CommentCount="2" FavoriteCount="1" />
  <row Id="342" PostTypeId="1" CreationDate="2012-11-10T00:26:06.763" Score="-1" ViewCount="116" Body="&lt;p&gt;Is there a taxonomy of errors that are common in robotics? Things that come to mind but I don't have names for are:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Getting stuck in a stable infinite loop&lt;/li&gt;&#xA;&lt;li&gt;Going into an unstable feedback loop (A balancing robot overcompensating more with each correction)&lt;/li&gt;&#xA;&lt;li&gt;An inability to generalize between tasks (Pick up a bowl vs pick up a glass)&lt;/li&gt;&#xA;&lt;li&gt;An inability to generalize between 'similar' sensory inputs.&lt;/li&gt;&#xA;&lt;li&gt;Causing damage to itself or its environment.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;These would be things that make a robot look 'stupid' to a non-roboticist. If you're curious I want to have this list so I can then prepare a clear answer ready for people who don't know why these various things are hard.&lt;/p&gt;&#xA;" OwnerUserId="54" LastActivityDate="2012-11-12T00:25:59.593" Title="What are some common mistakes that robots make?" Tags="&lt;errors&gt;" AnswerCount="2" CommentCount="3" ClosedDate="2012-11-12T03:21:27.017" />
  <row Id="343" PostTypeId="2" ParentId="215" CreationDate="2012-11-10T04:57:12.930" Score="3" Body="&lt;p&gt;The answers so far have covered the more general electronics stuff pretty well, so I'm going to focus on your mention of the Kinect.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Something Arduino-based is a good starting point for embedded electronics even though you already know C/assembly. What Arduino offers for you is a higher level API -- you COULD muck around with bitwise operations to modify peripheral configuration registers all day, but you have robots to make! &lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, it has nowhere near the horsepower needed to make use of a Kinect on its own. It needs quite a bit of USB bandwidth just to process &lt;a href=&quot;http://openkinect.org/wiki/FAQ#What_is_the_frame_size.2Fbitrate_of_the_rgb.2Fdepth.2FIR_stream_contained_in_the_isochronous_usb_tranfers_etc..3F&quot; rel=&quot;nofollow&quot;&gt;all of the raw output data&lt;/a&gt;, let alone do anything useful with it. I've heard of proof-of-concept robots connecting one to a netbook and I think once even a PandaBoard (which has smartphone-level performance using an OMAP chip), but nothing smaller than that. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Start reading up on ROS and the Kinect &lt;a href=&quot;http://www.ros.org/wiki/openni_camera&quot; rel=&quot;nofollow&quot;&gt;openni_camera&lt;/a&gt; and &lt;a href=&quot;http://www.ros.org/wiki/openni_tracker&quot; rel=&quot;nofollow&quot;&gt;openni_tracker&lt;/a&gt; drivers. Use a laptop/netbook (the Raspberry Pi is apparently &lt;a href=&quot;http://www.raspberrypi.org/phpBB3/viewtopic.php?f=37&amp;amp;t=6552&amp;amp;start=25&quot; rel=&quot;nofollow&quot;&gt;too slow&lt;/a&gt; to give more than 2-3 FPS) for the Kinect and have that talk over USB to the Arduino, which will control all of your other electronics directly.&lt;/p&gt;&#xA;" OwnerUserId="308" LastEditorUserId="308" LastEditDate="2012-11-10T19:48:21.033" LastActivityDate="2012-11-10T19:48:21.033" CommentCount="1" />
  <row Id="344" PostTypeId="1" CreationDate="2012-11-10T09:40:37.547" Score="6" ViewCount="392" Body="&lt;p&gt;Given a six-axis articulated robot arm holding a tool at its end-effector,  if I have a desired tool position and tool orientation,  there will be exactly 1 solution to the inverse kinematics equation for the robot to reach that position.&lt;br&gt;&#xA;(or rather up to 16 different solutions, depending on range of the joints)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/CkYqu.gif&quot; alt=&quot;http://en.wikipedia.org/wiki/Robotic_arm&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But if the robot is holding something like a pen, and I want the robot to mark a specific point with that pen on the target, then I do not care how the pen is oriented, as long as it is perpendicular to the marked surface.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So the inverse-kinematics equation will have infinitely many solutions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How can I pick among these solutions the joint configuration that is closest to the current configuration: the one that will require the least amount of movement to reach?&lt;br&gt;&#xA;(or the joint configuration that is optimal according to some other similar criterion, such as that all joint angles are furthest from their maximum and minimum?)&lt;/p&gt;&#xA;" OwnerUserId="362" LastEditorUserId="362" LastEditDate="2012-11-10T10:24:49.623" LastActivityDate="2013-12-18T18:31:22.517" Title="With a 6-axis robot, given end-effector position and range of orientations, how to find optimal joint values" Tags="&lt;localization&gt;&lt;motion-planning&gt;&lt;industrial-robot&gt;&lt;inverse-kinematics&gt;&lt;kinematics&gt;" AnswerCount="3" FavoriteCount="1" />
  <row Id="345" PostTypeId="2" ParentId="344" CreationDate="2012-11-10T11:17:14.240" Score="8" Body="&lt;p&gt;First, we need to define &lt;strong&gt;optimal&lt;/strong&gt;. Since you do not say what you consider optimal, most people choose a quadratic expression. For example, suppose your current joint angles are given by the vector $\vec{\alpha}$. We can consider minimizing the movement required - with an error $\vec{x} = \vec{\alpha} - \vec{\alpha}_{start}$, you can define a cost function $J=\vec{x}^TQ\vec{x}$ for some matrix $Q$. We normally use a diagonal matrix, but any positive-definite matrix will do.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In a simplified example with two joint angles, if joint $a$ had a cheaper motor (perhaps closer to end-effector), we might have a cost function of&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$J=\left[\begin{matrix}x_a\\x_b\end{matrix} \right]\left[\begin{matrix}1&amp;amp;0\\0&amp;amp;2\\\end{matrix} \right]\left[\begin{matrix}x_a&amp;amp;x_b\end{matrix} \right]$, ie. movement of joint $b$ is twice as costly as joint $a$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now, the kinematic equation is a matrix formula, and in Denavit-Hartenberg notation might be:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$\prod{T_i}=\left[\begin{matrix}1&amp;amp;0&amp;amp;0&amp;amp;x\\0&amp;amp;1&amp;amp;0&amp;amp;y\\0&amp;amp;0&amp;amp;1&amp;amp;z\\0&amp;amp;0&amp;amp;0&amp;amp;1\end{matrix} \right]$, where the right hand side represents the position $(x,y,z)$ and orientation (currently set as zero rotation), given the joint angles.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Since we do not care about the orientation, and only the position, we can truncate the first 3 columns of the last transformation matrix, and the last row of the first transformation matrix. We can equivalently express this formula as:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$\left[\begin{matrix}1&amp;amp;0&amp;amp;0&amp;amp;0\\0&amp;amp;1&amp;amp;0&amp;amp;0\\0&amp;amp;0&amp;amp;1&amp;amp;0\end{matrix}\right]\prod{T_i}\left[\begin{matrix}0\\0\\0\\1\end{matrix}\right]=\left[\begin{matrix}x\\y\\z\end{matrix} \right]$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Multiplying out the left hand side, we get three equations. If the parameters were linear, it would be simple to solve. This is the case if all the actuators are linear actuators. In this case, the problem is actually a &lt;strong&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Quadratic_programming&quot;&gt;quadratic program&lt;/a&gt;&lt;/strong&gt;. We can re-arrange the left hand side to get the equation:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$K\vec{x}=\left[\begin{matrix}x\\y\\z\end{matrix}\right]$, for some matrix $K$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A quadratic program is a problem which can be expressed in the form:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Minimize $J=\frac{1}{2}\vec{x}^TQ\vec{x}+\vec{c}^T\vec{x}$&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Subject to $A\vec{x}\leq\vec{b}$, $E\vec{x}=\vec{d}$&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;To solve this, there are a number of algorithms you can use, for example, interior point, active set, ... . Just find a suitable library, and it will solve it for you.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A non-linear system of equations is more difficult to solve. This is called &lt;strong&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Nonlinear_programming&quot;&gt;non-linear programming&lt;/a&gt;&lt;/strong&gt;, but it is what you have if you have rotating joints.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Essentially, in place of matrix equations, you have nonlinear functions.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Minimize $f(x)$ subject to $\vec{h}(x) = 0$, $\vec{g}(x) \leq 0$ (re-arrange if necessary to make the RHS of the constraints zero)&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;The algorithms used to solve this are even more complex, but includes Interior-point, Sequential quadratic programming (SQP), Active-set, Trust-region reflective algorithms. Obviously, the explanation of how these algorithms work is very lengthy, and I will leave it out of the scope of this answer. Suffice it to say, the amount of content on the algorithms used for just quadratic programming could be a whole course by itself.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You should just find a library to solve the problem, it would take a long time to code up an efficient implementation, and efficient implementations can handle 100 (or more) variables at a time. For example, if you use MATLAB, then there is documentation on how to use the function &lt;a href=&quot;http://www.mathworks.com/help/optim/ug/constrained-nonlinear-optimization-examples.html#f11071&quot;&gt;fmincon&lt;/a&gt; from the Optimization Toolbox.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To solve it online, you might want C++ or other native implementation, for example, NLopt. Do note that this may not be something a microcontroller can solve quickly, and many libraries may have other dependencies which are not easy to use on a microcontroller (since they are intended for a computer).&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;If you are not worried about efficiency, and just want something you can code yourself, then assuming there is a function you can call to solve the &lt;strong&gt;inverse kinematic problem&lt;/strong&gt;, you can simply do a gradient descent method. For example, arbitrarily choosing a random starting orientation, solve the inverse problem, then check the cost function. Then you can use perturbation analysis to check how you should vary the orientation. For example, if you check similar orientations around your current orientation (ie. 8 points in a cubic grid), you can get a second order approximation of how the cost function varies in each direction.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Using the second order approximation (known as a Hessian matrix since it is multivariate - 3-dimensional for orientation), you can find the zero-crossing of the gradient of the cost function (ie. the predicted local minima).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;With the new predicted orientation, just put it through the inverse solver again, and repeat until the accuracy is sufficient.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Do note that this will probably not be as efficient, because the inverse kinematic problem itself must be iteratively solved (so you are repeatedly using a function which itself takes a while to solve). Also, the code involved may be less than a fully-fledged optimization algorithm, but it is still quite substantial, and not an insignificant investment of time.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Using either method (formally solving as a nonlinear program or using the iteratively using a function to solve the inverse problem), the solution may not be optimal if there are multiple local minima. In this case, you can try to find the global minima by using various approaches. Even with a non-linear programming solver, you will be expected to seed it with initial values (eg. joint angles). You can repeatedly run either method with the seed generated in various ways:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;random restart (it is generated randomly)&lt;/li&gt;&#xA;&lt;li&gt;grid-based&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;or other custom methods.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However do note that if there are many minima, there is no good way to guarantee that you will find the global minima. You can only improve your chances.&lt;/p&gt;&#xA;" OwnerUserId="145" LastEditorUserId="145" LastEditDate="2012-11-10T12:11:49.050" LastActivityDate="2012-11-10T12:11:49.050" />
  <row Id="346" PostTypeId="2" ParentId="309" CreationDate="2012-11-10T12:40:15.673" Score="2" Body="&lt;p&gt;short answer; no you really need to do things quite a bit differently.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;long incomplete answer;&#xA;Let me give you some psuedo code appropriate for robotC, that puts you on a better path. First, do not use tasks - this is NOT what robotC tasks are for. They could be made to work, maybe, maybe not (and you need quite a few changes to even try).&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;// global variables&#xA;int distance;&#xA;int light;&#xA;&#xA;main() {&#xA;   while (true) {&#xA;   distance = read_distance;&#xA;   light = read_light;&#xA;   if (task1_wantsToRun())&#xA;     task1_run();&#xA;   if (task2_wantsToRun())&#xA;     task2_run();   &#xA;   }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;there is a couple of things here; priority becomes irrelevant. As nice as it seems to have tasks in robotC with priorities, they are not a good choice for subsumption implementation in my experience. For reasons like, priorities are not always honored, tasks can not be interrupted (sometimes) so when a higher priority event occurs, it is not going to react like you expect, robotC only recently became re-entrant, so things like accessing a sensor from more than 1 task may be risky (I2C timing issues), and in some cases it is not (automatically polled sensors).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can add your own priority implementation to the above loop as you get things working, but it really is not needed for starts.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Your comment &quot;//box the obstruction&quot;  describes a ballistic behavior. Those are a bit tricky to implement using multi-tasking. The simple loop I used makes it a lot easier, and better for starters/learning.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The other thing I will leave you with, is that subsumption while being neat and appropriate for a lot of things, is not a good way to implement what is better done traditionally. Indeed the 'evade' portion may be a good candidate for subsumption, but honestly your other task should be called 'GoOnAboutYourBusiness'. I say this because you probably do not want to change from searching to following with subsumption. Handle those with traditional programming loops. With a single sensor, - is the light sensed darker or lighter than it was last loop?  if it got darker (assuming black line) keep turning the same direction, if it got lighter turn the other way, if it stayed the same, go straight. You probably need to add some PID and use a steering curve instead of just turning left and right to be smoother.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And yes, multiple sensors help. &lt;a href=&quot;http://www.mindsensors.com/&quot; rel=&quot;nofollow&quot;&gt;http://www.mindsensors.com/&lt;/a&gt;  - yeah, that's me in the movie currently (11/10/2012)&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Update: actual code&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;I will try this out in a little while, but it compiles and illustrates what I wrote above:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#pragma config(Sensor, S1,     S_LIGHT,        sensorLightActive)&#xA;#pragma config(Sensor, S2,     S_DISTANCE,     sensorSONAR)&#xA;#pragma config(Motor,  motorB,          LEFT,          tmotorNXT, PIDControl, encoder)&#xA;#pragma config(Motor,  motorC,          RIGHT,         tmotorNXT, PIDControl, encoder)&#xA;//*!!Code automatically generated by 'ROBOTC' configuration wizard               !!*//&#xA;&#xA;int distance_value, light_value;&#xA;&#xA;bool evade_wantsToRun()&#xA;{&#xA;    return distance_value &amp;lt; 30;&#xA;}&#xA;&#xA;void evade_task()&#xA;{&#xA;    // full stop&#xA;    motor[LEFT] = 0;        &#xA;    // evade the object ballistically (ie in full control)  &#xA;    // turn left, drive&#xA;    nSyncedTurnRatio = 0;&#xA;    motor[LEFT] = -20;&#xA;    Sleep(500);&#xA;    nSyncedTurnRatio = 100;&#xA;    Sleep(1000);&#xA;    // turn right, drive&#xA;    nSyncedTurnRatio = 0;&#xA;    motor[LEFT] = 20;&#xA;    Sleep(500);&#xA;    nSyncedTurnRatio = 100;&#xA;    Sleep(1000);&#xA;    // turn right, drive&#xA;    nSyncedTurnRatio = 0;&#xA;    motor[LEFT] = 20;&#xA;    Sleep(500);&#xA;    nSyncedTurnRatio = 100;&#xA;    Sleep(1000);&#xA;    // turn left, resume&#xA;    nSyncedTurnRatio = 0;&#xA;    motor[LEFT] = 20;&#xA;    Sleep(500);&#xA;    motor[LEFT] = 0;&#xA;}&#xA;&#xA;///////////////////////////////&#xA;&#xA;void TurnBySteer(int d)&#xA;{&#xA;    // normalize -100 100 to 0 200&#xA;    nSyncedTurnRatio = d + 100; &#xA;}&#xA;///////////////////////////////&#xA;&#xA;typedef enum programPhase { starting, searching, following, finished };&#xA;programPhase phase = starting;&#xA;&#xA;// these 'tasks' are called from a loop, thus do not need to loop themselves&#xA;&#xA;void initialize()&#xA;{&#xA;    nSyncedTurnRatio = 50;&#xA;    nSyncedMotors = synchBC;&#xA;    motor[LEFT] = 30;       // start a spiral drive&#xA;    phase = searching;&#xA;}&#xA;&#xA;void search()&#xA;{&#xA;    if (light_value &amp;lt; 24)&#xA;    {&#xA;        nSyncedTurnRatio = 100;&#xA;        phase = following;&#xA;    }&#xA;}&#xA;&#xA;int lastLight = -1;&#xA;int currentSteer = 0;&#xA;void follow()&#xA;{&#xA;    // if it is solid white we have lost the line and must stop&#xA;    // if lightSensors detects dark, we are on line&#xA;    // if it got lighter, we are going more off line&#xA;    // if it got darker we are headed in a good direction, slow down turn in anticipation&#xA;    // +++PID will be even smoother&#xA;    if (light_value &amp;gt; 64)&#xA;    {&#xA;        motor[LEFT] = 0;&#xA;        phase = finished;&#xA;        return;&#xA;    }&#xA;    if (light_value &amp;lt; 24)&#xA;        currentSteer = 0;&#xA;    else if (light_value &amp;gt; lastLight)&#xA;        currentSteer += sgn(currentSteer) * 1;&#xA;    else    // implied (light_value &amp;lt; lastLight)&#xA;        currentSteer -= sgn(currentSteer) * 1;      &#xA;&#xA;    TurnBySteer(currentSteer);&#xA;}&#xA;&#xA;bool regularProcessing_wantsToRun()&#xA;{&#xA;    return phase != finished;&#xA;}&#xA;&#xA;void regularProcessing_task()&#xA;{&#xA;    switch (phase)&#xA;    {&#xA;    case starting:&#xA;        initialize();&#xA;        break;&#xA;    case searching:&#xA;        search();&#xA;        break;&#xA;    case following:&#xA;        follow();&#xA;    }&#xA;}&#xA;&#xA;task main()&#xA;{&#xA;    // subsumption tasks in priority oder&#xA;    while (true)&#xA;    {&#xA;        // read sensors once per loop&#xA;        distance_value = SensorValue[S_DISTANCE];&#xA;        light_value = SensorValue[S_LIGHT];&#xA;        if (evade_wantsToRun())&#xA;            evade_task();&#xA;        if (regularProcessing_wantsToRun())&#xA;            regularProcessing_task();&#xA;        else&#xA;            StopAllTasks();&#xA;        EndTimeSlice();     // give others a chance, but make it as short as possible&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="274" LastEditorUserId="94" LastEditDate="2012-11-12T03:25:10.157" LastActivityDate="2012-11-12T03:25:10.157" CommentCount="4" />
  <row Id="348" PostTypeId="2" ParentId="255" CreationDate="2012-11-10T18:54:15.103" Score="2" Body="&lt;p&gt;&lt;a href=&quot;http://www.arduino.cc&quot; rel=&quot;nofollow&quot;&gt;Arduino&lt;/a&gt; is a great fit for your problem. It is not only used by hobbyists and beginners but it is frequently used by top Universities for both teaching and in research. Arduino also has a large active community which makes helps when you have a problem.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are a couple of caveats to the Arduino solution however. 1) They have very limited computational power and no floating point unit which can further slow down calcuation. 2) Working with Arduino does require one to have a rudimentary understanding of electronics. Of course there are myriad tutorials that can help you get up and running in a matter of minutes. However when I first delved into robotics I wanted to avoid the electronics aspect so as to focus on the programming.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.phidgets.com/&quot; rel=&quot;nofollow&quot;&gt;Phidgets&lt;/a&gt; is a good alternative. Many Phidgets components are abstracted to the point that you only need to connect them to a computer via USB and processing is done on a desktop, laptop, or single board computer (SBC) which have more processing power. Furthermore Phidgets works with multiple operating systems and they offer a lot of well documented code to simplify interfacing with their parts. It is worth noting that Phidgets solutions tend to cost a bit more than Arduino solutions but they're still reasonably priced.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would suggest against &lt;a href=&quot;http://www.parallax.com/&quot; rel=&quot;nofollow&quot;&gt;Parallax&lt;/a&gt;. They are interesting but they don't offer anything over Arduino, they are more expensive (than Arduino), and they are considerably less flexible from a programming perspective in my experience.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also Phidgets do not work well in UAV applications. For that I would advise looking at the &lt;a href=&quot;http://diydrones.com&quot; rel=&quot;nofollow&quot;&gt;ArduPilot&lt;/a&gt;. It is an Arduino based solution to UAV and UGV robots and includes a number of built-in sensors for state estimation. Furthermore ArduPilo has its own a large active community.&lt;/p&gt;&#xA;" OwnerUserId="177" LastEditorUserId="177" LastEditDate="2012-11-10T19:03:49.077" LastActivityDate="2012-11-10T19:03:49.077" />
  <row Id="349" PostTypeId="2" ParentId="255" CreationDate="2012-11-10T19:05:53.840" Score="2" Body="&lt;p&gt;Get a LEGO NXT kit, it costs around $280, and will give you a lot of fun.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can control it from your computer using any programming language - just send Bluetooth commands to the LEGO NXT brick. It is very simple!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you want to learn more - here is a simple KB article about that: &lt;a href=&quot;http://www.robotappstore.com/Knowledge-Base/Introduction-To-Lego-NXT-Programming/32.html&quot; rel=&quot;nofollow&quot;&gt;http://www.robotappstore.com/Knowledge-Base/Introduction-To-Lego-NXT-Programming/32.html&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="394" LastActivityDate="2012-11-10T19:05:53.840" CommentCount="2" />
  <row Id="351" PostTypeId="2" ParentId="342" CreationDate="2012-11-10T19:22:07.843" Score="2" Body="&lt;p&gt;To a roboticist it might look like a stupid question, however, I think your question is valid, and even important!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Setting expectations is very important when introducing robots to the general public, this will help bridging between Hollywood-robots and real-life robots.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I think the most important difference is understanding the context. Robots (or computer) are very good with computing an answer to a mathematical question, however they are clueless about the context of the question.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;for example - ask a humanoid robot to reach his right hand to touch his left ear. In most of the cases I saw - the robot tried to get to the left ear through the head... the context has to be hard coded into everything...&lt;/p&gt;&#xA;" OwnerUserId="394" LastActivityDate="2012-11-10T19:22:07.843" />
  <row Id="352" PostTypeId="2" ParentId="287" CreationDate="2012-11-10T19:24:37.623" Score="5" Body="&lt;p&gt;&lt;a href=&quot;http://ros.org&quot;&gt;Robot Operating System&lt;/a&gt; (ROS) offers the ability to use Javascript to control your robots. Specifically you will want to look at &lt;a href=&quot;http://ros.org/wiki/rosbridge/Tutorials/Using%20Javascript%20to%20control%20ROS%20via%20rosjs&quot;&gt;rosbridge&lt;/a&gt;. You will then need to use &lt;a href=&quot;http://www.ros.org/wiki/rosserial&quot;&gt;rosserial&lt;/a&gt; to interface with the microcontroller controlling your robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;While I am a big fan of ROS this is an overly complicated way to begin exploring the field of robotics IMHO. You would be better served to pick up an &lt;a href=&quot;http://arduino.cc&quot;&gt;Arduino&lt;/a&gt; and learning a little bit of C. Arduino does a great job of making the process simple and C is not a large deviation from JS from a syntax perspective.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2012-11-10T19:24:37.623" />
  <row Id="353" PostTypeId="2" ParentId="301" CreationDate="2012-11-10T20:14:56.007" Score="1" Body="&lt;p&gt;I have not done it myself yet, but, I have always planned on finding algorithm(s) here; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://opensteer.sourceforge.net/&quot; rel=&quot;nofollow&quot;&gt;http://opensteer.sourceforge.net/&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The controller they include is called 'unaligned collision avoidance'.&lt;/p&gt;&#xA;" OwnerUserId="274" LastActivityDate="2012-11-10T20:14:56.007" />
  <row Id="354" PostTypeId="1" AcceptedAnswerId="367" CreationDate="2012-11-10T20:26:08.600" Score="2" ViewCount="113" Body="&lt;p&gt;I am interested in learning more about &lt;a href=&quot;http://en.wikipedia.org/wiki/Subsumption_architecture&quot; rel=&quot;nofollow&quot;&gt;subsumption architecture&lt;/a&gt;. I have read a number of books that talk about the idea but none of them go into great detail. I have also read a fair number of Dr. Brooks papers on the topic however he hasn't published much on the topic in recent years.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is this still an active area of research? Are there are any must read papers on the topic?&lt;/p&gt;&#xA;" OwnerUserId="177" LastEditorUserId="37" LastEditDate="2012-11-15T02:36:50.763" LastActivityDate="2012-11-15T02:36:50.763" Title="Is subsumption architecture still an active area of research?" Tags="&lt;control&gt;&lt;research&gt;" AnswerCount="1" CommentCount="1" FavoriteCount="4" />
  <row Id="355" PostTypeId="2" ParentId="287" CreationDate="2012-11-11T05:03:50.090" Score="2" Body="&lt;p&gt;A friend of mine actually has a pretty powerful &lt;a href=&quot;http://glench.com/make/nodejs-robot/&quot; rel=&quot;nofollow&quot;&gt;tank robot&lt;/a&gt; that's controlled with NodeJS over wifi. The robot itself isn't exactly &quot;small-robotics&quot; at 150 pounds, but you could probably learn quite a bit from the source code. It has a netbook onboard running a webserver and talking to an Arduino. You can find the source code on his Github &lt;a href=&quot;https://github.com/Glench/Capstone-Tank-Robot-Software&quot; rel=&quot;nofollow&quot;&gt;project page&lt;/a&gt;. The real-time control from a web browser on another computer is surprisingly responsive.&lt;/p&gt;&#xA;" OwnerUserId="308" LastActivityDate="2012-11-11T05:03:50.090" />
  <row Id="356" PostTypeId="2" ParentId="287" CreationDate="2012-11-11T07:58:20.457" Score="4" Body="&lt;p&gt;Generally there are many ways to use node.js with a platform, like &lt;a href=&quot;http://blog.tomg.co/post/21322413373/how-to-install-node-js-on-your-raspberry-pi&quot; rel=&quot;nofollow&quot;&gt;this one for the RPi&lt;/a&gt;. There are a lot more similar ones &lt;a href=&quot;https://www.google.co.in/search?sugexp=chrome,mod=3&amp;amp;sourceid=chrome&amp;amp;client=ubuntu&amp;amp;channel=cs&amp;amp;ie=UTF-8&amp;amp;q=nodejs+robotics&quot; rel=&quot;nofollow&quot;&gt;if you just search for them&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another interesting one is &lt;a href=&quot;http://www.arduinodev.com/software/ardugate/&quot; rel=&quot;nofollow&quot;&gt;ArduGate&lt;/a&gt;, which lets web pages communicate with the arduino via JS (though probably not exactly what you wanted since it doesn't compile and load to  the arduino)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Though I really don't see what's wrong with using a different language. I myself write primarily in JS, but I find myself perfectly comfortable programming an Arduino in C++ (it also allows C and Java, and if you put in a bit of work, &lt;a href=&quot;http://arduino.cc/playground/Main/Interfacing&quot; rel=&quot;nofollow&quot;&gt;quite a few more languages&lt;/a&gt; ). Remember, we're not needing anything fancy for programming a robot--just normal &lt;code&gt;if&lt;/code&gt;s,&lt;code&gt;for&lt;/code&gt;s,&lt;code&gt;while&lt;/code&gt;s,&lt;code&gt;switch&lt;/code&gt;es, and the occasional &lt;code&gt;class&lt;/code&gt;. Learn the syntax, and you're good to go :) The only thing is that C/C++/Java are strongly typed (though if you're using the RPi, python is weakly typed but picky in a million more ways), so you may get a bit of frustration in the beginning when you have to specify types for everything. One advantage of using the native languages is that it's much easier to find APIs and example code on the net. For example, aside from ArduGate(which has it built in and is probably not what you wanted), I can't find any way to access the EEPROM--a common task. So, unless you want to stick to simple programs, it's just better to use the native languages.&lt;/p&gt;&#xA;" OwnerUserId="126" LastActivityDate="2012-11-11T07:58:20.457" />
  <row Id="358" PostTypeId="1" CreationDate="2012-11-11T16:47:45.837" Score="4" ViewCount="157" Body="&lt;p&gt;I am looking for a way to restrict a robot's range of motion, using complex constraints such as not tearing of a cable attached to the robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Take an articulated 6-axis robot arm as shown below, with attached cable (red), fixed at points X (before axis A4) and Y (after axis A6).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/ipApa.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The cable will limit the range of movement for the robot. It can stretch and bend only to some extend, but something like a full 360° turn of axis A4, with all other axes remaining as they are in the picture, will tie the cable around the arm and rip it off.&lt;br&gt;&#xA;If joint A5 is at 0°, then A4 and A6 can still move the full 360°, but they cannot diverge too much from each other, as that would twist the cable. If A5 is tilted, the relationship becomes even more complicated.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How can you express such a constraint?  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;It is not a simple joint constraint, where you can independently limit the range of the joints, and it is also not a positional constraint, where you can define a region the robot must not enter. Checking a start and a goal posture is not sufficient, since along the path from start to goal posture there may still be a posture that puts too much strain on the cable.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Without limiting the robot to a small set of pre-tested paths, how can you limit the robot to movements that will not rip off the cable?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What are the standard techniques used for this sort of problem?&lt;/p&gt;&#xA;" OwnerUserId="362" LastEditorUserId="362" LastEditDate="2012-11-11T17:02:40.207" LastActivityDate="2012-11-14T18:28:36.620" Title="restricting range of motion with complex constraints" Tags="&lt;motion-planning&gt;&lt;industrial-robot&gt;&lt;joint&gt;" AnswerCount="3" CommentCount="1" />
  <row Id="359" PostTypeId="1" CreationDate="2012-11-11T16:58:29.480" Score="5" ViewCount="80" Body="&lt;p&gt;Currently I have a tricycle style robot that uses an extended kalman filter in order to track 6 state variables. The inputs to the system are a steer encoder, a distance encoder, and a rotating laser that returns bearing only information to known landmarks. Currently both encoders are located on the main wheel (The one that steers, and is also powered).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The 6 variables tracked by the Kalman Filter are X, Y, Heading, Distance Scaling (calibration of the distance encoder), Steer Calibration (offset of the steer encoder), and finally a bearing calibration of a rotating laser. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;With this kind of system we put together a vehicle give it a known good location with plenty of landmarks, drive it around a bit, and end up with a well calibrated vehicle that can drive extended distances reliably with few landmarks. Its simple and it works great. Over time if an encoder drifts it will automatically follow the drift and adjust. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;We are now attempting to apply the same principles to a robot with multiple steer and drive wheels. In this case the vehicle will be able to move in any direction, spin in place, etc. . Each steer/drive wheel will have its own steer and distance encoder that each need to be calibrated. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can I expect to get the same kind of reliability and performance out of the more complex system? Are there any common pitfalls to look out for when expanding a kalman filter to include more variables? Is there a risk of it settling on sub-optimal values?&lt;/p&gt;&#xA;" OwnerUserId="201" LastActivityDate="2012-11-11T20:42:48.040" Title="What kind of performance can I expect when using an Extended Kalman Filter for calibration and localization?" Tags="&lt;localization&gt;&lt;kalman-filter&gt;" AnswerCount="1" FavoriteCount="1" />
  <row Id="360" PostTypeId="2" ParentId="358" CreationDate="2012-11-11T17:21:14.760" Score="2" Body="&lt;p&gt;The cable has a certain amount of slack, and each joint it goes over takes up some of that slack as a function of the joint angle. The cable will break if the total amount of slack taken up by all joints exceeds the available slack.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Firstly, it would help if you could thread the cable along the robot in such a way that that each joint has a calculable effect on the slack, and each joint affects the cable independently. This will really help the calculations. Let's define the amount of slack taken up by joint 1 at an angle th1 by:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;f1(th1)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Now, your robot arm can move anywhere such that&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;f1(th1) + f2(th2) + ... + f6(th6) &amp;lt;= total_slack&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;This assumes that the cable is fixed in such a way that it can slide up and down the robot arm, distributing the slack where it's needed. Generally, this isn't the case in most robots, and isn't easy to do.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A more reliable way to solve this problem is to rigidly fix the cable before and after each joint, and make sure there's enough slack for every joint.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-11-11T17:21:14.760" />
  <row Id="361" PostTypeId="1" AcceptedAnswerId="363" CreationDate="2012-11-11T19:48:28.747" Score="8" ViewCount="327" Body="&lt;p&gt;I am considering programming a line following robot using reinforcement learning algorithms. The question I am pondering over is how can I get the algorithm to learn navigating through any arbitrary path?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Having followed the &lt;a href=&quot;http://webdocs.cs.ualberta.ca/~sutton/book/the-book.html&quot; rel=&quot;nofollow&quot;&gt;Sutton &amp;amp; Barto Book&lt;/a&gt; for reinforcement learning, I did solve an exercise problem involving a racetrack where in the car agent learnt not to go off the track and regulate its speed. However, that exercise problem got the agent to learn how to navigate the track it trained on.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is it in the scope of reinforcement learning to get a robot to navigate arbitrary paths? Does the agent &lt;strong&gt;absolutely&lt;/strong&gt; have to have a map of the race circuit or path? What parameters could I possibly use for my state space?&lt;/p&gt;&#xA;" OwnerUserId="272" LastEditorUserId="350" LastEditDate="2013-08-27T18:23:41.307" LastActivityDate="2013-08-27T18:23:41.307" Title="Programming a line following robot with reinforcement learning" Tags="&lt;machine-learning&gt;&lt;artificial-intelligence&gt;&lt;reinforcement-learning&gt;&lt;line-following&gt;" AnswerCount="1" CommentCount="3" FavoriteCount="2" />
  <row Id="362" PostTypeId="2" ParentId="359" CreationDate="2012-11-11T20:42:48.040" Score="1" Body="&lt;p&gt;In my opinion (based on my limited experience using the EKF for navigation):&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The performance of the EKF can be hugely improved by a good kinematic model. You did right by including bias in your steering and odometry models for the tricycle system. If you can derive and apply a detailed kinematics model for your more complicated system, then you should do quite well. If not, then the EKF must also account for your errors in modelling, in addition to your sensor errors and linearization errors. This is the danger: including a source of error that is &lt;em&gt;not&lt;/em&gt; accounted for will make your filter inconsistent very quickly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If things get out of hand (your filter isn't converging nicely), you can try multiple model methds (IMM).  So my advice is to model the system as well as possible. The EKF has a very good track record for these tasks. Good luck.&lt;/p&gt;&#xA;" OwnerUserId="163" LastActivityDate="2012-11-11T20:42:48.040" />
  <row Id="363" PostTypeId="2" ParentId="361" CreationDate="2012-11-11T20:56:55.387" Score="5" Body="&lt;p&gt;One of the key measures of any machine learning algorithm is it's ability to generalize (i.e. apply what it has learned to previously unsceen scenarios). Reinforcement learners (RL) &lt;strong&gt;can&lt;/strong&gt; generalize well but this ability is in part a function of the state-space formulation in my experience. This means that if you can find the right setup then the RL learner will not need a map of of the race circuit.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This leaves the question of which parameters to use. Without knowing more about the sensors available on your robot I can only speculate. My first inclinition is to try to encoded the relative orientation of the line and robot (i.e. is the robot tending to the right, left, or simply moving parallel with the line). Doing so would result in a nice small state-space. Though not strictly necessary it would make for a quick and simple implementation. Furthermore, if the robot is not going to move at a constant rate then it may help to encode the robots velocity as the robot will need to react more quickly when moving at higher speeds.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2012-11-11T20:56:55.387" CommentCount="2" />
  <row Id="365" PostTypeId="2" ParentId="342" CreationDate="2012-11-12T00:25:59.593" Score="0" Body="&lt;p&gt;This is not a clear question, is more of a fishing / discussion question. As much as I'd love to sit down and discuss this for a few hours, this is unfortunately not the type of things we can concisely and objectively answer. Expectations are better diffused by specific questions. Example: &quot;Bipedal robots: Can they walk over a pile of skulls like in Terminator 2?&quot; &lt;/p&gt;&#xA;" OwnerUserId="163" LastActivityDate="2012-11-12T00:25:59.593" />
  <row Id="366" PostTypeId="2" ParentId="358" CreationDate="2012-11-12T00:34:31.600" Score="3" Body="&lt;p&gt;I'm not sure what the &quot;standard techniques&quot; are but here are a few a ideas.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You could combine a standard &lt;a href=&quot;http://en.wikipedia.org/wiki/Robot_kinematics&quot; rel=&quot;nofollow&quot;&gt;jacobian based forward kinematics&lt;/a&gt; as your base and then apply a gradient search algorithm where you bias against things such as running out of slack on your wires or other constraints. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Let me go into a bit more detail. Generally you would just give the robotic arm an end point or perhaps a series of way points you expect the end effector to follow. You can then use the forward kinematics to move the end effector between those waypoints. In order to avoid your difficult to describe constraint you can define a value function that increases as the arm moves and reduces the slack on the wire. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you guess a path most likely your initial guess will result in the wire being snapped. You're value function will give you a score representing this fact. You can then take your in between waypoints and tweak them a bit which may result in the function represetnging your constraint to decrease. You then can tweak it a bit more reducing it further. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is called &lt;a href=&quot;http://en.wikipedia.org/wiki/Mathematical_optimization&quot; rel=&quot;nofollow&quot;&gt;optimization&lt;/a&gt; and it is a huge field but the most basic method is &lt;a href=&quot;http://en.wikipedia.org/wiki/Gradient_descent&quot; rel=&quot;nofollow&quot;&gt;Gradient Descent&lt;/a&gt;. In theory if you use an optimization method to adjust your waypoints eventually you will find a set of waypoints that keeps the tension along the wire to a minimum. The main issue with optimization is that you can run into local minimums that don't adequately solve your problem, and methods that get around local minimums can be slow.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are looking to get academic about it you  may want to look into the algorithm presented &lt;a href=&quot;http://www.ri.cmu.edu/publication_view.html?pub_id=6285&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;. Keep in mind there might not be a simple answer to your question or a simple algorithm to solve it.&lt;/p&gt;&#xA;" OwnerUserId="201" LastActivityDate="2012-11-12T00:34:31.600" />
  <row Id="367" PostTypeId="2" ParentId="354" CreationDate="2012-11-12T09:31:49.053" Score="6" Body="&lt;p&gt;As you probably guessed from the lack of answers, subsumption architecture is not an active area of research any more. Most papers on this have been published in the late 80's / early 90's.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This doesn't mean that subsumption architecture is dead; it has been very influential in robotics, and it's still used in education for example, but it is just not a hot topic in research any more.&lt;/p&gt;&#xA;" OwnerUserId="132" LastActivityDate="2012-11-12T09:31:49.053" CommentCount="3" />
  <row Id="368" PostTypeId="2" ParentId="338" CreationDate="2012-11-12T14:53:42.343" Score="1" Body="&lt;p&gt;I think you're caught up in trying to build high-level behavior (maneuvers) from low-level motor functionality, when in reality you should be attempting to decouple them somewhat.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So you're asking 3 questions.&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;How do the high level behaviors work?&lt;/li&gt;&#xA;&lt;li&gt;What low-level API do I want?&lt;/li&gt;&#xA;&lt;li&gt;How should the low-level API be implemented on my ESC?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;So, working backwards: the relevant information on implementation is most likely in your ESC's manual, on their website, or some such.  Call them up if it's unclear, sometimes they'll be familiar with the programming gotchas and can point you in the right direction.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'd focus on writing a motor controller API that accepts desired velocity for each tread.  You'll have to fake it in the dead zone, most likely by varying the motor speed so on average it's the speed you want (probably some sort of PID here).  But, your controller should maintain a desired velocity (0%-100% + direction) for each motor until it's handed a new desired velocity.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The high level behaviors just set desired velocity for each tread.  So, a U-turn is any setting where the velocities are equal and opposite; a turn is anything where velocities are unequal but aligned.  Your path planner (or whatever tells the platform where it should go) will be the one to decide how tightly to turn to get wherever it's going (another PID, most likely).&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2012-11-12T14:53:42.343" />
  <row Id="369" PostTypeId="1" AcceptedAnswerId="370" CreationDate="2012-11-12T18:50:20.770" Score="2" ViewCount="113" Body="&lt;p&gt;Are &lt;a href=&quot;http://en.wikipedia.org/wiki/Inverse_kinematics&quot; rel=&quot;nofollow&quot;&gt;inverse kinematics&lt;/a&gt; and &lt;a href=&quot;http://en.wikipedia.org/wiki/Reinforcement_learning&quot; rel=&quot;nofollow&quot;&gt;reinforcement learning&lt;/a&gt; techniques contending techniques to solve the same problem viz. movement of robotic manipulators or arm?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;By a glance through the wikipedia article, it appears that inverse kinematics seems to attempt to achieve a &lt;a href=&quot;http://en.wikipedia.org/wiki/Equation_solving&quot; rel=&quot;nofollow&quot;&gt;solution&lt;/a&gt;  as opposed to reinforcement learning which attempts to &lt;a href=&quot;http://en.wikipedia.org/wiki/Optimization&quot; rel=&quot;nofollow&quot;&gt;optimizes&lt;/a&gt; the problem. Have I misunderstood anything?&lt;/p&gt;&#xA;" OwnerUserId="272" LastEditorUserId="177" LastEditDate="2012-11-13T21:00:01.287" LastActivityDate="2012-11-14T17:40:44.207" Title="Are inverse kinematics and reinforcement learning competitive techniques?" Tags="&lt;inverse-kinematics&gt;&lt;reinforcement-learning&gt;&lt;machine-learning&gt;" AnswerCount="2" FavoriteCount="1" />
  <row Id="370" PostTypeId="2" ParentId="369" CreationDate="2012-11-12T20:20:50.067" Score="6" Body="&lt;p&gt;From what I understand of your question, you'd like to know if inverse kinematics and reinforcement learning are trying to solve the same problem in the particular case of robotic manipulation. Of course both of these techniques can be applied outside of this particular realm, but let's focus on robot manipulation for now.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You're right that inverse kinematics is trying to find a solution, although this can be a family of solutions. You'd like to pose the end effector of your manipulator in a particular position and you have to find out the state of the rest of the arm in order to perform the motions that will achieve your goal.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Reinforcement learning is also trying to find a solution to the problem, and it's trying to optimize its solution with respect to a cost function. Imagine, for example, that there's a minimal set of movements that would get your end effector in the required position (e.g. by attaching a cost to actuating each of the manipulator's joints, you could learn the optimal way of achieving your goal with respect to power consumed).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Instead of considering the techniques to be at odds with each other, you could use inverse kinematics to find the family of solutions to your problem and reinforcement learning to search this space and find an optimal solution with respect to some cost/reward criteria of your choosing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you're intent on choosing one technique over the other, by posing the reinforcement learning problem as an optimization that rewards, say, how fast you reach the goal state of the end effector, you could still find a solution. However, there's a chance that you'd like to use some notion of the manipulator's kinematics to inform how you search the space of its movements.&lt;/p&gt;&#xA;" OwnerUserId="295" LastActivityDate="2012-11-12T20:20:50.067" />
  <row Id="371" PostTypeId="5" CreationDate="2012-11-12T21:38:16.873" Score="0" ViewCount="3" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2012-11-12T21:38:16.873" LastActivityDate="2012-11-12T21:38:16.873" />
  <row Id="372" PostTypeId="4" CreationDate="2012-11-12T21:38:16.873" Score="0" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2012-11-12T21:38:16.873" LastActivityDate="2012-11-12T21:38:16.873" />
  <row Id="373" PostTypeId="2" ParentId="327" CreationDate="2012-11-12T22:19:11.210" Score="7" Body="&lt;p&gt;There is not a specific set of learning algorithms that you will need to implement. Genetic algorithms (GA), neural networks (GA), and reinforcement learning (RL) have all successfully been applied to the problem of gait generation. I can also conceive of ways to use unsupervised learning methods to approach this problem but I can't say for certain whether they would work. Even if they would I'm inclined to think RL is the better approach.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Dr. Hod Lipson talks about using GAs in his TED video entitled &lt;a href=&quot;http://www.ted.com/speakers/hod_lipson.html&quot;&gt;Hod Lipson builds &quot;self-aware&quot; robots&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;NNs have often been used. A few examples include:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.mitpressjournals.org/doi/abs/10.1162/neco.1992.4.3.356&quot;&gt;A Distributed Neural Network Architecture for Hexapod Robot Locomotion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.sciencedirect.com/science/article/pii/0921889096000036&quot;&gt;Biologically based distributed control and local reflexes improve rough terrain locomotion in a hexapod robot&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.sciencedirect.com/science/article/pii/S092188909600036X&quot;&gt;Application of evolved locomotion controllers to a hexapod robot&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://matwbn.icm.edu.pl/ksiazki/amc/amc20/amc2015.pdf&quot;&gt;A biologically inspired approach to feasible gait learning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;I don't know whether RL has been appplied to quadrapeds but there are a number of succesful applications to hexapods.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://dl.acm.org/citation.cfm?id=1346424&quot;&gt;Free gait generation with reinforcement learning for a six-legged robot&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=2&amp;amp;ved=0CD0QFjAB&amp;amp;url=http%3A%2F%2Fdownload.intel.com%2Fembedded%2Fapplications%2Find%2FQ-LearningHexapod.pdf&amp;amp;ei=YnOhUMHfJc3siQKF44CwCA&amp;amp;usg=AFQjCNEEE7tVf5I1Nydo6t3zYm6jTkhqIw&amp;amp;sig2=t68ZLQYy7UgaiX0_ScdQlw&amp;amp;cad=rja&quot;&gt;Q-Learning Hexapod&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Beware that these lists are by no means comprehensive.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;GA and NN would be relatively simple to implement. RL on the other is a more principled way to approached the problem. In all cases you will need more processing power than the Uno offers to actually perform the learning. If you intended to do offline learning then the Uno may work after the learning phase.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2012-11-12T22:19:11.210" />
  <row Id="374" PostTypeId="5" CreationDate="2012-11-12T22:21:30.613" Score="0" ViewCount="5" Body="&lt;p&gt;Reinforcement learning (RL) is a &lt;a href=&quot;http://robotics.stackexchange.com/questions/tagged/machine-learning&quot;&gt;machine learning&lt;/a&gt; (ML) technique wherein an agent improves its performance through interaction with its environment by attempting to minimize an objective or cost function referred to as the reward function.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;RL is a class of algorithms separate from both &lt;a href=&quot;http://en.wikipedia.org/wiki/Supervised_learning&quot; rel=&quot;nofollow&quot;&gt;superverised learning&lt;/a&gt; and &lt;a href=&quot;http://en.wikipedia.org/wiki/Unsupervised_learning&quot; rel=&quot;nofollow&quot;&gt;unsupervised learning&lt;/a&gt;. It differs from superverised learning methods in that RL agents are not provided with the correct answer at the time of training. Instead they receive a &quot;reward&quot; with each action. This reward is often referred to as a penalty when its value is negative. Furthermore the reward function also defines how RL differs from unsupervised learning methods. Specifically unsupervised learning methods receive no information what-so-ever regarding what is correct during training.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Common formulations of the reward function provide the agent with a positive or zero reward as long as it performs within the acceptable bounds and a negative reward if it performs incorrect or sub-optimal actions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Frequently an RL agent cannot directly determine the reward function and instead it develops a policy that defines which action to take given a particular state of the world. This policy is developed through repeated training and following the policy maximizes the reward.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One problem with always following the policy is that nothing new can be learned in doing so. Since there is no guarantee that the current policy is optimal it is necessary for the agent to occasionally select actions other than what is prescribed by the policy. This is known as exploration and permits the agent to find superior solutions. However it is done at the risk of recieving penalties or lower overall rewards. One common technique for selecting actions off-policy is epsilon-greedy selection. This method has the agent randomly select an action some percentage of the time and select the policy action the remaining percentage of the time.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The text &lt;a href=&quot;http://webdocs.cs.ualberta.ca/~sutton/book/ebook/the-book.html&quot; rel=&quot;nofollow&quot;&gt;Reinforcement Learning: An Introduction&lt;/a&gt; by Sutton and Barto details the myriad facets of reinforcement learning.&lt;/p&gt;&#xA;" OwnerUserId="272" LastEditorUserId="177" LastEditDate="2012-11-19T19:56:41.430" LastActivityDate="2012-11-19T19:56:41.430" />
  <row Id="375" PostTypeId="4" CreationDate="2012-11-12T22:21:30.613" Score="0" Body="Reinforcement learning is a technique wherein an agent improves its performance via interaction with its environment. For this reason it is a commonly used machine learning technique in robotics." OwnerUserId="272" LastEditorUserId="177" LastEditDate="2012-11-19T19:56:45.690" LastActivityDate="2012-11-19T19:56:45.690" />
  <row Id="376" PostTypeId="2" ParentId="237" CreationDate="2012-11-12T22:22:30.423" Score="2" Body="&lt;p&gt;I think the form of your question is wrong.  The problem is not that you've improperly calculated how much data-per-second can be thrown at the microcontroller; it's that you have no way for the microcontroller to indicate its readiness to receive the next command.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;To put it another way, if you attempt to solve this problem by precisely calculating how quickly to send data, you will inevitably do one of the following things:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;send less data than the microcontroller can handle&lt;/li&gt;&#xA;&lt;li&gt;send more data than the microcontroller can handle (and in the worst case, it will be only &lt;em&gt;very&lt;/em&gt; slightly more so that the buffer takes an hour to overrun and leads you to debug something completely unrelated)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;The solution is for your microcontroller to provide feedback -- flow control.  In the most basic example just send back a single character representing command completion (@Rocketmagnet's SpaceWire suggestion would be the most robust, but also heavy handed).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Most likely, you can afford to have a few commands in the buffer.  So, the calculation you should do is to divide your buffer size by the size of the largest command you'll send, then subtract 1 (or more) for safety.  That will tell you the greatest allowable difference between commands sent and acknowledgements received, and will allow you to work at maximum speed by keeping the buffer filled.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Example&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Say that your longest possible command is 7 bytes (&quot;fw 4.32&quot;) or some such, and that you have a 64-byte buffer.  That means you can fit 9 commands in the buffer ($7 \times 9 = 63 &amp;lt; 64$), but for safety you'll subtract one and only allow 8 commands.  Here's some python psudeocode:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;MAX_UNACKED = 8  # constant, how many un-acked commands to send&#xA;unacked = 0      # number of un-acked commands that have been sent&#xA;while (true):&#xA;    # can send up to MAX_UNACKED commands as we like&#xA;    if MAX_UNACKED &amp;gt; unacked:&#xA;        send_command()&#xA;        unacked = unacked + 1&#xA;&#xA;    # assume that the ack is a single character, we don't care which&#xA;    acks = receive_response()      # receive a string of characters&#xA;    unacked = unacked - len(acks)  # number of characters = number of acks&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Note that this psuedocode is an example of spin blocking and that there are better ways to wait for input... but which one specifically will depend on how your PC code works.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2012-11-21T17:41:00.177" LastActivityDate="2012-11-21T17:41:00.177" CommentCount="2" />
  <row Id="377" PostTypeId="2" ParentId="117" CreationDate="2012-11-13T03:07:12.833" Score="0" Body="&lt;p&gt;Graph-based planning is a simplification of a space (that may be continuous) into the set of possible branching points, each representing the decisions that can be made.  In a pure simulation, that simplification usually goes as far as working in terms of steps instead of distance or time.  So, restricting movement to the 4 cardinal directions would be the correct choice because you'd want all the distances to be equal.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For a simulation with diagonals, it should still work -- provided that you adjust your algorithm so that diagonal step costs $\sqrt 2$ times more than the vertical/horizontal steps (which pushes you back in the direction of a continuous space, difficult to simulate).  But it might make more sense to just adopt a hexagonal grid if you want more ways to move between squares.  (For more discussion on grid types and their algorithms, see &lt;a href=&quot;http://www-cs-students.stanford.edu/~amitp/game-programming/grids/&quot; rel=&quot;nofollow&quot;&gt;http://www-cs-students.stanford.edu/~amitp/game-programming/grids/&lt;/a&gt;)&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Example 1&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;You have a car-style robot -- front-wheel steering.  You might represent 3 possible branches from each state: turn left, go straight, and turn right.  In this case, a hexagonal grid would make the most sense; at every space, only 3 of the 6 neighbors would be valid and exactly which ones would depend on the direction you came from.  This would reflect reality more than a cardinal-directions grid because to reach the space to your immediate right (or left) would require a U-turn over a few extra spaces.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Example 2&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;You have a gantry robot -- X and Y actuation.  In this case, both motors can be active at once, so moving diagonally &quot;costs&quot; the same as moving vertically or horizontally.  The 8-neighbor square grid would be correct.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Example 3&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;You are simulating a large room with some objects that move.  If you allow diagonal movement, you lose the ability to use an integer for the time component -- things would end up only partway between squares.  The 4-neighbor square grid would be correct.  &lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2012-11-13T03:07:12.833" />
  <row Id="378" PostTypeId="2" ParentId="167" CreationDate="2012-11-13T05:20:05.947" Score="2" Body="&lt;p&gt;In contrast to the other two answers I'd say a good manual way of tuning a PID is ignoring the Kd. So start at 0 and increase Kp until you are getting to the target, then increase Ki to get rid of steady state error.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Kd can confuse the issue as it responds poorly to noise, then you start adding filters on your analog input and then question what that does besides slow down your control and make the whole thing harder to work out...&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another thing bound to confuse me is if the PID equation is in the standard form or in an independent (parallel in wikipedia) form. The effect of Ki seems to inverse when the form is the wrong way to what you think it is. Both types are used in automation, sometimes with the option to switch between them.   &lt;/p&gt;&#xA;" OwnerUserId="412" LastActivityDate="2012-11-13T05:20:05.947" />
  <row Id="379" PostTypeId="2" ParentId="237" CreationDate="2012-11-13T05:52:44.040" Score="0" Body="&lt;p&gt;Instead of calculating the speed requirement (which may vary from time to time/comp to comp and whenever you change the code), there are some other things you can do:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Have your μC &lt;em&gt;request&lt;/em&gt; input by sending interrupts to the master device (in this case, it's a PC--you may not need to use interrupts, just keep a port reserved). You can either have the master device buffer the outputs (easier to do that with a pc--effectively unlimited buffering), or you can just discard them unless necessary.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;With your scenario, it's better to get rid of buffering entirely. Accept the inputs to the  μC via the interrupt pin. Have some flag variable that basically says &quot;need input&quot; on the μC. If this flag is set, the  μC will accept the input. Otherwise, it will just discard it. This way, all the input is rapidly consumed (keeping buffers free), but not all is used. For efficiency, adjust the timing to the approximate baud of the entire setup. Instead of discarding it, you may wish to code your own buffer-type thing--have a small array in which a few inputs are stored. Now, you have gotten rid of all the upstream buffers, and have a single &quot;artificial&quot; buffer on the μC--over which you have complete control.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;It may be better to keep all computations on the pc and use the μC as a simple slave controller--give it simple motion/position commands that can be piped directly to the motors. If you have enough interrupt pins/interrupt MUXing, you may want to send these commands via interrupts for faster response.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="126" LastActivityDate="2012-11-13T05:52:44.040" />
  <row Id="380" PostTypeId="1" AcceptedAnswerId="385" CreationDate="2012-11-13T09:34:55.917" Score="1" ViewCount="140" Body="&lt;p&gt;I want to build a robot arm that'll be approximately 1.25 meter long and will be able to lift up to 2 kilograms. It'll have 6 dof and it is an expensive project. And most importantly, i am the only programmer in this brand new robotics facility of ours. :)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The robot that i want to build will be led by Inverse Kinematics, so with all these parameters and matrices, i think that i'll need a tough processor (Not so sure).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Assuming that my robots control interface will be on an Android tablet, i thought that i also could develop my program for Android, and send necessary commands to the control chip via RS-232 interface.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, my question is, are standart 1 GHz Android tablets suitable for these tasks? If not, has anybody got an advice for me?&lt;/p&gt;&#xA;" OwnerUserId="305" LastEditorUserId="305" LastEditDate="2012-11-13T10:27:59.877" LastActivityDate="2012-11-13T23:08:16.067" Title="Processor and command interface preference for a robot arm" Tags="&lt;software&gt;&lt;inverse-kinematics&gt;&lt;arm&gt;&lt;rs232&gt;" AnswerCount="3" CommentCount="5" />
  <row Id="381" PostTypeId="2" ParentId="237" CreationDate="2012-11-13T10:02:18.053" Score="2" Body="&lt;blockquote&gt;&#xA;  &lt;p&gt;At 1st glance:&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;115200 == 115.2 bits per millisecond == ~12.8 bytes per millisecond&#xA;  (assuming 1 stop bit)&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Is that a valid way to calculate timing for&#xA;  serial transmissions?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Very simplistically, this is OK - but don't forget any start and parity bits also, and don't forget any protocol overhead along the bluetooth links&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Also, given my specific setup:&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;PC Program &amp;lt;--&gt; Bluetooth Serial Profile Driver &amp;lt;--&gt; Bluetooth&#xA;  Transceiver &amp;lt;-*-&gt; BlueSMIRF Wireless Modem &amp;lt;--&gt; Parallax Propellor&#xA;  Program&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;I think it is reasonable to assume that the PC through to the Modem are capable of handling the traffic at 115200 bps, so you can eliminate these from the equation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, having multiple hops like this does prevent use of flow-control signals, without introducing response messages... which would slow down response time.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now, take the worst case, of no protocol overhead, 115200 bps means your Parallax will be receiving a byte every 69us - adding in start, stop or parity bits will slow this rate down a little bit, but assuming worst case gives you some leeway.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This means that your controller has to handle receiving a byte every 69us, as well as doing its normal stuff (calculations etc).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But in reality, you will be sending a message string of (n) bytes, which need to be buffered, and processed as a string - whilst still doing the normal stuff.  Calculating the buffer is an art in itself, but I would normally work on (a minimum of) twice the size of the longest string (if you have the RAM space).  Anything less has the potential for losing messages, if one is not processed before reception of the next commences.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are restricted to only the length of the longest message, you need to be 100% sure that you can process that message between the receipt of the last byte, and the receipt of the first byte of the next message. (Obviously less of a problem with smaller messages).&lt;/p&gt;&#xA;" OwnerUserId="134" LastActivityDate="2012-11-13T10:02:18.053" />
  <row Id="382" PostTypeId="1" AcceptedAnswerId="386" CreationDate="2012-11-13T10:51:35.660" Score="10" ViewCount="1703" Body="&lt;p&gt;My team and I are setting up an outdoor robot that has encoders, a commercial-grade &lt;a href=&quot;http://en.wikipedia.org/wiki/IMU&quot;&gt;IMU&lt;/a&gt;, and &lt;a href=&quot;http://en.wikipedia.org/wiki/Global_Positioning_System&quot;&gt;GPS&lt;/a&gt; sensor. The robot has a basic tank drive, so the encoders sufficiently supply ticks from the left and right wheels. The IMU gives roll, pitch, yaw, and linear accelerations in x, y, and z. We could later add other IMUs, which would give redundancy, but could also additionally provide angular rates of roll, pitch, and yaw. The GPS publishes global x, y, and z coordinates.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Knowing the robot's x y position and heading will useful for the robot to localize and map out it's environment to navigate. The robot's velocity could also be useful for making smooth movement decisions. It's a ground-based robot, so we don't care too much about the z axis. The robot also has a &lt;a href=&quot;http://en.wikipedia.org/wiki/LIDAR&quot;&gt;lidar&lt;/a&gt; sensor and a camera--so roll and pitch will be useful for transforming the lidar and camera data for better orientation. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm trying to figure out how to fuse all these numbers together in a way that optimally takes advantage of all sensors' accuracy. Right now we're using a &lt;a href=&quot;http://en.wikipedia.org/wiki/Kalman_filter&quot;&gt;Kalman filter&lt;/a&gt; to generate an estimate of &lt;code&gt;[x, x-vel, x-accel, y, y-vel, y-accel]&lt;/code&gt; with the simple transition matrix:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;[[1, dt, .5*dt*dt, 0,  0,        0],&#xA; [0,  1,       dt, 0,  0,        0],&#xA; [0,  0,        1, 0,  0,        0],&#xA; [0,  0,        0, 1, dt, .5*dt*dt],&#xA; [0,  0,        0, 0,  1,       dt],&#xA; [0,  0,        0, 0,  0,        1]]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;The filter estimates state exclusively based on the accelerations provided by the IMU. (The IMU isn't the best quality; within about 30 seconds it will show the robot (at rest) drifting a good 20 meters from its initial location.) I want to know out how to use roll, pitch, and yaw from the IMU, and potentially roll, pitch, and yaw rates, encoder data from the wheels, and GPS data to improve the state estimate. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Using a bit of math, we can use the two encoders to generate x, y, and heading information on the robot, as well as linear and angular velocities. The encoders are very accurate, but they can be susceptible to slippage on an outdoor field. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;It seems to me that there are two separate sets of data here, which are difficult to fuse:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Estimates of x, x-vel, x-accel, y, y-vel, y-accel&lt;/li&gt;&#xA;&lt;li&gt;Estimates of roll, pitch, yaw, and rates of roll, pitch, and yaw&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Even though there's crossover between these two sets, I'm having trouble reasoning about how to put them together. For example, if the robot is going  at a constant speed, the direction of robot, determined by its x-vel and y-vel, will be the same as its yaw. Although, if the robot is at rest, the yaw cannot be accurately determined by the x and y velocities. Also, data provided by the encoders, translated to angular velocity, could  be an update to the yaw rate... but how could an update to the yaw rate end up providing better positional estimates?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Does it make sense to put all 12 numbers into the same filter, or are they normally kept separate? Is there already a well-developed way of dealing with this type of problem?&lt;/p&gt;&#xA;" OwnerUserId="181" LastEditorUserId="37" LastEditDate="2012-11-15T06:00:35.110" LastActivityDate="2013-03-04T16:46:18.293" Title="How to fuse linear and angular data from sensors" Tags="&lt;sensors&gt;&lt;kalman-filter&gt;&lt;sensor-fusion&gt;" AnswerCount="2" FavoriteCount="2" />
  <row Id="384" PostTypeId="2" ParentId="380" CreationDate="2012-11-13T13:54:06.703" Score="0" Body="&lt;p&gt;It looks like you are implementing Inverse kinematics(IK) control of robot manipulator for first time. I would suggest you to start of inverse kinematics control program in regular computer. Once you have implemented stable IK control program, you can implement the same same for Android tablet. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Please don't complicate the task which is already complicated! Best way start is to keep building of arm and developing IK control for the arm as separate modules and integrate them once both modules are working properly. For IK control program you can start off with simulated robot arm. Building reliable 6 DoF arm of reach 1.25 meter is definitely not easy job, especially if you are doing it for first time. It would be good idea to start with smaller prototype and later scale it up required size.&lt;/p&gt;&#xA;" OwnerUserId="289" LastActivityDate="2012-11-13T13:54:06.703" CommentCount="1" />
  <row Id="385" PostTypeId="2" ParentId="380" CreationDate="2012-11-13T13:56:20.310" Score="2" Body="&lt;p&gt;This project sounds quite plausible. The question is, where do the servo loops happen? Does it go through the Android Tablet, or just the control chip? What chip is this?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If the servo loops go through the tablet, then be warned that the tablet needs to be able to process that servo loop in good time each cycle. No being late, or missing cycles. No sudden waiting for a WiFi connection, or spending too much time doing voice recognition. It doesn't need to be hard real time (ROS isn't for example) but it should be fairly reliable.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If the servo loop goes only through the control chip, whatever that is, then that would be much better. The tablet would just send demand values to the control chip, and it wouldn't matter so much if these were a bit late or were skipped.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Your robot arm is only 6 degrees of freedom, meaning the Inverse Kinematics function can be solved analytically every control cycle, and will be very fast. 1GHz is actually quite a fast processor. I used to do IK on a &lt;a href=&quot;http://freespace.virgin.net/hugo.elias/models/m_ik.htm&quot; rel=&quot;nofollow&quot;&gt;12 DOF simulation&lt;/a&gt; in QBASIC on an old 486, and could easily get 30 FPS.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-11-13T13:56:20.310" CommentCount="2" />
  <row Id="386" PostTypeId="2" ParentId="382" CreationDate="2012-11-13T14:53:53.370" Score="11" Body="&lt;p&gt;Two things. &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;If you plan to do mapping, you need a full-fledged Simultaneous Localization and Mapping (SLAM) Algorithm. See: &lt;a href=&quot;http://www.cs.berkeley.edu/~pabbeel/cs287-fa09/readings/Durrant-Whyte_Bailey_SLAM-tutorial-I.pdf&quot; rel=&quot;nofollow&quot;&gt;Simultaneous Localisation and Mapping (SLAM):&#xA;Part I The Essential Algorithms&lt;/a&gt;. In SLAM, estimating the robot state is only half the problem. How to do that is a bigger question than can be answered here.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Regarding localization (estimating the state of the robot), this is not a job for a Kalman Filter. The transition from&#xA;$x(t)=[x,y,\dot{x},\dot{y},\theta,\dot{\theta}]$ to $x(t+1)$ is not a linear function due to the&#xA;angular accelerations and velocities. Therefore you need to consider&#xA;non-linear estimators for this task. Yes, there are standard ways of&#xA;doing this. Yes, they are available in literature. Yes, typically all&#xA;inputs are put into the same filter. Position, velocity,&#xA;orientation, and angular velocity of the robot are&#xA;used as outputs. And Yes, I'll present a brief introduction to their&#xA;common themes here.   The main take-aways are&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;include the Gyro and IMU bias in your state or your estimates will&#xA;diverge&lt;/li&gt;&#xA;&lt;li&gt;An &lt;a href=&quot;http://en.wikipedia.org/wiki/Extended_Kalman_filter&quot; rel=&quot;nofollow&quot;&gt;Extended Kalman Filter&#xA;(EKF)&lt;/a&gt; is commonly used for this problem&lt;/li&gt;&#xA;&lt;li&gt;Implementations can be derived from scratch, and don't generally&#xA;need to be &quot;looked up&quot;. &lt;/li&gt;&#xA;&lt;li&gt;Implementaitons exist for most of the localization and SLAM problem, so don't do more work than you have to. See: Robot Operating System &lt;a href=&quot;http://www.ros.org&quot; rel=&quot;nofollow&quot;&gt;ROS&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Now, to explain the EKF in the context of your system.&#xA;We have an IMU+Gyro, GPS, and&#xA;odometry. The robot in question is a differential drive as mentioned.&#xA;The filtering task is to take the current pose estimate of the robot&#xA;${\hat{x}_t}$, the control inputs $u_t$, and the measurements from&#xA;each sensor, $z_t$, and produce the estimate at the next time step&#xA;$\hat{x}_{t+1}$. We'll call the IMU measurements $I_t$, GPS is $G_t$, and&#xA;odometry, $O_t$. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I assume we are interested in estimating the robot pose as&#xA;$x_t={x,y,\dot{x},\dot{y},\theta,\dot{\theta}}$.&#xA;The problem with IMU and Gyros is drift. There is a non-stationary&#xA;bias in the accelerations which you must account for in the EKF. This&#xA;is done (usually) by putting the bias into the estimated state. This&#xA;allows you to directly estimate the bias at each time step.&#xA;$x_t={x,y,\dot{x},\dot{y},\theta,\dot{\theta},b}$, for a vector of&#xA;biases $b$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm assuming:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;$O_t$ = two distance measurements representing the distance the&#xA;treads have travelled in some small time increment&lt;/li&gt;&#xA;&lt;li&gt;$I_t$ = three orientation measurements ${\alpha, \beta, \theta}$ and three accelleration&#xA;measurements ${\ddot{x},\ddot{y},\ddot{z}}$. &lt;/li&gt;&#xA;&lt;li&gt;$G_t$ = the position of the robot in the &lt;em&gt;global&lt;/em&gt; frame,&#xA;$^Gx_t,^Gy_t$.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Typically, the result of the control inputs (desired speeds for each&#xA;tread) are difficult to map to the outputs (the change in the pose of&#xA;the robot).  In place of $u$, it is common (see &lt;a href=&quot;http://www.probabilistic-robotics.org/&quot; rel=&quot;nofollow&quot;&gt;Thrun&lt;/a&gt;, &lt;a href=&quot;http://robotics.stackexchange.com/questions/106/what-is-a-suitable-model-for-two-wheeled-robots/134#134&quot;&gt;Odometry Question&lt;/a&gt;) to use the&#xA;odometry as the &quot;result&quot; of the control. This assumption works well&#xA;when you are not on a near-frictionless surface. The IMU and GPS can&#xA;help correct for slippage, as we'll see.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So the first task is to predict the next state from the current state:&#xA;$\hat{x}_{t+1} = f(\hat{x}_t,u_t)$. In the case of a differential&#xA;drive robot, this prediction can be obtained directly from literature&#xA;(see &lt;a href=&quot;http://ijr.sagepub.com/content/8/5/15.short&quot; rel=&quot;nofollow&quot;&gt;On the Kinematics of Wheeled Mobile Robots&lt;/a&gt; or the more concise treatment in any modern robotics textbook), or derived from scratch as shown here: &lt;a href=&quot;http://robotics.stackexchange.com/questions/106/what-is-a-suitable-model-for-two-wheeled-robots/134#134&quot;&gt;Odometry Question&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, we can now predict $\hat{x}_{t+1} = f(\hat{x}_t, O_t)$. This is&#xA;the propagation or prediction step. You &lt;em&gt;can&lt;/em&gt; operate a robot by simply&#xA;propagating. If the values $O_t$ are completely accurate, you will&#xA;never have an estimate $\hat{x}$ which does not exactly equal your&#xA;true state. This never happens in practice.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This only gives a predicted value from the previous estimate,&#xA;and does not tell us how the accuracy of the estimate degrades with&#xA;time. So, to propagate the uncertainty, you must use the EKF equations&#xA;(which propagate the uncertainty in closed form under Gaussian noise&#xA;assumptions), a particle filter (which uses a sampling-based&#xA;approach)*, the UKF (which uses a point-wise approximation of the&#xA;uncertainty), or one of many other variants.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the case of the EKF, we proceed as follows. Let $P_t$ be the&#xA;covariance matrix of the robot state. We linearize the function $f$&#xA;using Taylor-series expansion to obtain a linear system. A linear&#xA;system can be easily solved using the Kalman Filter. Assume the&#xA;covariance of the estimate at time $t$ is $P_t$, and the assumed&#xA;covariance of the noise in the odometry is given as the matrix $U_t$&#xA;(usually a diagonal $2\times2$ matrix, like $.1\times I_{2\times 2}$).&#xA;In the case of the function $f$, we obtain the &lt;a href=&quot;http://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant&quot; rel=&quot;nofollow&quot;&gt;Jacobian&lt;/a&gt;&#xA;$F_x=\frac{\partial f}{\partial x}$ and $F_u=\frac{\partial f}{\partial&#xA;u}$, then propagate the uncertainty as,&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$P_{t+1}=F_x*P_t*F_x^T + F_u*U_t*F_u^T$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now we can propagate the estimate and the uncertainty. Note the&#xA;uncertainty will monotonically increase with time. This is expected.&#xA;To fix this, what is typically done, is to use the $I_t$ and $G_t$ to&#xA;update the predicted state. This is called the measurement step of the&#xA;filtering process, as the sensors provide an indirect measurement of&#xA;the state of the robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;First, use each sensor to estimate some part of the robot state&#xA;as some function $h_g()$ and $h_i()$ for GPS, IMU. Form&#xA;the &lt;em&gt;residual&lt;/em&gt; or &lt;em&gt;innovation&lt;/em&gt; which is the difference of the&#xA;predicted and measured values. &#xA;Then, estimate the accuracy for each sensor estimate in&#xA;the form of a covariance matrix $R$ for all sensors ($R_g$, $R_i$ in&#xA;this case). Finally, find the Jacobians of $h$ and update the state&#xA;estimate as follows:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For each sensor $s$ with state estimate $z_s$  (&lt;a href=&quot;http://en.wikipedia.org/wiki/Extended_Kalman_filter#Update&quot; rel=&quot;nofollow&quot;&gt;Following wikipedia's entry&lt;/a&gt;)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$v_s=z_s- h_s(\hat{x}_{t+1})$$&#xA;$$S_s = H_s*P_{t+1}*H_s^T + R_s$$&#xA;$$K = P_{t+1}*H_s^T S^{-1}_s$$&#xA;$$\hat{x}_{t+1} = \hat{x}_{t+1} - K*v$$&#xA;$$P_{t+1} = (I-K*H_s)*P_{t+1}$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the case of GPS, the measurement $z_g=h_g()$ it is probably just a&#xA;transformation from latitude and longitude to the local frame of the&#xA;robot, so the Jacobian $H_g$ will be nearly Identity. $R_g$ is&#xA;reported directly by the GPS unit in most cases.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the case of the IMU+Gyro, the function $z_i=h_i()$ is an integration of&#xA;accelerations, and an additive bias term. One way to handle the IMU is&#xA;to numerically integrate the accelerations to find a position and&#xA;velocity estimate at the desired time.  If your IMU has a small&#xA;additive noise term $p_i$ for each acceleration estimate, then you&#xA;must integrate this noise to find the accuracy of the position&#xA;estimate.  Then the covariance $R_i$ is the integration of all the&#xA;small additive noise terms, $p_i$. Incorporating the update for the&#xA;bias is more difficult, and out of my expertise. However, since you are interested in planar motion, you can probably simplify the problem. &#xA;You'll have to look in literature for this.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some off-the-top-of-my-head references: &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://www.ee.ucr.edu/~mourikis/papers/Li2012-ICRA.pdf&quot; rel=&quot;nofollow&quot;&gt;Improving the Accuracy of EKF-Based Visual-Inertial&#xA;Odometry&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://www-users.cs.umn.edu/~stergios/papers/AR-CL-Consistency-2010.pdf&quot; rel=&quot;nofollow&quot;&gt;Observability-based Consistent EKF Estimators for Multi-robot&#xA;Cooperative&#xA;Localization&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://s-space.snu.ac.kr/handle/10371/10151&quot; rel=&quot;nofollow&quot;&gt;Adaptive two-stage EKF for INS-GPS loosely coupled system with&#xA;unknown fault bias&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;This field is mature enough that google (scholar) could probably find&#xA;you a working implementation. If you are going to be doing a lot of&#xA;work in this area, I recommend you pick up a solid textbook. Maybe&#xA;something like &lt;a href=&quot;http://www.probabilistic-robotics.org/&quot; rel=&quot;nofollow&quot;&gt;Probablistic Robotics by S. Thrun&lt;/a&gt; of Google Car fame.&#xA;(I've found it a useful reference for those late-night&#xA;implementations).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;*There are several PF-based estimators available in the&#xA;&lt;a href=&quot;http://ros.org&quot; rel=&quot;nofollow&quot;&gt;Robot Operating System&lt;/a&gt; (ROS). However, these have&#xA;been optimized for indoor use. Particle filters deal with the&#xA;multi-modal PDFs which can result from map-based localization (am I&#xA;near &lt;em&gt;this&lt;/em&gt; door or &lt;em&gt;that&lt;/em&gt; door). I believe most outdoor&#xA;implementations (especially those that can use GPS, at least&#xA;intermittently) use the &lt;a href=&quot;http://en.wikipedia.org/wiki/Extended_Kalman_filter&quot; rel=&quot;nofollow&quot;&gt;Extended Kalman Filter&lt;/a&gt; (EKF). I've&#xA;successfully used the Extended Kalman Filter for an outdoor, ground&#xA;rover with differential drive. &lt;/p&gt;&#xA;" OwnerUserId="163" LastEditorUserId="37" LastEditDate="2013-03-04T16:46:18.293" LastActivityDate="2013-03-04T16:46:18.293" CommentCount="3" />
  <row Id="387" PostTypeId="2" ParentId="317" CreationDate="2012-11-13T15:26:29.630" Score="2" Body="&lt;p&gt;You could think of robotics as being broken down into 3 parts: sensing, decision making, and actuating.  Open loop systems are just the &quot;actuating&quot; part of that picture, and it sounds like you have a good handle on that already from your work with CNC machines.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I think the next area for you to check out would be sensing.  It's not as easy as it looks, and Katy Levinson will explain some of it to you: &lt;a href=&quot;http://www.youtube.com/watch?v=gFW0schumkE&quot; rel=&quot;nofollow&quot;&gt;http://www.youtube.com/watch?v=gFW0schumkE&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Not that you need to jump right into sophisticated sensors.  Getting comfortable with sensors (and their limitations, and filtering, and combining separate sensors into a unified world view) could be as simple as using a clock and a light sensor to determine whether it is a cloudy day ouside.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The last thing to check out would be the decision making: how to use the data from the sensors to decide what to do with the actuators.  There are too many possibilities to enumerate here, so it's best to come up with a project idea like &quot;I want to dispense water into my plants when the soil gets too dry&quot; or &quot;I want to close my blinds at night and open them in the morning&quot; or &quot;I want to put a sharpie in my CNC machine and move the table to plot the signal from my phone's accelerometer in realtime&quot;.... then use that problem to teach yourself the theory.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2012-11-13T15:26:29.630" />
  <row Id="388" PostTypeId="2" ParentId="380" CreationDate="2012-11-13T23:08:16.067" Score="0" Body="&lt;p&gt;How many degrees of freedom do you plan to implement?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I use Arduino Mega for my arm with 4 axis and plan to use simple ARM processor instead it.&lt;/p&gt;&#xA;" OwnerUserId="415" LastActivityDate="2012-11-13T23:08:16.067" CommentCount="2" />
  <row Id="390" PostTypeId="1" AcceptedAnswerId="393" CreationDate="2012-11-13T23:27:22.663" Score="3" ViewCount="257" Body="&lt;p&gt;I have been using the Cyberglove to control a humanoid robot hand, but found it disappointing as it doesn't measure the posture of the human hand very accurately.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/T7TYQ.png&quot; alt=&quot;Cyberglove&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have been wondering about the possibility of using Inertial Measurement Units (&lt;a href=&quot;http://en.wikipedia.org/wiki/Inertial_measurement_unit&quot; rel=&quot;nofollow&quot;&gt;IMU&lt;/a&gt;s) mounted on the fingers to track position and measure posture. But I'm not sure how feasible it is.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Would an IMU return enough data to make tracking reliable in all circumstances?&lt;/li&gt;&#xA;&lt;li&gt;Would it be possible to fool the system into incorrectly tracking the fingers?&lt;/li&gt;&#xA;&lt;li&gt;Might it be possible to get away with using simple 3-axis accelerometers, or would it need 9-axis (accelerometer, gyro, and magnetometer)?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="40" LastEditorUserId="350" LastEditDate="2012-11-30T14:27:09.583" LastActivityDate="2012-11-30T14:27:09.583" Title="Can I use IMUs to improve the position/posture measurement of fingers in a &quot;data glove&quot;?" Tags="&lt;imu&gt;&lt;sensor-fusion&gt;&lt;hri&gt;" AnswerCount="3" CommentCount="1" />
  <row Id="391" PostTypeId="2" ParentId="255" CreationDate="2012-11-14T01:37:30.583" Score="1" Body="&lt;p&gt;Parrallax offers some products in the space you are looking, but I think what you really want to do is go to hobby king; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/__657__501__Multi_Rotors_Parts-Flight_Controller.html&quot; rel=&quot;nofollow&quot;&gt;http://www.hobbyking.com/hobbyking/store/_&lt;em&gt;657&lt;/em&gt;_501__Multi_Rotors_Parts-Flight_Controller.html&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;make no mistake, they ARE cheap copies of other products, and if that bothers you go back to parallax and spend the full amount. I'd go with the 550 frame with motors, and add speed controlers, and props then&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Look at &lt;a href=&quot;http://store.openpilot.org/&quot; rel=&quot;nofollow&quot;&gt;http://store.openpilot.org/&lt;/a&gt; for open source modifiable hardware and software. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;hobby king also has a few controllers including an arduino, but I'd prefer the wii if it was me (just personal preference)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is not a plug and play adventure!! You will at very least end up soldering your own cables, and if you are not comfortable with that, stay clear.&lt;/p&gt;&#xA;" OwnerUserId="274" LastEditorUserId="274" LastEditDate="2012-11-14T01:50:06.967" LastActivityDate="2012-11-14T01:50:06.967" />
  <row Id="393" PostTypeId="2" ParentId="390" CreationDate="2012-11-14T04:27:42.560" Score="5" Body="&lt;p&gt;Simple 3-axis accelerometers will give you an estimate of pitch. However, this will be very noisy, especially when the hand is moving from one pose to another. This is because the direction of acceleration is directly used to estimate the direction of gravity. Thus, &lt;strong&gt;this option would only be useful if the hand is not moving&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Gyroscopes allow the direction of gravity to be stabilized. &lt;strong&gt;This allows the data to remain useful during movement.&lt;/strong&gt; Drift/bias is not a problem, so long as you correct for this. This can be done by using a Kalman filter, with a model of gyroscopic drift. The drift is corrected by comparing the derivative of the long term estimate of the direction of gravity compared to the gyroscopic data. Some IMUs correct for drift automatically, for example, the &lt;a href=&quot;http://www.vectornav.com/products/vn100-rug&quot; rel=&quot;nofollow&quot;&gt;VN-100 from VectorNav&lt;/a&gt;. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Magnetometers provides a global estimate of the remaining angular direction (yaw). This simply &lt;strong&gt;adds further useful data&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you only place the IMUs on the fingertips, the data is insufficient to estimate pose. Remember that IMUs only measure &lt;strong&gt;attitude&lt;/strong&gt; (also known as orientation) in space. Can you imagine cases where the fingertip may remain in the same orientation, yet the hand pose is different?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/cUbSv.jpg&quot; alt=&quot;Hand pose&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Observe that the index fingertip orientation does not change, however, the position (pose) has changed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Therefore, you can see that IMU data on the fingertips is not enough to estimate pose. However, additional data can improve the estimate of hand pose, if you fuse the IMU data with your existing data using a Kalman filter.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It is theoretically &lt;strong&gt;possible&lt;/strong&gt; for &lt;strong&gt;IMU data alone&lt;/strong&gt; to be sufficient to estimate pose. However, this would require an IMU for each and every &lt;strong&gt;independently movable&lt;/strong&gt; part of the hand. Since I cannot independently move the top two segments of each finger, we would only need 2 IMUs per finger (one on the fingertip, and one on the segment just after the knuckle, ie. segments 1 and 3 on the finger), plus 2 for the hand, and another for the end of the arm (to get the wrist motion). Therefore, you need a total of &lt;strong&gt;13 IMUs&lt;/strong&gt; to get all the data required.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I do not know that much about the price of tiny IMUs, however, I would guess that it is not that cheap to get that many IMUs (I don't know your budget). Normally, a single IMU is used for a rigid body. IMUs vary in price (a list at &lt;a href=&quot;http://damien.douxchamps.net/research/imu/&quot; rel=&quot;nofollow&quot;&gt;http://damien.douxchamps.net/research/imu/&lt;/a&gt;), but say, the VN-100 IMU might be able to give you 0.1 degree accuracy in optimal conditions. If you get a cheaper IMU, the accuracy may not be as good and/or they may lack an integrated Kalman Filter. Getting 13 VN-100 IMUs, costing thousands would probably break the bank (although the VN-100 at 20x20x2mm may not be appropriate if you want an IMU with a smaller form factor).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My suggestion is to consider other data sources which may be obtained more cheaply. For example:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;camera-based systems&lt;/strong&gt;, after image processing, you can get data about the position of different parts of the hand. Image processing can be aided by using some sort of reflective markers.&lt;/li&gt;&#xA;&lt;li&gt;sensors embedded in the fabric of the glove&#xA;&lt;ul&gt;&#xA;&lt;li&gt;strain gauges&lt;/li&gt;&#xA;&lt;li&gt;SMA wire&lt;/li&gt;&#xA;&lt;li&gt;...&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="145" LastEditorUserId="145" LastEditDate="2012-11-14T10:18:24.913" LastActivityDate="2012-11-14T10:18:24.913" CommentCount="3" />
  <row Id="395" PostTypeId="2" ParentId="390" CreationDate="2012-11-14T08:55:43.483" Score="1" Body="&lt;p&gt;While &lt;a href=&quot;http://robotics.stackexchange.com/a/393/127&quot;&gt;ronalchn&lt;/a&gt; already provided a pretty good answer, I would actually like to take the stance that it should be possible. It would essentially work the same as the &lt;a href=&quot;http://www.xsens.com/en/general/mvn&quot; rel=&quot;nofollow&quot;&gt;full-body tracking&lt;/a&gt; devices that XSens is selling. In these applications you perform model fitting, based on the orientation data from your imu. I am not sure how many sensing nodes you would need, but e.g. you could use something like this integrated &lt;a href=&quot;https://www.sparkfun.com/products/10937&quot; rel=&quot;nofollow&quot;&gt;6DOF IMU&lt;/a&gt; sensor. Using 13 sensors wouldn't be all that implausible anymore, even from a price point of view. I guess you could also do it with just accelerometers, and one full IMU on the wrist, but it would be quite involved. In the end it comes down to the accuracy that you require.&lt;/p&gt;&#xA;" OwnerUserId="127" LastActivityDate="2012-11-14T08:55:43.483" />
  <row Id="397" PostTypeId="1" CreationDate="2012-11-14T12:29:54.057" Score="-1" ViewCount="103" Body="&lt;p&gt;I am interested in Robotics. Practically I have no idea about Robotics. I want to start learning the basics of Robotics. But I am confused what to start with. So I need suggestions about what will be the best resources to start Robotics with. That may be books, sites, or others. Please help me with this.&lt;/p&gt;&#xA;" OwnerUserId="408" LastEditorUserId="37" LastEditDate="2012-11-14T16:36:51.893" LastActivityDate="2012-11-14T16:36:51.893" Title="Resources for learning basics of Robotics" Tags="&lt;books&gt;" AnswerCount="1" CommentCount="2" ClosedDate="2012-11-14T16:45:19.933" />
  <row Id="398" PostTypeId="2" ParentId="397" CreationDate="2012-11-14T13:50:06.693" Score="2" Body="&lt;p&gt;I suspect that this question will be closed fairly quickly, because you're asking a very broad one, but here goes:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Robotics is a VERY broad field, encompassing mechanical, electro-magnetic, electronic and software aspects, coupled with a lot of control theory. You need to decide what part of this you are interested in.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Do you want to build something from a kit? Do you want to construct something that can evolve (eg Lego, Meccanno) or do you want to design something from scratch, designing your own algorithms?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Where do you want to start?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you can narrow the question down a bit, then we can help :)&lt;/p&gt;&#xA;" OwnerUserId="134" LastEditorUserId="134" LastEditDate="2012-11-14T13:59:51.867" LastActivityDate="2012-11-14T13:59:51.867" CommentCount="2" />
  <row Id="399" PostTypeId="5" CreationDate="2012-11-14T16:42:06.267" Score="0" ViewCount="16" Body="&lt;h1&gt;Unmanned aerial vehicle.&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;From the &lt;a href=&quot;http://en.wikipedia.org/wiki/Unmanned_aerial_vehicle&quot; rel=&quot;nofollow&quot;&gt;Wikipedia page&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;An &lt;strong&gt;unmanned aerial vehicle&lt;/strong&gt; (&lt;strong&gt;UAV&lt;/strong&gt;), commonly known as a &lt;strong&gt;drone&lt;/strong&gt;, is an aircraft without a human pilot on board. Its flight is either controlled autonomously by computers in the vehicle, or under the remote control of a navigator, or pilot (in military UAVs called a Combat Systems Officer on UCAVs) on the ground or in another vehicle.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;There are a wide variety of drone shapes, sizes, configurations, and characteristics. Historically, UAVs were simple remotely piloted aircraft, but autonomous control is increasingly being employed.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;They are predominantly deployed for military applications, but also used in a small but growing number of civil applications, such as firefighting and nonmilitary security work, such as surveillance of pipelines. UAVs are often preferred for missions that are too 'dull, dirty, or dangerous' for manned aircraft.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;h3&gt;Note that:&lt;/h3&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Questions about &lt;a href=&quot;http://en.wikipedia.org/wiki/Autonomous_underwater_vehicle&quot; rel=&quot;nofollow&quot;&gt;Autonomous underwater vehicle&lt;/a&gt;s should use the &lt;a href=&quot;/questions/tagged/auv&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'auv'&quot; rel=&quot;tag&quot;&gt;auv&lt;/a&gt; tag.&lt;/li&gt;&#xA;&lt;li&gt;Questions about autonomous &lt;a href=&quot;http://en.wikipedia.org/wiki/Unmanned_ground_vehicle&quot; rel=&quot;nofollow&quot;&gt;Unmanned ground vehicle&lt;/a&gt;s should use the &lt;a href=&quot;/questions/tagged/ugv&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'ugv'&quot; rel=&quot;tag&quot;&gt;ugv&lt;/a&gt; tag.&lt;/li&gt;&#xA;&lt;li&gt;The &lt;a href=&quot;/questions/tagged/drone&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'drone'&quot; rel=&quot;tag&quot;&gt;drone&lt;/a&gt; tag should only be used for questions about autonomous drones which don't fit into the &lt;a href=&quot;/questions/tagged/auv&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'auv'&quot; rel=&quot;tag&quot;&gt;auv&lt;/a&gt;, &lt;a href=&quot;/questions/tagged/uav&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'uav'&quot; rel=&quot;tag&quot;&gt;uav&lt;/a&gt; or &lt;a href=&quot;/questions/tagged/ugv&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'ugv'&quot; rel=&quot;tag&quot;&gt;ugv&lt;/a&gt; tags.&lt;/li&gt;&#xA;&lt;li&gt;Questions about &lt;a href=&quot;http://en.wikipedia.org/wiki/Unmanned_aerial_vehicle#Degree_of_autonomy&quot; rel=&quot;nofollow&quot;&gt;remotely controlled UAV&lt;/a&gt;s are probably off topic on &lt;em&gt;Robotics&lt;/em&gt; and are more likely to be suitable over on &lt;a href=&quot;http://electronics.stackexchange.com/&quot;&gt;Electrical Engineering&lt;/a&gt; Stack Exchange.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="37" LastEditorUserId="37" LastEditDate="2012-11-19T19:57:02.677" LastActivityDate="2012-11-19T19:57:02.677" />
  <row Id="400" PostTypeId="4" CreationDate="2012-11-14T16:42:06.267" Score="0" Body="Unmanned aerial vehicle. See also the tags [tag:ugv], [tag:auv] &amp; [tag:drone]." OwnerUserId="37" LastEditorUserId="37" LastEditDate="2012-11-19T19:56:55.737" LastActivityDate="2012-11-19T19:56:55.737" />
  <row Id="401" PostTypeId="5" CreationDate="2012-11-14T16:47:36.117" Score="0" ViewCount="4" Body="&lt;p&gt;A motor, not necessarily electric, which converts energy into some kind of motion. More generic than &lt;em&gt;motor&lt;/em&gt; which is usually assumed to be both electric and rotary.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From the &lt;a href=&quot;http://en.wikipedia.org/wiki/Actuator&quot; rel=&quot;nofollow&quot;&gt;Wikipedia page&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;An &lt;strong&gt;actuator&lt;/strong&gt; is a type of motor for moving or controlling a mechanism or system. It is operated by a source of energy, usually in the form of an electric current, hydraulic fluid pressure or pneumatic pressure, and converts that energy into some kind of motion. An actuator is the mechanism by which an agent acts upon an environment. The agent can be either an artificial intelligence agent or any other autonomous being (human, other animal, etc.).&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="37" LastEditorUserId="37" LastEditDate="2012-11-14T17:30:26.647" LastActivityDate="2012-11-14T17:30:26.647" />
  <row Id="402" PostTypeId="4" CreationDate="2012-11-14T16:47:36.117" Score="0" Body="A motor, not necessarily electric, which converts energy into some kind of motion." OwnerUserId="37" LastEditorUserId="37" LastEditDate="2012-11-14T17:30:22.210" LastActivityDate="2012-11-14T17:30:22.210" />
  <row Id="403" PostTypeId="1" AcceptedAnswerId="421" CreationDate="2012-11-14T16:52:39.187" Score="-2" ViewCount="110" Body="&lt;p&gt;I am aware of the legislation's in Nevada, but what is happening with the technology currently. When is it expected to be commercialized ?&lt;/p&gt;&#xA;" OwnerUserId="417" LastEditorUserId="350" LastEditDate="2012-11-30T14:01:14.433" LastActivityDate="2012-11-30T14:01:14.433" Title="What is the current state of the Google Self Driving Car Project?" Tags="&lt;ugv&gt;" AnswerCount="2" CommentCount="3" ClosedDate="2012-12-05T21:15:29.853" />
  <row Id="404" PostTypeId="2" ParentId="369" CreationDate="2012-11-14T17:40:44.207" Score="2" Body="&lt;p&gt;If you consider e.g. a robotic arm, the inverse kinematics tell you how to choose the arm's joint angles to move the arm to some position and orientation where you want it to be. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In contrast to determining the forward kinemactics of some mechanism, determining it's &lt;em&gt;inverse kinematics&lt;/em&gt; is usually hard and sometimes, there isn't even an analytic solution. Industrial robots, however, are often designed in such a way that they have an analytic solution for the inverse kinematics. This can be achieved by e.g. clever alignment of joint axes. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Reinforcement Learning&lt;/em&gt;, on the other hand, is a machine learning technique. Like any other machine learning technique or algorithm, it can be used to determine a function which you don't know - given that you choose a good reward function that is related to the problem you want to solve. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, in a nutshell: you can use Reinforcement Learning to determine the inverse kinematics of a robot (if there is no analytical solution or determining one would be ridiculously hard). &lt;/p&gt;&#xA;" OwnerUserId="422" LastActivityDate="2012-11-14T17:40:44.207" />
  <row Id="405" PostTypeId="1" CreationDate="2012-11-14T17:56:40.557" Score="7" ViewCount="91" Body="&lt;p&gt;I have never used an accelerometer before, but I am aware that they come with I2C, SPI and analog outputs. If I choose to use an I2c or SPI, device, will I accumulate errors due to communication time?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is the fast sampling of an analog signal likely to get me a more accurate deduced position than using am I2C?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Will this be true for &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;A robot moving in a room &lt;/li&gt;&#xA;&lt;li&gt;A robot moving in an outdoor terrain and is likely to slip and roll down a slope.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Also, I have no sense of Gs. I tried to move my hand around fast with my phone running andro-sensor in my fist and saw that the readings saturated at 20m/s&lt;sup&gt;2&lt;/sup&gt;. What G can I expect my robot to experience if it is hit by another fat moving bot or bumped by a fast walking human?&lt;/p&gt;&#xA;" OwnerUserId="272" LastEditorUserId="134" LastEditDate="2012-11-15T08:21:41.017" LastActivityDate="2012-11-15T20:16:37.210" Title="Selecting an accelerometer for Deduced Reckoning" Tags="&lt;sensors&gt;&lt;deduced-reckoning&gt;&lt;navigation&gt;&lt;accelerometer&gt;" AnswerCount="3" />
  <row Id="406" PostTypeId="2" ParentId="405" CreationDate="2012-11-14T18:11:42.773" Score="4" Body="&lt;p&gt;Increasing the sampling frequency of the sensor doesn't improve it's accuracy or precision. That is a feature of the sensor which you usually cannot change. If you try to estimate your position by integrating accelerations alone, you definitely &lt;em&gt;will&lt;/em&gt; accumulate error over time, because every sensor is noisy. If you want to use the accelerometers to determine position or velocity, you should combine them with some other sensor that actually measures position (even with lower precision) or velocity. Then, you can combine these different sensor signals with a &lt;em&gt;Kalman filter&lt;/em&gt; to obtain a reasonable estimate of where you are and how fast you are moving. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Considering G forces, consider that 1 G is 9.81 m/s^2, which seems a lot to me, in the context of small hobby robots, at least for indoor robots. Outdoor could be a different story, depending on how powerful your engine is. A saturation at 20m/s^2 should be enough.&lt;/p&gt;&#xA;" OwnerUserId="422" LastActivityDate="2012-11-14T18:11:42.773" />
  <row Id="407" PostTypeId="5" CreationDate="2012-11-14T18:17:17.483" Score="0" ViewCount="4" Body="&lt;p&gt;deduced-reckoning, Dead Reckoning or ded reckoning is a technique of computing the current position based on a known initial position by integrating the acceleration experienced through time and the velocity.&lt;/p&gt;&#xA;" OwnerUserId="272" LastEditorUserId="272" LastEditDate="2012-11-15T19:50:06.613" LastActivityDate="2012-11-15T19:50:06.613" />
  <row Id="408" PostTypeId="4" CreationDate="2012-11-14T18:17:17.483" Score="0" Body="Deduced Reckoning, Dead Reckoning or Ded Reckoning is a technique of computing the current position based on a known initial position." OwnerUserId="272" LastEditorUserId="272" LastEditDate="2012-11-15T19:49:19.080" LastActivityDate="2012-11-15T19:49:19.080" />
  <row Id="409" PostTypeId="5" CreationDate="2012-11-14T18:21:43.823" Score="0" ViewCount="2" Body="&lt;p&gt;Accelerometers may measure acceleration on one two or three axis. It is useful in deduced reckoned navigation of robots. All accelerometers measure 1G og force due to the gravitation of the earth.&lt;/p&gt;&#xA;" OwnerUserId="272" LastEditorUserId="272" LastEditDate="2012-11-15T19:49:48.813" LastActivityDate="2012-11-15T19:49:48.813" />
  <row Id="410" PostTypeId="4" CreationDate="2012-11-14T18:21:43.823" Score="0" Body="Accelerometer is a sensor that measures acceleration." OwnerUserId="272" LastEditorUserId="272" LastEditDate="2012-11-15T19:50:14.163" LastActivityDate="2012-11-15T19:50:14.163" />
  <row Id="411" PostTypeId="2" ParentId="358" CreationDate="2012-11-14T18:28:36.620" Score="1" Body="&lt;p&gt;Don't fix it in software. Fix it in your mechanical cable harness design. If you try to do it in software, your robot will inevitably break itself. Even if it never exceeds its limits, using a cable this way will wear it out quickly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Trying to share the slack between joints will require sliding movement of the cable, which will damage the cable over time by abrasion and by repeatedly bending the cable around tight radii when you get close to overall limits. Sharing the slack means you'll have to attach the cable loosely, which will make it tend to flop around, encouraging you to leave even less slack.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Instead, fix the cable along each segment of the robot and treat each joint individually. Ensure that the cable bend radius is greater than 10X its diameter (more is better) over the entire range of motion of each joint. If this requires a large loop, then there are chain cable guides (looks a bit like wide plastic bicycle chain) to help keep it from getting in the way of other parts. &lt;/p&gt;&#xA;" OwnerUserId="223" LastActivityDate="2012-11-14T18:28:36.620" CommentCount="1" />
  <row Id="412" PostTypeId="2" ParentId="405" CreationDate="2012-11-14T19:03:51.070" Score="3" Body="&lt;p&gt;Think in terms of your control loop speed. A typical fast control loop speed is 1kHz. Some robots use a faster rate, some slower. Usually your control loop speed is higher than you really need it to be.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So each control frame lasts for 1000us. Within this control frame you need to:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Sample your sensors&lt;/li&gt;&#xA;&lt;li&gt;Perform the control calculations&lt;/li&gt;&#xA;&lt;li&gt;Send the new outputs to the motors&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;As long as you can comfortably do all of this within the time frame, you've got no problems. So how long does it take to read the accelerometer? If it's a 3-axis device, using 400kbps I2C, then it might take about 160us to read the data. That leaves you 840us to perform the calculation and update the motors. Even an 8-bit PIC can manage that.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;About G forces. During an impact, they can be surprisingly high. For example, how much of a whack do you think it would take to break a hard drive? Probably not that much. Well a hard drive I had recently said it was rated for 75G max acceleration. So expect two robots colliding to produce at least several G. It's impossible to estimate accurately because it depends hugely on the mechanical design of the robots. If they are both completely solid like snooker balls, then you can expect very high accelerations. If they have some kind of flexible shell to them, then this will reduce the acceleration a great deal. But, the question is, do you really need to know the actual value of acceleration during an impact?&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-11-14T19:03:51.070" />
  <row Id="413" PostTypeId="1" CreationDate="2012-11-14T19:12:09.213" Score="6" ViewCount="938" Body="&lt;p&gt;I have not bought any parts yet, but I am making my own quadcopter. I have done the research and know all about the parts that I need, but many guides are sponsored and cost thousand(s) of euros/dollars while not explaining things entirely clearly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Firstly, I have found this &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/__24723__Hobbyking_KK2_0_Multi_rotor_LCD_Flight_Control_Board.html&quot;&gt;flight control board&lt;/a&gt;. Would I need another microcontroller (such as the Arduino nano) for it to work? (IF ANYONE has experience with this board, let me know!).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Secondly, would the above board work with this &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/uh_viewitem.asp?idproduct=9042&amp;amp;aff=655899&quot;&gt;radio controller&lt;/a&gt;. Are controllers universal?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(Please tell me if I'm not in the right section here, or if this doesn't count as a relevant topic).&lt;/p&gt;&#xA;" OwnerUserId="424" LastEditorUserId="350" LastEditDate="2012-11-30T21:17:52.360" LastActivityDate="2012-12-14T02:38:47.913" Title="Questions about quadcopter and radio controller" Tags="&lt;microcontroller&gt;&lt;quadrotor&gt;&lt;radio-control&gt;" AnswerCount="3" CommentCount="4" FavoriteCount="1" />
  <row Id="414" PostTypeId="2" ParentId="403" CreationDate="2012-11-14T20:28:22.223" Score="0" Body="&lt;p&gt;Google themselves have suggested that fully self driving cars will not be around for a decade. They have cars that can drive themselves but the entire standard is not there yet. It's difficult to take any risks with this project because it puts so many lives at risk. &lt;/p&gt;&#xA;" OwnerUserId="80" LastActivityDate="2012-11-14T20:28:22.223" />
  <row Id="415" PostTypeId="2" ParentId="413" CreationDate="2012-11-14T21:02:51.210" Score="3" Body="&lt;p&gt;As I understand it, the flight control board allows you to control your Quadcopter using a standard 5 or 6 channel RC receiver. So you don't need any other equipment. The radio controller you suggested is 6 channel, so that's plenty. The flight control board just provides stability, as it would be almost impossible for a human to control the speeds of all four motors rapidly enough to keep it stable.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You'll be able to steer the quadcopter using the controller, but won't be able to use GPS or anything clever without adding some more electronics.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-11-14T21:02:51.210" />
  <row Id="416" PostTypeId="1" AcceptedAnswerId="465" CreationDate="2012-11-14T21:36:19.967" Score="10" ViewCount="216" Body="&lt;p&gt;I apologize if this question may sound a little vague. I am working on a robotics project that will contain 27 servos of various sizes and I am having trouble figuring it how they should be powered.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I was hoping to use several (3-6) 5 W 18650 battery boxes to power them, but the smallest motors would use 2.5 W each, so 1 battery box can only power two. The larger servos, obviously, use even more current, so this plan of using a small number of 18650's becomes infeasible.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is not enough room on the robot for a 12 V car battery, and adding one would require recalculating the sizes of the servomotors that would be needed. Furthermore, I am not sure how to convert the 12 V it gives down to 5 V for the servomotors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;P.S. What about the stall current of the motors? Should the power supply be able to supply the stall current of all the motors it supplies (at the same time) or just the working current? Should I use a fuse to handle when (if?) the servomotors stall? Should I use a fuse or a circuit breaker? Do they make 5 V fuses? If so, where can I get one?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Something like a larger version of the 18650 box would be most preferable.&lt;/p&gt;&#xA;" OwnerDisplayName="user428" LastEditorUserId="350" LastEditDate="2012-11-30T14:33:14.603" LastActivityDate="2012-11-30T14:33:14.603" Title="What is the best way to power a large number (27) servos at 5 V?" Tags="&lt;design&gt;&lt;servos&gt;&lt;power&gt;" AnswerCount="3" CommentCount="2" FavoriteCount="1" />
  <row Id="417" PostTypeId="2" ParentId="416" CreationDate="2012-11-14T22:49:08.870" Score="1" Body="&lt;p&gt;This problem is a lot like rocket science. With a rocket, the heavier it is, the more fuel they need to lift off which makes it even heavier! You have your servos, but to power them you need a big battery making the robot heavier, this means stronger servos and an even bigger battery! If you can't work out how to power the robot with an onboard battery then prehaps you would have to settle for an off-board power supply.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Hope this helps.&lt;/p&gt;&#xA;" OwnerUserId="374" LastActivityDate="2012-11-14T22:49:08.870" />
  <row Id="418" PostTypeId="2" ParentId="416" CreationDate="2012-11-14T22:55:39.167" Score="6" Body="&lt;p&gt;It's always difficult speccing the power supply for a robot, and you've hit the exact problem we all face. Do you spec it to cope with the typical load, or the absolute maximum load when all motors are stalled at max current?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There's no right answer to this, except that whatever happens it shouldn't damage anything. The good news is that the servos probably won't be consuming 2.5W all the time, so a good way to start is to connect your system up to a large power supply with an ammeter and measure the actual current draw under typical heavy use. Once you know the maximum current draw, you can spec the batteries for that. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The other thing you need to decide is how long you want the thing to run for. That will tell you how much battery capacity you need, and therefore the size of the battery. But, as you say, if that means you need a larger battery, then it might mean you need larger servos and more current, and therefore a larger battery! There might be no solution to this problem, except:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Ease your requirements. Accept that the robot won't run as long as you'd hoped.&lt;/li&gt;&#xA;&lt;li&gt;If possible, add torsion springs to the servos to help them lift the battery weight. This will mean they consume slightly less power.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;But what to do in the extreme case where all the motors are stalled?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You might consider something like a &lt;a href=&quot;http://www.linear.com/products/hot_swap_controllers&quot;&gt;Hot Swap controller&lt;/a&gt;. This is a little chip which guards the power input to your system. It protects against the large inrush current caused by your system's capacitors. It also protects against over current in general, as well as over voltage.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-11-14T22:55:39.167" />
  <row Id="419" PostTypeId="1" AcceptedAnswerId="622" CreationDate="2012-11-14T23:06:21.523" Score="-1" ViewCount="198" Body="&lt;p&gt;I'm building a walking robot that will need to know when it moves forward. I'm using on-board intelligence and I plan on using accelerometers, gyros, and magnometers (if needed) to be able to detect if the robot moves forward. The problem is, I dont know how to program an Internal Navigation System or an IMU.  What software algorithms are needed?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To clarify my problem, I need to know how to program the micro controller to read the sensors and be able to tell if the robot has displaced itself &lt;em&gt;forward&lt;/em&gt; since a previous measurement.&#xA;Also if I used &lt;a href=&quot;http://store.diydrones.com/ArduIMU_V3_p/kt-arduimu-30.htm&quot; rel=&quot;nofollow&quot;&gt;this sensor board&lt;/a&gt; (or similar) could I use it to determine the displacement. &lt;/p&gt;&#xA;" OwnerUserId="374" LastEditorUserId="350" LastEditDate="2012-12-04T04:55:36.247" LastActivityDate="2012-12-04T04:55:36.247" Title="How do you implement an INS from an accelerometer and (optionally) gyros and a magnetometer?" Tags="&lt;software&gt;&lt;imu&gt;&lt;deduced-reckoning&gt;&lt;artificial-intelligence&gt;" AnswerCount="2" CommentCount="4" />
  <row Id="420" PostTypeId="2" ParentId="413" CreationDate="2012-11-14T23:26:52.390" Score="4" Body="&lt;p&gt;We have used an older generation of that board in our lab. It takes it's commands via RC which means you would not need another microcontroller. It is only a hover controller however so if you want to do any autonomy you will need another solution. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;One possibility is to use an &lt;a href=&quot;http://arduino.cc&quot; rel=&quot;nofollow&quot;&gt;Arduino&lt;/a&gt; and an &lt;a href=&quot;http://www.trossenrobotics.com/p/Xbee-Communication-Starter-Kit.aspx&quot; rel=&quot;nofollow&quot;&gt;Xbee&lt;/a&gt; to replace the RC system and use your computer to control it. We have been doing this in our lab for nearly a year now and it works fairly well.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another solution is to use an &lt;a href=&quot;http://diydrones.com&quot; rel=&quot;nofollow&quot;&gt;ArduPilot&lt;/a&gt; (instead of the aforementioned controller) and communicate directly with it via an Xbee. Again you will use your laptop, desktop, or tablet to control it.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2012-11-14T23:26:52.390" CommentCount="1" />
  <row Id="421" PostTypeId="2" ParentId="403" CreationDate="2012-11-15T00:00:01.140" Score="3" Body="&lt;p&gt;There's a good, if slightly overly optimistic study done by KPMG and the Center for Automotive Research called &lt;a href=&quot;http://www.kpmg.com/US/en/IssuesAndInsights/ArticlesPublications/Documents/self-driving-cars-next-revolution.pdf&quot; rel=&quot;nofollow&quot;&gt;Self Driving Cars: the Next Revolution&lt;/a&gt;.  You'll be seeing more and more semi-autonomous features within the decade, starting in higher end vehicles (all the major automakers are working on such systems and we already have advanced cruise control and lane departure warning).  However full autonomy is still a fair ways off, for cost as well as perception and institutional/legal issues.  One of the problems with commercializing Google's car is that the sensor systems cost over $250,000 (see &lt;a href=&quot;http://www.businessinsider.com/google-self-driving-car-sensor-cost-2012-9&quot; rel=&quot;nofollow&quot;&gt;http://www.businessinsider.com/google-self-driving-car-sensor-cost-2012-9&lt;/a&gt;).  Even with economies of scale, we're a ways off from that system being affordable. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Google's accomplishments are VERY impressive.  They've expanded to more vehicle types and more uses for testing (e.g., commuting to and from Google).  They still don't work in all environments (snow being one issue).  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;By the way, though, California and Florida have joined Nevada in passing laws regulating experimental use of autonomous vehicles on public roads.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Hope this gives you some info.&lt;/p&gt;&#xA;" OwnerUserId="58" LastActivityDate="2012-11-15T00:00:01.140" CommentCount="3" />
  <row Id="422" PostTypeId="2" ParentId="419" CreationDate="2012-11-15T03:00:09.867" Score="2" Body="&lt;p&gt;If you're looking for an inexpensive sensor, you could check out &lt;a href=&quot;http://www.invensense.com/mems/gyro/mpu6050.html&quot; rel=&quot;nofollow&quot;&gt;InvenSense's MPU-6000&lt;/a&gt;, which combines a 3-axis gyroscope and a 3-axis accelerometer. It communicates via an I2C or SPI bus with your main processor and is capable of estimating attitude when you add a magnetometer.&lt;/p&gt;&#xA;" OwnerUserId="295" LastActivityDate="2012-11-15T03:00:09.867" />
  <row Id="423" PostTypeId="2" ParentId="341" CreationDate="2012-11-15T06:43:47.260" Score="3" Body="&lt;p&gt;Robot tendons aren't much different from any other load-bearing cable. The same sources of stress and wear apply: the load tension, bending around pulleys, friction with other objects and friction between its own strands.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Fatigue is much of what limits the life of a cable/wire rope, and both bending stress and abrasion play a role. Each time a section of the cable passes through a pulley or is wound around a drum, it must bend and straighten again. This creates a repeated reversing stress that causes cracks to grow through the material until it breaks (fatigue). Abrasion has a synergistic effect, by roughening the outside of the wires and making it easier for cracks to form. Both the abrasion and bending stresses are greatest at the outside of the cable, so those strands tend to fail first.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It might not even be the cable itself that breaks. Consider an everyday cable actuated mechanism: the window regulator that raises and lowers side windows in an automobile. It's not usually the cable or motor that fails, but rather the pulleys break. The pulleys are usually plastic and only supported on one side, so they're not as strong as the steel cable they're supporting. Sometimes the manufacturers don't even use pulleys, and instead just use a U-shaped plastic channel. Then, the cable slowly saws through the plastic piece. I suppose it only has to outlast the warranty.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some guidelines for maximum life are:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Keep the diameters of pulleys and winding drums large relative to the cable. 10 times the diameter of the cable is barely enough, and 40 times the diameter of the cable is not too much.&lt;/li&gt;&#xA;&lt;li&gt;Lubricating the cable helps extend life both by reducing abrasion and by letting the strands slide against each other, making the cable more flexible and reducing bending stress.&lt;/li&gt;&#xA;&lt;li&gt;Don't neglect the other parts of the system, such as the pulleys the cable wraps around, guides it runs through, and its attachment points. &lt;/li&gt;&#xA;&lt;li&gt;Don't neglect the environment. Make sure any materials can handle the temperatures and chemicals they may be exposed to. Keep abrasive dust away from anything that moves.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;As far as fatigue testing materials goes, there are commercial testing machines for fatigue testing wire and cable, and testing houses that can perform the tests as a service. Actually getting a sample to fail in fatigue can take days at low stress levels, and accelerated (high stress) tests don't map easily across different materials. Narrowing options down based on calculations before testing is a good idea.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;References:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Shigley et al. &lt;em&gt;Mechanical Engineering Design&lt;/em&gt;, 7th ed. McGraw Hill, 2004 (specifically, chapter 17-6 on Wire Rope)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.wireropeworks.com/product_pdfs/EL_TB_09.pdf&quot; rel=&quot;nofollow&quot;&gt;Wirerope Works Technical Bulletin on Fatigue&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="223" LastActivityDate="2012-11-15T06:43:47.260" />
  <row Id="424" PostTypeId="5" CreationDate="2012-11-15T06:56:37.133" Score="0" ViewCount="8" Body="&lt;p&gt;A Kalman filter is an optimal estimator for linear dynamical systems with Gaussian noise. This algorithm takes as a series of noisy measurements from the dynamical system and combines them to estimate possibly unknown variables. In fact, if the system meets the theoretical assumptions of having linear dynamics and Gaussian noise, there is no better estimate of the unknown system state. The filter itself is usually defined in terms of matrices, one for the system model, one for the control model, one for the process noise, one for the observation model and one for the measurement noise.&lt;/p&gt;&#xA;" OwnerUserId="42" LastEditorUserId="42" LastEditDate="2012-11-15T19:49:42.823" LastActivityDate="2012-11-15T19:49:42.823" />
  <row Id="425" PostTypeId="4" CreationDate="2012-11-15T06:56:37.133" Score="0" Body="A Kalman filter is an optimal estimator for linear dynamical systems with Gaussian noise." OwnerUserId="42" LastEditorUserId="42" LastEditDate="2012-11-15T19:49:36.240" LastActivityDate="2012-11-15T19:49:36.240" />
  <row Id="426" PostTypeId="5" CreationDate="2012-11-15T07:00:33.970" Score="0" ViewCount="2" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2012-11-15T07:00:33.970" LastActivityDate="2012-11-15T07:00:33.970" />
  <row Id="427" PostTypeId="4" CreationDate="2012-11-15T07:00:33.970" Score="0" Body="Rapidly-exploring Random Trees is an algorithm for performing motion planning in high-dimensional spaces" OwnerUserId="42" LastEditorUserId="42" LastEditDate="2012-11-15T19:49:46.163" LastActivityDate="2012-11-15T19:49:46.163" />
  <row Id="428" PostTypeId="2" ParentId="413" CreationDate="2012-11-15T07:02:41.943" Score="5" Body="&lt;p&gt;specific answers;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;yes that controller will work fine, and is pretty popular. No it does not need anything additional other than to be hooked up to the receiver. from it, you hook up four speed controllers, and to them 4 motors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;yes that transmitter receiver will work, but it is a little on the 'too inexpensive' side. You do realize it requires hooking it up to a computer to reverse a channel don't you? If you really can guarantee that will not be an inconvenience, then it will work, but usually people opt for the turnigy 9x (http://www.hobbyking.com/hobbyking/store/_&lt;em&gt;8992&lt;/em&gt;_Turnigy_9X_9Ch_Transmitter_w_Module_8ch_Receiver_Mode_2_v2_Firmware_.html). The great thing about it is that it often flashed with an improved firmware; &lt;a href=&quot;http://code.google.com/p/er9x/&quot; rel=&quot;nofollow&quot;&gt;http://code.google.com/p/er9x/&lt;/a&gt;  It is only a few more dollars and will be a much better choice. If you are at a point where 30 dollars makes a difference, do NOT get involved in this hobby. Radio controllers are universal, and what you buy now should last you for many years, so spend the extra $30 and get something a little better quality and more popular.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Edit - update: I purchased both of these since writing this answer. The transmitter is still work in progress but will become a long range transmitter (10 or so miles). The KK board has been pretty impressive, I've been pleased with it so far. &lt;a href=&quot;http://www.youtube.com/watch?v=gm-UdPIaIv4&quot; rel=&quot;nofollow&quot;&gt;watch&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="274" LastEditorUserId="274" LastEditDate="2012-12-14T02:38:47.913" LastActivityDate="2012-12-14T02:38:47.913" CommentCount="4" />
  <row Id="429" PostTypeId="5" CreationDate="2012-11-15T09:09:12.877" Score="0" ViewCount="6" Body="&lt;p&gt;A two-wire (data, SDA and clock SCL) bi-directional master/slave data-bus, originally for slow-speed peripherals (100KHz clock speed) but now available in faster versions (up to 5MHz)&lt;/p&gt;&#xA;" OwnerUserId="134" LastEditorUserId="134" LastEditDate="2012-11-15T19:49:12.217" LastActivityDate="2012-11-15T19:49:12.217" />
  <row Id="430" PostTypeId="4" CreationDate="2012-11-15T09:09:12.877" Score="0" Body="A two-wire bi-directional master/slave data-bus" OwnerUserId="134" LastEditorUserId="134" LastEditDate="2012-11-15T19:49:40.187" LastActivityDate="2012-11-15T19:49:40.187" />
  <row Id="431" PostTypeId="1" AcceptedAnswerId="448" CreationDate="2012-11-15T12:23:57.450" Score="-2" ViewCount="244" Body="&lt;p&gt;I'm planning to write an Inverse Kinematics controlled 6 dof virtual robot for Android. I did some research on packages avaliable and couldn't choose the right one which will satisfy my needs on this project. I've seen a work with Eigen in C++, and used it, it was just fine. But since i'm not so experienced in Java, i wanted to ask before i start, if someone knows some appropiate packages for these operations.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here is what i found so far:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;JAMA,&#xA;Vecmath,&#xA;Jmathtools,&#xA;EJML,&#xA;JAMPACK&#xA;I ask this because i really dont want to get stuck in the middle of my project. Thanks in advance.&lt;/p&gt;&#xA;" OwnerUserId="305" LastActivityDate="2012-11-17T18:29:07.723" Title="Inverse Kinematics in Java" Tags="&lt;inverse-kinematics&gt;&lt;programming-languages&gt;" AnswerCount="1" CommentCount="4" />
  <row Id="432" PostTypeId="2" ParentId="390" CreationDate="2012-11-15T14:47:10.517" Score="3" Body="&lt;p&gt;The short answer is yes, this can work.  The long answer is &quot;Yes, but you need to do a lot of sensor fusion&quot;.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The technology you're after was conceived about 5 years ago, the academic work is here:&#xA;&lt;a href=&quot;http://people.csail.mit.edu/wojciech/MoCap/index.html&quot; rel=&quot;nofollow&quot;&gt;http://people.csail.mit.edu/wojciech/MoCap/index.html&lt;/a&gt;&#xA;&lt;img src=&quot;http://people.csail.mit.edu/wojciech/MoCap/teaser.jpg&quot; alt=&quot;Motion capture in the real world&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;They combined the accelerometer data with ultrasonic ranges between the joints to improve the position estimation.  In this case, it was for full-body motion capture but doing it for just fingers should be a similar problem.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This project immediately became a company that began making motion capture devices (for 3D movies, video games, etc), but I can't remember the company name.  A google search led me to &quot;animazoo&quot;, but I don't think that's what it was called before.  Maybe it's the same company with a new name.  In either case, those are the only relevant resources I know of but they seem to support your idea.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2012-11-16T19:11:53.780" LastActivityDate="2012-11-16T19:11:53.780" />
  <row Id="433" PostTypeId="1" CreationDate="2012-11-15T17:23:01.367" Score="6" ViewCount="226" Body="&lt;p&gt;What are the pros/cons of the different &lt;a href=&quot;http://en.wikipedia.org/wiki/Visual_odometry&quot; rel=&quot;nofollow&quot;&gt;visual&lt;/a&gt; &lt;a href=&quot;http://en.wikipedia.org/wiki/Odometry&quot; rel=&quot;nofollow&quot;&gt;odometry&lt;/a&gt; options? &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Stereo Camera&lt;/li&gt;&#xA;&lt;li&gt;Optical Flow&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping&quot; rel=&quot;nofollow&quot;&gt;SLAM&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;other?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Criteria:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;how well it performs vs other odometry options/sensors (lidar, radar)&lt;/li&gt;&#xA;&lt;li&gt;sensor fidelity&lt;/li&gt;&#xA;&lt;li&gt;computation&lt;/li&gt;&#xA;&lt;li&gt;accuracy&lt;/li&gt;&#xA;&lt;li&gt;precision&lt;/li&gt;&#xA;&lt;li&gt;drift&lt;/li&gt;&#xA;&lt;li&gt;native resilience and repeadability in sensor noise or vehicle speed&lt;/li&gt;&#xA;&lt;li&gt;ease of integrating with &lt;a href=&quot;http://en.wikipedia.org/wiki/Inertial_measurement_unit&quot; rel=&quot;nofollow&quot;&gt;IMU&lt;/a&gt;/GPS&lt;/li&gt;&#xA;&lt;li&gt;etc&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;In general, of course, because there are a lot of different ways the trade-offs go when we get into specifics about applications and hardware.  I'm asking out of curiosity, not for designing anything in particular.&lt;/p&gt;&#xA;" OwnerUserId="431" LastEditorUserId="350" LastEditDate="2012-11-30T14:08:50.077" LastActivityDate="2013-03-23T17:38:19.233" Title="Visual Odometry options?" Tags="&lt;mobile-robot&gt;&lt;localization&gt;&lt;computer-vision&gt;&lt;odometry&gt;" AnswerCount="3" CommentCount="5" FavoriteCount="1" ClosedDate="2013-05-30T22:40:31.200" />
  <row Id="434" PostTypeId="5" CreationDate="2012-11-15T18:02:17.957" Score="0" ViewCount="3" Body="&lt;p&gt;Odometry is used by some robots, whether they be legged or wheeled, to estimate (not determine) their position relative to a starting location. This method is sensitive to errors due to the integration of velocity measurements over time to give position estimates. Rapid and accurate data collection, equipment calibration, and processing are required in most cases for odometry to be used effectively.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;-From &lt;a href=&quot;http://en.wikipedia.org/wiki/Odometry&quot; rel=&quot;nofollow&quot;&gt;Wikipedia&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="272" LastEditorUserId="272" LastEditDate="2012-11-15T19:49:08.660" LastActivityDate="2012-11-15T19:49:08.660" />
  <row Id="435" PostTypeId="4" CreationDate="2012-11-15T18:02:17.957" Score="0" Body="Odometry is the use of data from moving sensors to estimate change in position over time." OwnerUserId="272" LastEditorUserId="272" LastEditDate="2012-11-15T19:50:10.203" LastActivityDate="2012-11-15T19:50:10.203" />
  <row Id="436" PostTypeId="1" CreationDate="2012-11-15T18:24:02.007" Score="7" ViewCount="228" Body="&lt;p&gt;The answers I received to the question on &lt;a href=&quot;http://robotics.stackexchange.com/questions/361/programming-a-line-following-robot-with-reinforcement-learning&quot;&gt;training a line following robot using reinforcement learning techniques&lt;/a&gt;, got me to think on how to train a robot. I believe there are essentially two ways -&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Train the physical robot.&lt;/li&gt;&#xA;&lt;li&gt;Model the robot and simulate the training.&lt;/li&gt;&#xA;&lt;li&gt;Did I miss something?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Approach 2 is definitely the better approach. However, a priori knowledge of the motion (response), a certain PWM signal (stimulus) would cause when the robot is in a given state is required. The motion caused by a PWM signal may depend on the (&lt;strong&gt;1&lt;/strong&gt;) current battery voltage, (&lt;strong&gt;2&lt;/strong&gt;) the mass of the robot and the (&lt;strong&gt;3&lt;/strong&gt;) current velocity (did I miss something?).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How do I model such a robot? And how do I model it quick? If I change the battery or add a few boards and other peripherals and change the mass of the robot, I would have to remodel and retrain the robot. Can I do this by providing some random stimulus PWMs and measuring the response?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;added:&lt;/strong&gt; My related &lt;a href=&quot;http://dsp.stackexchange.com/questions/6006/how-do-i-compute-the-imuplse-response-of-a-robot&quot;&gt;question in dsp.SE&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; A suggested edit to the title by &lt;a href=&quot;http://robotics.stackexchange.com/users/350/ian&quot;&gt;Ian&lt;/a&gt; worth mentioning - &quot;&lt;em&gt;How do I model train a robot so that if its dynamics change, it does not need complete re-training?&lt;/em&gt;&quot; I think this is a good question too but different from the one I am asking here. I am okay with re-training for now.&lt;/p&gt;&#xA;" OwnerUserId="272" LastEditorUserId="558" LastEditDate="2012-12-05T18:14:26.897" LastActivityDate="2013-01-22T08:45:23.490" Title="How do I model a robot?" Tags="&lt;reinforcement-learning&gt;&lt;pwm&gt;" AnswerCount="2" CommentCount="8" FavoriteCount="2" />
  <row Id="437" PostTypeId="2" ParentId="433" CreationDate="2012-11-15T18:41:39.893" Score="2" Body="&lt;p&gt;I'm not familiar with all visual odometry options, but you might find the following two articles that recently appeared in the IEEE Robotics and Automation Magazine relevant:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Scaramuzza, D., Fraundorfer, F., &lt;strong&gt;Visual Odometry: Part I - The First 30 Years and Fundamentals&lt;/strong&gt;, IEEE Robotics and Automation Magazine, Volume 18, issue 4, 2011.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Fraundorfer, F., Scaramuzza, D., &lt;strong&gt;Visual Odometry: Part II - Matching, Robustness, and Applications&lt;/strong&gt;, IEEE Robotics and Automation Magazine, Volume 19, issue 2, 2012.&lt;/p&gt;&#xA;" OwnerUserId="295" LastActivityDate="2012-11-15T18:41:39.893" />
  <row Id="438" PostTypeId="5" CreationDate="2012-11-15T19:21:25.573" Score="0" ViewCount="3" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2012-11-15T19:21:25.573" LastActivityDate="2012-11-15T19:21:25.573" />
  <row Id="439" PostTypeId="4" CreationDate="2012-11-15T19:21:25.573" Score="0" Body="BLDC stands for &quot;Brush-Less DC&quot;, as in &quot;BLDC Motor&quot;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2012-11-15T19:49:00.487" LastActivityDate="2012-11-15T19:49:00.487" />
  <row Id="440" PostTypeId="2" ParentId="433" CreationDate="2012-11-15T20:03:10.383" Score="4" Body="&lt;p&gt;In general, visual odometry is a method that performs odometric measurements using visual means. This rules out the SLAM component, since visual odometry is only a relative means of navigation (see my answer on &lt;a href=&quot;http://robotics.stackexchange.com/a/207/127&quot;&gt;navigation&lt;/a&gt;). There are a number of methods to extract the relative motion of the camera. Since the transform from camera to robot is known this will also give you the relative transform of your robot.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;If you only work with a single camera, you will always have a scale ambiguity, unless you have something to resolve that ambiguity in your image (e.g. object of known size) or combine it with another form of odometry like wheel odometry.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;From a vision point of you, there are two ways you can follow: dense and sparse processing. Dense processing means, you use a regular sampling of your image points for your processing (could also be the full image). Sparse processing would mean, that you first extract feature points and only perform your operations on these features. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Using optical flow for visual odometry, I would consider a dense approach. Once you got the flow field, you need to extract the motion components. This is not so trivial, as it largely depends on how your environment looks. There was an interesting way of resolving this in the presence of outliers presented in &quot;Monocular Heading Estimation in Non-Stationary Urban Environment&quot;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Sparse approaches will use features, which are extracted using feature detectors. Then there are two different methods on handling the features. First approach will perform tracking of the feature and in this way estimate where the scene point was moving to. Second approach performs association of features through feature descriptors. First one is usually used with fast algorithms on high frequency, while the second one is more robust to larger scene changes and hence can be run at lower frequency. The visual odometry on the MER Rovers works this way e.g. Some form of geometric constraint is used to remove outliers, usually with a form of RANSAC. There is quite a nice library called &lt;a href=&quot;http://www.cvlibs.net/software/libviso2.html&quot; rel=&quot;nofollow&quot;&gt;libviso2&lt;/a&gt; for performing visual odometry this way.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="127" LastActivityDate="2012-11-15T20:03:10.383" />
  <row Id="441" PostTypeId="2" ParentId="405" CreationDate="2012-11-15T20:16:37.210" Score="1" Body="&lt;p&gt;From your question I figure you are trying to get your position from the accelerometers. Have a look at what sort of &lt;a href=&quot;http://www.vectornav.com/support/library?id=76#unaided-position-estimate&quot; rel=&quot;nofollow&quot;&gt;errors&lt;/a&gt; you are expecting before, and then maybe reconsider. Position estimation has very large errors, mainly due to the uncertainty in the orientation. The application in ships, planes, rockets etc use very expensive high precision navigation grade IMUs. The latency, which your question boils down to is not so much of a problem. More relevant is the synchronization between your other sensors (e.g. Gyros). Accelerometers are usually not used for position estimation (there are some cases where it helps, but only for short periods), but rather for compensating gyro drift in orientation estimation. You can also use them directly to estimate your orientation, but then your estimate is perturbed by dynamic accelerations. &lt;/p&gt;&#xA;" OwnerUserId="127" LastActivityDate="2012-11-15T20:16:37.210" CommentCount="1" />
  <row Id="442" PostTypeId="1" CreationDate="2012-11-15T20:52:29.157" Score="8" ViewCount="239" Body="&lt;p&gt;Digital compasses (magnetometers) require a hard/soft iron calibration in order to be accurate.  This compensates for the magnetic disturbances caused by nearby metal objects -- the robot's chassis.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/vrsV8.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(image from &lt;a href=&quot;http://diydrones.com/forum/topics/magnetometer-soft-and-hard-iron-calibration&quot;&gt;http://diydrones.com&lt;/a&gt;)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, digital compasses are also susceptible to the electric fields caused by the relatively high amount of current drawn by motors.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In order to get an accurate compass reading, what is the best way to measure (and compensate for) the interference caused by changing motor current levels?&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2012-11-15T22:36:42.447" Title="How can the dynamic effects of motor current on a digital compass be characterized and compensated for?" Tags="&lt;mobile-robot&gt;&lt;sensors&gt;" AnswerCount="1" CommentCount="3" />
  <row Id="443" PostTypeId="2" ParentId="442" CreationDate="2012-11-15T22:36:42.447" Score="6" Body="&lt;p&gt;Generally, this is not possible. This is because motors usually rotate very rapidly, creating rapidly fluctuating magnetic fields. Whether the disturbance is enough depends on how large the motors are.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, because I mounted an IMU (Inertial Measurement Unit) with magnetometers near some motors, and was forced to turn off the magnetometers to avoid the measurement affecting the state estimation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In practice, the solutions most likely to solve your problem is:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;move the compass/magnetometer away from from the motors&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;use shielding material (basically material with high magnetic permeability). They do not block magnetic fields, but because they provide a path of low magnetic resistance, they attact the magnetic field (lines from north to south) to pass through their interior, so that the magnetic field intensity is lower elsewhere.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The best shape for magnetic shields is thus a closed container surrounding the shielded volume. The effectiveness of this type of shielding depends on the material's permeability, which generally drops off at both very low magnetic field strengths and at high field strengths where the material becomes saturated. So to achieve low residual fields, magnetic shields often consist of several enclosures one inside the other, each of which successively reduces the field inside it. - &lt;a href=&quot;http://en.wikipedia.org/wiki/Electromagnetic_shielding#Magnetic_shielding&quot;&gt;Wikipedia/Magnetic shielding&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;You can thus wrap the motors in shielding material, such as:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Giron&lt;/li&gt;&#xA;&lt;li&gt;MagnetShield&lt;/li&gt;&#xA;&lt;li&gt;PaperShield&lt;/li&gt;&#xA;&lt;li&gt;Magnetic Shielding Foil&lt;/li&gt;&#xA;&lt;li&gt;Mag-Stop Plates&lt;/li&gt;&#xA;&lt;li&gt;MetGlas&lt;/li&gt;&#xA;&lt;li&gt;JointShield&lt;/li&gt;&#xA;&lt;li&gt;Finemet (for kHz frequency fields)&lt;/li&gt;&#xA;&lt;li&gt;CobalTex&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;A good site for comparison of these materials is &lt;a href=&quot;http://www.lessemf.com/mag-shld.html&quot;&gt;LessEMF.com Magnetic Field Shielding&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;It is theoretically possible to correct for the magnetic disturbance without shielding. We do need to be aware that there are two possible sources - a rotating permanent magnet and/or current in the coils. If we have feedback of the rotor position, we can correct for the permanent magnet or coil position. If you perform some experiments, recording current and rotor position, you should be able to fit a model of the magnetic field. Fitting is necessary because the actual field strength is very hard to calculate because of how the magnetic field looks depends on the size and shape of both the magnet and coils.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In practice, it is difficult to do this - unless the motor is turning very slowly and your sensor and model is accurate enough. First, if the frequency is high, it can cause problems because of synchronization issues and communication delays. If you cannot synchronize the data obtained from the motor feedback (position and current) and that from your magnetometers, you will increase your uncertainty. Even if the frequency is low, you need to have good control of the accuracy of:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;the magnetometer&lt;/li&gt;&#xA;&lt;li&gt;the model&lt;/li&gt;&#xA;&lt;li&gt;the inputs to the model (position and current)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;If any of the above are not accurate enough, the residue magnetic field (assumed to be the earth's magnetic field) could be very inaccurate.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In general, accuracy can be decreased by:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;frequency&lt;/li&gt;&#xA;&lt;li&gt;motor field strength (since for the equation $residue magnetic field = raw measurement - motor model$, if the two terms on the right hand side are large, even at 1% accuracy, taking the difference could result in large left hand side uncertainties)&lt;/li&gt;&#xA;&lt;li&gt;sensor resolutions&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="145" LastActivityDate="2012-11-15T22:36:42.447" CommentCount="2" />
  <row Id="444" PostTypeId="2" ParentId="436" CreationDate="2012-11-16T00:42:20.687" Score="3" Body="&lt;p&gt;As I see it there are two main questions here. The first is, how do I model a robot? This is frequently done with a &lt;a href=&quot;http://en.wikipedia.org/wiki/State_space&quot; rel=&quot;nofollow&quot;&gt;state-space&lt;/a&gt; formulation of the &lt;a href=&quot;http://en.wikipedia.org/wiki/Equations_of_motion&quot; rel=&quot;nofollow&quot;&gt;equations of motion&lt;/a&gt;. The exact equations depend on the physical construction of your robot. Yes, in order to model them with PWM input then you need to determine the transfer function from the PWM values you supply to the output of your actuators. Then you plug that function in for the control signal in your model. Again the derivation of this function is robot specific. The current battery voltage and the mass of the robot would likely be useful but I don't know about the velocity.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The second question is, given a mathematical model of my robot, what is the best way to train a reinforcement learning (RL) algorithm to control it? In short there is no one best way. Training directly on the robot tends to be time consuming because it takes the robot longer to execute trials. Simulations however can result in policies that are less accurate because the physics of the simulation are necesssarily simplified. Another approach is to train the learner in simulation to get a reasonable approximation and then transfer the resulting policy to the robot for further refinement. This of course fails if the model is not sufficiently accurate. It also requires extra development.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Finally you ask &quot;Can I [remodel and retrain the robot] by providing some random stimulus PWMs and measuring the response?&quot; In the case of RL there is no reason to think the new optimal policy is anything like the previous optimal policy and as such there isn't much reason to think a few random controls will supply sufficient information to change the policy appropriately. Of course retraining only needs to occur if the changes you make to your robot affect the formulation of the state-space model and/or the action model that you use. For instance, if your action model is in terms of high level actions (&quot;go-left&quot;, &quot;go-right&quot;, &quot;go-forward&quot;) then changing the dynamics requires changing how you implement these motions but the policy should still hold.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2012-11-16T00:42:20.687" />
  <row Id="445" PostTypeId="1" CreationDate="2012-11-16T20:22:37.827" Score="6" ViewCount="429" Body="&lt;p&gt;I am trying to use a stereo camera for scene reconstruction, but I can usually only obtain sparse point clouds (i.e. over half the image does not have any proper depth information). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I realize that stereo processing algorithms rely on the presence of texture in the images and have a few parameters that can be tweaked to obtain better results, such as the disparity range or correlation window size. As much as I tune these parameters, though, I am never able to get results that are even remotely close to what can be obtained using an active sensor such as the Kinect.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The reason why I want that is because very often point clouds corresponding to adjacent regions don't have enough overlap for me to obtain a match, so reconstruction is severely impaired.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My question to the Computer Vision experts out there is the following: &lt;strong&gt;what can I do to obtain denser point clouds in general&lt;/strong&gt; (without arbitrarily modifying my office environment)?&lt;/p&gt;&#xA;" OwnerUserId="95" LastActivityDate="2012-11-24T00:03:25.917" Title="How to obtain dense point clouds from stereo cameras?" Tags="&lt;slam&gt;&lt;computer-vision&gt;" AnswerCount="3" CommentCount="3" FavoriteCount="2" />
  <row Id="446" PostTypeId="1" AcceptedAnswerId="525" CreationDate="2012-11-16T21:03:22.347" Score="5" ViewCount="1335" Body="&lt;p&gt;I have a handful of 31.2oz-in stepper motors (&lt;a href=&quot;http://www.mouser.com/Search/ProductDetail.aspx?R=HT17-268Dvirtualkey55010000virtualkey834-HT17-268D&quot;&gt;Mouser.com - Applied Motion: HT17-268D&lt;/a&gt;), and I was curious if they would be big enough to run a 3D printing/cutting/etching type (think RepRap) of machine. I had in mind to attach them via  a simple gear to a screw-type drive to run the tool head back and forth. &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Maximum bed size would probably be ~1.5'&lt;sup&gt;3&lt;/sup&gt;. &lt;/li&gt;&#xA;&lt;li&gt;Heaviest tool head would be something about half the weight of a Dremel tool.&lt;/li&gt;&#xA;&lt;li&gt;Hardest substances I would use it on would probably be hardwoods (with high speed cutter) and copper (for PCB etching).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;How do I figure the amount of torque needed to drive the head, and would the motors that I already have be big enough to do the job?&lt;/p&gt;&#xA;" OwnerUserId="416" LastActivityDate="2013-05-09T18:51:47.127" Title="How much torque do I need for a CNC machine?" Tags="&lt;stepper-motor&gt;&lt;reprap&gt;" AnswerCount="3" CommentCount="5" FavoriteCount="3" />
  <row Id="447" PostTypeId="2" ParentId="445" CreationDate="2012-11-17T10:54:45.570" Score="3" Body="&lt;p&gt;You can try to skip the salient point detection, and just densely sample over the image (as grid or so) and compute a feature descriptor at every sample point. You can probably even go as far as computing a descriptor for every pixel.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You might lose scale-invariance, but I think this won't hurt too much for stereo vision as objects will be at approximately the same scale in both images.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another approach might be to combine multiple salient point detection algorithms: corners, edges, blobs and so on. Then you have to use the same feature descriptor algorithm for all detected points, however this latter part could be somewhat tricky to implement.&lt;/p&gt;&#xA;" OwnerUserId="443" LastActivityDate="2012-11-17T10:54:45.570" />
  <row Id="448" PostTypeId="2" ParentId="431" CreationDate="2012-11-17T18:29:07.723" Score="2" Body="&lt;p&gt;These are matrix-vector math libraries. They are related to inverse kinematics only because inverse kinematics involves matrices, vectors, and math. If you need an implementation of an inverse kinematics library, that is a different question. But any of those would be fine for doing the required math, once you solve the inverse kinematics in closed form or by some other method. Personally, I've used JAMA (it works).&lt;/p&gt;&#xA;" OwnerUserId="163" LastActivityDate="2012-11-17T18:29:07.723" />
  <row Id="449" PostTypeId="5" CreationDate="2012-11-18T00:55:48.197" Score="0" ViewCount="8" Body="&lt;h1&gt;Autonomous underwater vehicle.&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;From the &lt;a href=&quot;http://en.wikipedia.org/wiki/Autonomous_underwater_vehicle&quot; rel=&quot;nofollow&quot;&gt;Wikipedia page&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;An &lt;strong&gt;autonomous underwater vehicle (AUV)&lt;/strong&gt; is a robot which travels underwater without requiring input from an operator. AUVs constitute part of a larger group of undersea systems known as &lt;a href=&quot;http://en.wikipedia.org/wiki/Unmanned_underwater_vehicle&quot; rel=&quot;nofollow&quot;&gt;unmanned underwater vehicles&lt;/a&gt;, a classification that includes non-autonomous &lt;a href=&quot;http://en.wikipedia.org/wiki/Remotely_operated_underwater_vehicle&quot; rel=&quot;nofollow&quot;&gt;remotely operated underwater vehicles (ROVs)&lt;/a&gt; – controlled and powered from the surface by an operator/pilot via an umbilical or using remote control. In military applications AUVs more often referred to simply as &lt;strong&gt;unmanned undersea vehicles (UUVs)&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;h3&gt;Note that:&lt;/h3&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Questions about autonomous &lt;a href=&quot;http://en.wikipedia.org/wiki/Unmanned_aerial_vehicle&quot; rel=&quot;nofollow&quot;&gt;Unmanned aerial vehicle&lt;/a&gt;s should use the &lt;a href=&quot;/questions/tagged/uav&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'uav'&quot; rel=&quot;tag&quot;&gt;uav&lt;/a&gt; tag.&lt;/li&gt;&#xA;&lt;li&gt;Questions about autonomous &lt;a href=&quot;http://en.wikipedia.org/wiki/Unmanned_ground_vehicle&quot; rel=&quot;nofollow&quot;&gt;Unmanned ground vehicle&lt;/a&gt;s should use the &lt;a href=&quot;/questions/tagged/ugv&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'ugv'&quot; rel=&quot;tag&quot;&gt;ugv&lt;/a&gt; tag.&lt;/li&gt;&#xA;&lt;li&gt;The &lt;a href=&quot;/questions/tagged/drone&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'drone'&quot; rel=&quot;tag&quot;&gt;drone&lt;/a&gt; tag should only be used on questions about autonomous drones which don't fit into the &lt;a href=&quot;/questions/tagged/auv&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'auv'&quot; rel=&quot;tag&quot;&gt;auv&lt;/a&gt;, &lt;a href=&quot;/questions/tagged/uav&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'uav'&quot; rel=&quot;tag&quot;&gt;uav&lt;/a&gt; or &lt;a href=&quot;/questions/tagged/ugv&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'ugv'&quot; rel=&quot;tag&quot;&gt;ugv&lt;/a&gt; tags.&lt;/li&gt;&#xA;&lt;li&gt;Questions about &lt;a href=&quot;http://en.wikipedia.org/wiki/Remotely_operated_underwater_vehicle&quot; rel=&quot;nofollow&quot;&gt;Remotely operated underwater vehicle&lt;/a&gt;s are probably off topic on &lt;em&gt;Robotics&lt;/em&gt; and are more likely to be suitable over on &lt;a href=&quot;http://electronics.stackexchange.com/&quot;&gt;Electrical Engineering&lt;/a&gt; Stack Exchange.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;If the tags &lt;a href=&quot;/questions/tagged/uuv&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'uuv'&quot; rel=&quot;tag&quot;&gt;uuv&lt;/a&gt; &amp;amp; &lt;a href=&quot;/questions/tagged/rov&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'rov'&quot; rel=&quot;tag&quot;&gt;rov&lt;/a&gt; start to be used, then they should probably be considered synonyms of &lt;a href=&quot;/questions/tagged/auv&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'auv'&quot; rel=&quot;tag&quot;&gt;auv&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="37" LastEditorUserId="37" LastEditDate="2012-11-19T19:57:10.370" LastActivityDate="2012-11-19T19:57:10.370" />
  <row Id="450" PostTypeId="4" CreationDate="2012-11-18T00:55:48.197" Score="0" Body="Autonomous underwater vehicle. See also the tags [tag:ugv], [tag:uav] &amp; [tag:drone]." OwnerUserId="37" LastEditorUserId="37" LastEditDate="2012-11-19T19:57:16.750" LastActivityDate="2012-11-19T19:57:16.750" />
  <row Id="451" PostTypeId="5" CreationDate="2012-11-18T01:11:13.090" Score="0" ViewCount="8" Body="&lt;h1&gt;Unmanned ground vehicle.&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;From the &lt;a href=&quot;http://en.wikipedia.org/wiki/Unmanned_ground_vehicle&quot; rel=&quot;nofollow&quot;&gt;Wikipedia page&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;An &lt;strong&gt;unmanned ground vehicle (UGV)&lt;/strong&gt; is a vehicle that operates while in contact with the ground and without an onboard human presence. UGVs can be used for many applications where it may be inconvenient, dangerous, or impossible to have a human operator present. Generally, the vehicle will have a set of sensors to observe the environment, and will either autonomously make decisions about its behavior or pass the information to a human operator at a different location who will control the vehicle through teleoperation.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;The UGV is the land-based counterpart to unmanned aerial vehicles and remotely operated underwater vehicles. Unmanned robotics are being actively developed for both civilian and military use to perform a variety of dull, dirty, and dangerous activities.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;h3&gt;Note that:&lt;/h3&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Questions about autonomous &lt;a href=&quot;http://en.wikipedia.org/wiki/Unmanned_aerial_vehicle&quot; rel=&quot;nofollow&quot;&gt;Unmanned aerial vehicle&lt;/a&gt;s should use the &lt;a href=&quot;/questions/tagged/uav&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'uav'&quot; rel=&quot;tag&quot;&gt;uav&lt;/a&gt; tag.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Questions about &lt;a href=&quot;http://en.wikipedia.org/wiki/Autonomous_underwater_vehicle&quot; rel=&quot;nofollow&quot;&gt;Autonomous underwater vehicle&lt;/a&gt;s should use the &lt;a href=&quot;/questions/tagged/auv&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'auv'&quot; rel=&quot;tag&quot;&gt;auv&lt;/a&gt; tag.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;The &lt;a href=&quot;/questions/tagged/drone&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'drone'&quot; rel=&quot;tag&quot;&gt;drone&lt;/a&gt; tag should only be used on questions about autonomous drones which don't fit into the &lt;a href=&quot;/questions/tagged/auv&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'auv'&quot; rel=&quot;tag&quot;&gt;auv&lt;/a&gt;, &lt;a href=&quot;/questions/tagged/uav&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'uav'&quot; rel=&quot;tag&quot;&gt;uav&lt;/a&gt; or &lt;a href=&quot;/questions/tagged/ugv&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'ugv'&quot; rel=&quot;tag&quot;&gt;ugv&lt;/a&gt; tags.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Questions about &lt;a href=&quot;http://en.wikipedia.org/wiki/Unmanned_ground_vehicle#Remote-Operated&quot; rel=&quot;nofollow&quot;&gt;remotely operated ground vehicles&lt;/a&gt; are probably off topic on &lt;em&gt;Robotics&lt;/em&gt; and are more likely to be suitable over on &lt;a href=&quot;http://electronics.stackexchange.com/&quot;&gt;Electrical Engineering&lt;/a&gt; Stack Exchange.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="37" LastEditorUserId="37" LastEditDate="2012-11-19T19:57:19.150" LastActivityDate="2012-11-19T19:57:19.150" />
  <row Id="452" PostTypeId="4" CreationDate="2012-11-18T01:11:13.090" Score="0" Body="Unmanned ground vehicle. See also the tags [tag:auv], [tag:uav] &amp; [tag:drone]." OwnerUserId="37" LastEditorUserId="37" LastEditDate="2012-11-19T19:57:13.177" LastActivityDate="2012-11-19T19:57:13.177" />
  <row Id="453" PostTypeId="1" AcceptedAnswerId="458" CreationDate="2012-11-18T05:44:20.077" Score="5" ViewCount="1129" Body="&lt;p&gt;In our lab we use LiPo batteries to power our quadrotors. Lately we have been experiencing stability issues when using certain batteries. The batteries seem to charge and balance normally and our battery monitor indicates they are fine even when putting them under load. However when we attempt to fly the quadrotor with one of these batteries, manually or autonomously, it has a severe tendency to pitch and/or roll. My guess is that the battery is not supplying sufficient power to all the motors which brings me to my question. Is this behavior indicative of a LiPo going bad? If so what is the best way to test a battery to confirm my suspicions?&lt;/p&gt;&#xA;" OwnerUserId="177" LastEditorUserId="350" LastEditDate="2012-11-30T14:28:05.310" LastActivityDate="2013-01-25T16:47:11.043" Title="How can one determine whether a LiPo battery is going bad?" Tags="&lt;batteries&gt;&lt;troubleshooting&gt;" AnswerCount="3" CommentCount="2" />
  <row Id="454" PostTypeId="2" ParentId="445" CreationDate="2012-11-18T06:54:47.537" Score="1" Body="&lt;p&gt;When you say, &quot;over half the image does not have any proper depth information&quot;, which half ?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One issue we ran into is that if distance-to-object is of the same order of magnitude than your baseline (usually associated with very wide angle cameras), then the &quot;standard&quot; dense stereo algorithms don't work so well. We've been using the libelas library, and its developers told us that this is called &quot;large baseline stereo&quot; and is yet another problem.&lt;/p&gt;&#xA;" OwnerUserId="56" LastActivityDate="2012-11-18T06:54:47.537" CommentCount="2" />
  <row Id="455" PostTypeId="2" ParentId="453" CreationDate="2012-11-18T07:19:33.400" Score="2" Body="&lt;p&gt;There's a possibility that the battery is going bad under those conditions. Assuming you have some kind of &lt;a href=&quot;https://en.wikipedia.org/wiki/Supervisory_circuit&quot; rel=&quot;nofollow&quot;&gt;battery supervisor&lt;/a&gt;, just adding an interrupt indicating that the battery is below a certain level would be very informative. That way, if you have a freshly charged battery and the interrupt is triggered sooner than expected, then you know that the battery is going bad. That is, unless the problem is more obvious by observing swelling of the battery, in which case you should probably (and safely) dispose of it. You could also try the fresh battery with a comparable load to that expected while in flight (e.g. when all motors are on and all processors and sensors are running nominally).&lt;/p&gt;&#xA;" OwnerUserId="295" LastActivityDate="2012-11-18T07:19:33.400" />
  <row Id="456" PostTypeId="2" ParentId="382" CreationDate="2012-11-18T07:39:27.350" Score="4" Body="&lt;p&gt;You can greatly simplify the problem in most common cases:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A lot of &quot;commercial grade&quot; IMus (e.g. Xsens) have very noisy accelerometers. Don't even bother fusing them to get speed, the odometry is already order of magnitudes better. The only usable data the IMU is going to provide is the pitch and roll, and to some extent the heading (see next point)&lt;/li&gt;&#xA;&lt;li&gt;heading from IMUs is not that trustworthy. It uses magetometers, and will show huge drifts (up to 25 degrees over 2m in our case) near ferromagnetic masses, such as the one you can find in building walls. What we did to solve this is to use the IMU heading, but estimate a heading bias.&lt;/li&gt;&#xA;&lt;li&gt;If you are outdoors, don't forget that travelling 10m on a 10 degree incline does not lead to the same change in X and Y than travelling 10m on a flat terrain. This is usually accounted for by estimating Z, but I guess it can be estimated differently.&lt;/li&gt;&#xA;&lt;li&gt;GPS is also a lying bitch, typically in high-multipath environments. Plus low-grade (and even in some conditions high-grade) GPSes have a tendency to report very wrong standard deviations. We used some simple chi-square tests to check whether a particular GPS measurement should be integrated (i.e. checking that it matches the current filter estimate up to a certain point), which gave us decent results.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The &quot;typical&quot; solution for us is to use odometry + IMU to get an ego-motion estimate and then use GPS to correct X,Y,Z and heading bias.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.rock-robotics.org/stable/pkg/slam/pose_ekf/index.html&quot; rel=&quot;nofollow&quot;&gt;Here is an EKF implementation that we extensively used.&lt;/a&gt; If you need to estimate the IMU's orientation (i.e. if it does not already have a built-in filter), you can also use on of these two filter: &lt;a href=&quot;http://www.rock-robotics.org/master/pkg/slam/quater_ukf/index.html&quot; rel=&quot;nofollow&quot;&gt;UKF&lt;/a&gt; and &lt;a href=&quot;http://www.rock-robotics.org/master/pkg/slam/quater_ekf/index.html&quot; rel=&quot;nofollow&quot;&gt;EKF&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="56" LastActivityDate="2012-11-18T07:39:27.350" />
  <row Id="457" PostTypeId="2" ParentId="453" CreationDate="2012-11-18T08:57:44.260" Score="2" Body="&lt;p&gt;&quot;behavior indicative of a LiPo going bad&quot; - in my experience this is usually a puffy battery, or a fire. My understanding of it is when a LiPo goes bad, the individual cells within it are not charging and/or discharging evenly, and that indirectly leads to the previously mentioned symptoms. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can you check the voltage balance after a bad flight? Are they more than a 1/10  volt different?  Can you verify other exact same batteries are performing adequately, and thus your C rating (burst amperage) is appropriate?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I suppose it is possible to exhibit the behavior you describe, but that would mean the specifications were very close to begin with, you should try allow a little more room (ie a higher C rating, at a higher cost $$ of course).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is pretty much the same thing movrev said in his answer - so mark it instead of this one.&lt;/p&gt;&#xA;" OwnerUserId="274" LastActivityDate="2012-11-18T08:57:44.260" />
  <row Id="458" PostTypeId="2" ParentId="453" CreationDate="2012-11-18T14:15:19.493" Score="5" Body="&lt;p&gt;It sounds like you're asking 2 questions:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Is an imbalance in motor performance indicative of a failing battery?&lt;/li&gt;&#xA;&lt;li&gt;How would you test for a failing battery?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;The answer to the first question is &quot;maybe&quot;.  We had an issue on one of the AUVs I used to work on, where sometimes at the end of the day it would lose all heading control.  By chance, we discovered that one of the motor controllers (used for differential drive) stopped working when it dipped below a certain voltage, where the other one was unaffected.  So in that sense, the imbalance in motor performance was related to the battery but not necessarily a battery failure.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The best way to rule out the battery would be to tie your quadrotor (with only a few inches of freedom) to a table, and measure the battery voltage while you manually control it.  Does it drop below what you're expecting, indicating an inability to supply enough current?  Another way to do it would be to replace the battery with a simulated battery (variable voltage source + variable resistor) and test whether dips in the output voltage or increased internal resistance are to blame.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The answer to the second question is more complicated, but a decent resource for it is here:&#xA;&lt;a href=&quot;http://batteryuniversity.com/learn/article/testing_lithium_based_batteries&quot; rel=&quot;nofollow&quot;&gt;http://batteryuniversity.com/learn/article/testing_lithium_based_batteries&lt;/a&gt;&#xA;&lt;img src=&quot;http://i.stack.imgur.com/V3Fv5.jpg&quot; alt=&quot;Failure &quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Essentially, you must measure the response times of the battery to changes in load.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-01-25T16:47:11.043" LastActivityDate="2013-01-25T16:47:11.043" />
  <row Id="459" PostTypeId="2" ParentId="215" CreationDate="2012-11-19T10:45:59.123" Score="4" Body="&lt;p&gt;If you have no idea what to do with your microcontroller, I would start slower. I wouldn't say using a Kinect is that great an idea right now.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some of the other answers mentioned using development kits and boards to avoid soldering, which I think is a great way to get started with embedded programming without having to worry about soldering practically anything.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My tip is to look into a great website I found when I knew nothing about robots: &lt;a href=&quot;http://www.societyofrobots.com/&quot; rel=&quot;nofollow&quot;&gt;Society of Robots&lt;/a&gt; and their great &lt;a href=&quot;http://www.societyofrobots.com/step_by_step_robot.shtml&quot; rel=&quot;nofollow&quot;&gt;$50 Robot Tutorial&lt;/a&gt;! There you will find a lot of basic information for people who want to build their own robots.&lt;/p&gt;&#xA;" OwnerUserId="95" LastActivityDate="2012-11-19T10:45:59.123" />
  <row Id="460" PostTypeId="2" ParentId="94" CreationDate="2012-11-19T11:22:09.613" Score="2" Body="&lt;p&gt;I can say from my own experience three libraries are awesome to use with 8-bit AVR microcontrollers:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://www.nongnu.org/avr-libc/&quot; rel=&quot;nofollow&quot;&gt;AVR Libc&lt;/a&gt; is the standard C library for AVR programming. It is very low-level in the sense that you really need to know your hardware down to the register level, but it gives you great freedom to do &lt;strong&gt;exactly&lt;/strong&gt; what you want. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Even if you don't want to dive so deep, you should become somewhat familiar with it since every now and then Arduino users end up using bits of it to surpass the capabilities of the standard Arduino API. An interesting fact is that you can use AVR Libc snippets within your Arduino code since the Arduino API is based on the AVR GNU Toolchain.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/dreamiurg/avr-liberty&quot; rel=&quot;nofollow&quot;&gt;AVR Liberty&lt;/a&gt; is currently my favorite library to develop with. It is both very straightforward and very powerful, so I feel I get the best of both worlds: I don't have to reinvent the wheel as with AVR Libc, but I also don't have to be agnostic of everything that goes on with the hardware as with the Arduino API. I &lt;strong&gt;strongly&lt;/strong&gt; recommend it.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;The &lt;a href=&quot;http://www.arduino.cc&quot; rel=&quot;nofollow&quot;&gt;Arduino API&lt;/a&gt; can be used in the Arduino boards, in breadboard versions&lt;a href=&quot;http://arduino.cc/en/Main/Standalone&quot; rel=&quot;nofollow&quot;&gt;[1]&lt;/a&gt;&lt;a href=&quot;http://arduino.cc/en/Tutorial/ArduinoToBreadboard&quot; rel=&quot;nofollow&quot;&gt;[2]&lt;/a&gt; of the Arduino board, or even in standalone microcontrollers using a programmer such as the &lt;a href=&quot;http://www.fischl.de/usbasp/&quot; rel=&quot;nofollow&quot;&gt;USBasp&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I like to use Arduino boards for quick prototyping, but I find its API to be somewhat limiting at times. However, they have &lt;a href=&quot;http://arduino.cc/en/Reference/Libraries&quot; rel=&quot;nofollow&quot;&gt;many specific libraries&lt;/a&gt; that extend the standard API's functionality. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;The Arduino board can also be used with any other AVR library&lt;/strong&gt; as long as you understand how to upload your code (either through the bootloader or a programmer), so it is definitely a dev board worth buying to get started.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="95" LastActivityDate="2012-11-19T11:22:09.613" />
  <row Id="461" PostTypeId="1" CreationDate="2012-11-19T14:04:21.143" Score="7" ViewCount="638" Body="&lt;p&gt;Whenever I read a text about control (e.g. PID control) it often mentions 'poles' and 'zeros'. What do they mean by that?  What physical state does a pole or a zero describe?&lt;/p&gt;&#xA;" OwnerUserId="40" LastEditorUserId="350" LastEditDate="2012-11-20T15:43:16.130" LastActivityDate="2012-11-20T15:43:16.130" Title="In PID control, what do the poles and zeros represent?" Tags="&lt;control&gt;&lt;pid&gt;" AnswerCount="2" CommentCount="1" FavoriteCount="3" />
  <row Id="462" PostTypeId="2" ParentId="461" CreationDate="2012-11-19T16:07:04.057" Score="7" Body="&lt;p&gt;The function $T(\mathbf{x})$ that describes how ones input to a system maps to the output of the system is referred to as a transfer function.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For linear systems the transfer function can be written as $N(\mathbf{x})/D(\mathbf{x})$ where $N$ and $D$ are polynomials, i.e. $$T(\mathbf{x}) = {N(\mathbf{x})\over D(\mathbf{x})}$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The zeros of the system are the values of $x$ that satisfy the statement $N(\mathbf{x}) = 0$. In other words they are the roots of the polynomial $N(\mathbf{x})$. As $N(\mathbf{x})$. approaches a zero, the numerator of the transfer function (and therefore the transfer function itself) approaches the value 0.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Similarly the poles of the system are the values of $x$ that satisfy the statement $D(\mathbf{x}) = 0$. In other words they are the roots of the polynomial $D(\mathbf{x})$. When $D(\mathbf{x})$ approaches a pole, the denominator of the transfer function approaches zero, and the value of the transfer function approaches infinity.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The poles and zeros allow us to understand how a system will react to various inputs. The zeros are interesting for their ability to block frequencies while the poles provide us information about the stability of the system. Generally we plot the poles and zeros in the &lt;a href=&quot;http://en.wikipedia.org/wiki/Complex_plane&quot; rel=&quot;nofollow&quot;&gt;complex plane&lt;/a&gt; and we say a system is &lt;a href=&quot;http://en.wikipedia.org/wiki/BIBO_stability&quot; rel=&quot;nofollow&quot;&gt;bounded-input bounded-output&lt;/a&gt; (BIBO) stable if the poles are located in the left half of the complex plane (LHP - Left Half Plane). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Finally, when we design a controller we are in effect manipulating it's poles and zeros so as to achieve specific design parameters.&lt;/p&gt;&#xA;" OwnerUserId="177" LastEditorUserId="177" LastEditDate="2012-11-19T19:44:50.687" LastActivityDate="2012-11-19T19:44:50.687" CommentCount="3" />
  <row Id="463" PostTypeId="1" CreationDate="2012-11-19T18:02:23.310" Score="3" ViewCount="220" Body="&lt;p&gt;We are trying to power &lt;a href=&quot;http://www.e-fliterc.com/Products/Default.aspx?ProdID=EFLM3032DFA&quot; rel=&quot;nofollow&quot;&gt;this motor&lt;/a&gt; with &lt;a href=&quot;http://www.coolcomponents.co.uk/catalog/vnh2sp30-motor-driver-carrier-md01b-p-228.html&quot; rel=&quot;nofollow&quot;&gt;this motor driver&lt;/a&gt; , using a 11.1V 2.2Ah lithium-ion polymer battery.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(We're in over our heads with this and really need the help) &lt;/p&gt;&#xA;&#xA;&lt;p&gt;We checked with the company (E-flite) and the motor is definitely DC -- we're a bit confused as to the purpose of three wires, and how we should connect them to the motor. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any help would be appreciated.&lt;/p&gt;&#xA;" OwnerUserId="459" LastEditorUserId="126" LastEditDate="2012-11-19T19:57:07.187" LastActivityDate="2012-11-19T19:57:07.187" Title="Connecting a 6 pole motor to a motor driver?" Tags="&lt;brushless-motor&gt;&lt;driver&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="464" PostTypeId="2" ParentId="463" CreationDate="2012-11-19T18:28:06.333" Score="2" Body="&lt;p&gt;The motor you have there is a Brushless DC motor. It's still technically a DC motor, but you won't be able to drive it by plugging it into a battery, or even into the driver you linked to. You need a driver specifically for brushless motors that can drive all three wires correctly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/Npsce.gif&quot; alt=&quot;Brushless motor driver]&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Something like this &lt;a href=&quot;http://www.coolcomponents.co.uk/catalog/electronic-speed-controller-p-716.html&quot; rel=&quot;nofollow&quot;&gt;Electronic Speed Controller&lt;/a&gt; will drive it pretty well:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/LH5yo.jpg&quot; alt=&quot;Electronic speed controller&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You connect the motor to the 3 wires, and the power to the two wires. The little 3-wire connector normally goes to a Radio Control (RC) receiver, plugging into the servo socket. It accepts a PWM signal just like a normal servo.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-11-19T18:28:06.333" CommentCount="4" />
  <row Id="465" PostTypeId="2" ParentId="416" CreationDate="2012-11-19T18:44:02.960" Score="5" Body="&lt;p&gt;As Rocketmagnet mentioned, just because a motor is rated at 2.5 W doesn't mean it will be pulling 2.5 W &lt;em&gt;all the time&lt;/em&gt;. Most robots have at most 1 or 2 servos that are running at full power at any one time; the rest have very low mechanical loads (and therefore pull much less electrical power) or are &quot;off&quot; and therefore pull practically zero electrical power.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This leads to 2 very different approaches to power supplies:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Tethered robots and desktop computers use a power supply and heat-sinks that can handle the maximum possible worst-case power draw --&#xA;when everything pulls the maximum power at the same time.&#xA;27 servos * 2.5 W @ 5V requires a 5 VDC and at least 14 A power supply&#xA;(or perhaps several 5 VDC supplies that add up to at least 14 A).&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Autonomous robots and modern laptops use a power supply and heat-sinks that can handle some &lt;a href=&quot;http://en.wikipedia.org/wiki/thermal_design_power&quot; rel=&quot;nofollow&quot;&gt;thermal design power&lt;/a&gt;.&#xA;Some human arbitrarily picks some the TDP, which is much smaller than the worst-case power, but somewhat above the power required in &quot;typical situations&quot;.&#xA;Then the power supply is designed so it can handle any load from 0 to &lt;em&gt;slightly above&lt;/em&gt; the TDP.&#xA;And the rest of the system is designed so it &lt;em&gt;never exceeds&lt;/em&gt; the TDP --&#xA;except perhaps for a few milliseconds.&#xA;The simplest approach is to have something that measures the total current draw --&#xA;then when the current exceeds the TDP, assume that things have already gone horribly wrong, and shut everything down for a few seconds.&#xA;More sophisticated approaches measure the current of each motor individually:&#xA;When some motor stalls, &quot;limp mode&quot; kills the power to that one motor,&#xA;so the robot continues to use the other motors at full power.&#xA;When lots of motors pull a total current that is too high,&#xA;&quot;tired mode&quot; reduces the power to all the motors&#xA;so the robot continues to use all the motors at a slower speed.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;5 V fuses?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;You could install one big 14 A fuse. Or you could install 27 individual 0.5 A fuses, one in the +5V power line of each motor. Or both. You'll probably find it easier to find &quot;12 V&quot; or &quot;250 V&quot; fuses, which will work just fine in your application.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are many cheap polyfuses available (designed to protect 5V USB ports from excessive current). Alas, polyfuses take several seconds to &quot;blow&quot; -- too late to protect stuff from permanent damage, but quick enough to keep stuff from heating up, catching on fire, and burning down your house.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;possibly related:&#xA;&lt;a href=&quot;http://electronics.stackexchange.com/questions/44845/how-to-do-a-simple-overcurrent-protection-circuit-breaker-circuit-for-12v-1-2a&quot;&gt;How to do a simple overcurrent protection/circuit breaker circuit for 12V 1-2A?&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;convert 12 V to 5 V&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Most people using servo motors use an off-the-shelf DC-DC converter to convert whatever voltage the batteries supply to the 5V required by the servos.&lt;a href=&quot;http://www.societyofrobots.com/schematics_powerregulation.shtml&quot; rel=&quot;nofollow&quot;&gt;(c)&lt;/a&gt;&#xA;I see that &lt;em&gt;some&lt;/em&gt; 18650 battery box (&lt;a href=&quot;http://www.aliexpress.com/item/Free-Shipping-DIY-2A-5V-Mobile-Power-Supply-USB-Battery-Charger-18650-Box-with-voltage-meter/654255654.html&quot; rel=&quot;nofollow&quot;&gt;a&lt;/a&gt;) include a little DC-DC converter to convert the battery power to 5 VDC &quot;USB battery charger&quot;.&#xA;(A few people use servomotors designed to be connected directly to 12 VDC. &lt;a href=&quot;http://www.pololu.com/catalog/product/1390/specs&quot; rel=&quot;nofollow&quot;&gt;a&lt;/a&gt;)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Many DC-DC converters are set up so that they never pull more than some maximum current from the battery -- when the motor connected to their output stalls, the converter switches to a &quot;constant-current&quot; mode at some lower output voltage, pulling &lt;em&gt;less&lt;/em&gt; power from the batteries.&#xA;If you put such a DC-DC converter on each servo, it automatically goes into and comes out of &quot;limp mode&quot; appropriately.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;batteries&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;&quot;Selecting the proper battery for your robot&quot; &lt;a href=&quot;http://letsmakerobots.com/node/28427&quot; rel=&quot;nofollow&quot;&gt;(a)&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&quot;Robot batteries&quot; &lt;a href=&quot;http://www.backyardrobots.com/parts/parts.shtml&quot; rel=&quot;nofollow&quot;&gt;(b)&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&quot;Batteries I use in my Robotics&quot; &lt;a href=&quot;http://robosapienv2-4mem8.page.tl/Batteries.htm&quot; rel=&quot;nofollow&quot;&gt;(c)&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;etc.&#xA;&lt;a href=&quot;http://www.societyofrobots.com/batteries.shtml&quot; rel=&quot;nofollow&quot;&gt;a&lt;/a&gt;&#xA;&lt;a href=&quot;http://www.robotmarketplace.com/products/battery_build_main.html&quot; rel=&quot;nofollow&quot;&gt;b&lt;/a&gt;&#xA;&lt;a href=&quot;http://www.protechrobotics.com/products.php?cat=39&quot; rel=&quot;nofollow&quot;&gt;c&lt;/a&gt;&#xA;&lt;a href=&quot;http://www.terrorhurtz.com/a123/&quot; rel=&quot;nofollow&quot;&gt;d&lt;/a&gt;&#xA;&lt;a href=&quot;http://www.seattlerobotics.org/encoder/200210/lithiumion.htm&quot; rel=&quot;nofollow&quot;&gt;e&lt;/a&gt;&#xA;&lt;a href=&quot;http://www.batteryspace.com/robotbatteries.aspx&quot; rel=&quot;nofollow&quot;&gt;f&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="187" LastEditorUserId="187" LastEditDate="2012-11-20T15:45:35.247" LastActivityDate="2012-11-20T15:45:35.247" />
  <row Id="466" PostTypeId="2" ParentId="128" CreationDate="2012-11-19T22:52:43.610" Score="0" Body="&lt;p&gt;Yes, assuming the hardware resources can meet the timing requirements (enough processing power, low enough latency), when the scheduler can not sequence processes and threads appropriately, then one uses a real-time scheduler, usually attached to a kernel specifically optimized for the challenges of this. Hardware drivers can also be optimized for real-time conditions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Yes, if ones software cannot be guaranteed to do it's job in the required time constraints, then one uses real-time approaches.&lt;/p&gt;&#xA;" OwnerUserId="184" LastActivityDate="2012-11-19T22:52:43.610" />
  <row Id="467" PostTypeId="2" ParentId="331" CreationDate="2012-11-20T00:59:16.667" Score="3" Body="&lt;p&gt;I found out the problem was with the serial communication card..I connected the robot through the direct PC com port 2. It was working fine&lt;/p&gt;&#xA;" OwnerUserId="377" LastActivityDate="2012-11-20T00:59:16.667" CommentCount="2" />
  <row Id="468" PostTypeId="2" ParentId="277" CreationDate="2012-11-20T04:40:49.590" Score="5" Body="&lt;p&gt;You could use particle filters as well. For the basic intro to Particle Filters, you could have a look at Professor Thrun's videos in Programming a Robotic Car.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.youtube.com/watch?v=H0G1yslM5rc&quot; rel=&quot;nofollow&quot;&gt;http://www.youtube.com/watch?v=H0G1yslM5rc&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.youtube.com/watch?v=QgOUu2sUDzg&quot; rel=&quot;nofollow&quot;&gt;http://www.youtube.com/watch?v=QgOUu2sUDzg&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Particle filters are more robust and have a far lesser probability of the loop closure error, which commonly occurs while implementing an EKF.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The videos describe the functioning of a particle filter.&lt;/p&gt;&#xA;" OwnerUserId="333" LastEditorUserId="333" LastEditDate="2012-11-20T10:17:06.440" LastActivityDate="2012-11-20T10:17:06.440" CommentCount="2" />
  <row Id="469" PostTypeId="1" AcceptedAnswerId="490" CreationDate="2012-11-20T04:54:02.230" Score="5" ViewCount="136" Body="&lt;p&gt;I would like to have a better understanding of work in the field of &quot;Navigation Among Movable Obstacles&quot;. I started off with &lt;a href=&quot;http://www.ri.cmu.edu/pub_files/pub4/stilman_michael_2007_1/stilman_michael_2007_1.pdf&quot; rel=&quot;nofollow&quot;&gt;Michael Stilman's thesis under James Kuffner&lt;/a&gt;, but that has not yet sated my appetite.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am currently trying to simulate a scenario where debris (Tables and Table parts) from a disaster scenario block pathways. The debris forms part of a movable obstacle. The robot which will be used is a bipedal humanoid.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The thesis describes an approach to define the search space of possible actions leading from the start point to the goal. However, it assumes a mobile robot which works via gliding. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I think the state space definitions would change for a bi-pedal robot. Why is why I wonder what other work is being done in this field. Perhaps the work of other research groups could give me clues as to how to design and perhaps reduce the search space for a bipedal humanoid robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;An implementation of Navigation among Movable Obstacles would also aid me in understanding how to reduce the search space of possible actions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So does anyone know of a working implementation of Navigation among movable obstacles? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any supporting information about other professors or research groups working on similar problems would also be very useful.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I hope this edit is sufficient for the problem description.&lt;/p&gt;&#xA;" OwnerUserId="333" LastEditorUserId="131" LastEditDate="2012-11-21T17:20:54.703" LastActivityDate="2012-11-23T21:06:12.147" Title="Is there a working implementation of &quot;Navigation Among Movable Obstacles&quot; for a bi-pedal robot?" Tags="&lt;navigation&gt;" AnswerCount="1" CommentCount="10" FavoriteCount="1" />
  <row Id="471" PostTypeId="2" ParentId="461" CreationDate="2012-11-20T10:43:11.440" Score="3" Body="&lt;p&gt;These polynomial transfer functions occur, when you perform a &lt;em&gt;Laplace transform&lt;/em&gt; on some linear differential equation which either actually describes your robot or is the result of &lt;em&gt;linearizing&lt;/em&gt; the robot's dynamics at some desired state. Think of it like a &quot;Taylor expansion&quot; around that state. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The Laplace transform is the generalization of the Fourier transform to functions which are not periodic. In electrical engineering, the Laplace transform is interpreted as the representation of the system in the &lt;em&gt;frequency domain&lt;/em&gt;, i.e. it describes, how the system transmits any frequencies from the input signal. Zeros then describe frequencies that don't get transmitted. And as already mentioned by DaemonMaker, poles are important when considering the system's stability: The transfer function of the system goes to infinity near the poles. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What they mean in a control context:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Poles&lt;/strong&gt;: They tell you, if a system (that can also be a new system, in which you have inserted a feedback loop with a control law) is stable or not. Usually you want a system to be stable. So, you want all the poles of the system to be in the left half plane (i.e. the real parts of the poles must be smaller than zero). The poles are the &lt;em&gt;eigenvalues of your system matrix&lt;/em&gt;. How far they are on the left half-plane tells you how fast the system converges to it's resting state. The further they are away from the imaginary axis, the faster the system converges.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Zeros&lt;/strong&gt;: They can be convenient if you have a pole on the right half plane or still on the left half plane, but too close to the imaginary axis: By clever modification of your system, you can shift the zeros &lt;em&gt;onto your unwanted poles to annihilate them&lt;/em&gt;. &lt;/p&gt;&#xA;" OwnerUserId="422" LastActivityDate="2012-11-20T10:43:11.440" CommentCount="2" />
  <row Id="472" PostTypeId="1" CreationDate="2012-11-20T12:01:19.523" Score="-4" ViewCount="115" Body="&lt;p&gt;I want to learn robotics and build my first robot. I am looking for a well supported kit that is simple enough and can walk me through, the initial stages of my intellectual pursuit in Robotics. I want to be able to do the basic things first and build a solid foundation in robotics. And then I want to be able to use the solid foundation, to gain confidence in my ability to build new and interesting robotic contraptions. In other words, I want to be able to follow the rules off the game to gain a solid foundation and then once I'm comfortable with what I know, I want to break free of the rules and start making my own robots. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would like help with 2 things,&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;I would like to begin my robotics learning with a good kit that can walk me through my initial stages. I expect that this initial stage might take quite a while. So, any recommendations for how I can start and/or what kit I can buy, to get my feet wet, would be helpful.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;I would like suggestions for &quot;other&quot; actions I can take, that will set me on a path to gain confidence in my knowledge of robotics.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;A little bit about myself. I have a BS and MS in IT. So I am not new to programming. I like to code in golang and haskell. I do not know if it is possible, but it would be awesome if I can write the software aspect of all my robotic projects in haskell.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks&lt;/p&gt;&#xA;" OwnerUserId="466" LastActivityDate="2012-11-20T12:34:21.650" Title="Humble beginnings" Tags="&lt;kit&gt;" AnswerCount="1" CommentCount="4" FavoriteCount="1" ClosedDate="2012-12-05T21:14:40.790" />
  <row Id="473" PostTypeId="2" ParentId="472" CreationDate="2012-11-20T12:34:21.650" Score="1" Body="&lt;p&gt;I got drawn into Robotics by a Lego Mindstorms lab course at our university, in which the participants were divided into 2 teams whose robots had to compete against each other in some predefined task. That was shortly before the NXT were introduced. In my experience, a Lego Mindstorms kit is a good way for &quot;software people&quot; to get into Robotics because it doesn't overwhelm you with electronics and manufacturing-related questions when you just want to build e.g. a line follower robot. The NXT kits can also be flased with many different kinds of custom firmware that is available on the Interent. There is also a LabVIEW interface, if i recall correctly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another good starting point may be Arduino boards or anything from this company:&#xA;&lt;a href=&quot;http://www.vexrobotics.com/&quot; rel=&quot;nofollow&quot;&gt;http://www.vexrobotics.com/&lt;/a&gt;&#xA;I used them to order some parts i needed for a mechatronics class project. A Parrot AR drone may also be interesting. Or look for game engines or simulators if you want to stay away from hardware at first.&lt;/p&gt;&#xA;" OwnerUserId="422" LastActivityDate="2012-11-20T12:34:21.650" />
  <row Id="474" PostTypeId="1" AcceptedAnswerId="476" CreationDate="2012-11-20T15:46:48.243" Score="11" ViewCount="257" Body="&lt;p&gt;RS232 is not popular as it used to be and is mainly replaced by USB [&lt;a href=&quot;http://en.wikipedia.org/wiki/RS-232#Role_in_modern_personal_computers&quot;&gt;wikipedia&lt;/a&gt;]. Problems such as mentioned in &lt;a href=&quot;http://robotics.stackexchange.com/q/331/158&quot;&gt;this question&lt;/a&gt; doesn't help its reputation either.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In a new system design therefore, one could think of using USB instead of Serial Port for communication. However, it still seems like RS232 is the serial communication protocol/port of choice.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Why is that? I understand changing old machinery that work with RS232 is costly, but what prevents &lt;em&gt;new&lt;/em&gt; system designers from using USB instead of RS232?&lt;/p&gt;&#xA;" OwnerUserId="158" LastActivityDate="2013-01-13T22:17:02.603" Title="USB instead of RS232" Tags="&lt;rs232&gt;&lt;usb&gt;" AnswerCount="4" />
  <row Id="475" PostTypeId="2" ParentId="474" CreationDate="2012-11-20T17:15:20.320" Score="7" Body="&lt;p&gt;Simplicity, i guess. A USB implementation (chips and driver software) is usually more complex than good ol' RS232, which can even be found in many 8-bit microcontrollers. While USB has many protocol mechanisms and is designed to deal with many participants over a bus, a RS232 connection doesn't have any of that. Instead, it's the &quot;rawest&quot; form possible of sending bytes over a wire.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Although Arduino and increasing spread of USB-to-serial adapters show promise that USB will eventually become as dominant as RS232 used to be.&lt;/p&gt;&#xA;" OwnerUserId="422" LastActivityDate="2012-11-20T17:15:20.320" />
  <row Id="476" PostTypeId="2" ParentId="474" CreationDate="2012-11-20T17:22:01.290" Score="12" Body="&lt;p&gt;At least in the microcontroller level:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;Serial ports (usually TTL or LVTTL) are still the most common way to communicate, since most simple microcontrollers don't have a USB controller. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;For instance: most 8-bit AVR or PIC microcontrollers don't have USB, a few 32-bit ARM microcontrollers do, but they all usually have serial ports.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Conversion from TTL/LVTTL serial communication to RS-232 requires a &quot;simple&quot; logic level conversion, which can be done with very cheap ICs (MAX232/MAX3232)&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Conversion from TTL/LVTTL serial communication to USB when your microcontroller does not have a USB controller usually requires using a slightly more expensive IC (FTDI) which does not have any through-hole packaging options, only surface mount.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;There are a few details relative to the protocol one has to pay attention to when using USB devices in general, such as the current level it may request from the USB host. With serial ports, you only have to worry about 3 to 5 fixed parameters that have to be consistent in your system (baudrate, # of stop bits, parity, etc).&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="95" LastEditorUserId="95" LastEditDate="2012-11-22T15:31:14.560" LastActivityDate="2012-11-22T15:31:14.560" />
  <row Id="477" PostTypeId="2" ParentId="474" CreationDate="2012-11-21T10:40:21.363" Score="5" Body="&lt;p&gt;I think the biggest reason that RS232 has stayed around is the simplicity in implementing common use-cases in embedded hardware - like sending a sequence ASCII bytes between two devices for control. The use-cases for sending information at the much higher speeds available with USB are not worth the trade-off in complexity caused by implementing &lt;a href=&quot;http://en.wikipedia.org/wiki/Universal_Serial_Bus#Signaling&quot;&gt;the USB protocol's signalling&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As the requirements for higher speeds appear, I wouldn't be surprised if &lt;a href=&quot;http://en.wikipedia.org/wiki/RS-485&quot;&gt;RS-485&lt;/a&gt; became more common with it's very simple physical interface and high (up to 10Mb/s) data rates.&lt;/p&gt;&#xA;" OwnerUserId="435" LastActivityDate="2012-11-21T10:40:21.363" />
  <row Id="478" PostTypeId="1" AcceptedAnswerId="670" CreationDate="2012-11-21T10:59:55.920" Score="6" ViewCount="177" Body="&lt;p&gt;As an industrial roboticist I spent most of my time working with robots and machines which used brushless DC motors or linear motors, so I have lots of experience tuning PID parameters for those motors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now I'm moving to doing hobby robotics using stepper motors (I'm building my first &lt;a href=&quot;http://tvrrug.org.uk/&quot;&gt;RepRap&lt;/a&gt;), I wonder what I need to do differently. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Obviously without encoder feedback I need to be much more conservative in requests to the motor, making sure that I always keep within the envelope of what is possible, but how do I find out whether my tuning is optimal, sub optimal or (worst case) marginally unstable?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Obviously for a given load (in my case the extruder head) I need to generate step pulse trains which cause a demanded acceleration and speed that the motor can cope with, without missing steps.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My first thought is to do some test sequences, for instance:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Home motor precisely on it's home sensor.&lt;/li&gt;&#xA;&lt;li&gt;Move $C$ steps away from home slowly.&lt;/li&gt;&#xA;&lt;li&gt;Move $M$ steps away from home with a conservative move profile.&lt;/li&gt;&#xA;&lt;li&gt;Move $N$ steps with the test acceleration/speed profile.&lt;/li&gt;&#xA;&lt;li&gt;Move $N$ steps back to the start of the test move with a conservative move profile.&lt;/li&gt;&#xA;&lt;li&gt;Move $M$ steps back to home with a conservative move profile.&lt;/li&gt;&#xA;&lt;li&gt;Move $C$ steps back to the home sensor slowly, verifying that the sensor is triggered at the correct position.&lt;/li&gt;&#xA;&lt;li&gt;Repeat for a variety of $N$, $M$, acceleration/speed &amp;amp; load profiles.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;This should reliably detect missed steps in the test profile move, but it does seem like an awfully large space to test through however, so I wonder what techniques have been developed to optimise stepper motor control parameters.&lt;/p&gt;&#xA;" OwnerUserId="37" LastActivityDate="2012-12-13T00:00:38.803" Title="How can I optimise control parameters for a stepper motor?" Tags="&lt;control&gt;&lt;stepper-motor&gt;&lt;tuning&gt;" AnswerCount="1" CommentCount="2" FavoriteCount="1" />
  <row Id="479" PostTypeId="1" AcceptedAnswerId="481" CreationDate="2012-11-21T15:36:22.960" Score="10" ViewCount="837" Body="&lt;p&gt;I understand the basic principle of a particle filter and tried to implement one. However, I got hung up on the resampling part. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Theoretically speaking, it is quite simple: From the old (and weighted) set of particles, draw a new set of particles with replacement. While doing so, favor those particles that have high weights. Particles with high weights get drawn more often and particles with low weights less often. Perhaps only once or not at all. After resampling, all weights get assigned the same weight.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My first idea on how to implement this was essentially this:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Normalize the weights&lt;/li&gt;&#xA;&lt;li&gt;Multiply each weight by the total number of particles&lt;/li&gt;&#xA;&lt;li&gt;Round those scaled weights to the nearest integer (e.g. with &lt;code&gt;int()&lt;/code&gt; in Python)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Now I should know how often to draw each particle, &lt;em&gt;but&lt;/em&gt; due to the roundoff errors, I end up having &lt;em&gt;less particles&lt;/em&gt; than before the resampling step. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The Question: How do I &quot;fill up&quot; the missing particles in order to get to the same number of particles as before the resampling step? Or, in case I am completely off track here, how do I resample correctly?&lt;/p&gt;&#xA;" OwnerUserId="422" LastEditorUserId="127" LastEditDate="2012-11-22T10:54:06.150" LastActivityDate="2012-11-26T16:12:03.137" Title="Particle filters: How to do resampling?" Tags="&lt;localization&gt;&lt;particle-filter&gt;" AnswerCount="3" FavoriteCount="5" />
  <row Id="480" PostTypeId="2" ParentId="479" CreationDate="2012-11-21T17:29:56.173" Score="4" Body="&lt;p&gt;For an example of python code that properly implements resampling, you might find this github project to be useful:&#xA;&lt;a href=&quot;https://github.com/mjl/particle_filter_demo&quot; rel=&quot;nofollow&quot;&gt;https://github.com/mjl/particle_filter_demo&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Plus, it comes with its own visual representation of the resampling process, that should help you debug your own implementation.&#xA;&lt;img src=&quot;http://i.stack.imgur.com/YylQT.gif&quot; alt=&quot;Particle filter operation&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In this visualization, the green turtle shows the actual position, the large grey dot shows the estimated position and turns green when it converges.  The weight goes from likely (red) to unlikely (blue).&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2012-11-26T16:12:03.137" LastActivityDate="2012-11-26T16:12:03.137" CommentCount="3" />
  <row Id="481" PostTypeId="2" ParentId="479" CreationDate="2012-11-21T17:30:15.313" Score="5" Body="&lt;p&gt;The issue you're running into is often referred to as sample impoverishment. We can see why your approach suffers from it with a fairly simple example. Let's say you have 3 particles and their normalized weights are 0.1, 0.1, 0.8. Then multiplying by each weight by the 3 yields 0.3, 0.3, and 2.4. Then rounding yields 0, 0, 2. This means you would not pick the first two particles and the last one would be picked twice. Now you are down to two particles. I suspect this is what you have been seeing when you say &quot;due to the roundoff errors, I end up having less particles.&quot;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;An alternative selection method would be as follows.&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Normalize weights.&lt;/li&gt;&#xA;&lt;li&gt;Calculate an array of the cumulative sum of the weights.&lt;/li&gt;&#xA;&lt;li&gt;Randomly generate a number &amp;amp; determine which range in that cumulative weight array to which the number belongs.&lt;/li&gt;&#xA;&lt;li&gt;The index of that range would correspond to the particle that should be created.&lt;/li&gt;&#xA;&lt;li&gt;Repeat until you have the desired number of samples.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;So, using the example above we would start with the normalized weights. We would then calculate the array [0.1, 0.2, 1]. From there we calculate 3 random numbers say 0.15, 0.38, and 0.54. This would have us pick the second particle once and the third particle twice. The point is that it gives the smaller particles a chance to propagate.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One thing to note is that while this method will deal with impoverishment it can lead to a suboptimal solutions. For instance, it may be that none of the particles really match your given location well (assuming you're using this for localization). The weights only tell you which particles match best, not the quality of the match. As such when you take additional readings and repeat the process you may find that all your particles group at a single location that is not the correct location. This is usually because there were no good particles to start. &lt;/p&gt;&#xA;" OwnerUserId="177" LastEditorUserId="350" LastEditDate="2012-11-25T21:19:02.897" LastActivityDate="2012-11-25T21:19:02.897" CommentCount="2" />
  <row Id="482" PostTypeId="2" ParentId="39" CreationDate="2012-11-21T19:04:51.070" Score="4" Body="&lt;p&gt;More driver details:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;OpenNI or freenect can be used with the Xtion and the XBox Kinect.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The &quot;Kinect for Windows&quot; requires the Microsoft SDK and drivers. However, there is also a bridge to go from the MSSDK drivers to OpenNI: &lt;a href=&quot;http://code.google.com/p/kinect-mssdk-openni-bridge/&quot; rel=&quot;nofollow&quot;&gt;http://code.google.com/p/kinect-mssdk-openni-bridge/&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, the latest version of the Kinect for Windows (&gt;=1.5) has a &lt;a href=&quot;http://blogs.msdn.com/b/kinectforwindows/archive/2012/01/20/near-mode-what-it-is-and-isn-t.aspx&quot; rel=&quot;nofollow&quot;&gt;near mode&lt;/a&gt; that allows for better operation close to the device, this may be of use depending on the application. I do not believe the Xtion has this mode.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The XBox Kinect and Kinect for Windows appear to have different USB interfaces, so you have to use the right set of drivers depending on which one you have.&lt;/p&gt;&#xA;" OwnerUserId="479" LastEditorUserId="479" LastEditDate="2012-11-22T14:15:59.220" LastActivityDate="2012-11-22T14:15:59.220" />
  <row Id="483" PostTypeId="1" CreationDate="2012-11-22T06:56:45.117" Score="4" ViewCount="110" Body="&lt;p&gt;What are some good strategies to follow while designing power supply for electrical systems on mobile robots?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Such robots typically comprise of systems with&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;microprocessor, microcontroller, DSP, etc units and boards along with immediate peripherals&lt;/li&gt;&#xA;&lt;li&gt;Motor control &lt;/li&gt;&#xA;&lt;li&gt;Analog Sensors(proximity, audio, voltage, etc)&lt;/li&gt;&#xA;&lt;li&gt;Digital Sensors (Vision, IMU, and other exotica)&lt;/li&gt;&#xA;&lt;li&gt;Radio comm circuits (Wifi, Bluetooth, Zigbee, etc)&lt;/li&gt;&#xA;&lt;li&gt;Other things more specific to the purpose of the robot being designed.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Are there unified approaches/architectural rules to designing power systems which can manage clean power supply to all these various units which may be distributed across boards, without issues of interference, common ground, etc? Furthermore, also including aspects of redundancy, failure management, and other such 'power management/monitoring' features?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;well explained examples of some such existing power systems on robots would make for excellent answers.&lt;/p&gt;&#xA;" OwnerUserId="222" LastEditorUserId="222" LastEditDate="2012-11-22T07:55:24.433" LastActivityDate="2012-11-25T05:27:55.233" Title="Strategies for managing power on electrical systems for mobile robots" Tags="&lt;mobile-robot&gt;&lt;electronics&gt;" AnswerCount="2" />
  <row Id="484" PostTypeId="2" ParentId="479" CreationDate="2012-11-22T10:49:18.167" Score="4" Body="&lt;p&gt;As I guess you found out yourself, the resampling method you are proposing is slightly flawed, as it should not alter the number of particles (unless you want to). The principle is that the weight represents the relative probability with respect to the other particles. In the resampling step, you draw from the set of particles such that for each particle, the normalized weight times the number of particles represents the number of times that particle is drawn on average. In that your idea is correct. Only by using rounding instead of sampling, you will always eliminate particles for which the expected value is less than half. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are a number of ways to perform the resampling properly. There is a nice paper called &lt;a href=&quot;http://users.isy.liu.se/rt/schon/Publications/HolSG2006.pdf&quot; rel=&quot;nofollow&quot;&gt;On resampling algorithms for particle filters&lt;/a&gt;, comparing the different methods. Just to give a quick overview:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Multinomial resampling: imagine a strip of paper where each particle has a section, where the length is proportional to its weight. Randomly pick a location on the strip N times, and pick the particle associated with the section.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Residual resampling: this approach tries to reduce the variance of the sampling, by first allocating each particle their integer floor of the expected value, and leave the rest to multinomial resampling. E.g. a particle with an expected value of 2.5 will have 2 copies in the resampled set and another one with an expected value of 0.5.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Systematic resampling: take a ruler with regular spaced marks, such that N marks are the same length as your strip of paper. Randomly place the ruler next to your strip. Take the particles at the marks.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Stratified resampling: same as systematic resampling, except that the marks on the ruler are not evenly placed, but added as N random processes sampling from the interval 0..1/N.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;So to answer your question: what you have implemented could be extended to a form of residual sampling. You fill up the missing slots by sampling based on a multinonmial distribution of the reminders.&lt;/p&gt;&#xA;" OwnerUserId="127" LastEditorUserId="127" LastEditDate="2012-11-22T11:02:59.407" LastActivityDate="2012-11-22T11:02:59.407" CommentCount="1" />
  <row Id="485" PostTypeId="2" ParentId="483" CreationDate="2012-11-22T11:47:46.667" Score="2" Body="&lt;p&gt;I don't know any &quot;rules&quot;, but for complex bots, I create separate &quot;power&quot; unit. It basically consists of the battery, as well as some 7805s/7809s. The 78xx series takes a 12V input and gives an xx V output. Most ICs work well on 5V, and an Arduino needs 9V, so that's what I end up using (Note: the 5V/3V output pins on the Arduino are &lt;em&gt;not&lt;/em&gt; really meant to be used much. They don't supply much power, so it's best to have a separate 5V line for your circuitry).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;After this, I connect all components in parallel to their respective power pins. It is generally beneficial to power the motor with a separate source (common ground). The motor draws the most current, so the simple act of stopping/slowing a motor can send fluctuations throughout the circuit. If you don't want to do this, at least add &lt;a href=&quot;http://www.seattlerobotics.org/encoder/jun97/basics.html&quot; rel=&quot;nofollow&quot;&gt;bypass capacitors&lt;/a&gt; to the motor and the power inputs(Vcc/Gnd) of logic circuits (see &lt;a href=&quot;http://robotics.stackexchange.com/questions/267/why-are-capacitors-added-to-motors-in-parallel-what-is-their-purpose&quot;&gt;here&lt;/a&gt; for more on how they work). These solve quite a few interference issues.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you want to be a bit more sophisticated, you can add zener diodes to the power outputs. Never had to do this myself, but it's apparently a good way of &quot;rationing out&quot; power. There also are &quot;constant current diodes&quot; that you can use--though I've never even seen one of those.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For redundancy, the most you can do (for DC) is put two batteries in parallel and maybe send power to components by different physical routes. Take note of the &quot;physical&quot; there--the placement of the wires may be different (and they may attach do different parts of the board), but the overall circuit should remain unchanged. The reason behind doing this is that not doing this right may lead to power pins being shorted-- two logically separate 5V outputs shouldn't be shorted together, they won't be exactly the same and you'll probably have some heating/leakage.&lt;/p&gt;&#xA;" OwnerUserId="126" LastEditorUserId="126" LastEditDate="2012-11-22T12:20:02.423" LastActivityDate="2012-11-22T12:20:02.423" />
  <row Id="487" PostTypeId="2" ParentId="167" CreationDate="2012-11-23T18:48:58.630" Score="1" Body="&lt;p&gt;I just came across &lt;a href=&quot;http://www.microcontrollercentral.com/author.asp?section_id=2379&amp;amp;doc_id=254676&amp;amp;&quot; rel=&quot;nofollow&quot;&gt;this article&lt;/a&gt; showing the results of using genetic algorithms to tune a PID controller.&lt;/p&gt;&#xA;" OwnerUserId="61" LastActivityDate="2012-11-23T18:48:58.630" />
  <row Id="488" PostTypeId="1" CreationDate="2012-11-23T19:01:14.153" Score="4" ViewCount="91" Body="&lt;p&gt;Is it possible to use the matlab's &quot;system&quot; function to call ROS commands?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, using:&#xA;system('rostopic pub /cmd_vel geometry.msgs.Twist {....}&#xA;or system('rospack find ipc_bridge)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm trying to send some commands to ROS without using something like IPC-Bridge.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;PS: I know, however, that I need to use IPC-Bridge to subscribe to topics.&lt;/p&gt;&#xA;" OwnerUserId="483" LastActivityDate="2012-11-23T19:10:12.973" Title="Matlab 'system' function with ROS" Tags="&lt;mobile-robot&gt;&lt;software&gt;&lt;ros&gt;" AnswerCount="1" />
  <row Id="489" PostTypeId="2" ParentId="488" CreationDate="2012-11-23T19:10:12.973" Score="2" Body="&lt;p&gt;This is possible. But it is very sloppy, in my humble opinion. It is useful for one-off commands, but how will you read back output, verify your command was executed, etc. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are dead-set against the IPC bridge, you may want to look at using the &lt;a href=&quot;http://www.mathworks.com/help/matlab/matlab_external/product-overview.html&quot; rel=&quot;nofollow&quot;&gt;MATLAB-java interface&lt;/a&gt;. ROS also allows you to program in Java using ros-fuerte-client-rosjava (ubuntu), or just &lt;a href=&quot;http://www.ros.org/wiki/rosjava&quot; rel=&quot;nofollow&quot;&gt;rosjava&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="163" LastActivityDate="2012-11-23T19:10:12.973" CommentCount="2" />
  <row Id="490" PostTypeId="2" ParentId="469" CreationDate="2012-11-23T21:06:12.147" Score="2" Body="&lt;p&gt;Speaking about navigation among moving obstacles, look at Jur van den Berg thesis. Also Lavalle provided a tutorial at ICRA12 &lt;a href=&quot;http://msl.cs.uiuc.edu/~lavalle/icra12/&quot; rel=&quot;nofollow&quot;&gt;http://msl.cs.uiuc.edu/~lavalle/icra12/&lt;/a&gt; and the videos are here &lt;a href=&quot;http://techtalks.tv/events/105/&quot; rel=&quot;nofollow&quot;&gt;http://techtalks.tv/events/105/&lt;/a&gt; but neither mention the problem of bipeds.&lt;/p&gt;&#xA;" OwnerUserId="484" LastActivityDate="2012-11-23T21:06:12.147" CommentCount="1" />
  <row Id="491" PostTypeId="2" ParentId="445" CreationDate="2012-11-24T00:03:25.917" Score="2" Body="&lt;p&gt;So the stereo image processing algorithms I have used in the past were implemented pixel by pixel. We just used the pinhole camera model and did some old fashioned measurements with measuring tape until our depth estimations matched the real thing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The equations for a pair of parallel cameras are:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;$d = $half the distance between the cameras&lt;/li&gt;&#xA;&lt;li&gt;$f = $the focal length of the cameras (assumed to be the same)&lt;/li&gt;&#xA;&lt;li&gt;Coordinate Frames: &#xA;&lt;ul&gt;&#xA;&lt;li&gt;$x, y, z = $ coordinate frame between the cameras (i.e. the camera base frame)&lt;/li&gt;&#xA;&lt;li&gt;$u_R, v_R$ camera coordinates in the right camera from the perspective of the robot (u is horizontal, v is vertical)&lt;/li&gt;&#xA;&lt;li&gt;$u_L, v_L$ camera coordinates in the left camera &lt;/li&gt;&#xA;&lt;li&gt;Note: the camera coordinates have their origins at the coordinate frame between the cameras (i.e. the u axes face opposite directions)&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;$u_L = \frac{f(x-d)}{z}$, $u_R = \frac{f(x+d)}{z}$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$zu_R = f(x+d)$, $zu_L = f(x-d)$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$z(u_R - u_L) = 2df$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$z = \frac{2df}{u_R - u_L}$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$y = \frac{v_L*z + df}{f}$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$x = \frac{u_L*z + df}{f}$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Using these equations you can compute a dense stereo cloud.  One for each pixel on your cameras.&lt;/p&gt;&#xA;" OwnerUserId="485" LastActivityDate="2012-11-24T00:03:25.917" CommentCount="1" />
  <row Id="492" PostTypeId="2" ParentId="167" CreationDate="2012-11-24T05:05:53.153" Score="2" Body="&lt;p&gt;&lt;strong&gt;System modeling&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Of course experimental tuning can be done as mentioned in the other answers, but if you are able to define a reasonable dynamic model for whatever you want to control and are able to &lt;a href=&quot;http://en.wikipedia.org/wiki/System_identification&quot; rel=&quot;nofollow&quot;&gt;identify its parameters&lt;/a&gt;, you should be able to design your controller based on well-defined criteria such as &lt;a href=&quot;http://en.wikipedia.org/wiki/Overshoot_%28signal%29&quot; rel=&quot;nofollow&quot;&gt;overshoot&lt;/a&gt;, &lt;a href=&quot;http://en.wikipedia.org/wiki/Rise_time&quot; rel=&quot;nofollow&quot;&gt;rise time&lt;/a&gt;, &lt;a href=&quot;http://en.wikipedia.org/wiki/Settle_time&quot; rel=&quot;nofollow&quot;&gt;settling time&lt;/a&gt;, &lt;a href=&quot;http://en.wikipedia.org/wiki/Steady_state_%28electronics%29&quot; rel=&quot;nofollow&quot;&gt;steady-state&lt;/a&gt; error and so on. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are even &lt;a href=&quot;http://www.mathworks.com/help/control/ref/pidtool.html&quot; rel=&quot;nofollow&quot;&gt;tools in MATLAB&lt;/a&gt; that are able to tune your controller to optimize for a combination of these criteria, which makes it even better to use.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Know your controller&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Learning what each parameter in the PID controller does is quite helpful as well. All the experimental algorithms are based on this kind of knowledge somehow. If you not only follow instructions, but are able to get that feeling yourself, you may find it easier to tune your controller manually.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Real world problems&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is a chance one of these things, among others, will get on your way when tuning your controller: &lt;a href=&quot;http://en.wikipedia.org/wiki/Integral_windup&quot; rel=&quot;nofollow&quot;&gt;windup&lt;/a&gt;, &lt;a href=&quot;http://en.wikipedia.org/wiki/Nyquist_frequency&quot; rel=&quot;nofollow&quot;&gt;inadequate sampling rate&lt;/a&gt;, &lt;a href=&quot;http://wikis.controltheorypro.com/index.php?title=Saturation&quot; rel=&quot;nofollow&quot;&gt;saturation&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the end, it all depends on what you can actually do with your system to get some knowledge about how it works and what kind of experimentation can be done. The best thing is to actually learn more about PID controllers and control theory in general, IMO, but I'm biased :)&lt;/p&gt;&#xA;" OwnerUserId="95" LastActivityDate="2012-11-24T05:05:53.153" />
  <row Id="493" PostTypeId="2" ParentId="277" CreationDate="2012-11-24T05:10:03.493" Score="5" Body="&lt;p&gt;A Kalman Filter is an algorithm that is commonly used in UAVs to fuse multiple sensor measurements together to provide an &quot;optimal&quot; estimate of the position and/or orientation of the UAV.  For example, a Kalman Filter can fuse accelerometer, gyro and magnetometer measurements with a velocity estimate to estimate the UAV's yaw, pitch and roll.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For more information on the sensors and algorithms used in UAV state estimation, try the stand-alone article &lt;a href=&quot;http://www.jhuapl.edu/techdigest/TD/td3102/31_02-Barton.pdf&quot;&gt;Fundamentals of Small Unmanned Aircraft Flight&lt;/a&gt;.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The article also links to accompanying Matlab code implementing the described Kalman Filter UAV state estimation algorithms.&lt;/p&gt;&#xA;" OwnerUserId="486" LastActivityDate="2012-11-24T05:10:03.493" CommentCount="1" />
  <row Id="494" PostTypeId="1" AcceptedAnswerId="495" CreationDate="2012-11-24T10:28:54.920" Score="3" ViewCount="4162" Body="&lt;p&gt;I'm interested to build Robot from my imagination, and I was looking to purchase a robotic kit.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I find the Lego Mindstorm NXT 2.0 really interesting for many reasons : You can plug whatever brick you want, and you can develop in the language you want.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am a developer, and the use of this kind of robotic would be interaction mostly (not moving, so the servo motors are useless to me, at least now).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But regarding the spec of the NXT main component, I feel it's a bit low (proc, ram &amp;amp; rom).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;That made me wonder if any of you know something similar (where I can plug whatever I want on it, and most importantly, program the reaction), but with a more powerful hardware ?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Price will also be a limitation : I like the NXT also because I can build what I want under 300 USD. I don't want to spend 10k USD on my first kit, but I would appreciate buying a better piece of robotic if the price isn't too distant from the NXT's.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Do you have some alternatives to check out ?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks for your help !  :)&lt;/p&gt;&#xA;" OwnerUserId="488" LastEditorUserId="488" LastEditDate="2012-11-24T12:12:50.780" LastActivityDate="2013-03-11T16:44:48.730" Title="More powerful alternatives to Lego Mindstorm NXT 2.0?" Tags="&lt;nxt&gt;" AnswerCount="5" CommentCount="3" FavoriteCount="3" ClosedDate="2013-03-12T13:16:45.653" />
  <row Id="495" PostTypeId="2" ParentId="494" CreationDate="2012-11-24T11:28:24.697" Score="4" Body="&lt;p&gt;I do not think you will find ANY kit better than the NXT 2.0.  You may find components, and be able to piece together your own Robot, but there is nothing available as a kit that I know of in that price range (which BTW is $230 at walmart at the moment, pretty good deal). I also do not understand how you are planning to do very much without using servos. A robot that has no movement at all is pretty boring, and more like a refrigerator than a robot. The use of servos is IMHO an important part of robotics.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Exactly what is &quot;a more powerful &quot;AI&quot;'? As a developer, I would not have expected that type of question. Are you sure an NXT does not have enough AI for your current robotic experience? Personally, short of some neural network stuff, I have never exceeded capacity with an NXT, and I was able to size that down and make it workable. Learning to be efficient is part process.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The NXT also open up great opportunities in mechanical design as well as pure robotics. There is plenty to keep anyone busy for quite a while, until college at least, then you step up to $1/2million dollar PR2s that someone else paid for.&lt;/p&gt;&#xA;" OwnerUserId="274" LastActivityDate="2012-11-24T11:28:24.697" CommentCount="5" />
  <row Id="496" PostTypeId="2" ParentId="494" CreationDate="2012-11-24T11:40:34.580" Score="3" Body="&lt;blockquote&gt;&#xA;  &lt;p&gt;but with a more powerful &quot;AI&quot; ?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Firstly, &lt;em&gt;no&lt;/em&gt; robotics kit has any AI built in. AI needs to be tailor-made for the situation, it's not like you &lt;a href=&quot;http://xkcd.com/353/&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;import AI&lt;/code&gt;&lt;/a&gt; and everything just... works. You need to program your own AI every time you want a smart bot. That being said, some  AI-related things like image processing can be found prepackaged for use.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Regarding kits, I don't know of there's any such kit that's better than the NXT. For &quot;serious robotics&quot;, such kits will always prove inadequate as they're restrictive in many ways. What I suggest is to start using an Arduino or Raspberry Pi. A Raspberry Pi fits your criteria more--it has a good amount of RAM, and runs Linux--so it's easier to work with (it's pretty much like programming a normal application, except you don't need to create a GUI for the app). It's extremely cheap, costs $25-$35. You can use whatever language you want here, as long as you have something to make the language run on Linux (gcc/python/java--generally these are all built in, though you can easily find APT packages for stuff like ruby). In addition, it's easy to find packages for tasks like image processing/etc. It also has 512MB of RAM, which is good enough unless you want to play Warcraft on it. You do have to get familiar with Linux to use this, though.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The Arduino's another good (possibly better) option. You can program it in C/C++/Java (and some other languages if you use some third party tools). It is low on RAM, though--you sometimes need to chain two Arduinos in a master-slave configuration to get stuff done. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The only issue is, you need to make your own sensors for the Raspberry Pi (sensors for the Arduino exist and some can be found &lt;a href=&quot;http://www.trossenrobotics.com/c/arduino-sensors.aspx&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;. In addition, there is some examples using NXT equipment &lt;a href=&quot;http://www.dexterindustries.com/blog/2013/02/27/connecting-the-arduino-and-the-lego-mindstorms-howto/&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;.) Generally not that hard (for example, a light/dark sensor can be made with a photodiode and resistor), though this is a big shift from the NXT (which was plug-and-play). You'll have to get your own servos and learn how they are controlled, and lots of other little things. You &lt;em&gt;will&lt;/em&gt; have to get your hands dirty with soldering control boards/etc, and you &lt;em&gt;will&lt;/em&gt; have to know a decent amount of electronics.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Otherwise you can just continue using the NXT, there are all sorts of premade sensors out there (though custom making your own sensor isn't that easy). &lt;/p&gt;&#xA;" OwnerUserId="126" LastEditorUserId="998" LastEditDate="2013-03-09T11:39:43.197" LastActivityDate="2013-03-09T11:39:43.197" CommentCount="9" />
  <row Id="497" PostTypeId="1" CreationDate="2012-11-24T12:35:35.347" Score="1" ViewCount="125" Body="&lt;p&gt;I was wondering whether something like this is possible: A block of ice(say) needs to be transferred piece by piece from a source to a destination with the help of 5 robots standing in a straight line between the source and destination. The first robot picks up a piece of the block from the source and checks if the next robot in line is busy. If yes, it waits for it to complete its task and proceeds, otherwise it transfers the piece and goes back to collect another piece. Please help me on implementing this if it is possible, as I am thinking to make it a project topic.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;to clear out the confusions, here's a smaller prototype of the project i'm thinking,&lt;/p&gt;&#xA;&#xA;&lt;p&gt;i have two cars, one wired, another wireless. the wired car is the master here, the wireless, the slave. through a remote, i send a command to the wired car to instead command the wireless car to move forward. the wired car will then check if the wireless slave is already executing some previously given command or no, and accordingly send the command.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;conversely, the master may send the command as soon as it receives it, it's on the slave now to complete the task it's doing, and then execute the command it just received.&lt;/p&gt;&#xA;" OwnerUserId="489" LastEditorUserId="350" LastEditDate="2012-11-30T00:52:30.300" LastActivityDate="2012-11-30T00:52:30.300" Title="Collaborative Behavior: Implementing a Bucket Brigade With Robot Arms" Tags="&lt;mobile-robot&gt;&lt;multi-agent&gt;" AnswerCount="2" CommentCount="7" FavoriteCount="1" />
  <row Id="498" PostTypeId="2" ParentId="494" CreationDate="2012-11-24T13:09:48.280" Score="1" Body="&lt;p&gt;If you look for more advanced kits than the NXT brick, consider picking any ARM board you like. For example the &lt;a href=&quot;http://www.raspberrypi.org/&quot; rel=&quot;nofollow&quot;&gt;Raspberry Pi&lt;/a&gt;, the &lt;a href=&quot;http://cubieboard.org/&quot; rel=&quot;nofollow&quot;&gt;CubieBoard&lt;/a&gt; or the &lt;a href=&quot;http://www.pandaboard.org/&quot; rel=&quot;nofollow&quot;&gt;PandaBoard&lt;/a&gt;. All of them can be rather easily combined or expanded with electronics or sensors you like, some of them, like the RasPi have plenty of GPIO pins. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Considering hardware extensions, &lt;a href=&quot;http://www.vexrobotics.com/&quot; rel=&quot;nofollow&quot;&gt;VEX Robotics&lt;/a&gt; have many different parts like structural elements, wheels, motors, sensors, nuts, bolts and sprockets who are standardized by the company to fit nicely with each other.&lt;/p&gt;&#xA;" OwnerUserId="422" LastActivityDate="2012-11-24T13:09:48.280" CommentCount="8" />
  <row Id="499" PostTypeId="1" CreationDate="2012-11-24T17:09:46.203" Score="8" ViewCount="398" Body="&lt;p&gt;I dont understand integral part of PID controller. Let's assume this pseudocode from Wikipedia:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;previous_error = 0&#xA;integral = 0 &#xA;start:&#xA;  error = setpoint - measured_value&#xA;  integral = integral + error*dt&#xA;  derivative = (error - previous_error)/dt&#xA;  output = Kp*error + Ki*integral + Kd*derivative&#xA;  previous_error = error&#xA;  wait(dt)&#xA;  goto start&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Integral is set to zero in the beginning. And then in the loop it's integrating the error over the time. When I make a (positive) change in setpoint, the error will become positive and integral will &quot;eat&quot; the values over the time (from the beginning). But what I dont understand is, when error stabilizes back to zero, the integral part will still have some value (integrated errors over time) and will still contribute to the output value of controller, but it should not, because if error is zero, output of PID should be zero as well, right?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can somebody explain me that please?&lt;/p&gt;&#xA;" OwnerUserId="491" LastActivityDate="2012-11-25T21:03:08.797" Title="I don't understand Integral part of PID controller" Tags="&lt;control&gt;&lt;pid&gt;" AnswerCount="2" FavoriteCount="2" />
  <row Id="500" PostTypeId="2" ParentId="499" CreationDate="2012-11-24T18:09:25.390" Score="12" Body="&lt;p&gt;The main purpose of the integral term is to eliminate the steady state error.&#xA;In the normal case there is going to be a small steady state error and the integral is mainly used to eliminate this error.&#xA;It's however true that when the error gets to 0 the integral will still be positive and will make you overshoot. Then after overshoot the integral will start to go down again. This is the negative effect of the integral term.&#xA;So there is always the trade-off and you have to tune the PID controller to make sure that the overshoot is as small as possible and that the steady state error is minimized.&#xA;Here is where the derivative term come into play. The derivative term helps to minimize the overshoot in the system.&lt;/p&gt;&#xA;" OwnerUserId="128" LastEditorUserId="128" LastEditDate="2012-11-24T18:14:29.947" LastActivityDate="2012-11-24T18:14:29.947" CommentCount="2" />
  <row Id="501" PostTypeId="2" ParentId="494" CreationDate="2012-11-24T20:39:26.583" Score="1" Body="&lt;p&gt;For a programmer, you might want to check out &lt;a href=&quot;http://www.netmf.com/gadgeteer/&quot; rel=&quot;nofollow&quot;&gt;Gadgeteer&lt;/a&gt;.  No soldering or electronics experience required.  There is a wide range of processors that run .NET MF and interface with compatible devices.  &lt;a href=&quot;http://www.ghielectronics.com/catalog/category/265/&quot; rel=&quot;nofollow&quot;&gt;GHI&lt;/a&gt; is one of the larger purveyors of Gadgeteer devices.&lt;/p&gt;&#xA;" OwnerUserId="493" LastActivityDate="2012-11-24T20:39:26.583" />
  <row Id="502" PostTypeId="1" AcceptedAnswerId="503" CreationDate="2012-11-24T21:27:31.757" Score="2" ViewCount="104" Body="&lt;p&gt;Robots are somewhat videogenic, and the old saying &quot;show me, don't tell me&quot; is especially applicable.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But of course, a video is not a &lt;em&gt;question&lt;/em&gt;, so it doesn't fit the Stack Exchange format.  Maybe video links would be more suitable in a CodeProject post.  It just seems like this board hits the right cross-section of people, whose projects I would be interested in seeing.&lt;/p&gt;&#xA;" OwnerUserId="493" LastActivityDate="2012-11-25T22:17:47.680" Title="Is there a place for posting &quot;look at what I did&quot; videos?" Tags="&lt;untagged&gt;" AnswerCount="3" FavoriteCount="1" />
  <row Id="503" PostTypeId="2" ParentId="502" CreationDate="2012-11-24T21:40:54.527" Score="6" Body="&lt;p&gt;&lt;a href=&quot;http://letsmakerobots.com/&quot;&gt;Let's Make Robots&lt;/a&gt; is a good place to show off ones projects. See the &lt;a href=&quot;http://letsmakerobots.com/view/node/list/robot&quot;&gt;robots&lt;/a&gt; section to see other peoples work as well.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2012-11-24T21:40:54.527" CommentCount="3" />
  <row Id="504" PostTypeId="1" AcceptedAnswerId="508" CreationDate="2012-11-24T21:43:42.497" Score="2" ViewCount="284" Body="&lt;p&gt;I am making a 2 wheel drive robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Suppose I know that my robot is going to weight x kg when finished and I know the diameter of the wheels y (geared motors will be connected directly to the wheels). I can choose from several geared motors and I know the peak torque of each motor and the idling speed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How can I calculate the load that a specific motor can take? I.e. will a motor with a given torque be able to move my robot without being too overloaded? What rpm will the motor have when it has load?&lt;/p&gt;&#xA;" OwnerUserId="128" LastActivityDate="2012-12-12T15:06:27.483" Title="Choosing motors for 2 wheel drive robot" Tags="&lt;motor&gt;" AnswerCount="2" />
  <row Id="505" PostTypeId="2" ParentId="497" CreationDate="2012-11-24T23:20:33.917" Score="2" Body="&lt;p&gt;The generic answer is yes, such a project could be implemented using existing hardware and frameworks (ROS, MRDS, something else, or none).  The collaboration part is pretty simple in this scenario, it's a straightforward handshake between producer &amp;amp; consumer.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The hard part would be first defining each of the jobs in detail, procuring hardware that meets the requirements, and actually getting each robot to do his assigned task reliably.  As others have pointed out, you'll need to be a lot more specific.&lt;/p&gt;&#xA;" OwnerUserId="493" LastActivityDate="2012-11-24T23:20:33.917" />
  <row Id="506" PostTypeId="2" ParentId="502" CreationDate="2012-11-25T00:22:37.967" Score="2" Body="&lt;p&gt;The AAAI video competition is a good yearly place to put them.  Otherwise, submitting them to IEEE Spectrum is a good idea as well.  Though its not the best robot news ever, it is the most consistent and most people in the industry check it at least weekly.&lt;/p&gt;&#xA;" OwnerUserId="485" LastActivityDate="2012-11-25T00:22:37.967" />
  <row Id="507" PostTypeId="2" ParentId="483" CreationDate="2012-11-25T05:27:55.233" Score="1" Body="&lt;p&gt;These are the rules I follow when I am building power supply systems on my (small, mobile) robots:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I always separate the motors' power supply from any other circuitry, to reduce interference (as @Manishearth &lt;a href=&quot;http://robotics.stackexchange.com/a/485/435&quot;&gt;mentions&lt;/a&gt;).&lt;/li&gt;&#xA;&lt;li&gt;For the rest of my electronic systems, I step down (using linear regulators) from a battery to each of the required voltages (usually 5V and 3.3V in my applications) in parallel.&lt;/li&gt;&#xA;&lt;li&gt;I always include standard diodes as the first component after the battery's connection to any circuit boards, to protect against damage by reverse polarity. The voltage drop here should be taken into account when looking at regulator drop-outs.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Most of my robots have been fairly simple and have not merited much in the way of redundancy, but a common way to add basic redundancy in the case of one power supply failing is through a simple relay-based switch box. This can be configured such that the power supply powers the relay coil in parallel to passing through the Normally-Open contacts to the robot. A second backup supply can be wired to pass through the Normally-Closed contacts. If the first supply fails, the relay will toggle over to the second supply. Cleverer systems can monitor power supply health and manually switch between primary and backup sources as required.&lt;/p&gt;&#xA;" OwnerUserId="435" LastActivityDate="2012-11-25T05:27:55.233" />
  <row Id="508" PostTypeId="2" ParentId="504" CreationDate="2012-11-25T07:50:14.843" Score="4" Body="&lt;p&gt;I would say you should use the diameter of the wheel (and any gearing embedded in the motor) to calculate how much force each motor can provide in the point of contact, and estimate the amount of friction your wheel would have against the expected surface your robot would be moving around on.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Note that this isn't exactly trivial to estimate&lt;/strong&gt;, so usually what people do as far as I know is either choose a motor that is obviously much stronger than what would be necessary or prototype until they reach a sweet spot. &lt;strong&gt;Open-source projects&lt;/strong&gt; are also a great way to become more aware of the realistic needs of your robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I will also add another point that wasn't included in your question but is mighty important: &lt;strong&gt;if you plan to use DC motors, make sure they have encoders&lt;/strong&gt;. That way, you will be able to perform closed-loop control and your robot will be able to walk in a straight line. Also, if its possible, &lt;strong&gt;try to use current sensing&lt;/strong&gt; so you can detect overloading conditions when your robot is stalled.&lt;/p&gt;&#xA;" OwnerUserId="95" LastActivityDate="2012-11-25T07:50:14.843" />
  <row Id="509" PostTypeId="2" ParentId="497" CreationDate="2012-11-25T09:30:29.897" Score="2" Body="&lt;p&gt;A standard way to model that kind of discrete-event behavior is through &lt;a href=&quot;http://en.wikipedia.org/wiki/Petri_net&quot; rel=&quot;nofollow&quot;&gt;Petri Nets&lt;/a&gt; or a &lt;a href=&quot;http://users.abo.fi/jboling/cdes/op_on_aut.pdf&quot; rel=&quot;nofollow&quot;&gt;Parallel Composition&lt;/a&gt; of &lt;a href=&quot;http://en.wikipedia.org/wiki/Finite_state_machine&quot; rel=&quot;nofollow&quot;&gt;Automata&lt;/a&gt;. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;An interesting start might be to simply create the model and see if it works in &lt;a href=&quot;http://www.informatik.uni-hamburg.de/TGI/PetriNets/tools/quick.html&quot; rel=&quot;nofollow&quot;&gt;simulation&lt;/a&gt; first. That will help you solve the high-level logic of your problem. After that is dealt with, you can begin to think about which robot you want to use (or whether you want to build your own) and how you'll implement that high-level logic in your programming language of choice.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The good thing about using these models is that you have means to systematically evaluate whether you have solved your problem or not. Ad-hoc programming might work if the problem is simple enough, but as soon as you incorporate more difficult situations it becomes too error-prone IMO.&lt;/p&gt;&#xA;" OwnerUserId="95" LastActivityDate="2012-11-25T09:30:29.897" />
  <row Id="510" PostTypeId="2" ParentId="106" CreationDate="2012-11-25T09:40:10.533" Score="-1" Body="&lt;p&gt;If you really want to dive into the mathematics of it, &lt;a href=&quot;http://web.cecs.pdx.edu/~mperkows/CLASS_479/S2006/kinematics-mobot.pdf&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;'s the seminal paper that unified and categorized most models for wheeled robots.&lt;/p&gt;&#xA;" OwnerUserId="95" LastActivityDate="2012-11-25T09:40:10.533" CommentCount="2" />
  <row Id="511" PostTypeId="1" AcceptedAnswerId="517" CreationDate="2012-11-25T18:30:52.343" Score="0" ViewCount="92" Body="&lt;p&gt;I recently got an arduino wifi shield known as &quot;juniper&quot; (I believe it was by cutedigi). I've tried to find code examples, but when I saw code, it was un-commented and very little explained, I could really use a tutorial or some sample code with a good explanation, can anyone help me find a place to start? I found a piece of code here: &lt;a href=&quot;http://arduino.cc/forum/index.php?action=printpage;topic=103582.0&quot; rel=&quot;nofollow&quot;&gt;http://arduino.cc/forum/index.php?action=printpage;topic=103582.0&lt;/a&gt;&#xA;and I just want to connect to a network, maybe send some get requests, or open a socket.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT:&#xA;after poking around for a while, i found documentation, but I still can't get it to work.&#xA;my code:&#xA;&lt;a href=&quot;http://pastie.org/5455603&quot; rel=&quot;nofollow&quot;&gt;http://pastie.org/5455603&lt;/a&gt;&#xA;I can't seem to get any input at all from the wifi shield.&lt;/p&gt;&#xA;" OwnerUserId="498" LastEditorUserId="498" LastEditDate="2012-11-30T01:07:53.007" LastActivityDate="2012-11-30T01:07:53.007" Title="Where can I find a tutorial or sample code for the Juniper WiFi Arduino Shield?" Tags="&lt;arduino&gt;&lt;electronics&gt;&lt;wifi&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="512" PostTypeId="1" CreationDate="2012-11-25T19:03:29.883" Score="-4" ViewCount="306" Body="&lt;p&gt;For someone interested in robotics but do not know the ABC of robotics or mechanical/electronic engineering .What's a good roadmap for becoming an amateur roboticist . I'm studying theoretical physics so that I have no problems on the physics/math . If the question is too broad and doesn't meet the criteria of posting on this site . Please inform me of any helpful advice/study material etc. before the question get closed .&#xA;Thanks in advance.&lt;/p&gt;&#xA;" OwnerUserId="499" LastActivityDate="2012-11-25T23:01:16.720" Title="How can I start learning robotics?" Tags="&lt;books&gt;" AnswerCount="2" CommentCount="3" FavoriteCount="1" ClosedDate="2012-11-27T16:30:03.197" />
  <row Id="514" PostTypeId="2" ParentId="512" CreationDate="2012-11-25T20:42:21.480" Score="4" Body="&lt;p&gt;Start with basic electronics, ditch the books, start empirically do stuff. Chances are you will be bored as hell and it will be over.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Buy some cheap breadboard, LEDs transistors, buttons and see if its fun. Next buy some cheap engines and play with them. Still reading? Buy some books like &quot;Robot Building for Beginners-David Cook&quot; or surf the web. &#xA;Next buy Arduino Uno (the cheapest) and learn some C or Java to program it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then you will know enough to decide for yourself and you will spend no more than 100$ on the stuff until then.&lt;/p&gt;&#xA;" OwnerUserId="501" LastEditorUserId="177" LastEditDate="2012-11-25T21:08:38.197" LastActivityDate="2012-11-25T21:08:38.197" CommentCount="3" />
  <row Id="515" PostTypeId="2" ParentId="499" CreationDate="2012-11-25T21:03:08.797" Score="3" Body="&lt;p&gt;Imagine that you set up a PID controller on your own arm, so that you could hold a cup of coffee straight out in front of you.  &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The proportional element would control your arm strength relative to your hand position being too high or too low.&lt;/li&gt;&#xA;&lt;li&gt;The derivative element would adjust that strength based on how quickly you were already moving, so that you don't overshoot your target.  &lt;/li&gt;&#xA;&lt;li&gt;The integral element would compensate for the effects of gravity; without it, the cup would come to rest where the proportional force equaled the force of gravity.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;It sounds like the part of the code you're stuck on is that the system must somehow measure the weight of the coffee, and one way to do that is to accumulate the position error over time.  Most PID controllers have an additional term to specify a reasonable limit on the size that the integral element can be.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2012-11-25T21:03:08.797" CommentCount="1" />
  <row Id="516" PostTypeId="2" ParentId="502" CreationDate="2012-11-25T22:09:48.730" Score="1" Body="&lt;p&gt;While there are specific outlets, as the other answers show, you shouldn't underestimate plain old &lt;a href=&quot;http://youtube.com&quot; rel=&quot;nofollow&quot;&gt;YouTube&lt;/a&gt;. Most research labs and companies simply host their videos there (e.g. &lt;a href=&quot;https://www.youtube.com/user/mitmedialab&quot; rel=&quot;nofollow&quot;&gt;MIT&lt;/a&gt;, &lt;a href=&quot;https://www.youtube.com/user/BostonDynamics&quot; rel=&quot;nofollow&quot;&gt;BostonDynamics&lt;/a&gt; and the likes), as do &lt;a href=&quot;https://www.youtube.com/watch?v=NqDTE6dHpJw&quot; rel=&quot;nofollow&quot;&gt;individuals&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="131" LastEditorUserId="131" LastEditDate="2012-11-25T22:17:47.680" LastActivityDate="2012-11-25T22:17:47.680" />
  <row Id="517" PostTypeId="2" ParentId="511" CreationDate="2012-11-25T22:56:55.463" Score="1" Body="&lt;p&gt;I think your best ally will be Google. A quick search for &quot;arduino juniper cutedigi&quot; led me to the &lt;a href=&quot;http://www.cutedigi.com/wireless/wifi/juniper-wifi-shield-for-arduino-based-on-gainspan-module.html&quot; rel=&quot;nofollow&quot;&gt;manufacturer's website&lt;/a&gt;, which includes a good amount of documentation and sample code under the &quot;Download:&quot; heading at the end of the page. Here's an extra &lt;a href=&quot;http://arduino.cc/forum/index.php/topic,118268.0.html&quot; rel=&quot;nofollow&quot;&gt;troubleshooting forum post&lt;/a&gt; that may be of use.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Even if you don't find the best documented code out there, finding several sample scripts that do similar things might help you understand the basics.&lt;/p&gt;&#xA;" OwnerUserId="295" LastActivityDate="2012-11-25T22:56:55.463" CommentCount="1" />
  <row Id="518" PostTypeId="2" ParentId="512" CreationDate="2012-11-25T23:01:16.720" Score="1" Body="&lt;p&gt;&lt;a href=&quot;http://robotics.stackexchange.com/questions/472/humble-beginnings&quot;&gt;This same question&lt;/a&gt; was just asked a few days ago.  Please &lt;a href=&quot;http://robotics.stackexchange.com/faq#questions&quot;&gt;look around&lt;/a&gt; before posting.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;That being said, I would suggest taking a programming course for a start.  The &lt;a href=&quot;http://www.udacity.com/overview/Course/cs373/CourseRev/apr2012&quot; rel=&quot;nofollow&quot;&gt;Udacity CS373&lt;/a&gt; class is the gentlest introduction to robotics I'm aware of.  I also recommend the &lt;a href=&quot;http://www.probabilistic-robotics.org/&quot; rel=&quot;nofollow&quot;&gt;textbook&lt;/a&gt; that the prof co-authored (but it's not used in the class).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then you can use the time as you're working through the class to educate yourself more on hardware options.&lt;/p&gt;&#xA;" OwnerUserId="493" LastActivityDate="2012-11-25T23:01:16.720" CommentCount="1" />
  <row Id="519" PostTypeId="1" CreationDate="2012-11-26T04:29:40.547" Score="10" ViewCount="282" Body="&lt;p&gt;I'm using an EKF for SLAM and I'm having some problem with the update step.  I'm getting a warning that K is singular, rcond evaluates to near eps or NaN. I think I've traced the problem to the inversion of Z.  Is there a way to calculate the Kalman Gain without inverting the last term? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm not 100% positive this is the cause of the problem, so I've also put my entire code here &lt;a href=&quot;https://github.com/jdowns/EKF-SLAM&quot;&gt;https://github.com/jdowns/EKF-SLAM&lt;/a&gt;.  The main entry point is slam2d.&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;function [ x, P ] = expectation( x, P, lmk_idx, observation)&#xA;    % expectation&#xA;    r_idx = [1;2;3];&#xA;    rl = [r_idx; lmk_idx];&#xA;&#xA;    [e, E_r, E_l] = project(x(r), x(lmk_idx)); &#xA;    E_rl = [E_r E_l];&#xA;    E = E_rl * P(rl,rl) * E_rl';&#xA;&#xA;    % innovation&#xA;    z = observation - e;&#xA;    Z = E;&#xA;&#xA;    % Kalman gain&#xA;    K = P(:, rl) * E_rl' * Z^-1;&#xA;&#xA;    % update&#xA;    x = x + K * z;&#xA;    P = P - K * Z * K';&#xA;end&#xA;&#xA;&#xA;function [y, Y_r, Y_p] = project(r, p)     &#xA;    [p_r, PR_r, PR_p] = toFrame2D(r, p);&#xA;    [y, Y_pr]   = scan(p_r);&#xA;    Y_r = Y_pr * PR_r;&#xA;    Y_p = Y_pr * PR_p;    &#xA;end&#xA;&#xA;&#xA;function [p_r, PR_r, PR_p] = toFrame2D(r , p)&#xA;    t = r(1:2);&#xA;    a = r(3);&#xA;    R = [cos(a) -sin(a) ; sin(a) cos(a)];&#xA;    p_r = R' * (p - t);&#xA;    px = p(1);&#xA;    py = p(2);&#xA;    x = t(1);&#xA;    y = t(2);&#xA;    PR_r = [...&#xA;        [ -cos(a), -sin(a),   cos(a)*(py - y) - sin(a)*(px - x)]&#xA;        [  sin(a), -cos(a), - cos(a)*(px - x) - sin(a)*(py - y)]];&#xA;    PR_p = R';    &#xA;end&#xA;&#xA;&#xA;function [y, Y_x] = scan(x)&#xA;    px = x(1);&#xA;    py = x(2);&#xA;    d = sqrt(px^2 + py^2);&#xA;    a = atan2(py, px);&#xA;    y = [d;a];&#xA;    Y_x =[...&#xA;    [     px/(px^2 + py^2)^(1/2), py/(px^2 + py^2)^(1/2)]&#xA;    [ -py/(px^2*(py^2/px^2 + 1)), 1/(px*(py^2/px^2 + 1))]];&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Edits:&#xA;project(x(r), x(lmk)) should have been project(x(r), x(lmk_idx)) and is now corrected above.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;K goes singular after a little while, but not immediately.  I think it's around 20 seconds or so.  I'll try the changes @josh suggested when I get home tonight and post the results.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Update 1:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My simulation first observes 2 landmarks, so K is 7x2.  (P(rl,rl) * E_rl') * inv( Z ) results in a 5x2 matrix, so it can't be added to x in the next line.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;K becomes singular after 4.82 seconds, with measurements at 50Hz (241 steps).  Following the advice here (http://www.mathworks.com/help/matlab/ref/inv.html), I tried K = (P(:, rl) * E_rl')/Z which results in 250 steps before a warning about K being singular is produced.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;This tells me the problem isn't with matrix inversion, but it's somewhere else that's causing the problem.    &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Update 2&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My main loop is (with a robot object to store x,P and landmark pointers):&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;for t = 0:sample_time:max_time&#xA;    P = robot.P;&#xA;    x = robot.x;&#xA;    lmks = robot.lmks;&#xA;    mapspace = robot.mapspace;&#xA;&#xA;    u = robot.control(t);&#xA;    m = robot.measure(t);&#xA;&#xA;    % Added to show eigenvalues at each step&#xA;    [val, vec] = eig(P);&#xA;    disp('***')&#xA;    disp(val)&#xA;&#xA;    %%% Motion/Prediction&#xA;    [x, P] = predict(x, P, u, dt);&#xA;&#xA;    %%% Correction&#xA;    lids = intersect(m(1,:), lmks(1,:));  % find all observed landmarks&#xA;    lids_new = setdiff(m(1,:), lmks(1,:));&#xA;    for lid = lids&#xA;        % expectation&#xA;        idx = find (lmks(1,:) == lid, 1);&#xA;        lmk = lmks(2:3, idx);&#xA;        mid = m(1,:) == lid;&#xA;        yi = m(2:3, mid);&#xA;&#xA;        [x, P] = expectation(x, P, lmk, yi);&#xA;    end  %end correction&#xA;&#xA;    %%% New Landmarks&#xA;&#xA;    for id = 1:length(lids_new)&#xA;    % if id ~= 0&#xA;        lid = lids_new(id);&#xA;        lmk = find(lmks(1,:)==false, 1);&#xA;        s = find(mapspace, 2);&#xA;        if ~isempty(s)&#xA;            mapspace(s) = 0;&#xA;            lmks(:,lmk) = [lid; s'];&#xA;            yi = m(2:3,m(1,:) == lid);&#xA;&#xA;            [x(s), L_r, L_y] = backProject(x(r), yi);&#xA;&#xA;            P(s,:) = L_r * P(r,:);&#xA;            P(:,s) = [P(s,:)'; eye(2)];&#xA;            P(s,s) = L_r * P(r,r) * L_r';&#xA;        end&#xA;    end  % end new landmarks&#xA;&#xA;    %%% Save State&#xA;    robot.save_state(x, P, mapspace, lmks)&#xA;    end  &#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;At the end of this loop, I save x and P back to the robot, so I believe I'm propagating the covariance through each iteration.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;More edits&lt;/strong&gt;&#xA;The (hopefully) correct eigenvalues are now here: &lt;a href=&quot;http://pastebin.com/Vn4NzkQy&quot;&gt;http://pastebin.com/Vn4NzkQy&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are a number of eigenvalues that are negative.  Although their magnitude is never very large, 10^-2 at most, it happens on the iteration immediately after the first landmark is observed and added to the map (in the &quot;new landmarks&quot; section of the main loop).&lt;/p&gt;&#xA;" OwnerUserId="502" LastEditorUserId="502" LastEditDate="2012-12-01T06:40:32.687" LastActivityDate="2013-04-19T18:06:02.797" Title="EKF-SLAM Update step, Kalman Gain becomes singular" Tags="&lt;slam&gt;&lt;kalman-filter&gt;" AnswerCount="2" CommentCount="4" FavoriteCount="2" />
  <row Id="520" PostTypeId="1" AcceptedAnswerId="575" CreationDate="2012-11-26T07:34:40.657" Score="4" ViewCount="383" Body="&lt;p&gt;A lot of awesome optics projects like hacking cameras and projectors become possible with CAD lens modelling software&lt;sup&gt;1&lt;/sup&gt;, if we can also easily prototype the lenses we design.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What are some materials and additive or subtractive 3D fabrication strategies that can make a clear lens with strong refraction and the ability to be polished?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt; &lt;a href=&quot;http://www.optenso.com/links/links.html#lds&quot; rel=&quot;nofollow&quot;&gt;Here is a helpful list of 37 different lens design &amp;amp; simulation programs&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="106" LastEditorUserId="350" LastEditDate="2012-11-30T14:03:33.200" LastActivityDate="2014-01-16T15:26:04.110" Title="Is it practical to 3D print a refractive lens?" Tags="&lt;3d-printing&gt;&lt;manufacturing&gt;" AnswerCount="3" CommentCount="4" FavoriteCount="3" />
  <row Id="521" PostTypeId="1" AcceptedAnswerId="522" CreationDate="2012-11-26T08:00:05.007" Score="10" ViewCount="1792" Body="&lt;p&gt;When computing the Jacobian matrix for solving an Inverse Kinematic analytically,I read from many places that I could use this formula to create each of the columns of a joint in the Jacobian matrix:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/EYHBM.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Such that $a'$ is the rotation axis in world space, $r'$ is the pivot point in world space, and $e_{pos}$ is the position of end effector in world space.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, I don't understand how this can work when the joints have more than one DOFs. Take the following as example:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/7mVwI.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The $\theta$ are the rotational DOF, the $e$ is the end effector, the $g$ is the goal of the end effector, the $P_1$, $P_2$ and $P_3$ are the joints.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;First, if I were to compute the Jacobian matrix based on the formula above for the diagram, I will get something like this:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$J=\begin{bmatrix}&#xA;((0,0,1)\times \vec { e } )_{ x } &amp;amp; ((0,0,1)\times (\vec { e } -\vec { P_{ 1 } } ))_{ x } &amp;amp; ((0,0,1)\times (\vec { e } -\vec { P_{ 2 } } ))_{ x } \\ ((0,0,1)\times \vec { e } )_{ y } &amp;amp; ((0,0,1)\times (\vec { e } -\vec { P_{ 1 } } ))_{ y } &amp;amp; ((0,0,1)\times (\vec { e } -\vec { P_{ 2 } } ))_{ y } \\ ((0,0,1)\times \vec { e } )_{ z } &amp;amp; ((0,0,1)\times (\vec { e } -\vec { P_{ 1 } } ))_{ z } &amp;amp; ((0,0,1)\times (\vec { e } -\vec { P_{ 2 } } ))_{ z } \\ 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 \\ 1 &amp;amp; 1 &amp;amp; 1 &#xA;\end{bmatrix} $$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is assumed that all the rotation axes are $(0,0,1)$ and all of them only have one rotational DOF. So, I believe each column is for one DOF, in this case, the $\theta_\#$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now, here's the problem: What if all the joints have full 6 DOFs? Say now, for every joint, I have rotational DOFs in all axes, $\theta_x$, $\theta_y$ and $\theta_z$, and also translational DOFs in all axes, $t_x$, $t_y$ and $t_z$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To make my question clearer, suppose if I were to &quot;forcefully&quot; apply the formula above to all the DOFs of all the joints, then I probably will get a Jacobian matrix like this:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://i.stack.imgur.com/f6Fm7.png&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/f6Fm7.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(click for full size)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But this is incredibly weird because all the 6 columns of the DOF for every joint is repeating the same thing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How can I use the same formula to build the Jacobian matrix with all the DOFs? How would the Jacobian matrix look like in this case?&lt;/p&gt;&#xA;" OwnerUserId="503" LastEditorUserId="350" LastEditDate="2013-04-08T15:33:10.183" LastActivityDate="2013-09-06T14:19:20.803" Title="Computing the Jacobian matrix for Inverse Kinematics" Tags="&lt;inverse-kinematics&gt;&lt;kinematics&gt;" AnswerCount="3" CommentCount="1" />
  <row Id="522" PostTypeId="2" ParentId="521" CreationDate="2012-11-26T10:54:22.753" Score="6" Body="&lt;p&gt;I have to admit that i haven't seen that specific formula very often, but my guess would be that in case of more than one DOF, you would evaluate it for every joint in every column and then (perhaps?) multiply those results in each column.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But let me suggest a simpler apporach to Jacobians in the context of arbitrary many DOFs: Basically, the Jacobian tells you, how far each joint moves, if you move the end effector frame in some arbitrarily chosen direction. Let $f(\theta)$ be the forward kinematics, where $\theta = [\theta_1, ... , \theta_n]$ are the joints, $f_{\text{pos}}$ is the positional part of the forward kinematics and $f_{\text{rot}}$ the rotational part. Then you can obtain the Jacobian by &lt;em&gt;differentiating the forward kinematics&lt;/em&gt; with respect to the joint variables:&#xA;$$&#xA;J = \frac{\partial f}{\partial \theta} = &#xA;\begin{bmatrix}&#xA;  \frac{\partial f_{\text{pos}}}{\partial \theta_1}, &amp;amp; \frac{\partial f_{\text{pos}}}{\partial \theta_2} &amp;amp; ..., \frac{\partial f_{\text{pos}}}{\partial \theta_n} \\&#xA;  \frac{\partial f_{\text{rot}}}{\partial \theta_1}, &amp;amp; \frac{\partial f_{\text{rot}}}{\partial \theta_2} &amp;amp; ..., \frac{\partial f_{\text{rot}}}{\partial \theta_n}&#xA;\end{bmatrix}&#xA;$$ &#xA;is your manipulator's Jacobian. Inverting it would give you the inverse kinematics with respcet to &lt;em&gt;velocities&lt;/em&gt;. It can still be useful though, if you want to know how far each joint has to move if you want to move your end effector by some &lt;em&gt;small&lt;/em&gt; amount $\Delta x$ in any direction (because on position level, this would effectively be a linearization):&#xA;$$&#xA; \Delta \theta = J^{-1}\Delta x&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Hope that this helps.&lt;/p&gt;&#xA;" OwnerUserId="422" LastActivityDate="2012-11-26T10:54:22.753" CommentCount="6" />
  <row Id="523" PostTypeId="2" ParentId="184" CreationDate="2012-11-26T18:01:22.773" Score="3" Body="&lt;h2&gt;Rate of progress of computational power&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Moore%27s_law&quot; rel=&quot;nofollow&quot;&gt;Moore's law&lt;/a&gt;: over the history of computing hardware, the density of transistors on an integrated circuit doubles approximately every two years.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How long will that take until we have human-equivalent processing power (HEPP) ?&#xA;As Martin pointed out, Ray Kurzweil and those who listen to him say things like:&#xA;&quot;By some estimates, we already have supercomputers that have the raw processing power&#xA;necessary to produce HEPP -- we just don't know how yet to program them to act intelligently.&quot;&#xA;&quot;By 2030, the hardware for a HEPP will cost one dollar.&quot; (&lt;a href=&quot;http://mol-eng.com/takeoff.pdf&quot; rel=&quot;nofollow&quot;&gt;a&lt;/a&gt; &lt;a href=&quot;http://books.google.com/books?id=aL2QThQPuxgC&amp;amp;pg=PA340&amp;amp;lpg=PA340&amp;amp;dq=HEPP%3a%20Human%20Equivalent%20Processing%20Power&amp;amp;source=bl&amp;amp;ots=lOlF3nUjVY&amp;amp;sig=GEUZuDAnhXGnvPQV6KbcvOkrzTY&amp;amp;hl=en&amp;amp;sa=X&amp;amp;ei=kYazULSOJ4y29gTit4GoAw&amp;amp;ved=0CEgQ6AEwAw#v=onepage&amp;amp;q=HEPP%3a%20Human%20Equivalent%20Processing%20Power&amp;amp;f=false&quot; rel=&quot;nofollow&quot;&gt;b&lt;/a&gt;)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Nielsen's Law: network connection speeds double approximately every 21 months.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Rate of progress of electrical energy storage density&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://blogs.wsj.com/drivers-seat/2012/03/28/who%E2%80%99ll-name-the-law-for-electric-car-batteries/&quot; rel=&quot;nofollow&quot;&gt;unnamed law&lt;/a&gt;: electric vehicle batteries double in miles/dollar every 10 years. (&lt;a href=&quot;http://www.eaa.org/experimenter/articles/2010-05_electric.asp&quot; rel=&quot;nofollow&quot;&gt;b&lt;/a&gt;)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The power consumed by a integrated circuit running at full speed remains roughly constant.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The power consumed by a integrated circuit to do any fixed amount of processing halves approximately every two years.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Other trends relevant to robotics&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Hendy's Law: digital camera pixels per dollar doubles approximately every 18 months.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Haitz's law: the light output of an LED doubles approximately every 36 months.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://johnnyryan.wordpress.com/2011/08/24/a-moore%E2%80%99s-law-for-3d-printing-i-need-data/&quot; rel=&quot;nofollow&quot;&gt;Johnny Ryan&lt;/a&gt; is gathering data that may lead to a similar law for 3d printing.&#xA;(Robots are sometimes built using such 3D printed parts,&#xA;and 3D printers themselves are technically a kind of &quot;robot&quot; under most definitions).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;[unnamed law]: the power-to-weight ratio of electric motors and their control electronics doubles every [FIXME] years.&#xA;(This trend is most obvious in electric aircraft). ( &lt;a href=&quot;http://www2.electronicproducts.com/High_power_MOSFET_packages_muscle_in_on_high_density_power_systems-article-MARIR1-mar1999-html.aspx&quot; rel=&quot;nofollow&quot;&gt;a&lt;/a&gt; &lt;a href=&quot;http://www.eaa.org/experimenter/articles/2010-05_electric.asp&quot; rel=&quot;nofollow&quot;&gt;b&lt;/a&gt; )&lt;/p&gt;&#xA;&#xA;&lt;p&gt;These trends in the low-level quantitative measures of what people build are surprisingly &quot;linear&quot; (in a log-linear graph) and therefore easy to predict.&#xA;However, historically people have made terrible predictions of exactly how much quantity of such low-level hardware was necessary to achieve some qualitative features in AI and other areas of robotics.&#xA;Usually people woefully underestimate what is needed to automate things we find &quot;easy&quot; like riding a bike or &lt;a href=&quot;http://en.wikipedia.org/wiki/Darpa_grand_challenge&quot; rel=&quot;nofollow&quot;&gt;driving a car&lt;/a&gt;.&#xA;Occasionally people find it disturbing how easy it is to automate some things ( &lt;a href=&quot;http://en.wikipedia.org/wiki/ELIZA_effect&quot; rel=&quot;nofollow&quot;&gt;ELIZA effect&lt;/a&gt; ).&lt;/p&gt;&#xA;" OwnerUserId="187" LastActivityDate="2012-11-26T18:01:22.773" />
  <row Id="524" PostTypeId="1" CreationDate="2012-11-26T18:43:59.667" Score="1" ViewCount="114" Body="&lt;p&gt;Am trying to find the right ESC for the following two motors&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.e-fliterc.com/Products/Default.aspx?ProdID=EFLM30180MDFA#quickFeatures&quot; rel=&quot;nofollow&quot;&gt;http://www.e-fliterc.com/Products/Default.aspx?ProdID=EFLM30180MDFA#quickFeatures&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.e-fliterc.com/Products/Default.aspx?ProdID=EFLM3032DFA&quot; rel=&quot;nofollow&quot;&gt;http://www.e-fliterc.com/Products/Default.aspx?ProdID=EFLM3032DFA&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can't figure out which of the ESC's listed on the site would be best? Are there alternative (cheaper or better?) options?&lt;/p&gt;&#xA;" OwnerUserId="459" LastActivityDate="2012-11-26T20:37:45.160" Title="Compatable ESC's with brushless 3 phase motors" Tags="&lt;motor&gt;&lt;brushless-motor&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="525" PostTypeId="2" ParentId="446" CreationDate="2012-11-26T19:18:32.430" Score="3" Body="&lt;p&gt;I was hoping that someone else would answer this question with some sort of formula or rule of thumb that would apply to a much wider range of materials / cutting speeds / etc.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;According to the RepRap website,&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&quot;It is recommended that you get approximately 13.7 N-cm (= 0.137 N-m or 1400 gf-cm or 19.4 ozf-in or 1.21 lbf-in) of holding torque (or more) for RepRap axis motors to avoid issues, although one stepper with less has been used successfully.&#xA;For Wade's Geared Extruder (most widely used one as of 2012) it is suggested to use motor that is capable of creating a holding torque of at least 40 N-cm.&quot;&#xA;-- &lt;a href=&quot;http://reprap.org/wiki/StepperMotor#Holding_Torque&quot; rel=&quot;nofollow&quot;&gt;http://reprap.org/wiki/StepperMotor#Holding_Torque&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Since your motors have 31.2oz-in of holding torque -- significantly stronger than that recommendation -- the motors you already have should work fine for the axis motors of a RepRap-like machine.&lt;/p&gt;&#xA;" OwnerUserId="187" LastActivityDate="2012-11-26T19:18:32.430" CommentCount="5" />
  <row Id="526" PostTypeId="2" ParentId="524" CreationDate="2012-11-26T20:37:45.160" Score="1" Body="&lt;p&gt;Looking at the second, I see 62 amps continuous, 75 max burst, you want a brushless speed controler that can handle that, assuming you plan on using the full power of the motor. So, from that vendor; &lt;a href=&quot;http://www.e-fliterc.com/Products/Default.aspx?ProdID=EFLA1080B&quot; rel=&quot;nofollow&quot;&gt;http://www.e-fliterc.com/Products/Default.aspx?ProdID=EFLA1080B&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It takes some looking, but the first motor is a replacement for a kit. That kit comes with a 5 amp speed controler/receiver combo - so you would need a 5 amp brushless speed control. &lt;a href=&quot;http://www.e-fliterc.com/Products/Default.aspx?ProdID=EFLA1005&quot; rel=&quot;nofollow&quot;&gt;http://www.e-fliterc.com/Products/Default.aspx?ProdID=EFLA1005&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;That is quite a difference between the 2, power wise. You need to think about physical size and power requirements. Then I'd recommend cheap chinese verson instead; &#xA;&lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/__517__59__Brushless_Motors-Outrunners_by_size.html&quot; rel=&quot;nofollow&quot;&gt;hobbyking&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Just remember, brushless motors need brushless speed controlers. other than that, match up potential amp draw to speed controller capability. Choose batteries based on intended length of runtime. The battery C rating indicated how much current it can deliver. A 1000mah battery rated at 20C can deliver 20 amps.&lt;/p&gt;&#xA;" OwnerUserId="274" LastActivityDate="2012-11-26T20:37:45.160" />
  <row Id="527" PostTypeId="2" ParentId="184" CreationDate="2012-11-26T20:52:28.617" Score="1" Body="&lt;p&gt;This isn't a published study, but many people use the &lt;a href=&quot;http://en.wikipedia.org/wiki/Technology_readiness_level&quot; rel=&quot;nofollow&quot;&gt;Technology Readiness Level (TRL)&lt;/a&gt; system to assess the state of technologies. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Granted, it doesn't really tell you &lt;em&gt;when&lt;/em&gt; a technology might reach a particular stage, but it can be useful in establishing a common framework for this sort of question. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;It also can be useful for prioritizing and comparing different subsystems. For example, in a robotic system, if you deem that the actuators are at TRL 6 but your power storage technology is only at TRL 1, you can see what is holding the whole system back and put more effort ($) there.&lt;/p&gt;&#xA;" OwnerUserId="479" LastEditorUserId="479" LastEditDate="2012-11-26T21:14:26.653" LastActivityDate="2012-11-26T21:14:26.653" />
  <row Id="529" PostTypeId="2" ParentId="519" CreationDate="2012-11-26T21:33:52.903" Score="1" Body="&lt;p&gt;If you are only updating the covariance sub-matrix associated with the robot and landmark (as is typical), then K and P should be $(N_r + N_l)\times(N_r + N_l)$ for robot state size $N_r$ and landmark size $N_l$. Note that you have: &lt;/p&gt;&#xA;&#xA;&lt;p&gt;K = P(:, rl) * E_rl' * Z^-1&lt;/p&gt;&#xA;&#xA;&lt;p&gt;which I think should be (P(rl,rl) * E_rl') * inv( Z ).&lt;br&gt;&#xA;(but see: &lt;a href=&quot;http://www.mathworks.com/help/matlab/ref/mrdivide.html&quot; rel=&quot;nofollow&quot;&gt;matrix division&lt;/a&gt;).&#xA;Check the size of K.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also: &#xA;Please provide a little more information: Does K go singular immediately or only after some time? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;This worries me: &quot;project(x(r), x(lmk));&quot; since lmk is not defined. &lt;/p&gt;&#xA;" OwnerUserId="163" LastActivityDate="2012-11-26T21:33:52.903" />
  <row Id="530" PostTypeId="1" AcceptedAnswerId="540" CreationDate="2012-11-26T22:14:31.157" Score="0" ViewCount="305" Body="&lt;p&gt;OK, not really robotics, but has anyone been able to upload to a Rainboduino v3.0 using the Arduino IDE? I can't seem to figure it out, and there is virutally no documentation online. I followed &lt;a href=&quot;http://www.anyware.co.uk/2005/2012/01/17/getting-started-with-arduino-rainbowduino/&quot; rel=&quot;nofollow&quot;&gt;this blog entry&lt;/a&gt;, but got no connection to the board. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If anyone can give me some suggestions, I would appreciate it! &lt;/p&gt;&#xA;" OwnerUserId="506" LastEditorUserId="457" LastEditDate="2012-11-28T17:56:49.817" LastActivityDate="2012-11-28T17:56:49.817" Title="Rainbowduino 3.0 - Arduino IDE fails to upload" Tags="&lt;software&gt;&lt;arduino&gt;&lt;programming-languages&gt;" AnswerCount="1" CommentCount="2" />
  <row Id="531" PostTypeId="1" AcceptedAnswerId="548" CreationDate="2012-11-26T23:32:35.390" Score="2" ViewCount="124" Body="&lt;p&gt;What's needed to utilize an IMU such as the &lt;a href=&quot;http://store.diydrones.com/ArduIMU_V3_p/kt-arduimu-30.htm&quot; rel=&quot;nofollow&quot;&gt;ArduIMU+ V3&lt;/a&gt; to be used in an INS. Is there any other hardware needed? &lt;/p&gt;&#xA;" OwnerUserId="374" LastEditorUserId="374" LastEditDate="2012-11-27T03:27:07.683" LastActivityDate="2012-11-27T22:31:19.757" Title="Using an IMU to build an INS" Tags="&lt;arduino&gt;&lt;slam&gt;&lt;imu&gt;&lt;deduced-reckoning&gt;" AnswerCount="1" CommentCount="1" FavoriteCount="1" />
  <row Id="533" PostTypeId="1" AcceptedAnswerId="534" CreationDate="2012-11-27T03:34:04.287" Score="9" ViewCount="248" Body="&lt;p&gt;I'm a highschool student studying electronics and for an assessment task on the history of electronics I have decided to focus on the history of robotics. I want to begin with the earliest possible concept of a robot and progress through major developments in robotics to the current day. Where should I begin my research?&lt;/p&gt;&#xA;" OwnerUserId="374" LastEditorUserId="350" LastEditDate="2013-01-03T13:27:56.017" LastActivityDate="2013-01-03T17:00:30.720" Title="What was the earliest concept of a robot?" Tags="&lt;electronics&gt;&lt;research&gt;" AnswerCount="9" CommentCount="1" />
  <row Id="534" PostTypeId="2" ParentId="533" CreationDate="2012-11-27T04:05:41.467" Score="6" Body="&lt;p&gt;If I recall correctly Leonardo da Vinci is credited with the earliest design of a robot. My personal favorite is generally referred to as &lt;a href=&quot;http://en.wikipedia.org/wiki/Leonardo%27s_robot&quot;&gt;Leonardo's robot&lt;/a&gt;. However some accounts place &lt;a href=&quot;http://www.youtube.com/watch?v=a2qeZrejZp0&quot;&gt;Leonardo's cart&lt;/a&gt; as having come first and is generally considered a robot because it could be &quot;reprogrammed&quot; by replacing its cogs.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2012-11-27T04:05:41.467" />
  <row Id="535" PostTypeId="1" AcceptedAnswerId="536" CreationDate="2012-11-27T04:51:39.177" Score="3" ViewCount="921" Body="&lt;p&gt;What can an Arduino board such as the Uno really do? Of course simple things like controlling a couple servos is very easy for it. However, I don't think an Uno board would be able to preform real-time 3D SLAM from point cloud data gathered from a Kinect sensor on a mobile robot, right? If the robot had any speed at all the Arduino wouldn't be able to keep up, correct? Could it do 2D SLAM while moving and be able to keep up? What about taking 1/10 of the points from the Kinect sensor and processing only those?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Basically, what are some examples of the resource limitations of such an Arduino board?&lt;/p&gt;&#xA;" OwnerUserId="457" LastEditorUserId="350" LastEditDate="2012-11-27T20:12:46.613" LastActivityDate="2012-11-28T06:53:34.403" Title="How computationally powerful is an Arduino Uno board?" Tags="&lt;arduino&gt;&lt;slam&gt;&lt;kinect&gt;" AnswerCount="5" />
  <row Id="536" PostTypeId="2" ParentId="535" CreationDate="2012-11-27T05:06:01.763" Score="6" Body="&lt;p&gt;It depends - on the number of landmarks in the feature map, and how much time you're willing to invest tuning the algorithm for speed, and a number other parameters which you may or may not be able to control for a given application.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Edit:&lt;/strong&gt; As a &lt;em&gt;thought experiment&lt;/em&gt;, I think it would &lt;em&gt;theoretically&lt;/em&gt; be powerful enough to do extremely simple near-real-time SLAM in a very contrived environment, such as the center of a gym floor with a few cones set out.  It could take a single scan line from the Kinect and update a low-resolution, 2D internal map, updating periodically (say every 10 seconds).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The Uno's 2K RAM would probably be a deal breaker, but the Mega might have enough (8K) and there is &lt;a href=&quot;http://hackaday.com/2011/09/05/upgrading-ram-in-an-arduino-mega/&quot;&gt;hack&lt;/a&gt; for upgrading it to 520K.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In practice, doing floating point matrix calculations on an 8-bit processor is not a good idea.&lt;/p&gt;&#xA;" OwnerUserId="493" LastEditorUserId="493" LastEditDate="2012-11-27T06:15:56.363" LastActivityDate="2012-11-27T06:15:56.363" CommentCount="1" />
  <row Id="537" PostTypeId="2" ParentId="533" CreationDate="2012-11-27T15:10:48.330" Score="5" Body="&lt;p&gt;If you are interested in real and fictional robots (for concepts), the &lt;a href=&quot;http://www.robothalloffame.org/inductees.html&quot;&gt;CMU Robot Hall of Fame&lt;/a&gt; may be useful.&lt;/p&gt;&#xA;" OwnerUserId="479" LastActivityDate="2012-11-27T15:10:48.330" />
  <row Id="538" PostTypeId="2" ParentId="535" CreationDate="2012-11-27T16:09:32.020" Score="2" Body="&lt;p&gt;The &lt;a href=&quot;http://avrprogrammers.com/doc-atmega8-atmega328.php&quot; rel=&quot;nofollow&quot;&gt;raw specs on the Arduino's microcontrollers&lt;/a&gt; list clock speeds as high as 16 or 20 MHz -- around the speed of an mid-1990s Intel 386 computer.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;That sounds promising, until you consider the fact that it doesn't natively support floating point math -- the &quot;&lt;a href=&quot;http://en.wikipedia.org/wiki/FLOPS&quot; rel=&quot;nofollow&quot;&gt;FLOPS&lt;/a&gt;&quot; measurement by which most CPUs are compared.  I've seen some arduino demos that calculate the speed of the Arduino at about 60 kFLOPS, whereas the Intel 386 at 20 MHz does something like 170 kFLOPS (according to &lt;a href=&quot;http://www.obsolyte.com/sunFAQ/faq_hardware/hwref1.html&quot; rel=&quot;nofollow&quot;&gt;this page&lt;/a&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, it should be noted that the Arduino does 8-bit math and the 386 is doing 16-bit and 32-bit math.  A DSP board might be more suited to that kind of data acquisition, but I'm in no position to advise there.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Getting that code to work in such a constrained environment as the Arduino might be possible, but it will take a lot of optimization.  You'd be better served by using a more powerful CPU to implement those algorithms; make sure that they work on the powerful CPU, &lt;em&gt;then&lt;/em&gt; attempt to optimize for the weak CPU.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2012-11-27T16:09:32.020" CommentCount="1" />
  <row Id="539" PostTypeId="2" ParentId="215" CreationDate="2012-11-27T16:30:25.537" Score="2" Body="&lt;p&gt;It sounds like your enthusiasm is in the right place, but I think you're trying to make intelligent design decisions without knowing what you're designing.  This is good!  These are all things to be worried about when designing a robot, whether as big as your shoe or as big as your car.  But they aren't what you should be worried about right now.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In your situation, I'd choose a robotics kit that's based on an Arduino.  That will give you a good starting place in terms of seeing how other people solve the problems of materials, motors, etc.  The Arduino has a huge user base and is pretty simple to program and re-program.  You can always add your own hardware and software to a kit, to make it do the things you want -- keep pushing the envelope.  Also, get some electronic kits (non-robotic kits are perfectly fine); they will teach you a bit about electronics and circuits that would be less fun to learn from a book.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Make as many mistakes as you can&lt;/strong&gt;.   There are no right answers or silver bullets when it comes to building robots... It's an iterative process that comes with bursts of inspiration.  If you run out of I/O ports on the Arduino, start looking for another microcontroller board that has more of them.  If you find you need more user interaction (LCD, buttons, etc), get a board that supports that.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Just don't try to solve all the problems before you take your first step.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2012-11-27T16:30:25.537" />
  <row Id="540" PostTypeId="2" ParentId="530" CreationDate="2012-11-27T16:42:34.940" Score="1" Body="&lt;p&gt;It looks like the Rainbowduino 3.0 uses an ATmega328, so first be sure to choose a board that's using that.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If that doesn't solve the problem, try looking at this &lt;a href=&quot;http://www.seeedstudio.com/wiki/Rainbowduino_v3.0&quot; rel=&quot;nofollow&quot;&gt;wiki article about the Rainboduino v3.0&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="457" LastActivityDate="2012-11-27T16:42:34.940" CommentCount="1" />
  <row Id="541" PostTypeId="1" AcceptedAnswerId="542" CreationDate="2012-11-27T17:10:01.437" Score="9" ViewCount="2577" Body="&lt;p&gt;I'm building a small robot using some cheap Vex Robotics tank treads. However, my choice of picking tank treads is almost purely based on the fact that they seem like more fun than wheels. I don't actually know if they really have much of an advantage or disadvantage when compared to wheels.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What are the pros and cons of both wheels and continuous tracks?&lt;/p&gt;&#xA;" OwnerUserId="457" LastEditorUserId="350" LastEditDate="2012-11-30T14:29:36.073" LastActivityDate="2013-01-25T19:40:42.750" Title="Wheels vs Continuous Tracks (Tank Treads)" Tags="&lt;mobile-robot&gt;&lt;design&gt;&lt;wheeled-robot&gt;&lt;tracks&gt;" AnswerCount="2" CommentCount="2" FavoriteCount="2" />
  <row Id="542" PostTypeId="2" ParentId="541" CreationDate="2012-11-27T17:25:36.367" Score="13" Body="&lt;p&gt;Well, you generally use wheels when:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;You want speed&lt;/strong&gt;. Treads need a lot more torque to power, thus you generally use low-rpm/high torque motors.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;You want maneuverability:&lt;/strong&gt; Treads are a big pain to turn with. Differential steering is very ineffective (the bot skids to steer, which may not work if you have really grippy treads)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;But, treads are better when:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;You want to move on uneven terrain&lt;/strong&gt;: Wheels get stuck in potholes/bumps, treads don't.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;You want traction&lt;/strong&gt;: Treads in general are way grippier than wheels--climbing an incline is easier and you have less skids.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;You don't want the bot to be affected by pushing/gravity&lt;/strong&gt;: A wheeled bot is easily pushed around (and, as mentioned, can skid on inclines). Bots with treads are hard to push and they don't skid.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="126" LastActivityDate="2012-11-27T17:25:36.367" />
  <row Id="543" PostTypeId="1" AcceptedAnswerId="544" CreationDate="2012-11-27T18:01:18.020" Score="12" ViewCount="1539" Body="&lt;p&gt;I've noticed that almost all research being done with helicopter robots is done using quadcopters (four propellers). Why is there so little work done using tricopters in comparison? Or a different number of propellers? What about four propellers has made quadcopters the most popular choice?&lt;/p&gt;&#xA;" OwnerUserId="457" LastEditorUserId="2447" LastEditDate="2014-01-08T22:40:26.917" LastActivityDate="2014-01-08T22:40:26.917" Title="Why are quadcopters more common in robotics than other configurations?" Tags="&lt;quadrotor&gt;&lt;design&gt;&lt;uav&gt;" AnswerCount="4" CommentCount="1" FavoriteCount="1" />
  <row Id="544" PostTypeId="2" ParentId="543" CreationDate="2012-11-27T18:37:17.103" Score="16" Body="&lt;p&gt;At least in part quadrotors offer a nice balance between the complexity of the dynamics and power requirements. With traditional single rotor helicopters, control is a function of the orientation of the rotor which means you must change its orientation to change direction of the craft. This makes for very complex mechanical linkages comparatively speaking and it complicates the dynamics. With tri-copters the dynamics include an imbalance of the moments induced by the spinning of the rotors. With more than four rotors you get improved stability and some ability to handle failure, such as a motor going out, but you quickly run into a power problem. The more motors you need to drive the higher your power requirements and quadrotors are already very power hungry. This is a major issue in robotics in general. The quadrotor dynamics naturally balance the moments from the rotors and the mechanical linkages are simpler.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2012-11-27T18:37:17.103" CommentCount="3" />
  <row Id="545" PostTypeId="2" ParentId="543" CreationDate="2012-11-27T18:38:22.987" Score="4" Body="&lt;p&gt;I think the main reason is that they're simply easier to build in a stable way. A 120º angle is harder to get right than a 90º angle.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another thing that is a little easier to understand is how the relationship between propellers leads to different types of motion. Thinking about different propellers moving at different speeds and directions and how that affects robot motion is sort of intuitive, because you don't have to do a lot of trigonometry in your head.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Lastly, it's just a good compromise between stability/controllability and cost, since motors are usually one of the most expensive components for that kind of robot.&lt;/p&gt;&#xA;" OwnerUserId="95" LastActivityDate="2012-11-27T18:38:22.987" />
  <row Id="546" PostTypeId="2" ParentId="535" CreationDate="2012-11-27T19:21:38.883" Score="1" Body="&lt;p&gt;It's true that the Arduino is started to look underpowered now that people are by Raspberry Pis, but I think it depends more on the application. I like the arduino because the code is really easy to write, it's really easy to flash new code, and really easy to hook up new sensors. I wouldn't use it for a vision application like kinect or webcam stuff, but it can do a whole lot more than talking to servos. A good example would be a segway type application; the arduino is ideal for talking to accelerometer sensors, doing some 3D spatial math, and then talking to servos to keep things balanced.&lt;/p&gt;&#xA;" OwnerUserId="10" LastActivityDate="2012-11-27T19:21:38.883" CommentCount="1" />
  <row Id="547" PostTypeId="2" ParentId="533" CreationDate="2012-11-27T19:47:45.430" Score="10" Body="&lt;p&gt;I've found the &lt;a href=&quot;http://en.wikipedia.org/wiki/History_of_robots&quot;&gt;wikipedia article&lt;/a&gt; (as well as its linked articles) on the history of robots to be enlightening:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The &lt;strong&gt;history of &lt;a href=&quot;http://en.wikipedia.org/wiki/Robot&quot;&gt;robots&lt;/a&gt;&lt;/strong&gt; has its roots as far back as ancient myths and legends. Modern concepts were begun to be developed when the Industrial Revolution allowed the use of more complex mechanics and the subsequent introduction of electricity made it possible to power machines with small compact motors. After the 1920s the modern formulation of a humanoid machine was developed to the stage where it was possible to envisage human sized robots with the capacity for near human thoughts and movements, first envisaged millennia before.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Also, you might mention &lt;a href=&quot;http://en.wikipedia.org/wiki/R.U.R.&quot;&gt;R.U.R.&lt;/a&gt;, a play in the 1920s that popularized the term &lt;em&gt;robot&lt;/em&gt;:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;&lt;strong&gt;R.U.R.&lt;/strong&gt; is a 1920 science fiction play in the Czech language by &lt;a href=&quot;http://en.wikipedia.org/wiki/Karel_%C4%8Capek&quot;&gt;Karel Čapek&lt;/a&gt;. R.U.R. stands for Rossum's Universal Robots, an English phrase used as the subtitle in the Czech original.&lt;a href=&quot;http://en.wikipedia.org/wiki/History_of_robots&quot;&gt;1&lt;/a&gt; It premiered in 1921 and introduced the word &quot;robot&quot; to the English language and to science fiction as a whole.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="181" LastEditorUserId="37" LastEditDate="2012-11-30T17:04:22.933" LastActivityDate="2012-11-30T17:04:22.933" CommentCount="2" />
  <row Id="548" PostTypeId="2" ParentId="531" CreationDate="2012-11-27T22:31:19.757" Score="1" Body="&lt;p&gt;It contains all the necessary components to function as a rudimentary IMU.&#xA;If you read through the comments &lt;a href=&quot;http://code.google.com/p/ardu-imu/wiki/WhatNeed&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;, you'll see that either a GPS or magnometer will be required for error correction. All IMUs will suffer from drift without some calibration, especially one this cheap! I don't see a clear answer on whether this can operate without one, but I imagine it could, albeit with a large margin of error.&lt;/p&gt;&#xA;" OwnerUserId="366" LastActivityDate="2012-11-27T22:31:19.757" CommentCount="3" />
  <row Id="549" PostTypeId="2" ParentId="543" CreationDate="2012-11-27T23:00:07.663" Score="7" Body="&lt;p&gt;You need 4 degrees of freedom to control yaw, pitch, roll and thrust.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Four props is therefore the minimum number of actuators required.  Tricoptors require a servo to tilt one or more rotors which is more mechanically complicated.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is no restriction to only 4 props, hexa+ coptors are also very common.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Generally you want an even number of props unless you are tilting so the yaw forces balance out.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Choosing the exact number of propellers used involves many complicated tradeoffs.  A single prop cannot be too large or the inertia makes the multicopter unstable (which is why you see more props instead of larger props for large multirotors).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Large propellers are far, far, more efficient than many small propellers which is why there is essentially a size cap on multicoptors (unless you go variable/collective pitch which would be stupid).&lt;/p&gt;&#xA;" OwnerUserId="65" LastEditorUserId="65" LastEditDate="2012-11-27T23:09:49.420" LastActivityDate="2012-11-27T23:09:49.420" CommentCount="3" />
  <row Id="550" PostTypeId="1" CreationDate="2012-11-27T23:04:05.027" Score="12" ViewCount="479" Body="&lt;p&gt;Lets say I drop a robot into a featureless environment and any magnetic field based sensors (magnetometer/compass) are not allowed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What methods are there of determining where north is?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Tracking the sun/stars is an option but not reliable enough when the weather is considered.&#xA;Can you pick up the rotation of the earth using gyros?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Are there any more clever solutions?&lt;/p&gt;&#xA;" OwnerUserId="65" LastActivityDate="2013-01-25T16:35:13.470" Title="How To Determine Heading Without Compass" Tags="&lt;localization&gt;" AnswerCount="2" FavoriteCount="1" />
  <row Id="551" PostTypeId="2" ParentId="446" CreationDate="2012-11-27T23:24:11.500" Score="2" Body="&lt;p&gt;Formulas do exist but when DIYing something like this there will be too much uncertainty in the required variables.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here is an extremely basic way of going through the calculations:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You need to start with the required force delivered to the table at given speeds.  Generally this will be the cutting force + way friction.  Cutting speed/feed and force can be looked up from tables for given material/cutter combinations.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For high performance mills acceleration is a greater constraint than cutting force and should be used instead.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Way friction depends on what you are using for linear motion.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Once you know how much force you need to apply to the table at a given speed its pretty straightforward to figure out what motor you need.  Put the numbers through screw reduction/efficiency and pick a motor/reduction combination based on the torque/speed charts.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Don't forget to use a 2-6x safety margin.&#xA;Holding torque is not usable torque and should be approximately halved if operating torque is not given.&lt;/p&gt;&#xA;" OwnerUserId="65" LastActivityDate="2012-11-27T23:24:11.500" />
  <row Id="552" PostTypeId="2" ParentId="535" CreationDate="2012-11-27T23:36:19.857" Score="5" Body="&lt;p&gt;The Arduino has always been horifically underpowered.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can get a &lt;em&gt;stack&lt;/em&gt; of stm discovery or other ARM based dev board for the price of a single arduino, and each one of those boards will be orders of magnitude more powerful than the arduino.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The ubiquity of the arduino has also hampered many projects that should have known better.  Quadrotor stabilization and Reprap style g-code execution are two major areas where the arduino has been forced well beyond its capabilities and it shows. (The ardrupilot project needs &lt;em&gt;three&lt;/em&gt; arduinos.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Hopefully the teensy/due/leaflabs stuff will help make ARM development more friendly.  Many of the newer/better projects such as smoothie, openpilot etc have also made the jump.&lt;/p&gt;&#xA;" OwnerUserId="65" LastActivityDate="2012-11-27T23:36:19.857" CommentCount="1" />
  <row Id="553" PostTypeId="2" ParentId="550" CreationDate="2012-11-28T00:29:31.470" Score="20" Body="&lt;p&gt;Wilderness survival might be a better place to look for &quot;finding north without a compass&quot; than in robotics, but here are some electronic adaptations of those techniques that might actually work on a robot.&lt;/p&gt;&#xA;&#xA;&lt;h1&gt;Finding North&lt;/h1&gt;&#xA;&#xA;&lt;h2&gt;GPS method&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Of course, your first choice would be to use a GPS -- the line between each pair of fixes will give you your direction of travel (but it won't work while you're standing still).  If you want something that works while you're standing still (and your vehicle is large enough), you could just use 2 GPS units spaced as far apart on the chassis as possible and measure the angle between them.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/rKr0w.jpg&quot; alt=&quot;Bearing between 2 points])&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(Full question here: &lt;a href=&quot;http://stackoverflow.com/questions/8123049/calculate-bearing-between-two-locations-lat-long&quot;&gt;http://stackoverflow.com/questions/8123049/calculate-bearing-between-two-locations-lat-long&lt;/a&gt;)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is by far the easiest and best way, but to make things really interesting, here are some other possible-yet-impractical approaches.  &lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Shadow-stick method&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/GnFX7.png&quot; alt=&quot;Using a stick to cast a shadow and determine north&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Have the robot use its camera to watch its shadow for 10 or 15 minutes, and note the movement of the shadow.  Making a robot able to recognize its own silhouette is a problem in itself, but this is certainly an interesting thing to do with computer vision!&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Analog Watch Method&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/IObpU.jpg&quot; alt=&quot;Using an analog watch&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you can point a camera at an analog watch, you can take advantage of the fact that the hour hand makes two revolutions in 24 hours (while the sun only makes one).  If you just make an analog clock of your own that rotates once every 24 hours, you can just point the 0:00 mark at the sun and the arm will point north.  It won't work at night.&lt;/p&gt;&#xA;&#xA;&lt;h1&gt;Keeping North&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;Once you find north using the sun, you'll have to keep a good estimate of where it is while moving -- weather and time of day would prevent you from measuring it continuously.  There are a few ways to do this:&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;GPS&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Again, the best possible option.  A pair of GPSes would be even better.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;INS&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Inertial Navigation Systems can give you a decent approximation of angular position by doubly integrating the (measured) angular acceleration.  You'll inevitably accumulate errors over time, but you can mitigate those errors by buying progressively more expensive INS units (seriously, they can cost into the tens of thousands of dollars).  Assuming you know the initial heading, the INS can track it from there.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Visual SLAM&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;You could use visual landmarks to keep a sense of which way is north.  Since you said it was a featureless environment, that's probably not going to work.  On the other hand, I don't know of any places in the great outdoors on earth that would count as &quot;featureless&quot;.  Here is one possible resource for that: &lt;a href=&quot;http://www.cvlibs.net/publications/icra11.pdf&quot;&gt;http://www.cvlibs.net/publications/icra11.pdf&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Triangulation&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;You could also drop your own markers, and use surveying techniques to keep your bearings.&lt;br&gt;&#xA;&lt;img src=&quot;http://i.stack.imgur.com/gCW5O.gif&quot; alt=&quot;Example triangulation techniques&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-01-25T16:35:13.470" LastActivityDate="2013-01-25T16:35:13.470" />
  <row Id="554" PostTypeId="1" AcceptedAnswerId="562" CreationDate="2012-11-28T03:38:24.880" Score="16" ViewCount="8502" Body="&lt;p&gt;I'm trying to find where additional battery capacity becomes worthless in relation to the added weight in terms of a quadcopter. Currently with a 5500 mAh battery, 11.1V, I can get between 12 minutes and 12:30 flight time out of it. My question, then, is this - within the quads lifting capability of course, is there any way to find out where the added weight of a larger battery (or more batteries) cancels out any flight time improvement? Obviously it's not going to be as long as two separate flights, landing and swapping batteries; I'm just trying to maximize my continuous 'in air' time. I'm trying to figure out where the line is (and if I've already crossed it) with tacking bigger batteries onto the quad and seeing diminishing returns. Thanks!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(Again, for now presume that the quad is strong enough to lift whatever you throw at it. With one 5500mAh, ~ 470 grams, my max throttle is about 70%)&lt;/p&gt;&#xA;" OwnerUserId="176" LastActivityDate="2013-12-04T21:29:19.183" Title="Quadcopter liPo battery weight/capacity trade off" Tags="&lt;batteries&gt;&lt;quadcopter&gt;&lt;power&gt;" AnswerCount="3" FavoriteCount="11" />
  <row Id="555" PostTypeId="2" ParentId="541" CreationDate="2012-11-28T04:14:04.227" Score="16" Body="&lt;p&gt;The best option will depend on the type of terrain you expect to cover.  You want the correct balance of several factors: &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ground pressure&lt;/li&gt;&#xA;&lt;li&gt;traction&lt;/li&gt;&#xA;&lt;li&gt;suspension&lt;/li&gt;&#xA;&lt;li&gt;steering&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Ground pressure&lt;/strong&gt; from tracks is less than ground pressure than wheels, so they're more suited to soft surfaces.  Larger tires can help, but there are limits -- they may not work in something like snow (which is why snowmobiles use tracks).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://i.stack.imgur.com/eo1gA.jpg&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/eo1gAm.jpg&quot; alt=&quot;snowmobile rescuing a stuck 4-wheeler&quot;&gt;&lt;/a&gt; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;(0.75 psi snowmobile tows a 40 psi ATV)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Traction&lt;/strong&gt; from tracks is generally better than wheels, but still depends on the depth and firmness of the tread being adequately matched to the terrain for best results.&lt;br&gt;&#xA;&lt;img src=&quot;http://i.stack.imgur.com/pA0iPm.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(Much like a gear, a tire or track engages with the ground underneath it.  Tracks simply put more &quot;teeth&quot; into the ground.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Suspension&lt;/strong&gt; is related to traction; without the ability to conform the tracks or wheels to the terrain, the traction doesn't come into play, and your motors will just spin ineffectively.&lt;br&gt;&#xA;&lt;a href=&quot;http://i.stack.imgur.com/gIVUY.jpg&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/gIVUYm.jpg&quot; alt=&quot;articulated suspension&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Building good suspension is much more complicated for a tracked vehicle than for a wheeled vehicle, but by no means impossible --&#xA;as shown in this iRobot video: &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.youtube.com/watch?v=KWB3hkjpvKo&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/we5Lfm.png&quot; alt=&quot;suspension&quot;&gt;&lt;/a&gt;.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;But, compare the climbing ability of tracked vehicles to the &lt;a href=&quot;https://www.youtube.com/watch?v=V3hqQ5rv_CI&quot;&gt;rocker-bogie system used by the mars rovers&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://i.stack.imgur.com/14dky.jpg&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/14dkym.jpg&quot; alt=&quot;mars rover rocker bogie&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Steering&lt;/strong&gt; is necessary for maneuverability, and this is where wheels can have a significant advantage.  For skid steering, good traction works against you... and in uneven terrain, you might find yourself blocked from lateral movement.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://i.stack.imgur.com/QgIUt.jpg&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/QgIUtm.jpg&quot; alt=&quot;Steering difficulty&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are some hybrid approaches -- 4 tracks, non-skid steering -- that approach a &quot;best of both worlds&quot; design: &lt;a href=&quot;http://www.youtube.com/watch?v=bPVicyrU_bQ&quot;&gt;Mattracks&lt;/a&gt; and &lt;a href=&quot;http://www.youtube.com/user/Hagglunds1&quot;&gt;hagglunds&lt;/a&gt;, for example.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://i.stack.imgur.com/A2cEr.jpg&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/A2cErm.jpg&quot; alt=&quot;Mattracks&quot;&gt;&lt;/a&gt; &lt;a href=&quot;http://i.stack.imgur.com/fCnXy.jpg&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/fCnXym.jpg&quot; alt=&quot;Hagglunds&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One &lt;strong&gt;very important&lt;/strong&gt; balance to to all of these factors is maintainability.  The complexity of tracks means that there are a lot of ways to break them; you're adding a lot of moving parts that will wear out independently, or be prone to dirt and debris causing trouble.  Troubleshooting tracks will be more difficult than wheels, and tracks will be more difficult to service.  So from a durability standpoint, if you can get away with wheels then use wheels. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://i.stack.imgur.com/Y9Lhy.jpg&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/Y9Lhym.jpg&quot; alt=&quot;tread fixing&quot;&gt;&lt;/a&gt;&#xA;&lt;a href=&quot;http://i.stack.imgur.com/TbQGC.jpg&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/TbQGCm.jpg&quot; alt=&quot;tread fixing&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-01-25T19:40:42.750" LastActivityDate="2013-01-25T19:40:42.750" />
  <row Id="556" PostTypeId="1" AcceptedAnswerId="576" CreationDate="2012-11-28T05:02:11.690" Score="3" ViewCount="241" Body="&lt;p&gt;Do I need a complex system (of gyros, accelerometers etc.) to detect if a robot has moved forward or can I simply use an accelerometer. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm building a robot that learns to walk and I need to detect displacement for machine learning. Can I use an accelerometer or will I need a complicated/expensive Internal Navigation System?&lt;/p&gt;&#xA;" OwnerUserId="374" LastEditorUserId="350" LastEditDate="2012-11-28T14:59:53.763" LastActivityDate="2012-11-30T17:04:30.217" Title="Is an accelerometer sufficient to detect displacement, or do I need an INS?" Tags="&lt;slam&gt;&lt;machine-learning&gt;&lt;deduced-reckoning&gt;&lt;gyroscope&gt;&lt;accelerometer&gt;" AnswerCount="3" />
  <row Id="557" PostTypeId="2" ParentId="535" CreationDate="2012-11-28T06:53:34.403" Score="2" Body="&lt;p&gt;For the price of an Arduino Uno, or less, a recent alternative is the &lt;a href=&quot;http://www.ti.com/ww/en/launchpad/stellaris_head.html?DCMP=stellaris-launchpad&amp;amp;HQS=stellaris-launchpad-b&quot; rel=&quot;nofollow&quot;&gt;TI Stellaris Launchpad&lt;/a&gt; at $12.99 (including world-wide FedEx): Arm Cortex M4 with an excellent built-in library set called StellarisWare that resides on ROM - so your Flash and RAM remain free for application use.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Massively higher computational power than the Arduino Uno, but so far without the ubiquitous community participation that Arduino has garnered.&lt;/p&gt;&#xA;" OwnerUserId="109" LastActivityDate="2012-11-28T06:53:34.403" />
  <row Id="558" PostTypeId="1" CreationDate="2012-11-28T13:46:12.110" Score="11" ViewCount="706" Body="&lt;p&gt;Typically Mars rovers use wheels and not tracks. I guess &lt;a href=&quot;http://en.wikipedia.org/wiki/Spirit_rover&quot;&gt;Spirit&lt;/a&gt; would have better chances getting out of that soft soil should it have tracks. In general, Mars surface structure is not known in advance, so it seems wiser to be prepaired for difficult terrain and so use tracks.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Why do Mars rovers typically use wheels and not tracks?&lt;/p&gt;&#xA;" OwnerUserId="516" LastEditorUserId="350" LastEditDate="2012-11-28T15:00:02.390" LastActivityDate="2012-11-29T10:27:22.223" Title="Why do Mars rovers designers prefer wheels over tracks?" Tags="&lt;mobile-robot&gt;&lt;design&gt;" AnswerCount="3" CommentCount="2" FavoriteCount="2" />
  <row Id="559" PostTypeId="2" ParentId="558" CreationDate="2012-11-28T13:59:21.113" Score="9" Body="&lt;p&gt;There are multiple reasons wheels may be prefered over treads. The main ones that apply to the mars rovers I would put as:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Mass is a critical property, especially for space exploration missions. Treads are generally heavier than wheels.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Treaded vehicles only support skid steering and are thus less precise to manouver. They also take more power when turning.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;For space exploration simplicity is key. A wheel has less moving parts that can get damaged. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Material properties also have to be taken into account to fit the environmental conditions. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="127" LastEditorUserId="127" LastEditDate="2012-11-29T10:27:22.223" LastActivityDate="2012-11-29T10:27:22.223" />
  <row Id="560" PostTypeId="2" ParentId="558" CreationDate="2012-11-28T14:04:08.380" Score="9" Body="&lt;p&gt;I think the surface of mars was &lt;a href=&quot;http://www.space.com/12404-mars-explored-landers-rovers-1971.html&quot;&gt;pretty well known&lt;/a&gt; by the time Spirit / Op landed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The &lt;a href=&quot;http://en.wikipedia.org/wiki/Rocker-bogie&quot;&gt;rocker-bogie&lt;/a&gt; system allows the robot to climb over obstacles up to twice the diameter of the wheels, while avoiding springs completely. Springs could cause the chassis to tilt on uneven terrain. Watch this video: &lt;a href=&quot;https://www.youtube.com/watch?v=ON1zLBvYKRI&quot;&gt;https://www.youtube.com/watch?v=ON1zLBvYKRI&lt;/a&gt;, and imagine how much the chassis would tilt if it were suspended by a spring-based system or if the wheels were attached to each other by treads.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The Jet Propulsion Laboratory has a good video on this, actually. &lt;a href=&quot;http://www-a.jpl.nasa.gov/video/index.php?all_videos&amp;amp;id=932&quot;&gt;http://www-a.jpl.nasa.gov/video/index.php?all_videos&amp;amp;id=932&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="163" LastActivityDate="2012-11-28T14:04:08.380" CommentCount="2" />
  <row Id="561" PostTypeId="2" ParentId="556" CreationDate="2012-11-28T14:06:06.960" Score="2" Body="&lt;p&gt;Measuring if something has moved is ok with just accelerometers, how much and where not. You may need to specify your application a little better, but it sounds like you should use an external tracking system (e.g. camera based) instead. You might also use something simple like an ultrasonic sensor to get the distance your robot has moved, if you are looking for low-cost. &lt;/p&gt;&#xA;" OwnerUserId="127" LastActivityDate="2012-11-28T14:06:06.960" />
  <row Id="562" PostTypeId="2" ParentId="554" CreationDate="2012-11-28T15:15:27.690" Score="19" Body="&lt;p&gt;For quadcopter designs, you generally want to have around a 2:1 &lt;a href=&quot;https://en.wikipedia.org/wiki/Thrust-to-weight_ratio&quot; rel=&quot;nofollow&quot;&gt;thrust-to-weight ratio&lt;/a&gt;. That is, at 100% throttle, you want your combined propeller thrust to be capable of lifting two times the weight of the craft.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You then need to determine the amount of power the motors need to generate that thrust (usually given on the datasheet). When you have that amount of power, you can easily calculate the amount of time your battery will last.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This page on &lt;a href=&quot;https://code.google.com/p/ro-4-copter/wiki/QuadcopterPerformance&quot; rel=&quot;nofollow&quot;&gt;Quadcopter Performance&lt;/a&gt; gives a good example:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Looking at the data from the motor performance chart, it looks like&#xA;  the absolute maximum weight the motors can support is 560 each, so&#xA;  2240 grams. This is when the motors are working at 100%, using 95.2&#xA;  watts, which means about 8.6 amps at 11.1 volts.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Looking at the data from the flight weight vs power and battery life&#xA;  graph, it seems that the helicopter should not exceed 61 ounces (1700&#xA;  grams). At that weight, 61 watts of power is used, which is 5.5 amps&#xA;  at 11.1 volts.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/RKru1.jpg&quot; alt=&quot;Flying Weight vs Power &amp;amp; Battery Life&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The graph also shows that one ounce of flight weight would need one&#xA;  watt of power, and the two are linearly correlated. Assuming the craft&#xA;  is 60 ounces, 60 watts of power is needed.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;This quote is a bit misleading though. The original author is missing the words &quot;per motor&quot; in their conclusion. 230W/4 motors = 57.5 Watts. That's where they got the &quot;60 ounces needs 60 Watts (per motor)&quot; conclusion. However the general method of plotting performance is beneficial to answering the question.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you increase the maximum thrust-to-weight ratio, you can keep your throttle lower, use less power, and stay in the air longer. So you can either increase thrust or decrease weight to achieve longer flight times.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To more concisely answer your question, the point of diminishing returns comes when the additional weight added by the battery brings your thrust-to-weight ratio below 1.5:1 on the low end.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Something else to consider is the &lt;a href=&quot;https://en.wikipedia.org/wiki/Energy_density&quot; rel=&quot;nofollow&quot;&gt;energy density&lt;/a&gt; of your battery technology. How much power per unit weight the battery is capable of. You're probably using Lithium-ion batteries which are probably the best available from a price to performance perspective. But if you're really trying to get longer flight times without increasing weight, you can consider some of the more esoteric (and much more expensive) technologies out there.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://newenergyandfuel.com/http:/newenergyandfuel/com/2009/06/15/battery-research-prospects-grow/battery-specific-energy-list1/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/5M9Fd.png&quot; alt=&quot;Battery Specific Energy List&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.legitreviews.com/article/887/2/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/Z9Flb.jpg&quot; alt=&quot;Energizer Zinc-Air Battery Comparison&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And it's probably worth mentioning that even within the Lithium-ion category, not all batteries are created equal.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://batteryuniversity.com/learn/article/the_high_power_lithium_ion&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/NKfwd.gif&quot; alt=&quot;L-Ion Comparison&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="142" LastEditorUserId="142" LastEditDate="2013-12-04T21:29:19.183" LastActivityDate="2013-12-04T21:29:19.183" CommentCount="0" />
  <row Id="563" PostTypeId="2" ParentId="558" CreationDate="2012-11-28T15:33:30.080" Score="2" Body="&lt;p&gt;This may not be the biggest reason, but I would imagine that for space vehicles like this, wheels are easier to stow for launch and then deploy for landing.&lt;/p&gt;&#xA;" OwnerUserId="479" LastActivityDate="2012-11-28T15:33:30.080" />
  <row Id="564" PostTypeId="2" ParentId="556" CreationDate="2012-11-28T15:55:02.980" Score="3" Body="&lt;p&gt;You can theoretically use just an accelerometer for determining motion, but it may not be accurate enough to achieve your goals. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The big problem with accelerometers is drift over time (i.e., errors in the acceleration measurement get integrated twice), so your position accuracy significantly decreases over time. The severity of this problem depends on the quality of the accelerometer and the measurement time.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you don't need position information and just want some indication that the robot has moved in a particular direction, an accelerometer would do the job. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Otherwise you would want to use some other sensor in conjunction with the accelerometer, in which case you may need some SLAM techniques. You could also switch to another type of system (like external motion capture mentioned in the other answer).&lt;/p&gt;&#xA;" OwnerUserId="479" LastEditorUserId="479" LastEditDate="2012-11-28T23:40:16.957" LastActivityDate="2012-11-28T23:40:16.957" CommentCount="2" />
  <row Id="565" PostTypeId="1" CreationDate="2012-11-28T16:07:20.107" Score="2" ViewCount="928" Body="&lt;p&gt;What are the pros and cons of each? Which is better maintained? Which allows for more functionality? Which utilizes the hardware more efficiently? Etc.&lt;/p&gt;&#xA;" OwnerUserId="457" LastEditorUserId="457" LastEditDate="2012-12-05T17:04:11.147" LastActivityDate="2012-12-07T16:50:08.477" Title="Kinect - Libfreenect vs OpenNI+SensorKinect" Tags="&lt;software&gt;&lt;sensors&gt;&lt;kinect&gt;" AnswerCount="1" CommentCount="6" FavoriteCount="0" ClosedDate="2012-12-08T01:39:06.793" />
  <row Id="566" PostTypeId="1" AcceptedAnswerId="567" CreationDate="2012-11-28T18:58:27.267" Score="4" ViewCount="184" Body="&lt;p&gt;While experimenting with the OpenCV Machine Learning Library, I tried to make an example to learn the inverse kinematics of a 2D, 2 link arm using &lt;a href=&quot;http://docs.opencv.org/modules/ml/doc/decision_trees.html&quot; rel=&quot;nofollow&quot;&gt;decision trees&lt;/a&gt;. The forward kinematics code looks like this:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;const float Link1 = 1;&#xA;const float Link2 = 2;&#xA;&#xA;CvPoint2D32f forwardKinematics(float alpha, float beta) &#xA;{&#xA;    CvPoint2D32f ret;&#xA;&#xA;    // Simple 2D, 2 link kinematic chain&#xA;    ret.x = Link1 * std::cos(alpha) + Link2 * std::cos(alpha - beta);&#xA;    ret.y = Link1 * std::sin(alpha) + Link2 * std::sin(alpha - beta);&#xA;&#xA;    return ret;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I generate a random set of 1000 (XY -&gt; alpha) and (XY -&gt; beta) pairs, and then use that data to train two decision tree models in OpenCV (one for alpha, one for beta). Then I use the models to predict joint angles for a given XY position. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;It seems like it sometimes gets the right answer, but is wildly inconsistent. I understand that inverse kinematic problems like this have multiple solutions, but some of the answers I get back are just wrong.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is this a reasonable thing to try to do, or will it never work? Are there other learning algorithms that would be better suited to this kind of problem than decision trees?&lt;/p&gt;&#xA;" OwnerUserId="479" LastActivityDate="2012-11-29T01:08:25.593" Title="Decision trees for solving 2D inverse kinematics?" Tags="&lt;inverse-kinematics&gt;&lt;machine-learning&gt;" AnswerCount="2" FavoriteCount="1" />
  <row Id="567" PostTypeId="2" ParentId="566" CreationDate="2012-11-28T20:05:53.197" Score="1" Body="&lt;p&gt;I changed the training set generation to uniformly sample the joint space instead of using random samples, and also restricted the range of the second joint to prevent multiple solutions and singularities. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now the algorithm actually works pretty well, and gives me answers that are reasonably close to the desired position. I'm still not convinced that decision trees are the best algorithm for this problem though.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thinking about it some more, I think all I've really done here is build a big lookup table in a fancy way (especially when using a uniform training set).&lt;/p&gt;&#xA;" OwnerUserId="479" LastEditorUserId="479" LastEditDate="2012-11-28T20:37:43.167" LastActivityDate="2012-11-28T20:37:43.167" CommentCount="2" />
  <row Id="568" PostTypeId="1" AcceptedAnswerId="569" CreationDate="2012-11-28T23:14:15.997" Score="8" ViewCount="1169" Body="&lt;p&gt;Could you implement a simple neural network on a microprocessor such as the Arduino Uno to be used in machine learning?&lt;/p&gt;&#xA;" OwnerUserId="374" LastActivityDate="2013-06-05T19:25:42.677" Title="Is it possible to run a neural network on a microcontroller" Tags="&lt;microcontroller&gt;&lt;machine-learning&gt;" AnswerCount="4" CommentCount="8" FavoriteCount="3" />
  <row Id="569" PostTypeId="2" ParentId="568" CreationDate="2012-11-28T23:25:21.047" Score="6" Body="&lt;p&gt;Could you &lt;em&gt;train&lt;/em&gt; a neural network on a microcontroller? Maybe, but please don't try. Could you use a NN for classification, etc on a microcontroller? Sure, as long as you can calculate the result of propagating the node and edge values and handle the multiplications.&lt;/p&gt;&#xA;" OwnerUserId="163" LastActivityDate="2012-11-28T23:25:21.047" CommentCount="1" />
  <row Id="570" PostTypeId="2" ParentId="568" CreationDate="2012-11-28T23:33:06.007" Score="13" Body="&lt;p&gt;It's certainly possible to implement this on an Arduino.  Here are 3 such Arduino libraries that implement neural networks:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://diydrones.com/group/arducopter-evolution-team/forum/topics/neuroduino-a-neural-network-library-for-arduino&quot;&gt;Neuroduino&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://arduinobasics.blogspot.com/2011/08/neural-network-part-1-connection.html&quot;&gt;Arduino Basics&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://robotics.hobbizine.com/arduinoann.html&quot;&gt;ArduinoANN&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The complexity of the network that the Arduino can handle is a separate question, especially when it comes to training -- tens of thousands of iterations on training data.  Training on a fast machine and then copying the neuron weights to the Arduino will be a smarter way to develop your implementation.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2012-11-29T01:55:37.743" LastActivityDate="2012-11-29T01:55:37.743" />
  <row Id="571" PostTypeId="2" ParentId="533" CreationDate="2012-11-29T00:10:15.310" Score="4" Body="&lt;p&gt;&lt;a href=&quot;http://www.moah.org/exhibits/archives/robotman/history/history.html&quot; rel=&quot;nofollow&quot;&gt;This site&lt;/a&gt; gives a great time line of robotics. Keep in mind the origins of robots come well before electricity. As the article describes, the early egyptians designed and constructed simple automatons, which are considered the earliest type of robot. Another starting point worth mentioning is the materials that early robots were made from and continue to present the evolution of carbon fibre and other materials that make robots as amazing as they are today.&lt;/p&gt;&#xA;" OwnerUserId="374" LastEditorUserId="374" LastEditDate="2012-12-19T03:52:39.040" LastActivityDate="2012-12-19T03:52:39.040" />
  <row Id="572" PostTypeId="2" ParentId="566" CreationDate="2012-11-29T01:08:25.593" Score="0" Body="&lt;p&gt;The core problem here is that you are using two decision trees. As I understand it you are training two different decision trees on the same data. You then have one tree predict the required angle $\alpha$ and the other predict the required angle $\beta$. The problem is that $\beta$ is dependent on $\alpha$ but the $\beta$ tree has no concept of this fact. What you need to do is train one tree on both feaures (i.e. $\alpha$ and $\beta$).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In OpenCV each DT node uses a double called &lt;code&gt;value&lt;/code&gt; to store the splitting value for that node and it uses an integer called &lt;code&gt;class_idx&lt;/code&gt; to determine which feature to split on at any given level. When you train the DT you need to supply it with a matrix. Conventionally each row of the matrix is a feature vector and each column is an individual feature. However it appears that this is configurable in the OpenCV implementation by using the &lt;code&gt;tflag&lt;/code&gt; (Cool!). Using the conventional method you would need to create an $m{\times}n$ matrix where $m = 1000$ is the number of training samples and $n = 2$.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2012-11-29T01:08:25.593" CommentCount="1" />
  <row Id="573" PostTypeId="2" ParentId="554" CreationDate="2012-11-29T10:50:10.763" Score="4" Body="&lt;p&gt;&lt;strong&gt;The batteries should weigh roughly the same as everything else on the airframe combined.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;With a given aircraft -- everything known except for the mass of the batteries -- the absolute maximum flight time occurs when the weight of the batteries is twice as much as the weight of everything else on the airframe combined. Reference: Andres 2011. &lt;a href=&quot;http://api.ning.com/files/aFMLPsgnHmZXdNMAY8PM0KekqE4uAQSMx2C%2ausF6KDpKiqpO4L9-hrUKYBsS-xtRMqo-K4GR5TPsM2Isq56oMw__/battery_capacity.pdf&quot; rel=&quot;nofollow&quot;&gt;Optimal Battery Capacity&lt;/a&gt;. via &lt;a href=&quot;http://www.heino.com/?page_id=24443&quot; rel=&quot;nofollow&quot;&gt;Heino R. Pull&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This rule of thumb applies to all kinds of battery-powered aircraft -- fixed-wing, quadcopters, helicopters etc.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(Forgive me for recycling my answer to &lt;a href=&quot;http://robotics.stackexchange.com/questions/262/effectiveness-of-a-mobile-robot-in-relation-to-mass/305#305&quot;&gt;Effectiveness of a Mobile Robot In Relation To Mass&lt;/a&gt; ).&lt;/p&gt;&#xA;" OwnerUserId="187" LastActivityDate="2012-11-29T10:50:10.763" />
  <row Id="575" PostTypeId="2" ParentId="520" CreationDate="2012-11-29T14:05:52.013" Score="5" Body="&lt;p&gt;I interpret your question to read, that you want to directly manufacture the lens through an additive process.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My experience with this recently is that it basically isn't possible (practically anyway). Even injection molding lenses of good quality is quite an art. There is a reason that optical-quality glass lenses are so expensive. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;More specifically, we tried to make a custom LED focusing lens using stereo-lithography in a range of PC, PE, PTFE, and (even!) PVC-type plastics. In all cases we had trouble achieving sufficient optical clarity, uniform density, and dimensional accuracy. Granted, we were making a small lens (about 11mm diameter), but it was suspended across an integrated holder (causing a lot of the same problems you'll face if you try to fabricate just a lens in isolation).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I know this has been a bit of a hand-wavy response, but hopefully it's at least a little helpful. If anyone else has any better experiences with this, I'd love to hear about it.&lt;/p&gt;&#xA;" OwnerUserId="531" LastActivityDate="2012-11-29T14:05:52.013" />
  <row Id="576" PostTypeId="2" ParentId="556" CreationDate="2012-11-29T15:04:32.690" Score="2" Body="&lt;p&gt;For simple motion detection, you might take a look at these:&lt;a href=&quot;http://www.st.com/internet/analog/product/250725.jsp&quot; rel=&quot;nofollow&quot;&gt;LIS3DH&lt;/a&gt;, &lt;a href=&quot;http://www.st.com/internet/analog/product/252443.jsp&quot; rel=&quot;nofollow&quot;&gt;L3GD20&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you would like to look at more complex options, you might take a look at this package: &lt;a href=&quot;http://www.st.com/internet/analog/product/253162.jsp&quot; rel=&quot;nofollow&quot;&gt;INEMO-M1&lt;/a&gt;. I'm using this package in a 3D motion tracking application.  It is relatively cheap, and it's integrated sensor fusion provides the most robust measure of displacement I've found.  (Accelerometer drift is minimized, output is smooth, etc.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Finally, the fall detection and click/double-tap recognition features found on this part &#xA;may assist in a walking application: &lt;a href=&quot;http://www.st.com/internet/analog/product/152913.jsp&quot; rel=&quot;nofollow&quot;&gt;LIS302DL&lt;/a&gt;.  As an example, the free-fall detection (which may be slightly misnamed since motion triggers can be set on any axis) can assist with detection of leg motion.  The tap/double-tap feature could assist in detecting leg contact with the walking surface.&lt;/p&gt;&#xA;" OwnerUserId="532" LastEditorUserId="308" LastEditDate="2012-11-30T17:04:30.217" LastActivityDate="2012-11-30T17:04:30.217" />
  <row Id="577" PostTypeId="2" ParentId="550" CreationDate="2012-11-29T17:02:28.543" Score="7" Body="&lt;p&gt;Many gyros are sensitive enough to detect the Earth's rotation, and so get an estimate of &quot;true North&quot; (rotational North, as opposed to magnetic North).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've been told the first person to detect the rotation of the Earth using a gyroscope was Léon Foucault, in 1852. ( &lt;a href=&quot;http://en.wikipedia.org/wiki/Gyroscope#History&quot;&gt;a&lt;/a&gt; )&lt;/p&gt;&#xA;&#xA;&lt;p&gt;That is the operating principle of the &lt;a href=&quot;http://en.wikipedia.org/wiki/Gyrocompass&quot;&gt;gyrocompass&lt;/a&gt; and the &lt;a href=&quot;http://en.wikipedia.org/wiki/Gyrotheodolite&quot;&gt;gyro-theodolite&lt;/a&gt;,&#xA;which are used to find true north on many ocean-going ships and in underground tunnels.&#xA;They can directly find North from a cold start.&#xA;(Unlike the &quot;&lt;a href=&quot;http://en.wikipedia.org/wiki/directional_gyro&quot;&gt;directional gyro&lt;/a&gt;&quot; in most small planes).&lt;/p&gt;&#xA;" OwnerUserId="187" LastActivityDate="2012-11-29T17:02:28.543" />
  <row Id="578" PostTypeId="1" AcceptedAnswerId="582" CreationDate="2012-11-29T19:15:24.753" Score="8" ViewCount="314" Body="&lt;p&gt;We have an optional course in our high-school which is about robotics. We're using the Lego Mindstorms NXT and program it with the original Mindstorms-software.&#xA;However, we want to advance and use a major programming-language. We have tried NXC and LeJos. Plus, I tried out the Microsoft Robotics Development Studio, but with all these different possibilities we are a little bit overwhelmed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Because of that (now it becomes interesting), I want to ask, what technology is the best for NXT and especially: What is easy to use? I don't want to need 14 steps just to compile a program and get it running on the NXT. Also, it would be nice, if it's an extend-able language, like using C#, but are there some better or easier possibilities?&lt;/p&gt;&#xA;" OwnerUserId="534" LastEditorUserId="38" LastEditDate="2012-12-13T07:17:05.543" LastActivityDate="2013-06-10T20:25:31.547" Title="Which programming language should I use with the NXT?" Tags="&lt;programming-languages&gt;&lt;nxt&gt;" AnswerCount="3" CommentCount="1" FavoriteCount="1" ClosedDate="2013-12-08T21:21:36.753" />
  <row Id="579" PostTypeId="2" ParentId="578" CreationDate="2012-11-29T20:41:07.220" Score="3" Body="&lt;p&gt;The kit supplied NXT software is a bit basic, agreed... but before trying anything more complex, I can commend &lt;a href=&quot;http://www.ni.com/academic/mindstorms/&quot; rel=&quot;nofollow&quot;&gt;NI LabView for NXT&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Not only is this an improvement on the NXT-G but this gives you an introduction to LabView which is widely used in the Real World for data acquisition and test systems.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm sure there must be a C/C# API out there (I've not looked though)&lt;/p&gt;&#xA;" OwnerUserId="134" LastEditorUserId="134" LastEditDate="2012-12-03T20:10:48.817" LastActivityDate="2012-12-03T20:10:48.817" CommentCount="1" />
  <row Id="580" PostTypeId="5" CreationDate="2012-11-29T21:18:58.117" Score="0" ViewCount="1" Body="&lt;p&gt;Software, is any set of machine-readable instructions (most often in the form of a computer program) that directs a computer's processor to perform specific operations. The term is used to contrast with computer hardware, the physical objects (processor and related devices) that carry out the instructions. Hardware and software require each other and neither has any value without the other.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Software covers a multitude of aspects within a robotic system - eg: motor control, control algorithms, communications, displays etc as well as FPGA/PLD configration.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The &lt;code&gt;software&lt;/code&gt; is somewhat broad and should normally be used in conjunction with other tags to focus the question.&lt;/p&gt;&#xA;" OwnerUserId="134" LastEditorUserId="40" LastEditDate="2013-09-02T04:39:03.377" LastActivityDate="2013-09-02T04:39:03.377" />
  <row Id="581" PostTypeId="4" CreationDate="2012-11-29T21:18:58.117" Score="0" Body="A set of machine-readable instructions (most often in the form of a computer program) that directs a computer's processor to perform specific operations." OwnerUserId="40" LastEditorUserId="40" LastEditDate="2013-09-02T04:37:43.090" LastActivityDate="2013-09-02T04:37:43.090" />
  <row Id="582" PostTypeId="2" ParentId="578" CreationDate="2012-11-29T22:23:50.640" Score="7" Body="&lt;blockquote&gt;&#xA;  &lt;p&gt;&quot;We have tried NXC and LeJos. Plus, I tried out the Microsoft Robotics Development Studio, but with all these different possibilities we are a little bit overwhelmed.&quot;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;That basically leaves &lt;a href=&quot;http://www.robotc.net/index.php&quot; rel=&quot;nofollow&quot;&gt;RobotC&lt;/a&gt; - which is easier to use, and reasonably powerful. As it is based on C, you will not find it as powerful a language as JAVA (LeJOS), but robotics stuff is built in (motors/encoders, reading sensors, I2C, bluetooth). It does include a good IDE and debugging system, something NXC and LeJOS are missing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;MRDS is really not suited for NXT since it does not run on the NXT:, it is simply a remote control system. You can look at &lt;a href=&quot;http://www.mindsqualls.net/&quot; rel=&quot;nofollow&quot;&gt;mindsqualls&lt;/a&gt; for an alternative and not quite as complicated C# remote control system if that is acceptable to your project/studies.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A few people have ported &lt;a href=&quot;http://msdn.microsoft.com/en-us/library/ee436350.aspx&quot; rel=&quot;nofollow&quot;&gt;MF (micro frameworks C#)&lt;/a&gt; to the NXT but there was 0 room left, making it very impractical.&lt;/p&gt;&#xA;" OwnerUserId="274" LastEditorUserId="350" LastEditDate="2013-06-10T20:25:31.547" LastActivityDate="2013-06-10T20:25:31.547" CommentCount="11" />
  <row Id="583" PostTypeId="1" CreationDate="2012-11-30T08:53:51.253" Score="3" ViewCount="217" Body="&lt;p&gt;I have a manipulator having 4 revolute joints with some movement limitations. So, when I apply inverse kinematics, I'm getting results which are out of limits. Please provide me an algorithm that implements inverse kinematics considering joint limitations.&lt;/p&gt;&#xA;" OwnerUserId="536" LastEditorUserId="177" LastEditDate="2012-12-01T15:30:01.963" LastActivityDate="2012-12-03T23:15:18.693" Title="Inverse kinematics with joint contraints" Tags="&lt;inverse-kinematics&gt;" AnswerCount="2" />
  <row Id="584" PostTypeId="2" ParentId="583" CreationDate="2012-11-30T10:39:48.760" Score="3" Body="&lt;p&gt;4 joints gives you 4 degrees of freedom only. Therefore, if you use inverse kinematics on the full 6 degrees of freedom, not all positions have a solution, and if it does, it there is generally only one unique solution.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am therefore assuming that you are only trying to fix some of the positions, for example, x, y and z coordinates, but not the orientation (the 3 rotation axes) of the end effector.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It is a non-linear system, however, at any point, you can linearise it. It is likely that the inverse kinematics applied already repeatedly linearises the problem and performs some type of gradient descent.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To alter a solution, you can find the null-space of the linearised system of equations, and use that vector to modify your solution towards the joint limits.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To do this, you simply differentiate your system of equations to obtain a linearisation, so for example, you get:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$\Delta \alpha \vec{a}+\Delta \beta\vec{b}+\Delta \gamma\vec{c}+\Delta \delta\vec{d}=&#xA;\left[\begin{matrix}\vec{a}&amp;amp;\vec{b}&amp;amp;\vec{c}&amp;amp;\vec{d}\end{matrix}\right]&#xA;\left[\begin{matrix}\Delta \alpha \\\Delta \beta\\\Delta \gamma\\\Delta \delta\end{matrix}\right]&#xA;=&#xA;\left[\begin{matrix}\Delta x\\\Delta y\\\Delta z\end{matrix}\right]$, where $\alpha$, $\beta$, $\gamma$, $\delta$ are the angles of the revolute joints, with appropriate coefficients.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Finding the null-space means finding the $\Delta \alpha$, $\Delta \beta$, $\Delta \gamma$, $\Delta \delta$ such that $\Delta x, \Delta y, \Delta z = 0$. You can do this easily (choose from gaussian elimination, matrix divide etc.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you modify the angles by a small multiple of the null-space vector over many iterations, you should eventually get within the joint constraints (if it is possible). You just need to decide on the direction (check each angle, and if it is not within range, it should provide the appropriate angle).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If your inverse kinematics algorithm/code takes initial joint angles to start it off, you can put the new joint angles back in here so that the x, y and z positions don't drift away from the desired positions. This also allows you to take larger steps with the null-space vector (which otherwise tends to make the position tracked start to become less inaccurate).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In some cases, the null-space may contain more than one vector. This would occur if you only wanted to fix two of the degrees of freedom. In this case, in each iteration, you can modify using only one or both of the vectors. Similar logic can be applied to get the angles within the constraints - just decide on the direction in which to apply each vector by checking if each revolute joint angle is within the constraints, and if not, it will give you a direction to apply the vector.&lt;/p&gt;&#xA;" OwnerUserId="145" LastActivityDate="2012-11-30T10:39:48.760" />
  <row Id="585" PostTypeId="1" AcceptedAnswerId="598" CreationDate="2012-11-30T13:47:48.713" Score="-4" ViewCount="1346" Body="&lt;p&gt;I want to know if its currently possible for a robot to speak by it self as &lt;code&gt;King Robota&lt;/code&gt; does, or is just someone speaking on his behalf?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=UYI2UDpQtv4&quot; rel=&quot;nofollow&quot;&gt;Youtube video&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="537" LastEditorUserId="537" LastEditDate="2012-11-30T15:29:33.677" LastActivityDate="2013-09-12T03:47:44.650" Title="King Robota: Does he speak for himself?" Tags="&lt;control&gt;&lt;software&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="586" PostTypeId="5" CreationDate="2012-11-30T14:14:42.977" Score="0" ViewCount="2" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2012-11-30T14:14:42.977" LastActivityDate="2012-11-30T14:14:42.977" />
  <row Id="587" PostTypeId="4" CreationDate="2012-11-30T14:14:42.977" Score="0" Body="Hierarchical Markov Model" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2012-11-30T17:04:02.403" LastActivityDate="2012-11-30T17:04:02.403" />
  <row Id="588" PostTypeId="5" CreationDate="2012-11-30T14:16:14.923" Score="0" ViewCount="2" Body="&lt;p&gt;used to encode known relationships between observations and construct consistent interpretations&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2012-11-30T17:03:35.813" LastActivityDate="2012-11-30T17:03:35.813" />
  <row Id="589" PostTypeId="4" CreationDate="2012-11-30T14:16:14.923" Score="0" Body="Conditional Random Field" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2012-11-30T17:03:27.263" LastActivityDate="2012-11-30T17:03:27.263" />
  <row Id="590" PostTypeId="5" CreationDate="2012-11-30T14:17:01.553" Score="0" ViewCount="2" Body="&lt;p&gt;Used for minimizing the difference between two clouds of points&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2012-11-30T17:04:42.713" LastActivityDate="2012-11-30T17:04:42.713" />
  <row Id="591" PostTypeId="4" CreationDate="2012-11-30T14:17:01.553" Score="0" Body="Iterative Closest Point" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2012-11-30T17:03:24.747" LastActivityDate="2012-11-30T17:03:24.747" />
  <row Id="592" PostTypeId="5" CreationDate="2012-11-30T14:22:05.873" Score="0" ViewCount="2" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2012-11-30T14:22:05.873" LastActivityDate="2012-11-30T14:22:05.873" />
  <row Id="593" PostTypeId="4" CreationDate="2012-11-30T14:22:05.873" Score="0" Body="Tank treads -- continuous tracks" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2012-11-30T17:04:34.837" LastActivityDate="2012-11-30T17:04:34.837" />
  <row Id="594" PostTypeId="5" CreationDate="2012-11-30T14:26:10.287" Score="0" ViewCount="4" Body="&lt;p&gt;an electronic device that measures and reports its velocity, orientation, and gravitational force&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2012-11-30T17:04:39.920" LastActivityDate="2012-11-30T17:04:39.920" />
  <row Id="595" PostTypeId="4" CreationDate="2012-11-30T14:26:10.287" Score="0" Body="Inertial Measurement Unit" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2012-11-30T17:04:46.287" LastActivityDate="2012-11-30T17:04:46.287" />
  <row Id="596" PostTypeId="5" CreationDate="2012-11-30T14:26:44.437" Score="0" ViewCount="3" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2012-11-30T14:26:44.437" LastActivityDate="2012-11-30T14:26:44.437" />
  <row Id="597" PostTypeId="4" CreationDate="2012-11-30T14:26:44.437" Score="0" Body="Human-Robot Interaction" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2012-11-30T17:03:57.520" LastActivityDate="2012-11-30T17:03:57.520" />
  <row Id="598" PostTypeId="2" ParentId="585" CreationDate="2012-11-30T15:26:04.053" Score="3" Body="&lt;p&gt;Not only is a human voice behind this (likely through a vocoder), I believe you are looking at a mechanized costume and not an actual robot -- &lt;a href=&quot;http://kingrobota.com/faq.html&quot; rel=&quot;nofollow&quot;&gt;someone is inside&lt;/a&gt;.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Using fake robots to attract crowds has worked since &lt;a href=&quot;http://www.youtube.com/watch?v=T35A3g_GvSg&quot; rel=&quot;nofollow&quot;&gt;&quot;Elektro&quot; at the 1939 World's Fair (video)&lt;/a&gt;.  You can also &lt;a href=&quot;http://digitaldiscountproducts.com/WP/2012/04/18/start-your-own-robot-business-2012/&quot; rel=&quot;nofollow&quot;&gt;buy your own King Robota suit&lt;/a&gt; if you want to take up this form of entertainment yourself.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A more interesting question is how the costume's mouth reacts to the incoming speech, to emulate actual speaking.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2012-11-30T15:53:51.763" LastActivityDate="2012-11-30T15:53:51.763" CommentCount="2" />
  <row Id="599" PostTypeId="1" CreationDate="2012-11-30T16:04:26.703" Score="2" ViewCount="152" Body="&lt;p&gt;According to &lt;a href=&quot;http://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping&quot; rel=&quot;nofollow&quot;&gt;Wikipedia's article on SLAM&lt;/a&gt;, the original idea came from Randal Smith and Peter Cheeseman (&lt;em&gt;&lt;a href=&quot;http://www.frc.ri.cmu.edu/~hpm/project.archive/reference.file/Smith&amp;amp;Cheeseman.pdf&quot; rel=&quot;nofollow&quot;&gt;On the Estimation and Representation of Spatial Uncertainty&lt;/a&gt;&lt;/em&gt; [PDF]) in 1986, and was refined by Hugh F. Durrant-Whyte and J.J. Leonard (&lt;em&gt;&lt;a href=&quot;http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;amp;arnumber=174711&amp;amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D174711&quot; rel=&quot;nofollow&quot;&gt;Simultaneous map building and localization for an autonomous mobile robot&lt;/a&gt;&lt;/em&gt;) in 1991. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, neither paper uses the term &quot;SLAM&quot;.  Where (and when) did that term come from?  Was there a particular author or whitepaper that popularized it?&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="417" LastEditDate="2012-12-01T15:30:11.697" LastActivityDate="2012-12-03T10:09:49.077" Title="Who coined (or popularized) the term &quot;SLAM&quot;?" Tags="&lt;slam&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="600" PostTypeId="2" ParentId="167" CreationDate="2012-11-30T16:46:07.670" Score="0" Body="&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Ziegler%E2%80%93Nichols_method&quot; rel=&quot;nofollow&quot;&gt;Ziegler-Nichols&lt;/a&gt; is an easy manual method.  More robust methods also exist - these usually rely on mathematical solutions (analytic, iterative optimization, etc.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Beyond that, google &quot;self-tuning PID&quot; for some automated techniques.  My favorite is the application of neural networks to PID tuning.&lt;/p&gt;&#xA;" OwnerUserId="532" LastActivityDate="2012-11-30T16:46:07.670" />
  <row Id="601" PostTypeId="2" ParentId="271" CreationDate="2012-11-30T17:22:30.420" Score="2" Body="&lt;p&gt;Depending on how much you wanted to play with the GPS signals, you could use some form of differential GPS to calculate their relative positions way more precisely&#xA;than using the WGS84 outputs would give you. Basically this would remove most of the inaccuracies coming from atmospheric effects and ephemeris errors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The exact precision would depend on the receivers and algorithms used, especially whether you would also use carrier phase differencing. ... but my wild guess is you could get to 1 or 2 meters precision.&lt;/p&gt;&#xA;" OwnerUserId="482" LastActivityDate="2012-11-30T17:22:30.420" />
  <row Id="602" PostTypeId="1" AcceptedAnswerId="605" CreationDate="2012-11-30T17:38:20.133" Score="4" ViewCount="142" Body="&lt;p&gt;I've got a couple &lt;a href=&quot;http://www.vexrobotics.com/276-2181.html&quot; rel=&quot;nofollow&quot;&gt;Vex 269 Motors&lt;/a&gt; hooked up to an &lt;a href=&quot;http://www.arduino.cc/en/Main/ArduinoBoardDuemilanove&quot; rel=&quot;nofollow&quot;&gt;Arduino Duemilanove&lt;/a&gt;. These motors run a some &lt;a href=&quot;http://www.vexrobotics.com/276-2168.html&quot; rel=&quot;nofollow&quot;&gt;Vex Tank Treads&lt;/a&gt;. I powered the whole setup with an off-brand 9-volt battery. Everything seems to run great, except that it is only able to run for about 30 seconds worth of motor movement. Then the battery quickly isn't able to pump out the energy needed to move the treads and the whole thing quickly slows to being unusable.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What's my problem here? The tank treads seem loose enough that I don't think they're so restricting the motor has to pump out too much energy to move them. There's nothing else being powered except the Arduino and the motors. Is it because this Enercell 9-volt (alkaline) is just a terrible battery choice? Should I only expect that long of battery life for this robot on a 9-volt? Or is there something else I'm missing? Thank you much!&lt;/p&gt;&#xA;" OwnerUserId="457" LastEditorUserId="350" LastEditDate="2012-11-30T20:11:46.663" LastActivityDate="2012-11-30T20:19:43.967" Title="Vex motors and tank treads drained 9-volt battery more quickly than expected" Tags="&lt;batteries&gt;&lt;tracks&gt;&lt;troubleshooting&gt;" AnswerCount="1" />
  <row Id="603" PostTypeId="1" AcceptedAnswerId="604" CreationDate="2012-11-30T17:50:31.360" Score="8" ViewCount="288" Body="&lt;p&gt;I've got a couple &lt;a href=&quot;http://www.vexrobotics.com/276-2181.html&quot;&gt;Vex 269 Motors&lt;/a&gt; hooked up to an &lt;a href=&quot;http://www.arduino.cc/en/Main/ArduinoBoardDuemilanove&quot;&gt;Arduino Duemilanove&lt;/a&gt;. These motors run a some &lt;a href=&quot;http://www.vexrobotics.com/276-2168.html&quot;&gt;Vex Tank Treads&lt;/a&gt;. The two motors are run as servos on the Arduino using the Servo Library. The problem I'm having is that the two tracks don't turn at the same speed when sent the same servo angle. This is clearly due to the fact that the continuous tracks have so many moving parts that having identical friction forces on each track is hard to get.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How do I get them to move the same speed? Should they be moving the same speed given the same servo angle regardless of the friction and the Vex 269 Motors just aren't strong enough (meaning I should use the Vex 369 or some other more powerful motor)? Is it best to just doing trial and error long enough to figure out which servo angle results in equal speeds on each? Should I tinker with the tracks until they have nearly identical frictions? Thank you much!&lt;/p&gt;&#xA;" OwnerUserId="457" LastEditorUserId="37" LastEditDate="2013-05-20T15:51:27.397" LastActivityDate="2013-05-20T15:51:27.397" Title="How to get two continuous tracks (tank treads) to move at the same rate?" Tags="&lt;mobile-robot&gt;&lt;motor&gt;&lt;tracks&gt;" AnswerCount="1" FavoriteCount="1" />
  <row Id="604" PostTypeId="2" ParentId="603" CreationDate="2012-11-30T18:51:47.927" Score="12" Body="&lt;p&gt;The short answer is that you need better control (feedback) to do it. Practically, you will never be able to calibrate the system accurately enough to go straight for more than a few tens of robot-body lengths. Once you dial it perfectly for one set of conditions, the environment or wear conditions will change and you'll have to tune it up again.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Surface conditions, traction, attitude, motor-isolation (the distribution of electrical power to each motor from a common power source), and many other real-time operational factors effect forward velocity for each side of the 'bot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Depending on your precision requirements, something as simple as a magnetic compass (position as far forward on the robot as possible to maximize its responsiveness) could help you maintain a heading during forward motion. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Often it isn't critically important precisely which direction your 'bot is moving; rather, it simply needs to be making progress on some task (follow the leader, search for a target, etc). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you post greater detail on your robot and its design objectives, I could assist you further.&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;A note about magnetic sensor placement&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;But, why should I &quot;position [the magnetic transducer] as far forward as possble&quot;? Isn't it true that the angle is the same? Yup. That's true, but the magnitude of the Earth's magnetic field is not. &lt;em&gt;You are standing in a different spot on Earth&lt;/em&gt;. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Imagine your robot is as big as a car. If you sit in the geometric center of the car and the car pivots about you, your coordinates on the Earth have not changed; only your attitude has. Now if you are sitting on the hood of the car and the car repeats it's previous motion, &lt;em&gt;both&lt;/em&gt; your attitude and your coordinates have changed. Changing coordinates produces a bigger difference in magnitude of the Earth's field than rotation alone.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Over the last few years I worked on a team with Dr. Dwight Veihland of Virginia Tech, arguably the world's leading expert on super-high sensitivity magnetic sensors. If I were to crystallize the body of his work (&lt;a href=&quot;http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&amp;amp;arnumber=5185369&amp;amp;contentType=Journals+%26+Magazines&amp;amp;sortType%3Ddesc_p_Publication_Year%26queryText%3Ddwight+viehland&quot;&gt;like in this example&lt;/a&gt;), I would say that he is always in pursuit of greater signal-to-noise ratios in the detection of ever tinier magnitudes. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any increase in the magnitude difference you can generate makes life easier for your sensor... and in this case, you get it for free. A number of DARPA grand challenge robots placed the GPS sensor forward for this same reason.&lt;/p&gt;&#xA;" OwnerUserId="531" LastEditorUserId="531" LastEditDate="2012-12-08T19:04:08.027" LastActivityDate="2012-12-08T19:04:08.027" CommentCount="2" />
  <row Id="605" PostTypeId="2" ParentId="602" CreationDate="2012-11-30T20:08:50.580" Score="4" Body="&lt;p&gt;It looks like your motors can draw up to 2.5A each; there's no way a 9-volt alkaline can sustain that current (plus the other on-board electronics) for any length of time.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;You'll need to pick a more appropriate battery for this robot.  Have a look at the discharge curves for several batteries, and pick one that fits the current draw and desired operating time for your robot.  Here's an example of what a discharge curve for several 9V batteries looks like:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://www.powerstream.com/z/9v-100ma-discharge-tests.png&quot; alt=&quot;Discharge curve&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;mAH is Milliamp-hours: how many hours the battery will supply a given amount of current -- a way of measuring capacity.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The other factor is how much current you draw:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://www.rctoys.com/pr/pr-images/tp-extreme-5000-discharge-curve-graph.gif&quot; alt=&quot;Discharge curve&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The different curves indicate different loads for the battery.  &lt;strong&gt;There is a maximum load for every battery, and you should not exceed it&lt;/strong&gt;; best case, you get poor performance, worst case you get a fire or explosion.  In this graph, you can see that the 125A load causes a severe drop in voltage.  That's the same effect you're seeing -- a severe drop in performance caused by overloading the battery. &lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2012-11-30T20:19:43.967" LastActivityDate="2012-11-30T20:19:43.967" CommentCount="2" />
  <row Id="607" PostTypeId="5" CreationDate="2012-11-30T21:19:11.380" Score="0" ViewCount="3" Body="&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Denavit%E2%80%93Hartenberg_parameters&quot; rel=&quot;nofollow&quot;&gt;Denavit-Hartenberg Parameters on Wikipedia&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2012-12-01T15:30:15.847" LastActivityDate="2012-12-01T15:30:15.847" />
  <row Id="608" PostTypeId="4" CreationDate="2012-11-30T21:19:11.380" Score="0" Body="the four parameters associated with a particular convention for attaching reference frames to the links of a spatial kinematic chain, or robot manipulator" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2012-12-01T15:30:08.093" LastActivityDate="2012-12-01T15:30:08.093" />
  <row Id="609" PostTypeId="1" AcceptedAnswerId="610" CreationDate="2012-12-01T09:33:23.763" Score="5" ViewCount="394" Body="&lt;p&gt;I know this is a &lt;em&gt;broad&lt;/em&gt; statement, but when you've got support for both TCP as well as a full fledged computer on board (to integrate/run an arduino), does this essentially allow for anything that would run on a linux box (raspberryPi) to run and operate your robot?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I know clock speed as well as the dependency libraries for a given code base (on the Pi) would add some complexity here, but what are some of the big issues that I'm overlooking in such a vertically-integrated control system?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Including a RaspberryPi within a robot... Does this allow for a &quot;universal API&quot;?&lt;/p&gt;&#xA;" OwnerUserId="111" LastEditorUserId="111" LastEditDate="2012-12-20T20:30:53.640" LastActivityDate="2012-12-20T20:30:53.640" Title="Including a RaspberryPi within a robot... Does this allow for a &quot;universal API&quot;?" Tags="&lt;software&gt;&lt;arduino&gt;&lt;raspberry-pi&gt;" AnswerCount="3" CommentCount="3" FavoriteCount="3" />
  <row Id="610" PostTypeId="2" ParentId="609" CreationDate="2012-12-01T10:53:50.637" Score="10" Body="&lt;p&gt;The short answer is &quot;yes&quot;. I'm assuming you are describing an architecture that looks &lt;em&gt;broadly&lt;/em&gt; ;-) like this:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Real-time system &amp;lt;--&gt; Soft-time system&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is a very common robot architecture. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The real-time system (RTS) (for example, an Arduino with appropriate firmware) handles the low-level sensor farming (conditioning, data packaging, management, and routing), power management, motor management, and general purpose I/O operations.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The soft-time system (STS) (ex. the Raspberry Pi you mentioned) is a more powerful system designed to handle monitoring, long-range communications, and more elaborate sensor integration and processing tasks. It sits above the RTS, which handles all the intense timing details of waveform generation and low-speed local bus communication so that the STS can work the &quot;harder&quot; problems.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Obviously, this is a big over-simplification, but I think it gets the core ideas across.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I wrote a number of academic papers &lt;a href=&quot;http://research.cens.ucla.edu/projects/2005/Actuation/robogaming/&quot;&gt;1&lt;/a&gt; &lt;a href=&quot;http://nesl.ee.ucla.edu/document/list?project_id=26&quot;&gt;2&lt;/a&gt; on robot architecture if you would like to explore more deeply. If you have something specific in mind, please feel free to ask me (or the community) some follow-up questions. ;-)&lt;/p&gt;&#xA;" OwnerUserId="531" LastEditorUserId="531" LastEditDate="2012-12-03T06:33:42.430" LastActivityDate="2012-12-03T06:33:42.430" CommentCount="2" />
  <row Id="611" PostTypeId="2" ParentId="609" CreationDate="2012-12-01T12:21:20.573" Score="-2" Body="&lt;p&gt;&quot;Does this essentially allow for anything that would run on a linux box ( raspberryPi ) to run and operate your robot?&quot;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm an outsider, but from what I have heard Rasberry Pi has problems running ROS at the moment. A linux robot that can not run ROS is missing a huge part of the community, and I would have a hard time seeing that as &quot;allowing anything that runs on linux.&quot;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To me the purpose of ROS is to allow research/development in a specific area without having to  learn/develop all the other stuff that has already been done. That is the spirit of open source, that is the spirit of Linux, that is the spirit of ROS. Jut because you can not do this does not make it less of a robot, but it does make the reasons to use it much less, IMHO, and to answer your question.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Wouldn't it be a much better choice to run some non rasberyy pi computer with Arduinos? Is price the real issue? And if it is why does anything else matter then? A cute name does not make a cute robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;edit: can anyone explain to me what a &quot;universal API&quot; is? How about a &quot;vertically-integrated control system&quot;? Actually, explain how this is even a question, with up votes?&lt;/p&gt;&#xA;" OwnerUserId="274" LastEditorUserId="274" LastEditDate="2012-12-01T20:37:19.687" LastActivityDate="2012-12-01T20:37:19.687" CommentCount="9" />
  <row Id="612" PostTypeId="2" ParentId="599" CreationDate="2012-12-01T15:17:12.447" Score="4" Body="&lt;p&gt;According to this &lt;a href=&quot;http://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=2&amp;amp;cad=rja&amp;amp;ved=0CDkQFjAB&amp;amp;url=http%3A%2F%2Fwww.cs.berkeley.edu%2F~pabbeel%2Fcs287-fa09%2Freadings%2FDurrant-Whyte_Bailey_SLAM-tutorial-I.pdf&amp;amp;ei=qB26UJ7BJcGUrgeUoYHgCg&amp;amp;usg=AFQjCNHglzCdyHwwV9DdjXlTprqMQTcrwA&quot; rel=&quot;nofollow&quot;&gt;SLAM tutorial&lt;/a&gt;, &lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The structure of the SLAM problem, the convergence result and the&#xA;  coining of the acronym ‘SLAM’ was ﬁrst presented in a mobile robotics survey &#xA;  paper presented at the 1995 International Sym- posium on&#xA;  Robotics Research.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;which refers to this paper -&gt; &lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;H. Durrant-Whyte, D. Rye, and E. Nebot. Localisation of automatic&#xA;  guided vehicles. In G. Giralt and G. Hirzinger, editors, Robotics&#xA;  Research: The 7th International Symposium (ISRR’95), pages 613–625.&#xA;  Springer Verlag, 1996.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="417" LastEditorUserId="417" LastEditDate="2012-12-03T10:09:49.077" LastActivityDate="2012-12-03T10:09:49.077" CommentCount="2" />
  <row Id="613" PostTypeId="1" AcceptedAnswerId="615" CreationDate="2012-12-01T20:32:27.490" Score="15" ViewCount="4677" Body="&lt;p&gt;What are the stall and free currents of an electric motor? For example, &lt;a href=&quot;http://www.vexrobotics.com/276-2181.html&quot; rel=&quot;nofollow&quot;&gt;this Vex motor&lt;/a&gt; lists its stall and free currents at the bottom of the page.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I think I understand the general idea, but a detailed description would be helpful.&lt;/p&gt;&#xA;" OwnerUserId="457" LastEditorUserId="37" LastEditDate="2013-05-20T15:51:54.570" LastActivityDate="2013-05-20T15:51:54.570" Title="What is stall current and free current of motors?" Tags="&lt;motor&gt;&lt;current&gt;" AnswerCount="3" FavoriteCount="1" />
  <row Id="614" PostTypeId="2" ParentId="613" CreationDate="2012-12-01T22:08:35.087" Score="13" Body="&lt;p&gt;Stall current is how much the motor will draw when it is stuck, i.e. &lt;em&gt;stalled&lt;/em&gt;. Free current is how much current it draws when the motor has no load, i.e. &lt;em&gt;free to spin&lt;/em&gt;.  As you'd expect, the more strain on the motor, the more current it will draw in order to move; the stall current and free current are the maximum and minimum, respectively.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From a standing start, the motor will draw somewhere close to the stall current at first and then drop to the current required to maintain whatever speed it's operating at.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="158" LastEditDate="2012-12-07T15:45:51.790" LastActivityDate="2012-12-07T15:45:51.790" CommentCount="5" />
  <row Id="615" PostTypeId="2" ParentId="613" CreationDate="2012-12-01T23:24:41.493" Score="14" Body="&lt;h2&gt;Short answer&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Stall current&lt;/strong&gt; is the maximum current drawn&lt;sup&gt;1&lt;/sup&gt;, when the motor is applying its maximum torque, either because it is being prevented from moving entirely or because it can no longer accelerate given the load it is under.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Free current&lt;/strong&gt; is the current drawn when the motor is rotating freely at maximum speed, under no load&lt;sup&gt;2&lt;/sup&gt; other than friction and back-emf forces in the motor itself.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;sup&gt;1: Under normal conditions, i.e. the motor isn't being asked &lt;a href=&quot;http://robotics.stackexchange.com/a/644/37&quot;&gt;go from max speed in one direction to max speed in the other&lt;/a&gt;.&lt;br&gt;&#xA;2: This assumes the motor is not being &lt;a href=&quot;http://robotics.stackexchange.com/a/644/37&quot;&gt;driven by external forces&lt;/a&gt;.&lt;/sup&gt;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Long answer&lt;/h2&gt;&#xA;&#xA;&lt;h3&gt;Stall Current&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;From the Wikipedia page on &lt;a href=&quot;http://en.wikipedia.org/wiki/Stall_torque&quot;&gt;Stall Torque&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;&lt;strong&gt;Stall torque&lt;/strong&gt; is the &lt;a href=&quot;http://en.wikipedia.org/wiki/Torque&quot;&gt;torque&lt;/a&gt; which is produced by a device when the output rotational speed is zero. It may also mean the torque load that causes the output rotational speed of a device to become zero - i.e. to cause &lt;a href=&quot;http://en.wikipedia.org/wiki/Stall_%28engine%29&quot;&gt;stalling&lt;/a&gt;. Stalling is a condition when the motor stops rotating. This condition occurs when the load torque is greater than the motor shaft torque i.e. break down torque condition. In this condition the motor draws maximum current but the motor do not rotate.The current is called as Stalling current.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;...&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;h3&gt;Electric motors&lt;/h3&gt;&#xA;  &#xA;  &lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Electric_motor&quot;&gt;Electric motors&lt;/a&gt; continue to provide torque when stalled. However, electric motors left in a stalled condition are prone to overheating and possible damage since the current flowing is maximum under these conditions.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;The maximum torque an electric motor can produce in the long term when stalled without causing damage is called the &lt;strong&gt;maximum continuous stall torque&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Thus from the &lt;a href=&quot;http://www.vexrobotics.com/276-2181.html&quot;&gt;specification&lt;/a&gt; of this motor&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;Stall Torque:  8.6 in-lbs&#xA;Stall Current: 2.6 A&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;we can see that if the motor is required to apply more than 8.6 in-lbs of torque the motor will stop moving (or accelerating if working against friction) and will be drawing the maximum 2.6A of current.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Although it doesn't say what kind of motor it is, I would expect it to be a &lt;a href=&quot;http://en.wikipedia.org/wiki/Brushed_DC_electric_motor&quot;&gt;Brushed DC electric motor&lt;/a&gt; given it's two wire interface.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;As an unloaded DC motor spins, it generates a backwards-flowing electromotive force that resists the current being applied to the motor. The current through the motor drops as the rotational speed increases, and a free-spinning motor has very little current. It is only when a load is applied to the motor that slows the rotor that the current draw through the motor increases.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;From the &lt;a href=&quot;http://en.wikipedia.org/wiki/Counter-electromotive_force&quot;&gt;Counter electromotive force&lt;/a&gt; wikipedia page:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;In &lt;strong&gt;motor control&lt;/strong&gt; and &lt;strong&gt;robotics&lt;/strong&gt;, the term &quot;Back-EMF&quot; often refers to using the voltage generated by a spinning motor to infer the speed of the motor's rotation.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Note however, as &lt;a href=&quot;http://robotics.stackexchange.com/a/644/37&quot;&gt;DrFriedParts explains&lt;/a&gt;, this is only part of the story. The &lt;strong&gt;maximum &lt;em&gt;continuous&lt;/em&gt; stall torque&lt;/strong&gt; may be much lower than the &lt;strong&gt;maximum torque&lt;/strong&gt; and thus current. For instance if you switch from full torque in one direction to full torque in the other. In this case, the current drawn could be double the &lt;em&gt;continuous&lt;/em&gt; stall current. Do this often enough, exceeding the duty cycle of the motor and you could burn out your motor.&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Free Current&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Again, looking at the specification:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;Free Speed:     100 rpm&#xA;Free Current:   0.18 A&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;So when running freely, without load, it will rapidly accelerate up to 100 rpm, where it will draw just 180 mA to maintain that speed given friction and back-emf.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Again however, as &lt;a href=&quot;http://robotics.stackexchange.com/a/644/37&quot;&gt;DrFriedParts explains&lt;/a&gt;, this is also only part of the story. If the motor is being driven by an external force (effectively a -ve load), and thus the motor is turned into a generator, the current drawn may be cancelled out by the current generated by the external force.&lt;/p&gt;&#xA;" OwnerUserId="37" LastEditorUserId="37" LastEditDate="2012-12-11T13:37:16.057" LastActivityDate="2012-12-11T13:37:16.057" CommentCount="2" />
  <row Id="616" PostTypeId="1" AcceptedAnswerId="618" CreationDate="2012-12-03T05:36:41.723" Score="4" ViewCount="845" Body="&lt;p&gt;I've found that Arduino (Duemilanove) has a current limit of 40mA per pin. Does this include the V&lt;sub&gt;in&lt;/sub&gt; pin? Or does the V&lt;sub&gt;in&lt;/sub&gt; pin have some sort of work around in place on the board to allow for higher currents?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If this is the limit on the V&lt;sub&gt;in&lt;/sub&gt;, is there good way of using still using the power supply jack on the board and allowing other sources to draw on that supply without it needing to pass through the chip first?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thank you much.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT: For the second part, what should I do if I wanted to get up to something like 2 amps?&lt;/p&gt;&#xA;" OwnerUserId="457" LastEditorUserId="457" LastEditDate="2012-12-03T16:58:56.343" LastActivityDate="2012-12-03T19:41:16.703" Title="Arduino Vin Current Limit" Tags="&lt;arduino&gt;&lt;current&gt;" AnswerCount="2" CommentCount="3" />
  <row Id="617" PostTypeId="2" ParentId="616" CreationDate="2012-12-03T13:06:45.607" Score="1" Body="&lt;p&gt;According to &lt;a href=&quot;http://arduino.cc/forum/index.php/topic,27480.0.html&quot; rel=&quot;nofollow&quot;&gt;this discussion on the Arduino forums&lt;/a&gt;, you can draw about 1 amp through the V&lt;sub&gt;in&lt;/sub&gt; pin before frying the &quot;polarity protection&quot; diode that sits between the power supply and the pin. &lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2012-12-03T13:06:45.607" CommentCount="5" />
  <row Id="618" PostTypeId="2" ParentId="616" CreationDate="2012-12-03T19:41:16.703" Score="8" Body="&lt;p&gt;The 40mA current limit is the Absolute Maximum that an I/O pin on the &lt;a href=&quot;http://www.atmel.com/Images/doc8161.pdf&quot;&gt;ATmega328P&lt;/a&gt; can supply. V&lt;sub&gt;cc&lt;/sub&gt; on the ATmega can draw up to 200mA.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From page 313 of the datasheet:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/4LNpY.png&quot; alt=&quot;absolute maximums&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The 5V that connects to V&lt;sub&gt;cc&lt;/sub&gt; and powers your chip comes from one of two places. Either the USB connection, which in most cases is limited to supplying 500mA. Or an external power supply (wall wort or otherwise) which can supply as much current as is labeled on package.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;V&lt;sub&gt;in&lt;/sub&gt; is your external power supply if connected. USBVCC is your USB power if connected. +5V is whichever has a higher voltage.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You seem to be interested in using an external power supply to run your Arduino and a motor. No problem. You just need to branch off of V&lt;sub&gt;in&lt;/sub&gt; &lt;em&gt;before&lt;/em&gt; the regulator that turns V&lt;sub&gt;in&lt;/sub&gt; into +5V and powers your chip.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Have a look at this &lt;a href=&quot;http://www.ladyada.net/make/mshield/use.html&quot;&gt;Motor Shield tutorial by Adafruit&lt;/a&gt;. In the below diagram, they are powering a motor off of a +9V V&lt;sub&gt;in&lt;/sub&gt;. In this diagram they are branching off &lt;em&gt;before&lt;/em&gt; IC1 which is a 78L05Z. On your &lt;a href=&quot;http://arduino.cc/en/uploads/Main/arduino-duemilanove-schematic.pdf&quot;&gt;Duemilanove&lt;/a&gt;, this should be IC4, an MC33269.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/QjjOZ.png&quot; alt=&quot;motor shield connection&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This way the motor can take as much current as it wants from your external supply. And the AVR microcontroller can take as much current as it wants and be protected from any nasty spikes the motor puts on the line by the MC33269 voltage regulator.&lt;/p&gt;&#xA;" OwnerUserId="142" LastActivityDate="2012-12-03T19:41:16.703" CommentCount="1" />
  <row Id="619" PostTypeId="1" CreationDate="2012-12-03T21:00:24.960" Score="5" ViewCount="121" Body="&lt;p&gt;How do you program an &lt;a href=&quot;http://en.wikipedia.org/wiki/Electronic_speed_control&quot; rel=&quot;nofollow&quot;&gt;ESC&lt;/a&gt; to have a reverse mode? We're looking to control an ESC from a servo board (for a &lt;a href=&quot;http://greymatterrobotics.com/2012/09/18/the-hoverbot/&quot; rel=&quot;nofollow&quot;&gt;robotics project&lt;/a&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Assuming that the input will be between 0 and 255, we're looking for 127 as off, 255 as fully forward and 0 as full reverse, so how do we achieve that?&lt;/p&gt;&#xA;" OwnerUserId="459" LastEditorUserId="37" LastEditDate="2012-12-05T02:56:44.090" LastActivityDate="2014-01-12T05:07:22.150" Title="Programming an ESC to have reverse mode" Tags="&lt;control&gt;&lt;motor&gt;" AnswerCount="2" FavoriteCount="0" />
  <row Id="620" PostTypeId="2" ParentId="619" CreationDate="2012-12-03T21:27:50.920" Score="5" Body="&lt;p&gt;It varies from manufacturers. Some ESC allow reverse, or disabled reverse and allow breaks instead, or some combination (break for 5 seconds, then reverse). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;for example &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/__415__182__ESC_UBEC_VR-Programming_Cards.html&quot;&gt;HobbyKing&lt;/a&gt; has a bunch of programmers to make changing it easier. In most cases the same thing can be done with radio controls, although it generally is a bit more challenging.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I looked at your page a bit but did not see a reference to which speed control (ESC) you are going to use. If you have not chosen one yet, be aware that they usually come with instructions for programming reverse handling, timing etc.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Your assumptions about input seems reasonable, and is what I think you will find once you get going.&lt;/p&gt;&#xA;" OwnerUserId="274" LastActivityDate="2012-12-03T21:27:50.920" CommentCount="4" />
  <row Id="621" PostTypeId="2" ParentId="583" CreationDate="2012-12-03T23:15:18.693" Score="1" Body="&lt;p&gt;An iterative IK solver is capable of dealing with many kinds of constraints. I have already talked about this kind of solver in a &lt;a href=&quot;http://robotics.stackexchange.com/a/308/40&quot;&gt;previous answer&lt;/a&gt;. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The basic algorithm would look something like this:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;Move each joint to it's halfway position&#xA;&#xA;loop while arm is far from target&#xA;{&#xA;    calculate gradient vector&#xA;    add gradient vector to arm position vector&#xA;    if any joints are beyond their range, move them back into their range.&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;The nice thing about the iterative solver is that it can also handle 'soft' constraints. For example, you might want a humanoid arm to maintain a comfortable looking posture where possible. Or you might prefer to keep joints away from their end stops. In that case, you can simply add those constraints into the loop&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;Move each joint to it's halfway position&#xA;&#xA;loop while arm is far from target&#xA;{&#xA;    calculate gradient vector&#xA;    add gradient vector to arm position vector&#xA;&#xA;    calculate comfort vector&#xA;    add comfort vector to arm position vector&#xA;&#xA;    if any joints are beyond their range, move them back into their range.&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;In this case, the comfort vector is the direction in which to move all of the joints so that the arm appears more comfortable.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A fuller explanation of this can be found on my old web site: &lt;a href=&quot;http://freespace.virgin.net/hugo.elias/models/m_ik2.htm&quot; rel=&quot;nofollow&quot;&gt;The good-looking textured light-sourced bouncy fun smart and stretchy page&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-12-03T23:15:18.693" />
  <row Id="622" PostTypeId="2" ParentId="419" CreationDate="2012-12-03T23:41:26.080" Score="3" Body="&lt;p&gt;To get relative displacement between two time instants all you need to do is integrate the values given off by the accelerometer (twice for linear displacement) and gyro (once for angular displacement).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Due to measurement errors, which can many times be adequately modeled as Gaussian (you might have to estimate a bias and/or scale factor to the measurement), there will be drift in your estimate (i.e. errors accumulate and your estimate diverges). Because of that, if you plan to use the IMU to obtain position and orientation estimates relative to a fixed frame, you will also have to use more information to correct that estimate. These corrections can be made using a &lt;a href=&quot;http://tom.pycke.be/mav/71/kalman-filtering-of-imu-data&quot; rel=&quot;nofollow&quot;&gt;Kalman Filtering&lt;/a&gt; approach.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Many people use the accelerometer and magnetometer data to do that, assuming your robot isn't moving too fast (i.e. $g \gg a_{robot}$), there aren't many magnetic field disturbances (i.e. $m_{earth} \gg m_{other\_stuff}$), and both vectors are perpendicular and have fixed orientation with respect to the ground. See, for instance, the &lt;a href=&quot;http://en.wikipedia.org/wiki/Triad_method&quot; rel=&quot;nofollow&quot;&gt;TRIAD algorithm&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But then again, back to your question, if what you mean by &quot;robot has displaced itself forward since a previous measurement&quot; is:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Relative to his own body&lt;/strong&gt;, regardless of his orientation in space, all you need to do is check the sign of the accelerometer output in the forward direction (you might want to set a minimum threshold or perform median filtering due to sensor noise)&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Relative to a fixed frame&lt;/strong&gt;, you have to take everything I talked about into consideration&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="95" LastActivityDate="2012-12-03T23:41:26.080" />
  <row Id="623" PostTypeId="1" CreationDate="2012-12-03T23:48:59.127" Score="6" ViewCount="140" Body="&lt;p&gt;I'm building an open-source bio-research hardware (ask me how you can help!) and I've got this guy here:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/MZw6q.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My big questions are:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Can I get away with all the ground being common? (I've got a 12v and 5v needing to be grounded)&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Do I need two sets of capacitors? There are 2 wired up to the 12v regulator and 2 wired to the 5v regulator. (These are shown in blue)&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;I've generally denoted connections which go UNDER the shield as orange, and those above as green.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If anyone happens to see something which might backfire, feel free to point it out. As this is also my first time making anything quite like this!&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I've verified the regulator positions and they are correct.&lt;/li&gt;&#xA;&lt;li&gt;This is a &lt;a href=&quot;http://www.nkcelectronics.com/Protoshield-KIT-for-Arduino-UNO-R3_p_308.html&quot; rel=&quot;nofollow&quot;&gt;proto-shield&lt;/a&gt; for an Arduino R3 Uno.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;A larger version of the image can be seen here: &lt;a href=&quot;http://i.imgur.com/BPXjn.jpg&quot; rel=&quot;nofollow&quot;&gt;http://i.imgur.com/BPXjn.jpg&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="111" LastEditorUserId="158" LastEditDate="2012-12-04T17:37:23.687" LastActivityDate="2012-12-04T17:37:23.687" Title="When taking VCC power from an arduino to a 12v regulator, then to a 5v, do I need two sets of capacitors?" Tags="&lt;arduino&gt;&lt;electronics&gt;" AnswerCount="1" CommentCount="2" />
  <row Id="624" PostTypeId="2" ParentId="623" CreationDate="2012-12-03T23:57:39.417" Score="6" Body="&lt;h3&gt;Can I get away with all the ground being common?&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;That's exactly what should be done.&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Do I need two sets of capacitors?&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Yes, you usually want to keep all capacitors as they are even if you are cascading voltage regulators. They help keep the regulator stable and avoid sharp voltage variations. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Be aware that either regulator might limit the amount of current that can be supplied to your system (if you have things hooked up in the 12V regulator besides the 5V regulator, for instance).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I find it odd that you need a 12V regulator though... Where is the input voltage coming from?&lt;/p&gt;&#xA;" OwnerUserId="95" LastEditorUserId="37" LastEditDate="2012-12-04T17:37:11.660" LastActivityDate="2012-12-04T17:37:11.660" CommentCount="10" />
  <row Id="625" PostTypeId="2" ParentId="138" CreationDate="2012-12-05T09:13:23.187" Score="0" Body="&lt;p&gt;The &lt;a href=&quot;http://books.google.com/books/about/Springer_Handbook_of_Robotics.html?id=Xpgi5gSuBxsC&amp;amp;redir_esc=y&quot; rel=&quot;nofollow&quot;&gt;&lt;em&gt;Springer Handbook of Robotics&lt;/em&gt;&lt;/a&gt; is a good resource that explains what the requirements are for any particular robotic field you want to specialize in.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://bks2.books.google.com/books?id=Xpgi5gSuBxsC&amp;amp;printsec=frontcover&amp;amp;img=1&amp;amp;zoom=1&quot; alt=&quot;Springer Handbook of Robotics&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="558" LastEditorUserId="350" LastEditDate="2012-12-05T18:10:51.037" LastActivityDate="2012-12-05T18:10:51.037" />
  <row Id="626" PostTypeId="2" ParentId="565" CreationDate="2012-12-05T12:45:19.730" Score="4" Body="&lt;p&gt;&lt;a href=&quot;http://openkinect.org/wiki/Main_Page&quot; rel=&quot;nofollow&quot;&gt;OpenKinect&lt;/a&gt; is a community of people, not a library. The OpenKinect community releases the &lt;a href=&quot;https://github.com/OpenKinect/libfreenect&quot; rel=&quot;nofollow&quot;&gt;libfreenect&lt;/a&gt; Kinect driver. libfreenect and &lt;a href=&quot;http://openni.org/&quot; rel=&quot;nofollow&quot;&gt;OpenNI&lt;/a&gt;+&lt;a href=&quot;https://github.com/avin2/SensorKinect&quot; rel=&quot;nofollow&quot;&gt;SensorKinect&lt;/a&gt; are two competing, opensource libraries/drivers. libfreenect (Apache 2.0 or GPLv2) derives from the initial, reverse-engineered/hacked Kinect driver whereas OpenNI+SensorKinect is derived from open sourced (LGPL) PrimeSense code.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Both projects work on Windows, Linux (Ubuntu), and Mac OS X. Both projects allow you to access color and depth images from the camera. The projects are not compatible and they can not be used simultaneously.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Differences between the libraries are motor control (libfreenect has it, OpenNI+SensorKinect doesn't), and integration with the NITE middleware for higher-level NUI support (OpenNI+SensorKinect only). These differences tend to drive projects towards one of the libraries.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;See also:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/q/6086981/42473&quot;&gt;What is the difference between OpenNI and OpenKinect?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/q/7706448/42473&quot;&gt;Official Kinect SDK vs. Open-source alternatives&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="558" LastEditorUserId="37" LastEditDate="2012-12-07T16:50:08.477" LastActivityDate="2012-12-07T16:50:08.477" CommentCount="1" />
  <row Id="627" PostTypeId="1" AcceptedAnswerId="633" CreationDate="2012-12-05T08:04:45.150" Score="1" ViewCount="320" Body="&lt;p&gt;I have a Panda Board ES. I am not able to get it to boot. I sent it back to SVTronics to get it checked and they said that the board is OK; I am the one who is not able to configure it properly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;After doing a little research and following all the directions on the Panda Board and Ubuntu website, I am still not able to get the board to boot. I think the problem is how I am formatting the SD card. I am using disk utility for Mac to format the SD card to &quot;MSDOS(FAT)&quot; partition.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would like to know how to format an &quot;SD Card&quot; on a Macintosh to install Ubuntu on it for Panda Board ES.&lt;/p&gt;&#xA;" OwnerUserId="573" OwnerDisplayName="Killer_Alien_Monk" LastEditorUserId="38" LastEditDate="2012-12-13T15:34:38.153" LastActivityDate="2012-12-13T15:34:38.153" Title="Formatting an SD card for Panda Board ES" Tags="&lt;electronics&gt;&lt;operating-systems&gt;" AnswerCount="1" CommentCount="5" />
  <row Id="628" PostTypeId="1" CreationDate="2012-12-05T18:40:54.230" Score="15" ViewCount="1372" Body="&lt;p&gt;For this question assume that the following things are unknown:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The size and shape of the room&lt;/li&gt;&#xA;&lt;li&gt;The location of the robot&lt;/li&gt;&#xA;&lt;li&gt;The presence of any obstacles&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Also assume that the following things are constant:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The size and shape of the room&lt;/li&gt;&#xA;&lt;li&gt;The number, shape and location of all (if any) obstacles&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;And assume that the robot has the following properties:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It can only move forward in increments of absolute units and turn in degrees. Also the operation that moves will return true if it succeeded or false if it failed to move due to an obstruction&lt;/li&gt;&#xA;&lt;li&gt;A reasonably unlimited source of power (let's say it is a solar powered robot placed on a space station that faces the sun at all times with no ceiling)&lt;/li&gt;&#xA;&lt;li&gt;Every movement and rotation is carried out with absolute precision every time (don't worry about unreliable data)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Finally please consider the following properties of the robot's environment:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Being on a ceiling-less space station the room is a safe but frustratingly close distance to passing comets, so the dust (and ice) are constantly littering the environment.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;I was asked a much simpler version of this question (room is a rectangle and there are no obstacles, how would you move over it guaranteeing you could over every part at least once) and after I started wondering how you would approach this if you couldn't guarantee the shape or the presence of obstacles. I've started looking at this with &lt;a href=&quot;http://en.wikipedia.org/wiki/Dijkstra%27s_algorithm&quot;&gt;Dijkstra's algorithm&lt;/a&gt;, but I'm fascinated to hear how others approach this (or if there is a well accepted answer to this? (How does Roomba do it?)&lt;/p&gt;&#xA;" OwnerUserId="559" LastEditorUserId="163" LastEditDate="2012-12-05T19:39:54.070" LastActivityDate="2013-01-10T14:12:12.573" Title="What algorithm should I implement to program a room cleaning robot?" Tags="&lt;mobile-robot&gt;&lt;artificial-intelligence&gt;&lt;algorithm&gt;&lt;coverage&gt;&lt;theory&gt;" AnswerCount="4" CommentCount="2" FavoriteCount="6" />
  <row Id="629" PostTypeId="2" ParentId="628" CreationDate="2012-12-05T19:01:33.410" Score="6" Body="&lt;p&gt;Roomba starts in a spiral until it hits something, then does a perimeter sweep. Then it just bounces around. Roomba being the de facto standard in household robotic vaccum cleaners, I guess you could call it the &quot;accepted solution&quot;. But from personal experience (I own two), there is definitely room for improvement.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From &lt;a href=&quot;http://electronics.howstuffworks.com/gadgets/home/robotic-vacuum2.htm&quot; rel=&quot;nofollow&quot;&gt;How Stuff Works&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/AtbSs.jpg&quot; alt=&quot;algorithm&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From &lt;a href=&quot;http://www.electronicsinfoline.com/News/New_Gadgets/Robotics/botjunkie-interview-nancy-dussault-smith-on-irobot-s-roomba.html&quot; rel=&quot;nofollow&quot;&gt;an interview&lt;/a&gt; with Nancy Dussault Smith, Vice President of Marketing Communications at iRobot:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;When it starts you’ll notice a spiral pattern, it’ll spiral&#xA;  out over a larger and larger area until it hits an object. When it&#xA;  finds an object, it will follow along the edge of that object for a&#xA;  period of time, and then it will start cris-crossing, trying to figure&#xA;  out the largest distance it can go without hitting another object, and&#xA;  that’s helping it figure out how large the space is, but if it goes&#xA;  for too long a period of time without hitting a wall, it’s going to&#xA;  start spiraling again, because it figures it’s in a wide open space,&#xA;  and it’s constantly calculating and figuring that out. &lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;It’s similar&#xA;  with the dirt sensors underneath, when one of those sensors gets&#xA;  tripped it changes its behaviors to cover that area. It will then go&#xA;  off in search of another dirty area in a straight path. The way that&#xA;  these different patterns pile on to each other as they go, we know&#xA;  that that is the most effective way to cover a room. &lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;The patterns that&#xA;  we chose and how the algorithm was originally developed was based off&#xA;  of behavior-based algorithms born out of MIT studying animals and how&#xA;  they go about searching areas for food. When you look at how ants and&#xA;  bees go out and they search areas, these kinds of coverage and&#xA;  figuring all of that out comes from that research. It’s not exact,&#xA;  obviously, I’m not saying we’re honeybees, but it’s that understanding&#xA;  of how to search out an area in nature that is the basis behind how&#xA;  our adaptive technology is developed.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Some long exposure pics of Roombas with LEDs on them illustrate how it works in practice:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://news.cnet.com/8301-17938_105-20080916-1/vac-hack-lets-roomba-test-air-quality-too/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/YaWBns.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt;&#xA;&lt;a href=&quot;http://artstormer.com/2012/04/08/roomba-light-paintings-created-with-leds-attached-to-vacuums/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/Emsh0s.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt;&#xA;&lt;a href=&quot;http://www.petapixel.com/2011/06/30/light-painting-art-done-using-swarms-of-robot-vacuum-cleaners/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/8pVKMs.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="142" LastEditorUserId="350" LastEditDate="2013-01-10T14:12:12.573" LastActivityDate="2013-01-10T14:12:12.573" CommentCount="2" />
  <row Id="630" PostTypeId="2" ParentId="628" CreationDate="2012-12-05T19:18:03.210" Score="4" Body="&lt;p&gt;The first thing you need to establish is the goal of the robot -- not quite clear from your question.  There are two main tasks that your robot has to accomplish: discovering the shape of the clean-able area, and then cleaning it.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;But is the amount of dirt constant?  Is dirt added constantly?  Is it your goal to minimize the average time that dirt remains on the floor, or the median time?  Is the goal to keep the floor equally clean?  Or is it just to clean once, as quickly as possible?  Are there patterns in the accumulation of dirt that you can measure and use to your advantage in accomplishing your goal?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The answer to these questions will help guide what algorithm you choose.  In the Roomba's robot's case, there might be no point learning the exact layout of the room because furniture (like chairs around a table), people, and other obstacles move very often.  However, in your case it might be better to explore the space to build a complete map (some combination of a lawnmower pattern with finding edges), then use that map to compute the shortest path through the space (the term is &quot;coverage&quot;, and there are several ways to do it e.g. &lt;a href=&quot;http://www.cs.cmu.edu/~motionplanning/papers/sbp_papers/integrated4/gabriely_spanning.pdf&quot;&gt;spanning tree algorithm&lt;/a&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One more thing you'll need to worry about is how to discretize the space you're in.  Because you can move in any direction -- even with integer degree amounts and integer units of distance -- your X and Y positions can have fractional values.  You'll need to decide how to represent obstacles on that map without having it grow to an infinite number of data points.  &lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2012-12-05T19:18:03.210" CommentCount="1" />
  <row Id="631" PostTypeId="2" ParentId="628" CreationDate="2012-12-05T19:21:27.970" Score="4" Body="&lt;p&gt;Neato uses an organized approach. Using SLAM and bumpers, it maps the 'current' room, perimeter first, then applies some algorithm for cleaning as efficiently as possible.  I've never owned a Roomba, but given what I have read about it's algorithm, I would never switch from a neato.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The Laser Range Finder in the neato is often &lt;a href=&quot;http://www.hizook.com/blog/2009/12/20/ultra-low-cost-laser-rangefinders-actualized-neato-robotics&quot; rel=&quot;nofollow&quot;&gt;cannabilized&lt;/a&gt; for robotics, as it is a cost effective sensor for SLAM algorithms.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If I was given your task, First I would find a suitable &lt;a href=&quot;http://openslam.org/&quot; rel=&quot;nofollow&quot;&gt;SLAM implementation&lt;/a&gt;, based on the hardware I had.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then I would use a &lt;a href=&quot;http://link.springer.com/article/10.1007/s001700170013?LI=true#page-1&quot; rel=&quot;nofollow&quot;&gt;CNC ISLAND Motion planning&lt;/a&gt; algorithm. My experience is they tend to be very efficient at covering an arbitrary area with the least amount of movement.&lt;/p&gt;&#xA;" OwnerUserId="274" LastActivityDate="2012-12-05T19:21:27.970" CommentCount="5" />
  <row Id="632" PostTypeId="2" ParentId="628" CreationDate="2012-12-05T19:39:29.200" Score="10" Body="&lt;p&gt;As far as I know, this problem hasn't been &quot;solved.&quot;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Formally, this is an online coverage problem. Coverage, because we must cover each point on the floor, and online because we do not have offline access to the map. If you are interested in the most recent results, I suggest you lookup &quot;&lt;strong&gt;robotic online coverage algorithms&lt;/strong&gt;,&quot; perhaps in google scholar (there are &lt;em&gt;lots and lots&lt;/em&gt; of great results). In addition to @embedded.kyle's very colorful (re)post, I'll add some details (I'll also try to quickly find a few simple results):&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Dijkstra's will get you a path, but not necessarily a coverage. For example, how do you specify to Dijkstra's that you must visit &lt;em&gt;each&lt;/em&gt; point in the graph, instead of visiting &lt;em&gt;one&lt;/em&gt; point as quickly as possible? You can run all-pairs shortest paths, but what are the points? You don't have a map.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Online algorithms like this are often called &quot;bug&quot; algorithms because they tend to look like a bug wandering across an area, bumping into something, then wandering around it a bit.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;With no obstacles, and a rectangular room, and assuming you start on the &lt;em&gt;boundary&lt;/em&gt; a boustrophedon (way of the ox) path is optimal. &#xA;&lt;img src=&quot;http://i.stack.imgur.com/XYE6t.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Funny that farmers have been doing this forever, right? &lt;a href=&quot;http://en.wikipedia.org/wiki/Boustrophedon&quot;&gt;http://en.wikipedia.org/wiki/Boustrophedon&lt;/a&gt;. This can be extended to rooms with obstacles by finding roughly-rectangular area which are free of obstacles. &lt;a href=&quot;http://www.ri.cmu.edu/publication_view.html?pub_id=1416&quot;&gt;Howie Choset worked on this a bit&lt;/a&gt;. &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;To cover an area with unknown perimeter, and assuming you &lt;em&gt;don't&lt;/em&gt; start on the perimeter, what is the optimal strategy? Well, imagine you drop into the world, and can't see the perimeter. You can walk in a straight line until you reach the perimeter, then do a boustrophedon, right? Except now you &quot;wasted&quot; the time spent finding the perimeter, because you will cover that part twice.  This is why robots tend to spiral: By the time you reach a boundary, you have covered a lot of the area ($\pi*d^2$ where $d$ is the distance to the &lt;em&gt;nearest&lt;/em&gt; boundary, right?). This is helpful: now you are guaranteed to find the nearest boundary, and can trace it out.&lt;/li&gt;&#xA;&lt;li&gt;This is a huge, fascinating area. I'm sorry I can't provide a better summary! &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The biggest problem is you don't have a map. Without a map, you are limited to simple actions like perimeter following, and moving along a path (like the spiral mentioned).  So, there exist some robots that actually build the map while cleaning, decompose the mapped-out area into shapes, then cover each shape to ensure coverage. See: &lt;a href=&quot;http://mintcleaner.com/&quot;&gt;http://mintcleaner.com/&lt;/a&gt;  &lt;/p&gt;&#xA;" OwnerUserId="163" LastEditorUserId="163" LastEditDate="2012-12-05T20:06:19.247" LastActivityDate="2012-12-05T20:06:19.247" />
  <row Id="633" PostTypeId="2" ParentId="627" CreationDate="2012-12-05T19:55:01.567" Score="2" Body="&lt;p&gt;It's possible that your problem is not the filesystem format (although you should probably using Linux EXT2/EXT3/EXT4 instead of MS-DOS/FAT).  Is the bootloader installed properly? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here are some posts on putting an Ubuntu bootloader on an SD card:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://askubuntu.com/questions/191902/how-to-boot-ubuntu-from-my-sd-card&quot;&gt;http://askubuntu.com/questions/191902/how-to-boot-ubuntu-from-my-sd-card&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://bbs.archlinux.org/viewtopic.php?pid=760477&quot; rel=&quot;nofollow&quot;&gt;https://bbs.archlinux.org/viewtopic.php?pid=760477&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;More broadly, have you looked at this wiki, dedicated to putting Ubuntu on Panda boards?&#xA;&lt;a href=&quot;http://www.omappedia.org/wiki/OMAP_Ubuntu_Main&quot; rel=&quot;nofollow&quot;&gt;http://www.omappedia.org/wiki/OMAP_Ubuntu_Main&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2012-12-05T19:55:01.567" CommentCount="1" />
  <row Id="634" PostTypeId="1" AcceptedAnswerId="635" CreationDate="2012-12-05T20:03:56.590" Score="4" ViewCount="1140" Body="&lt;p&gt;From what I've seen, LiFePO4 batteries seem like one of the top battery choices for robotics applications. However, I've seen people mentioning that you can't use a charger for a different battery to charge these, but I haven't seen why. If I were to build my own setup to charge LiFePO4 batteries what would it specifically need to do? What kind of voltages or current rates does it need to supply to charge these?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;More specifically, I was think about setting up a solar charger for these batteries. Is there any immediate reason why this is a bad solution? Such as, the battery needs to charge with a current above some amount for it to work properly?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you're ambitious enough to provide an example along with your explanation, I'm specifically thinking of having &lt;a href=&quot;http://www.batteryspace.com/lifepo426650cell32v3300mah16.5arate10whunapproved.aspx&quot; rel=&quot;nofollow&quot;&gt;4 of these batteries&lt;/a&gt; with 2 pairs of 2 in series in parallel. &lt;/p&gt;&#xA;" OwnerUserId="457" LastActivityDate="2013-08-29T22:00:40.263" Title="How to charge a LiFePO4 battery?" Tags="&lt;batteries&gt;" AnswerCount="2" />
  <row Id="635" PostTypeId="2" ParentId="634" CreationDate="2012-12-05T20:13:58.417" Score="6" Body="&lt;p&gt;This is one of those questions where if you have to ask, you shouldn't be doing it.  There are charge-monitoring boards available for these batteries, and for safety's sake you should be using them.  You can still use a solar charger or some other method, but the output of that power source should feed a charge circuit that was built specifically for LiFePO&lt;sub&gt;4&lt;/sub&gt; batteries.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You're not so much looking for a battery charger as you are a &quot;battery manager&quot;.  You need something that will &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;prevent over-discharging (both current and voltage)&lt;/li&gt;&#xA;&lt;li&gt;prevent over-charging (both current and voltage)&lt;/li&gt;&#xA;&lt;li&gt;detect raised temperature (indicating some sort of failure)&lt;/li&gt;&#xA;&lt;li&gt;actually charge the battery&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Off-the-shelf LiFePO&lt;sub&gt;4&lt;/sub&gt; chargers accomplish the charging in 3 stages:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Supply constant current (correct amount is specific to battery model) until the cell voltage hits its maximum&lt;/li&gt;&#xA;&lt;li&gt;Supply constant voltage until the charge current hits some minimum, usually related to the initial charge current.&lt;/li&gt;&#xA;&lt;li&gt;Maintain the charge by lowering the voltage slightly, and making other adjustments (I'm not completely clear on this part)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;This is more of a pure-EE project than a robotics project, so if you are dead-set on building this then you should consult a more electronics-centric resource.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2012-12-05T21:27:42.303" LastActivityDate="2012-12-05T21:27:42.303" CommentCount="6" />
  <row Id="636" PostTypeId="1" AcceptedAnswerId="638" CreationDate="2012-12-06T02:36:00.553" Score="10" ViewCount="179" Body="&lt;p&gt;Many people claim that turning an NXT motor by hand will damage it. Is this true? Does it matter if the motor is idle or set on break? Are there any facts to confirm or refute this argument? I know that some projects (e.g. etch-a-sketch) use the built-in rotation sensor to measure how much the motor has turned. Does this indicate that hand-turning NXT motors is okay? Do they need to be put in a special 'rotation sensor' mode?&lt;/p&gt;&#xA;" OwnerUserId="38" LastEditorUserId="158" LastEditDate="2012-12-06T20:17:47.967" LastActivityDate="2012-12-06T20:17:47.967" Title="Will turning an NXT motor by hand damage it?" Tags="&lt;motor&gt;&lt;nxt&gt;&lt;mindstorms&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="637" PostTypeId="1" AcceptedAnswerId="640" CreationDate="2012-12-06T04:49:17.513" Score="6" ViewCount="159" Body="&lt;p&gt;I have built a robot from a wheelchair that has worked very well thus far. It is now time for me to take the next step. I need to implement a permanent power circuit with proper protection. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The lowest level of protection I can think of is a fuse, but I would like to take a step further (current/voltage/direction/switches/High/Low voltages). If some one could give some insight on this project of mine any info will be greatly appreciated.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Moderator comment:&lt;/strong&gt;  Please see &lt;a href=&quot;http://meta.robotics.stackexchange.com/questions/5/how-do-we-address-questions-about-related-subject-areas&quot;&gt;How do we address questions about related subject areas?&lt;/a&gt; before answering.  This question is close to the boundary, but is on-topic here.&lt;/p&gt;&#xA;" OwnerUserId="565" LastEditorUserId="134" LastEditDate="2013-01-06T08:43:00.293" LastActivityDate="2013-01-10T11:33:17.867" Title="Protecting electronics against voltage/current extremes and bad polarity" Tags="&lt;mobile-robot&gt;&lt;wheeled-robot&gt;&lt;protection&gt;&lt;circuit&gt;" AnswerCount="2" CommentCount="4" />
  <row Id="638" PostTypeId="2" ParentId="636" CreationDate="2012-12-06T05:48:54.433" Score="11" Body="&lt;p&gt;In general, no, it will not hurt the motor directly, BUT, the motor is geared down considerably. This means that when you turn the exterior part that you can physically touch by 1/4 turn - the motor might have actually completed 5 full rotations. The problem can happen when you turn the servo too fast, it may cause gear breakage simply due to excess speed internally.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It does not hurt the motor, but it may break a gear. Simple solution is to just not turn it fast.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If the motor is set on 'brake', it will apply opposite power to counter your turns, but you're not going to really hurt anything by over powering it, slowly! It is easier to turn if the motor is not in brake mode.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, in RobotC, this code releases the 'brake'&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;// release motors&#xA;    nSyncedMotors = synchNone;&#xA;    bFloatDuringInactiveMotorPWM = true;&#xA;    nMotorPIDSpeedCtrl[LEFT] = mtrNoReg;&#xA;    nMotorPIDSpeedCtrl[RIGHT] = mtrNoReg;&#xA;    motor[LEFT] = 0;&#xA;    motor[RIGHT] = 0;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="274" LastActivityDate="2012-12-06T05:48:54.433" CommentCount="2" />
  <row Id="640" PostTypeId="2" ParentId="637" CreationDate="2012-12-07T08:10:41.820" Score="6" Body="&lt;p&gt;I think this is a very relevant question for robotics, as you can spent a lot of time fixing your system if something went wrong in this area. Here are a few things to look out for:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Insulation: Ideally you don't want any high voltages to reach your equipment in the first place. So one of the most important rules we apply to our electronics is insulate. Try to have as little conductive surfaces flying around as possible. Especially when you system is moving, having something flying around that is conductive can screw you in the literal sense. insulation tape, tubing whatever are the weapons of choice here.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Connectors: Try never to use connectors that could be plugged the wrong way, or use the same connectors for different ports. Always check your connector thrice on the running system with a voltmeter before connecting it. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Diodes can be useful to prevent overvoltage or reverse polarity, they are however useless if your power source is very powerfull, burns your diode, and gets through anyway. That is what a &lt;a href=&quot;http://en.wikipedia.org/wiki/Crowbar_%28circuit%29&quot; rel=&quot;nofollow&quot;&gt;crowbar circuit&lt;/a&gt; will prevent. Its a combination of a fuse and a diode and will fix both overvoltage/overcurrent and reverse current. There are integrated parts available, and I've also successfully used &lt;a href=&quot;http://ae.rsdelivers.com/product/te-connectivity/zen056v130a24ls/polyzen-polymer-protected-diode-56v/0494723.aspx&quot; rel=&quot;nofollow&quot;&gt;polyfuses&lt;/a&gt; for small equipment.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://electronics.stackexchange.com/questions/7709/why-put-a-resistor-in-series-with-signal-line&quot;&gt;Resistors in series&lt;/a&gt; for data lines are also quite useful as they limit the current flowing through. Something between 50-100 Ohm should usually do the job.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Fuses are generally a good idea, especially when you use power sources with very high current capabilities (e.g. LiPo). &lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="127" LastEditorUserId="127" LastEditDate="2013-01-04T18:30:42.863" LastActivityDate="2013-01-04T18:30:42.863" CommentCount="3" />
  <row Id="641" PostTypeId="1" AcceptedAnswerId="647" CreationDate="2012-12-07T16:29:15.963" Score="1" ViewCount="176" Body="&lt;p&gt;I am working with students (9th &amp;amp; 10th grade) on robotics and wanted to get a good book which covers basic mechanisms.  Does anyone have any recommendations.  Searching Google or Amazon yields many results, however, I thought the community might have a standard book to use.  &lt;/p&gt;&#xA;" OwnerUserId="572" LastEditorUserId="38" LastEditDate="2012-12-11T12:45:09.060" LastActivityDate="2012-12-11T12:45:09.060" Title="Good book on mechanisms" Tags="&lt;design&gt;&lt;mechanism&gt;" AnswerCount="1" CommentCount="5" ClosedDate="2012-12-22T08:32:39.220" />
  <row Id="642" PostTypeId="1" AcceptedAnswerId="643" CreationDate="2012-12-08T05:06:56.877" Score="2" ViewCount="1195" Body="&lt;p&gt;I recently purchased a 3-axis accelerometer from Amazon, and can't seem to find how it works. I've been looking for quite a while now, and haven't found any real clues. The x, y, and z values always seem to return the same values. They change when I tilt or move the accelerometer, but revert to about 120 for each reading. I am currently using this device with the Arduino Uno, using the following code: &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;int x=1,y=2,z=3;&#xA;void setup() {&#xA;  pinMode(x, INPUT);&#xA;  pinMode(y, INPUT);&#xA;  pinMode(z, INPUT); &#xA;  Serial.begin(9600);&#xA;}&#xA;void loop() {&#xA; Serial.println();&#xA; Serial.print(analogRead(x));&#xA; Serial.print(&quot;, &quot;);&#xA; Serial.print(analogRead(y));&#xA; Serial.print(&quot;, &quot;);&#xA; Serial.print(analogRead(z));&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Also, how would I go about converting this to tilt?&lt;/p&gt;&#xA;" OwnerUserId="498" LastEditorUserId="177" LastEditDate="2012-12-08T16:26:05.280" LastActivityDate="2012-12-08T16:26:05.280" Title="MMA7361 Accelerometer Always Displays Same Values" Tags="&lt;arduino&gt;&lt;sensors&gt;&lt;accelerometer&gt;" AnswerCount="1" CommentCount="3" />
  <row Id="643" PostTypeId="2" ParentId="642" CreationDate="2012-12-08T07:13:51.893" Score="3" Body="&lt;p&gt;There is a project on Google Code called &lt;a href=&quot;http://code.google.com/p/mma7361-library/&quot; rel=&quot;nofollow&quot;&gt;MMA7361-library&lt;/a&gt;. The &lt;a href=&quot;http://www.geeetech.com/wiki/index.php/MMA7361_Triple_Axis_Accelerometer_Breakout&quot; rel=&quot;nofollow&quot;&gt;GE Tech Wiki&lt;/a&gt; has a simple example showing how to use this library. Copied inline below for posterity.&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#include &amp;lt;AcceleroMMA7361.h&amp;gt;&#xA;AcceleroMMA7361 accelero;&#xA;int x;&#xA;int y;&#xA;int z;&#xA;void setup()&#xA;{&#xA; Serial.begin(9600);&#xA; accelero.begin(13, 12, 11, 10, A0, A1, A2);&#xA; accelero.setARefVoltage(5); //sets the AREF voltage to 3.3V&#xA; accelero.setSensitivity(LOW); //sets the sensitivity to +/-6G&#xA; accelero.calibrate();&#xA;}&#xA;void loop()&#xA;{&#xA; x = accelero.getXAccel();&#xA; y = accelero.getYAccel();&#xA; z = accelero.getZAccel();&#xA; Serial.print(&quot;\nx: &quot;);&#xA; Serial.print(x);&#xA; Serial.print(&quot; \ty: &quot;);&#xA; Serial.print(y);&#xA; Serial.print(&quot; \tz: &quot;);&#xA; Serial.print(z);&#xA; Serial.print(&quot;\tG*10^-2&quot;);&#xA; delay(500); //make it readable&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="177" LastActivityDate="2012-12-08T07:13:51.893" />
  <row Id="644" PostTypeId="2" ParentId="613" CreationDate="2012-12-09T05:06:39.610" Score="9" Body="&lt;p&gt;&lt;a href=&quot;http://robotics.stackexchange.com/a/614/37&quot;&gt;@Ian&lt;/a&gt; and &lt;a href=&quot;http://robotics.stackexchange.com/a/615/37&quot;&gt;@Mark&lt;/a&gt; offer awesome (and correct) answers. I'll add one extra point for completeness...&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There seems to be trend among less experienced designers to assume that stall current and free current equate to the maximum and minimum currents the motor might encounter. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;They don't.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;They are the &lt;em&gt;effective nominal&lt;/em&gt; values. You can exceed these limits under relatively common circumstances if you are not careful.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Exceeding the minimum&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;As @Ian and @Mark have noted. The motor can turn into a generator (google &quot;regenerative braking&quot;) when an outside source or event causes the motor to move faster than its applied current/voltage. For example, Ian's going down a hill or someone hand cranking the motor. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The current in these situations can not only be less than the free current, but actually go negative (go in the opposite direction -- acts like a source rather than a load).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you think of it from a work (energy) perspective, say you are pushing a box of clothes down a hallway. It doesn't take much effort to do that, but if your buddy starts pushing with you, however little effort you were expending is lessened. That is the case of a motor going down a slight grade.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Exceeding the maximum&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;A secondary consequence of the generation function of the motor is that once it acquires momentum, it continues to convert that energy into electro-motive force (voltage) once power is no longer applied. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The interesting case is when you are reversing directions. If you rev the motor forward, then immediately switch directions, the voltage on the motor coil is momentarily about &lt;em&gt;twice&lt;/em&gt; the previous supply voltage since the motor back-EMF is now in series with the supply. This results, as expected from Ohm's law, in current in excess of stall current.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Practical solution&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;For these reasons, practical bi-directional motor control circuits include &quot;free-wheeling&quot; diodes (D1-D4) in the figure to provide a return path for the back-emf related currents and thereby clamp the voltage to within the supply rails +/- the forward diode voltage. If you are building your own motor control you should include them as well.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/adIDk.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="531" LastEditorUserId="531" LastEditDate="2012-12-14T22:18:24.867" LastActivityDate="2012-12-14T22:18:24.867" CommentCount="1" />
  <row Id="645" PostTypeId="2" ParentId="634" CreationDate="2012-12-09T20:59:45.130" Score="4" Body="&lt;p&gt;Further to @Ian's post, a couple of important comments:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Your Battery Management System (BMS) (not just a simple charger!) needs to monitor the condition of each individual cell, not the set as a whole - this applies during the discharge phase, as well as during charging.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And cell balancing (keeping all cells broadly level) is probably more relevant than simple charge/discharge monitoring.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Day-job non-disclosure requirements limit a long winded answer, but we are developing a BMS using the &lt;a href=&quot;http://www.ti.com/product/bq76pl536a&quot; rel=&quot;nofollow&quot;&gt;TI BQ76PL536A device&lt;/a&gt; to monitor each cell.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But it is not a trivial application.&lt;/p&gt;&#xA;" OwnerUserId="134" LastEditorUserId="350" LastEditDate="2012-12-11T01:55:33.923" LastActivityDate="2012-12-11T01:55:33.923" />
  <row Id="646" PostTypeId="1" AcceptedAnswerId="648" CreationDate="2012-12-10T11:51:14.537" Score="6" ViewCount="381" Body="&lt;p&gt;I am trying to calibrate a MEMS accelerometer. I was able to calibrate it for the current axis which is parallel to gravity and shows correctly, 1g. But the other two axes which should be 0.00g are showing +-0.02g instead. &#xA;So, e.g., when the accelerometer's x axis is parallel to gravity, it should show (1g, 0g, 0g) and not (1g, 0.02g, -0.01g) like now.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How could I eliminate those values, e.g. further calibrate accelerometer? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;EDIT:&lt;/strong&gt; I replaced &lt;em&gt;perpendicular&lt;/em&gt; with &lt;em&gt;parallel&lt;/em&gt; as I mixed-up the words. Sorry for that, now it should make more sense. &#xA;Also, the &lt;a href=&quot;http://www.st.com/internet/com/TECHNICAL_RESOURCES/TECHNICAL_LITERATURE/DATASHEET/CD00091417.pdf&quot; rel=&quot;nofollow&quot;&gt;acelerometer's datasheet&lt;/a&gt; says nothing about calibrating except that &lt;em&gt;The IC interface is factory calibrated for sensitivity (So) and Zero-g level (Off)&lt;/em&gt; (page 20).&lt;/p&gt;&#xA;" OwnerUserId="584" LastEditorUserId="584" LastEditDate="2012-12-11T08:24:15.570" LastActivityDate="2012-12-11T17:17:00.003" Title="MEMS accelerometer calibration" Tags="&lt;design&gt;&lt;electronics&gt;&lt;accelerometer&gt;&lt;calibration&gt;" AnswerCount="1" CommentCount="5" />
  <row Id="647" PostTypeId="2" ParentId="641" CreationDate="2012-12-10T12:35:34.767" Score="5" Body="&lt;p&gt;The best book I have seen on the subject of mechanisms is &lt;a href=&quot;http://www.amazon.co.uk/Mechanisms-Mechanical-Sourcebook-Nicholas-Chironis/dp/0071361693/&quot;&gt;Mechanisms And Mechanical Devices by Neil Sclater and Nicholas P. Chironis&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/0WZ63.jpg&quot; alt=&quot;Mechanisms And Mechanical Devices&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It's got loads of great mechanisms in it, from simple linear movements:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/gQroz.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;... to complex packaging machines:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/arW7F.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It also covers robotics.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2012-12-10T12:35:34.767" />
  <row Id="648" PostTypeId="2" ParentId="646" CreationDate="2012-12-10T15:30:07.040" Score="5" Body="&lt;p&gt;It is possibly a bias in the accelerometer.  The measured non-zero results (like yours) are the bias. No idea if the magnitude of these biases is right, i.e., you may be experiencing more error than you should expect from a bias. To be clear, you can subtract this bias from your estimate of acceleration. However, you should be sure that the bias doesn't change with time. Then you'll need more sophisticated methods. see: &lt;a href=&quot;http://www.vectornav.com/support/library?id=76&quot; rel=&quot;nofollow&quot;&gt;overview of INS&lt;/a&gt; or &lt;a href=&quot;http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05594974&quot; rel=&quot;nofollow&quot;&gt;some literature&lt;/a&gt;&#xA;and &lt;a href=&quot;http://www.analog.com/en/content/td_accelerometer_specifications_definitions/fca.html&quot; rel=&quot;nofollow&quot;&gt;typical accelerometer specs&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Does your datasheet help? There's probably a section on calibration schemes. &lt;a href=&quot;http://www.analog.com/en/mems-sensors/mems-inertial-sensors/adxl345/products/product.html&quot; rel=&quot;nofollow&quot;&gt;For example&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&quot;In a no-turn or single-point calibration scheme, the part is oriented &#xA;such that one axis, typically the z-axis, is in the 1 g field of gravity &#xA;and the remaining axes, typically the x- and y-axis, are in a 0 g&#xA;field. The output is then measured by taking the average of a &#xA;series of samples. The number of samples averaged is a choice of &#xA;the system designer, but a recommended starting point is 0.1 sec &#xA;worth of data for data rates of 100 Hz or greater. This corresponds &#xA;to 10 samples at the 100 Hz data rate. For data rates less than &#xA;100 Hz, it is recommended that at least 10 samples be averaged &#xA;together. These values are stored as X0g, Y0g, and Z+1g for the 0 g&#xA;measurements on the x- and y-axis and the 1 g measurement on &#xA;the z-axis, respectively&quot;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT: Also please compare this error to the specified precision of your sensor. Turns out this small error was not a problem, and not unexpected.&lt;/p&gt;&#xA;" OwnerUserId="163" LastEditorUserId="163" LastEditDate="2012-12-11T17:17:00.003" LastActivityDate="2012-12-11T17:17:00.003" CommentCount="1" />
  <row Id="649" PostTypeId="1" CreationDate="2012-12-10T17:07:02.340" Score="10" ViewCount="176" Body="&lt;p&gt;The optimal sampling-based motion planning algorithm $\text{RRT}^*$ (described &lt;a href=&quot;http://sertac.scripts.mit.edu/web/wp-content/papercite-data/pdf/karaman.frazzoli-ijrr11.pdf&quot; rel=&quot;nofollow&quot;&gt;in this paper&lt;/a&gt;) has been shown to yield collision-free paths which converge to the optimal path as planning time increases. However, as far as I can see, the optimality proofs and experiments have assumed that the path cost metric is Euclidean distance in configuration space. Can $\text{RRT}^*$ also yield optimality properties for other path quality metrics, such as maximizing minimum clearance from obstacles throughout the path?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To define minimum clearance: for simplicity, we can consider a point robot moving about in Euclidean space. For any configuration $q$ that is in the collision-free configuration space, define a function $d(q)$ which returns the distance between the robot and the nearest C-obstacle. For a path $\sigma$, the minimum clearance $\text{min_clear}(\sigma)$ is the minimum value of $d(q)$ for all $q \in \sigma$. In optimal motion planning, one might wish to &lt;strong&gt;maximize&lt;/strong&gt; minimum clearance from obstacles along a path. This would mean defining some cost metric $c(\sigma)$ such that $c$ increases as the minimum clearance decreases. One simple function would be $c(\sigma) = \exp(-\text{min_clear}(\sigma))$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the &lt;a href=&quot;http://sertac.scripts.mit.edu/web/wp-content/papercite-data/pdf/karaman.frazzoli-rss10.pdf&quot; rel=&quot;nofollow&quot;&gt;first paper&lt;/a&gt; introducing $\text{RRT}^*$, several assumptions are made about the path cost metric so that the proofs hold; one of the assumptions concerned additivity of the cost metric, which doesn't hold for the above minimum clearance metric. However, in the more recent &lt;a href=&quot;http://sertac.scripts.mit.edu/web/wp-content/papercite-data/pdf/karaman.frazzoli-ijrr11.pdf&quot; rel=&quot;nofollow&quot;&gt;journal article&lt;/a&gt; describing the algorithm, several of the prior assumptions weren't listed, and it seemed that the minimum clearance cost metric might also be optimized by the algorithm.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Does anyone know if the proofs for the optimality of $\text{RRT}^*$ can hold for a minimum clearance cost metric (perhaps not the one I gave above, but another which has the same minimum), or if experiments have been performed to support the algorithm's usefulness for such a metric?&lt;/p&gt;&#xA;" OwnerUserId="13" LastEditorUserId="163" LastEditDate="2012-12-18T16:16:17.780" LastActivityDate="2013-01-09T17:50:47.877" Title="Does RRT* guarantee asymptotic optimality for a minimum clearance cost metric?" Tags="&lt;motion-planning&gt;&lt;algorithm&gt;&lt;rrt&gt;&lt;theory&gt;" AnswerCount="2" CommentCount="4" FavoriteCount="1" />
  <row Id="650" PostTypeId="1" AcceptedAnswerId="657" CreationDate="2012-12-10T17:44:15.900" Score="-5" ViewCount="1861" Body="&lt;p&gt;I can control a relay from an Android smartphone using Arduino and Bluetooth as seen &lt;a href=&quot;http://bellcode.wordpress.com/2012/01/02/android-and-arduino-bluetooth-communication/&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, it seems too costly to be using Arduino and a Bluetooth receiver for driving a switch. As long as Bluetooth is a radio frequency, is it possible to make a &lt;strong&gt;simple&lt;/strong&gt; Bluetooth receiver which can output 1 or 0 to drive a relay? If yes, how tough that is going to be?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The main factor here is the &lt;strong&gt;cost&lt;/strong&gt;, which should be \$1-$5. &lt;/p&gt;&#xA;" OwnerUserId="587" LastEditorUserId="38" LastEditDate="2012-12-11T12:45:20.727" LastActivityDate="2012-12-13T00:11:58.127" Title="Can I make a simple Bluetooth receiver?" Tags="&lt;sensors&gt;&lt;circuit&gt;" AnswerCount="2" CommentCount="3" FavoriteCount="0" ClosedDate="2012-12-14T01:02:43.470" />
  <row Id="652" PostTypeId="2" ParentId="650" CreationDate="2012-12-10T19:16:26.043" Score="3" Body="&lt;p&gt;The question is a bit vague, but I would say that you at least need to spend ~$16 in a Bluetooth receiver. I have experience with roving networks modules, such as the &lt;a href=&quot;http://www.rovingnetworks.com/products/RN_42&quot; rel=&quot;nofollow&quot;&gt;RN42&lt;/a&gt;, which are easy to set up as wireless serial ports (you can talk to them via &lt;a href=&quot;http://pyserial.sourceforge.net/&quot; rel=&quot;nofollow&quot;&gt;pyserial&lt;/a&gt; or the like).&lt;/p&gt;&#xA;" OwnerUserId="295" LastActivityDate="2012-12-10T19:16:26.043" CommentCount="2" />
  <row Id="653" PostTypeId="1" CreationDate="2012-12-11T02:06:50.120" Score="6" ViewCount="168" Body="&lt;p&gt;I'm a long time &lt;a href=&quot;http://en.wikipedia.org/wiki/Java_%28programming_language%29&quot; rel=&quot;nofollow&quot;&gt;Java&lt;/a&gt; developer who is starting to learn on the &lt;a href=&quot;http://en.wikipedia.org/wiki/Lego_Mindstorms_NXT_2.0&quot; rel=&quot;nofollow&quot;&gt;Lego Mindstorms NXT 2.0&lt;/a&gt;. Are there any limitations to using the Java API? Which language is the most robust on the platform?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I found a post, &lt;a href=&quot;http://robotics.stackexchange.com/questions/578/lego-nxt-programming-tip%29&quot;&gt;&lt;em&gt;Which programming language should I use with the NXT?&lt;/em&gt;&lt;/a&gt; which mentions many of the alternatives. The answer is helpful, but doesn't mention the different languages' limitations.&lt;/p&gt;&#xA;" OwnerUserId="585" LastEditorUserId="1906" LastEditDate="2013-11-15T01:10:18.893" LastActivityDate="2013-11-15T01:10:18.893" Title="What are the notable limitations on using Java with Mindstorms NXT 2.0?" Tags="&lt;nxt&gt;&lt;programming-languages&gt;&lt;mindstorms&gt;" AnswerCount="1" CommentCount="6" FavoriteCount="1" />
  <row Id="654" PostTypeId="1" AcceptedAnswerId="660" CreationDate="2012-12-11T09:58:33.730" Score="16" ViewCount="4763" Body="&lt;p&gt;As I see there is a huge price gap between the two \$223 vs \$99 (at amazon).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My intention is to use one of those from Ubuntu linux to perform depth sensing, navigation etc. and naturally I prefer the cheaper. &#xA;However I am not sure if I miss some important point while betting on the Kinect for Xbox version. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;As it seems the Windows version is &lt;a href=&quot;http://www.pcworld.com/article/247724/kinect_for_windows_available_february_1_but_overpriced_at_249.html&quot;&gt;overpriced&lt;/a&gt; because it has the license for development. &lt;a href=&quot;http://gaming.stackexchange.com/questions/73290/can-kinect-for-windows-work-on-an-xbox-360&quot;&gt;Here&lt;/a&gt; it is stated that there are internal differences but without exact details (The minimum sensing distance seems to be better for Windows version.).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Could anyone give a comparison chart?&#xA;It would be good to know about&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Connectivity: USB, special connector, ... .&lt;/li&gt;&#xA;&lt;li&gt;Hardware differences: are they the same or do they really differ in weight, energy consumption, speed, sensing range, ...?&lt;/li&gt;&#xA;&lt;li&gt;Driver: could I use Xbox version under Ubuntu?&lt;/li&gt;&#xA;&lt;li&gt;API usage: could I develop on Xbox version, could I use the same/similar API on both, is the API for Xbox mature enough?&lt;/li&gt;&#xA;&lt;li&gt;License: is it against the license of Xbox version to develop for home/hobby/educational use?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Thanks.&lt;/p&gt;&#xA;" OwnerUserId="577" LastActivityDate="2013-03-20T08:23:59.003" Title="What is the difference between Kinect for Windows and Kinect for XBox?" Tags="&lt;sensors&gt;&lt;kinect&gt;" AnswerCount="3" CommentCount="1" FavoriteCount="2" />
  <row Id="655" PostTypeId="2" ParentId="654" CreationDate="2012-12-11T10:57:33.567" Score="8" Body="&lt;p&gt;According to &lt;a href=&quot;http://www.imaginativeuniversal.com/blog/post/2012/02/14/Why-the-Kinect-for-Windows-Sensor-Costs-2424999.aspx&quot;&gt;this article&lt;/a&gt; the hardware is almost the same, only the usb/power cord is different. Even the minimum sensing distance difference is not hardware-based it's only a firmware-based difference.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can use the cheaper hardware for developing programs using Kinect for Windows SDK, but your customers need the more expensive hardware since Kinect for Windows applications will not work with the cheaper hardware.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The article also states, that&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;If you want to use one of the non-Microsoft frameworks + drivers for&#xA;  writing Kinect enabled applications such as OpenNI, you are not&#xA;  required to use the new Kinect for Windows hardware.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="592" LastActivityDate="2012-12-11T10:57:33.567" />
  <row Id="656" PostTypeId="1" CreationDate="2012-12-11T20:25:27.937" Score="-1" ViewCount="155" Body="&lt;p&gt;I was wondering what options are there in terms of lightweight (&amp;lt; 5 lbs) robotic arms. I see &lt;a href=&quot;http://www.robai.com/products.php?prdt_id=1&quot; rel=&quot;nofollow&quot;&gt;Robai Cyton Gamma 300&lt;/a&gt;, and &lt;a href=&quot;http://www.crustcrawler.com/products/AX-18F%20Smart%20Robotic%20Arm/&quot; rel=&quot;nofollow&quot;&gt;CrustCrawler AX18&lt;/a&gt; look like interesting options. What lightweight arms do people use/like? &lt;/p&gt;&#xA;" OwnerUserId="595" LastEditorUserId="37" LastEditDate="2012-12-12T15:26:44.963" LastActivityDate="2012-12-12T16:48:55.613" Title="Lightweight, commercially available robotic arms" Tags="&lt;mobile-robot&gt;&lt;arm&gt;" AnswerCount="2" CommentCount="5" ClosedDate="2012-12-15T23:12:46.240" />
  <row Id="657" PostTypeId="2" ParentId="650" CreationDate="2012-12-11T21:01:33.773" Score="4" Body="&lt;p&gt;I'm in agreement with &lt;a href=&quot;http://robotics.stackexchange.com/a/652/37&quot;&gt;@movrev&lt;/a&gt; but wanted to expand beyond the scope of a comment.  RN-42 is slick.  I'm coding for it now, and I think it is an excellent BT choice.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Low cost and multiple receivers (switches) appear to be mutually exclusive.  You might consider the RN-42 as a BT receiver to preserve smartphone interface.  Then, you might consider an 802.15 (Zigbee) mesh-like solution to distribute a switch command from the RN-42 &quot;master&quot; receiver to the &quot;slave&quot; switches.  The Microchip MRF24J40 is a reasonable 802.15 solution.&lt;/p&gt;&#xA;" OwnerUserId="532" LastEditorUserId="37" LastEditDate="2012-12-13T00:11:58.127" LastActivityDate="2012-12-13T00:11:58.127" />
  <row Id="658" PostTypeId="2" ParentId="656" CreationDate="2012-12-11T22:53:37.770" Score="1" Body="&lt;p&gt;Have you thought about cardboard? &lt;a href=&quot;http://www.kickstarter.com/projects/392540503/cardboard-robot-robotic-arm-and-smart-phone-camera&quot; rel=&quot;nofollow&quot;&gt;http://www.kickstarter.com/projects/392540503/cardboard-robot-robotic-arm-and-smart-phone-camera&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="110" LastActivityDate="2012-12-11T22:53:37.770" />
  <row Id="660" PostTypeId="2" ParentId="654" CreationDate="2012-12-11T23:48:43.910" Score="15" Body="&lt;p&gt;The two pieces of hardware are virtually identical, &lt;a href=&quot;http://robotics.stackexchange.com/a/655/37&quot;&gt;as asalamon74 points out&lt;/a&gt;.  There are only a few hardware differences, with a larger set of restrictions based on firmware.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To extend on what asalamon74 has already pointed out, here are some direct answers to your bullet points:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Connectivity for both devices are USB.  If you get a Kinect for Xbox as part of a bundle (i.e., with an Xbox 360) you will need to buy an adapter, &lt;a href=&quot;http://rads.stackoverflow.com/amzn/click/B004IXRXGY&quot;&gt;available from Amazon&lt;/a&gt; and others.  The adapter comes with when a Kinect for Xbox is sold individually (due to older Xboxs not having the required port).&lt;/li&gt;&#xA;&lt;li&gt;Hardware is virtually the same.  Kinect for Windows has a shorter USB cable.  Kinect for Windows may have a better microphone array, but I can't be sure of that.  Other then that, they are basically the same.&lt;/li&gt;&#xA;&lt;li&gt;Driver/API is the same for both devices.  The official &lt;a href=&quot;http://www.microsoft.com/en-us/kinectforwindows/&quot;&gt;Kinect for Windows SDK&lt;/a&gt;, &lt;a href=&quot;http://openkinect.org/wiki/Main_Page&quot;&gt;OpenKinect SDK&lt;/a&gt; and &lt;a href=&quot;http://openni.org/&quot;&gt;OpenNI SDK&lt;/a&gt; will all work with both devices.&lt;/li&gt;&#xA;&lt;li&gt;License allows you to use the Kinect for Xbox for anything except a deployed (commercial) application.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;I use both for development.  I have two Kinect for &lt;em&gt;Windows&lt;/em&gt; that I use at work and I have a Kinect for &lt;em&gt;Xbox&lt;/em&gt; at home.  I bring work home with me frequently and I'm able to develop with either version of the hardware, depending on where I am.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are a few firmware differences that can cause a bit of a hick-up in development.  For example, Kinect for Xbox does not support &quot;near mode&quot; tracking.  Of course, it only effects you if you're trying to use those features.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Microsoft has said that they are actively developing the SDK with the Kinect for Windows in mind.  Although functionality is very close now, that is not necessarily true in the future.  Microsoft could very easily flip a switch to disallow Kinect for Xbox to be used in SDK v1.7 -- unlikely, but possible.  Although more expensive, Kienct for Windows is a safer buy.&lt;/p&gt;&#xA;" OwnerUserId="597" LastEditorUserId="597" LastEditDate="2012-12-13T17:45:28.227" LastActivityDate="2012-12-13T17:45:28.227" />
  <row Id="661" PostTypeId="2" ParentId="649" CreationDate="2012-12-12T01:27:36.177" Score="4" Body="&lt;p&gt;*Note, $a|b$ is the concatenation of paths $a$ and $b$. Then $c(\cdot)$ defined as the minimum clearance implies $c(a|b)=min(c(a),c(b))$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You refer to (in reference 1):&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;&lt;strong&gt;Theorem 11: (Additivity of the Cost Function.)&lt;/strong&gt;&#xA;  For all&#xA;  $\sigma_1$,$\sigma_2$ $\in X_{free}$&#xA;  , the cost function c satisﬁes the following:&#xA;  $c(\sigma_1|\sigma_2) = c(\sigma_1) + c(\sigma_2)$&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Which has become (in reference 3, Problem 2): &lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The cost function is assumed to be monotonic, in the sense that&#xA;  for all $\sigma_1,\sigma_2\in\Sigma:c(\sigma_1)\leq c(\sigma_1|\sigma_2)$&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Which is still not the case for minimum clearance distance. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; Given the relaxed restriction on path costs, your suggested exp(-min_clearance) seems fine.&lt;/p&gt;&#xA;" OwnerUserId="163" LastEditorUserId="163" LastEditDate="2012-12-13T15:43:46.497" LastActivityDate="2012-12-13T15:43:46.497" CommentCount="5" />
  <row Id="662" PostTypeId="2" ParentId="533" CreationDate="2012-12-12T15:02:13.187" Score="4" Body="&lt;p&gt;You can find some nice presentations on &lt;a href=&quot;http://prezi.com/explore/&quot; rel=&quot;nofollow&quot;&gt;prezi&lt;/a&gt; about robotic history (and about many other topics).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example &lt;a href=&quot;http://prezi.com/_a_tszqyeiut/robotics-history/&quot; rel=&quot;nofollow&quot;&gt;this&lt;/a&gt; or &lt;a href=&quot;http://prezi.com/mhcel532cxeq/the-history-of-robots/&quot; rel=&quot;nofollow&quot;&gt;this&lt;/a&gt; or &lt;a href=&quot;http://prezi.com/a3pg61a2t6qr/robots-past-present-and-future/&quot; rel=&quot;nofollow&quot;&gt;this&lt;/a&gt; presentations mention the ancient greek Archytas's robotic pigeon well before Leonardo's work around 350 B.C. and the klepsydra from around 300 B.C. having a feedback control system.&lt;/p&gt;&#xA;" OwnerUserId="577" LastEditorUserId="577" LastEditDate="2012-12-12T15:33:58.403" LastActivityDate="2012-12-12T15:33:58.403" CommentCount="2" />
  <row Id="663" PostTypeId="2" ParentId="504" CreationDate="2012-12-12T15:06:27.483" Score="2" Body="&lt;p&gt;There are really nice on-line &lt;a href=&quot;http://www.societyofrobots.com/calculator.shtml&quot; rel=&quot;nofollow&quot;&gt;calculators on societyofrobots&lt;/a&gt; including a &lt;a href=&quot;http://www.societyofrobots.com/RMF_calculator.shtml&quot; rel=&quot;nofollow&quot;&gt;robot motor factor calculator&lt;/a&gt; that could be helpful for you.&lt;/p&gt;&#xA;" OwnerUserId="577" LastActivityDate="2012-12-12T15:06:27.483" />
  <row Id="664" PostTypeId="2" ParentId="656" CreationDate="2012-12-12T16:48:55.613" Score="0" Body="&lt;p&gt;The &lt;a href=&quot;http://www.owirobots.com/cart/html/owi-535-robotic-arm-edge-kit.html&quot; rel=&quot;nofollow&quot;&gt;OWI robotic arm&lt;/a&gt; is a cheap starting possibility for $30. &#xA;There is an &lt;a href=&quot;http://www.instructables.com/id/Intro-and-what-youll-need/&quot; rel=&quot;nofollow&quot;&gt;instructables tutorial&lt;/a&gt; on how to connect it to arduino.&lt;/p&gt;&#xA;" OwnerUserId="577" LastActivityDate="2012-12-12T16:48:55.613" />
  <row Id="667" PostTypeId="1" AcceptedAnswerId="668" CreationDate="2012-12-12T19:57:51.837" Score="7" ViewCount="280" Body="&lt;p&gt;Is there an operating system for the Raspberry Pi that is specifically made for running robotics applications? Or an operating system whose purpose is to optimized just to run a few specific programs?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've been working with an Arduino for a while now. As far as efficiency goes, it makes sense to me to just upload a specific set of commands and have the hardware only need to handle that, and not have to worry about running a full fledged operating system. Is something like this possible to do on a Raspberry Pi?&lt;/p&gt;&#xA;" OwnerUserId="457" LastEditorUserId="38" LastEditDate="2012-12-13T15:35:05.300" LastActivityDate="2012-12-13T15:40:55.890" Title="Raspberry Pi operating system for robotics" Tags="&lt;raspberry-pi&gt;&lt;operating-systems&gt;" AnswerCount="2" FavoriteCount="2" />
  <row Id="668" PostTypeId="2" ParentId="667" CreationDate="2012-12-12T20:12:36.290" Score="7" Body="&lt;p&gt;You are asking two different things. 1) Is there a robotics-specific operating system, and 2) Is it possible to do hardware-level control on an R-Pi without messing around with an operating system. This is sort of a false dichotomy, as an operating system is a benefit, not a cost, unless you are &lt;em&gt;severely&lt;/em&gt; constrained for processing power.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Microcontrolers (Arduino) are designed to handle time-critical things, and usually only one or two time critical things. They are great for turning wheels, etc. When it comes to high level planning, a high-level language / libraries are very helpful. As are multi-threaded applications, etc. This is where your OS comes in. Without further details about your project, I can't help you decide what is the best fit: Arduino or R-Pi.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To answer 1: Yes, just google around.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To answer 2: Yes, the hardware interfaces IO are available to code API's. But you'll need (want) something like this:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You -&gt; OS -&gt; microcontroller -&gt; hardware.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;See &lt;a href=&quot;http://robotics.stackexchange.com/a/610/37&quot;&gt;This excellent answer&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="163" LastEditorUserId="163" LastEditDate="2012-12-13T15:40:55.890" LastActivityDate="2012-12-13T15:40:55.890" CommentCount="2" />
  <row Id="669" PostTypeId="2" ParentId="667" CreationDate="2012-12-12T21:18:02.973" Score="4" Body="&lt;p&gt;From your question, what you might be interested in is an RTOS for microcontrollers. A very popular one is &lt;a href=&quot;http://www.freertos.org/&quot; rel=&quot;nofollow&quot;&gt;FreeRTOS&lt;/a&gt;, which apparently was &lt;a href=&quot;https://github.com/everslick/piratos&quot; rel=&quot;nofollow&quot;&gt;ported to Raspberry Pi&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="95" LastActivityDate="2012-12-12T21:18:02.973" />
  <row Id="670" PostTypeId="2" ParentId="478" CreationDate="2012-12-13T00:00:38.803" Score="1" Body="&lt;p&gt;The &quot;math&quot; way to do this is to generate a speed/torque curve for your stepper at its given voltage, and determine the maximum force that will be applied to the object in motion (in this case, the largest force is likely to be acceleration).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note that most hobby 3d printers are so flimsy that the frame bending under acceleration will harm print quality long before you start missing steps.  In this case, you could model the deflection of the frame under load.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In my experience, 90% of missed steps are caused by mechanical or software problems such as the axes binding or pulses being missed.  Try moving everything by hand to check if it is smooth.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Overly aggressive speeds and accelerations should be visible (and audible) on a 3d printer long before the steppers stall.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Generally a single missed step will also cause the next steps to also be missed (since the motor must now work even harder to catch up) and you get a few seconds of buzzing instead of motion.&lt;/p&gt;&#xA;" OwnerUserId="65" LastActivityDate="2012-12-13T00:00:38.803" />
  <row Id="671" PostTypeId="1" AcceptedAnswerId="676" CreationDate="2012-12-13T04:43:47.557" Score="2" ViewCount="70" Body="&lt;p&gt;Is there a way to check if a task, function or variable exists in Not eXactly C?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I know that in PHP you can use &lt;code&gt;isset()&lt;/code&gt; to check if a variable exists and &lt;code&gt;function_exists()&lt;/code&gt; to do the same for a function, but is there a way to do that in NXC?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am specifically interested in checking whether a task exists or it is alive.&lt;/p&gt;&#xA;" OwnerUserId="38" LastEditorUserId="158" LastEditDate="2012-12-13T11:14:47.870" LastActivityDate="2012-12-15T00:19:19.497" Title="Check if task exists in Not eXactly C" Tags="&lt;nxt&gt;&lt;programming-languages&gt;&lt;mindstorms&gt;&lt;not-exactly-c&gt;" AnswerCount="2" />
  <row Id="672" PostTypeId="1" CreationDate="2012-12-13T04:45:21.737" Score="2" ViewCount="363" Body="&lt;p&gt;I'm currently working on a line-following robot which uses three sensors to follow a black line. The sensors are pretty much in line and right next to each other.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Right now, I'm doing a simple line follow: if on the line go forward, otherwise turn left or right to regain the line. This means that the robot is wiggling along the line most of the time.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm looking for a better way for this robot to follow the line using three sensors. The program I'm writing is in Not eXactly C code. I'm trying to get the robot to utilize the power of PID control, but I'm not sure how one would go about writing a three-sensor PID line-follower program in NXC.&lt;/p&gt;&#xA;" OwnerUserId="38" LastEditorUserId="38" LastEditDate="2012-12-18T02:57:38.567" LastActivityDate="2012-12-18T02:57:38.567" Title="PID line follow with three sensors in Not eXactly C" Tags="&lt;nxt&gt;&lt;programming-languages&gt;&lt;mindstorms&gt;&lt;algorithm&gt;&lt;not-exactly-c&gt;" AnswerCount="2" CommentCount="1" />
  <row Id="673" PostTypeId="5" CreationDate="2012-12-13T04:47:09.083" Score="0" ViewCount="3" Body="&lt;p&gt;Not eXactly C (NXC) is a high-level programming language for the LEGO Mindstorms NXT, built on top of Next Byte Codes (NBC).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://bricxcc.sourceforge.net&quot; rel=&quot;nofollow&quot;&gt;Learn More …&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="38" LastEditorUserId="38" LastEditDate="2012-12-13T15:34:50.993" LastActivityDate="2012-12-13T15:34:50.993" />
  <row Id="674" PostTypeId="4" CreationDate="2012-12-13T04:47:09.083" Score="0" Body="Not eXactly C (NXC) is a high-level programming language for the LEGO Mindstorms NXT, built on top of Next Byte Codes (NBC)." OwnerUserId="38" LastEditorUserId="38" LastEditDate="2012-12-13T15:34:56.827" LastActivityDate="2012-12-13T15:34:56.827" />
  <row Id="675" PostTypeId="2" ParentId="671" CreationDate="2012-12-13T07:30:45.910" Score="2" Body="&lt;p&gt;No, it seems that there's no such possibility, because there's no method in &lt;a href=&quot;http://bricxcc.sourceforge.net/nbc/nxcdoc/NXC_Guide.pdf&quot; rel=&quot;nofollow&quot;&gt;the manual&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="534" LastEditorUserId="534" LastEditDate="2012-12-13T08:21:44.057" LastActivityDate="2012-12-13T08:21:44.057" CommentCount="3" />
  <row Id="676" PostTypeId="2" ParentId="671" CreationDate="2012-12-13T08:53:49.850" Score="4" Body="&lt;p&gt;As NXC is a compiled language, I would assume calling a non-existent function or accessing a non-existent variable would throw a syntax error during compilation as it does in other compiled languages I have used.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Conversely, in interpreted languages like PHP and Python you can often call or access things that don't exist without creating an issue until that actual call or access happens - hence the need for method's like &lt;code&gt;isset()&lt;/code&gt; and &lt;code&gt;function_exists()&lt;/code&gt; in PHP.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Edit:&lt;/strong&gt; Looking at the &lt;a href=&quot;http://bricxcc.sourceforge.net/nbc/nxcdoc/nxcapi/task.html&quot; rel=&quot;nofollow&quot;&gt;Tasks docs&lt;/a&gt; it seems that a &quot;task&quot; is similar to a function in that it is defined in the source code, versus being created dynamically at run-time. I expect if you write something like: &lt;code&gt;Precedes(non_existent_task_name);&lt;/code&gt; (&quot;Precedes&quot; being a function to start tasks), and try to compile you would trigger the same sort of syntax error as you would if you did something like: &lt;code&gt;call_of_non_existent_function();&lt;/code&gt;&lt;/p&gt;&#xA;" OwnerUserId="435" LastEditorUserId="435" LastEditDate="2012-12-15T00:19:19.497" LastActivityDate="2012-12-15T00:19:19.497" CommentCount="2" />
  <row Id="677" PostTypeId="2" ParentId="672" CreationDate="2012-12-13T16:31:15.690" Score="1" Body="&lt;p&gt;I don't think traditional PID control is appropriate &lt;em&gt;per se&lt;/em&gt;, since your sensors only provide a binary &quot;is the line under me&quot; signal; PID controls need to be able to calculate error (error = actual - desired).  Also, you need motors that can adjust their speed instead of simply turning on and off.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One way to get PID control might be to increase the number of sensors from 3 to 9, with barely-overlapping sense area.  That might get you a range of 17 values, 9 from sensors and 8 more in cases where 2 adjacent sensors are triggered.  I'm not sure how many points you'll need to be able to measure in order for PID control to become effective.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A more abstract way to approach this would be to consider the wiggles-per-second to be the value controlled by the PID.  In this case, the PID would control the maximum difference in speed between the two motors -- the maximum rate of turn.  If your robot is wiggling to much, such a PID should cause it to turn in more gradual arcs.  In this case, the correct target wiggles-per-second will depend on the radius of the tightest turn that the robot will have to make.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2012-12-13T16:31:15.690" />
  <row Id="678" PostTypeId="2" ParentId="672" CreationDate="2012-12-13T17:19:38.277" Score="2" Body="&lt;p&gt;I dont use NXC, so I am hesitant to propose this as an answer, but I will comment that the sensors ARE linear - not binary. They measure dark, grey, and light - On, middle, off of line. You simply devise a scheme to get a unique #, and use that as the SetPoint to PID - works great. See &lt;a href=&quot;http://www.mindsensors.com/index.php?module=pagemaster&amp;amp;PAGE_user_op=view_page&amp;amp;PAGE_id=168&quot; rel=&quot;nofollow&quot;&gt;Mindsensors light array&lt;/a&gt; for sample NXC code for their array. Adopt it to 3 sensors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I don't know if this helps or not but is the scheme I use in RobotC; (higly shortened)&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;int LSA_GetAvg()&#xA;{&#xA;    char value[8];&#xA;    int som = 0;&#xA;    I2Cread(MINDSENSORS_LSA, LSA_ADDRESS, 0x42, value, 8);  // read 8 sensor values into an array&#xA;    int bits = 0;&#xA;    for (int i=0;i&amp;lt;8;i++)&#xA;        if (value[i] &amp;lt; 0x32)&#xA;    {&#xA;        som += ((8-i)*10);&#xA;        bits++;&#xA;    }&#xA;    return som / bits;&#xA;}&#xA;&#xA;main loop {&#xA;&#xA;    int avg = LSA_GetAvg();&#xA;    printf(&quot;avg %d\n&quot;, avg);&#xA;&#xA;    if (avg != 0)&#xA;    {&#xA;      steering = S3Pid(Oval, avg, 45, elapsedTime); // 45 is our goal, set point&#xA;      printf(&quot;Steer %d\n&quot;, steering);&#xA;&#xA;      motor[LEFT] = clipBAD((basePower - steering), -100, 100);&#xA;      motor[RIGHT] = clipBAD((basePower + steering), -100, 100);&#xA;    }&#xA;    else&#xA;    {&#xA;        // stuff gone wrong, we lost the line, check packed bits=0xff for a crossing&#xA;      PlaySound(soundBlip);&#xA;    }&#xA;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Edit: as I look at that OLD code - i see that is is not very optimum, and would work just fine with 3 binary sensors - just FYI.&lt;/p&gt;&#xA;" OwnerUserId="274" LastEditorUserId="274" LastEditDate="2012-12-13T17:36:41.107" LastActivityDate="2012-12-13T17:36:41.107" />
  <row Id="679" PostTypeId="1" CreationDate="2012-12-14T11:34:34.700" Score="41" ViewCount="2473" Body="&lt;p&gt;Mars rovers are typically very slow. Curiosity, for example, has average speed of about 30 meters per hour.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Why is it designed so slow? Is it because of some specific power restrictions or for other reasons? What is the top reason why it is so slow?&lt;/p&gt;&#xA;" OwnerUserId="516" LastEditorUserId="516" LastEditDate="2012-12-14T11:42:23.107" LastActivityDate="2013-06-21T20:03:16.020" Title="Why are Mars rovers so slow?" Tags="&lt;mobile-robot&gt;&lt;design&gt;" AnswerCount="4" CommentCount="2" FavoriteCount="8" />
  <row Id="680" PostTypeId="2" ParentId="679" CreationDate="2012-12-14T12:10:21.310" Score="17" Body="&lt;p&gt;I'm not such an expert in physics, but I can think of a few reasons:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Power&lt;/strong&gt;. The amount of power you need to do a task is inversely proportional to the time it takes to do that task. I think it is well known that doing something faster requires more power, otherwise you could do everything infinitely fast at no cost.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Computation Speed&lt;/strong&gt;. The statement about power (above) is not limited to movements. It is also true for computation. Have you noticed when your laptop is on power-saving mode, it runs slower? With processors, if you compute something twice as fast, you need four times more energy to do it. As a result, most probably, the CPU of mars rovers are also &lt;em&gt;not&lt;/em&gt; working at a high speed. Therefore, if the rover needs time to process something before moving on (for example images of the environment), it needs to move slower so it would receive data at a slower rate. Slow enough so that it can process them.&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Stability&lt;/strong&gt;. I believe I don't need to give you formulas for this phenomenon:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/u7Tox.jpg&quot; alt=&quot;car jump&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Simply put, the slower you go, the smaller the chance of lifting off over a ridge and possibly losing your stability when you land.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Maneuverability&lt;/strong&gt;. If you go at a reasonably slow speed, you wouldn't have any trouble steering. On the other hand, at high speeds, you need larger curvature to turn, as well as more pressure on the wheels on the outer side.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Note that some of these issues, such as stability, are true for robots on earth too. However, here on earth we can always flip the vehicle if it turned over, but on Mars we can't trust Martians on it (they may like the rover stuck on its back and start worshipping it, which is totally not cool for us).&lt;/p&gt;&#xA;" OwnerUserId="158" LastEditorUserId="158" LastEditDate="2013-04-12T14:39:26.833" LastActivityDate="2013-04-12T14:39:26.833" CommentCount="13" />
  <row Id="681" PostTypeId="2" ParentId="679" CreationDate="2012-12-14T12:22:35.467" Score="16" Body="&lt;p&gt;One reason is because of the communications delay between Earth and Mars.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The round trip time for signals from Earth to Mars is several minutes, which means that you can't teleoperate the robot in realtime. That means that the robot needs some autonomous obstacle avoidance capability to help prevent it from getting stuck or otherwise in trouble. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The hazard avoidance equipment on mars rovers is generally designed in a very conservative way, which means drive slow and stop frequently to check your environment.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From Wikipedia, for the Mars Exploration Rovers (Spirit and Opportunity):&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;...hazard avoidance software causes it to stop every 10 seconds for 20&#xA;  seconds to observe and understand the terrain into which it has&#xA;  driven.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="479" LastEditorUserId="479" LastEditDate="2012-12-14T13:05:39.643" LastActivityDate="2012-12-14T13:05:39.643" CommentCount="2" />
  <row Id="682" PostTypeId="2" ParentId="679" CreationDate="2012-12-14T16:15:34.333" Score="48" Body="&lt;p&gt;It has more to do with the &lt;a href=&quot;http://en.wikipedia.org/wiki/Rocker-bogie&quot;&gt;rocker bogie suspension&lt;/a&gt; than anything else.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The system is designed to be used at slow speed of around 10 cm/s, so as to minimize dynamic shocks and consequential damage to the vehicle when surmounting sizable obstacles.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;In exchange for moving slowly, the rover is able to climb rocks that are double the wheel diameter (normal suspension has trouble with anything over half the wheel diameter).  This is important when travelling in &amp;mdash; literally &amp;mdash; an alien landscape.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/qcnqs.gif&quot; alt=&quot;Climbing&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(image via &lt;a href=&quot;http://en.smath.info/forum/yaf_postst995p2_Animation-of-mechanisms.aspx&quot;&gt;http://en.smath.info/forum/yaf_postst995p2_Animation-of-mechanisms.aspx&lt;/a&gt;)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are other benefits that come with slow speed: better &lt;a href=&quot;http://trs-new.jpl.nasa.gov/dspace/bitstream/2014/37431/1/05-0761.pdf&quot;&gt;correlation between successive frames captured by its navigation cameras&lt;/a&gt;, more time to &lt;a href=&quot;http://marsrover.nasa.gov/technology/is_autonomous_mobility.html&quot;&gt;plan its path&lt;/a&gt;, and power savings.  However, without the capabilities provided by the suspension system &amp;mdash; &lt;a href=&quot;http://vimeo.com/66656664&quot;&gt;surmounting the obstacles present on the martian surface without getting stuck or causing damage&lt;/a&gt; &amp;mdash; the other benefits are moot.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-06-21T20:03:16.020" LastActivityDate="2013-06-21T20:03:16.020" CommentCount="7" />
  <row Id="683" PostTypeId="2" ParentId="679" CreationDate="2012-12-14T20:51:55.190" Score="22" Body="&lt;p&gt;This seems like a softball question but is surprisingly subtle. There are some excellent answers here, but I can add some basic rigor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The reason the rovers move so slow is essentially the need to be cautious with a multi-million-dollar piece of equipment. But there are some other design constraints worth mentioning.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Energy&lt;/strong&gt; is simply the worst bottleneck for mobile, autonomous systems. The energy cost for a system to relocate across a surface can be typically modeled as&#xA;$$ \int^{T_{final}}_{T_{initial}} [ c_0 v(t)^2 + c_1 a(t)^2 + c_3v(t) + c_4a(t) + c_5v(t)*a(t) + C ]dt $$ where $c_0...c_6$ are constants representing the motor parameters (see &lt;a href=&quot;http://www.cs.umn.edu/~isler/pub/icra11tokekar.pdf&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;http://www-users.cs.umn.edu/~isler/pub/iser2012solar.pdf&quot;&gt;here&lt;/a&gt;).&#xA;So the cost of travelling to a nearby crater is proportional to the square of the velocity and square of the acceleration. Thus, slower costs less power overall. There is usually a &quot;tipping speed&quot; at which the power consumption spikes, and this is usually a very slow speed. Thus, robots move slow to save power. Additionally, this means a robot cannot carry energy-intensive sensors like &lt;a href=&quot;http://en.wikipedia.org/wiki/LIDAR&quot;&gt;LIDAR&lt;/a&gt;. Note LIDAR is used extensively in autonomous, driverless vehicles like the &lt;a href=&quot;http://www.slashgear.com/back-to-basics-how-googles-driverless-car-stays-on-the-road-09227396/&quot;&gt;Google Car&lt;/a&gt;. Which brings me to...&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Computational Sensing&lt;/strong&gt;. Note, we're not considering power. Now, we have to realize that the robot is &lt;em&gt;autonomous&lt;/em&gt; (i.e., driver-less). Given the reduced sensors, a robot cannot model its whole environment, and plan a large route. Think of it this way, would you run through the forest in the dark? Not if you didn't need to. The robot is constantly &quot;in the dark&quot; since it cannot see very far ahead, so it moves slowly, carefully planning each step. The memory and cpu required to plan these things is $O(r^3)$ or worse, where $r$ is the radius of planning. see &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=C47C6FE1DB3CE7AB3F24921BF5394BBD?doi=10.1.1.44.4807&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1013713&amp;amp;tag=1&quot;&gt;here&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Communication Delays&lt;/strong&gt;. As mentioned, the robot is i) autonomous, and ii), sensing-limited. The humans have to constantly &quot;check-in&quot; to make sure the robot isn't doing something stupid (despite its state of the art planning algorithms). This means the robot will wait for instructions a &lt;em&gt;lot&lt;/em&gt;, thus slow average progress towards a goal. The previous references address this.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Stability&lt;/strong&gt;. To achieve stability / robustness, the rovers use the rocker-bogie system. see &lt;a href=&quot;http://trs-new.jpl.nasa.gov/dspace/bitstream/2014/38435/1/04-0705.pdf&quot;&gt;this&lt;/a&gt;. This system is designed to be operated at slow speeds. If you go fast, and hit a rock, you break your rover. Try to imagine doing that sensor-based motion planning.  Now try to do so when all your relevant sensors are &lt;a href=&quot;http://www.nasa.gov/mission_pages/msl/multimedia/gallery/pia13809.html&quot;&gt;on a mast attached to the top of your robot&lt;/a&gt;, and you'll see that keeping the sensing payload stable is very important.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="163" LastEditorUserId="350" LastEditDate="2013-06-21T17:06:42.790" LastActivityDate="2013-06-21T17:06:42.790" CommentCount="2" />
  <row Id="684" PostTypeId="1" AcceptedAnswerId="686" CreationDate="2012-12-15T13:14:25.053" Score="5" ViewCount="370" Body="&lt;p&gt;I have an LM2576 circuit plus an adjuster to adjust the output voltage, for controlling motor speed in a line follower robot. The circuit works great when adjusted to give out low voltages, but when I adjust it to higher voltages for my motors to go faster, it works great for 1-2 minutes, then suddenly cuts down the power and motors start to go extremely slow.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Even when I decrease or increase the output voltage, it won't respond until I turn off the power and turn it back on again. There is something mentioned in the LM2576 datasheet that if we overload the IC it will cut down the power until the load comes lower, so I think it might be a problem with that.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Since this problem has already caused us to lose the competitions with 5+ teams, I would like to solve it for our next competition, so why does our LM2576 circuit suddenly reduce the power?&lt;/p&gt;&#xA;" OwnerUserId="21" LastEditorUserId="37" LastEditDate="2012-12-23T23:54:08.693" LastActivityDate="2012-12-23T23:54:08.693" Title="Why does our LM2576 circuit suddenly cut down the power?" Tags="&lt;motor&gt;&lt;electronics&gt;&lt;power&gt;" AnswerCount="2" CommentCount="1" />
  <row Id="685" PostTypeId="2" ParentId="684" CreationDate="2012-12-15T17:47:11.693" Score="5" Body="&lt;p&gt;According to the &lt;a href=&quot;http://www.ti.com/lit/ds/symlink/lm2576.pdf&quot;&gt;datasheet&lt;/a&gt;, there are three possibilities: TTL shutdown, thermal shutdown and current limiting. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;From what I looked up, TTL shutdown means simply that you have a pin you can use to cut-off the regulator output current. My guess is that it is pin 5 and you simply grounded it, as seen in the typical application circuit, so that possibility can be eliminated.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Since the circuit works great for 1-2 minutes and then shuts down, my guess is that you are not properly heatsinking and the regulator is going through thermal shutdown. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If the IC isn't feeling hot enough, however, then you can probably assume current limiting. In that case, you have to investigate why your circuit is demanding so much current (probably a flawed design).&lt;/p&gt;&#xA;" OwnerUserId="95" LastActivityDate="2012-12-15T17:47:11.693" />
  <row Id="686" PostTypeId="2" ParentId="684" CreationDate="2012-12-15T19:35:24.243" Score="10" Body="&lt;p&gt;If I were you, I would first (1) read the &lt;a href=&quot;http://www.onsemi.com/pub_link/Collateral/LM2576-D.PDF&quot;&gt;LM2576 datasheet&lt;/a&gt;.&#xA;I'm assuming you are using a circuit similar to the schematic and PCB layout on page 23 of the LM2576 datasheet.&#xA;I'm guessing you've tweaked the circuit slightly, replacing the manually-operated pot shown on the schematic for R2, replaced with some sort of microprocessor-controlled thing that frequently changes its effective resistance to make that motor spin faster or slower.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then I would (2) put my finger on the chip.&#xA;If it feels so hot that I can't hold my finger on it, I would suspect&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;thermal shutdown.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;georgebrindeiro covered this. You'll also want to read p. 18 of the datasheet, the section &quot;Thermal Analysis and Design&quot;: &quot;The following procedure must be performed to determine whether or not a heatsink will be required. ...&quot;. The typical solution is to add a big heat sink to the chip. Do you see the size of the heatsink on the PCB layout on page 23 of the datasheet?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Next I would (3) take a cheap multimeter, switch it to &quot;Amp&quot; mode, and connect it in-line with the motor leads.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When the output voltage drops (which I measure with my more expensive multimeter),&#xA;and I hear and see the motors slow down, what does the cheap multimeter say?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Does the cheap multimeter stay pegged at some high current above 3 A (the datasheet says the internal limit will be somewhere between 3.5 A and 7.5 A)?&#xA;If so, then we almost certainly have:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;current limiting. The regulator is working as-designed.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The typical solution is to figure out what is pulling so much current, and somehow replace it with something that pulls less current.&#xA;Perhaps the robot has run into a wall or got stuck in a rut, and the motors have stalled out.&#xA;Then maybe the controller needs to sense this condition, stop its futile efforts to punch through the wall, and reverse direction.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Sometimes we really need more current than one regulator can supply.&#xA;Then we must replace that regulator with multiple regulators or higher-current regulators or both.&#xA;(But not so much current that it immediately melts the wires in the motor).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On the other hand, if the output voltage &lt;em&gt;and&lt;/em&gt; the output current drop, then&#xA;I would (4) connect my more expensive multimeter to the power input pins of the regulator.&#xA;If that is much lower than I expected, then perhaps:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The input voltage is lower than I expected.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;When you supply the motors with a higher voltage, they drain the batteries much quicker. Partially-drained batteries have a no-load voltage &lt;em&gt;lower&lt;/em&gt; than you might expect from the &quot;nominal&quot; voltage printed on the battery, and &lt;em&gt;loaded&lt;/em&gt; batteries have an even lower voltage. I doubt this is your problem, since you imply that if you disconnect the battery and reconnect the &lt;em&gt;same&lt;/em&gt; battery, it seems to start working again. The typical solution is to put more batteries in series to increase the actual working voltage.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Next I would (5) try disconnecting the batteries, and powering everything from a high-current grid-powered &quot;power supply&quot; set to the appropriate output voltages.&#xA;If it seems to run fine off that power supply, but not from batteries, I would suspect:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;switching-regulator latchup. &quot;Latchup of Constant-Power Load With Current-Limited Source&quot; &lt;a href=&quot;http://www.smpstech.com/latch000.htm&quot;&gt;http://www.smpstech.com/latch000.htm&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;When you supply the motors with a higher voltage, they pull a higher current.&#xA;Surprisingly often, the total impedance at the input power pins of switching regulator is so high (bad) that when the regulator turns its internal power switch on, the voltage at its input power pins plummets so low that it's not possible to pull the desired current from that battery.&#xA;Milliseconds later, when the switch turns off, the battery pulls the voltage back up to some reasonable voltage -- so this problem is difficult to debug with a standard multimeter, but obvious when you have the input power pins connected to an oscilloscope.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The only complete cure is to somehow reduce the total input impedance at the input power pins.&#xA;Occasionally all you need to do is reduce the wiring impedance -- shorten the wires (reduce the resistance), or bring closer together the PWR and GND wires (reduce the inductance), or both.&#xA;Occasionally all you need to do is put more capacitance across the power input pins of the regulator.&#xA;As a battery drains, its effective series resistance increases.&#xA;In theory, you can always cure this by putting more batteries in parallel to reduce the net ESR of of all the batteries in parallel.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some people want a very lightweight robot, and so they can't add more batteries, so they can't completely cure the problem.&#xA;Sometimes they can get adequate performance from the robot by using various &quot;soft-start&quot; or &quot;load-shedding&quot; techniques.&#xA;Rather than trying to pull a lot of power from the batteries to get up to speed quickly -- more power than the battery can physically supply, and so triggering this unwanted latchup -- we pull somewhat less power from the batteries, slowly ramping up to speed, and applying various &quot;limp mode&quot; and &quot;tired mode&quot; techniques to keep the total power at any one instant low enough that the battery can supply it.&#xA;(You may be interested in&#xA;&lt;a href=&quot;http://robotics.stackexchange.com/questions/416/what-is-the-best-way-to-power-a-large-number-27-servos-at-5-v&quot;&gt;What is the best way to power a large number (27) servos at 5 V?&lt;/a&gt;&#xA;).&lt;/p&gt;&#xA;" OwnerUserId="187" LastActivityDate="2012-12-15T19:35:24.243" CommentCount="5" />
  <row Id="687" PostTypeId="1" AcceptedAnswerId="688" CreationDate="2012-12-15T21:31:07.840" Score="1" ViewCount="256" Body="&lt;p&gt;I want to learn robotics and really interested in making a robot based on Kinect sensor.&#xA;I see so many projects like this one : &lt;a href=&quot;http://www2.macleans.ca/2011/11/03/the-150-robot-revolution/&quot; rel=&quot;nofollow&quot;&gt;http://www2.macleans.ca/2011/11/03/the-150-robot-revolution/&lt;/a&gt;&#xA;and just wondering how it works on top level. I downloaded Kinect SDK and did some basic tutorials, but I just don't think that Microsoft SDK is the library to use for real robotics projects. Any suggestions where to start and what library to use ? Any good books in particular or online resources ? If this question is not making sense or not well structured, its due to my non existent experience with robotics. Any help is appreciated, thank you.&lt;/p&gt;&#xA;" OwnerUserId="575" LastActivityDate="2012-12-17T10:21:54.470" Title="Robotics with Kinect" Tags="&lt;kinect&gt;" AnswerCount="2" CommentCount="1" />
  <row Id="688" PostTypeId="2" ParentId="687" CreationDate="2012-12-15T22:17:41.517" Score="3" Body="&lt;p&gt;Welcome to the Robotics StackExchange! The Kinect is only a sensor, albeit a relatively powerful one for its price. To use it with a robot, you need to cover basically two bases:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Get a robot that is able to interface with it&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;That means you need to somehow build/buy something consisting of processing unit (a microcontroller or PC) with USB connectivity and the appropriate drivers to recognize and control the Kinect (usually easier with a PC running Linux). This thing also needs to be able to provide appropriate power input to the sensor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You also want it to be able to move, so you need to add motors or other actuators to it and figure out how to get your processing unit to control them (usually easier with a microcontroller).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you want it to be able to process all the data from the Kinect and make complex decisions by itself you will need enough processing power onboard (usually a PC). Otherwise, you might have to add wireless communication with other computers that will do the heavy calculations.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Figure out how to get the Kinect data and what to do with it&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The Microsoft SDK is perfectly usable, as is OpenNI or libfreenect... It really comes down to what operating system is running on your robot. I am not aware of how to interface the Kinect with less powerful microcontrollers not running a popular OS (Windows/Linux/Mac) and while it may be possible it definitely is not desirable (as in it would be a lot of work for a beginner).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Once you've chosen which programming library and driver to use to get Kinect data, you will need to find out what you want to do with the data you get. The raw sensor data is just a range image, but some of these libraries can provide some higher-level info extracted from these range images such as skeletonized models of people.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;In short:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;Start by figuring out what kind of robot you want, how you want it to move, where the Kinect will be placed and so on. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Choose your processing unit after searching for alternatives that are able to interface with the Kinect easily. I would suggest something like a netbook running Linux to a beginner, with a microcontroller board like the Arduino connected via USB to control motors and other low-level components of the robot.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Once you have the basic components of your robot ready (e.g. mechanical parts in place, PC running Linux, motor control working, etc) add the Kinect to the mix by connecting it to your processing unit and start working on what to do with it.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="95" LastEditorUserId="95" LastEditDate="2012-12-16T18:31:12.400" LastActivityDate="2012-12-16T18:31:12.400" CommentCount="1" />
  <row Id="689" PostTypeId="1" AcceptedAnswerId="717" CreationDate="2012-12-16T01:59:01.610" Score="6" ViewCount="111" Body="&lt;p&gt;I'm building a motion control platform with 3 DoF: 1 axis of rotation (theta) and 2 cartesian (x,y). In most applications, like wrist actuation, you have an X-Y stage with a rotating servo as the stage's payload. This configuration works well since little of the power and data wiring needs to transit to the non-linear moving portion of the platform. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;For my inverted application, the stackup is reversed. The rotating axis comes first (from the mounting plane) with the stage connected as the rotating platform's payload. Now nearly all of the wiring (power, command, sensor, and otherwise) must be routed to the non-linearly moving section.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I can see two broad approaches: &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;The inside track, I route the cabling through the center of rotation.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;The outside track, I route the cabling around outside the outer diameter of the rotating platform.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Mathematically, I can see that (1) results in minimum cable length, but maximum torsional loading, while (2) results in maximum cable length, but minimum torsional loading on the wires.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Having limited experience with cable routing (and the associated carriers, strategies, and products) in non-linear applications, my question is...&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;...which approach is better in practice?&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Cost isn't really the issue here. I'm more interested in reliability, ease of construction, availability of commercial components (says something about the popularity of the technique), etc...&lt;/p&gt;&#xA;&#xA;&lt;p&gt;e.g. the generic concepts behind why you pick one over the other. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;...of course, if you have some part numbers for me I wouldn't be upset &amp;lt;-- I know I'm not supposed ask that here ;-)&lt;/p&gt;&#xA;" OwnerUserId="531" LastEditorUserId="531" LastEditDate="2012-12-16T02:52:45.463" LastActivityDate="2012-12-21T14:00:35.390" Title="Cable routing in theta, x, y motion control system. Better inside or outside?" Tags="&lt;control&gt;&lt;wiring&gt;&lt;routing&gt;&lt;motion&gt;" AnswerCount="1" CommentCount="6" />
  <row Id="690" PostTypeId="1" AcceptedAnswerId="691" CreationDate="2012-12-16T05:29:07.907" Score="5" ViewCount="124" Body="&lt;p&gt;When using an EKF for SLAM, I often see the motion and measurement models being described as having some noise term.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;This makes sense to me if you're doing a simulation, where you need to add noise to a simulated measurement to make it stochastic.  But what about when using real robot data?  Is the noise already in the measurement and thus does not need to be added, or does the noise matrix mean something else?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, in Probabilistic Robotics (on page 319), there is a measurement model: $z_t^i = h(y,j) + Q_t$, where $Q_t$ is a noise covariance.  Does $Q_t$ need to be calculated when working with real data?&lt;/p&gt;&#xA;" OwnerUserId="502" LastActivityDate="2012-12-16T05:39:56.813" Title="Noise in motion and measurement models" Tags="&lt;slam&gt;&lt;kalman-filter&gt;" AnswerCount="1" />
  <row Id="691" PostTypeId="2" ParentId="690" CreationDate="2012-12-16T05:39:56.813" Score="8" Body="&lt;p&gt;When using the EKF (or standard KF) on a real robot, you will want to tell the filter how much noise there is in each measurement, and in the process.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The purpose of this is so that the Kalman filter can decide how much it &quot;trusts&quot; each source of data, and therefore, the weighting to give each measurement in its final estimation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For real robot data, the noise is already in the measurement. I think when you say &quot;noise matrix&quot;, you are referring to the covariance matrix. This is not the actual noise per se, but rather, the noise covariance matrix describes the magnitude of the noise (that can be expected by the Kalman Filter), and the correlation between different noise terms, for a normal distribution of noise. You will generally want as accurate a noise covariance as possible, however, it can simply be estimated. When working with real data, you can perform a quick experiment to estimate the noise covariance, or you can also estimate it by consulting datasheets, or select a somewhat sensible value. Where there is not much data available, the covariance will normally be a diagonal matrix (ie. no correlation). The diagonal elements of the covariance matrix is also referred to as the &lt;strong&gt;variance&lt;/strong&gt;. That means that you are telling the Kalman filter what the variance of the different noise sources are (square of standard deviation of the noise).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If on the other hand, you are wondering why the models related to the Kalman Filter may have a noise term (as opposed to a noise covariance), they are only models, and those equations are not actually used in the algorithm. The equations used by the algorithm will have terms representing the noise covariance (not the actual noise - which is unknown), which it normally keeps an online estimate of.&lt;/p&gt;&#xA;" OwnerUserId="145" LastActivityDate="2012-12-16T05:39:56.813" />
  <row Id="692" PostTypeId="2" ParentId="687" CreationDate="2012-12-17T10:11:24.910" Score="0" Body="&lt;p&gt;Evil Closet Monkey nicely itemized the possible Kinect libraries in &lt;a href=&quot;http://robotics.stackexchange.com/a/660/577&quot;&gt;his answer&lt;/a&gt; to another Kinect related question mentioning &lt;a href=&quot;http://openkinect.org/wiki/Main_Page&quot; rel=&quot;nofollow&quot;&gt;OpenKinect SDK&lt;/a&gt; and &lt;a href=&quot;http://openni.org/&quot; rel=&quot;nofollow&quot;&gt;OpenNI SDK&lt;/a&gt; besides Windows SDK.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A good book on Kinect is &lt;a href=&quot;http://shop.oreilly.com/product/0636920020684.do&quot; rel=&quot;nofollow&quot;&gt;Making Things See&lt;/a&gt; by Greg Borenstein from O'Reilly.&lt;/p&gt;&#xA;" OwnerUserId="577" LastEditorUserId="577" LastEditDate="2012-12-17T10:21:54.470" LastActivityDate="2012-12-17T10:21:54.470" />
  <row Id="693" PostTypeId="1" AcceptedAnswerId="694" CreationDate="2012-12-18T01:47:33.573" Score="5" ViewCount="162" Body="&lt;p&gt;Is there anything different between a iRobot Roomba and the Create?  I want go start building my own turtlebot and playing with ROS but with the cost of all the parts I'm going to have to do it piece by piece.  It's pretty easy to find cheap used Roombas.  &lt;/p&gt;&#xA;" OwnerUserId="529" LastEditorUserId="163" LastEditDate="2012-12-18T16:13:21.920" LastActivityDate="2012-12-23T21:13:46.587" Title="Can I use ROS with a Roomba?" Tags="&lt;ros&gt;" AnswerCount="2" />
  <row Id="694" PostTypeId="2" ParentId="693" CreationDate="2012-12-18T03:34:36.223" Score="4" Body="&lt;p&gt;Can you use a Roomba with ROS? &lt;a href=&quot;http://www.ros.org/wiki/Robots/Roomba&quot; rel=&quot;nofollow&quot;&gt;Absolutely&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can you use a Roomba with the existing turtlebot code? Most likely but it may depend on model of the Roomba since older models have a slightly different API. Of course even if there are API differences that haven't been accounted for it should not be too difficult to adjust the code to handle them.&lt;/p&gt;&#xA;" OwnerUserId="177" LastEditorUserId="163" LastEditDate="2012-12-18T16:12:33.383" LastActivityDate="2012-12-18T16:12:33.383" CommentCount="2" />
  <row Id="696" PostTypeId="1" CreationDate="2012-12-18T09:53:59.407" Score="3" ViewCount="73" Body="&lt;p&gt;The interesting &lt;a href=&quot;http://www.eecs.harvard.edu/ssr/projects/progSA/kilobot.html&quot; rel=&quot;nofollow&quot;&gt;Kilobot project&lt;/a&gt; from Harvard for investigating multi-robot behavior with masses of small dumb robots has been made &lt;a href=&quot;http://ssr.wikidot.com/kilobot-documents&quot; rel=&quot;nofollow&quot;&gt;open hardware&lt;/a&gt; for a year now. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;However I cannot find so much activity about robot creation and movies about results. Is it too hard to create the robots, the programmer, the charger or isn't the project interesting enough?&lt;/p&gt;&#xA;" OwnerUserId="577" LastEditorUserId="350" LastEditDate="2012-12-18T22:16:30.563" LastActivityDate="2013-01-22T21:02:53.550" Title="Are there working instances of Kilobot projects?" Tags="&lt;multi-agent&gt;" AnswerCount="1" CommentCount="6" />
  <row Id="697" PostTypeId="1" CreationDate="2012-12-18T17:13:05.567" Score="7" ViewCount="294" Body="&lt;p&gt;I'm a software engineer who volunteers with a non-profit that introduces young girls to technology. We have recently been talking about methods of introducing these children to the world of robotics, and I am curious what types of low-cost options we have.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One very appealing idea would be to have an online simulator, or (more preferable) an off-line standalone-simulator that we can build and program simple robots with. Perhaps nothing more than dragging components together, and then programming the interactions between those components.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What solution(s) exist that I might be able to make use of in our outreach?&lt;/p&gt;&#xA;" OwnerUserId="250" LastActivityDate="2013-01-25T17:50:21.990" Title="Standalone (or capable of being) Robotics Simulator" Tags="&lt;software&gt;&lt;simulator&gt;&lt;children&gt;" AnswerCount="7" CommentCount="2" FavoriteCount="3" />
  <row Id="698" PostTypeId="2" ParentId="697" CreationDate="2012-12-18T17:50:43.980" Score="7" Body="&lt;p&gt;Stage and Gazebo are open source 2D and 3D simulators respectively. They are created and maintained by the &lt;a href=&quot;http://playerstage.sourceforge.net/&quot;&gt;Player project&lt;/a&gt;. They are very easy to use and have a lot of pre-built maps and robots. Depending on the experience of your audience you may need to do a bit of the heavy lifting (i.e. building configuration files and the main classes).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;They have a couple of additional benefits as well. First, so long as you create your main control code as player plug-ins then they can be easily adapted to real robots. Second, there are a large number of plug-ins already built to work with real hardware. Third, they work with &lt;a href=&quot;http://ros.org&quot;&gt;ROS&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2012-12-18T17:50:43.980" />
  <row Id="699" PostTypeId="2" ParentId="697" CreationDate="2012-12-18T18:02:38.617" Score="4" Body="&lt;p&gt;&lt;a href=&quot;https://www.microsoft.com/robotics/&quot; rel=&quot;nofollow&quot;&gt;Microsoft robotics&lt;/a&gt; is FREE and includes a &lt;a href=&quot;https://www.microsoft.com/robotics/#GetStartedStep3&quot; rel=&quot;nofollow&quot;&gt;simulator&lt;/a&gt;. It is not exactly the easiest environment in the world, however it IS robust and appropriate to real robotics.  I think with some teacher involvement to set things up beforehand, it could be usable. There is a simulator 'package' for LEGO, Neato and some other robots, and they can be programmed in C# or a visual drag and drop language. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Again, I think it would need some work up front to make it easy for youngsters to use, but it wouldn't be that hard, and would be my approach given your requirements. I would say as far as complexity goes, this (windows) vs. a Linux environment with Gazebo/ROS, the windows environment would be slightly less complicated, although most of that would hopefully be hidden with preparation work.&lt;/p&gt;&#xA;" OwnerUserId="274" LastActivityDate="2012-12-18T18:02:38.617" />
  <row Id="700" PostTypeId="2" ParentId="697" CreationDate="2012-12-18T18:09:25.960" Score="2" Body="&lt;p&gt;&lt;a href=&quot;http://www.robotc.net/index.php&quot; rel=&quot;nofollow&quot;&gt;RobotC&lt;/a&gt; has a &lt;a href=&quot;http://www.robotc.net/blog/2012/11/19/new-versions-of-rvw-curriculum-and-competition-tables/&quot; rel=&quot;nofollow&quot;&gt;simulator&lt;/a&gt; available, although both are products at some costs. However, they are very geared towards younger students and education. This would be the easiest, and most appropriate route if costs are not a blocking factor (&lt;a href=&quot;http://www.robotc.net/purchase/rvw/&quot; rel=&quot;nofollow&quot;&gt;around \$100 per license for both for single user, \$300 for 6 users, \$600 for 30 users&lt;/a&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you buy the student version &lt;a href=&quot;http://www.robotc.net/purchase/nxt/&quot; rel=&quot;nofollow&quot;&gt;ROBOTC for MINDSTORMS NXT of LEGO&lt;/a&gt; the price can be 49\$ for each or 40$ (more than 20 licences) &lt;/p&gt;&#xA;" OwnerUserId="274" LastEditorUserId="274" LastEditDate="2012-12-19T17:53:18.237" LastActivityDate="2012-12-19T17:53:18.237" />
  <row Id="701" PostTypeId="2" ParentId="697" CreationDate="2012-12-18T20:32:01.393" Score="4" Body="&lt;p&gt;May be it is a bit pricy (CHF 75) but I still suggest &lt;a href=&quot;http://www.ceebot.com/colobot/edu-e.php&quot; rel=&quot;nofollow&quot;&gt;Colobot&lt;/a&gt;. It is a nice, almost game-like environment where robots need to help humans to make a space base habitable. Robots are programmed by the kids while increasingly complex tasks are performed. The program teaches the fundamentals of programming in a goal-oriented, funny way.&lt;/p&gt;&#xA;" OwnerUserId="577" LastActivityDate="2012-12-18T20:32:01.393" />
  <row Id="702" PostTypeId="2" ParentId="327" CreationDate="2012-12-19T03:57:37.393" Score="2" Body="&lt;p&gt;A simplified method for learning would be to make the robot into one random position and then another and tweak the second position until it moves forward. Using this position as a start do the process again n times and then you will have n positions to move through that make the robot move forward.&lt;/p&gt;&#xA;" OwnerUserId="374" LastActivityDate="2012-12-19T03:57:37.393" />
  <row Id="703" PostTypeId="2" ParentId="533" CreationDate="2012-12-19T09:46:13.297" Score="1" Body="&lt;p&gt;One major development milestone was the first functioning robot to use electricity. As mentioned in Jordan Brown's link, Nikola Tesla demonstrated a radio-controlled robotic boat (more of an ROV I suppose) in a specially-built pool in Madison Square Garden in 1898. He even implemented a crude logic gate designed to prevent other transmitters from taking control from him.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Radio being a not exactly well-known technology in 1898 (Marconi had not even filed for any patents in the US yet), disbelieving onlookers gave such explanations as witchcraft, telepathy, and a tiny trained monkey hidden inside the vehicle.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Related US patents:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.google.com/patents/US613809&quot; rel=&quot;nofollow&quot;&gt;Patent 613,809: Method of and Apparatus for Controlling Mechanism of Moving Vessels or Vehicles&lt;/a&gt;&#xA;&lt;a href=&quot;http://www.google.com/patents/US725605&quot; rel=&quot;nofollow&quot;&gt;Patent 725,605: System of Signaling&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="308" LastActivityDate="2012-12-19T09:46:13.297" />
  <row Id="704" PostTypeId="1" CreationDate="2012-12-20T00:06:58.897" Score="3" ViewCount="199" Body="&lt;p&gt;I recently asked a question about the juniper WiFi shield, and am now working with wifly from spark fun. I've been using an updated version of their experimental library, and have been attempting to set up a webserver. Unfortunately, when I attempt to connect through a web browser, I get an error saying that the page sent no data. Here's my code:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#include &amp;lt;SPI.h&amp;gt;&#xA;#include &amp;lt;WiFly.h&amp;gt;&#xA;&#xA;WiFlyServer s(80);&#xA;boolean current_line_is_blank=true;&#xA;void setup() {&#xA;  Serial.begin(9600);&#xA;  WiFly.begin();&#xA;  if(!WiFly.join(placeholderssid, placeholderpass,WPA_MODE)) {&#xA;    Serial.println(&quot;Connection Failed.&quot;);&#xA;  } else {&#xA;    Serial.println(&quot;Connection Succesful!&quot;);&#xA;    Serial.println(WiFly.ip());&#xA;    Serial.println(&quot;Receving Client Input...&quot;);&#xA;    s.begin();&#xA;&#xA;  }&#xA;}&#xA;void loop() { &#xA;   WiFlyClient c = s.available();&#xA;   if(c) {&#xA;   Serial.println(&quot;Server Ready.&quot;);&#xA;   current_line_is_blank=true;&#xA;   while(c.connected()) {&#xA;     Serial.println(&quot;Client Connected.&quot;);&#xA;     if(c.available()) {&#xA;       Serial.println(&quot;Client Available for data.&quot;);&#xA;       char tmp = c.read();&#xA;       Serial.println(tmp);&#xA;       if(tmp == '\n' &amp;amp;&amp;amp; current_line_is_blank) {&#xA;         Serial.println(&quot;Sent OK Response.&quot;);&#xA;         c.println(&quot;HTTP/1.1 200 OK&quot;);&#xA;         c.println(&quot;Content-Type: text/html&quot;);&#xA;         c.println();&#xA;         c.print(&quot;WiFly Webserver Running!&quot;);&#xA;         c.println(&quot;&amp;lt;br /&amp;gt;&quot;);&#xA;         break;&#xA;       }&#xA;      if (tmp == '\n') {&#xA;          // we're starting a new line&#xA;          current_line_is_blank = true;&#xA;        } else if (tmp != '\r') {&#xA;          // we've gotten a character on the current line&#xA;          current_line_is_blank = false;&#xA;        }&#xA;       }&#xA;   }&#xA;   }&#xA;    delay(2000);&#xA;    c.stop();&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I am using Arduino Uno, and the serial monitor looks like this:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;Connection Succesful!&#xA;10.100.1.173&#xA;Receving Client Input...&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Is there anything obviously wrong with my code?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT:&#xA;I now have a new shield, but I'm still working with the same problem. Is it a malfunction in the hardware? I just can't figure this out!&lt;/p&gt;&#xA;" OwnerUserId="498" LastEditorUserId="498" LastEditDate="2013-02-19T01:47:30.850" LastActivityDate="2013-02-19T01:47:30.850" Title="Wifly Shield Not Connecting" Tags="&lt;arduino&gt;&lt;software&gt;&lt;wifi&gt;&lt;c&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="706" PostTypeId="2" ParentId="704" CreationDate="2012-12-20T04:49:39.110" Score="1" Body="&lt;p&gt;I've never programmed an Arduino or used this module, but from a quick look at the code and its output, it looks like only setup() is getting run, while loop() is the source of the problem (sort of expected). Try adding a println statement before checking for c to see if the loop gets run at all. &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;...&#xA;void loop() { &#xA;  WiFlyClient c = s.available();&#xA;  Serial.println(&quot;Looping...&quot;);&#xA;  if(c) {&#xA;    Serial.println(&quot;Server Ready.&quot;);&#xA;    ...&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Assuming the above checks out, my hunch is that the problem is in the first line of the loop:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;...&#xA;WiFlyClient c = s.available();&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Why are you initializing the client, c, with the server's availability? This seems to imply that the if statement is essentially testing for the server's availability, instead of the client's availability. What's more, you then also run c.connected(), c.available(), and c.println(), which is somewhat at odds with c's initialization.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Try checking what you need to initialize c with and then probably switch the if statement as follows:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;...&#xA;if(c.available()) {&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Just my 2c. &lt;/p&gt;&#xA;" OwnerUserId="295" LastActivityDate="2012-12-20T04:49:39.110" CommentCount="2" />
  <row Id="707" PostTypeId="2" ParentId="609" CreationDate="2012-12-20T16:59:54.730" Score="2" Body="&lt;p&gt;To offer an answer that (specifically) addresses the question, as I understand it, the RaspberryPi offers (either as part of the standard Pi distros, as add-ons or compilable from source) pretty much anything and everything that the Linux operating system provides.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, for those that are not part of the distro (or from the repositories) there are portability issues, due to the specific hardware platform.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;does this essentially allow for anything that would run on a linux box&#xA;  (raspberryPi) to run and operate your robot&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;As such, I'm of the opinion that &quot;Maybe&quot; is the answer... but whether I'd trust a robot to a Pi is another question entirely.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;That having been said, now some personal opinion:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Yes I have a couple of Pis that I'm experimenting with, but I've rapidly broken through the hype surrounding the Raspie.  I've come to the conclusion that it is so general purpose that it is, in effect, a solution looking for a problem.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As an embedded prototyping system, one is better off with an Arduino or a PIC dev-kit, in my humble opinion.&lt;/p&gt;&#xA;" OwnerUserId="134" LastActivityDate="2012-12-20T16:59:54.730" CommentCount="2" />
  <row Id="708" PostTypeId="2" ParentId="327" CreationDate="2012-12-20T20:37:37.580" Score="2" Body="&lt;p&gt;I have built a lot of walking robots, in my experience if you can't get it to walk by programming a gait you are not going to get it to learn because you don't know what it is supposed to do and the search space is too large. Using an Arduino you may be able to get it to fine tune some movements iff you can define good movements.&lt;/p&gt;&#xA;" OwnerUserId="653" LastActivityDate="2012-12-20T20:37:37.580" CommentCount="1" />
  <row Id="709" PostTypeId="1" AcceptedAnswerId="713" CreationDate="2012-12-20T20:49:33.020" Score="21" ViewCount="688" Body="&lt;p&gt;I was working on a project to make a bedside night light out of a stuffed butterfly or bird. I was making a mechanism to make the wings flap with a servo motor and some small gears. The &lt;a href=&quot;http://www.vexrobotics.com/276-2162.html&quot;&gt;servo motor&lt;/a&gt; was very loud as it moved. And this was whether or not the servo was moving large amounts, small amounts, fast or slow. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've worked with small servos before and realized they usually are pretty noisy machines, but I can't really explain why.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Why are small servo motors noisy when they move? Is it backlash in the internal gearing?&lt;/p&gt;&#xA;" OwnerUserId="654" LastEditorUserId="654" LastEditDate="2013-05-21T21:01:53.427" LastActivityDate="2013-05-21T21:01:53.427" Title="Why are Servo Motors so noisy?" Tags="&lt;rcservo&gt;" AnswerCount="1" CommentCount="1" FavoriteCount="5" />
  <row Id="711" PostTypeId="2" ParentId="533" CreationDate="2012-12-20T22:01:40.420" Score="2" Body="&lt;p&gt;I started where you are but found lots of misconceptions and omissions so I started a small page on History making robots at &lt;a href=&quot;http://davidbuckley.net/DB/HistoryMakers.htm&quot; rel=&quot;nofollow&quot;&gt;http://davidbuckley.net/DB/HistoryMakers.htm&lt;/a&gt;&#xA;Reuben Hogget contributed a lot of information and after our trip round Europe talking to researchers who had built robots in the 1950s he started &lt;a href=&quot;http://cyberneticzoo.com&quot; rel=&quot;nofollow&quot;&gt;http://cyberneticzoo.com&lt;/a&gt; - not everything about the history of robotics is there yet. Humans have talked about robots (by other names) for a long time. &#xA;In the Greek myths Hephaestus creates 'walking' tripods and golden ladies to help him. The Greeks built large animated sculptures such as a 12 foot high statue of Nysa mounted on a huge cart. Heron of Alexandria (~50AD) created animated figures for theatre shows and also described mechanically programmable devices. There was nothing particularly new about Leonardo's drawings of a mechanical statue of a knight, it is just that his drawings have survived. The first 'modern' 'robot' was probably Dederick's 1868 steam man (Boilerplate is fictional). From early in the last century there have been many drawings of electromechanical men and several working ones (albeit of limited funtionality and really precursors of Disney's animatronic figures). Capek's RUR really only went along with people's fascination with robots (the robots he describes though are biological). A major advance came in the 1940s with Grey Walter's tortoises Elmer and Elsie which had simple electronic brains. The mobile robot Shakey (1966) was another 'milestone'. After that you have the walking robots from Waseda University, the subsumption (a dead end) robots from the MIT Mobile Robot Lab, and then Honda's P2 humanoid which led to a veritable explosion of humanoid robots from Japan followed by Korea and others. Whatever you read, all the writers will have their own slant on things and it is a huge field. Reuben has well over 500 posts on robotics history and PlastiPals.com is the site to read for more modern robots. &lt;/p&gt;&#xA;" OwnerUserId="653" LastActivityDate="2012-12-20T22:01:40.420" />
  <row Id="712" PostTypeId="1" AcceptedAnswerId="722" CreationDate="2012-12-20T22:33:51.033" Score="4" ViewCount="225" Body="&lt;p&gt;I'm currently building a robot with four legs (&lt;a href=&quot;http://en.wikipedia.org/wiki/Quadrupedalism/&quot; rel=&quot;nofollow&quot;&gt;quadruped&lt;/a&gt;), 3 DOF (Degrees of Freedom) and Its been suggested &lt;a href=&quot;http://robotics.stackexchange.com/questions/327/learning-algorithms-for-walking-quadruped/&quot;&gt;here&lt;/a&gt; that I use a simulator to do the learning on a computer and then upload the algorithms to the robot. I'm using an &lt;a href=&quot;http://arduino.cc&quot; rel=&quot;nofollow&quot;&gt;Arduino Uno&lt;/a&gt; for the robot and what software could I use to simulate the learning and then be able to upload to the Arduino board?&lt;/p&gt;&#xA;" OwnerUserId="374" LastEditorUserId="374" LastEditDate="2012-12-20T22:41:26.500" LastActivityDate="2012-12-25T16:38:43.793" Title="Quadruped Learning Simulator" Tags="&lt;mobile-robot&gt;&lt;arduino&gt;&lt;microcontroller&gt;&lt;machine-learning&gt;&lt;simulator&gt;" AnswerCount="2" CommentCount="2" FavoriteCount="2" />
  <row Id="713" PostTypeId="2" ParentId="709" CreationDate="2012-12-21T00:42:58.203" Score="26" Body="&lt;p&gt;They aren't.  The word servo refers solely to a device that uses negative feedback for control.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Gearboxes or cheap brushed motors can be noisy.  You can get very quiet systems if you are willing to pay for it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cheap hobby grade servos can sometimes chatter if they do not settle in a stable state.  This is normal and is caused by poor tuning, a lack of a deadband, and backlash between the motor and the encoder (potentiometer).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Gearbox noise is caused by the spur gear teeth hitting eachother.  You can use heavier grease or quieter gear geometries such as helical gears which mesh smoothly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/kOyp1.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are also piezoelectric or memory wire based servos which are completely silent.&lt;/p&gt;&#xA;" OwnerUserId="65" LastEditorUserId="65" LastEditDate="2012-12-21T00:48:47.563" LastActivityDate="2012-12-21T00:48:47.563" CommentCount="3" />
  <row Id="714" PostTypeId="2" ParentId="712" CreationDate="2012-12-21T00:43:02.943" Score="1" Body="&lt;p&gt;This wouldn't cover the robot simulation, but the &lt;a href=&quot;http://docs.opencv.org/modules/ml/doc/ml.html&quot; rel=&quot;nofollow&quot;&gt;OpenCV Machine Learning Library&lt;/a&gt; might be useful for evaluating learning algorithms and training parameters to download to the robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It includes a neural network implementation, which may be of particular interest for this problem.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;OpenCv is a standard library too, and would likely integrate well with some other simulator for the robot itself.&lt;/p&gt;&#xA;" OwnerUserId="479" LastEditorUserId="479" LastEditDate="2012-12-25T16:38:43.793" LastActivityDate="2012-12-25T16:38:43.793" CommentCount="5" />
  <row Id="715" PostTypeId="2" ParentId="533" CreationDate="2012-12-21T02:39:41.540" Score="-2" Body="&lt;p&gt;I think it is better to start with explaining about an automation. And then go for robotics and their milestones. &lt;/p&gt;&#xA;" OwnerUserId="655" LastActivityDate="2012-12-21T02:39:41.540" />
  <row Id="716" PostTypeId="1" AcceptedAnswerId="733" CreationDate="2012-12-21T10:31:13.480" Score="3" ViewCount="255" Body="&lt;p&gt;Often when I need to perform model fitting I find myself looking for a decent C++ library to do this. There is the RANSAC implementation in &lt;a href=&quot;http://reference.mrpt.org/svn/classmrpt_1_1math_1_1_model_search.html&quot; rel=&quot;nofollow&quot;&gt;MRPT&lt;/a&gt;, but I was wondering if there are alternatives available.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To give an example for the type of problems I would like to solve: For a set $A$ of (approx 500) 3D point pairs $(a, b)$ I would like to find the Isometry transform $T$, which maps the points onto each other so that $|(a - Tb)| &amp;lt; \epsilon$. I would like to get the largest subset of $A$ for a given $\epsilon$. Alternatively I guess I could have the subset size fixed and ask for the lowest $\epsilon$.&lt;/p&gt;&#xA;" OwnerUserId="127" LastActivityDate="2012-12-28T08:48:55.087" Title="C++ Robust Model Fitting Library" Tags="&lt;c++&gt;&lt;ransac&gt;" AnswerCount="1" FavoriteCount="1" />
  <row Id="717" PostTypeId="2" ParentId="689" CreationDate="2012-12-21T14:00:35.390" Score="2" Body="&lt;p&gt;I've seen a number of systems in this configuration and most went for an outside track solution. Part of the reason for this is control of bend radius. With an outside track, the bend is obvious at all positions and it is clear when you &lt;em&gt;run out of track&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are bothered about cabling complexity, you could put more of the electronics on the rotated stage, so instead of having motor, encoder and other cables all running down the energy chain, you would just have power and data lines, with everything else done by remote i/o.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Taking this to the extreme, I've worked at a place where this technique was used with slip rings for a continuously revolving robot. It had two scara arms and all of the control electronics for them mounted on a revolving platform. The data slip rings were horribly noisy, so the data connection had to have more ECC than normal, but it all worked well.&lt;/p&gt;&#xA;" OwnerUserId="37" LastActivityDate="2012-12-21T14:00:35.390" CommentCount="1" />
  <row Id="718" PostTypeId="1" CreationDate="2012-12-21T14:47:11.653" Score="6" ViewCount="135" Body="&lt;p&gt;How do we know that an object is contained inside another object or is just lying on top of it? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Lets take an example of a cup-plate-spoon. The cup is lying on top of the plate. But the spoon is inside the cup. How do we distinguish between the 2 situations? What are the criteria to decide whether A is contained inside B or just lying above B?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am trying to solve it using kinect.&lt;/p&gt;&#xA;" OwnerUserId="658" LastEditorUserId="350" LastEditDate="2012-12-21T14:58:15.877" LastActivityDate="2012-12-28T08:35:18.263" Title="How can computer vision distinguish one object being contained by another vs being on top of it?" Tags="&lt;kinect&gt;&lt;computer-vision&gt;&lt;algorithm&gt;" AnswerCount="2" FavoriteCount="1" />
  <row Id="719" PostTypeId="5" CreationDate="2012-12-21T15:01:02.210" Score="0" ViewCount="2" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2012-12-21T15:01:02.210" LastActivityDate="2012-12-21T15:01:02.210" />
  <row Id="720" PostTypeId="4" CreationDate="2012-12-21T15:01:02.210" Score="0" Body="&quot;RANdom SAmple Consensus&quot;. It is an iterative method to estimate parameters of a mathematical model from a set of observed data which contains outliers." OwnerUserId="350" LastEditorUserId="350" LastEditDate="2012-12-21T16:04:56.880" LastActivityDate="2012-12-21T16:04:56.880" />
  <row Id="721" PostTypeId="2" ParentId="718" CreationDate="2012-12-21T15:26:56.820" Score="7" Body="&lt;p&gt;Actually we don't. This is the source of myriad visual illusions. Through a life time of experience we learn context which tells us when one thing can be on another vs. in it. But even then a sculpture can be built to trick us. For example it can look like a plate, cup, and spoon organized in a certain way but in fact be non of the above. A good example of this are the &lt;a href=&quot;http://io9.com/5935888/mc-eschers-impossible-structures-printed-in-3d&quot;&gt;3D printed Escher pieces&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The Kinect has the added ability to sense depth. With such information you may be able to make better determinations but we can still conceive of structures that would trick the system. I cannot speak to what CV methods exist to assist in your endeavor but I know that &lt;a href=&quot;http://en.wikipedia.org/wiki/Deep_learning&quot;&gt;Deep Learning&lt;/a&gt; from the ML world has been making inroads here.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2012-12-21T15:26:56.820" CommentCount="2" />
  <row Id="722" PostTypeId="2" ParentId="712" CreationDate="2012-12-23T16:10:37.183" Score="1" Body="&lt;p&gt;&lt;a href=&quot;http://gazebosim.org/&quot; rel=&quot;nofollow&quot;&gt;Gazebo&lt;/a&gt; is a good tool for what you want to do. Since your using a custom robot you will need to &lt;a href=&quot;http://gazebosim.org/user_guide/started__models.html&quot; rel=&quot;nofollow&quot;&gt;build a model&lt;/a&gt; for the simulator to use. They have managed to make doing so pretty easy but for a quadraped I can imagine it will take a bit of time.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Gazebo is also nice because it works well with &lt;a href=&quot;http://ros.org&quot; rel=&quot;nofollow&quot;&gt;ROS&lt;/a&gt; which means that if you build you could build a program to control your robot and send the commands to the simulated robot via the integration or to the real robot via &lt;a href=&quot;http://www.ros.org/wiki/rosserial&quot; rel=&quot;nofollow&quot;&gt;rosserial&lt;/a&gt;. Just beware that if you have not used any of these tools then it will take some time to develop your solution.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2012-12-23T16:10:37.183" CommentCount="2" />
  <row Id="723" PostTypeId="2" ParentId="696" CreationDate="2012-12-23T20:51:15.807" Score="1" Body="&lt;p&gt;It appears that Nikolaus Correll at CU-Boulder is doing research with a derivative of the kilobots: &lt;a href=&quot;http://www.colorado.edu/news/releases/2012/12/14/cu-boulder-team-develops-swarm-pingpong-ball-sized-robots&quot; rel=&quot;nofollow&quot;&gt;http://www.colorado.edu/news/releases/2012/12/14/cu-boulder-team-develops-swarm-pingpong-ball-sized-robots&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="110" LastActivityDate="2012-12-23T20:51:15.807" CommentCount="1" />
  <row Id="724" PostTypeId="2" ParentId="693" CreationDate="2012-12-23T21:13:46.587" Score="2" Body="&lt;p&gt;Yes, there is a difference between the Create and an off-the-shelf Roomba.  The Create doesn't have a vacuum motor or any of the cleaning brushes.  And there is an empty payload bay where all of the cleaning stuff used to be.  Additionally, the Create has an added microcontroller on it that you can push code onto.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;But both the create and the Roomba let you control the robot directly over a serial interface.  I think this API is the same between the Create and the 500 series Roomba.  I am not sure about the 600 or 700 series Roombas, but i kind of doubt it changed.&lt;/p&gt;&#xA;" OwnerUserId="110" LastActivityDate="2012-12-23T21:13:46.587" CommentCount="1" />
  <row Id="725" PostTypeId="1" AcceptedAnswerId="729" CreationDate="2012-12-24T00:50:05.517" Score="7" ViewCount="154" Body="&lt;p&gt;&lt;strong&gt;There is a lot of background here, scroll to the bottom for the question&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am trying out the map joining algorithm described in &lt;a href=&quot;http://services.eng.uts.edu.au/~sdhuang/Shoudong_IROS_2010.pdf&quot;&gt;How Far is SLAM From a Linear Least Squares Problem&lt;/a&gt;; specifically, formula (36).  The code I have written seems to always take the values of the second map for landmark positions.  My question is, am I understanding the text correctly or am I making some sort of error. I'll try to explain the formulas as I understand them and show how my code implements that.  I'm trying to do the simple case of joining just two local maps. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;From the paper (36) says joining two local maps is finding the a state vector $X_{join,rel}$ that minimizes:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$&#xA;\sum_{j=1}^{k}(\hat{X_j^L} - H_{j,rel}(X_{join,rel}))^T(P_j^L)^{-1}(\hat{X_j^L} - H_{j,rel}(X_{join,rel}))&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Expanded for two local maps $\hat{X_1^L}$ and $\hat{X_2^L}$ I have:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$&#xA;(\hat{X_1^L} - H_{j,rel}(X_{join,rel}))^T(P_1^L)^{-1}(\hat{X_1^L} - H_{j,rel}(X_{join,rel})) + (\hat{X_2^L} - H_{j,rel}(X_{join,rel}))^T(P_2^L)^{-1}(\hat{X_2^L} - H_{j,rel}(X_{join,rel}))&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As I understand it, a submap can be viewed as an integrated observation for a global map, so $P^L_j$ is noise associated with the submap (as opposed to being the process noise in the EKF I used to make the submap, which may or may not be different). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The vector $X_{join,rel}$ is the pose from the first map, the pose from the second map and the union of the landmarks in both maps.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The function $H_{j,rel}$ is:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$&#xA;\begin{bmatrix} X_{r_{je}}^{r_{(j-1)e}}\\&#xA;                 \phi_{r_{je}}^{r_{(j-1)e}}\\&#xA;                 R(\phi_{r_{(j-1)e}}^{r_{m_{j1}e}})&#xA;                        (X^{r_{m_{j1}e}}_{f_{j1}} -&#xA;                         X^{r_{m_{j1}e}}_{r_{(j-1)e}})\\.\\.\\.\\&#xA;                 R(\phi_{r_{(j-1)e}}^{r_{m_{jl}e}})&#xA;                        (X^{r_{m_{jl}e}}_{f_{jl}} -&#xA;                         X^{r_{m_{jl}e}}_{r_{(j-1)e}})\\&#xA;                         X_{f_{j(l+1)}}^{r_{j-1e}}\\&#xA;                         .\\.\\.\\&#xA;                         X_{f_{jn}}^{r_{j-1e}}&#xA;\end{bmatrix}&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;I'm not convinced that my assessment below is correct:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The first two elements are the robot's pose in the reference frame of the previous map.  For example, for map 1, the pose will be in initial frame at $t_0$; for map 2, it will be in the frame of map 1.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The next group of elements are those common to map 1 and map 2, which are transformed into map 1's reference frame.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The final rows are the features unique to map 2, in the frame of the first map.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;My matlab implementation is as follows:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;function [G, fval, output, exitflag] = join_maps(m1, m2)&#xA;    x = [m2(1:3);m2];&#xA;    [G,fval,exitflag,output] = fminunc(@(x) fitness(x, m1, m2), x, options);&#xA;end&#xA;&#xA;function G = fitness(X, m1, m2)&#xA;    m1_f = m1(6:3:end);&#xA;    m2_f = m2(6:3:end);&#xA;    common = intersect(m1_f, m2_f);&#xA;    P = eye(size(m1, 1)) * .002;&#xA;    r = X(1:2);&#xA;    a = X(3);&#xA;    X_join = (m1 - H(X, common));&#xA;    Y_join = (m2 - H(X, common));&#xA;    G = (X_join' * inv(P) * X_join) + (Y_join' * inv(P) * Y_join);&#xA;end&#xA;&#xA;function H_j = H(X, com)&#xA;    a0 = X(3);&#xA;    H_j = zeros(size(X(4:end)));&#xA;    H_j(1:3) = X(4:6);&#xA;    Y = X(1:2);&#xA;    len = length(X(7:end));&#xA;    for i = 7:3:len&#xA;        id = X(i + 2);&#xA;        if find(com == id)&#xA;            H_j(i:i+1) = R(a0) * (X(i:i+1) - Y);&#xA;            H_j(i+2) = id;&#xA;        else  % new lmk&#xA;            H_j(i:i+2) = X(i:i+2);&#xA;        end&#xA;    end&#xA;end&#xA;&#xA;function A = R(a)&#xA;    A = [cos(a) -sin(a); &#xA;         sin(a)  cos(a)];&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I am using the &lt;a href=&quot;http://www.mathworks.com/help/optim/ug/fminunc.html&quot;&gt;optimization toolbox&lt;/a&gt; to find the minimum of the fitness function described above.  The fitness function itself is pretty straightforward I think.  The function H returns the vector H described above.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;The result is:&lt;/strong&gt;&#xA;When I run join_maps on the two vectors&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;map_1 = [3.7054;1.0577;-1.9404; %robot x, y, angle&#xA;      2.5305;-1.0739;81.0000]; % landmark x, y, id&#xA;map_2 = [3.7054;1.0577;-1.9404;&#xA;         2.3402;-1.1463;81.0000]; % note the slightly different x,y&#xA;&#xA;[G,fv,output,exitflag] = join_maps(map_1, map_2)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;The output is:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;Warning: Gradient must be provided for trust-region algorithm;&#xA;  using line-search algorithm instead. &#xA;&amp;gt; In fminunc at 341&#xA;  In join_maps at 7&#xA;&#xA;Local minimum found.&#xA;&#xA;Optimization completed because the size of the gradient is less than&#xA;the default value of the function tolerance.&#xA;&#xA;&amp;lt;stopping criteria details&amp;gt;&#xA;&#xA;&#xA;Local minimum possible.&#xA;&#xA;fminunc stopped because it cannot decrease the objective function&#xA;along the current search direction.&#xA;&#xA;&amp;lt;stopping criteria details&amp;gt;&#xA;&#xA;G = &#xA;      3.7054&#xA;      1.0577&#xA;     -1.9404&#xA;      3.7054&#xA;      1.0577&#xA;     -1.9404&#xA;      2.3402&#xA;     -1.1463&#xA;      81.0000&#xA;&#xA; fv =&#xA;     1.3136e+07&#xA;  output = &#xA;     iterations: 1&#xA;      funcCount: 520&#xA;       stepsize: 1.0491e-16&#xA;  firstorderopt: 1.6200e+05&#xA;      algorithm: 'medium-scale: Quasi-Newton line search'&#xA;        message: [1x362 char]&#xA;  exitflag =&#xA;   5&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;The question:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My program gives map 2 is the minimum of the map joining function.  It seems like the minimum should be somewhere between map 1 and map 2.  I'm pretty sure the problem is with the matrix H.  What am I doing wrong?&lt;/p&gt;&#xA;" OwnerUserId="502" LastActivityDate="2012-12-26T19:10:05.097" Title="Least squares map joining" Tags="&lt;slam&gt;" AnswerCount="1" FavoriteCount="3" />
  <row Id="726" PostTypeId="1" CreationDate="2012-12-24T20:24:04.710" Score="5" ViewCount="215" Body="&lt;p&gt;I am working on a quadrotor.  I know its position -- $a$, where I would like to go -- target position $b$, and from that I calculate a vector $c$ -- a unit vector that will take me to my target:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;c = b - a&#xA;c = normalize(c)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Since a quadrotor can move in any direction without rotation, what I have tried to do is &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;rotate $c$ by the robots yaw angle&lt;/li&gt;&#xA;&lt;li&gt;split it into its $x, y$ components &lt;/li&gt;&#xA;&lt;li&gt;pass them to the robot as roll and pitch angles.  &lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;The problem is that if the yaw is 0&amp;deg; &amp;plusmn;5 then this works, but if the yaw is near +90 or -90 it fails and steers to wrong directions. My question is am I missing something obvious here?&lt;/p&gt;&#xA;" OwnerUserId="665" LastEditorUserId="350" LastEditDate="2012-12-27T14:31:57.600" LastActivityDate="2014-01-10T16:10:50.010" Title="Guiding a Quadrotor Towards a Target" Tags="&lt;quadrotor&gt;&lt;uav&gt;&lt;navigation&gt;" AnswerCount="2" CommentCount="5" FavoriteCount="2" />
  <row Id="727" PostTypeId="2" ParentId="726" CreationDate="2012-12-24T20:39:21.067" Score="3" Body="&lt;p&gt;Re-implementing your solution, I get this:&lt;/p&gt;&#xA;&#xA;&lt;h1&gt;Angle Between Vectors&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;First, you want the angle between points $A$ and $B$ -- not specifically the unit vector.&#xA;&lt;a href=&quot;http://i.stack.imgur.com/m7CLt.jpg&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/m7CLtm.jpg&quot; alt=&quot;Angle between 2 points&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(&lt;a href=&quot;http://fxprogramming.blogspot.com/2011/01/angle-between-2-points-in-2d-space.html&quot; rel=&quot;nofollow&quot;&gt;via Fx Programming&lt;/a&gt;):&#xA;$\theta = math.atan2(B_{x}-A_{x}, B_{y}-A_{y})$&lt;/p&gt;&#xA;&#xA;&lt;h1&gt;Vehicle Yaw Angle&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;Next (and I suspect this is your problem), you need to &lt;em&gt;subtract&lt;/em&gt; the vehicle's yaw angle $\psi$ from your calculated $\theta$.  &lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Heading vs Yaw&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;If you're using a compass for the &quot;yaw angle&quot; of your vehicle, this could also be your mistake; &lt;strong&gt;heading and yaw are not the same&lt;/strong&gt;. &#xA;Compass heading is zero along the positive $y$ axis, increasing as it turns &lt;em&gt;clockwise&lt;/em&gt;:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://ccphysics.us/henriques/a105l/compass.gif&quot; alt=&quot;Compass rose&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Yaw is zero along the positive $x$ axis, increasing as it turns &lt;em&gt;counterclockwise&lt;/em&gt;:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/commons/thumb/1/13/Polar_graph_paper.svg/300px-Polar_graph_paper.svg.png&quot; alt=&quot;Polar graph&quot;&gt; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The 90 degree overlap between these measurements, combined with adding (instead of subtracting) the vehicle yaw from the desired yaw, may be why things worked when your target was within &amp;plusmn;5&amp;deg; and behaved badly at &amp;plusmn;90&amp;deg;.&lt;/p&gt;&#xA;&#xA;&lt;h1&gt;Conversion to Component X and Y&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;From there, you say that you are converting this result $(\theta-\psi)$ into its $x$ and $y$ components, passing them to the robot as the roll and pitch angles.  With the above corrections, you should get the desired result at this point.  However, directly mapping these components to tilt angles might be problematic since you are only considering the difference in position, and not the velocity (really, the momentum) of the vehicle.&lt;/p&gt;&#xA;&#xA;&lt;h1&gt;PID Control&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;You may be best served by using PID control loops for the roll and pitch of the vehicle.  That is, once you fix your code and are able to hit your target, my guess is that you'll start overshooting it instead -- oscillating back and forth.  A correctly-tuned PID will prevent that from happening while still allowing you to approach the target quickly.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Instead of plugging your $x$ and $y$ into roll and pitch, consider them to be the &lt;em&gt;error&lt;/em&gt; values that the roll and pitch PIDs accept as input.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2014-01-10T16:10:50.010" LastActivityDate="2014-01-10T16:10:50.010" CommentCount="6" />
  <row Id="728" PostTypeId="2" ParentId="726" CreationDate="2012-12-25T01:01:59.903" Score="4" Body="&lt;p&gt;I'll assume you're talking about a 3D vector here. Can you just generalize &lt;code&gt;normalize()&lt;/code&gt; like that? Is it that common (i've never seen it so if it is, then news to me). Otherwise, obvious compass wrap issues apply to each of the X and Y components. Why not call them roll and/or pitch and/or yaw? (mixing 3D and 2D nomenclature confuses the question).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My 2D normalize looks something like this;&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;int Pilot_QuickestTurnTo(int hdgNow, int hdgNew)&#xA;{&#xA;    hdgNow = Pilot_Hdg360(hdgNow);&#xA;    hdgNew = Pilot_Hdg360(hdgNew);&#xA;    if (hdgNow &amp;lt; hdgNew)&#xA;        hdgNow += 360;&#xA;    int left = hdgNow - hdgNew;&#xA;        return (left &amp;lt; 181 ? -left : 360 - left);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;If it is indeed a quad, I assume your X and Y components are really YAW, Altitude ( (X, Y) &amp;amp; Z). You'll need to handle the &lt;code&gt;YAW(X, Y)&lt;/code&gt; in 2D, and simply drop or gain altitude for Z (and again that's why I suspect normalize is more than you have it as).&lt;/p&gt;&#xA;" OwnerUserId="274" LastEditorUserId="350" LastEditDate="2012-12-27T14:18:24.683" LastActivityDate="2012-12-27T14:18:24.683" />
  <row Id="729" PostTypeId="2" ParentId="725" CreationDate="2012-12-26T19:10:05.097" Score="2" Body="&lt;p&gt;This seems to work correctly and is a much simpler solution:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;function [X, FVAL, EXITFLAG, OUTPUT, GRAD] = join_maps(m1, m2)&#xA;    p = [m1(1:3);m2(1:3)];&#xA;    x1 = [p;m1(4:end)];&#xA;    x2 = [p;m2(4:end)];&#xA;    guess_0 = zeros(size(x1,1),1);&#xA;    q = @(x)x'*eye(length(x))*x;&#xA;    fit = @(x)q(x1-x)+q(x2-x);&#xA;    [X,FVAL,EXITFLAG,OUTPUT,GRAD] = fminunc(fit ,guess_0);&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I've changed the output to better match the description for fminunc.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The output with map_1 and map_2 is&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;X =&#xA; 3.7054&#xA; 1.0577&#xA;-1.9404&#xA; 3.7054&#xA; 1.0577&#xA;-1.9404&#xA; 2.4353&#xA;-1.1101&#xA; 81.0000&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;In this case, there is no need to call H(X), because the first two poses are identical, so the two maps share the same frame of reference.  The function H just transforms the state estimate into the frame of reference of the submap.&lt;/p&gt;&#xA;" OwnerUserId="502" LastActivityDate="2012-12-26T19:10:05.097" />
  <row Id="730" PostTypeId="1" CreationDate="2012-12-27T00:15:13.797" Score="2" ViewCount="50" Body="&lt;p&gt;Have you ever seen one those video games that has headset/goggles you stand in and look around the virtual scene with? I'm building one of those, and I'm trying to design a simple controller. I need the output of the controller to emulate a mouse input. So if you look to the left, it's as if you were moving the mouse to the left. Supposing I use optical encoders, the pan and tilt will need to be in separate locations (a couple of inches apart). It seems that many mouse hacks online have the components very close together.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Do you think it's possible to have one of the encoders some distance away from the controller chip? For OEM purposes, is there a good mouse controller chip that will output USB protocol mouse movements that I could buy in bulk?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Many thanks for any suggestions. Cheers&lt;/p&gt;&#xA;" OwnerUserId="671" LastActivityDate="2012-12-27T00:34:24.157" Title="Good method for building a pan and tilt controller?" Tags="&lt;microcontroller&gt;" AnswerCount="1" />
  <row Id="731" PostTypeId="2" ParentId="730" CreationDate="2012-12-27T00:34:24.157" Score="2" Body="&lt;p&gt;Probably not the answer you want, but IMU boards have gotten so cheap and easy I'm not sure if going the mouse encoder route is worth the trouble.  I fly FPV quads, and I have the parts for pan and tilt, although not installed yet. The head tracking is built into the &lt;a href=&quot;http://www.youtube.com/watch?v=WveSggtwwNQ&quot; rel=&quot;nofollow&quot;&gt;goggles&lt;/a&gt; (ie no added costs). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I also installed a MultiWii Flight control board this morning and was watching real time signals show roll/pitch/yaw(heading) with the option to add full gps. The &lt;a href=&quot;http://witespyquad.gostorego.com/flight-controllers/flip-mwc-flight-controller.html&quot; rel=&quot;nofollow&quot;&gt;board&lt;/a&gt; costs less than \$20. It would be pretty easy to install that on a hat, and add a &lt;a href=&quot;http://www.rctimer.com/index.php?gOo=goods_details.dwt&amp;amp;goodsid=764&amp;amp;productname&quot; rel=&quot;nofollow&quot;&gt;Bluetooth option&lt;/a&gt; (another \$8) for easy robust wireless pan and tilt tracking. You would need to do some sort of HUI device driver though, I do not know of anything already existing. Then again, if you are doing all your own software you could access the bluetooth stream directly and avoid needing a driver.&lt;/p&gt;&#xA;" OwnerUserId="274" LastActivityDate="2012-12-27T00:34:24.157" CommentCount="2" />
  <row Id="732" PostTypeId="2" ParentId="718" CreationDate="2012-12-27T23:26:01.143" Score="3" Body="&lt;p&gt;The problem is much easier, when you want solve this for specific object categories like cup-plate-spoon instead of any generic pair of objects. Also in my opinion there degeneracies as mentioned by DaemonMaker is not going to happen in this case since we have depth image instead of just a 2D image.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When you know the objects in scene and you have a depth image, it is possible to estimate the full 3D orientation (pose) of each of those objects. If the objects in question are rigid, some sort of &lt;a href=&quot;http://pointclouds.org/documentation/tutorials/iterative_closest_point.php&quot; rel=&quot;nofollow&quot;&gt;ICP&lt;/a&gt; may be enough in getting this pose. For harder scenarios where the object is non-rigid (humans) or you don't know the exact specific model of the object (say tea cup vs coffee cup), you should refer to some computer-vision/Kinect literature. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Once you have the 3D poses of the objects, answering object-object 3D positional queries will be easier.&lt;/p&gt;&#xA;" OwnerUserId="674" LastEditorUserId="674" LastEditDate="2012-12-28T08:35:18.263" LastActivityDate="2012-12-28T08:35:18.263" CommentCount="1" />
  <row Id="733" PostTypeId="2" ParentId="716" CreationDate="2012-12-28T08:48:55.087" Score="4" Body="&lt;p&gt;&lt;a href=&quot;http://www.pointclouds.org/&quot; rel=&quot;nofollow&quot;&gt;PCL&lt;/a&gt; has a nice C++ templated &lt;a href=&quot;http://docs.pointclouds.org/trunk/group__sample__consensus.html&quot; rel=&quot;nofollow&quot;&gt;RANSAC library&lt;/a&gt; which can solve your problem.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you feel, PCL is too big of a dependency, then using &lt;a href=&quot;http://eigen.tuxfamily.org/dox/group__Geometry__Module.html#gab3f5a82a24490b936f8694cf8fef8e60&quot; rel=&quot;nofollow&quot;&gt;umeyama&lt;/a&gt; function in &lt;a href=&quot;http://eigen.tuxfamily.org/index.php?title=Main_Page&quot; rel=&quot;nofollow&quot;&gt;Eigen's&lt;/a&gt; geometry module is probably the easiest way towards a working solution for your problem.&lt;/p&gt;&#xA;" OwnerUserId="674" LastActivityDate="2012-12-28T08:48:55.087" CommentCount="1" />
  <row Id="734" PostTypeId="1" AcceptedAnswerId="735" CreationDate="2012-12-28T16:47:56.377" Score="5" ViewCount="60" Body="&lt;p&gt;When you've created a map with a SLAM implementation and you have some groundtruth data, what is the best way to determine the accuracy of that map?  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;My first thought is to use the Euclidean distance between the map and groundtruth. Is there some other measure that would be better?  I'm wondering if it's also possible to take into account the covariance of the map estimate in this comparison. &lt;/p&gt;&#xA;" OwnerUserId="502" LastActivityDate="2012-12-28T17:28:24.880" Title="Comparing maps to groundtruth" Tags="&lt;slam&gt;&lt;mapping&gt;" AnswerCount="1" CommentCount="1" FavoriteCount="2" />
  <row Id="735" PostTypeId="2" ParentId="734" CreationDate="2012-12-28T17:28:24.880" Score="5" Body="&lt;p&gt;Assuming the map is a point cloud and that you know the alignment between the ground truth data and the map then calculating the &lt;a href=&quot;http://en.wikipedia.org/wiki/Mean_squared_error&quot;&gt;mean squared error&lt;/a&gt; (MSE) would give you a relative understanding of the accuracy. A lower MSE would indicate they are very similar, 0 of course mean identical, and a high MSE would idicate they are very different.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you do not know the alignment between the ground truth and the map then you could use &lt;a href=&quot;http://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm&quot;&gt;expectation maximization&lt;/a&gt; over the alignments to find the best fit and then use MSE.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2012-12-28T17:28:24.880" CommentCount="2" />
  <row Id="736" PostTypeId="1" AcceptedAnswerId="737" CreationDate="2012-12-29T17:06:37.283" Score="9" ViewCount="413" Body="&lt;p&gt;I'm building a hobby 6-DOF robotic arm and am wondering what the best way is to communicate between the processors (3-4 AVRs, 18 inches max separation). I'd like to have the control loop run on the computer, which sends commands to the microprocessors via an Atmega32u4 USB-to-??? bridge.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some ideas I'm considering:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;RS485&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Pros: all processors on same wire, differential signal more robust&lt;/li&gt;&#xA;&lt;li&gt;Cons: requires additional chips, need to write (or find?) protocol to prevent processors from transmitting at the same time&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;UART loop (ie, TX of one processor is connected to RX of next)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Pros: simple firmware, processors have UART built in&lt;/li&gt;&#xA;&lt;li&gt;Cons: last connection has to travel length of robot, each processor has to spend cycles retransmitting messages&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;CANbus (I know very little about this)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;My main considerations are hardware and firmware complexity, performance, and price (I can't buy an expensive out-of-box system).&lt;/p&gt;&#xA;" OwnerUserId="681" LastActivityDate="2013-10-31T09:51:04.067" Title="Inter-processor communication for robotic arm" Tags="&lt;microcontroller&gt;&lt;electronics&gt;&lt;arm&gt;" AnswerCount="3" />
  <row Id="737" PostTypeId="2" ParentId="736" CreationDate="2012-12-29T23:48:03.293" Score="11" Body="&lt;p&gt;You want to use USB for communications with the computer. If you have a number of microcontrollers, you will probably only connect one of the microcontrollers directly to the computer. The other microcontrollers will need to get their commands from the main microcontroller.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The communication you choose will depend on a number of factors:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;required bandwidth (we will assume you are running them at 16MHz)&lt;/li&gt;&#xA;&lt;li&gt;complexity (wiring and coding)&lt;/li&gt;&#xA;&lt;li&gt;bi-directional, or master-slave&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Almost all options have built-in support on the AVR microcontroller. There is no option you might reasonably prefer over the built-in options which would require additional hardware. Because they have built-in support, the software complexity is all similar, in that you just configure the port (using registers), put the data to transmit in another register, then trigger the transmission by setting a bit in another register. Any data received is found in another register, and an interrupt is triggered so you can handle it. Whichever option you choose, the only difference is the change in register locations, and some changes to the configuration registers.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;A USART loop has the following features:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Maximum baud rate of CLK/16 = 1MHz (at 16MHz clock) which is a transfer rate of around 90KB/s&lt;/li&gt;&#xA;&lt;li&gt;fully bi-directional communications (no master or slave designation)&lt;/li&gt;&#xA;&lt;li&gt;requires separate wires between each pair of microcontrollers - the Atmega32u4 supports two USART ports natively, limiting the number of microcontrollers you can connect in a network in practice (or else you end up with a long string of microcontrollers - ie. connected in a linked list manner)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Note: this is also what you would use to get RS232 communication, except that because RS232 requires 10V, it requires a driver to get those voltage levels. For communication between microcontrollers, this is not useful (only voltage levels are changed).&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;RS485:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Essentially, you use the USART port in a different mode - there is no advantage in bandwidth, and it may only simplify the wiring slightly, but it also complicates it. This is not recommended.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Two-wire interface:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;This is also referred to as I2C. This means that all devices share the same two wires.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;You need a pull-up resistor on both wires&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;It is slow (because the pull-up resistors are limited in value, and there is increasing capacitance as the number of devices increases, and the wire length increases). For this AVR microcontroller, the speed is up to 400 kHz - slower than USART (but this speed depends on limiting your capacitance). The reason is that although a device drives the data wire low, the opposite transition is accomplished by letting the wire float high again (the pull-up resistor).&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;It is even slower when you consider that ALL communication shares the same limited bandwidth. Because all communication shares the same limited bandwidth, there may be delays in communication where data must wait until the network is idle before it can be sent. If other data is constantly being sent, it may also block the data from ever being sent.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;It does rely on a master-slave protocol, where a master addresses a slave, then sends a command/request, and the slave replies afterwards. Only one device can communicate at a time, so the slave must wait for the master to finish.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Any device can act as both a master and/or a slave, making it quite flexible.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;SPI&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;This is what I would recommend/use for general communication between microcontrollers.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;It is high speed - up to CLK/2 = 8MHz (for CLK at 16MHz), making it the fastest method. This is achievable because of its separate wire solely for the clock.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;The MOSI, MISO data, and SCK clock wires are shared across the whole network, which means it has simpler wiring.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;It is a master-slave format, but any device can be a master and/or slave. However, because of the slave select complications, for shared wiring (within the network), you should only use it in a hierarchical manner (unlike the two-wire interface). IE. if you organise all devices into a tree, a device should only be master to its children, and only a slave to its parent. That means that in slave mode, a device will always have the same master. Also, to do this correctly, you need to add resistors to MISO/MOSI/SCK to the upstream master, so that if the device is communicating downstream (when not selected as a slave), the communications will not affect communications in other parts of the network (note the number of levels you can do this using resistors is limited, see below for better solution using both SPI ports).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The AVR microcontroller can automatically tri-state the MOSI signal when it is slave-selected, and switch to slave mode (if in master).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Even though it might require a hierarchical network, most networks can be organised in a tree-like manner, so it is usually not an important limitation&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;The above can be relaxed slightly, because each AVR microcontroller supports two separate SPI ports, so each device can have different positions in two different networks.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Having said this, if you need many levels in your tree/hierarchy (more than 2), the above solution using resistors gets too fiddly to work. In this case, you should change the SPI network between each layer of the tree. This means each device will connect to its children on one SPI network, and its parent on the other SPI network. Although it means you only have a single tree of connections, the advantage is that a device can communicate with both one of its children and its parent at the same time and you don't have fiddly resistors (always hard to choose the right values).&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Because it has separate MOSI and MISO wires, both the master and slave can communicate at the same time, giving it a potential factor of two increase in speed. A extra pin is required for the slave-select for each additional slave, but this is not a big burden, even 10 different slaves requires only 10 extra pins, which can be easily accommodated on a typical AVR microcontroller.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;CAN&lt;/strong&gt; is not supported by the AVR microcontroller you have specified. As there are other good options, it is probably not important in this case anyways.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;The recommendation is &lt;strong&gt;SPI&lt;/strong&gt;, because it is fast, the wiring isn't too complex, and doesn't require fiddly pull-up resistors. In the rare case where SPI doesn't fully meet your needs (probably in more complicated networks), you can use multiple options (eg. use both SPI ports, along with the two-wire interface, as well as pairing some of the microcontrollers using a USART loop!)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In your case, using SPI means that naturally, the microcontroller with the USB connection to the computer can be the master, and it can just forward the relevant commands from the computer to each slave device. It can also read the updates/measurements from each slave and send these to the computer.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;At 8MHz, and 0.5m wire length, I don't think it will become a problem. But if it is, try be more careful of capacitance (keep ground and signal wires getting too close, and also be careful of connections between different conductors), and also signal termination. In the unlikely event that it remains a problem, you can reduce the clock rate, but I don't think it is necessary.&lt;/p&gt;&#xA;" OwnerUserId="145" LastEditorUserId="145" LastEditDate="2013-01-02T22:10:02.137" LastActivityDate="2013-01-02T22:10:02.137" CommentCount="12" />
  <row Id="738" PostTypeId="1" AcceptedAnswerId="740" CreationDate="2012-12-31T01:09:06.787" Score="9" ViewCount="184" Body="&lt;p&gt;I've got a tread-driven robot, with low precision wheel encoders for tracking distance and an electronic compass for determining heading.  The compass has significant (&gt; 1 second) lag when the robot turns quickly, e.g. after reaching a waypoint &amp;mdash; pivoting in place to point to its new heading.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What are ways for dealing with the lag?  I would think one could take a lot of measurements and model the compass response.  However, this seems problematic since it's rate-dependent and I don't know the instantaneous rate.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As a simple-but-slow approach, I have the robot turn until it's very roughly pointed in the right direction, then make very small incremental turns with brief measurement pauses until it's pointed the right way.  Are there other ways of dealing with this? &lt;/p&gt;&#xA;" OwnerUserId="58" LastEditorUserId="350" LastEditDate="2012-12-31T14:24:06.783" LastActivityDate="2013-01-01T02:51:36.627" Title="What are methods for dealing with compass lag (rate dependent hysteresis)?" Tags="&lt;sensors&gt;&lt;compass&gt;" AnswerCount="2" />
  <row Id="739" PostTypeId="2" ParentId="738" CreationDate="2012-12-31T01:41:31.007" Score="4" Body="&lt;p&gt;A gyro is the simple answer. I've always heard, gyro for the short measurements, compass for the long. And realistically a cup of kallman filter between the two most of the time. The price of a 6DOF gyro/acc board is less than $20 these days, far too cheap to not use one.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;At one time, I worked through &lt;a href=&quot;http://nxttime.wordpress.com/2010/10/06/robotc-code-for-the-kalman-filter/&quot; rel=&quot;nofollow&quot;&gt;someone else's Kallman filter&lt;/a&gt;. and got it working. A kallman filter is actually more of an approach, not a exact implementation, and in the gyro case, the end result does not need to use matrix math. It makes for much simpler code.&lt;/p&gt;&#xA;" OwnerUserId="274" LastEditorUserId="274" LastEditDate="2013-01-01T02:51:36.627" LastActivityDate="2013-01-01T02:51:36.627" />
  <row Id="740" PostTypeId="2" ParentId="738" CreationDate="2012-12-31T02:56:45.393" Score="11" Body="&lt;p&gt;The lag in the compass is because of a low-pass filter, to suppress high frequency noise. &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;There exist more expensive magnetometers which have less noise, and therefore, less lag.&lt;/li&gt;&#xA;&lt;li&gt;It is also possible to use a gyroscope to improve accuracy. In fact, this is what Inertial Measurement Units (IMUs) do. This can be accomplished by using a Kalman filter. Improving accuracy helps to decrease lag, because increased accuracy reduces the dependency on a low pass filter to suppress noise. The Kalman filter fuses the data from the magnetometer, and also the gyroscope (which measures rate of change in heading).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;If you stick with your current compass, there are two possible solutions (Warning, this does get increasingly advanced, but option 1 should be accessible to most people without too much work).&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;You can try to cancel out the filter. This can remove lag, but also increases high frequency noise. After doing this, you can try to control the robot based on the new estimate of heading. To do this, you must experiment to work out the low pass filter parameters. For example, in discrete time, you might find:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$\hat\theta(t)=a_0\theta(t)+a_1\theta(t-1)+\cdots+a_k\theta(t-k)$$&#xA;where $\hat\theta(t)$ is the estimated heading (compass output) at time $t$, $\theta$ is the actual heading (ground truth) at time $t$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can find the parameters $a_i$ by doing an experiment where you measure the ground truth using some other external means. Given $n+k+1$ samples, you have this equation:&#xA;$$\left[\matrix{\hat\theta(k)\\\vdots\\\hat\theta(k+n)}\right]=\left[\matrix{\theta(k)&amp;amp;\theta(k-1)&amp;amp;\cdots&amp;amp;\theta(0)\\\vdots&amp;amp;\vdots&amp;amp;&amp;amp;\vdots\\\theta(k+n)&amp;amp;\theta(k+n-1)&amp;amp;\cdots&amp;amp;\theta(n)}\right]\left[\matrix{a_0\\a_1\\\vdots\\a_k}\right]$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And you can solve by finding:&#xA;$$\left[\matrix{a_0\\a_1\\\vdots\\a_k}\right]=\left[\matrix{\theta(k)&amp;amp;\theta(k-1)&amp;amp;\cdots&amp;amp;\theta(0)\\\vdots&amp;amp;\vdots&amp;amp;&amp;amp;\vdots\\\theta(k+n)&amp;amp;\theta(k+n-1)&amp;amp;\cdots&amp;amp;\theta(n)}\right]^{+}\left[\matrix{\hat\theta(k)\\\vdots\\\hat\theta(k+n)}\right]$$ where $M^+$ is the pseudo-inverse matrix of $M$. There is no definitive way to work out $k$, so you will probably just guess. For bonus points, this assumes that the noise is white and independent, but you can whiten it first to remove bias, and therefore improve your estimate of the parameters.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can convert this to a transfer function (also known as Z-transform in the discrete time domain):&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$\frac{\hat\Theta(z)}{\Theta(z)}=a_0+a_1 z^{-1}+...+a_k z^{-k}$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To cancel this out, we can take the inverse (where $\bar\theta(t)$ is our new estimate of heading):&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$\frac{\bar\Theta(z)}{\hat\Theta(z)}=\frac{1}{a_0+a_1 z^{-1}+\cdots+a_k z^{-k}}$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Converting back to the time domain:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$a_0\bar\theta(t)+a_1\bar\theta(t-1)+\cdots+a_k \bar\theta(t-k)=\hat\theta(t)$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$\bar\theta(t)=\frac{\hat\theta(t)-a_1\bar\theta(t-1)-\cdots-a_k \bar\theta(t-k)}{a_0}$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;we can then use $\bar\theta$ to control the robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This will be very noisy, so you might want to still put $\bar\theta$ through a low-pass filter before use (although perhaps one with less lag).&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;The above solution is still not the best way. The noisy estimate may not be very useful. If we put this into a state space equation, we can design a Kalman filter, and a full-state feedback controller using LQR (linear quadratic regulator). The combination of a Kalman filter and LQR controller is also known as an LQG controller (linear quadratic gaussian), and use loop-transfer recovery to get a good controller.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To do this, come up with the (discrete-time) state-space equations:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$\vec{x}(t)=A\vec{x}(t-1)+B\vec{u}(t-1)$, $\vec{y}(t)=C\vec{x}(t)$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;or:&#xA;$$\vec{x}(t)=\left[\matrix{\theta(t)\\\theta(t-1)\\\cdots\\\theta(t-k)}\right]=&#xA;\left[\matrix{&#xA;    A_1&amp;amp;A_2&amp;amp;\cdots&amp;amp;0&amp;amp;0&amp;amp;0\\&#xA;    1&amp;amp;0&amp;amp;\cdots&amp;amp;0&amp;amp;0&amp;amp;0\\&#xA;    0&amp;amp;1&amp;amp;\cdots&amp;amp;0&amp;amp;0&amp;amp;0\\&#xA;    \vdots&amp;amp;\vdots&amp;amp;&amp;amp;\vdots&amp;amp;\vdots&amp;amp;\vdots\\&#xA;    0&amp;amp;0&amp;amp;\cdots&amp;amp;1&amp;amp;0&amp;amp;0\\&#xA;    0&amp;amp;0&amp;amp;\cdots&amp;amp;0&amp;amp;1&amp;amp;0&#xA;}\right]&#xA;\vec{x}(t-1)&#xA;+&#xA;\left[\matrix{B_0\\B_1\\0\\\vdots\\0\\0}\right]\vec{u}(t-1)$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$\vec{y}(t)=\left[\matrix{\hat\theta(t)}\right]=\left[\matrix{a_0\\a_1\\\vdots\\a_k}\right]\vec{x}(t)$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;where $\vec{u}(t-1)$ represents the power in the motors to turn the robot, and $A_0$, $A_1$, $B_0$, $B_1$ is how much it affects the heading based on position and speed (you can choose non-zero values for the other elements of the $B$ matrix, and first row of the $A$ matrix too).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then, you can build your observer (Kalman Filter), by choosing noise estimates $Q_o$ and $R_o$ for the process noise and measurement noise. The Kalman Filter can then find the optimal estimate of heading, given those assumptions about the noise. After choosing the noise estimates, the implementation just depends on implementing code for the Kalman Filter (equations can be found on Wikipedia, so I won't go over it here).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;After that, you can design an LQR controller, this time, choosing $Q_c$ and $R_c$ representing the weighting given to regulating the heading, and trying to limit the use of the actuators. In this case, you might choose $Q_c = \left[\matrix{1&amp;amp;0&amp;amp;0&amp;amp;\cdots&amp;amp;0\\0&amp;amp;0&amp;amp;0&amp;amp;\cdots&amp;amp;0\\\vdots&amp;amp;\vdots&amp;amp;\vdots&amp;amp;&amp;amp;\vdots\\0&amp;amp;0&amp;amp;0&amp;amp;\cdots&amp;amp;0}\right]$ and $R_c = \left[1\right]$. This is done because LQR finds the optimal controller to minimise a cost function: $J = \sum{(\vec{x}^T Q\vec{x} + \vec{u}^T R \vec{u})}$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then, you just put it through the discrete time algebraic Riccati equation:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$P = Q + A^T \left( P - P B \left( R + B^T P B \right)^{-1} B^T P \right) A$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;and solve for a positive definite matrix $P$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thus, your control law can be given by:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$\vec{u}(t)=-K(\vec{x}(t)-\vec{x}_{ref}(t))$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;where $K = (R + B^T P B)^{-1}(B^T P A)$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Finally, just doing this won't work very well, and is likely to be unstable because of the noise. Indeed, that means option 1 probably won't work unless you first put $\bar\theta$ through a low-pass filter (albeit not necessarily with such a long effective lag time). This is because while LQR is guaranteed stable, as soon as you use a Kalman filter, the guarantee is lost.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To fix this, we use the Loop Transfer Recovery technique, where you adjust the Kalman filter, and instead choose a new $Q_o = Q_0 + q^2BVB^T$, where $Q_0$ is your original $Q$ matrix, tuned so that the Kalman filter is optimal. $V$ is any positive definite symmetric matrix, which you can just choose as the identity matrix ($V=I$). Then, just choose a scalar $q$. The resulting controller should become (more) stable as $q \rightarrow \infty$, although the $Q_o$ matrix becomes de-tuned, which means it becomes less optimal.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Therefore, you just increase $q$ until it is stable. Another way you can try to make it stable, is to increase $R_c$ (or decrease $Q_c$) to make the LQR controller slower.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;The concepts in this post does get quite advanced, but if you need to solve things like the Riccati equation, you can use MATLAB or other software to do this. There may also be libraries already implementing the Kalman filter (again, I believe MATLAB also does this).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For an embedded application, you may need to implement the Kalman filter yourself, although there is probably a C implementation.&lt;/p&gt;&#xA;" OwnerUserId="145" LastActivityDate="2012-12-31T02:56:45.393" CommentCount="1" />
  <row Id="741" PostTypeId="1" AcceptedAnswerId="742" CreationDate="2013-01-01T22:39:17.693" Score="5" ViewCount="100" Body="&lt;p&gt;I've seen &lt;a href=&quot;http://robotics.stackexchange.com/questions/18/what-are-good-methods-for-tuning-the-process-noise-on-kalman-filters&quot;&gt;this question&lt;/a&gt;, which asks about determining the process noise for an EKF.  I don't see anything there about pre-recorded data sets.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;My thought on how to determine the noise parameters, assuming ground truth is available, would be to run the data several times with the EKF and minimize the mean square error, while varying the noise parameters.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is this an acceptable way to determine noise for a pre recorded data set?  Are there better (or just other) ways from determining the optimal noise values based just on the data set?&lt;/p&gt;&#xA;" OwnerUserId="502" LastEditorUserId="350" LastEditDate="2013-01-02T13:46:27.733" LastActivityDate="2013-01-02T13:46:27.733" Title="How do you determine EKF process noise for pre-recorded data sets?" Tags="&lt;noise&gt;&lt;ekf&gt;" AnswerCount="1" FavoriteCount="2" />
  <row Id="742" PostTypeId="2" ParentId="741" CreationDate="2013-01-01T23:25:53.343" Score="4" Body="&lt;p&gt;Yes, such a method can give you a reasonable estimates of noise. Note that it is susceptible to systematic error. For instance if you are flying a quadrotor in the presence of a fan. This would show up in your findings which is generally undesirable.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;With that said you could improve your estimates by using the &lt;a href=&quot;http://en.wikipedia.org/wiki/Forward%E2%80%93backward_algorithm&quot; rel=&quot;nofollow&quot;&gt;forward-backward algorithm&lt;/a&gt;. This algorithm is named from the fact that it consists of a forward pass and a backward pass. The forward pass is basically just an application of a Kalman-Filter, which as you may already realize, only includes data available up until the time step for which the state is being estimated. The backward pass then improves these estimates by including data available after the time in question.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have only used the forward-backward algorithm with a KF (i.e. not an EKF). As such I don't know the precise implementation details when using an EKF. However there does appear to be some &lt;a href=&quot;http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;amp;arnumber=4518436&amp;amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D4518436&quot; rel=&quot;nofollow&quot;&gt;literature&lt;/a&gt; on the topic.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Edit: As I think about this further it occurs to me that you can use &lt;a href=&quot;http://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm&quot; rel=&quot;nofollow&quot;&gt;expectation maximization&lt;/a&gt; (EM) and &lt;a href=&quot;http://en.wikipedia.org/wiki/Coordinate_descent&quot; rel=&quot;nofollow&quot;&gt;coordinate descent&lt;/a&gt; (CD) to automatically determine the noise parameters. The process would treat the covariance matrices for the process model (call it P) and observation models (call it O) as EM parameters and proceeds as follows:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Start with your best guess for one of the matrices. Say P for the&#xA;sake of an example. Then use EM to identify O.&lt;/li&gt;&#xA;&lt;li&gt;Use the O found in step 1 with EM to improve the estimate of P.&lt;/li&gt;&#xA;&lt;li&gt;Repeat steps 1 and 2 until the log-likelihood of using O and P reaches some stopping criterion (e.g. stops varying, varies very little, or is minimized).&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="177" LastEditorUserId="177" LastEditDate="2013-01-02T03:56:29.860" LastActivityDate="2013-01-02T03:56:29.860" />
  <row Id="743" PostTypeId="2" ParentId="736" CreationDate="2013-01-02T13:11:10.530" Score="5" Body="&lt;p&gt;I can highly recommend CAN for inter processor communications. We use it in our robots, with up to 22 processors on the same bus. With good protocol design, you can use up about 90% of the available bandwidth (about 640kbps when you take into account all of the error checking and inter frame spacing). We're able to servo 10 motors at 1000Hz on one CAN bus. This is approaching the limit. You could probably squeeze it to 20 motors if you pack the data very carefully.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Generally CAN needs to have one transceiver chip for each processor (it's just a little 8-pin device). The transceiver gives you the nice differential signal which emits very little interference, and also makes it immune to interference if you're working in an electrically noisy environment (motors, solenoids, and radio transmitters).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/4Tk7n.jpg&quot; alt=&quot;CAN Bus connections&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, in limited circumstances, it's actually possible to use &lt;a href=&quot;http://electronics.stackexchange.com/questions/30564/is-a-can-enabled-microcontroller-sufficient-to-drive-a-can-bus/30596#30596&quot;&gt;CAN with no transceivers&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/rzs1z.gif&quot; alt=&quot;EtherCAT&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you ever feel like implementing a bus with serious bandwidth, I suggest you try &lt;a href=&quot;http://en.wikipedia.org/wiki/EtherCAT&quot;&gt;EtherCAT&lt;/a&gt;. It's a 100Mb bus, which can be connected to your PC's Ethernet port. There are two important parts to the bus:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The Bridge. This converts the Ethernet physical layer to a simpler, lower cost LVDS physical layer, which doesn't require the large connectors, Phy chip, and many components that Ethernet itself does.&lt;/li&gt;&#xA;&lt;li&gt;The nodes. Each node just needs one ET1200 chip and a microcontroller.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The PC can transmit and receive large chunks of data to and from the nodes at 1kHz or faster. You can control &lt;a href=&quot;http://www.youtube.com/watch?v=UwP4DCwXoSM&quot;&gt;quite a lot of stuff&lt;/a&gt; on a single EtherCAT bus.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2013-01-02T13:11:10.530" CommentCount="1" />
  <row Id="746" PostTypeId="2" ParentId="533" CreationDate="2013-01-03T12:55:00.257" Score="0" Body="&lt;p&gt;When you start talking about the first robots, you quickly run into the question: &quot;What is a robot?&quot;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Before we can say whether or not some machine is the first robot, we need to define what exactly we mean by the word 'robot'. The problem is, that there's really no single definition, and it depends who you ask. For example, I had a &lt;a href=&quot;http://en.wikipedia.org/wiki/Talk%3aRobot/Archive_4#Timeline&quot; rel=&quot;nofollow&quot;&gt;massive argument&lt;/a&gt; with someone on the Wikipedia robots talk page about the definition of robot. And you can forget about looking up the word in a dictionary, all of the dictionary definitions I have seen are hopelessly naive. The best definition I have seen is on the Wikipedia page:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;A robot is a mechanical or virtual artificial agent.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;The most important word here is 'agent'. A machine which seems to have a sense of agency is more likely to be called a robot. I can imagine that if Leonardo had built his 'robot' then people would really have thought it has real agency of its own, and been practically alive, and would therefore have qualified to be included in that definition of robot. Today, however, roboticists have stricter definitions, and require robots to be more than just clockwork, and have some degree of autonomy and interaction with the environment.&lt;/p&gt;&#xA;" OwnerUserId="40" LastEditorUserId="40" LastEditDate="2013-01-03T17:00:30.720" LastActivityDate="2013-01-03T17:00:30.720" />
  <row Id="748" PostTypeId="1" AcceptedAnswerId="752" CreationDate="2013-01-05T02:37:24.810" Score="2" ViewCount="156" Body="&lt;p&gt;I'm trying to power 7-12 &lt;a href=&quot;http://en.wikipedia.org/wiki/Servo_%28radio_control%29&quot; rel=&quot;nofollow&quot;&gt;servos&lt;/a&gt;, and I was under the impression that each one would need about an amp, but in looking around for an appropriate &lt;a href=&quot;http://en.wikipedia.org/wiki/Battery_eliminator_circuit&quot; rel=&quot;nofollow&quot;&gt;BEC&lt;/a&gt; to supply them, I notice that most seem to output around 1-3.5 amps.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;They won't all be running at once, but often, say 4 will be drawing enough juice to move.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Obviously, I'm missing some link in my understanding.  How do I determine how many amps will be needed from the power supply?&lt;/p&gt;&#xA;" OwnerUserId="12" LastEditorUserId="37" LastEditDate="2013-05-20T16:24:50.807" LastActivityDate="2013-05-20T16:24:50.807" Title="How many amps do I want my Switching BEC to provide?" Tags="&lt;design&gt;&lt;power&gt;&lt;rcservo&gt;&lt;bec&gt;" AnswerCount="3" CommentCount="0" />
  <row Id="749" PostTypeId="2" ParentId="748" CreationDate="2013-01-05T07:21:15.513" Score="2" Body="&lt;p&gt;There's two possible current requirements to consider here.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ideally, you need to be able to supply enough current to account for the rated stall current (that is, the current drawn by the servo at its maximum rated torque) of all of your servos simultaneously. Imagine a bunch of your mechanical components getting jammed on each other in some gruesome fashion and busting your servos. You don't want to add insult to injury and fry your BEC in the process as well. If you don't have that number from the datasheet for the servo, you can test it by stalling a servo manually. This number can be quite a bit larger than your normal operating current, often to the point of being impractically large to design for. In the (unlikely) event that you can somehow prove that given servos in your application will never be placed in a stall condition, you can skimp on that a bit. Keep in mind that a servo doesn't have to be actively moving on its own to be stalled; a force trying to move it from its set position can do it as well.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The second, softer requirement is your real-world operating current, which is a lot more application-specific. The amount of current drawn by a motor is dependent on the amount of torque it is exerting to move the load. Measure the current drawn by each servo while moving its real-world load. Add those up for any given group of servos that might be moving at the same time. The largest of those is your maximum normal operating current. Multiply that by 1.5-2 for a safety margin.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;See also: &lt;a href=&quot;http://robotics.stackexchange.com/questions/416/what-is-the-best-way-to-power-a-large-number-27-servos-at-5-v&quot;&gt;What is the best way to power a large number (27) servos at 5 V?&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="308" LastEditorUserId="308" LastEditDate="2013-01-05T08:45:26.670" LastActivityDate="2013-01-05T08:45:26.670" />
  <row Id="750" PostTypeId="2" ParentId="748" CreationDate="2013-01-05T07:42:49.090" Score="0" Body="&lt;p&gt;I'm not sure why you are trying to make it hard than it is. If you have 4 servos that are in use at one time, that draw an amp each, you need 4 amps, period. BECs are convenience components, that are used because R/C servos used to burn out if provided with more than 5 volts. 6 Nicad batteries, which was the most common configuration before LiPo technology came around,  worked out to 9.6 volts (6 X 1.2v). BECs are &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/__112__182__ESC_UBEC_VR-VR_UBEC.html&quot; rel=&quot;nofollow&quot;&gt;available&lt;/a&gt; in many sizes, and greater than 3.5 amps is common. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If the requirement is greater than what is available, you simply provide your own voltage/amperage to the servos - often straight from a 6v battery, again the BEC is/was just a convenience component. If you do this with excessive current (more than the controller can pass through) you need to remove the red wire from the plug that goes into the controller, and supply voltage via that red wire. the black wire, needs to be both a ground connection for the signal, so it can not be removed from the controller, but it also needs to be the negative connection for power. The need to do this is pretty uncommon. The controller power connections are just straight pass through.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are using a plain R/C receiver the rule of thumb is the circuit board can handle about 6 amps max. A good digital servo will draw 2 amps at full power, but in most cases, what I have seen used in robotics are not good servos, so your guess of about an amp is reasonable.&lt;/p&gt;&#xA;" OwnerUserId="274" LastEditorUserId="274" LastEditDate="2013-01-05T07:50:39.570" LastActivityDate="2013-01-05T07:50:39.570" CommentCount="4" />
  <row Id="751" PostTypeId="1" AcceptedAnswerId="753" CreationDate="2013-01-05T09:00:41.440" Score="4" ViewCount="159" Body="&lt;p&gt;I'm trying to program advanced functions in &lt;a href=&quot;http://www.robotc.net/wiki/VEX2_Functions_Motors_and_Servos#motorType&quot; rel=&quot;nofollow&quot;&gt;RobotC&lt;/a&gt; but I'm not too sure I'm doing it right. I want to specify the motor port I'm using, but I assigned names to all the motors. Funny thing though, they don't exactly work the same as regular variables.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For instance, motor[port7]'s alternate name is light_blue.&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#pragma config(Motor,  port7,           light_blue,    tmotorVex393, openLoop)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I'm not really sure if these are new variables, or just specifications.  Anyway, here is the variable's signature:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;int motor[tMotor motor]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;My code plans on doing something similar to this:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;void testThing (Motor motorName)&#xA;{&#xA;  motorName = someValue;&#xA;}&#xA;&#xA;testThing(light_blue);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;But with the int/motor hybrid variable/unidentified I'm not sure how well that would work out. Or at all.&lt;/p&gt;&#xA;" OwnerUserId="685" LastEditorUserId="350" LastEditDate="2013-01-05T14:23:47.710" LastActivityDate="2013-01-06T18:14:52.810" Title="Confused about the variables in RobotC?" Tags="&lt;robotc&gt;" AnswerCount="2" />
  <row Id="752" PostTypeId="2" ParentId="748" CreationDate="2013-01-05T12:18:56.893" Score="2" Body="&lt;p&gt;Forgive me I seem to get caught up in people looking for answers to a question they didn't ask a few times already. So given this question; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&quot;How do I determine how many amps will be needed from the power supply?&quot;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can roughly guess it, in your case you say 4 servos drawing an amp each, 4 amps total.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pick any BEC that will supply greater than 4 amps, there are plenty available from the other answer I already gave.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then apply a logging circuit to validate your estimate; Make your own that logs both current and voltage, or buy a simple already build device that is made just for that purpose such as an &lt;a href=&quot;http://www.eagletreesystems.com/MicroPower/micro.htm&quot; rel=&quot;nofollow&quot;&gt;Eagle Tree Logger&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is no magic formula to find correct amperage. Only real world usage and observation will give you a more precise estimate. Any such formula would not account for your mechanical design, friction, drag, gravity etc.&lt;/p&gt;&#xA;" OwnerUserId="274" LastActivityDate="2013-01-05T12:18:56.893" CommentCount="1" />
  <row Id="753" PostTypeId="2" ParentId="751" CreationDate="2013-01-05T12:45:00.340" Score="2" Body="&lt;p&gt;The #pragma is more like a #define in terms of names, as opposed to a variable declaration.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Your code is very close; something like this would work fine;&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#pragma config(Motor,  motorA,          light_blue,    tmotorNXT, PIDControl, encoder)&#xA;&#xA;void testThing (tMotor  motor_name)&#xA;{&#xA;    motor[motor_name] = 20;   // set power to 20&#xA;}&#xA;&#xA;task main()&#xA;{&#xA;    testThing(light_blue);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;The actual type of a tmotor is an enum (and used like an int) and the definition can be found in RobotCintrinsics.c included with the product.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;for exmaple;&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#if (1)&#xA;&#xA;  // the actual 'enum' values for 'tMotor' are automatically defined by the ROBOTC compiler. Each platform&#xA;  // and circuit board type has its own set of &quot;enum names&quot; and it was becoming too hard to manage them in&#xA;  // this file. So they are automatically configured by the compiler which has better utilities for managing&#xA;  // differences between platform types.&#xA;&#xA;  typedef enum tMotor;&#xA;&#xA;#else&#xA;&#xA;    // The old definitions are temporarily maintained here as well until the new implementation is confirmed&#xA;  // to be working well!&#xA;&#xA;  #if defined(NXT) || defined(TETRIX)&#xA;&#xA;        typedef enum&#xA;        {&#xA;          motorA = 0,&#xA;          motorB = 1,&#xA;          motorC = 2,&#xA;          mtr_S1_C1_1 =  3,&#xA;&#xA;    ... etc&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;If i was to look at your code, and accept its functionality as literal then the following would work;&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#pragma config(Motor,  motorA,          light_blue,    tmotorNXT, PIDControl, encoder)&#xA;#pragma config(Motor,  motorB,          light_green,   tmotorNXT, PIDControl, encoder)&#xA;&#xA;void testThing (tMotor&amp;amp;  motor_name)&#xA;{&#xA;    tmotor_name = light_green;&#xA;}&#xA;&#xA;task main()&#xA;{&#xA;    tmotor motor_to_use = light_blue;&#xA;    testThing(motor_to_use);&#xA;    motor[motor_to_use] = 20; // will actually move light_green since testThing function changed its value&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;It's hard to guess what it is you are trying to actually do&lt;/p&gt;&#xA;" OwnerUserId="274" LastEditorUserId="274" LastEditDate="2013-01-05T20:48:49.130" LastActivityDate="2013-01-05T20:48:49.130" CommentCount="2" />
  <row Id="754" PostTypeId="5" CreationDate="2013-01-05T14:13:43.847" Score="0" ViewCount="1" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2013-01-05T14:13:43.847" LastActivityDate="2013-01-05T14:13:43.847" />
  <row Id="755" PostTypeId="4" CreationDate="2013-01-05T14:13:43.847" Score="0" Body="Battery Eliminator Circuit - an alternative to powering motor and hotel loads (i.e. circuits with separate current and voltage ratings) from separate battery systems, allowing both loads to be safely run from a single battery system (or other power supply).  " OwnerUserId="350" LastEditorUserId="134" LastEditDate="2013-01-05T22:16:34.367" LastActivityDate="2013-01-05T22:16:34.367" />
  <row Id="756" PostTypeId="2" ParentId="751" CreationDate="2013-01-05T15:02:21.343" Score="0" Body="&lt;p&gt;I think I see where you're confused, and you're correct in noticing that the motor variables are a little different than regular variables.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The &lt;code&gt;#pragma config( )&lt;/code&gt; is actually doing a &lt;em&gt;lot&lt;/em&gt; of heavy lifting for you because it is a &quot;&lt;a href=&quot;http://www.cplusplus.com/doc/tutorial/preprocessor/&quot; rel=&quot;nofollow&quot;&gt;preprocessor directive&lt;/a&gt;&quot;.  In other words, there is a hidden step &amp;mdash; preprocessing &amp;mdash; between the code you wrote and the code that the compiler sees.  The preprocessor is why you have access to the &lt;code&gt;motor[ ]&lt;/code&gt; array (which you didn't need to declare before using), and why assigning a value to a &lt;code&gt;motor&lt;/code&gt; causes your real-world motors to move (which does not happen when assigning to a &quot;normal&quot; variable).  The code generated by the preprocessor is saving you from writing a lot of setup code yourself, but it is also making some normal-looking variables do some unexpected things.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In your case, this is the motor config line that you wrote:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#pragma config(Motor,  port7,           light_blue,    tmotorVex393, openLoop)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;This tells the preprocessor to generate some code that does the following:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Declare a variable of type &lt;code&gt;tMotor&lt;/code&gt; and store it in &lt;code&gt;motor[light_blue]&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Set the port of &lt;code&gt;motor[light_blue]&lt;/code&gt; to &lt;code&gt;port7&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Add a function that gets called when you assign a value to &lt;code&gt;motor[light_blue]&lt;/code&gt;, which converts that value directly to a power-level signal understood by Vex 393 (and outputs this signal on &lt;code&gt;port7&lt;/code&gt;).  In other words, use &lt;em&gt;open loop&lt;/em&gt; control instead of PID control.&lt;/li&gt;&#xA;&lt;li&gt;(Other things not relevant to this question)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;So, &lt;code&gt;light_blue&lt;/code&gt; is not an &quot;alternate name&quot; for &lt;code&gt;motor[port7]&lt;/code&gt;, and in fact &lt;strong&gt;neither of those names are correct&lt;/strong&gt;.  The correct way to refer to this motor in code is &lt;code&gt;motor[light_blue]&lt;/code&gt;.   In other words, &lt;code&gt;light_blue&lt;/code&gt; is an index into the &lt;code&gt;motor[ ]&lt;/code&gt; array.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The &lt;a href=&quot;http://robotics.stackexchange.com/a/753/350&quot;&gt;code that Spiked3 posted&lt;/a&gt; would be the proper way to set up your function:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#pragma config(Motor,  motorA,          light_blue,    tmotorNXT, PIDControl, encoder)&#xA;&#xA;void testThing (tMotor  motor_name)&#xA;{&#xA;    motor[motor_name] = 20;   // set power to 20&#xA;}&#xA;&#xA;task main()&#xA;{&#xA;    testThing(light_blue);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-01-06T18:14:52.810" LastActivityDate="2013-01-06T18:14:52.810" CommentCount="3" />
  <row Id="757" PostTypeId="1" CreationDate="2013-01-06T08:40:44.293" Score="5" ViewCount="137" Body="&lt;p&gt;I would like a high torque motor (37 oz-in @ 5760 rpm) for souping up a &lt;a href=&quot;http://www.theoldrobots.com/scorbot.html&quot; rel=&quot;nofollow&quot;&gt;Scorbot 3&lt;/a&gt; I bought. I really need it to have an encoder to count the number of revolutions and to allow high start-up torque. So far, I'm having difficulty finding a suitable motor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The closest I've found are:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://holmeshobbies.com/product.php?productid=467&quot; rel=&quot;nofollow&quot;&gt;Revolver S Stubby&lt;/a&gt;&#xA;(still not ready for purchase)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://v2.teamnovak.com/products/index.php?main_page=product_info&amp;amp;cPath=1_126&amp;amp;products_id=79&quot; rel=&quot;nofollow&quot;&gt;Team Novak Ballistic 25.5T&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;I've found other RC car motors, but they are usually too big.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some alternatives I thought about are:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;adding hall sensors to an existing motor - how hard is this?&lt;/li&gt;&#xA;&lt;li&gt;rewinding a motor with more turns to increase torque (decrease Kv)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Does anybody know of any motors that fit these requirements or modifications I can make to existing ones?&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;Update:&lt;/em&gt;&lt;/strong&gt; I had almost given up hope, until someone at Homebrew Robotics suggested using the &lt;a href=&quot;http://www.maxonmotorusa.com/maxon/view/msp/&quot; rel=&quot;nofollow&quot;&gt;Maxon motor finder&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you just type in my given torque and speed, it returns 3 motors, but they're all over powered because the search interprets your specs as a continuous operating point, whereas my robot will only need that much power 20% of the time, and maybe for 1 second max.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If I type in 12V, 5000rpm, and 15 oz-in, then it returns 2 brushless motors, of which, the &lt;strong&gt;Motor EC 45&lt;/strong&gt; is the best fit, which has this operating curve:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://msp.maxonmotor.com/camosHtml/i?SIG=fb9a5d91198caf381122a3d6eab8b1bda3877f30_fa_1e0.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, I don't want to pay what Maxon is charging, so instead, I've contacted the guy who makes the yet to be released Revolver Stubby and he has kindly offered to build a custom high torque, low RPM motor for me.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can anyone comment on why high torque, low RPM motors like the one I want seem so rare? Is due to lack of applications (robotics) or is there some intrinsic difficulty in making them?&lt;/p&gt;&#xA;" OwnerUserId="710" LastEditorUserId="37" LastEditDate="2013-02-19T17:09:53.520" LastActivityDate="2013-02-19T17:09:53.520" Title="How can I upgrade an existing robot with a higher torque, sensored motor @ ~100 watts?" Tags="&lt;motor&gt;&lt;brushless-motor&gt;" AnswerCount="1" CommentCount="9" FavoriteCount="0" />
  <row Id="758" PostTypeId="1" AcceptedAnswerId="759" CreationDate="2013-01-07T21:09:56.563" Score="9" ViewCount="345" Body="&lt;p&gt;I'm familiar with the idea of the &lt;a href=&quot;http://en.wikipedia.org/wiki/Uncanny_valley&quot;&gt;uncanny valley&lt;/a&gt; theory in human-robot interaction, where robots with &lt;em&gt;almost&lt;/em&gt; human appearance are perceived as creepy. I also know that there have been research studies done to support this theory using MRI scans. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The effect is an important consideration when designing robotic systems that can successfully interact with people. In order to avoid the uncanny valley, designers often create robots that are very far from humanlike. For example, many therapeutic robots (Paro, Keepon) are designed to look like animals or be &quot;cute&quot; and non-threatening.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Other therapeutic robots, like &lt;a href=&quot;http://kaspar.herts.ac.uk/&quot;&gt;Kaspar&lt;/a&gt;, look very humanlike. Kaspar is an excellent example of the uncanny valley, since when I look at Kaspar it creeps me out. However, people on the autism spectrum may not experience Kaspar the same way that I do. And according to Shabaz's comment, children with autism have responded well to Kaspar.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the application of therapeutic robots for people on the autism spectrum, some of the basic principles of human-robot interaction (like the uncanny valley) may not be valid. I can find some anecdotal evidence (with Google) that people on the autism spectrum don't experience the uncanny valley, but so far I haven't seen any real studies in that area.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Does anyone know of active research in human-robot interaction for people on the autism spectrum?  In particular, how does the uncanny valley apply (or doesn't it apply) when people on the autism spectrum interact with a humanlike robot?&lt;/p&gt;&#xA;" OwnerUserId="479" LastEditorUserId="131" LastEditDate="2013-01-08T15:21:29.540" LastActivityDate="2013-12-02T17:18:37.163" Title="In HRI, how is the &quot;uncanny valley&quot; experienced by people on the autism spectrum?" Tags="&lt;research&gt;&lt;hri&gt;&lt;uncanny-valley&gt;" AnswerCount="6" CommentCount="6" FavoriteCount="4" />
  <row Id="759" PostTypeId="2" ParentId="758" CreationDate="2013-01-08T15:12:27.610" Score="8" Body="&lt;p&gt;The short answer is &lt;strong&gt;no&lt;/strong&gt;. There doesn't seem to be any study directly investigating if and how the uncanny valley applies to autistic children. At least, a Google Scholar search with the keywords &lt;a href=&quot;http://scholar.google.com/scholar?q=autism%20%22uncanny%20valley%22&quot;&gt;autism &quot;uncanny valley&quot;&lt;/a&gt; doesn't result in anything of the sort. I agree, though, that this would be a most interesting and useful area of research. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Keep in mind, however, that, despite the fMRI and other studies, the Uncanny Valley is far from considered an established theory. This is, partly, because the Uncanny Valley is likely a great deal more complex than Mori first proposed, that is, it is probably not just human likeness that affects our sense of familiarity, nor is familiarity the only factor affected (MacDorman, 2006). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In my personal opinion, there's no doubt something like the Uncanny Valley exists, even though it may not quite take the shape Mori gave it (Bartneck et al., 2007). Artists of all ilk have long been aware of it and have deliberately used it (e.g. Chucky or any zombie movie ever) or suffered when falling into it (the Polar Express being the most notable example). Several explanations have been put forward to explain it (Brenton et al., 2005; MacDorman, 2005; Saygin et al., 2010) and it's been observed in monkeys as well (Steckenfinger and Ghazanfar, 2009), so it's very likely evolutionary in nature.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are interested in this area, I'd probably look at how people suffering from autism process faces in general. In this area, there have been a number of studies using real faces (e.g. Scholar search &lt;a href=&quot;http://scholar.google.com/scholar?q=autism%20%22facial%20features%22&quot;&gt;autism &quot;facial features&quot;&lt;/a&gt;), as well as artificial faces (e.g. Scholar search &lt;a href=&quot;http://scholar.google.com/scholar?q=autism%20cartoon%20faces&quot;&gt;autism cartoon faces&lt;/a&gt;). This difference in decoding facial expressions might explain why they seem to not feel the effects of the uncanny valley the same way other people do. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;As for Kaspar in particular, Blow et al. (2006) goes into some detail on the design decisions involved in Kaspar's face. Also, in a &lt;a href=&quot;https://www.youtube.com/watch?v=wdF7TwhUgLY&quot;&gt;YouTube video&lt;/a&gt;, Kaspar's creators cite predictability and simplicity as some of the reasons for his particular design.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;References:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;SA Steckenfinger,  AA Ghazanfar. &quot;Monkey visual behavior falls into the uncanny valley.&quot; Proceedings of the National Academy of Sciences 106.43 (2009): 18362-18366.&lt;/li&gt;&#xA;&lt;li&gt;M Blow et al. &quot;Perception of robot smiles and dimensions for human-robot interaction design.&quot; Robot and Human Interactive Communication, 2006. ROMAN 2006. The 15th IEEE International Symposium on. IEEE, 2006.&lt;/li&gt;&#xA;&lt;li&gt;KF MacDorman. &quot;Androids as an experimental apparatus: Why is there an uncanny valley and can we exploit it.&quot; CogSci-2005 workshop: toward social mechanisms of android science. 2005.&lt;/li&gt;&#xA;&lt;li&gt;H Brenton et al. &quot;The uncanny valley: does it exist.&quot; proc HCI Annu Conf: workshop on human-animated character interaction, Edinburgh. 2005.&lt;/li&gt;&#xA;&lt;li&gt;KF MacDorman. &quot;Subjective ratings of robot video clips for human likeness, familiarity, and eeriness: An exploration of the uncanny valley.&quot; ICCS/CogSci-2006 long symposium: Toward social mechanisms of android science. 2006.&lt;/li&gt;&#xA;&lt;li&gt;AP Saygin, T Chaminade, H Ishiguro. &quot;The perception of humans and robots: Uncanny hills in parietal cortex.&quot; Proceedings of the 32nd Annual Conference of the Cognitive Science Society. 2010.&lt;/li&gt;&#xA;&lt;li&gt;C Bartneck et al. &quot;Is the uncanny valley an uncanny cliff?.&quot; Robot and Human interactive Communication, 2007. RO-MAN 2007. The 16th IEEE International Symposium on. IEEE, 2007.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="131" LastActivityDate="2013-01-08T15:12:27.610" />
  <row Id="760" PostTypeId="5" CreationDate="2013-01-08T15:37:46.970" Score="0" ViewCount="2" Body="&lt;p&gt;The Uncanny Valley is a theory first proposed by Masahiro Mori that posits that people find a robot more familiar, the more human-like its appearance is, but there is a sharp drop, once the robot looks very realistic but not quite real, where our reaction turns to disgust, before rising again once we can no longer distinguish it from a real human. Mori expected the effect to be more pronounced for moving robots as opposed to still images.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/XIL5A.png&quot; alt=&quot;Mori's graph of the Uncanny Valley&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="131" LastEditorUserId="131" LastEditDate="2013-01-08T15:37:46.970" LastActivityDate="2013-01-08T15:37:46.970" />
  <row Id="761" PostTypeId="4" CreationDate="2013-01-08T15:37:46.970" Score="0" Body="The Uncanny Valley is a theory first proposed by Masahiro Mori that posits that people find a robot more familiar, the more human-like its appearance is, but there is a sharp drop, once the robot looks very realistic but not quite real, where our reaction turns to disgust, before rising again once we can no longer distinguish it from a real human. Mori expected the effect to be more pronounced for moving robots as opposed to still images." OwnerUserId="131" LastEditorUserId="131" LastEditDate="2013-01-08T15:37:46.970" LastActivityDate="2013-01-08T15:37:46.970" />
  <row Id="762" PostTypeId="2" ParentId="649" CreationDate="2013-01-08T20:07:40.447" Score="1" Body="&lt;p&gt;In a &lt;a href=&quot;http://robotics.stackexchange.com/a/661/13&quot;&gt;previous answer&lt;/a&gt;, we came to agree that a cost function defined as&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$c(\sigma) = \text{exp}(-\text{min_clear}(\sigma))$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;would satisfy the properties required for RRT* to yield asymptotic optimality under this metric.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, upon reviewing the IJRR article which describes RRT*, this cost function does &lt;em&gt;not&lt;/em&gt; technically satisfy the assumptions made in the article. Specifically, this cost function violates the &lt;em&gt;boundedness&lt;/em&gt; property, defined as:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$\exists k_c \quad c(\sigma) \leq k_c\text{TV}(\sigma), \forall \sigma \in \Sigma$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;where $\text{TV}(\sigma)$ is the &lt;em&gt;total variation&lt;/em&gt; of a path, which is essentially the path's Euclidean length. Under this boundedness assumption, a path of length 0 must also have a cost of 0.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Let's define a path $\sigma_0$ to consist of a single configuration $q$, meaning the length of $\sigma_0$ is 0. Our path cost is therefore $c(\sigma_0) = \text{exp}(-d(q)) &amp;gt; 0$, which violates the boundedness assumption. Therefore, this cost function does not meet the requirements set in the IJRR article to yield asymptotic optimality.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I wonder if RRT* simply will not yield asymptotically optimal solutions under such a cost function, or if it still might but perhaps those assumptions simplified the optimality proofs in the paper.&lt;/p&gt;&#xA;" OwnerUserId="13" LastEditorUserId="13" LastEditDate="2013-01-09T17:50:47.877" LastActivityDate="2013-01-09T17:50:47.877" />
  <row Id="763" PostTypeId="1" AcceptedAnswerId="766" CreationDate="2013-01-09T00:41:35.487" Score="8" ViewCount="496" Body="&lt;p&gt;I got the following homework question:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;What are the general differences between robots with Ackermann steering and standard bicycles or tricycles concerning the kinematics?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;But, I don't see what differences there should be, because a car-like robot (with 2 fixed rear wheels and 2 &lt;strong&gt;dependent&lt;/strong&gt; adjustable front wheels) can be seen as a tricycle-like robot (with a single adjustable front wheel in the middle).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then, if you let the distance between the two rear wheels approach zero, you get the bicycle.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, I can't see any difference between those three mobile robots. Is there something I am missing?&lt;/p&gt;&#xA;" OwnerUserId="720" LastEditorUserId="350" LastEditDate="2013-01-09T14:43:45.113" LastActivityDate="2013-01-25T16:40:27.567" Title="Differences between Ackermann steering and standard bi/tricycles concerning kinematics?" Tags="&lt;mobile-robot&gt;&lt;design&gt;&lt;kinematics&gt;&lt;theory&gt;" AnswerCount="2" CommentCount="3" />
  <row Id="764" PostTypeId="1" AcceptedAnswerId="799" CreationDate="2013-01-09T03:56:58.867" Score="6" ViewCount="183" Body="&lt;p&gt;I am most familiar with SLAM maps that are point clouds, usually in the form of a vector like $&amp;lt;x,y,\theta,f_{1x},f_{1y},...,f_{nx},f_{ny}&amp;gt;$.  I also understand how to create a map like this using an EKF.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Today I came across a &lt;a href=&quot;http://www.mrpt.org/Graph-SLAM_maps&quot;&gt;.graph file format&lt;/a&gt;, which as you would expect consists of vertices and edges in the format:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;VERTEX2 id x y orientation&lt;/code&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;EDGE2 observed_vertex_id observing_vertex_id forward sideward rotate inf_ff inf_fs inf_ss inf_rr inf_fr inf_sr&lt;/code&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I know that there's a connection between matrices and graphs (an adjacency matrix for example).  But it's not clear to me how this graph format of a map is equivalent to a point cloud map that I'm familiar with.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What is the relationship?  Are the vertices both poses and landmarks? Are they in a global reference frame? How is this created from say velocity information and a range/bearing sensor?  Is there a transformation between a graph map and a point cloud?  &lt;/p&gt;&#xA;" OwnerUserId="502" LastActivityDate="2013-02-18T11:37:13.067" Title="The relationship between point cloud maps and graph maps" Tags="&lt;slam&gt;&lt;mapping&gt;" AnswerCount="2" />
  <row Id="765" PostTypeId="7" CreationDate="2013-01-09T12:40:28.560" Score="0" Body="&lt;p&gt;&lt;strong&gt;$SiteShortName&lt;/strong&gt;  is for professional robotic engineers, hobbyists, researchers and students.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We ask and answer questions about robotics, control systems, control theory, algorithms, actuators and sensors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We feel the best &lt;em&gt;Robotics&lt;/em&gt; questions have links to pertinent datasheets or code, but if your question generally covers …&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;a specific robotics design problem&lt;/li&gt;&#xA;&lt;li&gt;the theory and simulation of robotic systems&lt;/li&gt;&#xA;&lt;li&gt;a sensor for a robotic system&lt;/li&gt;&#xA;&lt;li&gt;the writing algorithms for robotic systems&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;… then you’re in the right place to ask your question!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some kinds of questions aren't allowed here:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Shopping recommendations&lt;/strong&gt;: Questions which ask &quot;which product or library should I use&quot;, are considered &lt;a href=&quot;http://blog.stackoverflow.com/2010/11/qa-is-hard-lets-go-shopping/&quot;&gt;shopping recommendations&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Electronics theory&lt;/strong&gt;: Questions which are more of generic electrical engineering questions and have no real relation to robotics are better off at &lt;a href=&quot;http://electronics.stackexchange.com&quot;&gt;Electrical Engineering&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Programming&lt;/strong&gt;: Generic programming questions with no relation to robotics should be asked on &lt;a href=&quot;http://stackoverflow.com&quot;&gt;Stack Overflow&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Sci-Fi Robotics&lt;/strong&gt; : Questions about movies/books involving robots should be be asked on &lt;a href=&quot;http://scifi.stackexchange.com&quot;&gt;Science Fiction&lt;/a&gt;, unless they involve some concept of robotics--in which they are fine here.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Generally speaking, if your question is directly related to &lt;em&gt;robotics&lt;/em&gt; then even if your question might &lt;em&gt;also&lt;/em&gt; be appropriate on another site, we are likely to be happy to see it here.&lt;/p&gt;&#xA;" OwnerUserId="-1" LastEditorUserId="1105" LastEditDate="2013-04-01T03:35:05.123" LastActivityDate="2013-04-01T03:35:05.123" />
  <row Id="766" PostTypeId="2" ParentId="763" CreationDate="2013-01-09T15:26:47.503" Score="7" Body="&lt;p&gt;You're making two mistakes that I can see, both related to the idea of &quot;shrinking&quot; the set of front or back wheels into a single wheel.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Rather than thinking of Ackermann steering as (conceptually) a single wheel, imagine expanding the single front wheel of a tricycle into 2 wheels.  At first, the tire gets wider, then splits into two tires, then they get further apart &amp;mdash; but the axles of the two wheels remain on the same line.  In other words, you end up with a &quot;steerable front beam axle&quot; like you'd find on a toy wagon &amp;mdash; &lt;strong&gt;not&lt;/strong&gt; an Ackermann system:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/XjorZ.jpg&quot; alt=&quot;radio flyer wagon&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You could think of an Ackermann system as two bicycles welded together side by side, noting that connecting the front wheels is not solved by simply forcing their steering angles to be equal.  Instead, you might look at techniques like &lt;a href=&quot;http://en.wikipedia.org/wiki/Burmester%27s_theory&quot; rel=&quot;nofollow&quot;&gt;Burmester's theory&lt;/a&gt; to design the proper kinematic linkage between them.  (In the Ackermann solution, it's a 4-bar linkage.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For the rear wheels, you're ignoring the ability to lean. In other words, a bicycle is not simply a tricycle with zero spacing between its back wheels; leaning is an integral part of maintaining stability with only two contact points.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://i.stack.imgur.com/Ixo0L.jpg&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/Ixo0Lm.jpg&quot; alt=&quot;tricycle leaning&quot;&gt;&lt;/a&gt; &lt;a href=&quot;http://i.stack.imgur.com/ZdrQ1.png&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/ZdrQ1m.png&quot; alt=&quot;bicycle leaning&quot;&gt;&lt;/a&gt;&#xA;(shifting weight to remain stable, via &quot;&lt;a href=&quot;http://www.easystreetrecumbents.com/articles/tag/greenspeed/&quot; rel=&quot;nofollow&quot;&gt;Tricycle Steering&lt;/a&gt;&quot;), (leaning to turn, via &lt;a href=&quot;http://www.phys.lsu.edu/faculty/gonzalez/Teaching/Phys7221/vol59no9p51_56.pdf&quot; rel=&quot;nofollow&quot;&gt;The stability of the bicycle&lt;/a&gt;)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Leaning is more of a dynamic discussion than a kinematic one, but worth noting since it affects the tires &amp;mdash; bicycle/motorcycle tires have a rounded cross section to accomodate that lean, while car/motor-trike tires have a flatter cross section.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-01-25T16:40:27.567" LastActivityDate="2013-01-25T16:40:27.567" CommentCount="2" />
  <row Id="767" PostTypeId="2" ParentId="763" CreationDate="2013-01-09T23:48:17.103" Score="3" Body="&lt;p&gt;You are correct in that there is no Kinematic difference. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Kinematics&quot; rel=&quot;nofollow&quot;&gt;Kinematics&lt;/a&gt; do not consider why things happen - ie dynamic stability.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are obvious physical differences, but when the math is worked out for kinematics, it should be the same. This of course implies a certain realistic cap on the level of kinematics. For example it has been pointed out a bicycle leans to steer, but that only occurs once a certain velocity is reached. Until then the kinematics are different. And once that velocity is reached &lt;a href=&quot;http://en.wikipedia.org/wiki/Precession&quot; rel=&quot;nofollow&quot;&gt;Gyroscopic precession&lt;/a&gt; also becomes involved. One has to choose where reasonableness is satisfied. If you think all the physics can be modeled, I have some contacts at Yamaha motorcycle racing I'd like to introduce you to.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I found a &lt;a href=&quot;https://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=1&amp;amp;cad=rja&amp;amp;sqi=2&amp;amp;ved=0CDIQFjAA&amp;amp;url=http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.41.7363&amp;amp;rep=rep1&amp;amp;type=pdf&amp;amp;ei=JgHuUP_-DqOSiALdtIDACw&amp;amp;usg=AFQjCNEj20VNHnRRCJVEvP4DIGIsZA3xnw&amp;amp;sig2=Nl3MEaEfABs3E9KYsQMjGQ&amp;amp;bvm=bv.1357700187,d.cGE&quot; rel=&quot;nofollow&quot;&gt;PDF&lt;/a&gt; that describes the math in detail. The Kinematic math for ackerman is known as the bicycle model. Unless that's a crued joke, I would say it implies the correct answer to your question.&lt;/p&gt;&#xA;" OwnerUserId="274" LastActivityDate="2013-01-09T23:48:17.103" CommentCount="2" />
  <row Id="768" PostTypeId="1" AcceptedAnswerId="769" CreationDate="2013-01-10T05:53:51.920" Score="4" ViewCount="1447" Body="&lt;p&gt;Im using my own code to create a quadcopter robot. The hardware part is done but I need to balance the copter. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is the video of its current status: &#xA;&lt;a href=&quot;https://www.dropbox.com/s/53tpf1jzaly6m33/Movie%20on%202013-01-10%20at%2006.36.mov&quot; rel=&quot;nofollow&quot;&gt;https://www.dropbox.com/s/53tpf1jzaly6m33/Movie%20on%202013-01-10%20at%2006.36.mov&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have tried to play with the speed of each motor to get it balanced. It didnt go. &#xA;I actually have a gyro and accelerometer onboard. But how shall I adjust the motor speed based on these values? What are the rules that I should beware of?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there any better solution other that try and error? Where shall I begin? Any tips? &lt;/p&gt;&#xA;" OwnerDisplayName="user697" LastEditorDisplayName="user697" LastEditDate="2013-01-10T06:07:11.300" LastActivityDate="2013-01-10T07:34:07.207" Title="How to balance a flying quadcopter?" Tags="&lt;balance&gt;&lt;quadcopter&gt;" AnswerCount="1" FavoriteCount="1" />
  <row Id="769" PostTypeId="2" ParentId="768" CreationDate="2013-01-10T07:34:07.207" Score="3" Body="&lt;p&gt;I believe a little Googling and you will find several of the existing controller boards have open source. For example I made a small change to &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/__24723__Hobbyking_KK2_0_Multi_rotor_LCD_Flight_Control_Board.html&quot; rel=&quot;nofollow&quot;&gt;hobby kings KK board&lt;/a&gt; last week, compiled it and it was fine (look for firmware 1.5 in the files tab). I think &lt;a href=&quot;http://www.rcgroups.com/forums/showthread.php?t=1568554&quot; rel=&quot;nofollow&quot;&gt;openAero&lt;/a&gt; is also readily available.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I sure would not try and start from scratch, but if you do, it is multiple PID loops on each axis, mixed with control signals from the receiver. Roll and pitch vary by changing motor speed as you guessed. Yaw is changed by changing opposite rotating pairs of motors. altitude is controlled by changing all motors at once. What code I have looked at leads me to believe you probably should be comfortable with &lt;a href=&quot;http://en.wikipedia.org/wiki/Euler_angles&quot; rel=&quot;nofollow&quot;&gt;euler angles&lt;/a&gt; in order to fuse sensor data from gyros and acceleration (which may or may not be &lt;a href=&quot;http://en.wikipedia.org/wiki/I%C2%B2C&quot; rel=&quot;nofollow&quot;&gt;I2C&lt;/a&gt; so learn that to if you are not familiar with it).&lt;/p&gt;&#xA;" OwnerUserId="274" LastActivityDate="2013-01-10T07:34:07.207" CommentCount="1" />
  <row Id="770" PostTypeId="2" ParentId="637" CreationDate="2013-01-10T11:33:17.867" Score="0" Body="&lt;p&gt;Keeping with the idea of robotics-relevant answers, another thing to take into consideration for mobile/wheeled robotics (albeit not so much with a wheelchair unless you plan to take it off-roading) is vibration and shock. In reviewing your design, ask yourself: is there anything that's going to come loose? Think connectors that aren't a very snug fit or jumper wires connected to a header pin. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;There's been some questions with great answers on Electronics.SE that cover this area at the PCB level:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://electronics.stackexchange.com/questions/5998/smd-vs-through-hole-components-in-high-vibration-environments&quot;&gt;SMD vs. Through-hole components in high vibration environments&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://electronics.stackexchange.com/questions/11457/board-design-for-high-impact-environments&quot;&gt;Board Design for High Impact Environments&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;While this is a pushing outside the scope of the question, be sure to account for disconnect/power loss conditions in software when possible as well. There's not a whole lot you can do on the power side if it's a single-supply system, but if you have multiple subsystems powered off of different supplies, you can monitor supply voltages so that one component can be aware of a failure elsewhere and act appropriately.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If your robot is controlled over a serial interface and the onboard controller can't get some kind of &quot;heartbeat&quot; signal from the host system, it needs to fail gracefully and not go careening down a hallway uncontrolled because the last command it received was &quot;go forward&quot;.&lt;/p&gt;&#xA;" OwnerUserId="308" LastActivityDate="2013-01-10T11:33:17.867" />
  <row Id="771" PostTypeId="5" CreationDate="2013-01-10T14:00:38.540" Score="0" ViewCount="2" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2013-01-10T14:00:38.540" LastActivityDate="2013-01-10T14:00:38.540" />
  <row Id="772" PostTypeId="4" CreationDate="2013-01-10T14:00:38.540" Score="0" Body="RS-232 is the electrical standard used on most serial ports." OwnerUserId="308" LastEditorUserId="308" LastEditDate="2013-01-10T15:08:17.700" LastActivityDate="2013-01-10T15:08:17.700" />
  <row Id="773" PostTypeId="5" CreationDate="2013-01-10T14:07:22.677" Score="0" ViewCount="2" Body="&lt;p&gt;*&lt;em&gt;P&lt;/em&gt;*ulsed *&lt;em&gt;W&lt;/em&gt;*idth *&lt;em&gt;M&lt;/em&gt;*odulation is most often used in robotics for motor control applications. &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;For a brushed DC motor, the PWM duty cycle controls the speed of the motor. &lt;/li&gt;&#xA;&lt;li&gt;For RC servos, the PWM duty cycle controls the servo position.&lt;/li&gt;&#xA;&lt;li&gt;Brushless DC motors use multiple PWM waveforms to control each phase of the motor.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="308" LastEditorUserId="134" LastEditDate="2013-01-10T15:07:54.550" LastActivityDate="2013-01-10T15:07:54.550" />
  <row Id="774" PostTypeId="4" CreationDate="2013-01-10T14:07:22.677" Score="0" Body="Pulse-width modulation (PWM) is varying the duty cycle of a rectangle wave, usually with a constant frequency.&#xD;&#xA;" OwnerUserId="308" LastEditorUserId="308" LastEditDate="2013-01-10T15:08:28.527" LastActivityDate="2013-01-10T15:08:28.527" />
  <row Id="775" PostTypeId="1" AcceptedAnswerId="776" CreationDate="2013-01-10T21:41:04.937" Score="4" ViewCount="191" Body="&lt;p&gt;I would like to design a robotic arm to hold a weight X at length Y (in my case I want to hold X=2.5 lbs at Y = 4 inches). Starting out simply, I would like try building an arm with a gripper plus one servo joint. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;[Servo Joint] ----- Y ------ [Gripper]  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;When designing an arm, would I want to say that the gripper has to have enough torque to hold the desired weight (e.g. 2.5 lbs) at a minimal distance (however long the fingers are) then design the servo joint to bear the weight of the gripper + the load?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would like to be able to hold the object at full extension&lt;/p&gt;&#xA;" OwnerUserId="721" LastEditorUserId="134" LastEditDate="2013-01-11T06:28:13.803" LastActivityDate="2013-01-11T13:09:33.457" Title="Getting started with robotic arm design" Tags="&lt;design&gt;&lt;servos&gt;&lt;arm&gt;" AnswerCount="1" />
  <row Id="776" PostTypeId="2" ParentId="775" CreationDate="2013-01-10T22:20:57.947" Score="3" Body="&lt;p&gt;You have the right idea, just be sure to design for the servo to bear the &lt;a href=&quot;http://en.wikipedia.org/wiki/Torque&quot; rel=&quot;nofollow&quot;&gt;moment force (aka torque)&lt;/a&gt; generated by the load at Y = 4 inches from the joint, not the 2.5 pounds of what you're trying to hold.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$\tau = r*F*\sin(\theta)$ &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Where:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;r is the displacement (your 4 inch arm)&lt;/li&gt;&#xA;&lt;li&gt;F is the magnitude of the force (2.5 pounds + the gripper)&lt;/li&gt;&#xA;&lt;li&gt;Theta is the angle between the force vector (gravity, pointing down) and the lever arm&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;br&gt;&#xA;You also want to account for the torque exerted by the weight of the 4-inch arm itself. The displacement you use to calculate this is not 4 inches, but the distance from the servo to the center of mass of the arm (probably 2 inches).&lt;/p&gt;&#xA;" OwnerUserId="308" LastEditorUserId="308" LastEditDate="2013-01-11T13:09:33.457" LastActivityDate="2013-01-11T13:09:33.457" CommentCount="2" />
  <row Id="777" PostTypeId="1" AcceptedAnswerId="779" CreationDate="2013-01-11T02:30:04.570" Score="5" ViewCount="271" Body="&lt;p&gt;I am trying to build a semi-analog timer. Something like those old egg timers that you rotate the face of. I want a knob that I can turn that can be read by a microcontroller, and I also want the microcontroller to be able to position the knob. I'd like to implement &quot;stops&quot; by letting the microcontroller push the knob towards certain positions. As it runs down, the knob should turn. This is my first project of this kind; I've built small robots in the past, but it's been many years.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've considered &lt;a href=&quot;http://forums.trossenrobotics.com/tutorials/how-to-diy-128/get-position-feedback-from-a-standard-hobby-servo-3279/&quot;&gt;hacking a servo motor&lt;/a&gt; to read its position, but the small hobby servos I've tried are too hard to turn, very noisy, and pick up too much momentum when turned. They don't act like a good knob.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm now considering a rotary encoder connected to a motor, but after hunting at several sites (SparkFun, ServoCity, DigiKey, Trossen, and some others), I haven't been able to find anything that seemed appropriate. I'm not certain how to find a motor that's going to have the right kind of low torque.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This seems like it shouldn't be a really uncommon problem. Is there a fairly normal approach to creating a knob that can be adjusted both by the user and a microcontroller?&lt;/p&gt;&#xA;" OwnerUserId="733" LastActivityDate="2013-01-31T06:35:34.400" Title="Building a controllable &quot;knob&quot;" Tags="&lt;motor&gt;&lt;servos&gt;" AnswerCount="5" CommentCount="1" />
  <row Id="778" PostTypeId="2" ParentId="777" CreationDate="2013-01-11T03:58:13.780" Score="0" Body="&lt;p&gt;I don't know if there is a normal approach to this, but you should definitely check out a video I found years ago and still blows my mind: &lt;a href=&quot;http://www.youtube.com/watch?v=zE5PGeh2K9k&quot; rel=&quot;nofollow&quot;&gt;The Secret Knock Detecting Lock&lt;/a&gt;. Basically the guy built an Arduino-based device you can hook up to your door and setup a secret knock that will trigger it to open... Awesome!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm sure just the video would be pretty good for inspiration (it's the first thing that came to my mind as I read the title of your question), but after a quick Google search I also found the &lt;a href=&quot;http://www.instructables.com/id/Secret-Knock-Detecting-Door-Lock/&quot; rel=&quot;nofollow&quot;&gt;instructable page&lt;/a&gt; that explains it all.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is a part of the instructable page where he says the motor he uses and gives out some recommendations:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;1  5v Gear reduction motor.  The higher torque the better.  &lt;a href=&quot;https://solarbotics.com/product/gm22/&quot; rel=&quot;nofollow&quot;&gt;Here&lt;/a&gt;'s a&#xA;  good one. (14-16mm diameter is ideal because it fits inside of 1/2&quot;&#xA;  PVC pipe.) I recommend one with at least 15oz/in (11 N-cm) of torque&#xA;  at 5v to turn a basic lock.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="95" LastActivityDate="2013-01-11T03:58:13.780" />
  <row Id="779" PostTypeId="2" ParentId="777" CreationDate="2013-01-11T09:55:38.550" Score="5" Body="&lt;p&gt;I have a couple of options for you.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Option 1, build your own servomechanism&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;As you only need a very low torque to move a knob, a very small motor should do the job nicely. You will probably need to add some friction so that it it doesn't move &lt;em&gt;too&lt;/em&gt; easily, or use a small stepper motor with a decent &lt;a href=&quot;http://en.wikipedia.org/wiki/Stepper_motor#Detent_torque&quot;&gt;detent torque&lt;/a&gt; and a little gearing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A very cheap way of getting your position feedback is to find an old &lt;a href=&quot;http://en.wikipedia.org/wiki/Mouse_%28computing%29#Mechanical_mice&quot;&gt;opto-mechanical mouse&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/File%3aMouse_mechanism_diagram.svg&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/4DwT7.png&quot; alt=&quot;opto-mechanical mouse - The copyright holder of this file allows anyone to use it for any purpose, provided that the copyright holder is properly attributed. Redistribution, derivative work, commercial use, and all other use is permitted.&quot;&gt;&lt;/a&gt; Opto-mechanical mouse&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Connect up the shaft to your motor/knob shaft and then either roll your own &lt;a href=&quot;http://en.wikipedia.org/wiki/Rotary_encoder#Incremental_rotary_encoder&quot;&gt;quadrature encoder&lt;/a&gt; (taking the A/B phase inputs directly into your microcontroller) or reuse the entire circuit board and hook up the 'mouse' to a serial port and read back the X or Y mouse position through software.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The article &lt;a href=&quot;http://members.shaw.ca/swstuff/mouse.html&quot;&gt;Recycle PS/2 Mice into Rotary Pulse Generators&lt;/a&gt; is a nice example of someone doing this.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Option 2, persevere with the RC servo&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;The reason why your &lt;a href=&quot;http://en.wikipedia.org/wiki/Servomechanism#RC_servos&quot;&gt;RC servo&lt;/a&gt;'s are hard to turn is that they have a high ratio gear train to give them the torque they need, and this makes them difficult to &lt;em&gt;backdrive&lt;/em&gt;. Take a look at this exploded diagram from the wikipedia &lt;a href=&quot;http://en.wikipedia.org/wiki/Servomechanism&quot;&gt;Servomechanism&lt;/a&gt; page:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/File%3aServo.jpg&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/ZgqPf.jpg&quot; alt=&quot;Exploded RC servo - This work has been released into the public domain by its author, Sonett72 at the wikipedia project.&quot;&gt;&lt;/a&gt; Small R/C servo mechanism&lt;/p&gt;&#xA;  &#xA;  &lt;ol&gt;&#xA;  &lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Electric_motor&quot;&gt;electric motor&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;position feedback &lt;a href=&quot;http://en.wikipedia.org/wiki/Potentiometer&quot;&gt;potentiometer&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;reduction &lt;a href=&quot;http://en.wikipedia.org/wiki/Gear&quot;&gt;gear&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Actuator&quot;&gt;actuator&lt;/a&gt; arm&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;/ol&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;A small turn of the actuator shaft of this RC servo would result in a large (many turn) movement of the motor, if you could get it to move without stripping the gears.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Again, since in your application you only need enough torque to turn the knob, you may be able to get rid of that gearing and use the motor position directly. By removing or reducing the gearing, you should find the motor moves very freely indeed. In fact, you may need to add some friction (or leave some gearing in place) in order to prevent the motor being very jittery.&lt;/p&gt;&#xA;" OwnerUserId="37" LastActivityDate="2013-01-11T09:55:38.550" CommentCount="4" />
  <row Id="780" PostTypeId="1" AcceptedAnswerId="781" CreationDate="2013-01-11T15:07:34.650" Score="5" ViewCount="267" Body="&lt;p&gt;The fact is that the more I search the less I find autonomous (real) robots in use. The companion robots are all toys with limited useless functionality. Whenever there is a natural disaster you don’t see operational search and rescue robots in the news. Even military robots in service are all remotely controlled machines. They are not intelligent machines. Industrial robotic arms are deterministic machines. The only robots with some levels of autonomous functionality are cleaning bots, warehouse operations bots and farming robots.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On the other hand, today:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;the artificial intelligence algorithms are very good in making decisions &lt;/li&gt;&#xA;&lt;li&gt;the sensing technologies are very sophisticated&lt;/li&gt;&#xA;&lt;li&gt;the communication technologies are very fast&lt;/li&gt;&#xA;&lt;li&gt;we can manufacture cheap parts&lt;/li&gt;&#xA;&lt;li&gt;people are extremely gadget savvy&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;So, why there is no real robot in our day to day life? No investment in the domain? No market yet? Not enough knowledge in the domain? A missing technology? Any idea?&lt;/p&gt;&#xA;" OwnerUserId="732" LastActivityDate="2013-01-12T20:32:36.790" Title="What are the reasons for not having autonomous robots in our daily activities?" Tags="&lt;mobile-robot&gt;" AnswerCount="2" CommentCount="2" />
  <row Id="781" PostTypeId="2" ParentId="780" CreationDate="2013-01-11T15:28:59.643" Score="5" Body="&lt;p&gt;First of all, everything is not as perfect as you think. A lot of algorithms (AI included) work well in theory, but in practice there are way too many &lt;code&gt;if&lt;/code&gt;s of unforeseen events. It happens so often that your algorithm works perfect in simulation and once you load it in a robot, it can't even go straight in a simple hallway.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;That aside, I believe there are two main reasons:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Robots are expensive&lt;/strong&gt;. You may have &lt;em&gt;some&lt;/em&gt; cheap parts, but really, robots are expensive. In my lab, we took part in making robotic skins, and just that, for a human-sized robot is not cheap at all. It's cheap for an industrial robot, but I doubt you would want to pay thousands of dollars/euros for not-useless robot.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Robots are not safe&lt;/strong&gt;. Not yet at least. If a small vacuum cleaner robot hits your leg, it won't hurt much. But if a humanoid robot crushes your hand during a hand-shake, well, no one likes to be responsible for that. Note that shortcomings of algorithms (for example sensor data processing, feature extraction and reasoning) are the main reason for this lack of safety.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;So I believe, even though we are not too far from having robot friends among us, it's still too early for it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Just to give you examples from real world:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The &lt;a href=&quot;http://en.wikipedia.org/wiki/Nao_%28robot%29&quot;&gt;Nao robot&lt;/a&gt;, designed to be a companion (from Wikipedia) but actually mostly used for soccer games, costs about &lt;strong&gt;16000$&lt;/strong&gt;:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://www.about-robots.com/images/nao-robot-price-how-much-does-the-nao-robot-cost-21603071.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The &lt;a href=&quot;http://en.wikipedia.org/wiki/Enon_%28robot%29&quot;&gt;Enon robot&lt;/a&gt;, built to be a personal assistant, costs about &lt;strong&gt;60000$&lt;/strong&gt;:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/commons/2/2d/Enon_robot.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The &lt;a href=&quot;http://en.wikipedia.org/wiki/ICub&quot;&gt;iCub&lt;/a&gt; humanoid costs &lt;strong&gt;200000$&lt;/strong&gt;:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://cdn.physorg.com/newman/gfx/news/hires/2009/DSC_5744.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="158" LastEditorUserId="158" LastEditDate="2013-01-11T15:38:24.130" LastActivityDate="2013-01-11T15:38:24.130" CommentCount="2" />
  <row Id="782" PostTypeId="2" ParentId="764" CreationDate="2013-01-12T06:19:56.733" Score="1" Body="&lt;p&gt;There's a &lt;a href=&quot;http://www.mrpt.org/node/1704&quot; rel=&quot;nofollow&quot;&gt;forum post&lt;/a&gt; with some more clarifying information on the format. It looks like the graph node values are initial estimates of self-poses, and edges encode pose constraints as represented by the &lt;a href=&quot;http://en.wikipedia.org/wiki/Kalman_filter#Information_filter&quot; rel=&quot;nofollow&quot;&gt;information filter&lt;/a&gt;, the dual of the Kalman filter.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From what I can tell, this map format includes only self-pose information and not landmarks, so there would not be a direct conversion from a point cloud map.&lt;/p&gt;&#xA;" OwnerUserId="55" LastEditorUserId="55" LastEditDate="2013-01-14T14:51:07.723" LastActivityDate="2013-01-14T14:51:07.723" CommentCount="2" />
  <row Id="783" PostTypeId="1" CreationDate="2013-01-12T11:46:10.993" Score="3" ViewCount="196" Body="&lt;p&gt;I am looking for a good embedded PC to run ROS on. I recently came across a couple of little machines using new very multi-core processors, such as the &lt;a href=&quot;http://www.kickstarter.com/projects/adapteva/parallella-a-supercomputer-for-everyone&quot; rel=&quot;nofollow&quot;&gt;Epiphany&lt;/a&gt; and the &lt;a href=&quot;http://www.xmos.com/&quot; rel=&quot;nofollow&quot;&gt;XMOS&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Since the one thing that ROS really seems to want is cores, would ROS be able to take advantage of all of these cores? Or are they all just too feeble with too little RAM to be of any use?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Would it make more sense to focus on machines with fewer, more powerful cores?&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2013-01-12T20:17:18.830" Title="Would ROS benefit from a multicore processor like Epiphany or XMOS?" Tags="&lt;ros&gt;" AnswerCount="2" />
  <row Id="784" PostTypeId="2" ParentId="783" CreationDate="2013-01-12T14:46:08.500" Score="2" Body="&lt;p&gt;Short answer; it depends.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;ROS is a framework that can support multiple cores, but it is up to the ROS modules themselves to thrive in a multi-core environment. You can NOT expect ROS to automatically use all the cores, but if your software is written in a way that they can be used, then ROS will accommodate them.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A little generic history; There was a way that program processes used to talk to each other within a computer. Soon that grew into a method where those process could communicate within the same computer or on to a physically separate computer. And then high efficiency versions of that became the basis for ROS and &lt;a href=&quot;https://www.microsoft.com/robotics/&quot; rel=&quot;nofollow&quot;&gt;Microsoft RDS&lt;/a&gt;. Microsoft found the project so successful they merged it with an existing technology &lt;a href=&quot;http://en.wikipedia.org/wiki/SOAP&quot; rel=&quot;nofollow&quot;&gt;SOAP&lt;/a&gt;, and developed &lt;a href=&quot;http://en.wikipedia.org/wiki/Windows_Communication_Foundation&quot; rel=&quot;nofollow&quot;&gt;WCF&lt;/a&gt;. The part you probably do not know is that WCF is being implemented as a processor to processor and/or sub-processor communication protocol on the hardware bus (with strong focus on robotic potential). The point is, that the message switching architectures pioneered by ROS and MRDS are super robust to the point where something similar will probably power hardware a generation or 2 from now.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Yes, by all means, use multi-core as much as possible. If you write code today that doesn't consider async and multi-core you might as well choose a different career path. There is little difference to writing well for 4 heavy cores, or 2000 small ones. Some difference, but if you know how to do one, you probably understand how to do the other as well.&lt;/p&gt;&#xA;" OwnerUserId="274" LastEditorUserId="308" LastEditDate="2013-01-12T20:17:18.830" LastActivityDate="2013-01-12T20:17:18.830" />
  <row Id="785" PostTypeId="2" ParentId="783" CreationDate="2013-01-12T19:57:38.353" Score="0" Body="&lt;p&gt;I can't comment on Epiphany, but you can absolutely connect additional RAM to an XMOS to be able to run ROS if the onboard 64KB/core RAM isn't sufficient. Check out the libraries on the XCore Github page: &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://github.xcore.com/repo_index/sc_sdram_readme.html&quot; rel=&quot;nofollow&quot;&gt;SDRAM&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://github.xcore.com/repo_index/sc_sdram_burst_readme.html&quot; rel=&quot;nofollow&quot;&gt;SDRAM burst mode&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://github.xcore.com/repo_index/sc_fram_if_readme.html&quot; rel=&quot;nofollow&quot;&gt;SPI FRAM&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://github.xcore.com/repo_index/sc_sram_readme.html&quot; rel=&quot;nofollow&quot;&gt;SRAM&lt;/a&gt; &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The &lt;a href=&quot;http://github.xcore.com/repo_index/proj_xmp64_readme.html&quot; rel=&quot;nofollow&quot;&gt;XK-XMP-64&lt;/a&gt; reference design has onboard SDRAM and the PDF schematics are in the Git repository if you want to go that route.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm picturing a lot of wrapper functions to call ROS functions and pass/stream data between threads with the XMOS inter-thread communication channels. There's a lot of design decisions you would have to make with respect to what threads to run on which cores -- if you run multiple threads on the same core, the 400-500 MIPS per core is split among them.&lt;/p&gt;&#xA;" OwnerUserId="308" LastActivityDate="2013-01-12T19:57:38.353" CommentCount="1" />
  <row Id="786" PostTypeId="2" ParentId="780" CreationDate="2013-01-12T20:32:36.790" Score="5" Body="&lt;p&gt;A major limiting factor to autonomous robots is intelligence. While AI has made great strides it has generally been unable to handle the complexity of the world. A common solution this problem has been to restrict autonomous robots to very simplified versions of the world.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The Roomba is a good example. It deals with the complexity of the world by essentially executing combinations of simple patterns (spirals, straight lines, etc.) where transitions between patterns are a function of obstacle presence and time. This has its benefits. For instance the Roomba only needs a hand full of bump and IR sensors to perceive its world which in turn limits the amount of processing power required.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The exception at the moment is autonomous vehicles. This comes predominantly from the large investments the military has been making over the years. Not only in Unmanned Aerial Vehicles (UAVs) but also ground based vehicles. Widely known examples of these investments include the &lt;a href=&quot;http://en.wikipedia.org/wiki/DARPA_Grand_Challenge&quot;&gt;DARPA Grand Challenge&lt;/a&gt; and &lt;a href=&quot;http://archive.darpa.mil/grandchallenge/&quot;&gt;DARPA Urban Challenge&lt;/a&gt;. Fortunately a lot of the techniques developed for these vehicles are more generally applicable. For instance the motion planning techniques are usually applicable to robots with other methods of locomotion.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Other types of autonomous robots are on the horizon because of similar investments. For instance DARPA recently announced a winner of the &lt;a href=&quot;http://www.theverge.com/2012/8/16/3247964/sandia-robot-hand-darpa-funded-replace-fingers&quot;&gt;DARPA hand challenge&lt;/a&gt; and is actively promoting a contest for &lt;a href=&quot;http://spectrum.ieee.org/automaton/robotics/humanoids/iros-2012-darpa-robotics-challenge-update&quot;&gt;bipeds&lt;/a&gt;. Similarly companies like &lt;a href=&quot;http://www.bostondynamics.com/&quot;&gt;Boston Dynamics&lt;/a&gt; have done a lot to advance autonomous robots. Of course one might object that their robots (e.g. &lt;a href=&quot;http://spectrum.ieee.org/automaton/robotics/military-robots/latest-ls3-alphadog-prototypes-get-less-noisy-more-brainy&quot;&gt;BigDog&lt;/a&gt; and &lt;a href=&quot;http://spectrum.ieee.org/automaton/robotics/military-robots/boston-dynamics-building-fast-running-robot-cheetah-new-agile-humanoid&quot;&gt;Cheetah&lt;/a&gt;) are only semi-autonomous but such an objection fails to recognize just how much autonomy is still involved.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-01-12T20:32:36.790" CommentCount="3" />
  <row Id="787" PostTypeId="2" ParentId="777" CreationDate="2013-01-13T04:55:24.117" Score="0" Body="&lt;p&gt;How about using a &lt;code&gt;stepper motor&lt;/code&gt;, you will be able to control the position exactly.&lt;/p&gt;&#xA;" OwnerUserId="743" LastEditorUserId="134" LastEditDate="2013-01-13T07:24:38.840" LastActivityDate="2013-01-13T07:24:38.840" CommentCount="2" />
  <row Id="788" PostTypeId="1" AcceptedAnswerId="793" CreationDate="2013-01-13T05:01:51.300" Score="7" ViewCount="740" Body="&lt;p&gt;I was wondering, do we have real nano bots, like the ones in the movies? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I think we have bots which can move through the blood vessels, am I right?&lt;/p&gt;&#xA;" OwnerUserId="743" LastEditorUserId="350" LastEditDate="2013-01-14T16:41:58.793" LastActivityDate="2013-09-06T19:40:00.233" Title="Do &quot;nano bots&quot; (that can fit inside the human body) actually exist?" Tags="&lt;mobile-robot&gt;" AnswerCount="3" CommentCount="2" FavoriteCount="1" />
  <row Id="789" PostTypeId="2" ParentId="788" CreationDate="2013-01-13T10:58:21.477" Score="7" Body="&lt;p&gt;&lt;a href=&quot;http://www.iris.ethz.ch/msrl/publications/files/Peyer_IROS2012.pdf&quot; rel=&quot;nofollow&quot;&gt;Movement of Artificial Bacterial Flagella in Heterogeneous Viscous&#xA;Environments at the Microscale&lt;/a&gt;&lt;sup&gt;&amp;dagger;&lt;/sup&gt; is a recent article from ETH Zürich that discusses the movement possibilities of an artificial bacteria in the blood stream or in the eye. Swim tests were performed in different methyl cellulose concentrations. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I do not think so that such methods can be used in human body in the near future because of the existing technological constraints.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It is still not clear how to &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;create such small machines from non-allergic material&lt;/li&gt;&#xA;&lt;li&gt;with effective motors&lt;/li&gt;&#xA;&lt;li&gt;and small battery storing enough energy for the duration of the job  &lt;/li&gt;&#xA;&lt;li&gt;that can move inside the body without making any &#xA;harm e.g. blocking the blood stream&lt;/li&gt;&#xA;&lt;li&gt;and that can deliberately move to the planned location&lt;/li&gt;&#xA;&lt;li&gt;recognize the destination &lt;/li&gt;&#xA;&lt;li&gt;and perform its job there &lt;/li&gt;&#xA;&lt;li&gt;and finally that could leave the body after the job is done,&lt;/li&gt;&#xA;&lt;li&gt;all reliable and stoppable if necessary, even with the possibility to track&#xA;the progress.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;sup&gt;&amp;dagger; by Kathrin E. Peyer, Famin Qiu, Li Zhang, and Bradley J. Nelson (978-1-4673-1735-1/12/S31.00 ©2012 IEEE)&lt;/sup&gt;&lt;/p&gt;&#xA;" OwnerUserId="577" LastEditorUserId="37" LastEditDate="2013-09-06T19:40:00.233" LastActivityDate="2013-09-06T19:40:00.233" CommentCount="4" />
  <row Id="790" PostTypeId="1" AcceptedAnswerId="792" CreationDate="2013-01-13T18:38:55.450" Score="3" ViewCount="226" Body="&lt;p&gt;Over the last month, I saw many robots that don't have any real purpose, which made me ask myself: &quot;Does this have any value?&quot; I saw dancing robot on CES, advanced lego based robots and also robots combined for very limited purpose. I saw ten year old children playing with robots, and competitions for them. Someone has told me that this is just for education and logic spreading. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In other cases, there were arguments like, &quot;this is for informing people that everything is going forwards&quot;. I know that people will buy robotic vacuum cleaners because they think that they'll save some time, but these robotic cleaners are not very reliable and I see it only as marketing. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Do these things (children's education, dancing robots, and other instances of &lt;a href=&quot;http://en.wikipedia.org/wiki/Pig_in_a_poke&quot; rel=&quot;nofollow&quot;&gt;selling a pig in a poke&lt;/a&gt;) have any value in terms of robotics, and are really advancing the field as manufacturers say?&lt;/p&gt;&#xA;" OwnerUserId="747" LastEditorUserId="350" LastEditDate="2013-01-14T16:58:33.223" LastActivityDate="2013-10-14T14:10:11.767" Title="Do &quot;toy&quot; robots move technology forwards?" Tags="&lt;research&gt;" AnswerCount="2" CommentCount="3" FavoriteCount="1" />
  <row Id="792" PostTypeId="2" ParentId="790" CreationDate="2013-01-13T19:10:15.817" Score="14" Body="&lt;p&gt;It certainly does. Ever since they started writing fiction about robots, they imagined robots as intelligent beings among ourselves. No one thought of robots as mechanical arms that replace your jobs. So first of all, there is no reason to think why the humans &lt;em&gt;wouldn't&lt;/em&gt; want to make useless robots.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You may have heard of the &lt;a href=&quot;http://en.wikipedia.org/wiki/Karakuri_ningy%C5%8D&quot; rel=&quot;nofollow&quot;&gt;karakuri dolls&lt;/a&gt; from the 17&lt;sup&gt;th&lt;/sup&gt; century, that serve tea (pretty useless, huh?):&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/commons/4/45/KarakuriBritishMuseum.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Or the &lt;a href=&quot;http://en.wikipedia.org/wiki/Digesting_Duck&quot; rel=&quot;nofollow&quot;&gt;digesting duck&lt;/a&gt; from the 18&lt;sup&gt;th&lt;/sup&gt; century (even worse):&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/commons/9/9a/Vaucanson_duck1.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;that you would argue that they don't make sense and they did not bring the technology forward, but that is not entirely correct.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are many aspects why such robots are useful:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Psychological effect&lt;/strong&gt;: As a human, you would probably be creeped out if you suddenly start seeing humanoids walking around. Useless robots (as well as fictional books) help the transition from our current life to one with robots.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Technological effect&lt;/strong&gt;: The useless robot could well be (and probably often is) the testbed for a new technology. The dancing robot may indeed be a prototype on which a system that keeps the robot in balance is being tested. Since dancing is more difficult than walking or running, the balance system on a robot that can dance can very well perform on one that merely walks.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Cultural effect&lt;/strong&gt;: In this subject, the Japanese come to mind. I am not thoroughly familiar with the Japanese culture, but they certainly seem to have a knack for robots that mimic a human. By your definition of &quot;useless&quot;, we humans all more or less are useless, so it is ok for them for the robots to be that way, too.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;On the second part of your question:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;are robotics really moving forwards as manufacturers say?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;I would again say yes. Most of the advances in technology (robotics included) is not made public, and by public I don't mean engineers and scientists, but your average teenage girl. You would probably never even hear in the news that they had made a super fantastic &lt;code&gt;&amp;lt;whatever&amp;gt;&lt;/code&gt; for robots. All you &lt;em&gt;would&lt;/em&gt; probably see is the &lt;em&gt;fun&lt;/em&gt; robots that people would enjoy watching.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I merely work in a lab and hear every now and then who does what, and I certainly believe that robotics is being developed quite fast!&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;To answer your comment:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;But what about using new technlogoies[sic] as deception of customer when saying this will help you; and it finally won't in most of cases.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;I'm afraid we live in a world of greed and lies. You hear all sorts of advertisements on all sorts of useless junk every day from companies that want to get more and more money.  And you should note that any company that mass produces robots (or any other thing) has only one goal: &lt;em&gt;sell those robots&lt;/em&gt;. It's not just robotics, so any effect such false advertising would have on people, you should ask psychologists rather than roboticists.&lt;/p&gt;&#xA;" OwnerUserId="158" LastEditorUserId="158" LastEditDate="2013-10-14T14:10:11.767" LastActivityDate="2013-10-14T14:10:11.767" CommentCount="5" />
  <row Id="793" PostTypeId="2" ParentId="788" CreationDate="2013-01-13T22:08:08.520" Score="8" Body="&lt;p&gt;Yes! Yes we do have robots which can swim through the bloodstream! &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://robotics.stackexchange.com/a/789/37&quot;&gt;rics&lt;/a&gt; did a good job of summarizing the difficulties in producing a completely autonomous nano robot. Something like a Mars rover, with more autonomy, but tiny. &lt;strong&gt;This is not the only type of robot.&lt;/strong&gt; While this is definitely beyond the capabilities of our current-day researchers / engineers, there is another thread in this domain that is worth mentioning: nano manipulators. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Traditionally, robots have been automated manipulators. In the case of robotic manipulators, most of the processing and localization challenges are offloaded, and the robot just carries out the task of delivering part A to location B.   &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/Sdnn7.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This closely matches the job description of a nano robot: deliver drug A to organ B, or take sample A, etc.  In this case, a very small magnetic manipulator can be inserted into the body and moved, turned, etc, by use of magnetic fields from &lt;em&gt;outside&lt;/em&gt; the body. So the robot ends up being a small piece of innocuous metal. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://www.iris.ethz.ch/msrl/research/current/helical_swimmers/images/swimmer_robot.png&quot; alt=&quot;A swimmer bot in the boodstream&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Think of it as the &quot;hand.&quot; The magnetic fields are the &quot;arms,&quot; an MRI is the &quot;eyes,&quot; and a computer somewhere is the &quot;brain.&quot;  Its not fully embedded, but it is technically a nano-scale robotic manipulator.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are interested in this (who wouldn't be?) Check out the following. There are plenty of awesome videos ahead:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;The key guy in this field is Brad Nelson. He gave a keynote talk at&#xA;ICRA 2012, in Saint Paul, MN. It is available freely&#xA;&lt;a href=&quot;http://techtalks.tv/talks/robotics-in-the-small/55951/&quot;&gt;here&lt;/a&gt;. Have&#xA;a look. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;More information (including the above reference paper), can be found on his webpage,&#xA;&lt;a href=&quot;http://www.iris.ethz.ch/msrl/research/current/index.php&quot;&gt;http://www.iris.ethz.ch/msrl/research/current/index.php&lt;/a&gt;  &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;One of &lt;em&gt;the coolest&lt;/em&gt; takeaways from the talk was his work on &quot;swimmer&quot; robots. More info (and videos!) here:&#xA;&lt;a href=&quot;http://www.iris.ethz.ch/msrl/research/current/helical_swimmers/&quot;&gt;http://www.iris.ethz.ch/msrl/research/current/helical_swimmers/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;There are two types of manipulators he is researching, but both are inserted, tracked using MRI, moved / manipulated using magnetic&#xA;fields, and then removed via a simple needle. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;The two types are based on size. A larger manipulator is easier to move using magnets, but a smaller one can be more precise.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;My impression after the keynote talk was this technology is quickly approaching human trials. They have tested in cow eyes and other biological organs. I'm interested to see what they produce this year.&lt;/p&gt;&#xA;" OwnerUserId="163" LastEditorUserId="37" LastEditDate="2013-01-13T23:47:20.417" LastActivityDate="2013-01-13T23:47:20.417" CommentCount="5" />
  <row Id="794" PostTypeId="2" ParentId="474" CreationDate="2013-01-13T22:17:02.603" Score="3" Body="&lt;ul&gt;&#xA;&lt;li&gt;Simplicity for hardware designers and easy usage for programmers &lt;/li&gt;&#xA;&lt;li&gt;Reliability&lt;/li&gt;&#xA;&lt;li&gt;Well known and supported in many systems&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Specially in robotics when we forced to use USB instead of RS232 (Our new PCs did not have RS232 ports). We faced many problems:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;Any USB socket disconnection need so much effort to recover the system. Sometimes it leads to a bad system-fault and we had to restart PCs.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Any shock or hazard make it unplugged.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Too much programming time &lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="748" LastActivityDate="2013-01-13T22:17:02.603" />
  <row Id="795" PostTypeId="1" AcceptedAnswerId="802" CreationDate="2013-01-14T14:40:31.087" Score="3" ViewCount="155" Body="&lt;p&gt;Microhard Systems currently sells several types of 900MHz modems, which are mostly used in robotics and SCADA applications.  One of their product lines, the 910 series (MHX910, n910, Spectra 910), is obsolete and no longer sold.  However, some older equipment is built with OEM versions of the 910 series soldered in place.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Microhard currently sells a 920 series (MHX920, n920, Spectra 920) that shares many of the specs with the 910 series, but cannot establish a radio link with a 910 series modem due to differences in encryption and hopping pattern.  Therefore, if you want to make new equipment communicate with equipment using the 910 series, your options are:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;De-solder the old 910 modem and replace it with the footprint-compatible 920 modem, or&lt;/li&gt;&#xA;&lt;li&gt;Reconfigure a 920 series modem to communicate with the 910 series modem.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Option 1 is undesirable, since I don't have access to the firmware on the older equipment in question.  Does anyone know how to accomplish option 2?&lt;/p&gt;&#xA;" OwnerUserId="736" LastEditorUserId="736" LastEditDate="2013-01-16T00:44:53.673" LastActivityDate="2013-01-16T14:27:55.273" Title="How can Microhard 920 series modems be made compatible with Microhard 910 series?" Tags="&lt;radio-control&gt;" AnswerCount="1" CommentCount="6" />
  <row Id="796" PostTypeId="2" ParentId="788" CreationDate="2013-01-14T16:51:10.853" Score="3" Body="&lt;p&gt;The branch of science that most closely resembles &quot;nano bots&quot; is &lt;a href=&quot;http://en.wikipedia.org/wiki/Capsule_endoscopy&quot; rel=&quot;nofollow&quot;&gt;Capsule Endoscopy&lt;/a&gt;.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/S6htU.jpg&quot; alt=&quot;Camera Pill&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The first generation of these were just &quot;edible&quot; video cameras with cameras inside, which passively recorded one's digestive tract.   The most recent round of development is focusing on making them smaller and more maneuverable.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;They are still not small enough to pass through blood vessels (at least, not safely).&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-09-06T16:35:36.543" LastActivityDate="2013-09-06T16:35:36.543" />
  <row Id="797" PostTypeId="1" CreationDate="2013-01-14T23:37:15.083" Score="1" ViewCount="50" Body="&lt;p&gt;I also asked this question on &lt;a href=&quot;http://answers.ros.org/question/52182/plans-to-use-vendor-id-to-identify-ethercat-devices/&quot; rel=&quot;nofollow&quot;&gt;ROS Answers&lt;/a&gt;, but it's not getting much interest there.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Currently the EtherCAT package in ROS uses the slaves' Product IDs to identify the devices, and load the correct drivers. This works great when all of the devices are manufactured by a single vendor, but are there any plans to prevent Product ID collisions when multiple vendors make ROS compatible EtherCAT devices?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We manufacture our own EtherCAT devices, and are just using some large values for Product ID, just hoping that these don't collide with anyone else's. Ideally, ROS would concatenate the vendor and product IDs into a single 64-bit value, and use that to identify the correct driver.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2013-01-15T09:30:29.677" Title="Plans to use Vendor ID to identify EtherCAT devices?" Tags="&lt;ros&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="798" PostTypeId="2" ParentId="797" CreationDate="2013-01-15T09:30:29.677" Score="2" Body="&lt;p&gt;That certainly is problematic. Given that ROS is free software, you could probably quite easily change the source code to use the &lt;code&gt;&amp;lt;vendor_id, product_code&amp;gt;&lt;/code&gt; pair as identifier and send a pull request.&lt;/p&gt;&#xA;" OwnerUserId="158" LastActivityDate="2013-01-15T09:30:29.677" />
  <row Id="799" PostTypeId="2" ParentId="764" CreationDate="2013-01-15T12:28:27.027" Score="3" Body="&lt;p&gt;As it says in the description of the file format, it is for graph based SLAM approaches. These work on minimizing the error of a pose constraint network. You can think of it this way: There are a number of reference frames (your vertices) and then you have knowledge on the transformation between these frames. These transformations are associated with an uncertainty. &lt;a href=&quot;http://ais.informatik.uni-freiburg.de/publications/papers/kuemmerle11icra.pdf&quot; rel=&quot;nofollow&quot;&gt;Pose graph optimization frameworks&lt;/a&gt; like e.g. &lt;a href=&quot;http://openslam.org/toro.html&quot; rel=&quot;nofollow&quot;&gt;TORO&lt;/a&gt;, &lt;a href=&quot;http://openslam.org/hog-man.html&quot; rel=&quot;nofollow&quot;&gt;HogMan&lt;/a&gt;, &lt;a href=&quot;http://openslam.org/g2o.html&quot; rel=&quot;nofollow&quot;&gt;G2O&lt;/a&gt; and so on will then give you the maximum likelihood of your vertex positions, given the constraints.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In practical robot terms, this usually means:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Each robot pose $p_k$ at time $k$ has its own reference frame and hence vertex&lt;/li&gt;&#xA;&lt;li&gt;Depending on you approach, you can also add landmarks as vertices. You don't have to however. &lt;/li&gt;&#xA;&lt;li&gt;Whenever you get new information on the relation between two poses, you add that to the constraint graph. E.g. your odometry will give you a transform between $p_k$ and $p_{k+1}$. &lt;/li&gt;&#xA;&lt;li&gt;If your approach works landmark based, you add transformations to your landmarks. If you only know the position to your landmark, you set a high uncertainty on the rotation information of your transformation. &lt;/li&gt;&#xA;&lt;li&gt;If your approach does not know about landmarks, e.g. you have large pointclouds that you match with ICP, you can add the ICP results to your constraint graph.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The pose constraints are usuall stored as sparse matrices of size $n \times n$ where $n$ is the number of vertices (again robot poses and landmarks) in your graph. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The file format itself provides initial guesses for the position of the vertices with the &lt;code&gt;VERTEX2&lt;/code&gt; (for 2D models) and &lt;code&gt;VERTEX3&lt;/code&gt; (for 3D models). You can't mix the two. &#xA;Constraints are added so that you specify the transform between the reference frames (vertices) given by &lt;code&gt;from_id&lt;/code&gt; and &lt;code&gt;to_id&lt;/code&gt;. The transform is given by either &lt;code&gt;EDGE2&lt;/code&gt; and &lt;code&gt;EDGE3&lt;/code&gt; as translation and rotation in euler angles, as well as the information matrix of the uncertainty. In this case the information matrix is the inverse of the covariance matrix for the transform vector $[x\, y \, z\, \text{roll}\, \text{pitch}\, \text{yaw}]$. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Depending on your framework, usually one of the vertices is grounded in a global reference frame. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Graph based pose graph optimizers are considered SLAM backends. How you generate the constraints e.g. from you range data is a front-end problem. There is a nice overview in these &lt;a href=&quot;http://ais.informatik.uni-freiburg.de/teaching/ws11/robotics2/pdfs/rob2-13-frontends.pdf&quot; rel=&quot;nofollow&quot;&gt;lecture notes&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="127" LastEditorUserId="127" LastEditDate="2013-02-18T11:37:13.067" LastActivityDate="2013-02-18T11:37:13.067" />
  <row Id="800" PostTypeId="2" ParentId="758" CreationDate="2013-01-16T10:14:58.307" Score="0" Body="&lt;p&gt;These robots appear creepy because they look like deformed humans and people with autism who find it difficult to read facial expressions and emotions may not perceive the disformities in the robot. They could also react the other way and be very frightened and creeped out by the robots. As someone with ADHD, I can tell you that they definitely creep me out. It's the ones like you have referenced that creep me the most, the futuristic robots from movies don't scare me so much.&lt;/p&gt;&#xA;" OwnerUserId="374" LastActivityDate="2013-01-16T10:14:58.307" />
  <row Id="801" PostTypeId="1" AcceptedAnswerId="803" CreationDate="2013-01-16T10:41:52.210" Score="2" ViewCount="105" Body="&lt;p&gt;I'm building a quadrupedal robot that will learn how to walk. From the &lt;a href=&quot;http://robotics.stackexchange.com/questions/568/is-it-possible-to-run-a-neural-network-on-a-microcontroller&quot;&gt;responses&lt;/a&gt; I got from asking if  its possible to run a NN on a micro controller I realised I needed to think of a clever system that wouldn't take 1000 years to be effective and would still be able to demonstrate onboard learning. I've designed a system but I'm not sure how effective it will be.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Firstly I hardcode 5-20 positions for the legs.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I set up a (simple) neural network where each node is a different set of positions for the legs, which I will write.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The robot moves from one node to another and the weight of the joint is determined by how far forward the robot moves.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Eventually there will be strong connections between the best nodes/positions and the robot will have found a pattern of moves that are most successful in walking.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;How effective would this be in learning to walk?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Note: instead of positions I could write short gaits and the process would work out which sets work best when combined.&lt;/p&gt;&#xA;" OwnerUserId="374" LastEditorUserId="177" LastEditDate="2013-01-16T16:58:18.067" LastActivityDate="2013-01-16T17:39:14.350" Title="Simple Neural Network with hardcoded positions for walk optimisation" Tags="&lt;microcontroller&gt;&lt;machine-learning&gt;&lt;walk&gt;" AnswerCount="2" CommentCount="4" />
  <row Id="802" PostTypeId="2" ParentId="795" CreationDate="2013-01-16T14:27:55.273" Score="2" Body="&lt;p&gt;After some conversations with Microhard's technical support, the following procedure worked for me:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Email Microhard technical support.  Explain what you're trying to do, and ask for a version of 920 series firmware that will communicate with your 910 series modem.  This firmware is available for the n920 via email, but is not on their website.  There is a firmware file for the Spectra 920 on their downloads page; I have not tried it.&lt;/li&gt;&#xA;&lt;li&gt;Connect a serial cable to the data port of the modem. (Not the diagnostics port)&lt;/li&gt;&#xA;&lt;li&gt;You must have hardware with an &quot;S2&quot; switch accessible, or with access to the !bootprog pin on the OEM 920 module.  Hold the switch down or hold the !bootprog line low, and power cycle the modem.  Do not release until procedure is completed.&lt;/li&gt;&#xA;&lt;li&gt;Use the Microhard Firmware loader (available on the Microhard downloads page) to load the provided firmware.&lt;/li&gt;&#xA;&lt;li&gt;Release the S2 switch (or raise the !bootprog line) and power cycle the modem.  Your 920 series modem is now ready to communicate with 910 series modems.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="736" LastActivityDate="2013-01-16T14:27:55.273" />
  <row Id="803" PostTypeId="2" ParentId="801" CreationDate="2013-01-16T16:43:02.230" Score="3" Body="&lt;p&gt;This reminds me of &lt;a href=&quot;http://www.foddy.net/Athletics.html&quot; rel=&quot;nofollow&quot;&gt;QWOP&lt;/a&gt; (seriously).  You need to plan a sequence of button presses to move forward.  For every situation the runner finds himself in, we need to know what button to press, how long to hold it, etc. When you play that, you probably look a lot like this video I stumbled across (pun alert): &lt;a href=&quot;https://www.youtube.com/watch?v=JFJkpVWTQVM&quot; rel=&quot;nofollow&quot;&gt;NN training bi-pedal walkers&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What you need to recognize is &lt;strong&gt;what configuration is my robot in&lt;/strong&gt; and you need to plan &lt;strong&gt;what leg should move to where&lt;/strong&gt;?  So you need a topology like this&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Leg encoder values → NN → Leg desired encoder values&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The difference is you need &lt;em&gt;actual&lt;/em&gt; input in the form of sensor values, and output in the form of actions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note, if you had other sensors (IMU would be helpful) it would be included in the inputs, and if you had force-controlled joints, those would be your outputs. &lt;/p&gt;&#xA;" OwnerUserId="163" LastActivityDate="2013-01-16T16:43:02.230" />
  <row Id="804" PostTypeId="2" ParentId="801" CreationDate="2013-01-16T17:39:14.350" Score="2" Body="&lt;p&gt;Really this is a question to be answered by experiments. Will it work? It seems like it could. Two things that will be important to look at are:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;em&gt;Training time&lt;/em&gt; - You are still using a neural network and they take time to train. Whether this formulation would reduce the number of rounds required for training is really to be seen. It will of course change with the number of connections in the net as your agent will need to test each multiple times.&lt;/li&gt;&#xA;&lt;li&gt;&lt;em&gt;Training method&lt;/em&gt; - Based on your description it seems you are planning to use a &lt;a href=&quot;http://en.wikipedia.org/wiki/Recurrent_neural_network&quot; rel=&quot;nofollow&quot;&gt;Recurrent Neural Network&lt;/a&gt; (RNN) which, if memory serves, makes training more computationally intense.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;There is a bit of literature on this topic already. For example a quick google reveals a paper titled &lt;a href=&quot;http://www.sciencedirect.com/science/article/pii/S0925231201005045&quot; rel=&quot;nofollow&quot;&gt;A neural network model for quadruped gait generation and transitions&lt;/a&gt;. It may be worth looking to see what has already been tried. But then sometimes it is just fun to run the experiments.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-01-16T17:39:14.350" />
  <row Id="805" PostTypeId="7" CreationDate="2013-01-17T00:48:57.617" Score="0" Body="&lt;ul&gt;&#xA;&lt;li&gt;a specific robotics design problem&lt;/li&gt;&#xA;&lt;li&gt;the theory and simulation of robotic systems&lt;/li&gt;&#xA;&lt;li&gt;a sensor for a robotic system&lt;/li&gt;&#xA;&lt;li&gt;the writing algorithms for robotic system&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="-1" LastEditorUserId="644" LastEditDate="2013-01-17T00:48:57.617" LastActivityDate="2013-01-17T00:48:57.617" />
  <row Id="806" PostTypeId="7" CreationDate="2013-01-17T00:49:51.250" Score="0" Body="&lt;ul&gt;&#xA;&lt;li&gt;shopping recommendations&lt;/li&gt;&#xA;&lt;li&gt;electronics theory&lt;/li&gt;&#xA;&lt;li&gt;programming&lt;/li&gt;&#xA;&lt;li&gt;sci-fi robotics&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="-1" LastEditorUserId="644" LastEditDate="2013-01-17T00:49:51.250" LastActivityDate="2013-01-17T00:49:51.250" />
  <row Id="807" PostTypeId="1" AcceptedAnswerId="808" CreationDate="2013-01-17T08:50:58.617" Score="6" ViewCount="241" Body="&lt;p&gt;We are currently designing a mobile robot + mounted arm with multiple controlled degrees of freedom and sensors. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am considering an architecture in two parts:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;A set of realtime controllers (either Raspeberry Pis running an RTOS such as Xenomai or bare metal microcontrollers) to control the arm motors and encoders.  Let us call these machines RTx, with x=1,2,3… depending on the number of microcontrollers.  This control loop will run at 200Hz.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;A powerful vanilla linux machine running ROS to compute SLAM, mocap, and execute high-level logic (decide the robot’s task and compute the motors' desired position and speed).  This control loop will run at 30Hz.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;I know my framework needs to be scalable to account for more motors, more sensors, more PCs (eg. for external mocap). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;My main problem is to decide how to have the different RTx communicate with PC1. I have looked at papers related to robots architecture (e.g. &lt;a href=&quot;http://global.kawada.jp/mechatronics/hrp2.html&quot; rel=&quot;nofollow&quot;&gt;HRP2&lt;/a&gt;), most often they describe the high level control architecture but I have yet to find information on how to have the low level communicate with the high level and in a scalable way. Did I miss something?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In order to connect the fast RT machines ensuring the motor control with PC1, I have considered TCP/IP, CAN and UART:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;TCP/IP: not deterministic but easy to put in place. Is non determinism a real issue (as it will only be used at at slow speed 30Hz anyways)?&lt;/li&gt;&#xA;&lt;li&gt;CAN: slow, very reliable, targeted to cars ( have seen there are some exemples using CAN with robots but it looked exotic)&lt;/li&gt;&#xA;&lt;li&gt;UART: if I had only had one RT machine for motor control I would have considered UART but I guess this port does not scale well with many RTx&#xA;Is TCP/IP really a no go because of its non-deterministic characteristics? It is so easy to use…&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;At the moment no solution really seems obvious to me. And as I can find no serious robot example using a specific reliable and scalable solution, I do not feel confident to make a choice. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Does anyone have a clear view on this point or literature to point to?  Are there typical or mainstream communication solutions used on robots?&lt;/p&gt;&#xA;" OwnerUserId="763" LastEditorUserId="350" LastEditDate="2013-01-17T23:08:42.567" LastActivityDate="2013-08-07T13:36:08.673" Title="How can I control a fast (200Hz) realtime system with a slow (30Hz) system?" Tags="&lt;control&gt;&lt;design&gt;&lt;communication&gt;" AnswerCount="2" CommentCount="3" />
  <row Id="808" PostTypeId="2" ParentId="807" CreationDate="2013-01-17T12:20:26.503" Score="6" Body="&lt;p&gt;I think you've taken a good first step; you've divided the problem into a mobile platform (which has uncertainty of position and must navigate) and the arm (which has a fair certainty of position in real time, through encoders).  &lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;I have looked at papers related to robots architecture [...] but I have yet to find information on how to have the low level communicate with the high level and in a scalable way. Did I miss something?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;From your description, it sounds like you're trying to tie each RTx controller directly to PC1, which is running ROS.  What you've missed is that ROS is &lt;em&gt;designed&lt;/em&gt; to handle a group of applications that may produce and consume data at different rates.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What your application needs is a &lt;strong&gt;communications bridge&lt;/strong&gt; &amp;mdash; a single interface between your 200Hz loop and your ROS environment.  In other words, instead of tying each RTx controller to PC1, tie all the RTx controllers together and connect &lt;em&gt;that&lt;/em&gt; to PC1.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, use an &lt;a href=&quot;http://www.robot-electronics.co.uk/acatalog/I2C_Tutorial.html&quot;&gt;I2C Bus&lt;/a&gt; to link the RTx systems together, and add another RTx controller to be the &quot;Arm Master&quot; (AM).  The AM's job would be to accept incoming commands in some PC1-friendly format and protocol, and convert those commands to I2C messages.  Then you'd write a ROS app to send commands to the AM.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another way to do it with I2C would be to put an I2C controller directly on PC1 and write all the arm controlling logic in a ROS app.  This may seem like a more streamlined way to accomplish your goal, but it can make debugging more difficult as you are removing the modularity of the system &amp;mdash; you'll have to troubleshoot it as one big complex system instead of two easily testable components.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-01-17T12:20:26.503" CommentCount="1" />
  <row Id="809" PostTypeId="2" ParentId="777" CreationDate="2013-01-17T17:21:51.117" Score="0" Body="&lt;p&gt;Use a rotatory potentiometer. Interface it to an ADC pin of your micro-controller, and depending on the resolution, you can get anywhere between 256 to 65536 values, which you can then use to set &quot;stops&quot;.&lt;/p&gt;&#xA;" OwnerUserId="765" LastActivityDate="2013-01-17T17:21:51.117" CommentCount="1" />
  <row Id="810" PostTypeId="1" AcceptedAnswerId="811" CreationDate="2013-01-17T23:17:15.437" Score="4" ViewCount="72" Body="&lt;p&gt;I'm running out of digital ports, and have no sensors that fit the definition 'analog'. Would it be possible to run a &lt;a href=&quot;http://www.robotc.net/support/vex/WebHelpCortex/index.htm#page=functions_vex/sensors/VEX_2.0_Cortex_-_Sensors.htm&quot; rel=&quot;nofollow&quot;&gt;touch sensor, a quadrature encoder, or an ultrasonic sensor on an analog port?&lt;/a&gt; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm thinking not, but I didn't run across anything that said otherwise.&lt;/p&gt;&#xA;" OwnerUserId="685" LastActivityDate="2013-01-18T03:35:12.763" Title="Can ultrasonic and button sensors be run in a VEX analog port?" Tags="&lt;sensors&gt;" AnswerCount="1" CommentCount="0" />
  <row Id="811" PostTypeId="2" ParentId="810" CreationDate="2013-01-18T03:35:12.763" Score="2" Body="&lt;p&gt;The underlying microcontroller in the VEX Cortex is some sort of STM32F1 or STM32F2. I'm not sure which model exactly (just that it's a ST-made Cortex M3), but they all do have digital I/O capabilities on the pins used for analog inputs. Given the bare microcontroller, you could do so.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, the VEX Cortex is not the bare microcontroller. According to the &lt;a href=&quot;http://www.vexforum.com/wiki/index.php/VEX_Cortex_Microcontroller&quot; rel=&quot;nofollow&quot;&gt;documentation&lt;/a&gt;, the controller board has been designed to add a much higher input impedance to the analog inputs which would likely interfere with digital operation:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Input Impedance: Analog - The 8 analog inputs each consist of a 470K pull-up to +5V, a series resistance of 10K and a 20K pull-down resistance to the uP.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;You can see the difference in the circuit connections on page 13 of the &lt;a href=&quot;http://content.vexrobotics.com/docs/VEXnet_Cortex_UserGuide_081811.pdf&quot; rel=&quot;nofollow&quot;&gt;User's Guide (PDF)&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="308" LastActivityDate="2013-01-18T03:35:12.763" CommentCount="1" />
  <row Id="812" PostTypeId="1" AcceptedAnswerId="813" CreationDate="2013-01-18T13:37:18.247" Score="6" ViewCount="155" Body="&lt;p&gt;I have a small motorized vehicle with gears as wheels running up and down a track made of gear racks. How can this robot know when it has run half the track? And what's the best method to keep it from running off its track at the end and then return to start.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The robot is carrying water, not exactly the same amount each time, so it will not weigh the same. Therefore it might not be the same amount of steps in the stepper-motor each time.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here I have some ideas that might work, though I am a beginner, and don't know what's the best solution.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;GPS tracking it (overkill on such a small scale?)&lt;/li&gt;&#xA;&lt;li&gt;Some kind of distance measurer&lt;/li&gt;&#xA;&lt;li&gt;Have a knob it will hit at the middle of the track, telling program to delay for a given time&lt;/li&gt;&#xA;&lt;li&gt;Track amount of steps the motor has performed (won't be as accurate?)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="689" LastEditorUserId="158" LastEditDate="2013-01-18T14:11:55.900" LastActivityDate="2013-01-22T03:49:18.343" Title="How to find out how far a motor has taken a vehicle?" Tags="&lt;mobile-robot&gt;&lt;arduino&gt;&lt;sensors&gt;" AnswerCount="3" CommentCount="2" FavoriteCount="1" />
  <row Id="813" PostTypeId="2" ParentId="812" CreationDate="2013-01-18T14:58:32.263" Score="4" Body="&lt;p&gt;If you are running on a fixed track, by far the easiest method is to use a pair of &lt;em&gt;endstops&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Typically these would be &lt;em&gt;mechanical&lt;/em&gt;, &lt;em&gt;magnetic&lt;/em&gt; or &lt;em&gt;optical&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Mechanical&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;A &lt;em&gt;mechanical endstop&lt;/em&gt; could be as simple as a physical barrier at the end of your track, much like a train track &lt;a href=&quot;http://en.wikipedia.org/wiki/Buffer_stop&quot; rel=&quot;nofollow&quot;&gt;buffer stop&lt;/a&gt;. Your vehicle would bump up to buffer, detect that it wasn't moving and take that as a signal that it had reached the end of travel.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you you are moving slowly, with low toque and the restraining force of the buffer is significantly greater than the motive force of the vehicle plus the force from dissipating the &lt;a href=&quot;http://en.wikipedia.org/wiki/Momentum&quot; rel=&quot;nofollow&quot;&gt;momentum&lt;/a&gt; of the vehicle, then a simple mechanical &lt;em&gt;endstop&lt;/em&gt; might be sufficient.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you want to get a little more sophisticated, you could add a mechanical switch to your vehicle &lt;a href=&quot;http://en.wikipedia.org/wiki/Bumper_%28automobile%29&quot; rel=&quot;nofollow&quot;&gt;bumpers&lt;/a&gt;, ideally on a spring such that it is closed before the main body of the vehicle hits the buffer. When the buffer stop is close, the control system would be told by the closing of the switch that and could apply the brakes.&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Magnetic&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;A &lt;em&gt;magnetic endstop&lt;/em&gt; would be a magnet on the track with a &lt;a href=&quot;http://en.wikipedia.org/wiki/Reed_switch&quot; rel=&quot;nofollow&quot;&gt;reed-switch&lt;/a&gt; attached to your control system. When the reed switch rolls over the magnet, the circuit is closed and the control system can stop the vehicle.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This has the advantage over the mechanical switch that it is non contact, so is less likely to be damages if the vehicle becomes a run-away.&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Optical&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;An &lt;em&gt;optical endstop&lt;/em&gt; would be an &lt;a href=&quot;http://www.micromo.com/why-stepper-motors-lose-steps.aspx&quot; rel=&quot;nofollow&quot;&gt;slotted optical switch&lt;/a&gt; on the vehicle and a blade of metal near the end of travel on the track, which runs through optical switch, blocking the beam when the vehicle gets close to the end of travel.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This has the advantage that rather than relying on a magnet that is in one spot on the track being detected, it can signal an end of travel condition for the whole distance from the end of required travel right up to any mechanical endstop.&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Soft endstops&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Essentially, this is just keeping track of where you have commanded your stepper motor to move and applying limits on how far you allow the higher level software to move. If you are requesting motion which is well within the parameters of the motor you have specified for your vehicle (speed, torque and acceleration profile etc.), then it should not be &lt;a href=&quot;http://www.micromo.com/why-stepper-motors-lose-steps.aspx&quot; rel=&quot;nofollow&quot;&gt;skipping steps&lt;/a&gt; and soft end-stops may well be sufficient.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you do this though, I would also recommend adding one of the other mechanisms as &lt;a href=&quot;http://idioms.thefreedictionary.com/belt+and+braces&quot; rel=&quot;nofollow&quot;&gt;belt and braces&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Combinations&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Most industrial systems have multiple end of travel detection and over travel prevention systems, usually soft limits and either a &lt;a href=&quot;http://reprap.org/wiki/Mechanical_Endstop&quot; rel=&quot;nofollow&quot;&gt;mechanical endstop&lt;/a&gt; plus &lt;a href=&quot;http://en.wikipedia.org/wiki/Limit_switch&quot; rel=&quot;nofollow&quot;&gt;limit switches&lt;/a&gt; or soft limits, mechanical endstop plus &lt;a href=&quot;http://reprap.org/wiki/OptoEndstop_2.1&quot; rel=&quot;nofollow&quot;&gt;opto endstop&lt;/a&gt;. All three systems have to fail in order for the system fail overall.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You might also want to have a look at the answers to &lt;a href=&quot;http://electronics.stackexchange.com/q/41733/3774&quot;&gt;Why do i need an endstop sensor with stepper motor?&lt;/a&gt; over on &lt;a href=&quot;http://electronics.stackexchange.com/&quot;&gt;Electrical Engineering&lt;/a&gt; Stack exchange.&lt;/p&gt;&#xA;" OwnerUserId="37" LastEditorUserId="350" LastEditDate="2013-01-20T17:39:16.740" LastActivityDate="2013-01-20T17:39:16.740" />
  <row Id="814" PostTypeId="2" ParentId="812" CreationDate="2013-01-18T15:28:59.377" Score="3" Body="&lt;p&gt;If you are running gears as wheels on gear tracks, I do not understand how weight could change the number of steps. How can they slip? If there is no slippage, then the amount of steps should always be sufficient, although as mark suggested, most real world solutions would also include a limiting touch switch in case of mechanical failure.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Since using number of steps involves some math, it may be just easier and as good to use only  limiting touch switches. It is common to put touch switches at any location such as the middle. In the case for a middle switch, some protrusion on the tracks would trigger the switch on the robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.radioshack.com/product/index.jsp?productId=2049718&quot; rel=&quot;nofollow&quot;&gt;typical switch&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/JgKH5.jpg&quot; alt=&quot;Touch Switch&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="274" LastActivityDate="2013-01-18T15:28:59.377" CommentCount="5" />
  <row Id="815" PostTypeId="1" AcceptedAnswerId="816" CreationDate="2013-01-18T19:08:37.780" Score="5" ViewCount="227" Body="&lt;p&gt;I'm working on a rather low budget project, and need some way to control four or more motors using one Arduino. I've looked at motor shields a little, but I have a shield on top of it already, It does have female input on the top though, so a motor shield may work. Any suggestions?&lt;/p&gt;&#xA;" OwnerUserId="498" LastActivityDate="2013-09-05T16:10:39.327" Title="Arduino Motor control" Tags="&lt;control&gt;&lt;arduino&gt;&lt;microcontroller&gt;&lt;motor&gt;&lt;power&gt;" AnswerCount="5" CommentCount="1" FavoriteCount="2" />
  <row Id="816" PostTypeId="2" ParentId="815" CreationDate="2013-01-18T19:21:09.853" Score="7" Body="&lt;p&gt;You'll have to determine yourself whether a motor controller shield &lt;a href=&quot;http://www.freetronics.com/pages/stacking-arduino-shields&quot;&gt;is compatible and can be stacked on your existing shield&lt;/a&gt;.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In some cases, you can use Arduino's &lt;a href=&quot;http://arduino.cc/en/Reference/SPI&quot;&gt;SPI&lt;/a&gt;.  In other cases, you'll need to check whether the pins that your shield uses would conflict with the pins needed by a motor controller.  &lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-01-18T19:21:09.853" />
  <row Id="817" PostTypeId="2" ParentId="812" CreationDate="2013-01-18T19:24:04.113" Score="3" Body="&lt;p&gt;A stepper motor actually will move the same amount of steps per control signal regardless of weight, drawing more current as needed to turn the motor shaft the same amount. If there was wheel slip to account for, weight would be a factor there. However, given your gear rack track, wheel slip is negligible and can be ignored. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've built small line-follower robots in the past using 5V geared stepper motors running off AA batteries. Wheel slip was fairly small due to rubber O-rings mounted to the wheels. We took two identical prototypes and set them side by side and sent a move forward signal to both simultaneously. They moved in perfect lockstep over the course of a meter. We then placed a glass bottle of beer on one of the robots and repeated the experiment. Same result despite the weight difference.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The specifications for your stepper motor will list a &lt;b&gt;Step Angle&lt;/b&gt;, the number of degrees that the motor shaft turns for a single step (I'm assuming that you're not doing any microstepping). You then need to account for the gear ratio to figure out how far you actually move. This is a little trickier to calculate with a rack and pinion than a normal pair of spur gears. Gear ratio is normally determined by the diameter of the input and output gears, but your output gear (the rack) is technically of infinite diameter.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you haven't already, set up your control code so that you can make your stepper motor turn a given number of steps. Suppose the step angle of your motor is 7.5 degrees. The number of steps required to turn 360 degrees is:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;360&amp;deg; / 7.5&amp;deg; per step = 48 steps&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can verify your 360 degree turn code by by placing a small mark on the pinion gear. Now set your robot on the rack and measure how far it travels along the rack when you turn the motor 360 degrees (48 steps in this case). You can use this measurement to determine how far along the rack the robot moves per step. Suppose it travels 12 centimeters.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;12 cm / 48 steps = &lt;b&gt;0.25 cm of linear motion per step&lt;/b&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Try the track measurement again with the maximum water load and verify that a 360 degree turn of the pinion gear still occurs. If not, you are trying to step too fast for the motor torque to keep up and it's missing steps. Increase the interval between steps until you get a full 360 degree turn of the pinion gear with the water weight.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can now encode movements to 0.25 cm resolution. If you know the length of the track and can guarantee your start position, you can get away with not having an endstop or limit switch. That being said, it's always a good idea to have them there anyways just in case.&lt;/p&gt;&#xA;" OwnerUserId="308" LastEditorUserId="308" LastEditDate="2013-01-22T03:49:18.343" LastActivityDate="2013-01-22T03:49:18.343" CommentCount="0" />
  <row Id="819" PostTypeId="1" AcceptedAnswerId="820" CreationDate="2013-01-21T06:25:29.593" Score="4" ViewCount="252" Body="&lt;p&gt;We have an electric wheel chair, and are looking to add a rotary encoder to each wheel.  We don't want to hack the motor itself, so want to add the encoder without harming the motor-to-wheel connection.  We will be using an arduino to read the signal.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Does anyone have any experience adding rotary encoders to already assembled wheel assemblies?  &lt;/p&gt;&#xA;" OwnerUserId="779" LastActivityDate="2013-01-21T20:45:09.747" Title="Adding Rotary Encoders to an Electronic Wheel Chair" Tags="&lt;arduino&gt;&lt;microcontroller&gt;" AnswerCount="1" FavoriteCount="1" />
  <row Id="820" PostTypeId="2" ParentId="819" CreationDate="2013-01-21T08:41:39.900" Score="5" Body="&lt;p&gt;An &lt;a href=&quot;https://www.google.com/search?q=optical%20encoder%20disk&amp;amp;hl=en&amp;amp;tbo=u&amp;amp;tbm=isch&amp;amp;source=univ&amp;amp;sa=X&amp;amp;ei=hvv8UKSBEMraigLkg4GQBA&amp;amp;ved=0CFkQsAQ&amp;amp;biw=1524&amp;amp;bih=1088&quot; rel=&quot;nofollow&quot;&gt;optical encoder&lt;/a&gt; is fairly simple to add to an existing wheel.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/GDZKa.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Essentially you mount a photosensor that can detect notches or patches on a disk as it rotates with the wheel. You could use through hole light detection as well.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The circuit design is fairly straight foward&#xA;&lt;img src=&quot;http://i.stack.imgur.com/TIfWj.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And your arduino program counts the number of pulses it receives. Knowing the number of ticks per revolution, and wheel size, you can get accurate odometry.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another solution that may work for you is add on encoders for DC motors. Their original intent is to make a regular motor a Servo motors, but would work great for this task as well. The only real difference being that a servo motor uses the information in a closed loop to position the motor, as opposed to just keeping track of it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/iPUKQ.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And one other solution I thought of - if your wheel chair has spokes like a bicycle, then a magnet like &lt;a href=&quot;http://www.ebay.com/itm/Universal-Cat-Eye-Wheel-Spoke-Magnet-Speed-Sensor-CatEye-4-ANY-Bicycle-Computer-/150765504458&quot; rel=&quot;nofollow&quot;&gt;this&lt;/a&gt; would be easy to attach, and a magnetic sensor, very similar to the above light detection circuit could be located on the chair/frame. That would probably be the least intrusive to implement. If you needed more than 1 per revolution accuracy, just add more magnets to more spokes, as long as they are distributed evenly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/Atj2x.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="274" LastEditorUserId="274" LastEditDate="2013-01-21T20:45:09.747" LastActivityDate="2013-01-21T20:45:09.747" />
  <row Id="821" PostTypeId="2" ParentId="757" CreationDate="2013-01-21T12:36:18.757" Score="2" Body="&lt;p&gt;One possible solution to your torque problem is to use &lt;a href=&quot;http://en.wikipedia.org/wiki/Mechanical_advantage&quot; rel=&quot;nofollow&quot;&gt;mechanical advantage&lt;/a&gt; to trade &lt;em&gt;speed&lt;/em&gt; for &lt;em&gt;torque&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you replace a 1:2 gear/drive belt combination with a 1:1 gear/drive belt combination then you will get twice the torque at half the speed. Swap the gears and you can use the same drive belt to get a 2:1 ratio instead and get even more torque for even less speed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Of course you will have to re-tune your motors, the PID control parameters will be completely different with the new gearing.&lt;/p&gt;&#xA;" OwnerUserId="37" LastActivityDate="2013-01-21T12:36:18.757" />
  <row Id="822" PostTypeId="2" ParentId="697" CreationDate="2013-01-22T08:22:43.647" Score="1" Body="&lt;p&gt;Maybe not a full robotics simulator but we are using 3D CAD, Autodesk Inventor, quite a lot for simulations. Usually we make an interface to the CAD similar to what we want it to be for the hardware. That way we can use the CAD model as a virtual prototype to:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Catch design errors early. Collisions, not enough stroke etc.&lt;/li&gt;&#xA;&lt;li&gt;It has also been useful for finding compensations to errors such as alignment errors. Using the CAD we can model different errors one by one and test our compensations. It is convenient to be able to introduce large errors with known sign.&lt;/li&gt;&#xA;&lt;li&gt;The CAD also gives answers about things such moments of inertia.&lt;/li&gt;&#xA;&lt;li&gt;We also use the CAD model to generate the program for the equipment.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="786" LastEditorUserId="786" LastEditDate="2013-01-22T13:04:25.930" LastActivityDate="2013-01-22T13:04:25.930" CommentCount="3" />
  <row Id="823" PostTypeId="2" ParentId="436" CreationDate="2013-01-22T08:45:23.490" Score="0" Body="&lt;p&gt;For modeling the kinematics &lt;a href=&quot;http://en.wikipedia.org/wiki/Denavit%E2%80%93Hartenberg_parameters&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;Denavit–Hartenberg parameters&lt;/code&gt;&lt;/a&gt; are commonly used.&#xA;the course Introduction to Robotics provided by Stanford University is available on &lt;a href=&quot;http://www.youtube.com/view_play_list?p=65CC0384A1798ADF&quot; rel=&quot;nofollow&quot;&gt;YouTube&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="786" LastActivityDate="2013-01-22T08:45:23.490" />
  <row Id="824" PostTypeId="2" ParentId="758" CreationDate="2013-01-22T14:53:15.660" Score="1" Body="&lt;p&gt;One of the primary facets of ADD/ADHD/Spectrum is awareness, that is, not missing small details. The phenomenon of the Uncanny Valley is probably more prevalent for these people. However, as also noted, many people sufficiently afflicted with ASD may not consciously recognize the signals they're getting.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would advise making a conscious effort to stay on the non-human-cute side of the Uncanny Valley, because this is some of the most shaky ground.&lt;/p&gt;&#xA;" OwnerUserId="31" LastActivityDate="2013-01-22T14:53:15.660" />
  <row Id="825" PostTypeId="2" ParentId="790" CreationDate="2013-01-22T15:22:48.500" Score="5" Body="&lt;p&gt;In general, toy robots probably face fewer challenges, except in human safety. I'd imagine that they don't usually advance the knowledge base themselves.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;HOWEVER, I think it's beyond question that our crop of engineers and scientists will be larger and more competent if they're exposed early and often to technologies and sciences such as, in this example, robotics. The tinkering culture is known to facilitate and produce innovators more than who has memorized the most mathematical formulae or protein folding shortcuts.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The FIRST Robotics Competition also doesn't &quot;move technology forwards&quot;, but I dare people to claim that it isn't important for our overall success of our technology sector. There's little technological advancement in playing with Lego, but the creativity and persistence in problem solving that gets reinforced by playing with Lego is absolutely essential.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So to answer your question: his statement is mostly true, in that things like what they're selling are sparks for the engine, but that particular company isn't directly pushing technology forward.&lt;/p&gt;&#xA;" OwnerUserId="31" LastActivityDate="2013-01-22T15:22:48.500" />
  <row Id="826" PostTypeId="1" CreationDate="2013-01-22T16:20:51.657" Score="8" ViewCount="248" Body="&lt;p&gt;I'm working with a lifesize (~130cm) humanoid robot (Hubo+) and looking for a way to easily program new motions and gestures into him. Obviously, I could write my own tool, but I am looking for a solution that can leverage existing tools or standards for robot motion. My first thought was trying to use animation software like Blender or Maya, and writing a script to extract the joint angles at keyframes. However, few robotics researchers are probably proficient with Maya. (I know I'm not!)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there already some kind of 3D posing tool for robotics that is a standard? The only things I have seen so far that comes close is the &lt;a href=&quot;http://support.robotis.com/en/software/roboplus/roboplus_motion/motionedit/poseedit/roboplus_motion_poseutility.htm&quot; rel=&quot;nofollow&quot;&gt;Pose Utility&lt;/a&gt; in RoboPlus and &lt;a href=&quot;http://web.eecs.utk.edu/~parker/Courses/CS494-529-fall11/NAOs/creatingmovement.html&quot; rel=&quot;nofollow&quot;&gt;Choregraphe&lt;/a&gt; for the Nao, but both programs seem limited to particular robots and don't appear to be extendable to Hubo.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So my questions are:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;em&gt;Are there standard file formats for robot motion?&lt;/em&gt; Not 2D wheeled robot motion. Arm and leg motion! Something equivalent to the .bvh file format used in motion capture.&lt;/li&gt;&#xA;&lt;li&gt;&lt;em&gt;Do you know of any WYSIWYGish tool for creating robot motion using keyframes and inverse kinematics?&lt;/em&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="788" LastEditorUserId="350" LastEditDate="2013-03-24T17:21:57.317" LastActivityDate="2013-04-27T21:11:22.223" Title="Can I use digital animation software to define the movements of humanoid robots?" Tags="&lt;software&gt;&lt;motion&gt;" AnswerCount="2" CommentCount="7" FavoriteCount="4" />
  <row Id="827" PostTypeId="2" ParentId="697" CreationDate="2013-01-23T02:41:19.260" Score="1" Body="&lt;p&gt;You might want to check out &quot;&lt;strong&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/MindRover&quot; rel=&quot;nofollow&quot;&gt;MindRover&lt;/a&gt;&lt;/strong&gt;&quot;.  It's old and harder to find now since the original website is defunct, but can still be found on &lt;a href=&quot;http://www.ebay.com/mindrover&quot; rel=&quot;nofollow&quot;&gt;Ebay&lt;/a&gt; or &lt;a href=&quot;http://www.amazon.com/s/url=search-alias=aps&amp;amp;field-keywords=mindrover&quot; rel=&quot;nofollow&quot;&gt;Amazon&lt;/a&gt;.  Although game/mission oriented, it involved picking from a palette of robot components, putting them on a chassis, and then wiring them together.  It was really well done for a game and could be used to explore simple to semi-advanced concepts. Some screenshots here: &lt;a href=&quot;http://images.google.com/images?q=mindrover&quot; rel=&quot;nofollow&quot;&gt;http://images.google.com/images?q=mindrover&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are looking for something a bit more serious with real world capabilities, you might want to check out &lt;strong&gt;&lt;a href=&quot;http://www.dsprobotics.com/academic.html&quot; rel=&quot;nofollow&quot;&gt;FlowStone for Education&lt;/a&gt;&lt;/strong&gt;. I have not used it, but I believe it is a visual programming environment ideally suited for robotics type work.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Last, although not software or simulation, I recently came across a &lt;a href=&quot;http://www.reddit.com/r/compsci/comments/16ov26/invited_to_talk_to_a_3rd_grade/c7xz4pg&quot; rel=&quot;nofollow&quot;&gt;comment on reddit by phblj&lt;/a&gt; regarding a &lt;strong&gt;technique for introducing programming&lt;/strong&gt;, and I thought it was really good (and especially adaptable to robotics programming). Quote:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Great example of computers I did with kids: One kid got to be the&#xA;  &quot;program&quot; and gave instructions on how to make a peanut-butter and&#xA;  jelly sandwich, but they couldn't watch my actions. I was the&#xA;  computer, and followed the instructions exactly. Hilarity resulted.&#xA;  (Not taking lid off peanut bar, not getting bread out of box I had it&#xA;  in). After a minute, another kid came up and tried. They got a little&#xA;  further, but still floundered. &quot;Put the peanut butter on the bread&quot;&#xA;  resulted in the jar sitting on the loaf, etc. It took several kids,&#xA;  but eventually we got it. If you've got an assistant, have them write&#xA;  the instructions as they're said, creating the &quot;program.&quot;&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;You can get into explanations, then, but the thing that really stuck&#xA;  was that the kids were each &quot;smarter than a computer.&quot; But that&#xA;  computers were really, really fast at following instructions. So they&#xA;  needed to use their smarts and the computers speed, and...&#xA;  programming!&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="167" LastActivityDate="2013-01-23T02:41:19.260" />
  <row Id="829" PostTypeId="1" CreationDate="2013-01-24T13:31:01.520" Score="9" ViewCount="138" Body="&lt;p&gt;I'm currently designing a robotic arm with 6-DOF, and my goal is to be able to give setpoints for 3d position, velocity and orientation ($x,y,z,\dot{x},\dot{y},\dot{z},\theta,\alpha,\gamma$).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I only had feedback-control for &lt;a href=&quot;http://en.wikipedia.org/wiki/Single-input_single-output_system&quot;&gt;SISO&lt;/a&gt; systems so far in College, so, taking the learning curve of multivariable control in consideration, should I approach this problem trying to model the system as a &lt;a href=&quot;http://en.wikipedia.org/wiki/MIMO&quot;&gt;MIMO&lt;/a&gt; or multiple SISOs?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If possible please mention possible disadvantages and advantages in each strategy.&lt;/p&gt;&#xA;" OwnerUserId="798" LastEditorUserId="350" LastEditDate="2013-01-24T16:15:13.513" LastActivityDate="2013-02-04T02:05:40.970" Title="Which is model is best for feedback control of robotic manipulators: MIMO or parallel SISO?" Tags="&lt;control&gt;&lt;manipulator&gt;&lt;robotic-arm&gt;" AnswerCount="3" FavoriteCount="1" />
  <row Id="830" PostTypeId="2" ParentId="829" CreationDate="2013-01-24T15:38:51.320" Score="3" Body="&lt;p&gt;Welcome to Robotics.SE! This is not exactly my area of expertise, but let me give you a few pointers.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A very common approach for controlling manipulators is to first design good joint velocity controllers, in the &quot;multiple SISO&quot; approach you mention. You would then use inverse kinematics to determine at each point in time what the joint velocities should be ideally to reach your desired end-effector pose.  Assuming your joint velocity control loop dynamics are fast enough, you should be able to achieve those velocities. The kinematic model of manipulators is usually obtained in terms of Denavit–Hartenberg parameters. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Considering that it is frequently done for robots and probably is enough for your purposes, I suggest you take that approach. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In a non-linear control class I took we saw a MIMO model for robot manipulators. I am not 100% sure about this, but I think you might want to use this if you are interested in modeling not only kinematics but also dynamics. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The main difference is that in this scenario the joint positions and velocities all affect the inertia matrix, Coriolis and centrifugal forces and damping in a non-linear and usually not separable fashion. So you would not only have to get used to MIMO control, but would have to look into non-linear control as well.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As I said, it's not my area of expertise so if someone thinks I said any gibberish I would be gladly corrected.&lt;/p&gt;&#xA;" OwnerUserId="95" LastActivityDate="2013-01-24T15:38:51.320" CommentCount="1" />
  <row Id="832" PostTypeId="1" AcceptedAnswerId="837" CreationDate="2013-01-25T13:51:19.353" Score="2" ViewCount="122" Body="&lt;p&gt;I have been trying to write code to connect a &lt;a href=&quot;http://www.hitechnic.com/cgi-bin/commerce.cgi?preadd=action&amp;amp;key=SPR2010&quot; rel=&quot;nofollow&quot;&gt;HiTechnic prototype board&lt;/a&gt; to my lego brick. Although I am using MSRDS studio, that isn't the issue; reading and writing to the serial port that the device is connected to works fine. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Where I am lacking is that I don't understand the data is that is being sent and received. It goes out and comes back in the form of a byte array. For example:&#xA;[128]&#xA;[15]&#xA;[0]&#xA;[2]&#xA;[16]&#xA;[2]&#xA;[8]&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is this byte array converted from hex? What is this response telling me? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Obviously I am a total newbie at this, I can program but I don't really understand electronics and I am trying to make that connection between what I have read about how an I2C controller works and what is happening when I send and receive data over a serial port. &lt;/p&gt;&#xA;" OwnerUserId="803" LastEditorUserId="350" LastEditDate="2013-01-25T16:15:57.647" LastActivityDate="2013-01-28T02:03:19.877" Title="How do I interpret this data, received by the I2C controller on an NXT 2 brick?" Tags="&lt;nxt&gt;&lt;i2c&gt;" AnswerCount="1" CommentCount="5" />
  <row Id="833" PostTypeId="2" ParentId="815" CreationDate="2013-01-25T15:21:29.047" Score="0" Body="&lt;p&gt;I've had luck using &lt;a href=&quot;https://www.sparkfun.com/products/9479&quot; rel=&quot;nofollow&quot;&gt;these&lt;/a&gt; motor driver units.  They can be speed-controlled with the PWM outputs, and motor direction can be provided with digital inputs.&lt;/p&gt;&#xA;" OwnerUserId="736" LastActivityDate="2013-01-25T15:21:29.047" />
  <row Id="834" PostTypeId="2" ParentId="697" CreationDate="2013-01-25T17:50:21.990" Score="1" Body="&lt;p&gt;&lt;a href=&quot;http://www.coppeliarobotics.com/&quot; rel=&quot;nofollow&quot;&gt;V-Rep&lt;/a&gt; (Virtual Robot Experimentation Platform) seems to be quite broad in the kinds of simulations that it can do. It is free for educational purposes and comes with a wide range of tools. You can take a look at this &lt;a href=&quot;http://www.youtube.com/watch?v=bwGYUayglHY&quot; rel=&quot;nofollow&quot;&gt;YouTube video&lt;/a&gt; for a demo.&lt;/p&gt;&#xA;" OwnerUserId="158" LastActivityDate="2013-01-25T17:50:21.990" />
  <row Id="835" PostTypeId="1" CreationDate="2013-01-26T01:50:21.100" Score="2" ViewCount="63" Body="&lt;p&gt;I want to injection-mold several thousand of a part that fits in a 6&quot; x 6&quot; x 2&quot; bed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would like to be able to use only tooling that I can make myself, so I can rapidly iterate on the tooling as production problems are discovered.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I know that typical injection-mold &quot;hard tooling&quot; is created using &lt;a href=&quot;http://en.wikipedia.org/wiki/Electrical_discharge_machining&quot; rel=&quot;nofollow&quot;&gt;electrical discharge machining&lt;/a&gt;, which requires first CNCing a carbon positive and then using that as an electrode to spark-burn out a negative mold from hard steel.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, I do not have the equipment for EDM. Instead, I would prefer to directly CNC the negative mold. I know that a soft enough steel to be CNCed will not last very long as an injection mold, but like I said, my run size is tiny, and I am ok with making a new mold every 500 units or so if necessary.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am open to buying an endmill that is diamond-tipped, to work with harder steel, but then the limitation will probably be how much torque the CNC can produce on the endmill.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What are some recommendations or links to helpful resources? In particular, what is a good CNC with enough torque, and what blend of steel should I use? Thanks!&lt;/p&gt;&#xA;" OwnerUserId="106" LastEditorUserId="106" LastEditDate="2013-01-26T02:22:33.220" LastActivityDate="2013-01-26T02:22:33.220" Title="CNCing an injection mold" Tags="&lt;cnc&gt;" AnswerCount="1" CommentCount="12" FavoriteCount="1" />
  <row Id="836" PostTypeId="2" ParentId="835" CreationDate="2013-01-26T02:18:58.500" Score="1" Body="&lt;p&gt;Answer from my MechE friend Sam who doesn't have an account:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;First, I don't think you're going to have trouble with any CNC not&#xA;  having enough torque&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Second I don't think you'll need diamond tipped. Tungsten carbide max.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;I would look into using aluminum I believe it is viable for some&#xA;  molding.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;And mild steel should definitely hold up. Easier to machine as well.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="106" LastActivityDate="2013-01-26T02:18:58.500" />
  <row Id="837" PostTypeId="2" ParentId="832" CreationDate="2013-01-26T03:34:21.520" Score="3" Body="&lt;p&gt;Your question is not clear. &quot;Is this byte array converted from hex?&quot;  If you know what the values are, you should know how you got them. 128 is not a hex number, it is the same as a hex 80, also written as 0x80.  It indicates a 'Direct command, reply not required' as a serial to NXT stream. 15 = 0x0F = LSWRITE.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It does not make sense to decode any more, as it is your program but you have not told us what you are trying to do and how you are trying to do it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Just to be clear, there is NO connection between the serial port (usb or bluetooth) and the i2c bus. But the LSWRITE/LSREAD would be the appropriate direct commands (I was wrong earlier, had to look at it some more). I would suggest starting on just the NXT using NXC or LeJOS or RobotC and getting an understanding of the I2C protocol before trying to extend that to a remote PC connection with MRDS.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Start &lt;a href=&quot;http://mindstorms.lego.com/en-us/support/files/default.aspx&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt; And download all the PDFs. They describe the command that can be sent over the PC to NXT serial link.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I2C is another step. Start with the &lt;a href=&quot;http://en.wikipedia.org/wiki/I%C2%B2C&quot; rel=&quot;nofollow&quot;&gt;Wiki&lt;/a&gt;. But you will find that LEGO vendors often do not completely implement the protocol, or they implement it incorrectly. You pretty much need to analyse each device and adjust how you treat it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/V5Wm6.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would suggest something like the &lt;a href=&quot;http://www.saleae.com/logic/&quot; rel=&quot;nofollow&quot;&gt;Saleae logic&lt;/a&gt; to analyse what is actually happening.&lt;/p&gt;&#xA;" OwnerUserId="274" LastEditorUserId="37" LastEditDate="2013-01-28T02:03:19.877" LastActivityDate="2013-01-28T02:03:19.877" CommentCount="4" />
  <row Id="838" PostTypeId="1" CreationDate="2013-01-26T08:58:44.237" Score="0" ViewCount="1073" Body="&lt;p&gt;I am working on building my own quadcopter from scratch. I noticed that many solutions available online use arduino, but I am not a fan of arduino. So my questions are: what microcontrollers should be used, what are the crucial features of those microcontrollers etc. I would like to build it from total scratch. I was thinking about PIC microcontrollers.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also what should be used for ESC, since I would build that from scratch too.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Summing it all up:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;4 ESCs&lt;/li&gt;&#xA;&lt;li&gt;Gyro,acceloremeter,gps&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;transceiver&lt;/p&gt;&#xA;&#xA;&lt;p&gt;which is about 8 slaves and one master microcontroller.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="807" LastEditorUserId="350" LastEditDate="2013-01-26T21:34:56.633" LastActivityDate="2013-01-26T22:04:37.387" Title="What microcontroller should be used for QuadCopter flight control and ESC?" Tags="&lt;microcontroller&gt;&lt;quadrotor&gt;&lt;quadcopter&gt;&lt;esc&gt;" AnswerCount="1" CommentCount="5" ClosedDate="2013-01-27T08:12:10.070" />
  <row Id="839" PostTypeId="1" AcceptedAnswerId="842" CreationDate="2013-01-26T17:51:53.783" Score="6" ViewCount="228" Body="&lt;p&gt;For avoiding obstacles during 2D robot navigation what is the best position/angle to place the sonar sensors? How many should there be?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would like to know if there is some theory or examples for the problem of placing. I realize that it depends on the way that the robot moves and its geometry, but I am searching for general answers.&lt;/p&gt;&#xA;" OwnerUserId="808" LastEditorUserId="350" LastEditDate="2013-01-26T21:37:45.010" LastActivityDate="2013-01-28T14:54:57.853" Title="Sonar for obstacle avoidance: how many sensors and where to place them?" Tags="&lt;mobile-robot&gt;&lt;sensors&gt;&lt;navigation&gt;&lt;acoustic-rangefinder&gt;" AnswerCount="2" CommentCount="1" />
  <row Id="840" PostTypeId="1" CreationDate="2013-01-26T22:03:10.763" Score="6" ViewCount="128" Body="&lt;p&gt;I am reading research papers about robotics and many of them follow the same pattern:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;some construction is established&lt;/li&gt;&#xA;&lt;li&gt;kinematical formulas are read from the mechanical structure&lt;/li&gt;&#xA;&lt;li&gt;the state space is analysed (e.g. how far the robot can reach, what the maximum speed can be, what is left underspecified and how to handle such mathematically incorrect systems and so on)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Is there some tool or software product that can receive (as input) the mechanical structure and then output the kinematical formulas?  Preferably, it would provide some kind of plots, analysis, suggestions for optimal design parameters (e.g. length, angles of the sturcture, optimum parameters of motors and so on).  Does this exist?&lt;/p&gt;&#xA;" OwnerUserId="809" LastEditorUserId="350" LastEditDate="2013-01-26T22:11:03.240" LastActivityDate="2013-03-24T11:16:50.043" Title="Is there a tool for building and analysing robots (kinematics, control) visually?" Tags="&lt;software&gt;&lt;design&gt;&lt;inverse-kinematics&gt;&lt;research&gt;&lt;kinematics&gt;" AnswerCount="2" CommentCount="0" FavoriteCount="1" />
  <row Id="841" PostTypeId="2" ParentId="838" CreationDate="2013-01-26T22:04:37.387" Score="3" Body="&lt;p&gt;You're asking about microcontrollers, but I get the sense that you're asking it for the wrong reasons.  Since you don't list a technical reason for being &quot;not a fan of arduino&quot;, I get the sense that you're trying to make a quadcopter that is different in every way from existing solution.  This decision sounds at best arbitrary and at worst misguided.  Why doesn't arduino fit your needs?  What are your needs?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If many quadcopter designs are using arduino, that's a good indication that arduino is a useful element of getting quadcopters to work.  There may be a better microcontroller to use, but how will you know what to look for until you experience firsthand a shortcoming in the arduino platform?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If your desire is to make a quadcopter from scratch, the best way to approach it is &lt;strong&gt;not&lt;/strong&gt; to conceive the design from first principles.  Take an existing design, study it, and improve it once you understand how it works.  It will take a lot of prototypes, trial, and especially error.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-01-26T22:04:37.387" />
  <row Id="842" PostTypeId="2" ParentId="839" CreationDate="2013-01-26T23:32:30.733" Score="8" Body="&lt;p&gt;Generally the main factor in positioning sensors is the actual &lt;a href=&quot;http://www.maxbotix.com/articles/008.htm&quot;&gt;beam width&lt;/a&gt; of the sensors themselves. It's usually the case that the longer range the sensor is, the narrower the beam width.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So firstly you need to work out the range you are aiming to sense at and pick some sensors that work at that range.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then you've got to decide on how wide an angle span you want to sense distance at. For instance, you may decide to cover everything in-front and to the sides of a robot (a 180 degree range, 90 degrees to either side of straight-ahead).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You then divide the angle span by the beam width of your chosen sensor to get the number of sensors you need.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Using the above example, if you have sensors with a 90 degree beam width, you'd only need two of them, each at 45 degrees either side of straight-ahead. If you had longer-range sensors with, say, a 20 degree beam width, you'd need 9 of them to cover the same area.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Obviously the beam width is not an exact measurement so its probably safer to have some overlap of the beams. Finally, the sensors should be installed symmetrically between the left and right sides of the robot.&lt;/p&gt;&#xA;" OwnerUserId="435" LastActivityDate="2013-01-26T23:32:30.733" />
  <row Id="843" PostTypeId="2" ParentId="839" CreationDate="2013-01-27T03:45:56.697" Score="6" Body="&lt;p&gt;To expand on &lt;a href=&quot;http://robotics.stackexchange.com/a/842/37&quot;&gt;thisismyrobot's answer&lt;/a&gt;, beam width is indeed important.  However, there are a number of other factors, such as the reflectivity of the environment (acoustic &quot;brightness&quot;), transmission frequency, etc.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Although it is from 1988, &lt;a href=&quot;http://www-personal.umich.edu/~ykoren/uploads/Obstacle_avoidance_w_ultrasonic_sensors_IEEE.pdf&quot; rel=&quot;nofollow&quot;&gt;Obstacle Avoidance with Ultrasonic Sensors&lt;/a&gt; covers the challenges well - the physics of echo-ranging appear to have changed little over the years :) &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The &lt;a href=&quot;http://www.generationrobots.com/ultrasonic-sonar-sensors-for-robots,us,8,19.cfm&quot; rel=&quot;nofollow&quot;&gt;Ultrasonic sonar sensors&lt;/a&gt; article on &lt;a href=&quot;http://www.generationrobots.com/boutique/index.cfm&quot; rel=&quot;nofollow&quot;&gt;Generation Robots&lt;/a&gt; introduces some of the more interesting issues in ultrasonic ranging: beam shapes and lobes (see the 50kHz figure).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From there, you should visit these more detailed articles on beam characteristics and sensor selection:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.sensorsmag.com/sensors/acoustic-ultrasound/choosing-ultrasonic-sensor-proximity-or-distance-measurement-838&quot; rel=&quot;nofollow&quot;&gt;Choosing an Ultrasonic Sensor for Proximity or             Distance Measurement Part 2: Optimizing Sensor Selection&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.ndt-ed.org/EducationResources/CommunityCollege/Ultrasonics/EquipmentTrans/beamspread.htm&quot; rel=&quot;nofollow&quot;&gt;Transducer Beam Spread&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://airmartechnology.com/uploads/AirPDF/Intro_Overview.pdf&quot; rel=&quot;nofollow&quot;&gt;Overview for Applying Ultrasonic Technology&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=1&amp;amp;cad=rja&amp;amp;sqi=2&amp;amp;ved=0CDIQFjAA&amp;amp;url=http://www.olympus-ims.com/.downloads/download/?file=285213495=en_US/&amp;amp;ei=Y6IEUZntGMWl2AX3loCgCQ&amp;amp;usg=AFQjCNE6CyPgNs60UjeUishZz5c8AbL0mA&amp;amp;sig2=APv39o2XxBbL181TI08rqw&amp;amp;bvm=bv.41524429,d.b2I&quot; rel=&quot;nofollow&quot;&gt;Important Characteristics of Sound Fields of Ultrasonic Transducers&lt;/a&gt; [pdf]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="532" LastEditorUserId="131" LastEditDate="2013-01-28T14:54:57.853" LastActivityDate="2013-01-28T14:54:57.853" CommentCount="1" />
  <row Id="844" PostTypeId="2" ParentId="840" CreationDate="2013-01-28T14:02:08.153" Score="3" Body="&lt;p&gt;&lt;a href=&quot;http://www.energid.com/actin-simulation-advantages.htm&quot; rel=&quot;nofollow&quot;&gt;The Actin toolkit&lt;/a&gt; is the only one I know of that sounds like what you want. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;It integrates with SolidWorks to provide the kind of analysis you are talking about. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Other people may know of other similar tools though.&lt;/p&gt;&#xA;" OwnerUserId="479" LastActivityDate="2013-01-28T14:02:08.153" CommentCount="1" />
  <row Id="845" PostTypeId="1" CreationDate="2013-01-28T15:19:54.600" Score="4" ViewCount="118" Body="&lt;p&gt;Using a depth sensing camera like Kinect, I would like to retrieve the position of an predetermined object (e.g. a cup, fork etc so that I would ultimately be able to grab the object). What would be a way to achieve this?&lt;/p&gt;&#xA;" OwnerUserId="721" LastEditorUserId="721" LastEditDate="2013-01-29T00:47:07.740" LastActivityDate="2013-02-17T07:58:15.883" Title="How to Identify Objects in Space" Tags="&lt;computer-vision&gt;&lt;algorithm&gt;" AnswerCount="2" CommentCount="2" />
  <row Id="847" PostTypeId="2" ParentId="845" CreationDate="2013-01-29T08:11:07.520" Score="2" Body="&lt;p&gt;If you want to recognise a predetermined object (so one that you have seen before) in a 3d scene. It seems this would work similar to the 2d case: using features. Only in this case using &lt;a href=&quot;http://pointclouds.org/documentation/tutorials/how_features_work.php#how-3d-features-work&quot; rel=&quot;nofollow&quot;&gt;3d feature&lt;/a&gt; extractors/descriptors. You provide your model (so the object that you have seen before), and find salient features in the model. In your new scene you also perform feature extraction and then compare the features with your model. If they match well enough, you have found your object. Have a look at the &lt;a href=&quot;http://pointclouds.org/documentation/tutorials/correspondence_grouping.php#correspondence-grouping&quot; rel=&quot;nofollow&quot;&gt;pcl tutorials&lt;/a&gt; on the subject.&lt;/p&gt;&#xA;" OwnerUserId="127" LastActivityDate="2013-01-29T08:11:07.520" />
  <row Id="848" PostTypeId="1" AcceptedAnswerId="849" CreationDate="2013-01-29T14:06:09.987" Score="0" ViewCount="157" Body="&lt;p&gt;I am learning about I2C on the Arduino. I was looking at a sample program to scan for I2C devices and saw this:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;// This sketch tests the standard 7-bit addresses&#xA;// from 0 to 127. Devices with higher bit address&#xA;// might not be seen properly.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;With the following code. &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;    for(address = 0; address &amp;lt;= 127; address++ ) &#xA;      {&#xA;        // The i2c_scanner uses the return value of&#xA;        // the Write.endTransmisstion to see if&#xA;        // a device did acknowledge to the address.&#xA;        Wire.beginTransmission(address);&#xA;        error = Wire.endTransmission();&#xA;&#xA;        if (error == 0)&#xA;        {&#xA;          Serial.print(&quot;I2C device found at address 0x&quot;);&#xA;          if (address&amp;lt;16) &#xA;            Serial.print(&quot;0&quot;);&#xA;          Serial.print(address,HEX);&#xA;          Serial.println(&quot; !&quot;);&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;As far as I understand it, a bit is just 1.  So, why how do 7 bits loop from 0 - 127? &lt;/p&gt;&#xA;" OwnerUserId="803" LastEditorUserId="350" LastEditDate="2013-01-29T14:50:42.363" LastActivityDate="2013-02-26T15:27:58.857" Title="Why must I loop 127 times for a &quot;7-bit&quot; address in this example?" Tags="&lt;arduino&gt;&lt;i2c&gt;" AnswerCount="4" CommentCount="1" />
  <row Id="849" PostTypeId="2" ParentId="848" CreationDate="2013-01-29T14:15:50.473" Score="9" Body="&lt;p&gt;If I understood your question correctly, you have a problem understanding binary numbers, right?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Think of a decimal digit. A digit is only either of 0, 1, 2, 3, 4, 5, 6, 7, 8 or 9, right? But a 7-digit number can be between 0000000 and 9999999. I presume you do understand this.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now a decimal number, for example 2569 is actually a short form of writing like this (again in base 10 (i.e. decimal)):&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;9 * 10^0   +   6 * 10^1   +   5 * 10^2   +   2 * 10^3&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;If you have a number in another base, for example 1423 in base 5, then that is equivalent to writing the following (in base 10):&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;3 * 5^0   +   2 * 5^1   +   4 * 5^2   +   1 * 5^3&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Which is basically the same, except all the &lt;code&gt;10&lt;/code&gt;s are changed for &lt;code&gt;5&lt;/code&gt;. That is, in the expanded form, each digit is multiplied by &lt;code&gt;b^p&lt;/code&gt; where &lt;code&gt;b&lt;/code&gt; is the base and &lt;code&gt;p&lt;/code&gt; is its position in the number.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now you know that in base 10, you have digits from 0 to 9. Similarly, in base 5, you have digits from 0 to 4. In base 2, you have digits from 0 to 1, which in other words is just 0 and 1.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So if you have a binary number like 1101, its expanded form is (in base 10):&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;1 * 2^0   +   0 * 2^1   +   1 * 2^2   +   1 * 2^3   = 13&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;If you have a 7 digit number in binary, which we normally call a 7-bit number, you can represent all numbers from 0000000 to 1111111. The first number corresponds to 0 and the second one corresponds to:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;1*2^0 + 1*2^1 + 1*2^2 + 1*2^3 + 1*2^4 + 1*2^5 + 1*2^6&#xA;= 1 + 2 + 4 + 8 + 16 + 32 + 64&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;or simply 127.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;P.S. The following loop:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;for (address = 0; address &amp;lt;= 127; address++)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;loops 128 times! ;)&lt;/p&gt;&#xA;" OwnerUserId="158" LastEditorUserId="158" LastEditDate="2013-02-26T15:27:58.857" LastActivityDate="2013-02-26T15:27:58.857" />
  <row Id="850" PostTypeId="2" ParentId="848" CreationDate="2013-01-29T14:55:20.693" Score="3" Body="&lt;p&gt;&quot;7-bit&quot; is like saying &quot;7-digit&quot;, but implies base two instead of base ten.  So, a 7-bit number can represent $2^7=128$ values in the same way that a &quot;conventional&quot; 7-digit number can represent $10^7=10000000$ values.  &lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-01-29T14:55:20.693" />
  <row Id="851" PostTypeId="1" CreationDate="2013-01-29T16:30:58.907" Score="10" ViewCount="345" Body="&lt;p&gt;I'm studying various optimal control methods (and implements them in Matlab), and as test case I choose (for now) a simple pendulum (fixed to the ground), which I want to control to the upper position.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I managed to control it using &quot;simple&quot; feedback method (swing-up based on energy control + LQR stabilization for the upper position), and the state trajectory is show in figure (I forgot the axis description: x is theta, y is theta dot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/rZAcD.png&quot; alt=&quot;Swing-up + LQR control state trajectory&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now I want to try a &quot;full&quot; optimal control method, starting with an iterative LQR method (which I found implemented here &lt;a href=&quot;http://homes.cs.washington.edu/~todorov/software/ilqg_det.m&quot;&gt;http://homes.cs.washington.edu/~todorov/software/ilqg_det.m&lt;/a&gt;)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The method requires one dynamic function and one cost function (&lt;code&gt;x = [theta; theta_dot], u&lt;/code&gt; is the motor torque (one motor only)):&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;function [xdot, xdot_x, xdot_u] = ilqr_fnDyn(x, u)&#xA;    xdot = [x(2);&#xA;        -g/l * sin(x(1)) - d/(m*l^2)* x(2) + 1/(m*l^2) * u];&#xA;    if nargout &amp;gt; 1&#xA;        xdot_x = [ 0, 1;&#xA;            -g/l*cos(x(1)), -d/(m*l^2)];&#xA;        xdot_u = [0; 1/(m*l^2)];&#xA;    end&#xA;end&#xA;&#xA;function [l, l_x, l_xx, l_u, l_uu, l_ux] = ilqr_fnCost(x, u, t)&#xA;    %trying J = x_f' Qf x_f + int(dt*[ u^2 ])&#xA;    Qf = 10000000 * eye(2);&#xA;    R = 1;&#xA;    wt = 1;&#xA;    x_diff = [wrapToPi(x(1) - reference(1)); x(2)-reference(2)];&#xA;&#xA;    if isnan(t)&#xA;        l = x_diff'* Qf * x_diff;&#xA;    else&#xA;        l = u'*R*u;&#xA;    end&#xA;&#xA;    if nargout &amp;gt; 1&#xA;        l_x = zeros(2,1);&#xA;        l_xx = zeros(2,2);&#xA;        l_u = 2*R*u;&#xA;        l_uu = 2 * R;&#xA;        l_ux = zeros(1,2);&#xA;&#xA;        if isnan(t)&#xA;            l_x = Qf * x_diff;&#xA;            l_xx = Qf;&#xA;        end&#xA;    end&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Some info on the pendulum: the origin of my system is where the pendulum is fixed to the ground. The angle theta is zero in the stable position (and pi in the unstable/goal position).&#xA;&lt;code&gt;m&lt;/code&gt; is the bob mass, &lt;code&gt;l&lt;/code&gt; is the rod length, &lt;code&gt;d&lt;/code&gt; is a damping factor (for simplicity I put &lt;code&gt;m=1&lt;/code&gt;, &lt;code&gt;l=1&lt;/code&gt;, &lt;code&gt;d=0.3&lt;/code&gt;)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My cost is simple: penalize the control + the final error.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is how I call the ilqr function&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;tspan = [0 10];&#xA;dt = 0.01;&#xA;steps = floor(tspan(2)/dt);&#xA;x0 = [pi/4; 0];&#xA;umin = -3; umax = 3;&#xA;[x_, u_, L, J_opt ] = ilqg_det(@ilqr_fnDyn, @ilqr_fnCost, dt, steps, x0, 0, umin, umax);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;This is the output&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Time From 0 to 10. Initial conditions: (0.785398,0.000000). Goal: (-3.141593,0.000000)&#xA;   Length: 1.000000, mass: 1.000000, damping :0.300000&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Using Iterative LQR control&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Iterations = 5;  Cost = 88230673.8003&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;the nominal trajectory (that is the optimal trajectory the control finds) is &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/tf9gp.png&quot; alt=&quot;ILQR optimal trajectory&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The control is &quot;off&quot;... it doesn't even try to reach the goal...&#xA;What am I doing wrong? (the algorithm  from Todorov seems to work.. at least with his examples)&lt;/p&gt;&#xA;" OwnerUserId="790" LastEditorUserId="350" LastEditDate="2013-01-29T17:11:00.603" LastActivityDate="2013-06-27T04:46:14.530" Title="Optimal Control for a simple pendulum" Tags="&lt;control&gt;" AnswerCount="2" FavoriteCount="1" />
  <row Id="852" PostTypeId="2" ParentId="848" CreationDate="2013-01-29T21:25:04.467" Score="2" Body="&lt;p&gt;The comments in this example are not quite clear. &lt;a href=&quot;http://en.wikipedia.org/wiki/I%C2%B2C&quot; rel=&quot;nofollow&quot;&gt;I2C uses 7-bit or 10-bit addresses.&lt;/a&gt; This example simply walks through the address possibilities of a 7-bits only, 0-127 decimal or (0x00-0x7f hex), and tries to read the status from each one. If 'no error' is encountered, it means a valid device(slave) was found at that address. It does not look at 10-bit addresses.&lt;/p&gt;&#xA;" OwnerUserId="274" LastActivityDate="2013-01-29T21:25:04.467" />
  <row Id="853" PostTypeId="2" ParentId="815" CreationDate="2013-01-29T23:14:51.510" Score="2" Body="&lt;p&gt;For a good budget solution used 2 L298D Motor Controller IC chips. Each chip can control 2 motors. They implement an H-Bridge and so can drive motors in forward or reverse and incorperate diodes for current protection and so are safer than implementing a DIY H-Bridge with transistors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;They are simple to use and you could make your own motor board for a fraction of the cost of the motor shields.&lt;/p&gt;&#xA;" OwnerUserId="823" LastActivityDate="2013-01-29T23:14:51.510" />
  <row Id="854" PostTypeId="1" AcceptedAnswerId="860" CreationDate="2013-01-30T03:44:23.420" Score="5" ViewCount="444" Body="&lt;p&gt;I have the following chassis along with an Arduino and a motor shield. &lt;img src=&quot;http://i.stack.imgur.com/DgPKZ.jpg&quot; alt=&quot;Robot Chassis&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm in the process of developing a tracking mechanism for use with differential drive.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Normally, a photo reflector can be placed adjacent to the wheel that will reflect when each &lt;em&gt;spoke&lt;/em&gt; passes through therefore allowing code to be written that will accurately measure each wheels position.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The problem I have is that you cannot see the wheels from inside the chassis, only small holes for the driveshaft. Placing sensors on the outside would look ridiculous and a wall crash would cause havoc.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Would I be able to use a photo reflector on the gears (as shown) if I accurately placed it to count each spoke on the gear itself? I'm a bit hesitant though because even a small bump could misalign the sensor - again causing havoc.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So does any one have an idea on how to track the wheel movements?&lt;/p&gt;&#xA;" OwnerUserId="825" LastEditorUserId="825" LastEditDate="2013-01-30T03:49:38.650" LastActivityDate="2013-01-30T22:19:21.553" Title="Sensors for differential drive" Tags="&lt;arduino&gt;&lt;two-wheeled&gt;" AnswerCount="4" CommentCount="6" />
  <row Id="855" PostTypeId="2" ParentId="854" CreationDate="2013-01-30T06:37:18.780" Score="3" Body="&lt;p&gt;Are the wheels essentially hollow except for the spokes? If they were, it would seem to me like adding a small hole a little offset from the front axle (the wheel without gears) would be a good place to put a light detector. Of course that would not work too well in the dark.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Each spoke, or more properly tooth on the gear, while technically would be correct, as you indicated may be hard to accomplish due to size.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Does the non-gear wheels axle come into the chassis? Could you add an optical encoder there? Possibly by making the axle fixed to the wheel but pass through some sort of bearing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've never experimented with odometry with tracks, but I assume due to their increased slippage, you will have to deal with greater errors than plain wheels during turns. Have you considered that?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In any case, I think you are going to have to do some 'customization' to get what you want.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I could not find that chassis at Pololu. Is it an older model?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ah I see now where it has been replaced. The newer chassis has &lt;a href=&quot;http://www.pololu.com/catalog/product/1551&quot; rel=&quot;nofollow&quot;&gt;encoders&lt;/a&gt; as an option.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/KMh7D.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="274" LastActivityDate="2013-01-30T06:37:18.780" CommentCount="4" />
  <row Id="856" PostTypeId="2" ParentId="854" CreationDate="2013-01-30T07:58:22.673" Score="4" Body="&lt;p&gt;One alternative to sensing the wheel movement is to actually track the vehicle movement over ground. I know that some people have done it using &lt;a href=&quot;https://www.sparkfun.com/products/10105&quot; rel=&quot;nofollow&quot;&gt;optical mouse sensors&lt;/a&gt;. The results will depend on the type of underground you are expecting. The upside is however that you track the actual vehicle movement, which is what you are really interested in.&lt;/p&gt;&#xA;" OwnerUserId="127" LastActivityDate="2013-01-30T07:58:22.673" CommentCount="2" />
  <row Id="857" PostTypeId="1" AcceptedAnswerId="858" CreationDate="2013-01-30T16:03:51.357" Score="5" ViewCount="82" Body="&lt;p&gt;Is there a way of initializing a Kalman filter using a population of particles that belong to the same &quot;cluster&quot;? How can you determine a good estimate for the mean value (compute weighted average ?) and the covariance matrix ? Each particle is represented as $[ x , y , θ , weight]$.&lt;/p&gt;&#xA;" OwnerUserId="164" LastEditorUserId="177" LastEditDate="2013-01-30T16:43:49.780" LastActivityDate="2013-01-30T16:43:49.780" Title="Can you seed a Kalman filter with a particle filter?" Tags="&lt;localization&gt;&lt;kalman-filter&gt;&lt;particle-filter&gt;" AnswerCount="1" />
  <row Id="858" PostTypeId="2" ParentId="857" CreationDate="2013-01-30T16:43:04.477" Score="3" Body="&lt;p&gt;While this can be done it will be problematic. The issue comes from the fact that particle filters are a method for dealing with multi-modal probability distributions (PD) while Kalman filters assume your PD can be well represented with a Gaussian distribution.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I can conceive of a few methods for doing so if you really must. The most naive would be to calculate the mean and covariance of each $[x, y, \theta]$ vector. This neglects the weights and as such will be impacted by outliers (in this case particles of low weights).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It may be better to calculate the mean and covariance of each $[x, y, \theta]$ vector using the normalized weight values as the probability of the vector. This may be what you were driving at in your question.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another naive approach would be select the largest mode and calculate its mean and covariance. Doing so requires that you select which particles belong to the mode and which don't which you could do with something like &lt;a href=&quot;http://en.wikipedia.org/wiki/K-means_clustering&quot; rel=&quot;nofollow&quot;&gt;K-means&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Yet another alternative would be to use K-means to find the centers for K clusters and then calculate the mean and covariance of of these centers. I suspect this will work out pretty close to the same things as the second option I offered but not having done the math I cannot say so for certain.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-01-30T16:43:04.477" />
  <row Id="859" PostTypeId="2" ParentId="854" CreationDate="2013-01-30T20:59:38.483" Score="5" Body="&lt;p&gt;Typically, tracking the position and orientation of a vehicle is not accomplished by looking at the wheels &amp;mdash; it's done with navigation sensors.  If you were attempting to have closed-loop control (i.e. servo control) of your motors then wheel-mounted position sensors might be appropriate.  But if the goal is to support &quot;autonomous driving&quot;, then I don't think position sensors will suffice.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Put simply, any non-flat terrain or slippage of the tracks would ruin your accuracy.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Instead, I would suggest one or more of the following navigation sensors:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Compass&lt;/li&gt;&#xA;&lt;li&gt;GPS&lt;/li&gt;&#xA;&lt;li&gt;Inertial navigation system&lt;/li&gt;&#xA;&lt;li&gt;Acoustic or laser rangefinder&lt;/li&gt;&#xA;&lt;li&gt;Acoustic beacons and triangulation&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-01-30T20:59:38.483" CommentCount="2" />
  <row Id="860" PostTypeId="2" ParentId="854" CreationDate="2013-01-30T22:19:21.553" Score="5" Body="&lt;p&gt;I put together encoders for this exact chassis.  Rather than reflecting ones, I used slot ones.  I thought I could work off the hole in the white gear, but it turns out the plastic is pretty transparent to IR, so I ended up using some black electical tape (high tech, I know) to make opaque regions on the gear.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;After building two encoders, I discovered there's a similar product online: &lt;a href=&quot;http://arduino-direct.com/sunshop/index.php?l=product_detail&amp;amp;p=202&quot;&gt;LightBeam OptoInterrupter Module&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For my first robot, I’m just using a rough encoder, with 4 counts per wheel revolution.  Here's my description from &lt;a href=&quot;http://www.mcgurrin.com/robots/?tag=wheel-encoder-electronics&quot;&gt;my blog&lt;/a&gt;: &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In looking in the chassis, there’s not a lot of room. As a result, I decided I’d use a small transmissive sensor, rather than a reflective sensor.  Both have an IR emitter and an IR photo detector.  For reflective units, they both face the same direction, and the detector measure IR reflected back to the sensor.  For a transmissive or interrupt sensor, the two units are separated by a gap, and the detector picks up IR passing through the gap. So far, so good.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I ended up using Vishay transmissive optical sensors (model TCST1202) I purchased from DigiKey.  I wired them up based on the circuit posted by Aniss1001 in the “&lt;a href=&quot;http://www.arduino.cc/cgi-bin/yabb2/YaBB.pl?num=1257038219&quot;&gt;Homemade wheel encoder&lt;/a&gt;“ thread on the Arduino forum.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/ZERQr.png&quot; alt=&quot;Encoder circuit diagram - for a different encoder, but it worked fine&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I built the circuit on a prototyping breadboard for testing and got a surprise.  The circuit worked fine, but the gear is transparent to IR!  It turns out that nylon and most plastics used for inexpensive gears are pretty transparent to IR.  I first tried creating an opaque section with a black marker, but while that worked on paper, it didn’t adhere well enough to the gear.  I ended up using a piece of black tape.  Once that worked, I cut some small circuit boards down to size and built the encoders, practicing my soldering skills.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I just used hot glue to mount the encoders.  The encoder boards stick up above the chassis base, so I’m using standoffs to raise the plastic plate with the Romeo controller and other devices.  Here’s a picture of one of the encoders before mounting,, and then mounted on the chassis:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/WUt0F.jpg&quot; alt=&quot;Homemade wheel encoder&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/8Jo7F.jpg&quot; alt=&quot;Mounted encoder&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Hope this helps!&lt;/p&gt;&#xA;" OwnerUserId="58" LastActivityDate="2013-01-30T22:19:21.553" CommentCount="7" />
  <row Id="861" PostTypeId="2" ParentId="777" CreationDate="2013-01-31T06:35:34.400" Score="0" Body="&lt;p&gt;The industry standard for solving this problem is with &lt;a href=&quot;https://www.google.com/search?q=moving+faders&amp;amp;hl=en&amp;amp;tbo=u&amp;amp;tbm=isch&amp;amp;source=univ&amp;amp;sa=X&amp;amp;ei=Pg4KUfqlI-r7iwKmpYDYCQ&amp;amp;ved=0CH4QsAQ&amp;amp;biw=1710&amp;amp;bih=1145&quot; rel=&quot;nofollow&quot;&gt;moving faders&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/ktnSQ.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;They are readily available inexpensive components that do exactly what you ask for, except the being round part. &lt;/p&gt;&#xA;" OwnerUserId="274" LastActivityDate="2013-01-31T06:35:34.400" />
  <row Id="862" PostTypeId="1" CreationDate="2013-01-31T10:28:54.003" Score="0" ViewCount="148" Body="&lt;p&gt;I am using mobilesim in windows with MatlabAriainterface.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am facing problem in accessing laser.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;when i run demo.exe from Aria,it was working fine(i am using laser code from example.cpp).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;myLaserInit:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;    void myLaserInit(){&#xA;    robot-&amp;gt;addRangeDevice(sick);&#xA;    robot-&amp;gt;runAsync(true);&#xA;simpleConnector-&amp;gt;setupLaser(sick);&#xA; sick-&amp;gt;runAsync();&#xA;     // connect the laser if it was requested&#xA; if (!sick-&amp;gt;blockingConnect())&#xA; {&#xA;        ArLog::log(ArLog::Normal, &quot;Could not connect to laser... exiting&quot;);&#xA;     Aria::shutdown();&#xA; }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;}&lt;/p&gt;&#xA;&#xA;&lt;p&gt;myLaserRange :&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;    void myLaserRange(double output[]){&#xA;int numLasers=0;&#xA;int rn = 0;&#xA;double dist, angle;&#xA;//std::list&amp;lt;ArPoseWithTime *&amp;gt; *readings;&#xA;//std::list&amp;lt;ArPoseWithTime *&amp;gt;::iterator it;&#xA;robot-&amp;gt;lock();&#xA;  std::map&amp;lt;int, ArLaser*&amp;gt; *lasers = robot-&amp;gt;getLaserMap();&#xA;&#xA;  for(std::map&amp;lt;int, ArLaser*&amp;gt;::const_iterator i = lasers-&amp;gt;begin(); i != lasers-&amp;gt;end(); ++i)&#xA;  {&#xA;    int laserIndex = (*i).first;&#xA;    ArLaser* laser = (*i).second;&#xA;    if(!laser)&#xA;        continue;&#xA;    ++numLasers;&#xA;    laser-&amp;gt;lockDevice();&#xA;&#xA;    // The current readings are a set of obstacle readings (with X,Y positions as well as other attributes) that are the most recent set from teh laser.&#xA;    std::list&amp;lt;ArPoseWithTime*&amp;gt; *currentReadings = laser-&amp;gt;getCurrentBuffer(); // see ArRangeDevice interface doc&#xA;    std::list&amp;lt;ArPoseWithTime *&amp;gt;::iterator it;&#xA;&#xA;&#xA;&#xA;for (it = currentReadings-&amp;gt;begin();it != currentReadings-&amp;gt;end(); ++it)&#xA;{&#xA;  i++;    &#xA;  dist = robot-&amp;gt;findDistanceTo(*(*it));&#xA;  angle = robot-&amp;gt;findDeltaHeadingTo(*(*it));&#xA;  output[i]=dist;&#xA;&#xA;&#xA;}&#xA;printf(&quot;%d readings in current buffer\n&quot;, i);&#xA;ArLog::log(ArLog::Verbose, &#xA;       &quot;%d readings in current buffer\n&quot;, currentReadings-&amp;gt;size());&#xA;    /////////////&#xA;&#xA;&#xA;    laser-&amp;gt;unlockDevice();&#xA;&#xA;    }       &#xA;robot-&amp;gt;unlock();&#xA;ArUtil::sleep(5000);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;}&lt;/p&gt;&#xA;&#xA;&lt;p&gt;i searched for the same in net and modified laserinit and laserrange but still i am not able to initialise and get laser range.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Referred codefrom Aria:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.ing.unibs.it/~arl/docs/documentation/Aria%20documentation/Current/demo_8cpp-example.html&quot; rel=&quot;nofollow&quot;&gt;http://www.ing.unibs.it/~arl/docs/documentation/Aria%20documentation/Current/demo_8cpp-example.html&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.robotics.cau.edu/zdoc/aria/ArModes_8cpp-source.html&quot; rel=&quot;nofollow&quot;&gt;http://www.robotics.cau.edu/zdoc/aria/ArModes_8cpp-source.html&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="714" LastEditorUserId="714" LastEditDate="2013-01-31T20:43:04.120" LastActivityDate="2013-01-31T20:43:04.120" Title="Using laser in Mobile Sim with Matlab Aria interface" Tags="&lt;mobile-robot&gt;" CommentCount="2" />
  <row Id="863" PostTypeId="1" AcceptedAnswerId="864" CreationDate="2013-01-31T10:58:41.593" Score="3" ViewCount="181" Body="&lt;p&gt;I need to simulate a stream of vehicles, such as on an assembly line. Automatons are performing operations on the vehicles when they come within reach.  The automatons do not keep track of the individual vehicles, they simply collect data.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We need to choose a method of matching the data gathered by each automaton with the vehicle it belongs to.  For example, we could guess the identity of a vehicle using its timing when arriving in the operation range (sensors) of an automaton.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have to check the possible problems we will face, so I would like a little (hopefully simple) video/simulation tool that I could play with.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;vehicles could be symbolized has moving black squares&lt;/li&gt;&#xA;&lt;li&gt;automatons/sensors could be static points or circles.&lt;/li&gt;&#xA;&lt;li&gt;it should be possible to change the time interval between two vehicles, and their speed, and add some random delays.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;What kind of software should I search for, or where should I look?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Should I consider to developing it from scratch? &lt;/p&gt;&#xA;" OwnerUserId="838" LastEditorUserId="350" LastEditDate="2013-01-31T18:14:25.567" LastActivityDate="2013-02-07T18:26:33.393" Title="How do I simulate an assembly line?" Tags="&lt;simulator&gt;" AnswerCount="2" FavoriteCount="1" />
  <row Id="864" PostTypeId="2" ParentId="863" CreationDate="2013-01-31T16:45:38.830" Score="1" Body="&lt;p&gt;This is a great question and has come up a couple of times already (see &lt;a href=&quot;http://robotics.stackexchange.com/questions/712/quadruped-learning-simulator&quot;&gt;Quadruped Learning Simulator&lt;/a&gt; and See &lt;a href=&quot;http://robotics.stackexchange.com/questions/697/standalone-or-capable-of-being-robotics-simulator&quot;&gt;Standalone (or capable of being) Robotics Simulator&lt;/a&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In short, the de facto standard simulators for all things robotic are &lt;a href=&quot;http://playerstage.sourceforge.net/&quot; rel=&quot;nofollow&quot;&gt;Stage&lt;/a&gt; (for 2D) and &lt;a href=&quot;http://gazebosim.org/&quot; rel=&quot;nofollow&quot;&gt;Gazebo&lt;/a&gt; (for 3D). &lt;a href=&quot;http://www.ros.org/wiki/&quot; rel=&quot;nofollow&quot;&gt;ROS&lt;/a&gt; is another option for what you are trying to do. Not only because it is highly compatible with the aforementioned simulators but because it has it's own simple visualization tool called &lt;a href=&quot;http://www.ros.org/wiki/rviz&quot; rel=&quot;nofollow&quot;&gt;RViz&lt;/a&gt; which excels at displaying primitives as you describe.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-01-31T16:45:38.830" />
  <row Id="865" PostTypeId="1" AcceptedAnswerId="867" CreationDate="2013-02-01T00:06:46.373" Score="2" ViewCount="964" Body="&lt;p&gt;I am creating a CNC machine on a budget, using old motors out of printers/scanners/etc. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am limited to about 650mA for the whole system, so my fear is that when the cutting bit touches the material, the stepper might be moving too quickly and won't have enough torque.  This would mean it will become one rotation behind, which could really mess up a CNC project.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Detecting when the motor &quot;misses&quot; a step would allow me to readjust the motor speed until it reaches a balance between working quickly and having adequate torque.  How can I achieve this?&lt;/p&gt;&#xA;" OwnerUserId="824" LastEditorUserId="350" LastEditDate="2013-02-01T15:59:31.850" LastActivityDate="2013-05-09T18:44:10.113" Title="How to tell a stepper motor's position, or detect slippage" Tags="&lt;arduino&gt;&lt;stepper-motor&gt;&lt;current&gt;&lt;cnc&gt;" AnswerCount="2" CommentCount="6" FavoriteCount="1" />
  <row Id="866" PostTypeId="2" ParentId="254" CreationDate="2013-02-01T14:54:39.790" Score="4" Body="&lt;p&gt;In industry, there is a strong preference for low maintenance brush-less motors over relatively high maintenance brushed motors. While the former may me more expensive in terms of the motor itself and the drive electronics, the reduction in the term long cost of maintenance usually out weighs the extra capital cost.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As &lt;a href=&quot;http://robotics.stackexchange.com/a/260/37&quot;&gt;user65&lt;/a&gt; suggests, you may need sinusoidal commutation to avoid torque ripple at low speeds, depending on precisely how you design your system and how fine you need your velocity control to be.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The paper &lt;a href=&quot;http://www.magnelab.com/uploads/4c51d9ba6fe5a.pdf&quot; rel=&quot;nofollow&quot;&gt;A Comparison Study of the Commutation Methods for ...&lt;/a&gt; has some interesting information commutation methods, which might be of use.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ultimately though, I think that avoiding using encoders is a false economy.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Unlike halls, they have the distinct advantage that they &lt;em&gt;aren't tied to the motor rotation&lt;/em&gt; - i.e. they don't have to go on the motor shaft. You could place them on the load side of the gearbox, which will allow you to quantify the precise effects of the backlash in your gearbox.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This would allow you to to perform backlash compensation in software, run dual servo loops (one for position tracking with backlash compensation and another for more immediate velocity control) and generally take much more precise control of your system both at high and low speeds.&lt;/p&gt;&#xA;" OwnerUserId="37" LastEditorUserId="37" LastEditDate="2013-05-23T14:52:32.803" LastActivityDate="2013-05-23T14:52:32.803" CommentCount="5" />
  <row Id="867" PostTypeId="2" ParentId="865" CreationDate="2013-02-02T01:43:13.053" Score="3" Body="&lt;p&gt;The ONLY difference between a stepper and a servo is that a Servo monitors its position with an encoder, and may increase power if it gets behind, or reduce power if it gets ahead, or generates a 'fault' condition if it is unable to move to the proper position in a predetermined time frame.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is no difference in power requirements. Any stepper can be a servo by the addition of encoders and closed loop electronics. Any Servo can be a stepper by bypassing the closed loop.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As long as power requirements are planned, a less expensive stepper is a good choice, like moving a print head on a rail. Servo's are more appropriate when there may be some unknown power requirement, like on a CNC cutting machine.&lt;/p&gt;&#xA;" OwnerUserId="274" LastActivityDate="2013-02-02T01:43:13.053" CommentCount="4" />
  <row Id="868" PostTypeId="2" ParentId="829" CreationDate="2013-02-03T06:24:06.830" Score="1" Body="&lt;p&gt;The set of Parallel SISO controllers is a is a subset of MIMO controllers so MIMO is at least as powerful and possibly more powerful.  As for pros and cons I see no reason to use parallel SISO except that you may be more comfortable for it so it may be easier to get done.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;That said the system may be separable by actuator in which case it can pop out as being several SISO problems.  Although control systems is my area I don't work on robots so I can't say if that's the case for your problem.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another thing that is often done, as georgebrindeiro pointed out, is to break the problem into inner and outer control loops, where the inner loops allow you to ignore much of the &lt;/p&gt;&#xA;" OwnerUserId="850" LastActivityDate="2013-02-03T06:24:06.830" />
  <row Id="869" PostTypeId="1" AcceptedAnswerId="890" CreationDate="2013-02-03T21:22:36.800" Score="4" ViewCount="508" Body="&lt;p&gt;I am very new to robotic design and I need to determine what parts I will need to assemble an arm joint.  The joint will contain one timing belt pulley which a remote motor will be turning, a forearm that the pulley will be rotating and an upper-arm piece that will actually be two parallel arms that will grip the pulley on top and bottom in order to brace the pulley from off axis torque from the timing belt.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am kind of at a lost as to how to mount all of these together.  I would like to mount the forearm directly to the pulley and then the two parallel arms (comprising the upper-arm) sandwich the top of the pulley and the lower part of the forearm.  This would be attached using a turn table.  Any ideas on how a shaft would mount to these?  Or how to attach the pulley to the arms themselves?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any kind of direction or links would be greatly appreciated, I don't even know the names of the parts I would be looking for.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In this ASCII art model the dashed lines (-) are the arms.  The arm on the left is the forearm and the two arms on the right are the two parallel parts of the upper arm.  The stars are the belt and the bars (||) are the pulleys at the elbow |E| and shoulder |S|.  &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;              -----------------&#xA;              |E|***********|S|&#xA;-----------------&#xA;              -----------------&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I am thinking of mounting the pulley to the left arm directly (a bushing?) and then maybe using turntables to mount the pulley to the top arm and another turn table to mount the left arm to the bottom arm.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here is a picture of the design to help you visualize:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://imgur.com/ci9BuKL&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/qyAQ9.png&quot; alt=&quot;Double Joint Arm assembly&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="852" LastEditorUserId="852" LastEditDate="2013-02-08T14:41:10.043" LastActivityDate="2013-02-08T15:33:52.950" Title="Building Robotic arm joint" Tags="&lt;design&gt;&lt;arm&gt;&lt;joint&gt;" AnswerCount="1" CommentCount="3" FavoriteCount="0" />
  <row Id="870" PostTypeId="2" ParentId="829" CreationDate="2013-02-04T02:05:40.970" Score="0" Body="&lt;p&gt;I've never seen &lt;a href=&quot;http://en.wikipedia.org/wiki/MIMO&quot; rel=&quot;nofollow&quot;&gt;MIMO&lt;/a&gt; used in this context before, but I can see how &lt;a href=&quot;http://en.wikipedia.org/wiki/Single-input_single-output_system&quot; rel=&quot;nofollow&quot;&gt;SISO&lt;/a&gt; might apply.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Most robotic systems I've seen have been aggregation's of single axis motor controllers (your &lt;em&gt;multiple SISO&lt;/em&gt;) each of which only had a single encoder for sensing and a single motor for actuation. So each axis was &lt;em&gt;SISO&lt;/em&gt;, but the robot as a whole was &lt;em&gt;MIMO&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some systems I have worked on had significant backlash between motor/rotary encoder and load/linear encoder, so implemented a dual feedback loops, with one motor control output, but two encoders. The rotary encoder on the motor was primarily used to track velocity accurately, while the linear encoder on the load was used to compensate for backlash in the (worm) gear and provide accurate position information and tracking.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I believe that for most control systems, these traditional control methods are the most you will ever need, however there are exceptions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have only seen one system which &lt;em&gt;might&lt;/em&gt; have benefited from a truly &lt;em&gt;MIMO&lt;/em&gt; control system and that was one with similar characteristics to your own, but also needed to control the force applied by the tool-point of the robot. We &lt;em&gt;did&lt;/em&gt; implement this with a traditional &lt;em&gt;multiple SISO&lt;/em&gt; approach, but it required exceptionally careful tuning, and I'm not convinced that trying to use some form of computed torque technique would have been any easier anyway.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would suggest that you start off with a &lt;em&gt;multiple SISO&lt;/em&gt; approach and if that fails to give you the performance or characteristics you require, research into more advanced methods. At the very least you will have learn a lot more about the kinematics and dynamics of your system by that point.&lt;/p&gt;&#xA;" OwnerUserId="37" LastActivityDate="2013-02-04T02:05:40.970" />
  <row Id="872" PostTypeId="1" AcceptedAnswerId="881" CreationDate="2013-02-04T07:16:00.323" Score="7" ViewCount="260" Body="&lt;p&gt;I'm working on a basic airplane flight stabilization system, as the precursor to a full autopilot system. I'm using a salvaged Wii Motion Plus and Nunchuk to create a 6DOF IMU. The first goal is to keep the wings level, then mix in the users commands. Am I correct in saying that this would not require a gyro, just a 3 (2?) axis accelerometer, to detect pitch and roll, then adjust the ailerons and elevator to compensate?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Secondly, if we extend my design goal from &quot;keeping the wings level&quot; to &quot;flying in a straight line&quot; (obviously two different things, given wind and turbulence), does the gyro become necessary, insofar as this can be accomplished without GPS guidance?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've tried integrating over the gyro values to get roll, pitch &amp;amp; yaw from that, however (as evidenced by this question), I'm at a level in my knowledge on the topic where I'd prefer simpler mathematics in my code. Thanks for any help!&lt;/p&gt;&#xA;" OwnerUserId="176" LastActivityDate="2013-02-08T10:25:38.283" Title="Do I really need a gyro for an airplane flight stabilization system?" Tags="&lt;uav&gt;&lt;accelerometer&gt;&lt;imu&gt;&lt;gyroscope&gt;" AnswerCount="2" CommentCount="2" />
  <row Id="873" PostTypeId="1" CreationDate="2013-02-04T10:30:06.383" Score="-1" ViewCount="2281" Body="&lt;p&gt;I have a quadcopter robot that has a KINECT on it and i want to do 3D mapping with it. &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Is KINECT reliable on a moving robot (i.e., can it give me stable images and maps with this movement)?&lt;/li&gt;&#xA;&lt;li&gt;Is there an SDK for producing 3D maps from KINECT data?  Will SLAM algorithms work?&lt;/li&gt;&#xA;&lt;li&gt;Is the arduino board on the copter (ATmega 2560) powerful enough to handle this?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="853" LastEditorUserId="350" LastEditDate="2013-02-05T20:28:27.710" LastActivityDate="2013-07-16T07:22:03.817" Title="3D Mapping from a quadcopter with KINECT" Tags="&lt;arduino&gt;&lt;slam&gt;&lt;kinect&gt;&lt;quadcopter&gt;" AnswerCount="5" CommentCount="5" ClosedDate="2013-07-16T13:39:23.000" />
  <row Id="874" PostTypeId="2" ParentId="873" CreationDate="2013-02-04T16:19:24.673" Score="1" Body="&lt;p&gt;I think what you are asking is on the edge of what is doable. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;To specifically answer your questions;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You should probably use the ROS package &lt;a href=&quot;http://www.ros.org/news/2011/01/ros-3d-entries-rgbd-slam.html&quot; rel=&quot;nofollow&quot;&gt;RGBD Slam&lt;/a&gt; made for this exact process.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Yes, it uses SLAM.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;No, an arduino is probably not sufficient, or appropriate. It will take a fairly powerful PC class computer to process 3D SLAM data, and that would be independent of any Autonomous processing - so it might actually need 2 full function PCs before it flies. Plus an arduino for flight control.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Being autonomous is an open concept. You have to write software that does something. SLAM will allow you to estimate where you are, and what your environment looks like, but you have to program the instructions to do anything within that environment. There is no general purpose &quot;let's be autonomous&quot; program.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The Kinect is part of a toy. It is reliable enough for experiments, you should at no time use a Kinect in any place where there is potential danger to life or property, such as on an unrestricted 'copter'. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The 'copter' will have to either have remote processing, which would involve some fairly high bandwidth transmission equipment, or be able to lift 2 decent size computers, plus a kinect in either case.  The rule of thumb for 'copters' is 2 to 1 thrust to weight ratio, so you are looking at a fairly robust platform with eight motors (typical), costing several thousand dollars. I'm not sure a $10,000 &lt;a href=&quot;http://www.quadrocopter.com/CineStar-8-Basic-Kit-_p_414.html&quot; rel=&quot;nofollow&quot;&gt;cinestar&lt;/a&gt; would even be up to it, more and likely something custom beyond that. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Just as reference as to whether or not it is doable, I found a &lt;a href=&quot;http://diydrones.com/profiles/blogs/quadcopter-with-kinect-doing&quot; rel=&quot;nofollow&quot;&gt;video&lt;/a&gt; showing it (a year ago, and we've gotten a little better since then).&lt;/p&gt;&#xA;" OwnerUserId="274" LastEditorUserId="274" LastEditDate="2013-02-05T20:13:49.450" LastActivityDate="2013-02-05T20:13:49.450" />
  <row Id="875" PostTypeId="2" ParentId="873" CreationDate="2013-02-04T19:28:31.247" Score="3" Body="&lt;p&gt;With respect to the Arduino + Kinect, see my answer to &lt;a href=&quot;http://robotics.stackexchange.com/a/343/308&quot;&gt;Start making robots with Kinect&lt;/a&gt; (short version: not happening without something with more CPU power than a Raspberry Pi, which you then have to carry onboard with sufficient additional battery power).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The other obstacle in your case is that the specifications of the Kinect are not well-suited for any sort of aircraft. The effective range of the depth sensor is 1.2 - 3.5 meters. It won't be able to detect a wall right next to it or recognize it from a distance. Your copter would have to be able to react quickly enough to avoid obstacles in that 1.2 - 3.5 meter viewing range. Even then, it could get blindsided by something too close to ever be detected in the first place. You would have to add additional sensors for obstacle avoidance and only use the Kinect for mapping when you know it's safe to do so.&lt;/p&gt;&#xA;" OwnerUserId="308" LastActivityDate="2013-02-04T19:28:31.247" />
  <row Id="876" PostTypeId="1" AcceptedAnswerId="877" CreationDate="2013-02-02T23:41:45.237" Score="0" ViewCount="78" Body="&lt;p&gt;Before I start asking you for help let you know that I am newbie in electronic field.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;All I want to know is the principle of wheel rotation (left-right) from remote car gadget. I am not talking about changing the spin rotation of DC motor (up,down buttons from remote), I am asking about left and right movement of wheel.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I know that spin change depends on polarity of DC motor, so changing polarity changes spin, but what is the principle of changing the left and right positions of front wheels.&lt;/p&gt;&#xA;" OwnerUserId="859" OwnerDisplayName="ttokic" LastEditorUserId="308" LastEditDate="2013-02-05T07:36:33.797" LastActivityDate="2013-02-05T07:36:33.797" Title="Remote car controlling" Tags="&lt;control&gt;&lt;wheel&gt;" AnswerCount="1" CommentCount="0" />
  <row Id="877" PostTypeId="2" ParentId="876" CreationDate="2013-02-05T00:04:21.300" Score="0" Body="&lt;p&gt;A DC motor has 2 directions, &lt;code&gt;forwards&lt;/code&gt; and &lt;code&gt;backwards&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The DC motor &lt;strong&gt;does not&lt;/strong&gt; control the direction of an RC car, instead it's the &lt;strong&gt;steering mechanism&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Rather than write everything here - I have found &lt;a href=&quot;http://rc4beginners.blogspot.co.nz/p/lesson-4-steering-system_06.html&quot; rel=&quot;nofollow&quot;&gt;an article&lt;/a&gt; for you that I believe will explain the principles of car steering. Hopefully it's a good starting point for you; feel free to Google for further information that you require. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The term &lt;a href=&quot;https://www.google.com/#hl=en&amp;amp;sugexp=les;&amp;amp;gs_rn=2&amp;amp;gs_ri=hp&amp;amp;tok=BBu9JIbGhlO8CVJL8oOmfQ&amp;amp;cp=22&amp;amp;gs_id=6&amp;amp;xhr=t&amp;amp;q=how+car+steering+works&amp;amp;es_nrs=true&amp;amp;pf=p&amp;amp;tbo=d&amp;amp;output=search&amp;amp;sclient=psy-ab&amp;amp;oq=how+car+steering+works&amp;amp;gs_l=&amp;amp;pbx=1&amp;amp;bav=on.2,or.r_gc.r_pw.r_cp.r_qf.&amp;amp;bvm=bv.41867550,d.dGI&amp;amp;fp=6daf5ba8052c93de&amp;amp;biw=1527&amp;amp;bih=840&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;how car steering works&lt;/code&gt;&lt;/a&gt; returns &lt;strong&gt;a lot&lt;/strong&gt; of results. Good luck!&lt;/p&gt;&#xA;" OwnerUserId="825" LastEditorUserId="350" LastEditDate="2013-02-05T04:29:30.057" LastActivityDate="2013-02-05T04:29:30.057" CommentCount="1" />
  <row Id="878" PostTypeId="1" AcceptedAnswerId="931" CreationDate="2013-02-05T06:36:50.580" Score="1" ViewCount="74" Body="&lt;p&gt;I have 3D printers at my school, but unfortunately they are not super high quality. I want to try 3D printing a model I made on google sketchup, but I would like for it to be fairly accurate.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What measures can I take to prevent error in the model? I understand that I need to export the file as an STL; is there anything I can do to the model before hand to ensure accuracy? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What can I do to calibrate a 3D printer for best results?  &lt;/p&gt;&#xA;" OwnerUserId="216" LastEditorUserId="350" LastEditDate="2013-02-05T18:47:27.370" LastActivityDate="2013-02-16T17:05:20.170" Title="Accurate 3D Printing W/Sketchup" Tags="&lt;3d-printing&gt;" AnswerCount="1" CommentCount="4" />
  <row Id="879" PostTypeId="2" ParentId="872" CreationDate="2013-02-05T12:53:26.347" Score="5" Body="&lt;p&gt;As the name of the accelerometer implies, you measure the acceleration on your system excluding that from the gravitational force. When your sensor is at rest, you measure the acceleration from the force that you use to counteract the gravitational force. This is how you can fix your orientation vs the gravity vector. When the sensor is accelerated, as would be the case when other external forces (like e.g. wind) are applied it gets mixed with the forces counteracting the gravity, and you can not uniquely identify the gravity vector anymore. When averaged over time you can smooth out the dynamic acceleration components, and this is for example what is used in an AHRS to compensate the gyro drift. For short term estimation - which is what you are asking for - an accelerometer is not likely to provide you the information that you need to keep your craft stable, and you need some other method to estimate your orientation (e.g. gyros, horizon sensor, etc...). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Effectively you can not differentiate between a level craft which is accelerated by a wind gust and a craft which is tilted, but otherwise not accelerated.&lt;/p&gt;&#xA;" OwnerUserId="127" LastActivityDate="2013-02-05T12:53:26.347" CommentCount="1" />
  <row Id="880" PostTypeId="2" ParentId="873" CreationDate="2013-02-05T18:52:39.920" Score="1" Body="&lt;p&gt;This is absolutely not feasible. The Arduino cannot handle the data rate from the Kinect. It &lt;em&gt;requires&lt;/em&gt; usb 2.0 (full speed) and a lot of power (full USB bus x2). Arduino would be swamped, especially given that the Kinect &lt;em&gt;requires a dedicated and optimized library&lt;/em&gt; to interface. Such a library does not exist for the Arduino. The Kinect is not an appropriate sensor for controlling a copter, due to limited range, high power requirements, high weight, and huge processing requirements.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Yes, you will have to use SLAM algorithms, of course. What you describe is exactly the job SLAM addresses.&lt;/p&gt;&#xA;" OwnerUserId="163" LastActivityDate="2013-02-05T18:52:39.920" />
  <row Id="881" PostTypeId="2" ParentId="872" CreationDate="2013-02-05T23:47:28.003" Score="5" Body="&lt;blockquote&gt;&#xA;  &lt;p&gt;Am I correct in saying that this would not require a gyro, just a 3 (2?) axis accelerometer, to detect pitch and roll, then adjust the ailerons and elevator to compensate?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;No. The opposite is true. The accelerometer will be almost useless to detect rotations on a platform that's experiencing unknown accelerations. Your plane will be subject to two force vectors: gravity and lift+drag. Lift+drag will vary hugely as a function of the plane's pitch.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But here's a more general way you can know this is impossible, and you can use this method in many other cases than just IMUs. A sensor, or set of sensors gives you N values. You can't interpret this into a space with more than N dimensions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A trivial example: You want a sensor to measure someone's position within a room. Would a single ultrasonic range finder be sufficient? No. A position in a room requires two values, (X, Y) coordinates. But an ultrasonic sensor gives you only one value, a length. There is no way to set up this sensor to solve your problem. But if you had two sensors, then it might be possible.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now let's look at the plane. A non-accelerating plane is subject to one force only, gravity. The direction of gravity relative to the plane is a 3D vector, but luckily (if you're on Earth) you know its magnitude. That's 1 value, leaving 2 unknowns, so you could theoretically get away with a 2-axis accelerometer to make up those 2 unknowns and calculate the vector of gravity.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;What about a plane in flight. Gravity and lift+drag are both 3D vectors, giving you 6 numbers. OK you know the magnitude of gravity, so 5 numbers. You'll need some kind of sensor that gives you at least 5 values. Therefore a 3-axis accelerometer cannot be enough.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;While neither a 3-axis gyro nor a 3-axis accelerometer will be enough on their own, the gyro would be much more useful. This is because it's directly measuring rotations, which is the very thing you're trying to control. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Likewise, the accelerometer will be more useful for detecting and correcting deviations from travel in a straight line.&lt;/p&gt;&#xA;" OwnerUserId="40" LastEditorUserId="40" LastEditDate="2013-02-08T10:25:38.283" LastActivityDate="2013-02-08T10:25:38.283" />
  <row Id="882" PostTypeId="1" CreationDate="2013-02-06T01:32:03.003" Score="1" ViewCount="33" Body="&lt;p&gt;I recently start a project to measure the force on a bathroom grab bar. The force/load is applied by the person who need to the grab bar for assistant. What I want to measure is the load against the wall and do the the real-time monitoring of the load for further analysis to improve the design.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am not quite sure about what kind of sensor would be suitable to do the measurement. I am looking at different load cells but cannot get the idea how to mount commercial load cells to do the measurement. What I am trying right now is using strain gauge to measure the strain near the end of the bar(wall side) and roughly calculate the load. I think (might be wrong) there may exists some kind of force/load sensors that can clamp on the bar to do the measurement.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any sensor types/models or suggestion are welcome.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I also posted this question to EE forum&#xA;&lt;a href=&quot;http://electronics.stackexchange.com/questions/57197/how-to-measure-force-that-applied-on-grab-bar&quot;&gt;http://electronics.stackexchange.com/questions/57197/how-to-measure-force-that-applied-on-grab-bar&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="861" LastEditorUserId="861" LastEditDate="2013-02-07T05:40:41.967" LastActivityDate="2013-02-07T05:40:41.967" Title="Force measurement on grab bars" Tags="&lt;sensors&gt;&lt;force&gt;" CommentCount="3" FavoriteCount="0" ClosedDate="2013-02-08T15:57:28.377" />
  <row Id="883" PostTypeId="1" AcceptedAnswerId="902" CreationDate="2013-02-06T10:36:06.213" Score="4" ViewCount="117" Body="&lt;p&gt;I have been experimenting with different fitness functions for my &lt;a href=&quot;http://www.cyberbotics.com/overview&quot; rel=&quot;nofollow&quot;&gt;Webots robot simulation&lt;/a&gt; (in short: I'm using genetic algorithm to evolve interesting behaviour).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The idea I have now is to reward/punish Aibo based on its speed of movement. The movement is performed by setting new joint position, and currently it results in jerky random movements. I have been looking at the nodes available in Webots, but apart from GPS node (which is not available in Aibo) I couldn't find anything relevant.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What I want to achieve is to measure the distance from previous location to current location after each movement.  How can I do this?&lt;/p&gt;&#xA;" OwnerUserId="863" LastEditorUserId="37" LastEditDate="2013-02-06T14:23:57.547" LastActivityDate="2013-02-10T21:27:56.637" Title="Measuring speed of movement in Webots" Tags="&lt;mobile-robot&gt;&lt;reinforcement-learning&gt;&lt;simulator&gt;" AnswerCount="2" />
  <row Id="884" PostTypeId="1" CreationDate="2013-02-06T22:51:06.027" Score="2" ViewCount="126" Body="&lt;p&gt;Is there a Matlab toolbox available to use &lt;a href=&quot;http://www.sick.com/us/en-us/home/products/product_portfolio/laser_measurement_systems/Pages/indoor_laser_measurement_technology.aspx&quot; rel=&quot;nofollow&quot;&gt;Sick lasers&lt;/a&gt; in Windows?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I found &lt;a href=&quot;http://sourceforge.net/projects/sicktoolbox/&quot; rel=&quot;nofollow&quot;&gt;one toolbox for Matlab in GNU/Linux&lt;/a&gt;.  Is there another way to use Sick laser via Matlab in Windows?&lt;/p&gt;&#xA;" OwnerUserId="714" LastEditorUserId="350" LastEditDate="2013-02-07T17:27:29.147" LastActivityDate="2013-07-11T17:30:11.980" Title="Using a Sick laser with Matlab in Windows" Tags="&lt;mobile-robot&gt;&lt;localization&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="885" PostTypeId="1" AcceptedAnswerId="888" CreationDate="2013-02-07T03:57:22.483" Score="1" ViewCount="81" Body="&lt;p&gt;Does anyone know if this is possible? It's just an i2c device right? I mean you would have to cut the cable and make it so you could plug into the pins on the Arduino but you should just be able to use the wire library and say something like. &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;Wire.beginTransmission(0x10);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;the NXT hardware developers kit tells you what pins are which &lt;a href=&quot;http://mindstorms.lego.com/en-us/support/files/default.aspx&quot; rel=&quot;nofollow&quot;&gt;http://mindstorms.lego.com/en-us/support/files/default.aspx&lt;/a&gt; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT. Turns out this is very possible. The main problem was that HiTechnic says the address is 0x10 and it is actually 0x08 but here is a short sketch that reads and prints some into about the device, i.e. the manufacturer and version. &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#include &amp;lt;Wire.h&amp;gt;&#xA;&#xA;#define ADDRESS 0x08&#xA;&#xA;void setup()&#xA;{&#xA;  Wire.begin();&#xA;  Serial.begin(9600);&#xA;}&#xA;&#xA;void loop()&#xA;{&#xA;  readCharData(0, 7);&#xA;  Serial.println();    &#xA;  readCharData(8, 8);&#xA;  Serial.println();&#xA;  readCharData(16, 8);&#xA;  Serial.println();&#xA;&#xA;  Serial.println(&quot;-----------------------------&quot;);&#xA;&#xA;  delay(1000);&#xA;}&#xA;&#xA;void readCharData(int startAddress, int bytesToRead)&#xA;{&#xA;  Wire.beginTransmission(ADDRESS);&#xA;  Wire.write(startAddress);&#xA;  Wire.endTransmission();&#xA;&#xA;  Wire.requestFrom(ADDRESS, bytesToRead);&#xA;&#xA;  while(Wire.available()) &#xA;  {&#xA;     char c = Wire.read();&#xA;     Serial.print(c);  &#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="803" LastEditorUserId="803" LastEditDate="2013-02-08T00:06:45.397" LastActivityDate="2013-02-08T00:06:45.397" Title="Would is be possible to connect a HiTechnic prototype board to an Arduino?" Tags="&lt;arduino&gt;" AnswerCount="2" CommentCount="1" />
  <row Id="886" PostTypeId="2" ParentId="885" CreationDate="2013-02-07T04:33:53.147" Score="1" Body="&lt;p&gt;According to the HiTechnic page for the prototype board it communicates with the NXT brick. As such it is possible for the Arduino to communicate with it. The one caveat would be whether they have correctly implement I2C. If they haven't then you likely could still use it but it would take additional work.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-02-07T04:33:53.147" CommentCount="1" />
  <row Id="887" PostTypeId="2" ParentId="883" CreationDate="2013-02-07T14:39:37.840" Score="0" Body="&lt;p&gt;I went to the source (Cyberbotics) and got these 2 solutions:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Aibo has no GPS. And it's not straight forward to add it, because its node hierachy is hidden behind the prototype mechanism. The definition of the Aibo if however open-source:&#xA;$WEBOTS/resources/projects/robots/aibo/protos/Aibo_ERS7.proto&#xA;GPS can be added to the project (into the protos path) and modified as we wish.&#xA;Adding GPS is as simple as adding a GPS node inside the direct children of the Robot node.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;A supervisor allows to query the scene tree. This includes getting the position of the Aibo.&#xA;This solution is clearer. The following example shows a supervisor retrieving information from the scene tree:&#xA;$WEBOTS/projects/samples/devices/worlds/supervisor.wbt&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="863" LastActivityDate="2013-02-07T14:39:37.840" />
  <row Id="888" PostTypeId="2" ParentId="885" CreationDate="2013-02-07T14:53:46.650" Score="3" Body="&lt;p&gt;Per the schematics of the UltraSonic Sensor the P1.3/SCL is DIGIAI0 or J1.5 and P3.0/SDA is DIGIAI1 or J1.6. And the developer Kit Manual states it is I2C as per philips original standard, detailing all the memory address's of the ESC015 chip and with all the recommended interfacing circuitry. The only note that I see is that they state the I2C's SCL is 9600. Kind of slow. But all very do-able for an Arduino. check out &lt;a href=&quot;http://www.openelectrons.com/index.php?module=pagemaster&amp;amp;PAGE_user_op=view_page&amp;amp;PAGE_id=7&quot; rel=&quot;nofollow&quot;&gt;http://www.openelectrons.com/index.php?module=pagemaster&amp;amp;PAGE_user_op=view_page&amp;amp;PAGE_id=7&lt;/a&gt; as they have a shield to directly connect and libraries for the Arduino.&lt;/p&gt;&#xA;" OwnerUserId="821" LastActivityDate="2013-02-07T14:53:46.650" CommentCount="4" />
  <row Id="889" PostTypeId="2" ParentId="863" CreationDate="2013-02-07T18:26:33.393" Score="1" Body="&lt;p&gt;As a child I had a copy of a software called &quot;&lt;a href=&quot;http://www.mhj-tools.com/sps-visu/&quot; rel=&quot;nofollow&quot; title=&quot;SPS VISU&quot;&gt;SPS Visu&lt;/a&gt;&quot; where you could do such simulations. (I thought it was a game and sure ha a lot of fun with it :D) Maybe this is what you are looking for?&lt;/p&gt;&#xA;" OwnerUserId="870" LastActivityDate="2013-02-07T18:26:33.393" />
  <row Id="890" PostTypeId="2" ParentId="869" CreationDate="2013-02-08T15:33:52.950" Score="2" Body="&lt;p&gt;This looks very much like a simplification of a traditional &lt;a href=&quot;http://en.wikipedia.org/wiki/SCARA&quot; rel=&quot;nofollow&quot;&gt;SCARA&lt;/a&gt; robot design.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It is a nice simple design in which the weight bearing axes are all nicely horizontal, which means these axes behave similarly irrespective of the load weight. The only downside of this design is that the some positions can only be accessed from a left handed configuration, some can only be accessed from a right handed configuration and some can be accessed from either (which can cause problems with the higher level control).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The normal nomenclature for these joints are that the upper arm is between the shoulder axis and the elbow, so that is what I will call these joints below.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you want the elbow pulley to turn the lower arm then you need to use either a fixed shaft or drive shaft:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;With a drive shaft you bolt the pulley and the lower arm to the shaft and set the shaft in bearings on the end of the upper arms. Torque is transmitted from the belt to the lower arm through the drive shaft.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;This route is easier, since both pulley and arm are probably designed to do this.&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;With a fixed shaft you bolt the shaft rigidly between the upper arms, mount both the lower arm and the pulley on bearings, then fix the pulley to the lower arm directly.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;This design could allow the upper arm to be much more rigid, which might be a concern if you are worried about the strength of your upper arm.&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The shoulder joint has similar options, but is complicated by the fact that you not only need to transmit torque to the lower arm, but you also have to turn the upper arm too. Now you have several options:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Use the shoulder shaft as a drive shaft, fix it to both halves of the upper arm, and use the shaft rotation to drive the upper arm, then use a fixed shaft mechanism to drive the lower arm pulley (this extra joint will be freely rotating on the upper arm drive shaft).&#xA;&lt;ul&gt;&#xA;&lt;li&gt;This is probably the easiest option.&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;Use the shoulder shaft as a drive shaft, but fix it to the lower arm pulley, and use the shaft rotation to drive the lower arm, then use a fixed shaft mechanism to mount and drive the upper arm.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The problem with this option is that unless you add a fixed shaft shoulder mechanism for both halves of the upper arm, you may end up twisting the arm when you apply torque to one half but not the other, a problem which is even more likely if you opted for a drive shaft elbow mechanism.&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;Fix the shoulder shaft to the base, and use a fixed shaft mechanism to drive both upper and lower arms.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Again, this might give you a slightly stronger robot overall, but has the same problem with regard to driving both halves of the upper arm.&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;It is this extra complexity which is why a single heavier duty upper arm might be preferable to increasing the strength of the upper arm by doubling up two lighter arms which are allowed to move (slightly) independently of each other.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another alternative to remove the need to transmit the elbow torque through the shoulder axis is to mount the lower arm motor &lt;em&gt;on the upper arm&lt;/em&gt;. Thus you can treat upper and lower arms as mechanically independent systems, and your design decision for one won't have ramifications for the other.&lt;/p&gt;&#xA;" OwnerUserId="37" LastActivityDate="2013-02-08T15:33:52.950" CommentCount="2" />
  <row Id="891" PostTypeId="1" CreationDate="2013-02-08T16:57:25.997" Score="4" ViewCount="1238" Body="&lt;p&gt;I'm a programmer by trade, and an amateur aerospace nut, with some degree-level training in both fields. I'm working on a UAV project, and while the good people over at &lt;a href=&quot;http://www.diydrones.com/&quot; rel=&quot;nofollow&quot;&gt;DIY Drones&lt;/a&gt; have been very helpful, this question is a little less drone-related and a little more general robotics/electronics. Essentially, I'm looking at options for ground stations, and my current rough plan is something like this:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have a PC joystick with a broken sensor in the base, which I plan to dismantle, separate the handle from the base, insert an Arduino Nano into the (mostly hollow) handle and hook it up to all the buttons and the hat thumbstick. Then, where the hole is that used to accept the stem to the base, I fit a bracket that runs horizontally to hold a smallish touchscreen (think &lt;a href=&quot;http://cdn11.mobilemag.com/wp-content/uploads/2012/12/Razer-Fiona.jpg&quot; rel=&quot;nofollow&quot;&gt;Razer's Project Fiona tablet&lt;/a&gt; with only one stick), behind which is mounted a Raspberry Pi. The Nano talks to the RPi over USB as a HID input. The RPi will be running some custom software to display telemetry and other data sent down from the UAV.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My main question whether that Nano would have enough power to run the XBee that provides the telemetry link without causing lag in the control inputs. It's worth mentioning that the UAV will be doing fly-by-wire moderation, so slight stutters won't result in wobbly flying, but serious interruptions will still be problematic - and annoying. It's also worth mentioning that this will only be used as a simplified &quot;guiding hand&quot; control; there will ALWAYS be a regular remote control available (not least because of EU flight regulations) so this is just for when I don't want to use that. If that Nano won't do, what are my options? My first thought is to get a second Nano and get that to drive the XBee (the RPi has two USB ports after all) but there may well be a better way.&lt;/p&gt;&#xA;" OwnerUserId="873" LastActivityDate="2013-02-08T20:13:20.180" Title="Arduino Nano + Raspberry Pi = UAV Ground Station?" Tags="&lt;arduino&gt;&lt;control&gt;&lt;uav&gt;&lt;raspberry-pi&gt;&lt;radio-control&gt;" AnswerCount="2" CommentCount="2" />
  <row Id="892" PostTypeId="1" AcceptedAnswerId="894" CreationDate="2013-02-08T17:27:08.697" Score="3" ViewCount="46" Body="&lt;p&gt;Is it possible to achieve arbitrary precision to the calibration of the extrinsic parameters of a camera or is there a minimum error wich can not be compensated (probably dictated by the camera's resolution)?&lt;/p&gt;&#xA;" OwnerUserId="799" LastActivityDate="2013-02-08T19:43:46.970" Title="Is it possible to achieve arbitrary precision in camera calibration?" Tags="&lt;computer-vision&gt;&lt;calibration&gt;" AnswerCount="1" />
  <row Id="893" PostTypeId="2" ParentId="891" CreationDate="2013-02-08T17:39:56.737" Score="2" Body="&lt;p&gt;The Arduino Nano should be able to interface with the XBee no problem. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If all you are using the Arduino for is forwarding a message that comes from the RPi, you might as well just use an &lt;a href=&quot;https://www.sparkfun.com/products/8687&quot; rel=&quot;nofollow&quot;&gt;XBee Explorer&lt;/a&gt; board (basically a &lt;a href=&quot;http://www.ftdichip.com/Products/ICs/FT232R.htm&quot; rel=&quot;nofollow&quot;&gt;FTDI Chip&lt;/a&gt; with a socket fit for an XBee). After configuration, all you need to do is to write to a serial port to get the XBee to send a message... All processing is done in-chip.&lt;/p&gt;&#xA;" OwnerUserId="95" LastActivityDate="2013-02-08T17:39:56.737" CommentCount="2" />
  <row Id="894" PostTypeId="2" ParentId="892" CreationDate="2013-02-08T18:21:20.710" Score="8" Body="&lt;p&gt;It is not possible to achieve &lt;em&gt;arbitrary&lt;/em&gt; precision in camera calibration, precisely because of camera resolution and camera imperfections (e.g. lens distortion, which is only approximated in the calibration of intrinsic parameters). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;That, however, isn't usually the worst part of the deal. You can go a long way if you are able to fabricate your calibration target with a decent precision. According to Trucco (p.124):&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The accuracy of calibration depends on the accuracy of the measurements of the calibration pattern; that is, its construction tolerances. To be on the safe side, the calibration pattern should be built with tolerances one or two order of magnitudes smaller than the desired accuracy of calibration. For example, if the desired accuracy of calibration is  0.1mm, the calibration pattern should be built with tolerances smaller than 0.01mm.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;A good quote for common sense, also by Trucco (p.136):&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;A practical guideline is: &lt;em&gt;the effort going into improving calibration accuracy should be commensurate to the requirements of the application&lt;/em&gt;.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;[1] E. Trucco, A. Verri. &lt;em&gt;Introductory Techniques for 3-D Computer Vision&lt;/em&gt;. Prentice Hall, 1998&lt;/p&gt;&#xA;" OwnerUserId="95" LastEditorUserId="95" LastEditDate="2013-02-08T19:43:46.970" LastActivityDate="2013-02-08T19:43:46.970" />
  <row Id="895" PostTypeId="2" ParentId="891" CreationDate="2013-02-08T20:13:20.180" Score="2" Body="&lt;p&gt;If I'm understanding your architecture (from joystick to UAV) correctly, it is this:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;${[\text{joystick}]-\text{wires}- \atop [\text{RPi}]-\text{USB HID}-}-[\text{Nano}]-\text{XBee}-[\text{UAV}]$ &lt;/p&gt;&#xA;&#xA;&lt;p&gt;You're considering laying it out like this:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$[\text{joystick}]-\text{wires}-[\text{Nano}]-\text{USB HID}-[\text{Rpi}]-\text{USB HID}-[\text{Nano}]-\text{XBee}-[\text{UAV}]$ &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The Nano should be more than powerful enough to run the XBee and the controls.  Even if it wasn't fast enough, I doubt that you could improve it by adding the latency introduced by two USB HID links and the processing onboard the RPi.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-02-08T20:13:20.180" CommentCount="1" />
  <row Id="896" PostTypeId="1" CreationDate="2013-02-09T21:53:47.387" Score="4" ViewCount="1637" Body="&lt;p&gt;I am in the process of building a stereo vision system to be used on a UGV. The system is for a robot that will be used in a competition wherein the robot is teleoperated to find relatively small colored rocks in a large outdoor field. I understand how to calibrate such a system and process the data for a stereo vision system. I do not however know how to select cameras for such a system. What are the best practices for picking cameras for a stereo vision system?&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-02-17T20:42:08.547" Title="How to select cameras for a stereo vision system?" Tags="&lt;computer-vision&gt;&lt;stereo-vision&gt;&lt;cameras&gt;" AnswerCount="4" FavoriteCount="1" />
  <row Id="897" PostTypeId="1" AcceptedAnswerId="898" CreationDate="2013-02-09T22:36:37.333" Score="4" ViewCount="1478" Body="&lt;p&gt;I'm trying to control a higher voltage motor than an arduino can source with a pin, with an arduino. I am trying to hook it up to a transistor. The battery pack is not supposed to be 4.8V, it's 6V, 4 D batteries.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here is the setup:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/m9QPz.png&quot; alt=&quot;Circuitry setup&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here is the arduino code I'm trying to run to it:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;int motorpin = 2;&#xA;&#xA;void setup()&#xA;{&#xA;    pinMode(motorpin, OUTPUT);&#xA;}&#xA;&#xA;void loop()&#xA;{&#xA;    digitalWrite(motorpin, HIGH);&#xA;    delay(500);&#xA;    digitalWrite(motorpin, LOW);&#xA;    delay(500);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Code gives me no errors, but no motor movement happens. What would make this work? Thanks.&lt;/p&gt;&#xA;" OwnerUserId="583" LastEditorUserId="583" LastEditDate="2013-02-12T01:48:15.590" LastActivityDate="2013-02-21T06:55:02.840" Title="High voltage motor control with arduino" Tags="&lt;arduino&gt;&lt;motor&gt;" AnswerCount="5" CommentCount="1" FavoriteCount="1" />
  <row Id="898" PostTypeId="2" ParentId="897" CreationDate="2013-02-10T06:37:02.613" Score="5" Body="&lt;p&gt;Your hardware configuration sounds wrong... your trying to provide all the drive current from the arduino&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Given your description, your using a bipolar (NPN or PNP) transistor, I'd wire up as:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Base: To arduino&lt;/li&gt;&#xA;&lt;li&gt;Collector: Motor -ve  (motor +ve to Vcc)&lt;/li&gt;&#xA;&lt;li&gt;Emmitter: Ground&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Alternatively:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Base: To arduino&lt;/li&gt;&#xA;&lt;li&gt;Collector: Vcc&lt;/li&gt;&#xA;&lt;li&gt;Emmitter: Motor +ve  (motor -ve to Ground)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;This way, the processor is switching the current flow between Vcc and the motor, not supplying all the power.&lt;/p&gt;&#xA;" OwnerUserId="134" LastEditorUserId="134" LastEditDate="2013-02-10T17:01:49.473" LastActivityDate="2013-02-10T17:01:49.473" CommentCount="3" />
  <row Id="899" PostTypeId="2" ParentId="896" CreationDate="2013-02-10T14:47:30.620" Score="4" Body="&lt;p&gt;You should start by calculating how many frames per second you need, and how much camera resolution you can process at that framerate.  If nothing else, that will prevent you from overspending or from buying a camera that won't suit your needs.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Beyond that, there are a variety of features that make the choice more difficult/interesting.  Different cameras (especially network cameras like Axis) allow you to alter the image quality, or to specify a max bitrate for the image stream.  Some cameras also give you choices on the shutter speed, allowing you to favor a constant exposure time or a constant average illumination in the image.  Some cameras are more sensitive than others (the last time I worked with this was in 2009, and we noticed that the PS3 Eye did really well in low light conditions).  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Probably the best thing you can do would be to run your image processing algorithms on a few static images that you take with a DSLR, then attempt to reduce the frame size and quality to see where things begin to break down.  &lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-02-10T14:47:30.620" />
  <row Id="900" PostTypeId="1" CreationDate="2013-02-10T14:54:03.493" Score="2" ViewCount="119" Body="&lt;p&gt;Given workspace constraints, load and task to be done, how do I select the best configuration of my robot? How do I select between a cartesian or Scara robot for instance? How do I select a manipulator? How do I determine how many axes that I need?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Most of what I have seen is based on experience, rules of thumb and readily available standard devices, but I would like a more formal answer to quantify my choice. Is there some technique (genetic algorithm?) which describes the task, load, workspace, budget, speed etc. and rates and selects an optimal robot configuration or maybe even multiple configurations? How can I be mathematically ensure I ultimately chose the optimal solution?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The only thing I found online was a thesis from 1999 titled &lt;a href=&quot;http://darwin2k.sourceforge.net/thesis.pdf&quot; rel=&quot;nofollow&quot;&gt;&lt;em&gt;Automated Synthesis and Optimization of Robot Configurations: An Evolutionary Approach&lt;/em&gt;&lt;/a&gt; (pdf, &lt;a href=&quot;http://scholar.google.co.uk/scholar?hl=en&amp;amp;q=CMU-RI-TR-99-43&amp;amp;btnG=&amp;amp;as_sdt=1,5&amp;amp;as_sdtp=&quot; rel=&quot;nofollow&quot;&gt;CMU-RI-TR-99-43&lt;/a&gt;). It is a synthesis and optimization tool called &lt;a href=&quot;http://darwin2k.sourceforge.net/&quot; rel=&quot;nofollow&quot;&gt;Darwin2K&lt;/a&gt; presented in a thesis written by Chris Leger at CMU. I am surprised no one has updated it or created a tool similar to it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To provide some context for my question, we are developing a robot to assist the elderly with domestic tasks. In this instance, the robot identifies and picks food items from a previously stored and known location. The hand opens the package and place it in the oven. The pick and place locations are fixed and nearby so the robot is stationary.&lt;/p&gt;&#xA;" OwnerUserId="881" LastEditorUserId="37" LastEditDate="2013-02-12T11:02:31.250" LastActivityDate="2013-02-12T11:02:31.250" Title="How do I select the best configuration for a known workspace, load and task?" Tags="&lt;design&gt;&lt;algorithm&gt;&lt;industrial-robot&gt;&lt;theory&gt;&lt;manipulator&gt;" AnswerCount="2" CommentCount="3" FavoriteCount="0" />
  <row Id="901" PostTypeId="2" ParentId="896" CreationDate="2013-02-10T15:24:52.400" Score="2" Body="&lt;p&gt;A few things you should be on the lookout for:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Global shutter&lt;/strong&gt; basically means all pixels get captured at the same time, as opposed to Rolling shutter where they are captured sequentially in a line scan fashion. Since your UGV will be moving around and performing stereo algorithms over the images you capture, it could be important that you avoid aberrations that occure when camera move, such as the ones seen in the pictures below (taken from &lt;a href=&quot;http://en.wikipedia.org/wiki/Rolling_shutter&quot; rel=&quot;nofollow&quot;&gt;Wikipedia&lt;/a&gt;):&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://i.stack.imgur.com/u8yKF.jpg&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/u8yKFm.jpg&quot; alt=&quot;Moving car taken with CMOS camera phone exhibits skew&quot;&gt;&lt;/a&gt;&#xA;&lt;a href=&quot;http://i.stack.imgur.com/EVM6g.jpg&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/EVM6gm.jpg&quot; alt=&quot;A photo exhibiting partial exposure. Lighting conditions changed between the exposure of the top and bottom parts of the photo.&quot;&gt;&lt;/a&gt;&#xA;&lt;a href=&quot;http://i.stack.imgur.com/Q6NJX.jpg&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/Q6NJXm.jpg&quot; alt=&quot;A shot of a turboprop propeller&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Camera synchronization&lt;/strong&gt; in hardware is achievable by some cameras, notably firewire cameras AFAIK. That can greatly improve the results for stereo when things are moving around.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Mounting&lt;/strong&gt; should be done in a way that changes in the extrinsic parameters (the relative pose between cameras) for the stereo pair will be unlikely to change after calibration. In your rig that might be more important, since the UGV might face uneven terrain outdoors and things will vibrate.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Dedicated stereo hardware&lt;/strong&gt; makes it possible to acquire disparity images directly as output of your stereo vision system, which eases the load off your embedded computing. It also tends to be much faster than running the very same algorithms in software.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;As usual, the more you're willing to pay the better the results. To be honest, if you're able to buy a full-blown stereo camera such as the &lt;a href=&quot;http://www.ptgrey.com/products/bumblebee2/bumblebee2_stereo_camera.asp&quot; rel=&quot;nofollow&quot;&gt;Bumblebee2&lt;/a&gt;, that's what I'd do. Otherwise, if you're on the cheaper side, I would simply go with a &lt;a href=&quot;http://www.xbox.com/en-US/kinect&quot; rel=&quot;nofollow&quot;&gt;Kinect&lt;/a&gt;: it's unlikely you'll be able to get a system that outperforms it for the same price.&lt;/p&gt;&#xA;" OwnerUserId="95" LastEditorUserId="350" LastEditDate="2013-02-13T16:27:38.650" LastActivityDate="2013-02-13T16:27:38.650" CommentCount="4" />
  <row Id="902" PostTypeId="2" ParentId="883" CreationDate="2013-02-10T21:27:56.637" Score="1" Body="&lt;p&gt;Some years ago I have used the supervisor to know the position of a simulated Khepera robot in Webots 4.&#xA;The main components of the C code was the following:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Declarations:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;  #define STEP 64&#xA;&#xA;  NodeRef robot_node;&#xA;  float robot_data[4]={0,0,0,0};&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Getting the node named Khepera:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;  robot_node=(NodeRef)supervisor_node_get_from_def(&quot;KHEPERA&quot;);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Getting data from the node in every STEP milliseconds: &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;supervisor_field_get(robot_node,SUPERVISOR_FIELD_TRANSLATION|SUPERVISOR_FIELD_ROTATION_ANGLE,&amp;amp;robot_data,STEP);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;All the above was called before the main cycle of the supervisor. The main cycle contained a &lt;code&gt;robot_step(STEP);&lt;/code&gt; call to let the system fill the elements of the robot data structure (x,y,z,head coordinates) regularly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Again it was Webots 4 may be there are better ways in Webots 7 to fulfill the task but it could be a starting point.&lt;/p&gt;&#xA;" OwnerUserId="577" LastActivityDate="2013-02-10T21:27:56.637" CommentCount="1" />
  <row Id="903" PostTypeId="2" ParentId="900" CreationDate="2013-02-11T04:58:18.347" Score="2" Body="&lt;p&gt;I'll just show why heuristics and experience are relevant in this problem by showing that is nearly impossible to solve optimally.  Note, genetic algorithms cannot necessarily always solve a problem optimally, they are just another heuristic-based search.&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Defining the manipulator&lt;/strong&gt;&#xA;Let's simplify things. According to &lt;a href=&quot;http://books.google.com/books/about/Introduction_to_Robotics.html?id=MqMeAQAAIAAJ&quot; rel=&quot;nofollow&quot;&gt;Craig 2005&lt;/a&gt;, robot manipulators can be reasonably decomposed into &lt;a href=&quot;http://en.wikipedia.org/wiki/Prismatic_joint&quot; rel=&quot;nofollow&quot;&gt;prismatic&lt;/a&gt; and &lt;a href=&quot;http://en.wikipedia.org/wiki/Revolute_joint&quot; rel=&quot;nofollow&quot;&gt;revolute&lt;/a&gt; joints. Each such joint is &lt;a href=&quot;http://en.wikipedia.org/wiki/Degrees_of_freedom_%28mechanics%29&quot; rel=&quot;nofollow&quot;&gt;one degree of freedom&lt;/a&gt; in your &lt;em&gt;input&lt;/em&gt; space. That is, a hand on the end of the robot can be specified by a vectors of length $N$, where the robot has $N$ joints of types prismatic or revolute. OK. we can now specify the manipulator position. The set of all possible configurations is called the &lt;a href=&quot;http://en.wikipedia.org/wiki/Configuration_space&quot; rel=&quot;nofollow&quot;&gt;&lt;em&gt;configuration space&lt;/em&gt;&lt;/a&gt;. Let's assume we know this completely, as you stated.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Defining the task&lt;/strong&gt;&#xA;Let's assume that the task consists of moving the manipulator through a series of stages. For example, suppose the manipulator must drill 30 holes in a sheet, then place the sheet on a pallet, or whatever. Since we have the manipulator positions as a vector of length $N$, we can specify each task as a desired position, $X_1, X_2 ... X_M$ for task length $M$. What we've just done is specified a series of points in the &lt;em&gt;configuration space&lt;/em&gt; which we defined above. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;OK break time to verify the terminology if anyone is confused. Watch this &lt;a href=&quot;https://www.youtube.com/watch?v=ciSaT0eH5cY&quot; rel=&quot;nofollow&quot;&gt;video&lt;/a&gt;. The robot has 3 degrees of freedom (each rotation point), so the configuration space is all sets of 3 real numbers (in the range 0-$2\pi$, corresponding to the 3 angles of the 3 revolute joints). The task is to cause the end-effector (the pen) to visit all points on a circle. If this isn't clear, I can clarify.&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Defining the cost&lt;/strong&gt; Now that we know the configuration space and the series of points, let's talk about cost. The cost is typically the force exerted by the joints. So suppose (a huge assumption), that we can model this directly as $f(X_1,X_2)$, a function which returns the energy to go from state $1$ to $2$. If we're lucky, the function is a &lt;a href=&quot;http://en.wikipedia.org/wiki/Metric_%28mathematics%29&quot; rel=&quot;nofollow&quot;&gt;&lt;em&gt;metric&lt;/em&gt;&lt;/a&gt;. If not, it defines &lt;a href=&quot;http://en.wikipedia.org/wiki/Complete_graph&quot; rel=&quot;nofollow&quot;&gt;a complete graph with $N\choose 2$&lt;/a&gt; links (the cost to go from any state to any other state).&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Defining the problem&lt;/strong&gt; Find the optimal ordering of manipulator states and paths between manipulator states to minimize the cost, $f(X_i,X_{i+1})$ for each sequential task $i$. This is clearly a Travelling Salesperson Problem &lt;a href=&quot;http://en.wikipedia.org/wiki/Travelling_salesman_problem&quot; rel=&quot;nofollow&quot;&gt;(See: TSP)&lt;/a&gt;. Since TSP is &lt;a href=&quot;http://en.wikipedia.org/wiki/NP-hard&quot; rel=&quot;nofollow&quot;&gt;NP-Hard&lt;/a&gt;, this problem is &lt;a href=&quot;http://en.wikipedia.org/wiki/NP-complete#Formal_definition_of_NP-completeness&quot; rel=&quot;nofollow&quot;&gt;NP-Complete&lt;/a&gt;*.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;What does the above mean? Well, for a &lt;em&gt;given&lt;/em&gt; robot design, we have arrive at an NP-Complete problem to derive the optimal task sequence: movements, manipulator positions, etc. To optimize the &lt;em&gt;robot itself&lt;/em&gt; is even more difficult. First, we have to search over all possible robot configurations (subject to what??), and for each, solve an NP-Complete problem. The best result is the robot configuration we want.  For a small-dimensional workspace (say one joint, or $N=1$), and a simple task (say a small number of possitions like $M$=3 or so) this is not too difficult. However, in general, $N$ is unbounded, and $M$ is large. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Even if there is some &lt;em&gt;ordering&lt;/em&gt; property on $N$, like a robot of 2 joints is better than a robot of 1 joints, etc, you still have to do $\log(n^\star)$ TSP solutions, where $n^\star$ is the perfect number of robot joints. Remember a TSP solution is incredibly difficult to solve optimally. This gets even worse if we want to say &quot;Well, what about two arms with two joints versus one arm with four joints.&quot;  I don't want to talk about that complexity ... It's exploding.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;So, because you can't solve it perfectly using computers, people pay big money to have an experienced engineer do it for them. Win-win?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;*well not really, but along the way we show a polynomial time reduction, so it sorta counts.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;EDIT&lt;/strong&gt; What we actually did here was describe the algorithm to select the optimal manipulator design. That should answer your first question. However, it is computationally infeasible to run on a computer, and so heuristics and other design choices are necessary, that should answer your second question.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What this means: We're also having this problem in our lab. Manipulators are very expensive, and we want one that is &lt;em&gt;just&lt;/em&gt; good enough to perform some task. What we converged to was an extremely minimal set of joints for each task, instead of one large and capable manipulator for all tasks. My advice: I would design the robot based on budget and programmability, rather than trying to make a claim about the optimal configuration.&lt;/p&gt;&#xA;" OwnerUserId="163" LastEditorUserId="163" LastEditDate="2013-02-11T17:10:39.167" LastActivityDate="2013-02-11T17:10:39.167" />
  <row Id="904" PostTypeId="2" ParentId="873" CreationDate="2013-02-11T06:09:43.257" Score="0" Body="&lt;p&gt;After reviewing the original post and the posted answers, I agree, the task is absolutely infeasible in real-time with Arduino.  Don't even bother - Arduino is off by orders of magnitude. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Have you considered strapping a larger USB stick/flash drive on board, and then simply using the copter as a &quot;sensor&quot;?  Fly the craft around, gather your 3D data, store it in flash, bring it home, and then aggregate/register/process your data offline. Very, very cool in my opinion.&lt;/p&gt;&#xA;" OwnerUserId="532" LastActivityDate="2013-02-11T06:09:43.257" CommentCount="1" />
  <row Id="905" PostTypeId="2" ParentId="897" CreationDate="2013-02-11T16:57:15.290" Score="0" Body="&lt;p&gt;I actually just ran into this and I found that my resistor going from my Arduino pin to the base was wrong. You might want to watch this video. It was very useful for me. &lt;a href=&quot;http://www.youtube.com/watch?v=DLl7-CmVT7w&quot; rel=&quot;nofollow&quot;&gt;http://www.youtube.com/watch?v=DLl7-CmVT7w&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="803" LastActivityDate="2013-02-11T16:57:15.290" />
  <row Id="906" PostTypeId="2" ParentId="900" CreationDate="2013-02-11T18:41:14.710" Score="1" Body="&lt;p&gt;The answer by &lt;a href=&quot;http://robotics.stackexchange.com/a/903/37&quot;&gt;Josh is excellent&lt;/a&gt; but here is an industrial perspective.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In my experience, industrial robot design always starts with the requirements of the load and the design decisions ripple back from there.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You need to look at the size, shape and weight of the object (or objects) to be manipulated, how fast you need to move the object and how accurate the control needs to be. Then you can marry this with details of &lt;em&gt;how&lt;/em&gt; the object is to be moved. At each stage you work out the worst case and give yourself a little &lt;em&gt;wriggle room&lt;/em&gt; in case something doesn't perform up to spec.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Although you can attempt to use &lt;em&gt;average case&lt;/em&gt; rather than &lt;em&gt;worst case&lt;/em&gt;, it is risky to do so. Just because you think that no-one will ever drive both axis A and B to it's full extent at the same time, doesn't mean that someone won't &lt;em&gt;accidentally&lt;/em&gt; try to do it, and if arm AB isn't able to carry the weight in this configuration, it could be dangerous, both to the machine and any people nearby.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are lucky, your mechanical designer has access to not only &lt;a href=&quot;http://en.wikipedia.org/wiki/Computer-aided_design&quot; rel=&quot;nofollow&quot;&gt;CAD tools&lt;/a&gt;, but also &lt;a href=&quot;http://en.wikipedia.org/wiki/Computer-aided_engineering&quot; rel=&quot;nofollow&quot;&gt;CAE tools&lt;/a&gt; such as &lt;a href=&quot;http://en.wikipedia.org/wiki/Finite_element_method&quot; rel=&quot;nofollow&quot;&gt;Finite Element Analysis&lt;/a&gt;, but many small, specialist robotics firms can't afford expensive CAE systems and rely entirely on experience, judgement and judicious &lt;a href=&quot;http://en.wikipedia.org/wiki/Overengineering&quot; rel=&quot;nofollow&quot;&gt;overengineering&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Even where a company does have access to CAE tools, they will often be used sparingly. Since it is unfeasible to simulate the whole of a complex system in one go, subsystems are instead analysed independently of each other.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ultimately as with many aesa of expertise, there is no one-size-fits-all robotics solution. Every requirement has implications on a whole bunch of desi for &lt;/p&gt;&#xA;" OwnerUserId="37" LastActivityDate="2013-02-11T18:41:14.710" CommentCount="3" />
  <row Id="907" PostTypeId="1" CreationDate="2013-02-11T23:01:55.563" Score="6" ViewCount="110" Body="&lt;p&gt;A 2d laser scanner is mounted on a rotary axis. I wish to determine the transformation matrix from the center of the axis to the center of the scanner, using only the input from the scanner and the angle of rotation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/bygWj.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The 2d scanner itself is assumed to be calibrated, it will accurately measure the position of any object inside the plane of the laser, in regards to the scanner origin.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The rotary axis is calibrated as well, it will accurately measure the angle of its own movement.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The scanner is aligned and mounted close to the center of rotation, but the exact offset is unknown, and may drift over time.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Assume it is impractical to measure the position and orientation of the scanner directly. &#xA;I am looking for a way to determine the exact values for the 6 degrees of offset the scanner may have in relation to the axis, determined solely on the 2d information from the scanner and the rotation angle from the axis.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/JtBDH.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am mainly interested in the 4 offsets depicted here, since the other two do not matter in regard to generating a consistent 3d point cloud from the input data.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;By scanning a known calibration object, it should be possible to determine these offsets. What are the mathematical formulas for this? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What sort of calibration information is required at a minimum?&#xA;Is it for example possible to determine all parameters simply by scanning a flat surface, knowing nothing about the surface except that it is flat?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(The transformation matrix from rotation axis to world is unknown as well, but that one is trivial to determine once the transformation from axis to camera is known.)&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/TQh9z.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On the left the camera is placed exactly on the rotational axis.  The camera scans a planar object with reference points A B and C. Based on the laser distance measurements and the angle of the axis, this planar object can be reconstructed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On the right, the camera has an unknown offset to the axis. It scans the same object. If the point cloud is constructed without knowing this offset, the planar surface maps to a curved surface. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can I calculate the offset based on the surface curvature?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If I know the real-world distances and angles between A, B and C, how can I calculate the camera offsets from that? What would be the minimum number of reference points I need for all 4 offsets?&lt;/p&gt;&#xA;" OwnerUserId="362" LastEditorUserId="362" LastEditDate="2013-02-18T07:53:19.880" LastActivityDate="2013-02-18T23:21:40.040" Title="Calibrate a 2d scanner mounted on a rotary axis" Tags="&lt;calibration&gt;" AnswerCount="2" />
  <row Id="908" PostTypeId="1" AcceptedAnswerId="1188" CreationDate="2013-02-11T23:41:06.083" Score="4" ViewCount="123" Body="&lt;p&gt;I've been looking into a &lt;a href=&quot;http://www.makeblock.cc/&quot; rel=&quot;nofollow&quot;&gt;Makeblock robotics kit&lt;/a&gt; but have found no information on the web that comes from end-users, and one of the main advertised features is not clear to me:  The slot threads shown below are straight, while the screw thread that will mate with them is angled.  Is there just very little contact between screw thread and rail thread vs. regular screw hole threads?  Or would the screw want to rest angled somewhat- and then the head would not be flush with the rim of the rail?  Or would the screw deform the aluminum rail if over-torqued?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is a close up picture of the slot with screws:&#xA;&lt;img src=&quot;http://www.wired.com/wiredenterprise/wp-content/uploads//2012/12/makeblock-threaded-slot.jpg&quot; alt=&quot;makeblock closeup&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="884" LastEditorUserId="884" LastEditDate="2013-10-09T15:26:16.853" LastActivityDate="2013-10-09T15:26:16.853" Title="How does the Makeblock threaded slot work?" Tags="&lt;mechanism&gt;&lt;kit&gt;" AnswerCount="1" CommentCount="2" FavoriteCount="1" />
  <row Id="909" PostTypeId="1" CreationDate="2013-02-12T02:58:36.187" Score="1" ViewCount="53" Body="&lt;p&gt;I'm looking for a GPS tracking device without screen or apps. I just need it to look for the current position of a bus and send it to a server through TCP/IP protocol. This process must be constant so I can have a real-time tracking. The bus already has a wireless access point. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What device can be useful? Do I need another piece of hardware to send the coordinates to the server? I have no experience but... can something like an arduino connected to the gps send the data?&lt;/p&gt;&#xA;" OwnerUserId="886" LastEditorUserId="37" LastEditDate="2013-02-12T21:45:23.083" LastActivityDate="2013-02-12T21:45:23.083" Title="GPS tracking device" Tags="&lt;gps&gt;" AnswerCount="1" CommentCount="2" />
  <row Id="910" PostTypeId="2" ParentId="909" CreationDate="2013-02-12T03:06:20.493" Score="2" Body="&lt;p&gt;I'm assuming you mean a passenger bus instead of a data bus. I'm also assuming you have access to a 12V output from the bus as well. If not you'll also need a battery.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Grab a Garmin GPS unit and an Arduino with Ethernet and USB. The Garmin outputs strings with the latitude and longitude over USB, which the Arduino can read in. Copy those strings to Ethernet packets and send it off via the TCP/IP connection. Easy as pie and one of the first projects I ever did with a microcontroller.  &lt;/p&gt;&#xA;" OwnerUserId="163" LastActivityDate="2013-02-12T03:06:20.493" />
  <row Id="911" PostTypeId="2" ParentId="907" CreationDate="2013-02-12T13:21:24.957" Score="1" Body="&lt;p&gt;If you can afford to have a small portion of your field of view obscured, you may want to consider having a &lt;a href=&quot;http://en.wikipedia.org/wiki/Fiduciary_marker&quot; rel=&quot;nofollow&quot;&gt;fiducial object&lt;/a&gt; somewhere in view.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;With a suitable fiducial object, scanning it as your axis rotates, you should be able to calculate the four offsets you desire.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you cannot afford to have any of your field of view obscured under normal operation, then you may need to place your fiducial on an actuator of it's own, bringing it into view when you want to calibrate and taking it out for normal operation. The only issue here is that you limit the accuracy of your calibration by the accuracy of your fiducial actuator.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note that if some part of your field of view is already obscured by another part of your robot, and it may be suitable to use as a fiducial, or at the very least as a mounting point for one.&lt;/p&gt;&#xA;" OwnerUserId="37" LastActivityDate="2013-02-12T13:21:24.957" CommentCount="2" />
  <row Id="913" PostTypeId="1" AcceptedAnswerId="914" CreationDate="2013-02-12T16:16:00.323" Score="5" ViewCount="170" Body="&lt;p&gt;I am designing a new platform for outdoor robotics and I need to calculate the power and/or torque that is needed to move the platform. I have calculated that I need about 720 W of total power to move it (360W per motor), but I don't know how to calculate the torque that I need. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is it really just about having the required power and ignoring the torque or is there a way to calculate it easily?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Already known parameters of the platform are:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Weight of the whole platform: 75 kg.&lt;/li&gt;&#xA;&lt;li&gt;Number of wheels: 4.&lt;/li&gt;&#xA;&lt;li&gt;Number of powered wheels: 4.&lt;/li&gt;&#xA;&lt;li&gt;Diameter of wheels: 30 cm.&lt;/li&gt;&#xA;&lt;li&gt;Number of motors: 2.&lt;/li&gt;&#xA;&lt;li&gt;Wanted speed: 180 RPM (3 m/s).&lt;/li&gt;&#xA;&lt;li&gt;Wanted acceleration: &gt; 0.2 m/s^2&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="890" LastEditorUserId="825" LastEditDate="2013-02-13T14:01:55.657" LastActivityDate="2013-02-13T16:16:24.567" Title="Are power and torque required related in some way?" Tags="&lt;mobile-robot&gt;&lt;design&gt;&lt;motor&gt;" AnswerCount="2" />
  <row Id="914" PostTypeId="2" ParentId="913" CreationDate="2013-02-12T17:00:14.150" Score="5" Body="&lt;p&gt;A good presentation on how to size your motors for a mobile robot is &lt;a href=&quot;http://www.scribd.com/doc/38698/Sizing-Electric-Motors-for-Mobile-Robotics&quot; rel=&quot;nofollow&quot;&gt;Sizing Electric Motors for Mobile Robotics&lt;/a&gt; from the &lt;a href=&quot;http://www.circpeoria.org/&quot; rel=&quot;nofollow&quot;&gt;Central Illinois Robotics Club&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The general procedure outlined there includes the following steps:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Step One: Determine total applied force at worst case&lt;/li&gt;&#xA;&lt;li&gt;Step Two: Calculate power requirement&lt;/li&gt;&#xA;&lt;li&gt;Step Three: Calculate torque and speed requirement&lt;/li&gt;&#xA;&lt;li&gt;Step Four: Find a motor that meets these requirements&lt;/li&gt;&#xA;&lt;li&gt;Step Five: Plot motor characteristics&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Since you also have an acceleration requirement, you will also need to factor that in as well.&lt;/p&gt;&#xA;" OwnerUserId="891" LastEditorUserId="350" LastEditDate="2013-02-13T16:16:24.567" LastActivityDate="2013-02-13T16:16:24.567" CommentCount="3" />
  <row Id="916" PostTypeId="2" ParentId="913" CreationDate="2013-02-12T20:36:08.047" Score="4" Body="&lt;p&gt;While the answer by &lt;a href=&quot;http://robotics.stackexchange.com/a/914/37&quot;&gt;freeman01in&lt;/a&gt; references a &lt;a href=&quot;http://www.scribd.com/doc/38698/Sizing-Electric-Motors-for-Mobile-Robotics&quot; rel=&quot;nofollow&quot;&gt;useful presentation&lt;/a&gt; (&lt;a href=&quot;http://in.docsity.com/en-docs/Sizing+Electric+Motors+for+Mobile+Robotics-Robotics-Lecture+Slides&quot; rel=&quot;nofollow&quot;&gt;alternative source&lt;/a&gt;) on the practical application aspect of your question, it is probably worth answering the specific question in the title too, in terms of first principles.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From the &lt;a href=&quot;http://en.wikipedia.org/wiki/Power_%28physics%29&quot; rel=&quot;nofollow&quot;&gt;Wikipedia Power&lt;/a&gt; page:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;In physics, &lt;strong&gt;power&lt;/strong&gt; is the rate at which energy is transferred, used, or transformed. The unit of power is the joule per second (J/s), known as the watt ...&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Energy transfer can be used to do work, so power is also the rate at which this work is performed. The same amount of work is done when carrying a load up a flight of stairs whether the person carrying it walks or runs, but more power is expended during the running because the work is done in a shorter amount of time. The output power of an electric motor is the product of the torque the motor generates and the angular velocity of its output shaft. The power expended to move a vehicle is the product of the traction force of the wheels and the velocity of the vehicle.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;The integral of power over time defines the work done. Because this integral depends on the trajectory of the point of application of the force and torque, this calculation of work is said to be &quot;path dependent.&quot;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Meanwhile, from the &lt;a href=&quot;http://en.wikipedia.org/wiki/Torque&quot; rel=&quot;nofollow&quot;&gt;Wikipedia Torque&lt;/a&gt; page:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Torque, moment or moment of force (see the terminology below), is the tendency of a force to rotate an object about an axis,&lt;a href=&quot;http://robotics.stackexchange.com/a/914/37&quot;&gt;1&lt;/a&gt; fulcrum, or pivot. Just as a force is a push or a pull, a torque can be thought of as a twist to an object. Mathematically, torque is defined as the cross product of the lever-arm distance and force, which tends to produce rotation.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Loosely speaking, torque is a measure of the turning force on an object such as a bolt or a flywheel. For example, pushing or pulling the handle of a wrench connected to a nut or bolt produces a torque (turning force) that loosens or tightens the nut or bolt.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;The symbol for torque is typically $\boldsymbol{\tau}$, the Greek letter tau. When it is called moment, it is commonly denoted $M$.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;The magnitude of torque depends on three quantities: the force applied, the length of the lever arm connecting the axis to the point of force application, and the angle between the force vector and the lever arm. ...&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;The SI unit for torque is the newton metre (N·m).&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;And from &lt;a href=&quot;http://en.wikipedia.org/wiki/Torque#Relationship_between_torque.2C_power.2C_and_energy&quot; rel=&quot;nofollow&quot;&gt;Relationship between torque, power, and energy&lt;/a&gt; you get the formula: &lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Power is the work per unit time, given by $$P = \boldsymbol{\tau} \cdot \boldsymbol{\omega}$$ where $P$ is power, $\boldsymbol{\tau}$ is torque, $\boldsymbol{\omega}$ is the angular velocity, and $\cdot$ represents the scalar product.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="37" LastEditorUserId="37" LastEditDate="2013-02-13T01:25:46.573" LastActivityDate="2013-02-13T01:25:46.573" />
  <row Id="917" PostTypeId="2" ParentId="897" CreationDate="2013-02-12T22:01:52.213" Score="3" Body="&lt;p&gt;It's possible that this isn't working because you have blown your transistor. There are a couple of things which could have blown it:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;No resistor to limit the base current&lt;/li&gt;&#xA;&lt;li&gt;No diode to protect against back EMF from the motor&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;So you should add a base resistor, and a flyback diode.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/HfX1h.png&quot; alt=&quot;Driving a motor with an NPN transistor.&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I always like to add an LED to the Arduino's output too, so that I can see exactly when the output is high. And if you're doing PWM on that pin, then the brightness of the LED tells you the duty cycle.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Added:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The reason for putting the transistor below the motor is that it's easier to make it work. To switch on the transistor, I just have to push a little current through the base by bringing its voltage up higher than the emitter. But if the transistor was above the motor, and the motor was running at 12v, then it's going to be impossible for the Arduino to do this, because it can't generate a voltage high enough.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When you put the transistor above the motor, you need to add &lt;em&gt;another&lt;/em&gt; transistor to help you deal with the large voltage required by the base.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/auKaY.png&quot; alt=&quot;High Side Driver&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In this circuit they're using a FET, rather than an NPN transistor, so the base is called a gate, but the same thing applies.&lt;/p&gt;&#xA;" OwnerUserId="40" LastEditorUserId="40" LastEditDate="2013-02-13T10:30:04.347" LastActivityDate="2013-02-13T10:30:04.347" CommentCount="1" />
  <row Id="918" PostTypeId="1" AcceptedAnswerId="919" CreationDate="2013-02-14T09:59:40.490" Score="1" ViewCount="93" Body="&lt;p&gt;Does anybody know if Kinect Data can be stored directly onto a USB Drive?? &#xA;I have a Kinect for Windows that i cannot use on Linux(ROS). However what i plan is to mount the Kinect on my robot, store the captured frames on a USB and then un mount the USB ,transfer to Linux and process them on ROS.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is this possible?? Any suggestions.  &lt;/p&gt;&#xA;" OwnerUserId="853" LastActivityDate="2013-02-14T11:28:38.520" Title="Storing Kinect Data on a USB Drive" Tags="&lt;kinect&gt;&lt;ros&gt;" AnswerCount="1" CommentCount="3" />
  <row Id="919" PostTypeId="2" ParentId="918" CreationDate="2013-02-14T11:23:28.993" Score="2" Body="&lt;p&gt;&lt;strong&gt;Can Kinect data be stored directly onto a USB drive?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Yes. In ROS that would be easily done using bag files. In Windows, however, you might have to look for something native in the Microsoft SDK/OpenNI or code it yourself. &lt;em&gt;Edit: In OpenNI there is something called .oni files for that purpose.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;The implicit question: Does Kinect for Windows work in Linux?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As far as I am aware, yes. From what I researched there were &lt;a href=&quot;https://groups.google.com/forum/#!topic/openni-dev/fFJM0DqLWq4&quot; rel=&quot;nofollow&quot;&gt;compatibility issues with OpenNI initially&lt;/a&gt; but &lt;a href=&quot;https://groups.google.com/forum/#!topic/openni-dev/fFJM0DqLWq4&quot; rel=&quot;nofollow&quot;&gt;they seem to be solved&lt;/a&gt; as of May 2012. There are reports of users successfully using K4W in both Windows and Linux there. See &lt;a href=&quot;http://robotics.stackexchange.com/questions/654/what-is-the-difference-between-kinect-for-windows-and-kinect-for-xbox&quot;&gt;this previous question&lt;/a&gt; for more info.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I assume the changes have made their way upstream, but the only way to be sure is to test it. If they haven't, you can always use the patched version referred in the link.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My suggestion is get your sensor working in Linux and don't waste your time trying to figure out how to save Kinect data to a USB drive in Windows.&lt;/p&gt;&#xA;" OwnerUserId="95" LastEditorUserId="95" LastEditDate="2013-02-14T11:28:38.520" LastActivityDate="2013-02-14T11:28:38.520" />
  <row Id="920" PostTypeId="2" ParentId="897" CreationDate="2013-02-14T13:49:45.700" Score="0" Body="&lt;p&gt;You need first to know how much current your motor draws at no load, and also at stall.&#xA;After that you need to choose a transistor that its collector or its drain can support the stall current. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;You have to know that your current configuration is just for a one direction control, and to which direction that depends on the polarity. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;You need an H-Bridge like L293-L298 for controlling in two directions.&lt;/p&gt;&#xA;" OwnerUserId="900" LastActivityDate="2013-02-14T13:49:45.700" CommentCount="2" />
  <row Id="921" PostTypeId="1" AcceptedAnswerId="1102" CreationDate="2013-02-14T16:56:23.807" Score="3" ViewCount="3343" Body="&lt;p&gt;I'm trying to connect a camera module to my Arduino Mega, connect my Mega to my Android phone (throught BlueTooth or other), and send the live view of the camera to the mobile phone.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I saw a &lt;a href=&quot;http://www.youtube.com/watch?v=qEVXqOJz-GY&quot; rel=&quot;nofollow&quot;&gt;video online&lt;/a&gt; that showed this for still images -- an image captured by the camera module on the Arduino was sent to Android and the output image was viewed after a couple of seconds (the time to send image by BT).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is this doable with live video instead of image?  If yes, please guide me; if no, please suggest some workarounds.&lt;/p&gt;&#xA;" OwnerUserId="888" LastEditorUserId="888" LastEditDate="2013-02-14T21:19:41.833" LastActivityDate="2013-03-22T23:24:17.057" Title="How can I send video from my Arduino camera module video to my Android screen?" Tags="&lt;arduino&gt;&lt;cameras&gt;" AnswerCount="4" CommentCount="3" FavoriteCount="0" />
  <row Id="922" PostTypeId="1" CreationDate="2013-02-15T02:25:01.773" Score="4" ViewCount="110" Body="&lt;p&gt;I need to make an omni wheeled robot platform (4 wheels), which should go at a minimum speed of 15 cm/s.  I have an idea for the design, but since this is my first time doing something like this I have made &lt;strong&gt;a lot&lt;/strong&gt; of assumptions. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I decided to choose the &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/__13360__TGY_S4505B_40g_4_8kg_0_10sec_Dual_Bearing_Analog_Servo.html&quot; rel=&quot;nofollow&quot;&gt;TGY-S4505B&lt;/a&gt; servos as my motor system. I intend to attach these servos to &lt;a href=&quot;http://store.kornylak.com/ProductDetails.asp?ProductCode=FXA308B&quot; rel=&quot;nofollow&quot;&gt;FXA308B&lt;/a&gt; wheels. Finally, I intend to power my servos with one &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/__25030__Turnigy_LSD_6_0V_2300mAh_Ni_MH_Flat_Receiver_Pack.html&quot; rel=&quot;nofollow&quot;&gt;Turnigy LSD 6.0V 2300mAh Ni-MH Flat Receiver Packs&lt;/a&gt; (not sure if LiPo is a better choice). I need to be able to run the servos continuously for roughly 8 minutes. You can ignore the microcontroller and other stuff, relatively speaking they will consume much less power. The robot will have four wheels (thus, four servos).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The basic specifications of each servo is:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Type: Analog&lt;/li&gt;&#xA;&lt;li&gt;Gear train: Plastic&lt;/li&gt;&#xA;&lt;li&gt;Bearings: Dual&lt;/li&gt;&#xA;&lt;li&gt;Motor Type: Carbon Brushed&lt;/li&gt;&#xA;&lt;li&gt;Weight: 40g (1.41oz)&lt;/li&gt;&#xA;&lt;li&gt;Lead: 30cm&lt;/li&gt;&#xA;&lt;li&gt;Torque: 3.9kg.cm @ 4.8v / 4.8kg.cm @ 6v&lt;/li&gt;&#xA;&lt;li&gt;Speed: 0.13sec 60°@ 4.8v / 0.10 60° @ 6v&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;So based on my battery pack, I will be running the servos at 6V. That gives me a speed of 60 degrees per 0.10 seconds. I plan on modifying these servos for continuous rotation, and connected them directly to the wheel. Since the wheel has a diameter of ~5 cm, it has a circumference of ~15 cm. Based on these specs, it seems to me that my robot can move at roughly 15 cm/0.6 seconds, or 25 cm/s (quite fast actually). I don't intend to run it constantly at that speed, so in the 8 minute run, assume my average speed to be 20 cm/s.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Are these assumptions reasonable, and are the calculations correct?  I would really appreciate any insight, advice, recommendations, and criticisms you may have.&lt;/p&gt;&#xA;" OwnerUserId="901" LastEditorUserId="37" LastEditDate="2013-05-20T15:02:26.757" LastActivityDate="2013-05-20T15:02:26.757" Title="How do I design for a target speed?" Tags="&lt;mobile-robot&gt;&lt;wheel&gt;&lt;rcservo&gt;" AnswerCount="1" CommentCount="3" FavoriteCount="2" />
  <row Id="923" PostTypeId="2" ParentId="235" CreationDate="2013-02-15T05:07:19.340" Score="4" Body="&lt;p&gt;You want to mount the batteries as close to the center of the hub and as close to the center both horizontally and vertically.  The closer it is, the less the controller has to work to keep the craft horizontally balanced and the less battery power you will use.&lt;/p&gt;&#xA;" OwnerUserId="902" LastActivityDate="2013-02-15T05:07:19.340" />
  <row Id="924" PostTypeId="1" AcceptedAnswerId="925" CreationDate="2013-02-15T08:20:41.940" Score="1" ViewCount="45" Body="&lt;p&gt;Do any of the TI &lt;a href=&quot;http://en.wikipedia.org/wiki/ARM_system-on-chip_architecture&quot; rel=&quot;nofollow&quot;&gt;ARM SOC&lt;/a&gt;s, e.g. &lt;a href=&quot;http://www.ti.com/lsds/ti/arm/sitara_arm_cortex_a_processor/sitara_arm_cortex_a8/omap3503_15_arm_cortex_a8/products.page?paramCriteria=no&quot; rel=&quot;nofollow&quot;&gt;OMAP&lt;/a&gt; or &lt;a href=&quot;http://www.ti.com/lsds/ti/dsp/video_processors/overview.page&quot; rel=&quot;nofollow&quot;&gt;Da Vinci&lt;/a&gt;, have a version with stacked RAM? (e.g. DDR2 or mDDR) For miniature robots like micro drones, it would be really nice to not need to spend board area on an external RAM chip. Thanks!&lt;/p&gt;&#xA;" OwnerUserId="106" LastEditorUserId="350" LastEditDate="2013-02-15T16:44:05.870" LastActivityDate="2013-02-15T16:46:18.593" Title="TI ARM with stacked RAM" Tags="&lt;arm&gt;" AnswerCount="1" />
  <row Id="925" PostTypeId="2" ParentId="924" CreationDate="2013-02-15T16:46:18.593" Score="3" Body="&lt;p&gt;According to TI's website, &lt;a href=&quot;http://www.ti.com/general/docs/wtbu/wtbuproductcontent.tsp?templateId=6123&amp;amp;navigationId=12828&amp;amp;contentId=50020&quot; rel=&quot;nofollow&quot;&gt;some of the OMAP processors (specifically the OMAP-DM5x range) have stacked RAM&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://focus.ti.com/en/multimedia/wtbu/OMAP-DM299-500-diagram.jpg&quot; alt=&quot;chip architecture&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;More info &lt;a href=&quot;http://www.ti.com/lit/ml/swpt036/swpt036.pdf&quot; rel=&quot;nofollow&quot;&gt;here (PDF)&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-02-15T16:46:18.593" />
  <row Id="926" PostTypeId="2" ParentId="921" CreationDate="2013-02-15T17:12:20.907" Score="0" Body="&lt;p&gt;To answer the question &quot;is it doable&quot;, I would say yes.  There is apparently a product called Looxcie that does this, according to &lt;a href=&quot;http://www.slashgear.com/looxcie-bluetooth-video-camera-review-with-an-htc-thunderbolt-11145337/&quot; rel=&quot;nofollow&quot;&gt;this review on Slashgear&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My guess is that it's using BlueTooth's &lt;a href=&quot;https://www.bluetooth.org/Building/HowTechnologyWorks/ProfilesAndProtocols/AVCTP.htm&quot; rel=&quot;nofollow&quot;&gt;Audio / Video Control Transport Protocol (AVCTP)&lt;/a&gt;, so you might check for devices and mobile phone software libraries that support AVCTP.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-02-15T21:01:42.250" LastActivityDate="2013-02-15T21:01:42.250" />
  <row Id="927" PostTypeId="2" ParentId="896" CreationDate="2013-02-15T20:18:42.453" Score="3" Body="&lt;p&gt;Off the top of my head I would go by the following selection criteria&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;color/b&amp;amp;w - usually b&amp;amp;w is better, since the stereo algorithms only use one channel anyway&lt;/li&gt;&#xA;&lt;li&gt;baseline - this really depends on the scene. With the baseline you control how much accuracy you get with distance. Wider baseline results in higher disparity values and thus less noise on the distance estimation. Higher baseline also means that you will get a reduced overlap between your field of views. Most importantly though, the wider the baseline the harder the matching between the two views. So the quality of the result goes down.&lt;/li&gt;&#xA;&lt;li&gt;shutter - always use a global shutter for anything with computer vision on mobile robots&lt;/li&gt;&#xA;&lt;li&gt;resolution - most stereo algorithms are computationally expensive. And you will likely not need that many 3d points. In the near field the sampling density is usually enough, and the far field your error from the low disparity is more of a problem than sampling density. 640x480 is fine in most cases. Some chips have a wider aspect ratio, which is favourable for the overlap, but you can get the same with using a sub-window of your chip.&lt;/li&gt;&#xA;&lt;li&gt;objectives/field of view - for mobile outdoor robots I prefer a wide field of view over narrow objectives. More or less for the same reasons as the resolution. Make sure your objectives are rigid and have a means to fixate any moving parts e.g. like adjustable focal length. In most cases a fixed focal length is fine anyway, since you are limited by the selection of your baseline.&lt;/li&gt;&#xA;&lt;li&gt;trigger - when you create your own stereo rig, your cameras should support hardware trigger and ideally one should trigger the other.&lt;/li&gt;&#xA;&lt;li&gt;framerate - In my opinion the least important consideration. Unless you have a lot of processing power you won't be getting much more than something like 5 Hz anyway. So your algorithm is much more likely to be the bottleneck, rather than the chip or the connection.&lt;/li&gt;&#xA;&lt;li&gt;interface - Most cameras come with Firewire/USB2/USB3/Ethernet. USB2 is useless as it consumes a lot of CPU. Firewire is good if you have a port, but I think it seems to be on the decline in favour of USB3 these days. Didn't have much experience with USB3 yet. Ethernet is quite nice because you are more likely to find embedded systems with GigEthernet than USB3 at the moment.&lt;/li&gt;&#xA;&lt;li&gt;housing - as rigid as possible. Recalibrating is an annoying procedure.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="127" LastActivityDate="2013-02-15T20:18:42.453" />
  <row Id="929" PostTypeId="2" ParentId="921" CreationDate="2013-02-16T10:31:10.710" Score="0" Body="&lt;p&gt;My solution is a workaround. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I do not send the relatively large image frames via Bluetooth but I use the Android phone with OpenCV to shoot the live video and direct the Arduino via Bluetooth with a few short commands after image processing. The phone is located near the Arduino just as an Arduino connected camera would be.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you want to see the images - or some processed version of them - remotely you can use another phone connected to camera phone via a second Bluetooth connection. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am not ready with the above, a Mindstorms NXT, Android, OpenCV version is &lt;a href=&quot;http://jataka.hu/rics/nxt_android_opencv/index.html&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="577" LastActivityDate="2013-02-16T10:31:10.710" />
  <row Id="931" PostTypeId="2" ParentId="878" CreationDate="2013-02-16T17:05:20.170" Score="1" Body="&lt;p&gt;What I've found 3d printing with SketchUp:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Use good geometry. Free Drawing should pretty much &lt;strong&gt;never&lt;/strong&gt; be used. Make sure all of your arcs &amp;amp; angles are clean.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;You can &lt;strong&gt;not&lt;/strong&gt; have unclosed areas. Some programs are very good about this. Sketchup is &lt;strong&gt;not&lt;/strong&gt;. Lines that go no where should be removed, and all lines should be connected to the model.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Pick a good ruby script for exporting as an STL. There are many free scripts available, and any of them should work if you do what is mentioned above.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Good Luck!&lt;/p&gt;&#xA;" OwnerUserId="216" LastActivityDate="2013-02-16T17:05:20.170" />
  <row Id="933" PostTypeId="5" CreationDate="2013-02-16T19:00:30.070" Score="0" ViewCount="2" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2013-02-16T19:00:30.070" LastActivityDate="2013-02-16T19:00:30.070" />
  <row Id="934" PostTypeId="4" CreationDate="2013-02-16T19:00:30.070" Score="0" Body="A programming language commonly used for controlling robotic devices " OwnerUserId="498" LastEditorUserId="498" LastEditDate="2013-02-19T12:08:51.967" LastActivityDate="2013-02-19T12:08:51.967" />
  <row Id="935" PostTypeId="1" CreationDate="2013-02-16T19:34:37.357" Score="0" ViewCount="52" Body="&lt;p&gt;I am working with sonar in a &lt;a href=&quot;http://www.mobilerobots.com/researchrobots/pioneerp3dx.aspx&quot; rel=&quot;nofollow&quot;&gt;Pioneer 3dx robot&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I can't figure out sonar sensor model parameters that work well.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I was able to find laser model parameters from ROS, but not for sonar models.  How do I get the right ones?&lt;/p&gt;&#xA;" OwnerUserId="714" LastEditorUserId="350" LastEditDate="2013-02-17T03:37:26.060" LastActivityDate="2013-02-17T03:37:26.060" Title="Good parameters for Pioneer 3dx sonar sensor model?" Tags="&lt;mobile-robot&gt;&lt;sensors&gt;&lt;localization&gt;&lt;wheeled-robot&gt;" />
  <row Id="937" PostTypeId="2" ParentId="845" CreationDate="2013-02-17T07:58:15.883" Score="0" Body="&lt;p&gt;You probably want to do this, check it out. They also have code &lt;a href=&quot;http://personalrobotics.ri.cmu.edu/projects/moped.php&quot; rel=&quot;nofollow&quot;&gt;http://personalrobotics.ri.cmu.edu/projects/moped.php&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="911" LastActivityDate="2013-02-17T07:58:15.883" CommentCount="2" />
  <row Id="938" PostTypeId="2" ParentId="896" CreationDate="2013-02-17T20:42:08.547" Score="2" Body="&lt;p&gt;That is an interesting topic, and not very easy to get right on the first try. From experience with this, here are the most important things. &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Synchronization&lt;/strong&gt;. The camera must be 100% synced. For example, say the UGV is driving at a modest 36Km/hr (10m/s)  and recording frames at 30 frames per second. That is, at every frame the UGV would cover 3m. Now, say your sync is off by 1ms, one of the cameras will be off by ~0.3m, which is bad [just off the top of my head]. Sync problems are very hard to detect.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Resolution&lt;/strong&gt;. In the context of stereo, we refer to depth resolution, or how much depth can we resolve given a change in disparity. An excellent explanation can be found here &lt;a href=&quot;http://pub1.willowgarage.com/~konolige/svs/disparity.htm&quot; rel=&quot;nofollow&quot;&gt;http://pub1.willowgarage.com/~konolige/svs/disparity.htm&lt;/a&gt; The equation you want to look at is a function of the focal length of the image and the stereo baseline. $\delta Z = \frac{Z^2}{Bf}\delta d$. This says that depth resolving power $\delta Z$ is inversely proportional to the baseline $B$ times the focal length $f$. That is the longer the baseline, the smaller $\delta Z$, the better. Meaning, you can resolve more depth. The minimum change in disparity $\delta d$ is controlled partially by the image resolution and the algorithm used. For your calculations, you can safely assume that $\delta d$ is at least $1/2$. It is better to be conservative with the choice of $\delta d$.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Overlap&lt;/strong&gt;. You want to have overlap between the cameras to get stereo. Hence, you need to choose a combination of lens focal length (field of view) and baseline so that you have enough overlap for the application. Basically, trigonometry work on the board, or a quick matlab/python script.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;For UGV's, there are two uses for stereo. &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Navigation and Pose Estimation&lt;/strong&gt; In this case you most probably need a large baseline + long focal length. This allows the stereo to see and resolve depth better and longer range.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Obstacle detection and avoidance&lt;/strong&gt; You will probably need a shorter baseline and wider lens (smaller focal length) so that  you can focus on things very close to you. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Some UGV's might have both stereo setups, the large baseline narrow field of view for navigation and another one or two for obstacle avoidance. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Be very careful what you buy. Some companies offer already built stereo setups. Those are great on the robustness side of things, they don't loose calibration easily and are always in sync. The problem is that the commercially available ones have a small baseline. If you want to build your own. I'm guessing you will end up doing so, make sure the camera are &lt;em&gt;syncable&lt;/em&gt;. Firewire is great for this, two camera on the same bus will sync with 125microsecond accuracy out of the box! USB and Gige cams are painful to sync.  When you put everything together, you want to make sure that the lenses are not going to move at all, and the baseline is rigid, very rigid for the application. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also be careful in lens selection. Not all lenses work with all cameras. Lenses have a resolution too. This is a another topic, here is a short article on this &lt;a href=&quot;http://www.qualitymag.com/articles/90642-q-a--selecting-lenses-for-machine-vision-systems&quot; rel=&quot;nofollow&quot;&gt;http://www.qualitymag.com/articles/90642-q-a--selecting-lenses-for-machine-vision-systems&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="911" LastActivityDate="2013-02-17T20:42:08.547" />
  <row Id="939" PostTypeId="1" AcceptedAnswerId="941" CreationDate="2013-02-17T21:09:19.683" Score="10" ViewCount="650" Body="&lt;p&gt;For my robot, I am using two continuous rotation servos to spin a threaded rod. I am trying to make this project as cheap as possible. Here are the servos that I can find:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Servo #1: This is a very cheap option and it has half of the torque I need.&lt;/li&gt;&#xA;&lt;li&gt;Servo #2: This has all of the torque my project requires, but it is much more expensive that two of servo #1.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Can I hook up two of servo #1 to each end of the rod and have them move synchronized? I can spare a few extra pins on my microprocessor that I am using; that isn't a issue. I know hooking two together will increase torque, but I don't want 75% of the torque I want in this situation. Also, I don't care if I only have 98% of my torque &quot;goal&quot; with the extra weight (which probably won't happen) but I don't want to, like I said earlier, have 70, 80, 90% of my &quot;target goal&quot; of torque if possible.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any help appreciated. Thanks in advance.&lt;/p&gt;&#xA;" OwnerUserId="824" LastEditorUserId="824" LastEditDate="2013-05-21T22:43:37.060" LastActivityDate="2013-11-21T05:03:51.717" Title="Will connecting two servo motors double the torque?" Tags="&lt;motor&gt;&lt;rcservo&gt;" AnswerCount="4" CommentCount="10" FavoriteCount="2" />
  <row Id="940" PostTypeId="1" AcceptedAnswerId="945" CreationDate="2013-02-18T11:18:22.693" Score="6" ViewCount="218" Body="&lt;p&gt;I'm doing robotics research as an undergraduate, and I understand the conceptual math for the most part; however, when it comes to actually implementing code to calculate the forward kinematics for my robot, I am stuck. I'm just not getting the way the book or websites I've found explain it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would like to calculate the X-Y-Z angles given the link parameters (Denavit-Hartenberg parameters), such as the &lt;a href=&quot;http://i.stack.imgur.com/j6Cf6.png&quot; rel=&quot;nofollow&quot;&gt;following&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$\begin{array}{ccc}&#xA;\bf{i} &amp;amp; \bf{\alpha_i-1} &amp;amp; \bf{a_i-1} &amp;amp; \bf{d_i} &amp;amp; \bf{\theta_i}\\&#xA;\\ &#xA;1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \theta_1\\&#xA;2 &amp;amp; -90^{\circ} &amp;amp; 0 &amp;amp; 0 &amp;amp; \theta_2\\&#xA;3 &amp;amp; 0 &amp;amp; a_2 &amp;amp; d_3 &amp;amp; \theta_3\\&#xA;4 &amp;amp; -90^{\circ} &amp;amp; a_3 &amp;amp; d_4 &amp;amp; \theta_4\\&#xA;5 &amp;amp; 90^{\circ} &amp;amp; 0 &amp;amp; 0 &amp;amp; \theta_5\\&#xA;6 &amp;amp; -90^{\circ} &amp;amp; 0 &amp;amp; 0 &amp;amp; \theta_6\\&#xA;\end{array}$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I don't understand how to turn this table of values into the proper transformation matrices needed to get $^0T_N$, the Cartesian position and rotation of the last link. From there, I'm hoping I can figure out the X-Y-Z angle(s) from reading my book, but any help would be appreciated.&lt;/p&gt;&#xA;" OwnerUserId="916" LastEditorUserId="350" LastEditDate="2013-03-18T15:43:13.703" LastActivityDate="2013-03-18T15:43:13.703" Title="How do I convert link parameters and angles (in kinematics) into transformation matrices in programming logic?" Tags="&lt;kinematics&gt;&lt;forward-kinematics&gt;" AnswerCount="1" />
  <row Id="941" PostTypeId="2" ParentId="939" CreationDate="2013-02-18T14:51:50.363" Score="16" Body="&lt;p&gt;In theory, you're correct.  But in practice, &lt;a href=&quot;http://finance.groups.yahoo.com/group/geckodrive/message/16536&quot; rel=&quot;nofollow&quot;&gt;slight differences between the two motors will make them fight each other&lt;/a&gt; instead of working in perfect harmony:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Even the smallest mismatch in wire tolerances, lengths etc. will create&#xA;  different back emf characteristics due to different impedances.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;So both will work separately, but the actual characteristics of the 2&#xA;  motor within the very small timeframes of a &quot;minimum&quot; move at relatively&#xA;  high speed will not be in synch .. and thus the 2 motors fight each other.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;For this reason, your plan to save money by connecting a second servo to your microcontroller will probably &lt;em&gt;cost&lt;/em&gt; you money.  Not only are you shortening the life of the servos, you're doubling your chance of a servo failure.  Worse, the failure of one servo may cascade to the other unless you are using a mechanical linkage (as &lt;a href=&quot;http://robotics.stackexchange.com/a/943/350&quot;&gt;ApockofFork's answer&lt;/a&gt; recommends), e.g. &lt;a href=&quot;http://www.youtube.com/watch?v=3fDyULSO8KU&quot; rel=&quot;nofollow&quot;&gt;the one in this video&lt;/a&gt;.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;With that said, connecting multiple servos with a fixed linkage is done all the time, e.g. &lt;a href=&quot;http://i.stack.imgur.com/ejpnP.jpg&quot; rel=&quot;nofollow&quot;&gt;RC plane rudders&lt;/a&gt;, &lt;a href=&quot;http://www.youtube.com/watch?v=uVhBszHmvtA&quot; rel=&quot;nofollow&quot;&gt;RC plane ailerons&lt;/a&gt;.  But to avoid the problems cited earlier, &lt;strong&gt;it requires an additional control component&lt;/strong&gt; that can compensate for the differences in the electrical characteristics of the servos.  These are commonly called &quot;servo equalizers&quot;, &quot;matchboxes&quot;, or &quot;servo synchronizers&quot;.  &lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-06-23T04:03:04.550" LastActivityDate="2013-06-23T04:03:04.550" CommentCount="2" />
  <row Id="943" PostTypeId="2" ParentId="939" CreationDate="2013-02-18T23:05:59.580" Score="10" Body="&lt;p&gt;What &lt;a href=&quot;http://robotics.stackexchange.com/a/941/37&quot;&gt;Ians answer&lt;/a&gt; says about the two motors fighting is true however, I wouldn't go as far to say that you can never put two motors together for more power. In general  if the two motors are identical and you are hooking them up and controlling them identically then you can probably get away with it but I would expect some wasted energy and thus extra heat from the two motors fighting a little bit. You will also not get exactly two times the output.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Worst of all it will probably hurt the lifespan of the motors. In other words it will probably do in a pinch but is definitely not ideal. If you really do, do a good job syncing them up then you can theoretically keep the losses to a manageable level.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are going to use two motors on the same output you will probably want to gear them together or use some other linkage that isn't fixed (I.E. don't attach them both to the same shaft). That way there is some looseness between them so they will fight each other a little less.&lt;/p&gt;&#xA;" OwnerUserId="201" LastEditorUserId="37" LastEditDate="2013-02-19T16:50:05.033" LastActivityDate="2013-02-19T16:50:05.033" CommentCount="2" />
  <row Id="944" PostTypeId="2" ParentId="907" CreationDate="2013-02-18T23:21:40.040" Score="1" Body="&lt;p&gt;The simplest method in this case is to essentially brute force the problem but to brute force it in an intelligent manner.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What you will need is a set of data from the scanner while it is scanning an object, preferably a mathematically simple object like a cube or a sphere and the exact offset position or offset of that object relative to the mount of this scanner.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you have these two pieces of information the next trick is essentially testing various combinations scanner offsets (what I would typically call calibration values) until you find offsets that cause the scanner data to accurately represent your object. For this you can either randomly guess values which can take forever and not get anywhere (but in theory would eventually get you the right answer) or you can use an &lt;a href=&quot;http://en.wikipedia.org/wiki/Mathematical_optimization&quot; rel=&quot;nofollow&quot;&gt;optimization method&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To use an optimization method you will need to develop some sort of metric to say whether a particular set of offsets works better than another set. Then whatever optimization method you are using will use that score to say whether to adjust the values in a particular direction. Eventually it will settle on a particular set of values that seem to work best.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is a pretty brief and poor description of a very in depth topic but hopefully it will get you pointed in a direction. If you would like a more detailed description of anything leave a comment.&lt;/p&gt;&#xA;" OwnerUserId="201" LastActivityDate="2013-02-18T23:21:40.040" />
  <row Id="945" PostTypeId="2" ParentId="940" CreationDate="2013-02-18T23:24:21.857" Score="5" Body="&lt;p&gt;The &lt;a href=&quot;http://en.wikipedia.org/wiki/Denavit%E2%80%93Hartenberg_parameters&quot; rel=&quot;nofollow&quot;&gt;DH Matrix&lt;/a&gt; section of the DH page on wikipedia has the details.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Basically you want to use the information in your table to create a set of homogeneous transformation matrices. We do so because homogeneous transformations can be multiplied to find the relation between frames seperated by one or more others. For example, $^0T_1$ represents the transformation from frame 1 to frame 0 while $^1T_2$ represents the transformation from frame 2 to frame 1. By multiplying them we get the transformation from frame 2 to frame 0, i.e. $^0T_2 = ^0T_1^1T_2$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;An easy way to create each of the transformations is to make a homogeneous transformation or homogeneous rotation matrix for each column in the table and multiply them together. For example, the transformation from 1 to 0 (e.g. $^{i-1}T_i, i = 1$) is&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$^0T_1 = Trans(d_1)*Rot(\theta_1)*Trans(a_2)*Rot(\alpha_2)$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;where&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$Trans(d_1) = \begin{bmatrix}1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; \bf{d_1 = 0} \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix},$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$Rot(\theta_1) = \begin{bmatrix} \text{cos}(\bf{\theta_1}) &amp;amp; - \text{sin}(\bf{\theta_1}) &amp;amp; 0 &amp;amp; 0 \\ \text{sin}(\bf{\theta_1}) &amp;amp; \text{cos}(\bf{\theta_1}) &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix},$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$Trans(a_2) = \begin{bmatrix} 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; \bf{a_2 = 0} \\ 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix},$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$Rot(\alpha_2) = \begin{bmatrix} 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \text{cos}(\bf{\alpha_2 = 0}) &amp;amp; -\text{sin}(\bf{\alpha_2 = 0}) &amp;amp; 0 \\ 0 &amp;amp; \text{sin}(\bf{\alpha_2 = 0}) &amp;amp; \text{cos}(\bf{\alpha_2 = 0}) &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix}$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In this case&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$^0T1 = Rot(\theta_1)$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Once you have all your transformations you multiply them togther, e.g.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$^0T_N = ^0T_1*^1T_2...^{N-1}T_N$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Finally you can read the displacement vector out of the homogenous transform $^0T_N$ (i.e. $d = [^0T_{N,14}, ^0T_{N,24}, ^0T_{N,34}]^T$). Similarly you can read out the rotation matrix from $^0T_N$ to find the X-Y-Z angles.&lt;/p&gt;&#xA;" OwnerUserId="177" LastEditorUserId="350" LastEditDate="2013-02-19T16:48:57.267" LastActivityDate="2013-02-19T16:48:57.267" CommentCount="1" />
  <row Id="946" PostTypeId="1" CreationDate="2013-02-19T01:51:50.357" Score="6" ViewCount="399" Body="&lt;p&gt;I'm new to robot making and just got my first arduino to play around.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I want to make a robot that will wander on a table, and it will last longer I think if I could make it avoid falling from the table.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What will be the best way to make it detect the edge of a table so I can make it stop and turn around ? It have to be something reliable and preferably cheap.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It will also be better if I don't need to add extra stuff to the table so I can use it on any surface (my first idea was to draw path lines on the table and make a line follower robot, but I don't like this idea very much).&lt;/p&gt;&#xA;" OwnerUserId="920" LastEditorUserId="920" LastEditDate="2013-02-19T17:59:22.770" LastActivityDate="2013-02-20T17:54:30.887" Title="How can I detect the edge of a table?" Tags="&lt;sensors&gt;" AnswerCount="3" />
  <row Id="947" PostTypeId="2" ParentId="946" CreationDate="2013-02-19T05:11:26.607" Score="7" Body="&lt;p&gt;An easy and cheap approach is to use a a touch sensor like a whisker. The controller just monitors whether the whisker is in contact with the ground, if one is not then it stops and moves away from that wisker.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another fairly cheap method is to use a set of &lt;a href=&quot;http://www.acroname.com/robotics/info/articles/sharp/sharp.html&quot;&gt;IR range finders&lt;/a&gt; pointed toward the ground. The controller then monitors the values returned from the rangers and if any of them go above some predefined threshold then the robot stops and moves away from that sensor.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-02-19T05:11:26.607" CommentCount="1" />
  <row Id="948" PostTypeId="1" CreationDate="2013-02-19T09:54:40.927" Score="3" ViewCount="205" Body="&lt;p&gt;A robotic joint is connected to two actuators, e.g. air muscles. One flexes the joint, while the other extends it. This arrangement is called 'antagonistic'.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/7FNlN.png&quot; alt=&quot;Pneumatic Muscle Joint&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But what if I had an electric motor instead of the air muscles? In that case it can only pull on one tendon at a time, and it's not antagonistic. What it the arrangement called in this case? Untagonistic?&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2013-02-24T15:02:47.147" Title="What is the opposite of 'Antagonistic'?" Tags="&lt;motor&gt;&lt;air-muscle&gt;" AnswerCount="2" CommentCount="2" FavoriteCount="1" />
  <row Id="949" PostTypeId="2" ParentId="946" CreationDate="2013-02-19T12:25:44.840" Score="12" Body="&lt;p&gt;The Roomba solution to this problem was to add &lt;a href=&quot;http://uksupport.irobot.com/app/answers/detail/a_id/964/~/what-are-cliff-sensors?&quot;&gt;cliff sensors&lt;/a&gt;, which are really just downward facing &lt;a href=&quot;http://en.wikipedia.org/wiki/Proximity_sensor&quot;&gt;proximity sensors&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/File%3aSharp_GP2Y0A21YK_IR_proximity_sensor_cropped.jpg&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/0pwNg.jpg&quot; alt=&quot;Sharp GP2Y0A21YK infrared proximity sensor. The sensor has an analog output that varies from 3.1V at 10cm to 0.4V at 80cm.&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Although this technique seems to have problems with some surfaces, such as &lt;a href=&quot;http://www.pottsland.com/roomba/Roomba_5xx_Cliff_Sensor.html&quot;&gt;dark tile floors&lt;/a&gt;, it sounds like this won't be a problem for your application.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can even make one yourself with an IR LED and an IR photo diode, for example this &lt;a href=&quot;http://www.instructables.com/id/DIY-Infrared-Proximity-Sensor-Arduino-Compatible/&quot;&gt;Arduino Compatible DIY Infrared Proximity Sensor&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You might also be able to get some ideas from &lt;a href=&quot;http://www.instructables.com/id/Tiny-Wanderer-A-Table-Top-Robot/&quot;&gt;Tiny Wanderer - A Table Top Robot&lt;/a&gt; over on &lt;a href=&quot;http://www.instructables.com/&quot;&gt;instructables&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="37" LastEditorUserId="37" LastEditDate="2013-02-20T17:54:30.887" LastActivityDate="2013-02-20T17:54:30.887" />
  <row Id="950" PostTypeId="2" ParentId="946" CreationDate="2013-02-19T15:38:13.263" Score="3" Body="&lt;p&gt;There are a number of different approaches to solving this problem:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Distance Sensors&lt;/li&gt;&#xA;&lt;li&gt;Touch Sensor&lt;/li&gt;&#xA;&lt;li&gt;RFID Tags around the edge of the table (Or magnets)&lt;/li&gt;&#xA;&lt;li&gt;Camera (Using image processing, would be harder and the arduino would probably not be powerful enough for this)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;With the distance sensor you will need to check whether it is a digital or analogue signal provided by the sensor. For the purpose of your 'cliff sensor' you would probably be fine with digital as you would be able to use the sensor as a toggle to detect when the distance is over a minimum distance. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are interested in analogue sensors to provide more information (such as distance from a wall) than just a toggle switch you will need to check what the range is on the device. The sharp sensor pictured in the answer above will provide you with a voltage, which you will have to convert into a distance (It has an inverse relationship with distance). You will require 3 sensors to cover the same range of distances that an ultrasonic sensor covers (e.g. SRF08 Ultrasonic Range Finder). Sharp GP2D120 Distance Measurement Sensor 4-30cm for short range, the Sharp GP2Y0A02YK Distance Measurement Sensor 20-150cm for medium range, and the Sharp GP2Y0A710K0F Distance Measurement Sensor 100-550cm for the long range sensor. I had issues with the ultrasonic sensor dropping to zero sporadically, so you would need to program a catch statement if this dropout is unacceptable in your application. The SRF08 Ultrasonic Range Finder was much easier to work with as it had been tuned by the manufacturer.&lt;/p&gt;&#xA;" OwnerUserId="925" LastActivityDate="2013-02-19T15:38:13.263" />
  <row Id="951" PostTypeId="2" ParentId="948" CreationDate="2013-02-19T16:37:11.683" Score="5" Body="&lt;p&gt;The opposite of an &lt;a href=&quot;http://en.wikipedia.org/wiki/Antagonist_%28muscle%29&quot; rel=&quot;nofollow&quot;&gt;antagonist muscle&lt;/a&gt; is an &lt;a href=&quot;http://en.wikipedia.org/wiki/Agonist_%28muscle%29&quot; rel=&quot;nofollow&quot;&gt;agonist muscle&lt;/a&gt;, but that doesn't really answer your question.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In nature, muscles are found in &lt;em&gt;antagonistic pairs&lt;/em&gt; because they can only really contract, thus once a muscle is contracted, only an opposing muscle can effectively change the state back again (unless the &lt;em&gt;muscle's natural state is opposite to that which is produced by the muscle&lt;/em&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In your system, by using a single motor to replace both flexor &lt;em&gt;muscle&lt;/em&gt; and extensor &lt;em&gt;muscle&lt;/em&gt; you are departing from the way nature works and thus the analogy breaks down. As far as I can see, there is unlikely to be a term from nature which can answer your question without compromising the metaphor, but since you have a single motor which is both flexing and extending your joint, you could just call it an &lt;em&gt;agonist&lt;/em&gt;.&lt;/p&gt;&#xA;" OwnerUserId="37" LastEditorUserId="37" LastEditDate="2013-02-19T16:47:26.847" LastActivityDate="2013-02-19T16:47:26.847" />
  <row Id="952" PostTypeId="1" CreationDate="2013-02-19T21:02:05.790" Score="8" ViewCount="245" Body="&lt;p&gt;I'm trying to create a map of the obstacles in a fairly coarse 2D grid space, using exploration.  I detect obstacles by attempting to move from one space to an adjacent space, and if that fails then there's an obstacle in the destination space (there is no concept of a rangefinding sensor in this problem).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://www.eriding.net/resources/general/prim_frmwrks/images/asses/asses_y3_5d_3.gif&quot; alt=&quot;example grid&quot;&gt; (for example)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The process is complete when all the reachable squares have been visited.  In other words, some spaces might be completely unreachable even if they don't have obstacles because they're surrounded.  This is expected.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the simplest case, I could use &lt;a href=&quot;http://stackoverflow.com/a/11556238/2063546&quot;&gt;a DFS algorithm&lt;/a&gt;, but I'm worried that this will take an excessively long time to complete &amp;mdash; the robot will spend more time backtracking than exploring new territory.  I expect this to be especially problematic when attempting to reach the unreachable squares, because the robot will exhaust every option.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the more sophisticated method, the proper thing to do seems to be &lt;a href=&quot;http://en.wikipedia.org/wiki/Boustrophedon_cell_decomposition&quot;&gt;Boustrophedon cell decomposition&lt;/a&gt;.&lt;br&gt;&#xA;&lt;img src=&quot;http://planning.cs.uiuc.edu/img2836.gif&quot; alt=&quot;Boustrophedon cell decomposition&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, I can't seem to find a good description of the Boustrophedon cell decomposition algorithm (that is, a complete description in simple terms).  There are resources like &lt;a href=&quot;http://planning.cs.uiuc.edu/node352.html&quot;&gt;this one&lt;/a&gt;, &lt;a href=&quot;http://planning.cs.uiuc.edu/node262.html&quot;&gt;or this more general one on vertical cell decomposition&lt;/a&gt; but they don't offer much insight into the high-level algorithms nor the low-level data structures involved.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How can I visit (map) this grid efficiently?  If it exists, I would like an algorithm that performs better than $O(n^2)$ with respect to the total number of grid squares (&lt;em&gt;i.e.&lt;/em&gt; better than $O(n^4)$ for an $n*n$ grid).&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-02-20T14:27:27.120" LastActivityDate="2013-02-21T04:37:49.780" Title="What's an efficient way to visit every reachable space on a grid with unknown obstacles?" Tags="&lt;algorithm&gt;&lt;coverage&gt;&lt;planning&gt;" AnswerCount="1" CommentCount="7" FavoriteCount="0" />
  <row Id="953" PostTypeId="1" CreationDate="2013-02-20T05:53:07.863" Score="5" ViewCount="265" Body="&lt;p&gt;I am having some issues with the &lt;a href=&quot;http://ardrone2.parrot.com/usa/&quot; rel=&quot;nofollow&quot;&gt;ARDrone Parrot 2.0&lt;/a&gt; and hope someone else may be running into the same thing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;While hovering, the drone is (seemingly) randomly losing altitude then recovering . It is doing so while not being commanded any velocity inputs and should hold altitude. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;We are using the drivers from the &lt;a href=&quot;https://github.com/AutonomyLab/ardrone_autonomy/tree/dev-unstable&quot; rel=&quot;nofollow&quot;&gt;ardrone_autonomy (dev_unstable branch) on github&lt;/a&gt;. We are able to watch the PWM outputs being sent to the motor and they are dropping from the hover command do a small value before exponentially returning to the hover value when this drop occurs.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The issue could be a communication between the IMU and the onboard controller or on our software control implementation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Has anyone seen a similar problem or suggestions to test/troubleshoot what is happening?&lt;/p&gt;&#xA;" OwnerUserId="772" LastEditorUserId="350" LastEditDate="2013-02-20T14:31:48.910" LastActivityDate="2013-04-21T19:09:15.137" Title="Dropping PWM on Ardrone Parrot 2.0" Tags="&lt;ros&gt;&lt;quadrotor&gt;&lt;pwm&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="954" PostTypeId="1" CreationDate="2013-02-20T06:15:26.710" Score="5" ViewCount="716" Body="&lt;p&gt;I'm using Teensy hardware specifically.  I have a Teensy 2.0 and a Teensy 3.0, and from the documentation it seems like there are two 16 bit timers available, and each should be able to control 12 servos.  However, I've attached a logic analyzer and have confirmed that only the first 12 servos attached ever function.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there anything special I have to do with my sketch in order to convince the Servo library to allocate the second timer for servos attached beyond number 12?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This works:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#define NUM_SERVOS 12&#xA;&#xA;Servo servos[NUM_SERVOS];&#xA;&#xA;// teensy 2.0 pins&#xA;int pin_assignments[NUM_SERVOS] = {0, 1, 2, 3, 4, 5, 20, 19, 18, 17, 16, 15};&#xA;&#xA;void setup() { &#xA;  for(int i = 0; i &amp;lt; NUM_SERVOS; i++) {&#xA;    servos[i].attach(pin_assignments[i]) ;&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;But this, below, only ever shows activity on the first twelve pins attached:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#define NUM_SERVOS 24&#xA;&#xA;Servo servos[NUM_SERVOS];&#xA;&#xA;// teensy 3.0 pins&#xA;int pin_assignments[NUM_SERVOS] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23};&#xA;&#xA;&#xA;void setup() { &#xA;  for(int i = 0; i &amp;lt; NUM_SERVOS; i++) {&#xA;    servos[i].attach(pin_assignments[i]) ;&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="928" LastEditorUserId="37" LastEditDate="2013-05-20T16:01:48.000" LastActivityDate="2013-06-24T09:54:15.750" Title="Controlling more than 12 Servos with the Arduino Servo library" Tags="&lt;arduino&gt;&lt;rcservo&gt;" AnswerCount="3" CommentCount="2" />
  <row Id="955" PostTypeId="2" ParentId="229" CreationDate="2013-02-20T10:03:24.740" Score="3" Body="&lt;p&gt;This has been merged as of six weeks ago:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://github.com/ros/ros_comm/commit/8a1f92fc0c888099fe47005f609883601b7d8d72#diff-1&quot; rel=&quot;nofollow&quot;&gt;https://github.com/ros/ros_comm/commit/8a1f92fc0c888099fe47005f609883601b7d8d72#diff-1&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="84" LastActivityDate="2013-02-20T10:03:24.740" />
  <row Id="956" PostTypeId="2" ParentId="953" CreationDate="2013-02-20T12:00:10.790" Score="1" Body="&lt;p&gt;I have not used the ARDrone but have experience with height hold on another autopilot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Without the further information, a quick google search found a possible firmware issue with ARDrone in &lt;a href=&quot;http://forum.parrot.com/ardrone/en/viewtopic.php?id=17&quot; rel=&quot;nofollow&quot;&gt;this thread&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are using the onboard ultrasound sensor then as I mentioned in my post on &lt;a href=&quot;http://robotics.stackexchange.com/questions/946/how-can-i-detect-the-edge-of-a-table&quot;&gt;How can I detect the edge of a table?&lt;/a&gt;. The ultrasound sensors can jump to zero sporadically for part of a second and this could cause the ARDrone to change altitude and then jump back to the real value.&lt;/p&gt;&#xA;" OwnerUserId="925" LastEditorUserId="37" LastEditDate="2013-02-20T18:02:41.733" LastActivityDate="2013-02-20T18:02:41.733" CommentCount="3" />
  <row Id="957" PostTypeId="1" AcceptedAnswerId="995" CreationDate="2013-02-20T14:54:30.407" Score="4" ViewCount="114" Body="&lt;p&gt;I have come across a number of methods for developing wall-climbing robots.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Suction&lt;/li&gt;&#xA;&lt;li&gt;Chemical Adhesion&lt;/li&gt;&#xA;&lt;li&gt;Gecko like hair adhesion&lt;/li&gt;&#xA;&lt;li&gt;Electroadhesion&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Which method would be the best for heavy robots (5kg+)? Are there any other methods that I have missed?&lt;/p&gt;&#xA;" OwnerUserId="925" LastEditorUserId="350" LastEditDate="2013-02-20T15:00:17.027" LastActivityDate="2013-03-02T22:50:35.107" Title="Adhesion for a heavy wall-climbing robot" Tags="&lt;mobile-robot&gt;" AnswerCount="2" CommentCount="4" />
  <row Id="958" PostTypeId="2" ParentId="952" CreationDate="2013-02-20T22:09:35.013" Score="5" Body="&lt;p&gt;Boustrophedon cell decomposition is simply sub-dividing an environment into areas which can be efficiently covered by a boustrophedon path. A trapezoidal decomposition will do, and can be accomplished using a line-sweep algorithm.&#xA;See [Choset 2000], &lt;a href=&quot;http://www.personal.kent.edu/~rmuhamma/Compgeometry/MyCG/PolyPart/polyPartition.htm&quot; rel=&quot;nofollow&quot;&gt;This web site&lt;/a&gt;&#xA;, or (I recommend!) the excellent book &quot;Computational Geometry&quot; by Mark de Berg, et. al, for a complete description of the data structures and algorithms required.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Choset, Howie. &quot;Coverage of Known Spaces: The Boustrophedon Cellular Decomposition&quot; &lt;em&gt;Autonomous Robots&lt;/em&gt;, 2000.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;For example, consider the set of obstacles as edges and vertices. Let's say the environment is also bounded by a special polygon. We have something like the following. To decompose this space, we simply add vertical edges between every vertex and the nearest line or vertex.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://www.jvanderhook.info/images/slabs/drawing_1.png&quot; height=&quot;200&quot;/&gt;&#xA;&lt;img src=&quot;http://www.jvanderhook.info/images/slabs/drawing_2.png&quot; height=&quot;200&quot;/&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://www.jvanderhook.info/images/slabs/drawing_3.png&quot; height=&quot;200&quot;/&gt;&#xA;&lt;img src=&quot;http://www.jvanderhook.info/images/slabs/drawing_4.png&quot; height=&quot;200&quot;/&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To accomplish this in code, you need only a line-segment intersection test, a sorted list of edges, and a sorted list of vertices. &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;From every vertex $v_i$ in left-to-right order,&lt;/li&gt;&#xA;&lt;li&gt;Create a vertical line $l_i$ at each $v_i$, extended until the first edge or vertex it intersects&lt;/li&gt;&#xA;&lt;li&gt;At each intersection, create a new vertex. &lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;When this is done, the set of new edges and vertices encloses only trapezoids. But I emphasize, you can't do this &lt;em&gt;online&lt;/em&gt; (without prior knowledge of the obstacles). If you want to do robust coverage without prior knowledge, you might look at &quot;bug algorithms.&quot; In particular, here's a simple algorithm, assuming the environment is bounded.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;From the start position, move up and left until you reach the upper-left corner of the environment. If you encounter an obstacle first, you must travel around it. You know something is an obstacle if it can be circumnavigated (bump and move).&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;From the upper left, move right until you encounter the boundary. Then move down and left (We're doing a boustrophedon of the entire space).&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;When you are on a left-right line and encounter an obstacle, you have two options.  (i) We can circumnavigate until we reach the left-right line we are trying to cover, then continue.  (ii), We can turn around and cover a new left-right line until we find our way past the obstacle or end up in this situation again.  I'll illustrate. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://www.jvanderhook.info/images/bou_cart2.png&quot; height=&quot;300&quot; alt=&quot;Option 2&quot;&gt;&#xA;&lt;img src=&quot;http://www.jvanderhook.info/images/bou_cart.png&quot; height=&quot;300&quot; alt=&quot;Option 2&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On the left, we move around the obstacle until we can return to the &quot;line&quot; we were trying to follow. On the right, we continue covering the (smaller) area on the one side of the obstacle.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The advantage of the first method is you always map out the obstacle completely before you make a decision about how to get around it, thus you can take the shorter path. The advantage of the second method is you don't have to get around the obstacle at all, you can just proceed to cover the area you are in. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Note that this defines your boustrophedon decomposition in an online way&lt;/em&gt;: You cover the area between the obstacles or between the obstacles and the boundary.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, as far as I know, the first method is easier to analyze. The more complicated algorithms (like BFS, etc), are chosen either because the environment is unbounded (you don't want to spend forever looking for a boundary), or there is a really nasty obstacle in the way that basically partitions the environment.  Why is this bad? look at this example:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://www.jvanderhook.info/images/bou_cart3.png&quot; height=&quot;300&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Moving left-right, then circling each obstacle produces &lt;em&gt;way&lt;/em&gt; too many covers of the small parts between each obstacle. In fact, without global path planning, you can make this as bad as the resolution of your grid by placing these columns 1 px wide, as tall as the entire environment and 1 px apart. Then you'd have to move around the obstacle each time you hit it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is why I asked if you had some idea of where you were in the environment or could do global path planning. But the &lt;em&gt;online&lt;/em&gt; vs &lt;em&gt;offline&lt;/em&gt; discussion and optimal algorithms for this is not what you really wanted.&lt;/p&gt;&#xA;" OwnerUserId="163" LastEditorUserId="163" LastEditDate="2013-02-21T04:37:49.780" LastActivityDate="2013-02-21T04:37:49.780" CommentCount="2" />
  <row Id="959" PostTypeId="2" ParentId="2" CreationDate="2013-02-21T02:45:21.020" Score="2" Body="&lt;p&gt;Don't, instead get yourself some &lt;a href=&quot;http://www.pololu.com/catalog/category/51&quot; rel=&quot;nofollow&quot;&gt;decent motors&lt;/a&gt; and drive them via an h-bridge like you'll find on this &lt;a href=&quot;http://arduino.cc/en/Main/ArduinoMotorShieldR3&quot; rel=&quot;nofollow&quot;&gt;motor shield&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/fNMxg.jpg&quot; alt=&quot;Pololu motors&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/6uKlD.jpg&quot; alt=&quot;Arduino Motor Shield&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="35" LastActivityDate="2013-02-21T02:45:21.020" />
  <row Id="960" PostTypeId="2" ParentId="922" CreationDate="2013-02-21T02:51:53.533" Score="2" Body="&lt;p&gt;With all you're going to invest in your robot, it's a better idea to start off with a more solid drive train than a servo.  Take a look at a DC motor with an integrated gearbox and start from there.  Your servo approach won't be as energy efficient, performant, and it won't last as long.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A great reference to start with is &lt;a href=&quot;http://rads.stackoverflow.com/amzn/click/0071408509&quot; rel=&quot;nofollow&quot;&gt;Building Robot Drive Trains&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/wREwW.jpg&quot; alt=&quot;Pololu gear motor&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/h0MKD.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="35" LastActivityDate="2013-02-21T02:51:53.533" CommentCount="2" />
  <row Id="961" PostTypeId="2" ParentId="939" CreationDate="2013-02-21T02:57:20.777" Score="3" Body="&lt;p&gt;Put some value on your time and on system reliability.  You're increasing design time &amp;amp; failure points with this approach.  Good small gear motors are pretty cheap to start with, it's a lot more valuable to have a working robot that's reliable than a broken or unfinished robot on the shelf.&lt;/p&gt;&#xA;" OwnerUserId="35" LastActivityDate="2013-02-21T02:57:20.777" />
  <row Id="962" PostTypeId="2" ParentId="897" CreationDate="2013-02-21T06:55:02.840" Score="2" Body="&lt;p&gt;And for the 'I'd rather be designing the sensors and grippers' of us, consider a ready made motor shield for Arduino such as:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.pololu.com/catalog/product/2504&quot; rel=&quot;nofollow&quot;&gt;Polulu Zumo Shield&lt;/a&gt; (1.2 amp motors) or the &lt;a href=&quot;http://arduino.cc/en/Main/ArduinoMotorShieldR3&quot; rel=&quot;nofollow&quot;&gt;Arduino Motor Shield&lt;/a&gt; (2 amp motors) or the &lt;a href=&quot;http://a.pololu-files.com/picture/0J4024.600.jpg?f1bcdd7324bf6307a61598052a9cede0&quot; rel=&quot;nofollow&quot;&gt;Polulu Dual Motor Driver Shield&lt;/a&gt; (3.0 amp motors).&#xA;&lt;img src=&quot;http://i.stack.imgur.com/aQUEm.jpg&quot; alt=&quot;Polulu Zumo Shield&quot;&gt;&#xA;&lt;img src=&quot;http://i.stack.imgur.com/FHdyt.jpg&quot; alt=&quot;Arduino Motor Shield&quot;&gt;&#xA;&lt;img src=&quot;http://i.stack.imgur.com/TI6SZ.jpg&quot; alt=&quot;Polulu Dual Motor Driver Shield&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="35" LastActivityDate="2013-02-21T06:55:02.840" />
  <row Id="963" PostTypeId="1" CreationDate="2013-02-21T08:09:56.070" Score="5" ViewCount="104" Body="&lt;p&gt;I asked this question on &lt;a href=&quot;http://answers.ros.org/question/53784/simulated-kinect-rotation-around-x-bug/&quot;&gt;answers.ros.org&lt;/a&gt; and &lt;a href=&quot;http://answers.gazebosim.org/question/1177/simulated-kinect-rotation-around-x-bug/&quot;&gt;gazebo.ros.org&lt;/a&gt; but still haven't got any answer. I'm posting my question here with the hope someone can help me.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In our robot, the Kinect can be mounted on the side of the arm, as shown in the screenshot below. When running the simulation in Fuerte, I found this weird behaviour. As you can observe on the image, the point cloud does not match the robot model (we see a partial image of the hand/arm at the bottom left of the screenshot, which should be on the robot model).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://answers.ros.org/upfiles/13597242445897604.png&quot; alt=&quot;Rotate Kinect&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As soon as I rotate the kinect against its X axis (so that the kinect is horizontal as you can see on the second screenshot), then the point cloud and robot model are aligned properly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://answers.ros.org/upfiles/13596283675382491.png&quot; alt=&quot;Horizontal Kinect&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The kinect xacro and dae are the one from the turtlebot. I'm simply attaching them with a rotation:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;joint name=&quot;base_camera_joint&quot; type=&quot;fixed&quot;&amp;gt;&#xA;  &amp;lt;origin  xyz=&quot;0.01216 0.1713 0.433&quot;&#xA;       rpy=&quot;-${M_PI/2} ${M_PI/4} -${M_PI/12}&quot; /&amp;gt; &#xA;  &amp;lt;!-- This -pi/2 in origin rpy is the offending parameter --&amp;gt;&#xA;&#xA;  &amp;lt;parent link=&quot;shadowarm_trunk&quot;/&amp;gt;&#xA;  &amp;lt;child link=&quot;camera_link&quot; /&amp;gt;&#xA;&amp;lt;/joint&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;The code can be seen on github.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any help is greatly appreciated!&lt;/p&gt;&#xA;" OwnerUserId="114" LastActivityDate="2013-03-24T09:51:05.430" Title="Simulated kinect rotation around X [gazebo bug?]" Tags="&lt;kinect&gt;&lt;ros&gt;&lt;simulator&gt;" AnswerCount="1" />
  <row Id="964" PostTypeId="1" AcceptedAnswerId="966" CreationDate="2013-02-21T13:50:43.330" Score="6" ViewCount="319" Body="&lt;p&gt;In the prediction step of EKF localization, linearization must be performed and (as mentioned in &lt;a href=&quot;http://books.google.co.uk/books/about/Probabilistic_Robotics.html?id=k_yOQgAACAAJ&amp;amp;redir_esc=y&quot; rel=&quot;nofollow&quot;&gt;Probabilistic Robotics [THRUN,BURGARD,FOX]&lt;/a&gt; page 206) the Jacobian matrix when using velocity motion model, defined as&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$\begin{bmatrix} x \\ y \\ \theta \end{bmatrix}' = \begin{bmatrix} x \\ y \\ \theta \end{bmatrix} + \begin{bmatrix} \frac{\hat{v}_t}{\hat{\omega}_t}(-\text{sin}\theta + \text{sin}(\theta + \hat{\omega}_t{\Delta}t)) \\ \frac{\hat{v}_t}{\hat{\omega}_t}(\text{cos}\theta - \text{cos}(\theta + \hat{\omega}_t{\Delta}t)) \\ \hat{\omega}_t{\Delta}t \end{bmatrix}$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;is calculated as &lt;/p&gt;&#xA;&#xA;&lt;p&gt;$G_{T}= \begin{bmatrix}&#xA;  1 &amp;amp; 0 &amp;amp; \frac{υ_{t}}{ω_{t}}(-cos {μ_{t-1,θ}} + cos(μ_{t-1,θ}+ω_{t}Δ{t})) \\&#xA;  0 &amp;amp; 1 &amp;amp; \frac{υ_{t}}{ω_{t}}(-sin {μ_{t-1,θ}} + sin(μ_{t-1,θ}+ω_{t}Δ{t})) \\&#xA;  0 &amp;amp; 0 &amp;amp; 1&#xA; \end{bmatrix}$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Does the same apply when using the odometry motion model (described in the same book, page 133), where robot motion is approximated by a rotation $\hat{\delta}_{rot1}$, a translation $\hat{\delta}$ and a second rotation $\hat{\delta}_{rot2}$ ? The corresponding equations are:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$\begin{bmatrix} x \\ y \\ \theta \end{bmatrix}' = \begin{bmatrix} x \\ y \\ \theta \end{bmatrix} + \begin{bmatrix} \hat{\delta}\text{cos}(\theta + \hat{\delta}_{rot1}) \\ \hat{\delta}\text{sin}(\theta + \hat{\delta}_{rot1}) \\ \hat{\delta}_{rot1} + \hat{\delta}_{rot2} \end{bmatrix}$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In which case the Jacobian is&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$G_{T}= \begin{bmatrix}&#xA;  1 &amp;amp; 0 &amp;amp; -\hat{\delta} sin(θ + \hat{\delta}_{rot1}) \\&#xA;  0 &amp;amp; 1 &amp;amp; -\hat{\delta} cos(θ + \hat{\delta}_{rot1}) \\&#xA;  0 &amp;amp; 0 &amp;amp; 1&#xA; \end{bmatrix}$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is it a good practise to use odometry motion model instead of velocity for mobile robot localization?&lt;/p&gt;&#xA;" OwnerUserId="164" LastEditorUserId="95" LastEditDate="2013-02-21T19:37:59.953" LastActivityDate="2013-02-21T19:56:16.600" Title="Extended Kalman Filter using odometry motion model" Tags="&lt;localization&gt;&lt;kalman-filter&gt;" AnswerCount="3" FavoriteCount="1" />
  <row Id="965" PostTypeId="1" CreationDate="2013-02-21T16:46:48.970" Score="1" ViewCount="182" Body="&lt;p&gt;I'm having some technical problems... I'm trying to use Firmata for arduino but over nrf24, not over Serial interface. I have tested nRF24 communication and it's fine. I have also tested Firmata over Serial and it works. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Base device is simple &quot;serial relay&quot;. When it has data available on Serial, read it and send it over &lt;a href=&quot;http://maniacbug.github.com/RF24Network/index.html&quot; rel=&quot;nofollow&quot;&gt;nRF24 network&lt;/a&gt;. If there is data available from network, read it and send it through Serial.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Node device is a bit complex. It has custom &lt;a href=&quot;https://github.com/arduino/Arduino/tree/master/libraries/Firmata&quot; rel=&quot;nofollow&quot;&gt;Standard Firmata&lt;/a&gt; where I have just added write and read override. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/nEj0s.png&quot; alt=&quot;Diagram&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Read override id handeled in &lt;code&gt;loop&lt;/code&gt; method in this way:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;while(Firmata.available())&#xA;    Firmata.processInput();&#xA;&#xA;// Handle network data and send it to Firmata process method&#xA;while(network.available()) {&#xA;    RF24NetworkHeader header;&#xA;    uint8_t data;&#xA;    network.read(header, &amp;amp;data, sizeof(uint8_t));&#xA;    Serial.print(data, DEC); Serial.print(&quot; &quot;);&#xA;    Firmata.processInputOverride(data);&#xA;    BlinkOnBoard(50);&#xA;}&#xA;&#xA;currentMillis = millis();&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Firmata &lt;code&gt;processInputOverrride&lt;/code&gt; is little changed method of &lt;code&gt;processInput&lt;/code&gt; where &lt;code&gt;processInput&lt;/code&gt; reads data directly from &lt;code&gt;FirmataSerial&lt;/code&gt;, and in this method we pass data down to method from network. This was tested and it should work fine.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Write method is overloaded in a different way. In &lt;code&gt;Firmata.cpp&lt;/code&gt; I have added an method pointer that can be set to a custom method and used to send data using that custom method. I have then added custom method call after each of the &lt;code&gt;FirmataSerial.write()&lt;/code&gt; call:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;Firmata.h&#xA;...&#xA;size_t (*firmataSerialWriteOverride)(uint8_t);&#xA;...&#xA;&#xA;void FirmataClass::printVersion(void) {&#xA;  FirmataSerial.write(REPORT_VERSION);&#xA;  FirmataSerial.write(FIRMATA_MAJOR_VERSION);&#xA;  FirmataSerial.write(FIRMATA_MINOR_VERSION);&#xA;  Firmata.firmataSerialWriteOverride(REPORT_VERSION);&#xA;  Firmata.firmataSerialWriteOverride(FIRMATA_MAJOR_VERSION);&#xA;  Firmata.firmataSerialWriteOverride(FIRMATA_MINOR_VERSION);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I have then set the overrided write method to a custom method that just writes byte to network instead of &lt;code&gt;Serial&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;size_t ssignal(uint8_t data) {&#xA;    RF24NetworkHeader header(BaseDevice);&#xA;    network.write(header, &amp;amp;data, sizeof(uint8_t));&#xA;}&#xA;&#xA;void setup() {&#xA;...&#xA;Firmata.firmataSerialWriteOverride = ssignal;&#xA;...&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;All stages pass right (I guess) and then I don't get any response from Node when I request pin states&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;...&#xA;&amp;lt; f0 6a 7f 7f 7f ... 7f 0 1 2 3 4 5 6 7 8 9 a b c d e f f7 // analog mapping&#xA;&amp;gt; f0 6d 0 f7 // sysex request pin 0 state and value&#xA;&amp;gt; f0 6d 1 f7 &#xA;&amp;gt; f0 6d 2 f7&#xA;...&#xA;&amp;gt; f0 6d 45 f7&#xA;// And I wait for response...&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;There is no response. Any ideas why would that happen? Node receive all messages correctly and code for handling pin states exist.&lt;/p&gt;&#xA;" OwnerUserId="933" LastEditorUserId="933" LastEditDate="2013-02-21T21:25:05.407" LastActivityDate="2013-02-21T21:25:05.407" Title="Firmata over nRF24" Tags="&lt;arduino&gt;&lt;serial&gt;&lt;c++&gt;" CommentCount="2" />
  <row Id="966" PostTypeId="2" ParentId="964" CreationDate="2013-02-21T16:55:24.313" Score="5" Body="&lt;p&gt;You have asked two questions. As I interpret them they are:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Is it necessary to linearize the odometry motion model for use with an extended Kalman filter (EKF)?&lt;/li&gt;&#xA;&lt;li&gt;Is it better to use the odometry motion model instead of the velocity motion model.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Regarding question 1, the short answer is &quot;yes.&quot; The guarantees of the Kalman filter (KF) only apply to linear systems. We linearize a non-linear system in hopes of retaining some of those guarantees for non-linear systems. In fact linearizing the non-linear components of a system (i.e. the motion model and/or the observation model) is the very thing that differentiates KFs and EFKs.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Regarding question 2, Dr. Thrun argues on page 132 of Probabilistic Robotics that &quot;[p]ractical experience suggests that odometry, while still erroneous, is usually more accurate than velocity.&quot; However I would not interpret this statement as an argument for supplanting the velocity model. If you have both velocity and odometric information then it is generally better to use both sources of information.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-02-21T16:55:24.313" />
  <row Id="967" PostTypeId="2" ParentId="964" CreationDate="2013-02-21T18:46:10.447" Score="0" Body="&lt;p&gt;In my experience, the answer to your last question is &quot;yes.&quot; I've had much more luck using odometry instead of dynamic (velocity) prediction. However, I've never used the motion model you describe (from Thrun's book). Instead, I've used the model I described &lt;a href=&quot;http://robotics.stackexchange.com/a/134/163&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="163" LastEditorUserId="163" LastEditDate="2013-02-21T19:35:36.100" LastActivityDate="2013-02-21T19:35:36.100" />
  <row Id="968" PostTypeId="2" ParentId="964" CreationDate="2013-02-21T19:56:16.600" Score="0" Body="&lt;p&gt;To your first question: &quot;Does the same apply when using the odometry motion model?&quot;, the answer is Yes.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The the EKF is pretty much the same thing as the KF, with the addition of the linearization step.  What you are linearizing here is the motion model, whatever model that is.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;For your second question: &quot;Is it a good practise to use odometry motion model instead of velocity for mobile robot localization?&quot;: I think the answer is 'it depends.'  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are using a data set that has velocity information and the localization is good enough for your purposes, then the simplicity of that model is probably preferred.  If you are directly controlling the robot and have access to the odometry information, then you're likely to get a better result.  &lt;/p&gt;&#xA;" OwnerUserId="502" LastActivityDate="2013-02-21T19:56:16.600" />
  <row Id="969" PostTypeId="2" ParentId="963" CreationDate="2013-02-22T09:18:41.500" Score="1" Body="&lt;p&gt;An answer from David Butterworth which solved my problem! Thanks David.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;I found that if you modify the visual/collision mesh to be aligned with your joint origin, then it's okay.&#xA;Don't do extra translations/rotations of the mesh from within your URDF, because that is broken.&#xA;The orientation of the sensor data should depend on the Gazebo macro, but there should be only translations in there, with 2 joint rotations for the extra pair of camera frames.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My Gazebo macro is based on the PR2 one, but with the visual/collision meshes fixed and re-scaled as per above.&#xA;The end result is that any translation/rotation is only done at the head_mount_kinect joint that orientates everything else, and you can successfully pitch the sensor up-down or vertically.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm guessing that in your situation, the PointCloud data is actually in the correct place, but because of the bug with the meshes, the visual model is in the wrong place.&lt;/p&gt;&#xA;" OwnerUserId="114" LastActivityDate="2013-02-22T09:18:41.500" />
  <row Id="970" PostTypeId="1" AcceptedAnswerId="971" CreationDate="2013-02-23T07:23:28.393" Score="7" ViewCount="237" Body="&lt;p&gt;Im in the process of making a robot which requires 12 3x10mm cylindric magnets for the construction. They are 30mm from the center of the robot where I plan to have the IMU. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I was thinking about using MPU-6050. Do magnets affect the values? If yes, is there a solution for it? like maybe I could have a shield or something around the IMU?&lt;/p&gt;&#xA;" OwnerDisplayName="user697" LastEditorDisplayName="user697" LastEditDate="2013-02-23T07:31:14.593" LastActivityDate="2013-05-08T03:12:20.987" Title="Do magnets affect IMU values?" Tags="&lt;sensors&gt;&lt;imu&gt;" AnswerCount="3" FavoriteCount="1" />
  <row Id="971" PostTypeId="2" ParentId="970" CreationDate="2013-02-23T10:00:18.053" Score="8" Body="&lt;p&gt;If permanent magnets are rigidly mounted at a fixed distance from the IMU, they have no effect on the accelerometers and gyros inside the MPU-6050.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can optionally connect the MPU-6050 to an external magnetometer.&#xA;(It's used to cancel out yaw drift).&#xA;That magnetometer, if you have one, will be affected by magnets.&#xA;In theory you could shield the magnetometer by wrapping it in &lt;a href=&quot;http://en.wikipedia.org/wiki/mu-metal&quot;&gt;mu-metal&lt;/a&gt;,&#xA;but that would also shield the magnetometer from the magnetic field of Earth, making the magnetometer useless -- better to leave out the magnetometer and the shield entirely.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Maybe you will be lucky and the magnets will merely shift the magnetometer values, without making it peg out.&#xA;If so, there are various ways of calibrating-out this fixed shift, and the IMU could work as well as it would have worked without those magnets.&#xA;(It's not clear to me if the MPU-6050 in particular supports such calibration).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm assuming your magnets have some purpose, yes?&#xA;Generally people use magnets in ways where the magnetic field in one small region is actually used, and any &quot;stray&quot; magnetic field elsewhere doesn't help.&#xA;There are several ways to &quot;concentrate&quot; the magnetic field,&#xA;making it stronger where it is actually useful, and making the stray fields weaker.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Counter-intuitively, it is possible to &lt;em&gt;add&lt;/em&gt; more magnets to your system in such a way that the total magnetic field, at the magnetometer, from all the magnets is almost perfectly cancelled out, leaving only the Earth's magnetic field.&#xA;(This often makes the magnetic field &lt;em&gt;elsewhere&lt;/em&gt; stronger).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, a &lt;a href=&quot;http://en.wikipedia.org/wiki/Halbach_array&quot;&gt;Halbach array&lt;/a&gt; arranges permanent magnets in a way that makes the field stronger on one side, while cancelling the field to almost zero on the other side.&lt;/p&gt;&#xA;" OwnerUserId="187" LastActivityDate="2013-02-23T10:00:18.053" />
  <row Id="972" PostTypeId="2" ParentId="970" CreationDate="2013-02-24T04:49:28.030" Score="3" Body="&lt;p&gt;Hard to tell in this exact case.  I looked up the MPU-6050 specs and I am unsure whether it integrates a digital compass to combat gyro drift.  On Sparkfun, it refers to it being a '9 axis fusion algorithm' which implies compass (three axis each for gyro, accel, and magento) but elsewhere it only refers to gyro and accel.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I was doing some related work with a Pololu MinIMU-9 which has all nine axis but requires you to implement the IMU integration logic in code.  What I found with that part was that placing it within 10 cm of the drive motors was causing the magnometer to be very difficult to use.  On one hand you can do a calibration and remove the static magnetic fields from your reading (assuming your IMU routines are coded for this).  On the other hand, I was finding that the strength of the static motor fields was so strong that the comparatively weaker Earth's magnetic fields were down in the 'noise'.  I was having to tune down the flux sensitivity to handle the drive field so my sensitivity to the Earth's field also dropped.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This fix was to ensure the magnometer was sufficiently far away from the drives that their fields were sufficiently smaller than the Earth's fields.  In my case I had to move the IMU sensor about 50 cm away from the motors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So in summary, 'it depends' :-)  It depends on your sensors, the strength of your local magnetic fields, and whether you can calibrate out the local fields in your IMU logic.&lt;/p&gt;&#xA;" OwnerUserId="35" LastActivityDate="2013-02-24T04:49:28.030" />
  <row Id="974" PostTypeId="2" ParentId="948" CreationDate="2013-02-24T11:55:12.003" Score="2" Body="&lt;p&gt;If you have an electric motor which can drive a linear system in two directions, essentially it is its own antagonist.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Edit:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;muscles, as well as single-acting pneumatic cylinders, can only provide force in one direction, so they are arranged in agonist/antagonist pairs.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A motor, perhaps running a belt, is capable of pulling the belt in each direction, thereby providing motive force to what you might consider to be the agonist belt in one direction and the antagonist belt in the other.&lt;/p&gt;&#xA;" OwnerUserId="928" LastEditorUserId="928" LastEditDate="2013-02-24T15:02:47.147" LastActivityDate="2013-02-24T15:02:47.147" CommentCount="2" />
  <row Id="975" PostTypeId="1" AcceptedAnswerId="1152" CreationDate="2013-02-24T12:18:01.820" Score="7" ViewCount="168" Body="&lt;p&gt;I know that temperature influences the characteristics of semiconductors and other materials, but we know how and can take that into account. Furthermore, lower temperatures makes electronics more efficient, sometimes even superconducting.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I remember reading somewhere that engineers building Curiosity even considered low temperature electronics for the motors driving the wheels but still decided against it in the end.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Why is it, apparently, so hard to build components with operating temperatures matching those on Mars, Europa, or in space?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Edit:&lt;/strong&gt; None of the answers address my question thus far. I know that all parts, both electronic and mechanical, and greases and so on have relatively narrow working temperatures. My question is, why don't we build special cold metals and cold greases and cold chips that have their narrow operating temperature band at -100 C or whatever?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Valid answers could be: it's too expensive, insufficient science has been done to determine materials appropriate for such cold, such cold materials cannot be manufactured in the sweltering heat of planet Earth.&lt;/p&gt;&#xA;" OwnerUserId="141" LastEditorUserId="141" LastEditDate="2013-03-30T19:49:07.267" LastActivityDate="2013-04-03T12:08:58.557" Title="Why do space probes need heating?" Tags="&lt;heat-management&gt;&lt;cooling&gt;" AnswerCount="6" CommentCount="4" />
  <row Id="976" PostTypeId="1" CreationDate="2013-02-24T12:24:30.333" Score="6" ViewCount="281" Body="&lt;p&gt;I have a small quadruped with three degree of freedom legs which I have been working on: &lt;a href=&quot;http://www.thingiverse.com/thing:50125&quot; rel=&quot;nofollow&quot;&gt;3DOF Mini Quadruped&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My original code for it was a simple servo controller on the arduino, and Scala code which would send servo commands over the wire.  I did all the Inverse Kinematics and Gait logic in Scala, and got it to walk: &lt;a href=&quot;https://www.youtube.com/watch?v=VsHNA3oLXC8&quot; rel=&quot;nofollow&quot;&gt;3dof quadruped first gait&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My Gait logic in Scala was somewhat naive; it depended on the legs being in the right position at the beginning (one side extended fore and aft, the other side in toward each other).  The logic was simply translate all four feet backward by 1mm along y, and whenever a coxa angle became excessively rearward, stop and perform a little routine where that foot is lifted 10mm in z, then translated forward 60mm along y, and set back down.  Naive, but effective.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now, I have rewritten my IK code in arduino C, and I'm trying to decide how to move forward with the Gait dynamics.  I've had a hard time finding good, easy to understand resources about gaits.  I do have some knowledge about the difference between dynamically stable gaits (like creep gaits) where the body is a stable tripod at all times and dynamically unstable gaits (walking, trotting), where two legs are off the ground at a time and the body is essentially falling forward into the advancing leg.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I had some thoughts about state machines and trying to calculate whether the body center falls within a triangle made by the remaining feet to decide which foot was safe to lift, but I'm not sure if these are ideas worth exploring.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I know this is kind of an overly general question, but I'm interested to see how other people have attacked this problem, and about all I've been able to find are research papers.&lt;/p&gt;&#xA;" OwnerUserId="928" LastEditorUserId="37" LastEditDate="2013-12-09T22:53:24.030" LastActivityDate="2013-12-09T22:53:24.030" Title="What is a good approach to a Quadruped Gait?" Tags="&lt;mobile-robot&gt;&lt;walk&gt;" AnswerCount="1" CommentCount="2" FavoriteCount="4" />
  <row Id="977" PostTypeId="2" ParentId="975" CreationDate="2013-02-24T12:45:47.547" Score="5" Body="&lt;p&gt;Because the parts work reliably only in a limited range of temperatures. If the temperature is out of the range, the chips may not work correctly or even not work at all.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Probes usually also have some kind of backup battery and batteries lose capacity really fast if they get colder than 0°C. It simply is easier and more efficient to keep the battery and electronics warm than to compensate for different characteristics.&lt;/p&gt;&#xA;" OwnerUserId="890" LastActivityDate="2013-02-24T12:45:47.547" />
  <row Id="978" PostTypeId="2" ParentId="976" CreationDate="2013-02-24T21:55:27.547" Score="2" Body="&lt;p&gt;The gait you've got is actually not too bad, although the feet don't have enough traction, so it's hard to see how good it really is.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm not sure about your terminology of dynamically stable gaits. As I've always understood it, the two tripod style gait is known as a statically stable gait, while a good walking biped like &lt;a href=&quot;http://www.bostondynamics.com/robot_petman.html&quot; rel=&quot;nofollow&quot;&gt;Petman&lt;/a&gt; uses a dynamically stable gait. Never heard of a dynamically unstable gait. That sounds more like drunkenness.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Two legs on the ground is probably the lower limit for this design of robot. Generally, it's easier to make this work with tall, humanoid robots, which take a long time to fall over. Wide flat robots need to lift and place their feet pretty quickly if they aren't leaving many on the floor. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;But how to develop a gair for your robot. Firstly, you should decide what you want to achieve from the gait. Are you looking for maximum speed on a flat surface, or maximum stability on uneven surfaces?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If your goal is stability, then I certainly think it's worth having the robot be aware of its centre of gravity in relation to its feet. To help it know this, it might even be worth adding some force sensors to its feet so it can calculate this easily.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If your goal is maximum speed only, then I'd simply concentrate on funding an optimum gait pattern. This is harder to do. There are two good ways to approach it:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;Modelling. Create a comprehensive computer model of the robot, including mass, stiffness, torque, etc. Use this model to fully understand the dynamic behaviour.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Trial and error. You can do this the hard way, programming in random gaits, adjusting them on a hunch and measuring their performance. Try making it walk both forwards, and diagonally. Or you can use a &lt;a href=&quot;http://en.wikipedia.org/wiki/Genetic_algorithm&quot; rel=&quot;nofollow&quot;&gt;genetic algorithm&lt;/a&gt; to help you automatically search for better gaits. The difficulty of using a GA is that you need to have some way to automatically measure the performance of the gait.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;A third way, is to make the robot into a scientist who runs concious experiments on itself to validate hypotheses about itself, and work out how to walk, like &lt;a href=&quot;https://www.youtube.com/watch?v=iNL5-0_T1D0&quot; rel=&quot;nofollow&quot;&gt;Cornell University's starfish robot&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2013-02-24T21:55:27.547" />
  <row Id="979" PostTypeId="1" CreationDate="2013-02-24T23:02:17.747" Score="2" ViewCount="1099" Body="&lt;p&gt;I'm building a quadcopter and have discovered that most ESC have a built-in BEC, but I was wondering if it wouldn't be better to use only one.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What if I delivered power to my four ESC with a unique BEC ? Would that work ?&#xA;I think this would be easier to configure (you have to set it up only once for the four ESC) and it would prevent each ESC from having it's own behavior.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Am I doing it wrong ?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here is an image of what I'm talking about :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://img837.imageshack.us/img837/8199/escbec.png&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://img837.imageshack.us/img837/8199/escbec.png&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Given the &lt;a href=&quot;http://robotics.stackexchange.com/a/982/37&quot;&gt;answer by Ian McMahon&lt;/a&gt; it appears that this schema is not the right thing to do, since I had misunderstood the role of BECs.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So would the right schema would look like this ?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://img43.imageshack.us/img43/6963/escbec2.png&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://img43.imageshack.us/img43/6963/escbec2.png&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm still not sure if I'm getting it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Do I need 4 ESCs with integrated BECs and connect all three cables to flight controller ?&lt;/p&gt;&#xA;" OwnerUserId="943" LastEditorUserId="943" LastEditDate="2013-02-26T14:46:33.380" LastActivityDate="2013-02-26T14:46:33.380" Title="One BEC for multiple ESC (Quadcopter)" Tags="&lt;electronics&gt;&lt;quadcopter&gt;&lt;bec&gt;&lt;esc&gt;" AnswerCount="1" CommentCount="9" FavoriteCount="1" />
  <row Id="980" PostTypeId="2" ParentId="848" CreationDate="2013-02-25T11:10:33.140" Score="2" Body="&lt;p&gt;As mentioned above 7-bits means possibility of 128 slave devices attached to the same i2c bus.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This loop is run 128 times(0-127) to determine how many slaves are present on the bus by asking them to respond(via ack) and prints whenever a device presence is detected. &lt;/p&gt;&#xA;" OwnerUserId="944" LastActivityDate="2013-02-25T11:10:33.140" CommentCount="1" />
  <row Id="982" PostTypeId="2" ParentId="979" CreationDate="2013-02-25T14:24:42.023" Score="1" Body="&lt;p&gt;typically you want to power the ESCs directly from the battery, and use a BEC to power 5v electronics such as your controller.  However, a lot of ESCs have the ability to provide 5v power back to the controller over the 5v line on their control cable (servo-style 3 pin cable).  In that case, you wouldn't need to use a BEC at all, but it's possible you might have issues with more than one ESC all trying to supply power on the 5v line with them all hooked together.  For maximum flexibility, it might make sense to select an ESC which has switchable BEC capability.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EditEdit:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Apparently my project experience is unwelcome, removing.&lt;/p&gt;&#xA;" OwnerUserId="928" LastEditorUserId="928" LastEditDate="2013-02-26T14:16:56.547" LastActivityDate="2013-02-26T14:16:56.547" CommentCount="4" />
  <row Id="984" PostTypeId="1" AcceptedAnswerId="992" CreationDate="2013-02-25T21:13:25.777" Score="2" ViewCount="41" Body="&lt;p&gt;Here is the background. I am trying to write a service for the HiTechnic prototype board. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Using the Appendix 2 from the blue tooth developers kit from Lego's site I am able to understand what is going on with this service I am trying to build however the response I get is always 221 = 0xDD = &quot;Communication Bus Error&quot; or 32 = 0x20 = &quot;Pending communication transaction in progress&quot;. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I figured out that the HiTechnic prototype board is using &lt;a href=&quot;http://refriedgeek.blogspot.com/2013/02/connecting-to-hitechnic-prototype-board.html&quot; rel=&quot;nofollow&quot;&gt;i2c address 0x08&lt;/a&gt; so I modified the brick code to use that address instead of the standard 0x02. It goes out and configures the device, I get a response and then it does an LSWrite which seems OK then I get a get an error when it does the LSGetStatus. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I know this thing works - I can bit bang it all day long with an Arduino but I only did that to test it out - &lt;a href=&quot;http://refriedgeek.blogspot.com/2013/02/connecting-to-hitechnic-prototype-board.html&quot; rel=&quot;nofollow&quot;&gt;see this link&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am not sure what else to try. Here is how I am setting it up in the connect to brick handler. &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt; pxbrick.Registration registration = new pxbrick.Registration(&#xA;                new LegoNxtConnection(LegoNxtPort.Sensor1),&#xA;                LegoDeviceType.DigitalSensor,&#xA;                Contract.DeviceModel,&#xA;                Contract.Identifier,&#xA;                ServiceInfo.Service,&#xA;                _state.Name);&#xA;        Debugger.Break();&#xA;        // Reserve the port&#xA;        LogInfo(&quot;ConnectToBrickHandler&quot;);&#xA;        yield return Arbiter.Choice(_legoBrickPort.ReserveDevicePort(registration),&#xA;            delegate(pxbrick.AttachResponse reserveResponse)&#xA;            {&#xA;                Debugger.Break();&#xA;                if (reserveResponse.DeviceModel == registration.DeviceModel)&#xA;                {&#xA;                    registration.Connection = reserveResponse.Connection;&#xA;                }&#xA;            },&#xA;            delegate(Fault f)&#xA;            {&#xA;                Debugger.Break();&#xA;                fault = f;&#xA;                LogError(&quot;#### Failed to reserve port&quot;);&#xA;                LogError(fault);&#xA;                registration.Connection.Port = LegoNxtPort.NotConnected;&#xA;            });&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I have also tried setting AnyPort as well so that it will hit the TestPortForI2CSensorHandler that just does what I explained before - it seems to set the mode fine and then gets an error when it tries to read the device information. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here is the data. - this first part is the set input more - both the message and response - You can see it is totally fine. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Send command data. &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;0 &#xA;5&#xA;0 &#xA;11 &#xA;0 &#xA;receive command data. (_commState.SerialPort.Read(receiveData, 0, packetSize);) &#xA;2 &#xA;5 &#xA;0&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Then it does an LSWrite - everything still seems fine... You can see I have modified the NxtComm code to use 0x08 instead of 0x02 which it would normally use, then the last byte is also 0x08 which is the starting address of the manufacturer. It's asking for 16 bytes which would be the manufacturer and sensor type. like I said - I know that works I can print that info out using the Arduino.  &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;128 &#xA;15 &#xA;0 &#xA;2 &#xA;16 &#xA;8 // i2c address&#xA;8 //I assume this is what address I want to read from? &#xA;Got response: True Error code Success [02/25/2013 02:20:31]&#xA;-- SendCommandHandler (NxtComm) [02/25/2013 02:20:31]&#xA;--- RequestResponseHandler (NxtComm) [02/25/2013 02:20:31]&#xA;--- CommSendImmediateHandler (NxtComm) [02/25/2013 02:20:31]&#xA;Send command data.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Then it tries to get the status&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;0 &#xA;14 &#xA;0 &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Here is the response... &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt; 2 &#xA;14 &#xA;32 &#xA; 0 &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;It's either 32 or 221. It's making me nuts... &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If anyone has anything that might help me out I would so much appreciate it. At this point I am running out of ideas. I can see what is going on, I can understand the entire transaction but can't seem to figure out why it just errors out like that. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also - just for grins I tried 0x10 which is what they tell you on the HiTechnic website. That gets a response of 2,14,0,0 from the NXT brick - that would indicate there is no data but as I pointed out I can get data using the Arduino. How could I have two different I2C device addresses? &lt;/p&gt;&#xA;" OwnerUserId="803" LastEditorUserId="37" LastEditDate="2013-02-26T13:34:06.260" LastActivityDate="2013-03-01T03:18:23.230" Title="Does anyone know what might be giving me this error coming from an i2c device" Tags="&lt;nxt&gt;&lt;i2c&gt;" AnswerCount="1" CommentCount="0" />
  <row Id="985" PostTypeId="1" AcceptedAnswerId="986" CreationDate="2013-02-26T02:47:45.793" Score="3" ViewCount="177" Body="&lt;p&gt;I was able to find a small ESC for about $12 off of ebay.  If you were designing a robot, would you see that and think?  &lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;\$12 bucks for an ESC that connects to simple pulse-wave interface -&#xA;  sign me up!&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Or would you think:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;\$12 just to control a motor? I could throw together an H-bridge for&#xA;  $0.50 and be done with it.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;My robot in particular actually has two motors and therefor $24 to control the two of them.  But the interface is really easy (plus has the added advantage of being R/C vs computer controlled with a simple change of connectors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Which way would you go?&lt;/p&gt;&#xA;" OwnerUserId="947" LastEditorUserId="947" LastEditDate="2013-02-26T03:15:11.677" LastActivityDate="2013-02-26T04:24:46.223" Title="Which is easier/cheaper: Hbridge vs ESC for controlling a motor?" Tags="&lt;design&gt;&lt;electronics&gt;&lt;wheeled-robot&gt;" AnswerCount="1" />
  <row Id="986" PostTypeId="2" ParentId="985" CreationDate="2013-02-26T04:24:46.223" Score="2" Body="&lt;p&gt;What kind of motors?  ESCs typically are for brushless DC motors, which are electronically commutated DC three phase motors, and you can't run them with an H-bridge. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;That said, ESCs give you a lot of bang for the buck, and they're certainly worth $12 :)&lt;/p&gt;&#xA;" OwnerUserId="928" LastActivityDate="2013-02-26T04:24:46.223" CommentCount="2" />
  <row Id="987" PostTypeId="1" CreationDate="2013-02-27T14:13:33.010" Score="1" ViewCount="321" Body="&lt;p&gt;I have written code to send data from controller to pc through serialport using interrupt&#xA;but it echos garbage value exactly 3 times back.&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;    ISR(USART_RX_vect)&#xA;{&#xA;    unsigned char index = UDR;&#xA;&#xA;    UDR = index;        &#xA;}&#xA;&#xA;void uartInit()&#xA;{&#xA;    UCSRA=0x00;&#xA;    UCSRB=0x18;&#xA;    UCSRC=0x86;&#xA;    UBRRH=0x00;&#xA;    UBRRL=0x67;&#xA;    UCSRB |= (1 &amp;lt;&amp;lt; RXCIE); // Enable the USART Receive Complete interrupt (USART_RXC)&#xA;    _delay_ms(10);&#xA;}&#xA;&#xA;int main(void)&#xA;{&#xA;    uartInit();&#xA;    lcd_init(); &#xA;    sei();&#xA;&#xA;   while(1)&#xA;    {&#xA;     }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;EDIT:&lt;/strong&gt;&#xA;Function used to set baud rate..&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#define FOSC 16000000// Clock Speed&#xA;#define BAUD 9600&#xA;#define MYUBRR FOSC/16/BAUD-1&#xA;&#xA;&#xA;void USART_Init( unsigned int baud )&#xA;{&#xA;/* Set baud rate */&#xA;UBRRH = (unsigned char)(baud&amp;gt;&amp;gt;8);&#xA;UBRRL = (unsigned char)baud;&#xA;/* Enable receiver and transmitter */&#xA;UCSRB = (1&amp;lt;&amp;lt;RXEN)|(1&amp;lt;&amp;lt;TXEN);&#xA;/* Set frame format: 8data, 1stop bit */&#xA;UCSRC = (0&amp;lt;&amp;lt;USBS)|(3&amp;lt;&amp;lt;UCSZ0);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="953" LastEditorUserId="953" LastEditDate="2013-02-28T09:39:00.277" LastActivityDate="2013-10-27T04:02:10.783" Title="problem in serial communication between PC and ATMEGA 8535(AVR)" Tags="&lt;serial&gt;&lt;avr&gt;" AnswerCount="1" CommentCount="8" FavoriteCount="1" />
  <row Id="989" PostTypeId="1" CreationDate="2013-02-28T15:03:18.117" Score="3" ViewCount="86" Body="&lt;p&gt;I am doing Local Localisation with sonar, particle filter (i.e all particles are initially with robot pose).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have grip map of environment. When I execute algorithm in environment (where doors are closed/open), particles are not able to followup the robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I don't have random particles since I know the initial position of the robot exactly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Adding random particle will change the pose of robot (i am find median of particles as robot pose).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any idea/methods how to improve local localisation?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I want to know, do I need random variable if I am doing local localisation? And how do I improve localisation if there are many changes in the map without adding random particles?&lt;/p&gt;&#xA;" OwnerUserId="714" LastEditorUserId="37" LastEditDate="2013-03-05T11:40:05.230" LastActivityDate="2013-03-05T11:40:05.230" Title="Local Localisation with particle filter" Tags="&lt;mobile-robot&gt;&lt;localization&gt;&lt;odometry&gt;&lt;particle-filter&gt;" AnswerCount="1" CommentCount="3" />
  <row Id="991" PostTypeId="2" ParentId="987" CreationDate="2013-03-01T01:31:00.967" Score="1" Body="&lt;p&gt;You are setting the UBRR register incorrectly: it should not directly hold the desired baudrate, but a value that depends on your CPU speed (which you defined as the macro FOSC, but never used) and the baudrate. The exact calculation is described in the &lt;a href=&quot;http://www.atmel.com/images/doc2502.pdf&quot; rel=&quot;nofollow&quot;&gt;ATMega8535 datasheet&lt;/a&gt; (p.147).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;See the &lt;a href=&quot;http://www.josephn.net/avr/avr_ubrr_calculator&quot; rel=&quot;nofollow&quot;&gt;AVR UBRR Calculator&lt;/a&gt; for easy calculation of the proper UBRR register values (note that the calculator assumes U2X = 0, as seen in Table 72, p.173).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;EDIT:&lt;/strong&gt; I just noticed your macro MY_UBRR, sorry about that. Are you calling USART_Init with baud = MY_UBRR? If so, I'll delete this answer.&lt;/p&gt;&#xA;" OwnerUserId="95" LastEditorUserId="95" LastEditDate="2013-03-01T01:36:55.113" LastActivityDate="2013-03-01T01:36:55.113" CommentCount="1" />
  <row Id="992" PostTypeId="2" ParentId="984" CreationDate="2013-03-01T03:18:23.230" Score="0" Body="&lt;p&gt;Triumphant&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Check this out. Under normal circumstances you would configure your sensor by giving it a port. It would look like the following.&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;pxbrick.Registration registration = new pxbrick.Registration(new LegoNxtConnection((LegoNxtPort)_state.SensorPort), &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Well, inside of the NxtBrick code there is a method called TestPortForI2CSensorHandler and reading the code you can see that if you pass in “AnySensorPort” it will try all four ports. Genuis that I am thought! Oh great. I will just let the already created code do the work for me, after all, at that point all I wanted to do was see of the thing worked. Well here is the problem. When you do that it creates a type of I2CReadSensorType inside of the ctor it executes this line of code.&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;ExpectedI2CResponseSize = 16;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;That doesn’t seem to work. OK - not seems, it doesn’t work. It won’t work for the sonsor sensor or any other digital sensor. I assume&#xA; because it’s 0 based, so 16 is actually 17 bytes? I am guessing. At anyrate, I changed it to 15 and low and behold it works. I even went back and tried it with the LEGO sonar sensor. It works to a point - that is to say it actually gets data back but it seems&#xA; like the sensor type data (which is “SuperPr” on the prototype board) is 0xFF for all the bytes. The name manufacturer is indeed set to LEGO though so I know it read data.&#xA; if you change the ExpectedI2CResponseSize  back to 16 it fails.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The other issue I had is that the NxtCommType contains the following. &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;[DataMember, Description(&quot;The default I2C Bus Address of the Ultrasonic or other I2C Sensor.&quot;)]&#xA;public const byte DefaultI2CBusAddress = 0x02;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;For my purposes at the moment I am just flipping it to 0x10 for the prototype board (which oddly enough when connected to my Arduino&lt;/p&gt;&#xA;&#xA;&lt;p&gt;shows up as 0x08 but that is another story). I need to modify things so I can use sensors that have differing i2c addresses but for now I am thrilled!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would love to see someone like Trevor Taylor comment on this as to how it ever worked with 16 as the ExpectedI2CResponseSize.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Awesome!&lt;/p&gt;&#xA;" OwnerUserId="803" LastActivityDate="2013-03-01T03:18:23.230" />
  <row Id="993" PostTypeId="1" CreationDate="2013-03-01T04:00:21.760" Score="4" ViewCount="50" Body="&lt;p&gt;I am looking to augment a GPS/INS solution with a conventional land vehicle (car-like) model. That is, front-wheel steered, rear wheels passive on an axle.  I don't have access to odometry or wheel angle sensors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am aware of the Bicycle Model (e.g. Chapter 4 of &lt;a href=&quot;http://link.springer.com/book/10.1007/978-3-642-20144-8/page/1&quot; rel=&quot;nofollow&quot;&gt;Corke&lt;/a&gt;), but I am not sure how to apply the heading/velocity constraint on the filter.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So my questions are:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Are there any other dynamic models that are applicable to the land vehicle situation, especially if they have the potential to provide better accuracy?&lt;/li&gt;&#xA;&lt;li&gt;Are there any standard techniques to applying such a model/constraint to this type of filter, bearing in mind I don't have access to odometry or wheel angle?&lt;/li&gt;&#xA;&lt;li&gt;Are there any seminal papers on the topic that I should be reading?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="959" LastEditorUserId="350" LastEditDate="2013-03-01T19:23:51.300" LastActivityDate="2013-03-02T22:58:49.710" Title="Conventional Land Vehicle Dynamic Models for GPS/INS augmentation" Tags="&lt;gps&gt;&lt;dynamics&gt;" AnswerCount="1" CommentCount="2" />
  <row Id="994" PostTypeId="1" AcceptedAnswerId="1001" CreationDate="2013-03-01T04:05:48.827" Score="5" ViewCount="114" Body="&lt;p&gt;My team is building a robot to navigate autonomously in an outdoor environment. We recently got a new integrated IMU/GPS sensor which apparently does some extended Kalman filtering on-chip. It gives pitch, roll, and yaw, north, east, and down velocities, and latitude and longitude.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, we also have some encoders attached to our wheels, which provide linear and angular velocities. Before we got this new IMU/GPS sensor, we made our own EKF to estimate our state using the encoders and some other low-cost sensors. We want to use this new sensor's on-chip filter, but also incorporate our encoders into the mix.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there any problem with chaining the filters? What I mean is, we'd use the output of the IMU/GPS sensor's on-chip EKF as an update to our own EKF, just as we use the data read from the encoders as an update to our EKF. It seems reasonable to me, but I was wondering what is usually supposed to be done in this case. &lt;/p&gt;&#xA;" OwnerUserId="181" LastActivityDate="2013-03-02T19:06:07.223" Title="Chaining Kalman filters" Tags="&lt;kalman-filter&gt;&lt;imu&gt;&lt;navigation&gt;" AnswerCount="1" CommentCount="2" FavoriteCount="1" />
  <row Id="995" PostTypeId="2" ParentId="957" CreationDate="2013-03-01T05:51:17.817" Score="4" Body="&lt;p&gt;Depends on what you want to climb on, if it is glass, probably your best bet will be suction, but I have no idea what you will need for normal house walls. Don't forget that many walls will not be able to survive 5kgs of weight that tears down the paint. Also if you want to climb on normal walls, you probably shouldn't use chemical adhesives, as they will leave some form of residue.&lt;/p&gt;&#xA;" OwnerUserId="890" LastActivityDate="2013-03-01T05:51:17.817" CommentCount="1" />
  <row Id="996" PostTypeId="2" ParentId="993" CreationDate="2013-03-01T23:39:15.197" Score="1" Body="&lt;p&gt;When doing filtering, the Kinematic model comes into play &lt;em&gt;only&lt;/em&gt; during the prediction step.  That is, you predict that the next state is one which is reachable given your current kinematic constraints. I'll reiterate: &lt;em&gt;this is not  a hard constraint on the filter output&lt;/em&gt;. It simply makes unreachable states unlikely, with only the granularity available to the 2-D Gaussian distribution.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then, the sensors are used to find which &lt;em&gt;of the predicted states&lt;/em&gt; are likely &lt;em&gt;given given the new information&lt;/em&gt; (GPS, etc). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you &lt;em&gt;must&lt;/em&gt; apply a kinematic model as a &lt;em&gt;constraint&lt;/em&gt; (i.e., we &lt;em&gt;cannot&lt;/em&gt; consider any state outputs which violate the kinematic model), then I know of only one option off hand: Use a particle filter to sample all nearby states, then apply a zero weight to all states which are not reachable given your Kinematics. Note, a particle filter is a general term with lots of different meanings. &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;A particle can represent all positions, $x,y,\theta$, e.g., a grid over the environment. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;A particle can represent all &lt;em&gt;nearby&lt;/em&gt; positions. In this case you sample the kinematic model many times with some noise, and propagate those forward. This implicitly honors the kinematic constraint.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;A particle can represent possible &lt;em&gt;paths&lt;/em&gt; (i.e., &lt;a href=&quot;http://robots.stanford.edu/papers/montemerlo.fastslam-tr.html&quot; rel=&quot;nofollow&quot;&gt;fastslam&lt;/a&gt;).&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Then, you can re-weight each particle according to it's probability given the GPS measurements. &lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;However, I recommend you use the INS in place of the wheel odometry during the prediction step. It will likely be a reasonable proxy, especially over the short term. In fact, this is a very common practice in the literature.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To make this clearer, you predict your next pose $x^+$, based on your current pose $x^-$, and your INS measurement which gives you a $\delta x$ (because you integrate the accellerations). So your EKF_PREDICT function goes from:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$x_{t+1|t} = f_{kinematics}(x_{t}, u_t)$, with odometry $u_t$ instead of the control vector. To something like:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$x_{t+1|t} = x_{t}+\delta x$. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What have we lost? We have lost the ability to condition on the fact that the robot can only take certain types of movements, i.e., is kinematically constrained.  To compensate for this, what I've suggested is you then &lt;em&gt;condition&lt;/em&gt; the estimate based on the liklihood given the kinematic model. That means, during the EKF_UPDATE step. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Do do this, you need to find the conditional probability:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$P(\delta x | x_{t}, u_t)$&lt;/p&gt;&#xA;" OwnerUserId="163" LastEditorUserId="163" LastEditDate="2013-03-02T22:58:49.710" LastActivityDate="2013-03-02T22:58:49.710" CommentCount="3" />
  <row Id="997" PostTypeId="1" CreationDate="2013-03-02T07:49:58.890" Score="0" ViewCount="162" Body="&lt;p&gt;As a holiday project we are building a surveillance robot that is capable of transmitting live images using a webcam and is also capable of lifting small objects.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;It uses a &lt;em&gt;CC2500 module&lt;/em&gt; for communicating with the robot.  The interface is designed in &lt;em&gt;Visual Basic 6&lt;/em&gt; and it allows us to set the port of the computer to which the transreceiver is connected. It is connected via a USB to RS232 port (USB side is connected to the computer).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We tried the settings as shown below and we get an error that the config is unsuccessful. We have tried the same settings in 4 different computers so far and it did not work.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/BJRwL.png&quot; alt=&quot;Screenshot of the GUI &quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Circuit diagram for the robot:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/VDb5R.jpg&quot; alt=&quot;x&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It is designed using an Atmel 89S52.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Please tell us what settings to try to make it work&lt;/strong&gt;&lt;/p&gt;&#xA;" OwnerUserId="965" LastEditorUserId="37" LastEditDate="2013-03-02T19:27:53.057" LastActivityDate="2013-03-13T14:20:53.693" Title="How do we make our robot work?" Tags="&lt;electronics&gt;&lt;computer-vision&gt;&lt;wheeled-robot&gt;&lt;robotic-arm&gt;" AnswerCount="2" CommentCount="2" />
  <row Id="998" PostTypeId="1" CreationDate="2013-03-02T15:57:31.173" Score="6" ViewCount="135" Body="&lt;p&gt;We are making a junior soccer robot and we just got our brilliant motors from Maxon.&#xA;Setting the PWM timer to low-frequencies (around 39kHz or 156 kHz ) the robot acts as expected. But this produces some problems. &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;It puts a heavy current on batteries (around 1.5A for 3 motors which is far too high).&lt;/li&gt;&#xA;&lt;li&gt;The high current causes our motor drivers (L6203) to heat up very quickly and even heat-sinks won't help them.&lt;/li&gt;&#xA;&lt;li&gt;The motors make such a bad sound as they are screaming and this is not normal.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;In contrast when I configure the timer on high-frequencies (such as 1250 kHz or 10000 kHz) the current drops off to 0.2A which is ideal and the sounds quit down.&#xA;But this causes a problem that our 3 motors when set to run on their highest speed (PWM set to 255) don't run by the same rpm. like one of them runs slower than others making robot turn to a specific side and so our handling functions fail to work correctly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Asking someone he told me that the drivers don't respond the same to frequencies thus resulting in different speeds and because on low frequencies the difference is very small I won't notice it but on higher frequencies the difference becomes bigger and noticeable.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So is there any workaround for this problem? or I should continue using low frequencies? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;PS: I'm using ATMEGA16 as the main controller with a 10 mHz external crystal. &lt;/p&gt;&#xA;" OwnerUserId="21" LastActivityDate="2013-03-03T01:11:11.993" Title="Motors response different with high-frequency PWM" Tags="&lt;pwm&gt;&lt;atmega&gt;" AnswerCount="1" CommentCount="6" />
  <row Id="999" PostTypeId="1" AcceptedAnswerId="1063" CreationDate="2013-03-02T17:54:46.930" Score="5" ViewCount="238" Body="&lt;p&gt;I am following a guide that recommends using stepper motors and it has an approximate holding and operating torque. It says that if you don't know the operating torque, it is often half of the holding torque. I am adapting this to use with a servo and I was wondering can this same formula be used with a servo. My servo has approximately &lt;code&gt;1.98 kg/cm&lt;/code&gt; of torque so does that mean that I can estimate the operating torque would be &lt;code&gt;~1 kg/cm&lt;/code&gt;?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;A couple of things:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I know operating torque and holding torque are different. This is just a estimate-it isn't an exact science.&lt;/li&gt;&#xA;&lt;li&gt;I know servos are harder to find their location (75 degrees, etc.) than to use a stepper and assume that it worked. I have external means of finding the location.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="824" LastEditorUserId="824" LastEditDate="2013-05-21T22:43:23.357" LastActivityDate="2013-05-21T22:43:23.357" Title="For servos, can it be implied that `Holding Torque = Operating Torque * 2` like with steppers?" Tags="&lt;rcservo&gt;&lt;stepper-motor&gt;" AnswerCount="1" CommentCount="0" FavoriteCount="1" />
  <row Id="1000" PostTypeId="2" ParentId="997" CreationDate="2013-03-02T18:26:32.060" Score="1" Body="&lt;p&gt;I believe your question starts with 'how do I configure and talk to a TI CC2500 transceiver from Windows treating it as a USB Virtual COM Port'.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Unfortunately, the answer to this is going to be very specific to the TI CC2500 device.  You'll need to load a driver.  You'll need to understand the communications protocol the CC2500 uses over the serial port.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'd recommend seeking help from a community closer to your device.  I haven't seen people using the TI CC2500 in robotics before, so there may not be anyone on this forum familiar with it.  Try the TI &lt;a href=&quot;http://e2e.ti.com/&quot; rel=&quot;nofollow&quot;&gt;E2E Community&lt;/a&gt; or contact one of their &lt;a href=&quot;http://www.ti.com/general/docs/contact.tsp&quot; rel=&quot;nofollow&quot;&gt;customer support centers&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Good luck with your project.  If you were to say using an Arduino with a Zigbee or Bluetooth communications chip in place of your TI CC2500 I think you'd find better support in the robotics community.&lt;/p&gt;&#xA;" OwnerUserId="35" LastActivityDate="2013-03-02T18:26:32.060" />
  <row Id="1001" PostTypeId="2" ParentId="994" CreationDate="2013-03-02T19:06:07.223" Score="4" Body="&lt;p&gt;You can use the INS / GPS as updates to the output of your first EKF. This is, in fact, not chaining, but simply conditioning the estimate based on the added information from the INS / GPS.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Suppose we have the following functions: &lt;/p&gt;&#xA;&#xA;&lt;p&gt;$x_{t+1|t}$, $P_{t+1|t}$ = EKF_PREDICT($x_t$, $P_t$, $u_t$), for inputs as state $x$, covariance $P$, and control inputs (estimated by odometry) $u_t$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;and&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$x_{t+1|t+1}$, $P_{t+1|t+1}$ = EKF_UPDATE($x_{t+1|t}$, $P_{t+1|t}$, $\hat{x}_{t+1}$).  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The estimates from sensors are the $\hat{x}_{t+1}$. We have things like:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$\hat{x}^{gps}_{t+1} = f(GPS)$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$\hat{x}^{map}_{t+1} = f(map)$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$\hat{x}^{ins}_{t+1} = f(INS)$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;etc for all other ways of estimating the state of the robot.&#xA;So running the function EKF_UPDATE for all of those sensors is good enough.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Your loop will be something like this:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;for all time $t$&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Let $u_t$ be the current odometry / kinematic estimate of pose, and $R_u$ be the noise on that estimate.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;$x_{t+1|t}$, $P_{t+1|t}$ = EKF_PREDICT($x_t$, $P_t$, $u_t$, $R_u$)&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;for all sensors $S$,&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Let $\hat{x}^{S}_{t+1}$ be the estimate of the pose from that sensor, and $R_{S}$ be the noise on that estimate&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;$x_{t+1|t+1}$, $P_{t+1|t+1}$ = EKF_UPDATE($x_{t+1|t}$, $P_{t+1|t}$, $\hat{x}_{t+1}, R_S$).  &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;end-for&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;end-for&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Some caveats are: &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Since we're using the EKF, there is no guarantee that the estimate is independent of the ordering of the updates. That is, if you do INS then GPS, the resulting estimate might be different than if you update with GPS then INS. This is usally not a big deal, but the filter will requiring significantly more tuning. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Please be aware your INS has a bias and drift, which might affect your long-term reliability. GPS can help you a &lt;em&gt;lot&lt;/em&gt; here. Most literature simultaneously estimates the bias and drift in the INS.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="163" LastActivityDate="2013-03-02T19:06:07.223" />
  <row Id="1003" PostTypeId="2" ParentId="957" CreationDate="2013-03-02T22:50:35.107" Score="1" Body="&lt;p&gt;As Plecharts said, it depends on your surface.  Magnets work really well for a heavy robot, but iff you're going to drive on metal.  An example can be found on this VEXLabs robot: &lt;a href=&quot;http://www.vexforum.com/wiki/Magbot_Model_3&quot; rel=&quot;nofollow&quot;&gt;http://www.vexforum.com/wiki/Magbot_Model_3&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="314" LastActivityDate="2013-03-02T22:50:35.107" CommentCount="1" />
  <row Id="1004" PostTypeId="2" ParentId="998" CreationDate="2013-03-03T01:11:11.993" Score="3" Body="&lt;p&gt;While I do not know how to fix the root cause of the problem, a work around is to use closed-loop feedback.  If you can measure the speed of each wheel (for example, with encoders), you can use a PID-like algorithm to adjust the speeds of your wheels so the robot goes straight.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A compass or gyroscope would also be suitable for this task.&lt;/p&gt;&#xA;" OwnerUserId="314" LastActivityDate="2013-03-03T01:11:11.993" CommentCount="2" />
  <row Id="1005" PostTypeId="1" CreationDate="2013-03-03T03:19:31.527" Score="6" ViewCount="107" Body="&lt;p&gt;I am trying to control the force of a solenoid. My current system has a bank of capacitors connected to a relay. In order to control the force (how hard I am trying to hit the object) I am increasing or decreasing the the time the relay is on. The problem is this works but it either hits with too much force or way too much force. I can turn the relay on for 5 ms or more. If I try to turn it on for 1 ms it does not even respond. (I am using a mechanical relay.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would like to have more control on how much of the energy I discharge so I can control how hard/soft the solenoid moves (say discharge only 10 percent of the total energy stored so it hits slower). While searching I found out about Solid State Relays which according to wikipedia can be switched on an off way faster that mechanical relay (of the order of microseconds to milliseconds).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So my question is am I on the right track? or is there something better to achieve what I am trying to achieve?&lt;/p&gt;&#xA;" OwnerUserId="968" LastActivityDate="2013-03-17T21:32:00.817" Title="Controlling the Power of a Solenoid" Tags="&lt;control&gt;" AnswerCount="2" CommentCount="2" />
  <row Id="1006" PostTypeId="1" AcceptedAnswerId="1008" CreationDate="2013-03-03T20:00:06.140" Score="5" ViewCount="122" Body="&lt;p&gt;In &lt;a href=&quot;http://www.probabilistic-robotics.org/&quot; rel=&quot;nofollow&quot;&gt;Probablistic Robotics by S. Thrun&lt;/a&gt;, in the first section on the Extended Kalman Filter, it talks about linearizing the process and observation models using first order Taylor expansion.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Equation 3.51 states:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$g(u_t,x_{t-1}) \approx g(u_t,\mu_{t-1}) + g\prime(u_t, \mu_{t-1})(x_{t-1} - \mu_{t-1})$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I think $\mu_{t-1}$ is the state estimate from the last time step.  My question is: what is $x_{t-1}$?  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, the EKF algorithm following this (on table 3.3) does not use the factor $(x_{t-1} - \mu_{t-1})$ anywhere, only $g\prime(u_t, \mu_{t-1})$.  So after being confused about $x_{t-1}$, I'm left wondering where it went in the algorithm.&lt;/p&gt;&#xA;" OwnerUserId="502" LastEditorUserId="163" LastEditDate="2013-03-10T18:22:14.480" LastActivityDate="2013-03-10T18:22:14.480" Title="Taylor Series expansion for EKF" Tags="&lt;kalman-filter&gt;&lt;theory&gt;&lt;ekf&gt;" AnswerCount="2" />
  <row Id="1007" PostTypeId="2" ParentId="1006" CreationDate="2013-03-03T20:40:28.717" Score="4" Body="&lt;p&gt;$\mu_{t-1}$ is the state estimate from the last time step, $x_{t-1}$ is the actual state (a random variable) in the last time step. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Basically it goes like this: in the traditional Kalman filter, you have linear models that tells us how states evolve and measurements are made. In the EKF you have non-linear models but want to use the Kalman filter equations, so you use the first order Taylor expansion as the KF linear model. That way you can still propagate covariances appropriately.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note that state and measurement predictions still use the non-linear models. So linearization &quot;only&quot; affects covariance propagation -- which affects everything really, because that regulates how certain you are about your estimates and the relative trust you place on your state estimate vs your measurements.&lt;/p&gt;&#xA;" OwnerUserId="95" LastActivityDate="2013-03-03T20:40:28.717" CommentCount="1" />
  <row Id="1008" PostTypeId="2" ParentId="1006" CreationDate="2013-03-04T03:11:40.997" Score="3" Body="&lt;p&gt;After the propagation step, we need to find the parameters of the Gaussian which describe our new estimate. These are, the mean $\mu$, and the co-variance $\Sigma$. You asked about the mean specifically, so here we go.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note that the definition of the mean of the propagated state is the expectation of the propagated state. Taking the expectation of the Taylor series expansion, we have (note I'm using shorter notation of superscript - for prior):&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$x = g(x^-, u) $$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And by Taylor series expansion,&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$x \approx g(x^-, u) + g^\prime(x^- , u) (x-x^-)$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Evaluating the approximate function $g()$ at the mean of the prior yeilds:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$x \approx g(\mu, u) + g^\prime(\mu , u) (x-\mu)$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, let's use $\mathbb{E}$ as the expectation operator to find the expected value of the output (which is the mean of our posterior estimate.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$\mu = \mathbb{E}[x]$$&#xA;$$\mu = \mathbb{E}[g(\mu^-,u)]$$&#xA;$$\mu \approx \mathbb{E}[g(x^-, u) + g^\prime(x^- , u) (x-\mu^-)]$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$\mu \approx \mathbb{E}[g(x^-, u)] + \mathbb{E}[g^\prime(x^- , u) (x-\mu^-)]$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now substitute in $G$, the Jacobian of the function $g$ also evaluated at the mean.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$\mu \approx \mathbb{E}[g(x^-, u)] + \mathbb{E}[G\cdot (x-\mu^-)]$$&#xA;$$\mu \approx \mathbb{E}[g(x^-, u)] + \mathbb{E}[G\cdot x - G\cdot \mu^- ]$$&#xA;And by linearity of expectation:&#xA;$$\mu \approx \mathbb{E}[g(x^-, u)] + G\cdot \mathbb{E}[x] - G\cdot \mathbb{E}[\mu^- ]$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And guess what? The expected value of both of those things on the right is zero. (why? because we assumed they were Gaussian).** &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now, we have to compute the co variance, defined as $\mathbb{E}\left[ (x-\mathbb{E}[x])(x-\mathbb{E}[x])^T\right]$. You can easily derive this by following the same steps. First expand the terms inside the first expectation, then substitute the linear approximation of $g$ as before. Some matrix algebra will yield the EKF co-variance update. Note that you have to include the &quot;white noise&quot; Jacobian. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;See &lt;a href=&quot;http://services.eng.uts.edu.au/~sdhuang/Extended%20Kalman%20Filter_Shoudong.pdf&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt; for a possibly better derivation.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;**The real lie the EKF tells you is that the term, $\mathbb{E}[g(x^-, u)]$ is the same as $g(\mu^-,u)$, which holds as long as the function $g()$ isn't too crazy.&lt;/p&gt;&#xA;" OwnerUserId="163" LastEditorUserId="163" LastEditDate="2013-03-04T16:50:51.113" LastActivityDate="2013-03-04T16:50:51.113" />
  <row Id="1010" PostTypeId="2" ParentId="1005" CreationDate="2013-03-04T10:16:13.823" Score="4" Body="&lt;p&gt;To clarify, you have a bank of capacitors and you want to use them to power a solenoid for a short period of time, right?  I assume you are directly connected to the solenoid coil, not through a controller or anything.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In this case the variables you can alter are length of pulse, and current of pulse.  Decreasing either of these will of course cause your capacitors to drain less with each pulse.  The actual force from the solenoid is much more linearly affected by current than length of pulse, and the easiest way to decrease current is to simply stick a power resistor somewhere along the line between the caps and the solenoid.&lt;/p&gt;&#xA;" OwnerUserId="972" LastActivityDate="2013-03-04T10:16:13.823" />
  <row Id="1011" PostTypeId="1" AcceptedAnswerId="1017" CreationDate="2013-03-04T14:46:52.133" Score="2" ViewCount="651" Body="&lt;p&gt;I'm looking to use 4 of &lt;a href=&quot;http://www.batteryspace.com/lifepo426650cell32v3300mah16.5arate10whunapproved.aspx&quot; rel=&quot;nofollow&quot;&gt;these 3.2V LiFePO4 batteries&lt;/a&gt;. I intend to have 2 pairs of 2 in series in parallel. So two 6.4V battery packs in parallel. Because my setup will be run off of this, it will also be easiest to recharge the batteries using the same setup. To accomplish this, I'm looking to charge all the batteries at once using &lt;a href=&quot;http://www.batteryspace.com/Smart-Charger-0.7-A-for-6.4V-2-cells-LiFePO4-Battery-Pack-100-240VAC.aspx&quot; rel=&quot;nofollow&quot;&gt;this 6.4V LiFePO4 smart charger&lt;/a&gt;. From a simplistic standpoint, the resulting voltage should be correct and this should work fine. However, I know (from a &lt;a href=&quot;http://robotics.stackexchange.com/questions/634/how-to-charge-a-lifepo4-battery&quot;&gt;previous question&lt;/a&gt;) that LiFePO4 battery chargers are a bit more complex then a basic voltage supply and check. Would the setup I've described work correctly? And in general, will a LiFePO4 smart charger be able to charge several batteries of the correct voltage at the same time so long as it doesn't try to charge them at too high an amperage? Or does a LiFePO4 battery also have a minimum amperage cutoff point to charge such that trying to charge more than one battery at a time will cause problems? Any other issues I didn't mention? Thank you much!&lt;/p&gt;&#xA;" OwnerUserId="457" LastActivityDate="2013-03-06T18:16:31.927" Title="Charging multiple LiFePO4 batteries at the same time?" Tags="&lt;batteries&gt;" AnswerCount="2" FavoriteCount="1" />
  <row Id="1012" PostTypeId="2" ParentId="1011" CreationDate="2013-03-04T19:24:24.810" Score="4" Body="&lt;p&gt;Basically for charging LiPo/LiFe, you will need charger with balancer which measure each cell voltage level, as they tend to overheat or get damaged or even burst into a flame when handling carelessly. Lipo/life doesn't like trickle charge as NiMh or NiCd and also you will need constant current output at different voltage levels. But there are smart chargers that can handle this. I guess you will need to connect all 4 cells to balancer as they are separated battery packs...&lt;/p&gt;&#xA;" OwnerUserId="973" LastEditorUserId="37" LastEditDate="2013-03-05T11:18:03.847" LastActivityDate="2013-03-05T11:18:03.847" CommentCount="3" />
  <row Id="1013" PostTypeId="2" ParentId="989" CreationDate="2013-03-04T21:54:21.053" Score="3" Body="&lt;p&gt;Of course adding random particles will change the pose of the robot. That's the point: To add randomness to account for errors you can't compute yourself. You should add random particles every time the state of the robot may change, then adjust the weight of the particles based on which seem likely given sensor data.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is a very basic definition of particle filters. I suggest you roll up your sleeves and do some more research on the subject.&lt;/p&gt;&#xA;" OwnerUserId="163" LastActivityDate="2013-03-04T21:54:21.053" />
  <row Id="1014" PostTypeId="1" CreationDate="2013-03-05T00:15:58.700" Score="4" ViewCount="299" Body="&lt;p&gt;I saw this art drawing robot on youtube:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.youtube.com/watch?v=Wo15zXhFdzo&quot; rel=&quot;nofollow&quot;&gt;http://www.youtube.com/watch?v=Wo15zXhFdzo&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What do I need to learn in order to build something like that? What are some beginner oriented projects that could lead up to building something like this?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm an experienced programmer but I have very little hardware experience.&lt;/p&gt;&#xA;" OwnerUserId="975" LastActivityDate="2013-03-07T11:58:40.830" Title="How would I go about making an art drawing robot like this?" Tags="&lt;robotic-arm&gt;" AnswerCount="2" CommentCount="0" FavoriteCount="1" />
  <row Id="1016" PostTypeId="2" ParentId="1014" CreationDate="2013-03-05T04:45:16.457" Score="7" Body="&lt;p&gt;This project is a great starter project for a programmer trying to get into robotics because it doesn't require a lot of knowledge or experience. Though it does require a small investment.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The arm itself is one of the &lt;a href=&quot;http://www.lynxmotion.com/c-27-robotic-arms.aspx&quot;&gt;LynxMotion Arms&lt;/a&gt; though I don't remember precisely which. An &lt;a href=&quot;http://www.lynxmotion.com/p-395-ssc-32-servo-controller.aspx&quot;&gt;SSC-32&lt;/a&gt; was used to interface the arm with the controlling computer. The SSC-32 has a really simple protocol and appears as a serial device. As such if you have any experience working with serial devices then you already know how to communicate with this robot. Otherwise, and it probably goes without saying, you need to learn how to communicate with serial devices.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;With that said the real challenge with such a project would be learning how to control the location of the end effector by setting the angles of the joints. This is known as the &lt;a href=&quot;http://en.wikipedia.org/wiki/Forward_kinematics&quot;&gt;forward kinematics&lt;/a&gt; problem and requires a &lt;a href=&quot;http://en.wikipedia.org/wiki/Kinematics&quot;&gt;kinematic&lt;/a&gt; model of the arm. You will also need to learn how to determine what joint angles are required given a desired end effector position. This is known as the &lt;a href=&quot;http://en.wikipedia.org/wiki/Inverse_kinematics&quot;&gt;inverse kinematics&lt;/a&gt; problem. Dr. Hollerbach's &lt;a href=&quot;http://www.eng.utah.edu/~cs5310/chapters.html&quot;&gt;notes&lt;/a&gt; are a good resource for learning how to solve these problems. Interestingly @abstractcement had the idea of using &lt;a href=&quot;http://en.wikipedia.org/wiki/Bilinear_interpolation&quot;&gt;bilinear interpolation&lt;/a&gt; to bypass the need for solving these problems which worked out beautifully.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You could also look into creating a &lt;a href=&quot;http://en.wikipedia.org/wiki/Dynamical_system&quot;&gt;dynamical&lt;/a&gt; model to control the forces and torques in the system. However in this project the robot moved slowly enough that the dynamics were neglible and were ignored altogether.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The real challenges with a painting robot are in the &lt;a href=&quot;http://en.wikipedia.org/wiki/Automated_planning_and_scheduling&quot;&gt;automated planning&lt;/a&gt;, &lt;a href=&quot;http://en.wikipedia.org/wiki/Motion_planning&quot;&gt;motion planning&lt;/a&gt;, and &lt;a href=&quot;http://en.wikipedia.org/wiki/Control_theory&quot;&gt;control&lt;/a&gt;. But I won't go into any of that here because I believe it's beyond the scope of what you are asking.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-03-05T04:45:16.457" />
  <row Id="1017" PostTypeId="2" ParentId="1011" CreationDate="2013-03-05T17:35:44.570" Score="2" Body="&lt;p&gt;It sounds like you're planning to create a 2&amp;times;2 configuration of individual cells, which is a common configuration:&#xA;&lt;img src=&quot;http://img.diytrade.com/cdimg/113732/22434825/0/1310733466/lifepo4_lithium_battery_6_4v_1ah.jpg&quot; alt=&quot;4 pack 6.4V lithium battery&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The 6.4V charger is designed for a pair of 3.2V cells in series, so you should be able to add as many parallel stacks of these as you like.  They will simply take longer to charge.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;At one of my previous jobs, we had a homemade 1.5kW battery that was made of 648 (yes, six hundred and forty eight) LiPoly 18650 cells: 24 supercells in series, each cell being 27 batteries in parallel.  &lt;strong&gt;I do not recommend this setup.&lt;/strong&gt;  The cells within each supercell will charge evenly because they are in parallel, but the series cells do not.  Here's an example of what the supercell charges looked like when we serviced the battery and each supercell was equally charged (ours were 3.7V min, 4.2V max):&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://1.bp.blogspot.com/_Hgp1nzunDXk/Ss-ltn0RyWI/AAAAAAAAAUo/9jzuvjOXeCw/s1600-h/chart_battery_recharge_456.png&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://1.bp.blogspot.com/_Hgp1nzunDXk/Ss-ltn0RyWI/AAAAAAAAAUo/9jzuvjOXeCw/s320/chart_battery_recharge_456.png&quot; alt=&quot;Mission 456&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As you can see, they mostly discharge and charge together -- you can see the point at which we plugged in the charger.  A few testing days later, one of the cells began drifting apart:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://4.bp.blogspot.com/_Hgp1nzunDXk/SuVxTh3O4AI/AAAAAAAAAX4/lIHVyUZ-8ZU/s1600-h/chart-batteryvoltage-546.png&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://4.bp.blogspot.com/_Hgp1nzunDXk/SuVxTh3O4AI/AAAAAAAAAX4/lIHVyUZ-8ZU/s320/chart-batteryvoltage-546.png&quot; alt=&quot;Mission 546&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Eventually, they look like this (what it looked like before servicing):&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://4.bp.blogspot.com/_Hgp1nzunDXk/SrOZSPKes0I/AAAAAAAAAQY/0DH79FlrRD0/s1600-h/Battery+Voltages+Recharging.png&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://4.bp.blogspot.com/_Hgp1nzunDXk/SrOZSPKes0I/AAAAAAAAAQY/0DH79FlrRD0/s320/Battery+Voltages+Recharging.png&quot; alt=&quot;Mission 394&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The moral of the story is that using many cells in series doesn't guarantee even charging, because each cell has a slightly different capacity.  Using cells in parallel is better because it keeps their voltages equal.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For your particular case: if you don't charge all 4 cells in parallel, make sure that you monitor the voltage of each set of cells in the series -- one parallel pair will have a higher voltage than the other parallel pair.  Don't discharge them below the minimum rated voltage of the low pair, and don't charge them above the maximum rated voltage of the higher pair.  The difference in voltage between the two sets of cells will impact your available operating time, so it will make sense to manually balance the voltages (using 3.2V parallel charging) every so often.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-03-06T18:16:31.927" LastActivityDate="2013-03-06T18:16:31.927" CommentCount="4" />
  <row Id="1018" PostTypeId="1" CreationDate="2013-03-07T02:33:41.910" Score="5" ViewCount="110" Body="&lt;p&gt;I am using the &lt;a href=&quot;http://www.pololu.com/file/0J37/ssc03a_guide.pdf&quot; rel=&quot;nofollow&quot;&gt;Pololu Micro Serial Servo Controller&lt;/a&gt; connected to an Arduino and multiple other servos (4 total) to make a robot arm.  Two of the four servos require 4-6 volts, while the other 2 require 7-10 volts, so I am planning on powering all the servos separate from the Pololu.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have the Arduino and Pololu connecting to each other correctly (flashing green led), but the servo(s) don't move when plugged in to the control pins.  All the servos work correctly when plugged into a servo-tester.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I think that this problem could be fixed by connecting the grounds of the servos to the ground of the Pololu, but would like advice because I am not sure if it will work, or will end up frying one of the parts (We already fried a pololu).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Would connecting the grounds of the batteries to the ground of the Pololu help, or damage the parts?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/Gf2t4.jpg&quot; alt=&quot;Wiring Diagram&quot;&gt;, but I couldn't figure out how to show the micro serial servo controller.&lt;/p&gt;&#xA;" OwnerUserId="984" LastEditorUserId="37" LastEditDate="2013-05-20T16:05:29.857" LastActivityDate="2013-05-20T16:05:29.857" Title="Connecting multiple different voltage servos to the same controller" Tags="&lt;rcservo&gt;" AnswerCount="2" CommentCount="2" />
  <row Id="1019" PostTypeId="2" ParentId="1014" CreationDate="2013-03-07T05:07:41.933" Score="2" Body="&lt;p&gt;I was in your situation when I made that video, but DaemonMaker, my friend who studies Robotics, helped immensely.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I can't really add much beyond &lt;a href=&quot;http://robotics.stackexchange.com/a/1016/37&quot;&gt;what DaemonMaker said&lt;/a&gt; because my focus is on stroke planning and automatic painting and most of my work runs on simulated brushes and simulated canvas.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm preparing my techniques for profit and publication and wouldn't disclose them on a public forum. However, there are other methods out there, to control the robot, such as those mentioned by Aaron Hertzmann in &lt;a href=&quot;http://www.mrl.nyu.edu/publications/hertzmann-thesis/&quot; rel=&quot;nofollow&quot;&gt;Algorithms for Rendering in Artistic Styles&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;We describe new algorithms and tools for generating paintings, illustrations, and animation on a computer. These algorithms are designed to produce visually appealing and expressive images that look hand-painted or hand-drawn. In many contexts, painting and illustration have many advantages over photorealistic computer graphics, in aspects such as aesthetics, expression, and computational requirements. We explore three general strategies for non-photorealistic rendering&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;This technology has been around for a long time and if you're mostly interested in the robot, you can use this instead of worrying about control.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Hertzmann's algorithm depends on comparisons between the canvas and the reference image. If you want to do it with a robot, you'll need a camera to photograph the painting before and after every brush stroke. You'll also probably need computer vision algorithms to negate lens distortion, align the canvas and reference images, and adjust color biases from the illumination.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It's good to see fresh interest in the subject.&lt;/p&gt;&#xA;" OwnerUserId="976" LastEditorUserId="37" LastEditDate="2013-03-07T11:58:40.830" LastActivityDate="2013-03-07T11:58:40.830" CommentCount="2" />
  <row Id="1020" PostTypeId="1" AcceptedAnswerId="1031" CreationDate="2013-03-07T15:52:55.750" Score="5" ViewCount="598" Body="&lt;p&gt;I would like to build a robot which follows a virtual path (Not a visible path like a 'black line on a white surface', etc).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm just enthusiastic by seeing some sci-fi videos which show robots carry goods and materials in a crowded place. And they really don't follow a physical line. They sense obstacles, depth, etc.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would like to build one such robot which follows a specific (virtual)  path from point A to B.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have tried a couple of things:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;Using a magnetic &quot;Hall effect&quot; sensor on the robot and wire carrying current (beneath the table). The problem here was that the vicinity of the hall effect sensor is so small (&amp;lt; 2cms) that it is very difficult to judge whether robot is on the line or off the line. Even using series of magnets couldn't solve this issue, as my table is 1 inch thick. So this idea flopped :P&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Using an ultraviolet paint (on a line) and using UV leds on the robot as sensors. This will give more Zig-Zag motion for the robot. And due to potential threats of using UV light source, even this idea flopped :P&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;I finally thought of having a camera on top and using image processing algorithms to see whether robot is on the line or diverging.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there any better solution than this? Really looking for some creative and simple solutions. :)&lt;/p&gt;&#xA;" OwnerUserId="986" LastEditorUserId="134" LastEditDate="2013-08-20T07:40:11.267" LastActivityDate="2013-08-20T07:40:11.267" Title="How to make an &quot;invisible line following robot&quot;?" Tags="&lt;mobile-robot&gt;&lt;localization&gt;&lt;wheeled-robot&gt;&lt;industrial-robot&gt;&lt;line-following&gt;" AnswerCount="1" CommentCount="7" />
  <row Id="1021" PostTypeId="1" CreationDate="2013-03-08T05:46:19.160" Score="3" ViewCount="75" Body="&lt;p&gt;Does anyone know if small mechanical actuators exist which can be controlled electrically, sort of like a miniature joystick, but in reverse.  Instead of it picking up mechanical movement and outputting electrical signals, I want it to generate mechanical movement controlled via my electrical input signals.  I’ve searched for : electromechanical actuators, not finding what I need. Think of a pencil attached to a surface which can pivot to point anywhere in its half dome.  I’m thinking small, on the order of an inch.  It will not be load bearing. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;My goal is to programmatically control the normal pointed to by a small flat surface attached to the end of each joystick rod.  Accuracy is more important than speed.  From across a small room, say 10' by 10', I'd like the surface normal to accurately point to arbitrary objects in the room, say a person walking across the room.  If I can cheaply buy/build such mechanisms to control the movement of these small flat surfaces, I would like dozens places across the walls of the room.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Its for an electromechanical sound project I’m planning. &lt;/p&gt;&#xA;" OwnerUserId="988" LastEditorUserId="988" LastEditDate="2013-03-08T20:42:32.280" LastActivityDate="2013-03-08T20:42:32.280" Title="looking for a miniature joystick, but in reverse" Tags="&lt;control&gt;&lt;actuator&gt;" AnswerCount="2" CommentCount="1" FavoriteCount="1" />
  <row Id="1022" PostTypeId="2" ParentId="1021" CreationDate="2013-03-08T06:46:54.897" Score="0" Body="&lt;p&gt;a mechanism like Stepper motor could be used. n-number of coils covering the central joystick in a circular manner. whichever coil is energized, the joystick is pulled in that direction. A spring mechanism can ensure that the joystick head moves back to its initial position. Sorry, no image coz i m not a expert in graphics.&lt;/p&gt;&#xA;" OwnerUserId="986" LastEditorUserId="986" LastEditDate="2013-03-08T16:51:41.457" LastActivityDate="2013-03-08T16:51:41.457" CommentCount="2" />
  <row Id="1023" PostTypeId="1" AcceptedAnswerId="1027" CreationDate="2013-03-08T08:44:20.903" Score="0" ViewCount="66" Body="&lt;p&gt;I'm building a quadruped and I'm not sure of the features I should be looking for in a servo motor. e.g. digital vs analog, signal vs dual bearings. Some of the ones I'm considering are &lt;a href=&quot;http://www.servodatabase.com/compare?servos=806,1660,1664,1666http://www.servodatabase.com/compare?servos=806,1660,1664,1666&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="374" LastEditorUserId="37" LastEditDate="2013-05-20T16:06:05.157" LastActivityDate="2013-05-20T16:06:05.157" Title="Servo motor considerations for a quadruped" Tags="&lt;rcservo&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="1024" PostTypeId="2" ParentId="1021" CreationDate="2013-03-08T09:17:09.473" Score="1" Body="&lt;p&gt;You could do this using two servos (one for each axis).&#xA;Here is what I mean (sorry for the poor graphics) :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://img843.imageshack.us/img843/2341/0073y.png&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://img843.imageshack.us/img843/2341/0073y.png&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="943" LastActivityDate="2013-03-08T09:17:09.473" CommentCount="4" />
  <row Id="1025" PostTypeId="1" CreationDate="2013-03-08T15:27:12.387" Score="3" ViewCount="634" Body="&lt;p&gt;I am working on this project that involves using the Kinect for XBOX 360S with ROS.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I did all the steps mentioned in the ROS Tutorials to have Openni Installed and the Prime sense and other drivers. and when i go to Openni samples i see a output. But in ROS i do a roscore and in another terminal do a roslaunch openni_launch openni.launch. And it loads with the regular calibration warnings and service already registered errors. Then in another terminal i open Rviz which gives a error /.rviz/display_config does not exist. And even though i accept the error and go ahead i see a black window which shows no output ,even if i do all tasks mentioned at the RVIZ Tutorials. Also i tried running &quot;rosrun image_view image_view image:=/camera/rgb/image_color&quot; and it shows up a blank window with no output. How do i resolve this and get ros to show my kinect data??&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I need to run RGBDSLAM and use this kinect later.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am on Ubuntu 12.04 and ROS-Fuerte.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Well when i launch the openni.launch it starts as usual except for the errors ¨Tried to advertise a service that is already advertised in this node.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And when i run a rostopic it just says subscribed to the /camera/depth_registered/points and cursor keeps blinking.&#xA;Even subscribing to the rectified topics just says subscribed and nothing more happens.&lt;/p&gt;&#xA;" OwnerUserId="853" LastEditorUserId="350" LastEditDate="2013-03-08T19:42:21.993" LastActivityDate="2013-07-19T19:48:25.337" Title="Cant see Kinect Data in ROS" Tags="&lt;kinect&gt;&lt;ros&gt;" AnswerCount="2" CommentCount="5" />
  <row Id="1026" PostTypeId="2" ParentId="287" CreationDate="2013-03-08T18:53:34.163" Score="2" Body="&lt;p&gt;&lt;a href=&quot;http://www.microsoft.com/robotics/&quot; rel=&quot;nofollow&quot;&gt;Microsoft Robotics&lt;/a&gt; uses a protocol called &lt;a href=&quot;http://social.msdn.microsoft.com/Forums/en-US/roboticsdss/thread/babf3e90-8196-40b2-a4a1-5f2ecc4e9b47&quot; rel=&quot;nofollow&quot;&gt;Decentralized Software Services Protocol (DSSP)&lt;/a&gt; and they &lt;a href=&quot;http://blogs.msdn.com/b/msroboticsstudio/archive/2007/07/10/decentralized-software-services-protocol-dssp-placed-under-microsoft-open-specification-promise.aspx&quot; rel=&quot;nofollow&quot;&gt;released the specs&lt;/a&gt; under a license that allows anyone to implement it in any language. The DSSP protocol is totally compatible with current web standards and I think it would be a great idea to implement it in JavaScript and NodeJS. That can make it possible for your node application to interact with any DSS robotics services available today.&lt;/p&gt;&#xA;" OwnerUserId="994" LastActivityDate="2013-03-08T18:53:34.163" />
  <row Id="1027" PostTypeId="2" ParentId="1023" CreationDate="2013-03-08T20:20:45.860" Score="1" Body="&lt;p&gt;If you are not on the budget, go for the digital with metal gears. Basically, higher the torque better your bot will be. For the legged bots speed of the servo is not an issue but torque is. &#xA;To be sure that servo will have enough torque, you will need to roughly calculate the mass of the bot, divide it by number of legs - 2. As during the walk two legs will be in the air and other legs need to be able to hold the mass of the bot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also consider how many DOF one leg will have. In 3 DOF leg systems, one servo is used for rotation of the leg and it will not be under heavy load. So that one can be &quot;cheaper&quot; servo. Consider that on 4 legged system you will need 12 servos. Having 4 of them cheaper would mean more money for sensors or lighter material for construction ... &lt;/p&gt;&#xA;" OwnerUserId="973" LastActivityDate="2013-03-08T20:20:45.860" />
  <row Id="1028" PostTypeId="2" ParentId="1018" CreationDate="2013-03-08T20:38:02.217" Score="2" Body="&lt;p&gt;You have a floating signal of servo ctrl, because they are not on the same common. &#xA;Output from arduino (if not on the same common as servo) will be on the different potential level than input on servos. So servo will see it as a floating potential between his ground and his vcc potential.&#xA;(i hope you did understand what i wanted to say, its hard for me to explain it on English :) )&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I guess your diagram is not connected like you have posted, because you have connected +5 and gnd from arduino to digital 3 and inputs from both servos are connected.&lt;/p&gt;&#xA;" OwnerUserId="973" LastActivityDate="2013-03-08T20:38:02.217" CommentCount="1" />
  <row Id="1030" PostTypeId="2" ParentId="1018" CreationDate="2013-03-08T23:20:30.377" Score="2" Body="&lt;p&gt;I fixed the servos by connecting the ground of the external batteries to the ground of the pololu and arduino circuit boards, then spent an hour to realize that a wire was loose.  :S&lt;/p&gt;&#xA;" OwnerUserId="984" LastActivityDate="2013-03-08T23:20:30.377" />
  <row Id="1031" PostTypeId="2" ParentId="1020" CreationDate="2013-03-08T23:47:22.313" Score="2" Body="&lt;p&gt;There are many possible ways to approach this problem, and they all depend on the material available and the expertise of the robot builder.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In short, the criteria is that:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;The robot must get from point A to B following a pre-defined path.&lt;/li&gt;&#xA;&lt;li&gt;The path taken must not follow a line visible to the human eye.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Depending on the length of the path, using &lt;strong&gt;encoders&lt;/strong&gt; could be sufficient.  However, it should be noted that due to physical inaccuracy, drift makes odometry (what we call using encoders to measure distance) impractical for long distances.  However, this is easy for short distances, and should be at least considered.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If the distance is too far for only odometry, one should consider using some sensor to measure turns (for instance, a &lt;strong&gt;gyroscope or compass&lt;/strong&gt;).  Turns tend to introduce the most error in odometry (measuring along a straight line doesn't have too much error), so using a sensor for turns can sometimes make odometry a viable solution.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If odometry or odometry + sensed turning doesn't work, then we get to be creative.  If you want the robot to follow a path composed of mostly straight segments, you could place &lt;strong&gt;IR LEDs&lt;/strong&gt; at given &quot;waypoints&quot; on the table, and have the robot sense those LEDs and drive towards each waypoint in series.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, that still leaves some visual marking on the table (although it could be disguised to some extent), and it would be great to be able to do without that.  Another approach would be to use &lt;strong&gt;laser pointers&lt;/strong&gt; shining parallel to the surface of the table, but a few inches above the table.  The robot could use a photoresistor to detect when it crosses a laser, and this could let it know when to turn.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;All-in-all, I think that the odometry augmented with an angle sensor is probably the best bet for your robot, at least with the way you have described it.  I may be able to think of more options, but that's all I see right now.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Just curious--why do you want the line to be invisible?  Knowing why could open up some more possibilities.&lt;/p&gt;&#xA;" OwnerUserId="314" LastActivityDate="2013-03-08T23:47:22.313" CommentCount="2" />
  <row Id="1032" PostTypeId="1" AcceptedAnswerId="1034" CreationDate="2013-03-09T15:52:12.467" Score="7" ViewCount="498" Body="&lt;p&gt;I'm considering experimenting with PIV control instead of PID control. Contrary to PID, PIV control has very little explanation on the internet and literature. There is almost a single source of information explaining the method, which is a &lt;a href=&quot;http://parkermotion.com/whitepages/ServoFundamentals.pdf&quot; rel=&quot;nofollow&quot;&gt;technical paper by Parker Motion&lt;/a&gt;. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What I understand from the control method diagram (which is in Laplace domain) is that the control output boils down to the sum of:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Kpp*(integral of position error)&lt;/li&gt;&#xA;&lt;li&gt;-Kiv*(integral of measured velocity)&lt;/li&gt;&#xA;&lt;li&gt;-Kpv*(measured velocity)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Am I correct? Thank you. &lt;/p&gt;&#xA;" OwnerUserId="1000" LastEditorUserId="95" LastEditDate="2013-03-10T19:52:09.437" LastActivityDate="2013-05-31T20:50:17.727" Title="How is PIV control performed?" Tags="&lt;control&gt;&lt;servos&gt;&lt;pid&gt;" AnswerCount="3" CommentCount="2" />
  <row Id="1033" PostTypeId="1" AcceptedAnswerId="1085" CreationDate="2013-03-09T17:01:12.603" Score="5" ViewCount="151" Body="&lt;p&gt;I'm trying to learn about servo control. I have seen that the most generic position control method for servos is PID, where the control input is position error. However, I am not sure about what is the actuated quantity. I am guessing that it is one of:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Voltage applied to the motor&lt;/li&gt;&#xA;&lt;li&gt;Current applied to the motor&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;I am then guessing that the actuated quantity gets turned into one of:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Torque that the motor exerts&lt;/li&gt;&#xA;&lt;li&gt;Angular velocity that the motor runs at&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;I haven't been able to get my hands on and explicitly control a physical servo so I cannot confirm that the actuated quantity is any of these. I know very little of the electronics that controls the motor. It might well be that the controlled quantities are different for different series servos. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;My bet is on torque control. However, assume that the servo is holding a weight at a distance (so it is acting against gravity), which means an approximately constant torque load. In this case, if the position error is zero and the servo is at rest, then each of P, I and D components are zero, which means the exerted torque is zero. This would cause the weight to sink, which is countered by the error in its position causing P,I components to increase. Wouldn't this situation cause the lifted weight to oscillate and balance at a constant position which is significantly different from the goal position? This isn't the case with the videos of servos I have seen lifting weights. Or is this the case and friction is smoothing everything out? Please help me understand. &lt;/p&gt;&#xA;" OwnerUserId="1000" LastEditorUserId="1000" LastEditDate="2013-03-10T09:07:44.020" LastActivityDate="2013-05-31T19:40:59.703" Title="What is the actual physical actuated quantity when controlling the position of a servo?" Tags="&lt;servos&gt;&lt;pid&gt;" AnswerCount="3" FavoriteCount="0" />
  <row Id="1034" PostTypeId="2" ParentId="1032" CreationDate="2013-03-09T21:59:37.393" Score="4" Body="&lt;p&gt;It seems to me like there are three basic differences between the classic PID topology and the so-called PIV topology mentioned in the white paper:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Desired velocity is assumed to be proportional to position error, the $K_p$ term regulates this.&lt;/li&gt;&#xA;&lt;li&gt;The integral error gain $K_i$ works to remove steady state errors in velocity, not position. That is essentially the same thing, however, due to item #1.&lt;/li&gt;&#xA;&lt;li&gt;The velocity estimate is fed directly through the $K_v$ term (instead of considering the derivative of position error).&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;In the paper they claim that the main advantage of this topology is that it is easier to tune.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The output of the controller is formed as follows:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$e_\theta=\theta^*-\theta\\&#xA;e_\omega = (K_pe_\theta-\hat{\omega})\\&#xA;\text{output} = \int K_ie_\omega dt - K_v\hat{\omega}$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Of course, since you will probably be programming this, the integral is replaced by an accumulator variable as follows:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$e_\theta=\theta^*-\theta\\&#xA;e_\omega = (K_pe_\theta-\hat{\omega})\\&#xA;\text{integral} = \text{integral} + K_ie_\omega \Delta t \\&#xA;\text{output} = \text{integral} - K_v\hat{\omega}$&lt;/p&gt;&#xA;" OwnerUserId="95" LastEditorUserId="95" LastEditDate="2013-03-10T14:41:48.330" LastActivityDate="2013-03-10T14:41:48.330" CommentCount="4" />
  <row Id="1035" PostTypeId="2" ParentId="1033" CreationDate="2013-03-09T22:11:30.297" Score="3" Body="&lt;p&gt;Your intuition is right but your question is actually a bit off, I would say. The variable controlled is indeed position. What you want to know is what variable is actuated, that is, what do we use to control position.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I don't know much about the internals of servomotors, but when performing PID control of DC motors it is quite common to use the voltage applied to the motor through pulse-width modulation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Regarding the second part of your question, part of what you see is probably due to the gears or simply appropriate tuning of the controller, but I can't say much about it without seeing the videos you mention. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you want to know more about the interplay of angular velocity, torque, etc., you should look up DC motor models, which is one of the building blocks of servos. That way you will find that it is common to assume that angular velocity is proportional to armature current and other things, and understand how the blue box the white paper you mentioned represents the motor.&lt;/p&gt;&#xA;" OwnerUserId="95" LastEditorUserId="95" LastEditDate="2013-03-10T15:05:14.130" LastActivityDate="2013-03-10T15:05:14.130" CommentCount="3" />
  <row Id="1036" PostTypeId="1" AcceptedAnswerId="1044" CreationDate="2013-03-10T07:07:13.193" Score="10" ViewCount="134" Body="&lt;p&gt;Is there web mapping tool that allows developers to use it to plot GPS data of autonomous vehicles/robots?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;Google Maps&lt;/code&gt; forbids it. See &lt;a href=&quot;https://developers.google.com/maps/terms&quot; rel=&quot;nofollow&quot;&gt;10.2.C&lt;/a&gt;. &lt;code&gt;Google Earth&lt;/code&gt; terms of use link jumps to the same page. &lt;code&gt;Bing&lt;/code&gt; Maps looks the similar (see &lt;a href=&quot;http://www.microsoft.com/maps/product/terms.html&quot; rel=&quot;nofollow&quot;&gt;3.2.(g)&lt;/a&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What I want is a internet-based tool that shows either/both satellite images and/or map, which can overlay plot using its API. &lt;a href=&quot;https://github.com/ros-visualization/rqt_common_plugins/issues/41&quot; rel=&quot;nofollow&quot;&gt;I'm making a generic GPS plotter&lt;/a&gt; on &lt;code&gt;ROS&lt;/code&gt; that could be used both for slow robots or fast vehicles/cars.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks!&lt;/p&gt;&#xA;" OwnerUserId="60" LastEditorUserId="60" LastEditDate="2013-03-16T09:27:23.673" LastActivityDate="2013-03-19T08:43:29.430" Title="Web mapping that can be used for autonomous vehicles/robots" Tags="&lt;gps&gt;&lt;visualization&gt;" AnswerCount="3" FavoriteCount="1" />
  <row Id="1037" PostTypeId="1" CreationDate="2013-03-10T19:38:35.130" Score="6" ViewCount="242" Body="&lt;p&gt;I've already built a two wheeled balancing robot using some continuous rotation servos and an accelerometer/gyroscope.  I upgraded the servos to some geared DC motors with 8-bit encoders with the goal having the robot drive around while balancing.   &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm kind of stuck on how to program it to drive around while still balancing.  I think one way would be to just have the control input to the motors act sort of like pushing it.  So the robot would be momentarily unbalanced in the direction I want it to travel.  That seems kind of clumsy to me though.  There must be a better way of doing?  I think I need to combine the dynamic model for the balancer with the differential drive but this is a bit beyond the control theory that I know.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt; &#xA;From Anorton's answer I have a good looking state matrix now. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now about pole placement:  The A matrix will will have to be 4x4 based on the new state vector.  And B will then have to be a 4x2 matrix since I can only control the left/right wheel torque (u = 2x1 vector).  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I may need to read more about this but is there a systematic way to determine the A matrix by pole placement?  It seems to me for this example and even more complicated examples, determining A by guess and check would be very difficult.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Update #2&lt;/strong&gt;&#xA;After a bit of reading I think I understand it now.  I still need the dynamics of the robot to determine the A matrix.  Once I have that I can do the pole placement using matlab or octave.   &lt;/p&gt;&#xA;" OwnerUserId="529" LastEditorUserId="529" LastEditDate="2013-03-14T02:37:16.413" LastActivityDate="2013-03-14T02:37:16.413" Title="Building a balancing robot with differential drive" Tags="&lt;mobile-robot&gt;&lt;control&gt;&lt;dynamics&gt;" AnswerCount="1" CommentCount="4" />
  <row Id="1039" PostTypeId="1" AcceptedAnswerId="1042" CreationDate="2013-03-11T00:45:09.677" Score="0" ViewCount="119" Body="&lt;p&gt;I am writing a method (Java) that will reset the position of e-puck in Webots. I have been following tutorial on &lt;a href=&quot;http://www.cyberbotics.com/guide/section6.3.php&quot; rel=&quot;nofollow&quot;&gt;Supervisor approach&lt;/a&gt;. I have two controllers in my project:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;SupervisorController extends &lt;a href=&quot;http://www.cyberbotics.com/reference/section3.47.php&quot; rel=&quot;nofollow&quot;&gt;Supervisor&lt;/a&gt; - responsible for genetic algorithm and resetting e-puck's position&lt;/li&gt;&#xA;&lt;li&gt;EpuckController extends &lt;a href=&quot;http://www.cyberbotics.com/reference/section3.41.php&quot; rel=&quot;nofollow&quot;&gt;Robot&lt;/a&gt; - drives the robot&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Robots are communicating via Emitter and Receiver, and everything works fine but the position reset.&#xA;This is what I'm doing in SupervisorController:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;412 Node epuck = getFromDef(&quot;epuck&quot;);    &#xA;413 Field fldTranslation = epuck.getField(&quot;translation&quot;);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;And as a result I get this exception:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;[SupervisorController] Exception in thread &quot;main&quot; java.lang.NullPointerException&#xA;[SupervisorController]  at SupervisorController.initialise(SupervisorController.java:413)&#xA;[SupervisorController]  at SupervisorController.main(SupervisorController.java:497)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;epuck variable is null. I tried calling different methods on epuck, and they all resulted in NullPointerException. The name of e-puck matches the world file. &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;DEF EPUCK DifferentialWheels {&#xA;  translation 0.134826 -0.000327529 0.107963&#xA;  rotation 0.0244439 0.999246 -0.0301538 1.95838&#xA;  children [&#xA;  (........)&#xA;  ]&#xA;  name &quot;epuck&quot;&#xA;  controller &quot;EpuckController&quot;&#xA;  axleLength 0.052&#xA;  wheelRadius 0.0205&#xA;  maxSpeed 6.28&#xA;  speedUnit 0.00628&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I would appreciate any advice on how to get a handle to the robot or where to look for issues in simulation/code.&lt;/p&gt;&#xA;" OwnerUserId="863" LastEditorUserId="350" LastEditDate="2013-03-11T16:20:07.677" LastActivityDate="2013-03-11T16:20:07.677" Title="Resetting position of e-puck in Webots using Supervisor node - problem with getting a handle to the robot" Tags="&lt;mobile-robot&gt;&lt;simulator&gt;" AnswerCount="1" />
  <row Id="1041" PostTypeId="2" ParentId="1037" CreationDate="2013-03-11T03:39:35.553" Score="7" Body="&lt;p&gt;Disclaimer: I have never done this myself, but only have seen a description of it being done through Georgia Tech's &quot;Control of Mobile Robotics&quot; on Coursera.  My knowledge of controls is spotty, too.  Thus... take this with a grain of salt. &lt;code&gt;:)&lt;/code&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To keep the robot upright (and still), you're trying to stabilize (send to $0$) the state $x$, where:&#xA;$$x=\left[\begin{array}{c}\text{leftVelocity} \\ \text{rightVelocity} \\ \text{angle from vertical}\end{array}\right]$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, when this system is stable, the left and right wheel velocities will be $0$.  So, we want an offset for the target speed:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$x_{new}=\left[\begin{array}{c}\text{leftVelocity}-\delta_L \\ \text{rightVelocity}-\delta_R \\ \text{angle from vertical}\end{array}\right]$$&#xA;Where $\delta$ is the target speed for either side.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When this system is stabilized, the robot will be upright, and will have each wheel rotating at a desired speed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is the basic approach/outline.  I'll edit this with some more details tomorrow (and actual math, etc.), but I wanted to at least post the general idea now.  (It's late in my time zone, and I have an early class to get to.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;EDITED:&lt;/strong&gt;&#xA;Oh goodness.  So, I just looked back at the slides relating to this in the Coursera course (Section 4, slide 29).  You may want to go and enroll in that class just to download that slide set... &lt;code&gt;:)&lt;/code&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The hard part is computing the $A$ and $B$ matrices (it's a big linearization mess).  Anyway, you want to make your state matrix as follows (not as above--my memory wasn't exactly right):&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$x=\left[\begin{array}{c}v \\ \omega \\ \phi \\ \dot \phi\end{array}\right]$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Where $v$ is the velocity of the segway, $\omega$ is the rotational velocity (how fast the robot is pivoting) and $\phi$ is the angle from vertical.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We want to have a desired velocity, so let's define a new state vector:&#xA;$$\begin{align}\tilde x &amp;amp;= x - \left[\begin{array}{c}v_d \\ \omega_d \\ 0 \\ 0 \end{array}\right]\\&#xA;&amp;amp;= x - \delta&#xA;\end{align}$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Where $\delta$ is the desired velocity and rotational quantity (as seen above).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Differentiating:&#xA;$$\dot{\tilde x} = \dot x - \dot \delta \underset{\text{$\delta$ is constant}}{=} \dot x$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thus, we have&#xA;$$\dot{\tilde x} = Ax + Bu$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Where $A$ is the standard coeff matrix $B$ is the input matrix, and $u$ is the control vector.  We can then say:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$\dot{\tilde x} = A(x - \delta) + Bu + A\delta$$&#xA;But, based on the solution for $A$ (from Coursera), $A\delta = 0$.  Thus:&#xA;$$\dot{\tilde x} = A\tilde x+ Bu$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now you can use pole placement to determine the correct eigenvalues, etc.&lt;/p&gt;&#xA;" OwnerUserId="314" LastEditorUserId="314" LastEditDate="2013-03-13T02:25:06.047" LastActivityDate="2013-03-13T02:25:06.047" CommentCount="4" />
  <row Id="1042" PostTypeId="2" ParentId="1039" CreationDate="2013-03-11T11:42:53.443" Score="1" Body="&lt;p&gt;The Solid nodes (including Robot and Supervisor nodes) have a DEF name, like any other node and it is usually written in upper-case. These nodes also have a field &quot;name&quot;. Both may be used by a Supervisor, it depends on which function is called. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In my case, the function getFromDef() expects a DEF name as argument, and not the name from the &quot;name&quot; field. The DEF name of my e-puck is &quot;EPUCK&quot; - hence modifying controller to:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;Node epuck = getFromDef(&quot;EPUCK&quot;);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;solved the problem.&lt;/p&gt;&#xA;" OwnerUserId="863" LastEditorUserId="863" LastEditDate="2013-03-11T13:56:18.517" LastActivityDate="2013-03-11T13:56:18.517" />
  <row Id="1043" PostTypeId="2" ParentId="1036" CreationDate="2013-03-11T16:28:22.947" Score="6" Body="&lt;p&gt;&lt;a href=&quot;http://www.google.com/earth/&quot; rel=&quot;nofollow&quot;&gt;Google Earth&lt;/a&gt; exists for precisely this purpose: overlaying your own data on a map.  You simply write scripts to translate (or export) your data into &lt;a href=&quot;https://developers.google.com/kml/documentation/&quot; rel=&quot;nofollow&quot;&gt;KML format&lt;/a&gt; then add the URL to Google Earth like so:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://www.woopra.com/wp-content/uploads/2009/10/add_network_link.png&quot; alt=&quot;Add network link&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;With regard to terms of use: the terms of use for Google Earth only forbid you to use the software to control the behavior of your vehicle, not to represent its past behavior.  (Their concern is most likely to limit their liability from you trying to draw a path on a road in GE for a robot to follow, and having it crash into something due to a map inaccuracy.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As quasi-proof, I wrote a mission planner with Google Earth at one point (&lt;a href=&quot;http://www.youtube.com/watch?v=vK0wWH9Ijnk&quot; rel=&quot;nofollow&quot;&gt;http://www.youtube.com/watch?v=vK0wWH9Ijnk&lt;/a&gt;) which I showed to the Google Earth team; they were fine with it.  They also put me in touch with a team at NASA that uses Goole Earth for this purpose.  I'm led to believe that such usage is allowed since I'm only generating mission scripts and not interacting with the autonomy. &lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-03-12T11:38:08.630" LastActivityDate="2013-03-12T11:38:08.630" CommentCount="5" />
  <row Id="1044" PostTypeId="2" ParentId="1036" CreationDate="2013-03-11T16:31:34.383" Score="5" Body="&lt;p&gt;I'd summarize my read of both of those as:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Don't use our logic to provide turn by turn navigation to vehicles&lt;/li&gt;&#xA;&lt;li&gt;Don't use our maps for business asset tracking unless you've signed a commercial use agreement&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Hard to tell if your use case described violates either of these terms.  In any case, check out &lt;a href=&quot;http://www.openstreetmap.us/&quot;&gt;http://www.openstreetmap.us/&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="35" LastActivityDate="2013-03-11T16:31:34.383" CommentCount="1" />
  <row Id="1045" PostTypeId="2" ParentId="494" CreationDate="2013-03-11T16:44:48.730" Score="0" Body="&lt;p&gt;I'd stick with a &lt;a href=&quot;http://beagleboard.org/bone&quot; rel=&quot;nofollow&quot;&gt;BeagleBone&lt;/a&gt; for the brains plus an &lt;a href=&quot;https://www.sparkfun.com/products/11286&quot; rel=&quot;nofollow&quot;&gt;Arduino Leonardo&lt;/a&gt; for the brawn.  This gets you a full computer capable of running Linux or Android with 512 MB of RAM and 800 MHz of CPU to write your AI and all the hardware capability that the Arduino ecosystem enables.  Connect the two together over USB and use a remote control library like &lt;a href=&quot;https://github.com/JayBeavers/Reflecta&quot; rel=&quot;nofollow&quot;&gt;Reflecta&lt;/a&gt; or &lt;a href=&quot;https://github.com/jgautier/firmata&quot; rel=&quot;nofollow&quot;&gt;Firmata&lt;/a&gt; to turn the Arduino into a set of 'remote hardware ports' for the Beaglebone.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A new entry into this space is the &lt;a href=&quot;https://www.sparkfun.com/products/11712&quot; rel=&quot;nofollow&quot;&gt;PCDuino from SparkFun&lt;/a&gt;.  Theoretically this combines both boards into one.  I haven't tried it out myself to validate however.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You should be able to put together a robot based on these parts for around your price range of $300.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;BeagleBone&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://beagleboard.org/static/bonescript/bone101/bone_connectors.jpg&quot; alt=&quot;BeagleBone&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Arduino Leonardo&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;https://dlnmh9ip6v2uc.cloudfront.net/images/products/1/1/2/8/6/11286-01_i_ma.jpg&quot; alt=&quot;Arduino Leonardo&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;PCDuino&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/bSp2H.jpg&quot; alt=&quot;PCDuino&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="35" LastActivityDate="2013-03-11T16:44:48.730" />
  <row Id="1046" PostTypeId="1" CreationDate="2013-03-11T22:06:31.510" Score="1" ViewCount="124" Body="&lt;p&gt;I want to make a list of what knowledge is necessary for &lt;a href=&quot;http://en.wikipedia.org/wiki/Sensor_fusion&quot; rel=&quot;nofollow&quot;&gt;sensor fusion&lt;/a&gt;. Since it has a wide array of possible applications, it is not clear where to begin studying. Can &lt;em&gt;we&lt;/em&gt; please verify add topics that are in-scope, and specify to what extent?:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Digital Signal Processing - course: &lt;a href=&quot;https://www.coursera.org/course/dsp&quot; rel=&quot;nofollow&quot;&gt;https://www.coursera.org/course/dsp&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Probability - course &lt;a href=&quot;http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-041-probabilistic-systems-analysis-and-applied-probability-spring-2006/lecture-notes/&quot; rel=&quot;nofollow&quot;&gt;http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-041-probabilistic-systems-analysis-and-applied-probability-spring-2006/lecture-notes/&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Machine Learning - course at Coursera from Stanford University&lt;/li&gt;&#xA;&lt;li&gt;Programming robotic car - course at Udacity&lt;/li&gt;&#xA;&lt;li&gt;Knowledge of Matlab and Simulink - tutorials on mathworks webpage and offline help.&lt;/li&gt;&#xA;&lt;li&gt;Basic knowledge about integrals, matrices operations, differential equations.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="1012" LastEditorUserId="163" LastEditDate="2013-03-13T21:59:35.110" LastActivityDate="2013-04-12T22:05:55.183" Title="Overview - what skills are needed for sensor fusion?" Tags="&lt;sensors&gt;&lt;sensor-fusion&gt;" AnswerCount="1" CommentCount="3" />
  <row Id="1047" PostTypeId="1" AcceptedAnswerId="1058" CreationDate="2013-03-12T07:59:49.377" Score="3" ViewCount="213" Body="&lt;p&gt;Currently I am reading a book of Mr. Thrun: &lt;a href=&quot;http://www.probabilistic-robotics.org/&quot; rel=&quot;nofollow&quot;&gt;Probabilistic Robotics&lt;/a&gt;. I find it really helpfull to understand concept of filters, however I would like to see some code in eg. Matlab. Is the book &quot;Kalman Filter for Beginners: with MATLAB Examples&quot; worth buying, or would you suggest some other source to learn the code snippets from?&lt;/p&gt;&#xA;" OwnerUserId="1012" LastEditorUserId="37" LastEditDate="2013-03-12T13:23:45.977" LastActivityDate="2013-06-03T17:01:27.983" Title="Source to learn Kalman Fusion, explanatory code snippets" Tags="&lt;kalman-filter&gt;&lt;books&gt;" AnswerCount="6" FavoriteCount="3" />
  <row Id="1048" PostTypeId="2" ParentId="1047" CreationDate="2013-03-12T09:53:06.160" Score="1" Body="&lt;p&gt;The Kalman Filter is based on some assumptions - a linear process with independent normally distributed noise. Noise over time is independent. Each measurement is also independent.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The Wikipedia article (&lt;a href=&quot;http://en.wikipedia.org/wiki/Kalman_filter&quot; rel=&quot;nofollow&quot;&gt;http://en.wikipedia.org/wiki/Kalman_filter&lt;/a&gt;) is quite complete in information on this. This article should be enough to allow you to implement the Kalman Filter. Other sources also exist on the internet. Most people here will not be able to give an opinion on the book you mentioned - since we have not read it, and I will never read it because I do not need to.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The Wikipedia article contains, in particular, &lt;a href=&quot;http://en.wikipedia.org/wiki/Kalman_filter#Details&quot; rel=&quot;nofollow&quot;&gt;detailed equations&lt;/a&gt; showing each step that a Kalman filter takes. In particular the equations given implement a filter allowing the covariance (noise in measurements) to differ on different timesteps, and keeps an updated estimate of the covariance (accuracy) of the estimated states.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is also an &lt;a href=&quot;http://en.wikipedia.org/wiki/Kalman_filter#Example_application.2C_technical&quot; rel=&quot;nofollow&quot;&gt;example&lt;/a&gt; which helps walk through the equations.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;An alternative way of implementing the Kalman filter is simply as a fixed state-space linear time-invariant filter. The relevant equation is $x(k)=x(k-1)+Ky(k)$. This is a simplification of the full set of equations, because $K$ - the Kalman gain, is fixed if the covariances are fixed. The gain can also be obtained from the solution to the &lt;a href=&quot;http://en.wikipedia.org/wiki/Algebraic_Riccati_equation&quot; rel=&quot;nofollow&quot;&gt;Discrete-time Algebraic Ricatti equation&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="145" LastActivityDate="2013-03-12T09:53:06.160" />
  <row Id="1049" PostTypeId="1" AcceptedAnswerId="1055" CreationDate="2013-03-12T16:25:48.563" Score="5" ViewCount="340" Body="&lt;p&gt;I want to built a robot and i need bunch of modules to track it like GSM/GPS Wifi and Camera&#xA;If i try to buy each of module separately it will cost me 300 dollar each aprox in Pakistan. On the other hand an android enable phone can be purchased on just 250$ having all of them. I was wondring if it is possible to interface android phones like (Huawaii or google nexus) with 8-bit microcontrollers or Arduino? The only port available with android phones are USB and Arduino supports USB. It is possible to some how attach both of them?&lt;/p&gt;&#xA;" OwnerUserId="1015" LastActivityDate="2013-03-12T22:07:13.753" Title="Is it possible to interface android mobile as GSM and GPS module with arduino based robotic applications?" Tags="&lt;arduino&gt;&lt;usb&gt;" AnswerCount="1" CommentCount="2" />
  <row Id="1050" PostTypeId="1" AcceptedAnswerId="1053" CreationDate="2013-03-12T17:18:03.467" Score="12" ViewCount="168" Body="&lt;p&gt;For example, if a rover has working temperature range of -70 to +120 Celsius, how does it survive and then restore itself if the temperature drops to -150 degrees for several months?&lt;/p&gt;&#xA;" OwnerUserId="1007" LastEditorUserId="37" LastEditDate="2013-03-13T11:23:49.523" LastActivityDate="2013-03-13T11:23:49.523" Title="How do space rovers survive at very low temperatures?" Tags="&lt;electronics&gt;&lt;ugv&gt;&lt;reliability&gt;" AnswerCount="1" FavoriteCount="1" />
  <row Id="1051" PostTypeId="1" CreationDate="2013-03-12T17:37:51.190" Score="6" ViewCount="105" Body="&lt;p&gt;Within robotics programming, orientation is primarily given in terms of x, y, &amp;amp; z coordinates, from some central location.  However x, y, z coordinates aren't convenient for rapid human understanding if there are many locations from which to select (e.g., {23, 34, 45}, {34, 23, 45}, {34, 32, 45}, {23, 43, 45} is not particularly human friendly, and is highly prone to human error).  Yet more common English orientation descriptors are frequently either too wordy or too imprecise for rapid selection (e.g.,  &quot;front-facing camera on robot 1's right front shoulder&quot; is too wordy; but &quot;front&quot;/ &quot;forward&quot; is too imprecise - is the camera on the leading edge or is it pointing forward?)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the naval and aeronautical fields vehicle locations are generically talked about as fore, aft (or stern), port, and starboard. While, direction of movement that is relative to the vehicle is frequently given in reference to a clockface (e.g., forward of the the fore would be &quot;at 12&quot;, rear of the aft would be &quot;at 6&quot;, while right of starboard and left of port would be &quot;at 3&quot; and &quot;at 9&quot;, respectively).  This language supports rapid human communication that is more precise than terms such as &quot;front&quot; and &quot;forward&quot;.  Are there equivalent terms within mobile robotics?&lt;/p&gt;&#xA;" OwnerUserId="1016" LastEditorUserId="350" LastEditDate="2013-03-18T15:16:26.173" LastActivityDate="2013-03-25T23:43:50.693" Title="What are human-friendly terms for mobile-robot orientation and relative direction of non-robot objects?" Tags="&lt;mobile-robot&gt;&lt;control&gt;&lt;design&gt;&lt;localization&gt;&lt;navigation&gt;" AnswerCount="2" CommentCount="2" />
  <row Id="1052" PostTypeId="2" ParentId="954" CreationDate="2013-03-12T17:42:14.807" Score="3" Body="&lt;p&gt;I'm guessing you're using the arduino libraries (haven't used the Teensy), in which case, if you read through the documentation (&lt;a href=&quot;http://arduino.cc/en/Reference/Servo&quot; rel=&quot;nofollow&quot;&gt;http://arduino.cc/en/Reference/Servo&lt;/a&gt;), you'll see that the Arduino servo library&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Supports up to 12 motors on most Arduino boards and 48 on the Arduino Mega&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;You can manually bitbang the pwm signals for your servo if you don't have too many other time-critical things going on, or make/get a separate serial servo controller, or do any of a number of other things. This is good reading to understand what is going on:&#xA;&lt;a href=&quot;http://arduino.cc/en/Tutorial/SecretsOfArduinoPWM&quot; rel=&quot;nofollow&quot;&gt;http://arduino.cc/en/Tutorial/SecretsOfArduinoPWM&lt;/a&gt; (I would click through to the original document for a visual view of the different timer modes).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;p.s. what are you doing with 24 servos and one microcontroller? sounds exciting!&lt;/p&gt;&#xA;" OwnerUserId="1005" LastActivityDate="2013-03-12T17:42:14.807" />
  <row Id="1053" PostTypeId="2" ParentId="1050" CreationDate="2013-03-12T18:29:48.907" Score="11" Body="&lt;p&gt;That is a very good question, and depends on the design. There are in general two ranges for components which are temperature sensitive. The operational range gives the temperature at which the component can be actively used. Within the survival range the component should generally take no harm but may not be actively used. Often what is even more demanding on the components than extreme temperatures is temperature cycling. Mars for example usually has a large amount of cycles, where as moon has the more extreme temperatures, but less cycling.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In principle there are two ways to handle low temperatures for space rovers&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Heating your rover so that all the components that are temperature sensitive stay within the respective limits. You can use active heating by for example using energy from your battery. Depending on the battery and your insulation you may not hold out very long though. Radioactive heater units (RHU) are another alternative that can be very effective.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Increasing the temperature tolerance of your system is another option. This can be done by selection of tolerant components, or potentially extending the range of existing components. Usually the most temperature sensitive component is the battery. Insulation is also possible, but may only get you so far.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;In general one could say that the thermal design is one of the most critical aspects for space probes, and will often decide about the feasibility of a mission.&lt;/p&gt;&#xA;" OwnerUserId="127" LastActivityDate="2013-03-12T18:29:48.907" CommentCount="2" />
  <row Id="1054" PostTypeId="2" ParentId="1051" CreationDate="2013-03-12T18:29:59.247" Score="5" Body="&lt;p&gt;Typically, a coordinate frame is placed at the robot center.  The x-axis points forward, the y-axis points left, and the z-axis points up.  Then, we measure angles with respect to the x-axis. So, a 90 degree angle would mean along the y-axis, as shown, &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/TjCRx.gif&quot; alt=&quot;Coordinate Frames for Mobile Robots&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, &quot;12&quot; corresponds to 0 yaw, or straight forward. &quot;9&quot; corresponds to 90 degree yaw, or along the y-axis.  6 corresponds to 180 degree yaw, or straight back along the minus x-axis, etc. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;You are asking &quot;How do I describe an object relative to the robot&quot;, which is the same as &quot;how do I describe the location of the object in the robot's coordinate frame&quot; By necessity, we consider the both to be the same, so the &quot;driver's side&quot; wheel is the &quot;front left&quot;. Front because it is +X, and left because it is +Y. The cans are in &quot;front&quot; of the robot because they have a +X coordinate. They are &quot;below&quot; the robot because they have a -Z coordinate.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;It's the same as &quot;Port&quot;, &quot;Aft&quot;, &quot;Starboard&quot;, because these are described &lt;em&gt;with respect to the vehicle&lt;/em&gt;, not with respect to the observer. This is the basic definition of a &lt;a href=&quot;http://en.wikipedia.org/wiki/Frame_of_reference&quot;&gt;Frame of Reference&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="163" LastEditorUserId="163" LastEditDate="2013-03-12T21:24:46.457" LastActivityDate="2013-03-12T21:24:46.457" CommentCount="12" />
  <row Id="1055" PostTypeId="2" ParentId="1049" CreationDate="2013-03-12T22:07:13.753" Score="3" Body="&lt;p&gt;Yes, it is possible. You need the Android Accessory API and &lt;a href=&quot;http://developer.android.com/tools/adk/index.html&quot; rel=&quot;nofollow&quot;&gt;Android Accessory Development Kit&lt;/a&gt;. It is based off Arduino, and is open. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In general, if the phone + the ADK is cheaper than buying the components separately (I suspect it would be), then I'd buy the phone + ADK.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Your other option is to buy a phone, and a bluetooth shield for a microcontroller, then use the bluetooth connection to send data between the phone and microcontroller.&lt;/p&gt;&#xA;" OwnerUserId="163" LastActivityDate="2013-03-12T22:07:13.753" CommentCount="1" />
  <row Id="1056" PostTypeId="1" AcceptedAnswerId="1067" CreationDate="2013-03-13T10:09:37.960" Score="2" ViewCount="97" Body="&lt;p&gt;I need help with figuring out the following things:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm developing a hexapod R-Hex type model with a tripod gait. However, the angles obtained during the robot's walking in real life are not perfectly aligned. Because of this the robot often collapses and falls even on perfectly straight terrain.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My configuration is: &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;60 rpm dc motors for each leg&lt;/li&gt;&#xA;&lt;li&gt;H-bridge motor drivers for each dc motor&lt;/li&gt;&#xA;&lt;li&gt;Atmega 8&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Should I change the gait type?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Or is Tripod sufficiently stable?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Are DC motors providing fine enough control or do I need servos?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Do I need a DC motor with an Encoder? &#xA;What will be its benefits?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What could be done to improve performance of the robot?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Added: Would a Stepper motor work as well, instead of a servo?&lt;/strong&gt;&lt;/p&gt;&#xA;" OwnerUserId="333" LastEditorUserId="333" LastEditDate="2013-03-15T04:59:59.177" LastActivityDate="2013-03-15T04:59:59.177" Title="Perfecting Tripod Gait - Building a R-Hex Robot" Tags="&lt;motor&gt;&lt;wheeled-robot&gt;&lt;gait&gt;" AnswerCount="1" CommentCount="4" />
  <row Id="1057" PostTypeId="2" ParentId="997" CreationDate="2013-03-13T14:20:53.693" Score="1" Body="&lt;p&gt;I use TI chips (typically the Stellaris line) and I agree that you need to provide much more information. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;That being said I think your problem lies in one of two areas (probably the second one):&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;1) Your device isn't emulating:&lt;/strong&gt;&#xA;When you connect your device to the computer does it make the '&lt;em&gt;du-duh&lt;/em&gt;' sound? Alternatively press start, right-click 'Computer', go to 'Manage' and check in Devices manager if you are showing up as a COM port. If you are not, then your problem lies with a) your driver (although your device should still show up) or on your embedded side. I'd bet on the latter. This means this is not the website for your to figure it out on and fixing this is no small task. However if you've come this far, maybe you won't mind coming a little further. However from your screen shot it does look like it is emulating, so let's go to option number two.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;2) You are throwing an exception when connecting:&lt;/strong&gt;&#xA;I'm going to assume that you are using the .NET framework &lt;code&gt;SerialPort&lt;/code&gt; class in VB (btw you should update to something newer than VB2006 or at least make sure your .NET framework is up to date if you haven't already). The &lt;code&gt;SerialPort&lt;/code&gt; class is widely regarding as being incredibly poorly written and the method &lt;code&gt;SerialPort.Open()&lt;/code&gt; actually performs about 8 things and if a single one of them fails then the whole method fails and you are up the creek. What I would do is download something like &lt;a href=&quot;http://www.compuphase.com/software_termite.htm&quot; rel=&quot;nofollow&quot;&gt;Termite&lt;/a&gt; and see if you can connect to the device that way. Most terminal programs ignore &lt;code&gt;IO Exceptions&lt;/code&gt; (which is what I bet is happening in your VB program). By the way, did you write the VB program yourself? If so, do you have a &lt;code&gt;try-catch&lt;/code&gt; around your &lt;code&gt;SerialPort.Open()&lt;/code&gt; method? Because that is a good way to figure out if that is where your problem lies. If you cannot connect with &lt;a href=&quot;http://www.compuphase.com/software_termite.htm&quot; rel=&quot;nofollow&quot;&gt;Termite&lt;/a&gt; then I would download &lt;a href=&quot;http://www.eltima.com/products/serial-port-monitor/&quot; rel=&quot;nofollow&quot;&gt;Eltima&lt;/a&gt; which is  port monitoring software. It runs in the background while you try to connect to a serial port and it will log what is happening and more importantly it will log errors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Good luck and happy coding :)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;TL;DR: get &lt;a href=&quot;http://www.eltima.com/products/serial-port-monitor/&quot; rel=&quot;nofollow&quot;&gt;Eltima&lt;/a&gt; and find the error.&lt;/strong&gt;&lt;/p&gt;&#xA;" OwnerUserId="1024" LastActivityDate="2013-03-13T14:20:53.693" />
  <row Id="1058" PostTypeId="2" ParentId="1047" CreationDate="2013-03-13T15:19:45.057" Score="3" Body="&lt;p&gt;I &lt;em&gt;have&lt;/em&gt; read the book, and found it unnecessarily obtuse. Unfortunately, the code snippets will not be very helpful, since they will probably look exactly like the equations, while using a matrix library like Eigen, OpenCV, boost, or just Matlab.  To get a good understanding of a Kalman Filter, you should start with a review of multi-variate Gaussian random variables, then brush up on Taylor Series expansions, then realize we are just inventing a covariance matrix for the joint distribution of measurements and state.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, here's some code I wrote for a robotic rover which uses an EKF. &lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;&#xA;void DifferentialKinematics::ekfMeasurement(Eigen::MatrixXd&amp;X,Eigen::MatrixXd&amp;Q,Eigen::MatrixXd&amp;Z,Eigen::MatrixXd&amp;R){&#xA;  Eigen::MatrixXd I=Eigen::MatrixXd::Identity(3,3);&#xA;  Eigen::MatrixXd ZP = Eigen::MatrixXd(Z);&#xA;  Eigen::MatrixXd XP = Eigen::MatrixXd(X);&#xA;  Eigen::MatrixXd z = Z-X;&#xA;  Eigen::MatrixXd S =Q+R;&#xA;&#xA;  Eigen::MatrixXd K=Q*S.inverse();&#xA;&#xA;  X = X + K*(z);&#xA;  Q = (I-K)*Q;&#xA;}&#xA;/**&#xA; * Update given wheel speeds left, right.&#xA; * Both are in/out&#xA; */&#xA;void DifferentialKinematics::ekfPredict(float left, float right, Eigen::MatrixXd&amp;pose, Eigen::MatrixXd&amp;cv){&#xA;  float hth=pose(2)+getTheta(left,right)/2;&#xA;  float dd = std::fabs(getVel(left,right));&#xA;  updatePose(left,right,pose);&#xA;&#xA;  //Form Jacobian&#xA;  Eigen::MatrixXd V=Eigen::MatrixXd::Zero(3,2);&#xA;  V(0,0)=(cos(hth)+(dd/width)*sin(hth))/2;&#xA;  V(0,1)=(cos(hth)-(dd/width)*sin(hth))/2;&#xA;  V(1,0)=(sin(hth)-(dd/width)*cos(hth))/2;&#xA;  V(1,1)=(sin(hth)+(dd/width)*cos(hth))/2;&#xA;  V(2,0)=(-1/width);&#xA;  V(2,1)=(1/width);&#xA;&#xA;  Eigen::MatrixXd G;&#xA;  G=Eigen::MatrixXd::Identity(3,3);&#xA;  G(0,2)=-dd*sin(hth);&#xA;  G(1,2)=cos(hth)*dd;&#xA;&#xA;  Eigen::MatrixXd M=Eigen::MatrixXd::Zero(2,2);&#xA;  M(0,0)=left &amp;lt 0? -1*left*kl:left*kl;&#xA;  M(1,1)=right &amp;lt 0? -1*right*kr:right*kr;&#xA;&#xA;  Eigen::MatrixXd R=V*M*V.transpose();&#xA;  Eigen::MatrixXd r2 = G*cv*G.transpose()+R;&#xA;  cv = r2; &#xA;  return;&#xA;}&#xA;&lt;/code&gt;&#xA;&lt;/pre&gt;&#xA;" OwnerUserId="163" LastEditorUserId="163" LastEditDate="2013-03-13T15:25:22.427" LastActivityDate="2013-03-13T15:25:22.427" CommentCount="1" />
  <row Id="1059" PostTypeId="2" ParentId="1046" CreationDate="2013-03-13T16:02:58.323" Score="1" Body="&lt;p&gt;You can skip all but 2,6,5, if you want to learn how sensor information is fused to form a consistent estimate of something. 5 is optional but helpful. The best course you can take is a Optimal Estimation / Filtering course, and a Probabilities and Stochastic Processes course. Try MIT Courseware for both of those.&lt;/p&gt;&#xA;" OwnerUserId="163" LastActivityDate="2013-03-13T16:02:58.323" CommentCount="2" />
  <row Id="1060" PostTypeId="1" CreationDate="2013-03-13T23:32:26.337" Score="1" ViewCount="799" Body="&lt;p&gt;I want to know if there is best algorithm and technique to implement self learning maze solving robot in 8 bit limited resource micro-controller? I was looking for some well optimized algorithm and/or technique. Maze can be of any type. Of-course first time it has to walk all the way and keep tracking obstacles it found. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I think best technique would be neural networks but is it possible to do this in such a short resources of 8bit? Any example online with similar kind of problem? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;My wall detection is based on units, well, I have counted the wheel turns and it is almost 95% accurate in integers. For sensing the walls Ultrasonic range finding is used. Wheel can remeber its current position in let say, 3 feet staight, 2 feet right, etc.&lt;/p&gt;&#xA;" OwnerUserId="1015" LastEditorUserId="187" LastEditDate="2014-01-13T20:52:48.597" LastActivityDate="2014-01-13T20:52:48.597" Title="Self learning maze solving robot using 8bit microcontroller?" Tags="&lt;algorithm&gt;&lt;machine-learning&gt;&lt;mapping&gt;&lt;micromouse&gt;" AnswerCount="4" CommentCount="4" FavoriteCount="1" />
  <row Id="1061" PostTypeId="2" ParentId="1060" CreationDate="2013-03-14T00:45:33.297" Score="1" Body="&lt;p&gt;Neural networks are not the best by a loooong shot. Neural networks are &lt;em&gt;not&lt;/em&gt; AI, they are a way to do regression and classification. If you don't know what those things are, then you have no business working with Neural Networks.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What you have described is a mapping problem. You need two things from a good algorithm in this case:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;Coverage. You need to ensure that the robot can reach every part of the maze. If it cannot, then it might not find the exit / entrance.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Mapping. You need to ensure that you can keep track of all the obstacles.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Without more information about the type of maze, type of robot, and type of obstacles, I'm afraid this problem is under-determined. &lt;/p&gt;&#xA;" OwnerUserId="163" LastEditorUserId="163" LastEditDate="2013-03-15T16:45:25.990" LastActivityDate="2013-03-15T16:45:25.990" />
  <row Id="1062" PostTypeId="2" ParentId="1060" CreationDate="2013-03-14T02:41:55.713" Score="4" Body="&lt;p&gt;Perhaps the best way to get started on this kind of problem is to take relevant coursework(either online or in real life) or to read an introductory book on this topic. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;A good introductory book on motion planning and SLAM is &lt;a href=&quot;http://mitpress.mit.edu/books/principles-robot-motion&quot; rel=&quot;nofollow&quot;&gt;Principles of Robotic Motion&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A good course on SLAM/Mobile Robots: &lt;a href=&quot;https://www.coursera.org/course/conrob&quot; rel=&quot;nofollow&quot;&gt;Control of Mobile Robots&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="333" LastActivityDate="2013-03-14T02:41:55.713" />
  <row Id="1063" PostTypeId="2" ParentId="999" CreationDate="2013-03-14T05:49:20.607" Score="3" Body="&lt;p&gt;Holding torque, by the stepper motor definition, is not a valid way to quantify servo performance.  Stepper motor torque drops off with speed whereas in a servo it remains relatively constant.  (Operating torque is never half of holding torque and is RPM dependent, your guide lied to you).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A real servo will always have a torque (continuous/operating) rating under which it will remain controlled, and a maximum torque rating where it is just running full power.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I cannot imagine ever buying a servo that does not list those two values, (especially considering that most servos will have a fairly substantial datasheet) but a quick survey shows that continuous torque is generally not half of the maximum torque.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note that hobby servo specifications are so inaccurate they might as well be made up so this question would not apply to them either.&lt;/p&gt;&#xA;" OwnerUserId="65" LastActivityDate="2013-03-14T05:49:20.607" CommentCount="1" />
  <row Id="1064" PostTypeId="1" AcceptedAnswerId="1109" CreationDate="2013-03-14T11:18:41.797" Score="2" ViewCount="158" Body="&lt;p&gt;I want to prototype a therapeutic device that will have a lot of tiny mobile-phone type vibration motors &lt;a href=&quot;http://www.cutedigi.com/robotics/vibration-motor.html&quot; rel=&quot;nofollow&quot;&gt;like this one&lt;/a&gt; in it, and I want to be able to activate them in any configuration I want.  I'm going to need analogue control, and support for logic like perlin noise functions and so on.  I'm not really going to need sensor data or any other kind of feedback beyond a few buttons for control.  I just need fine control over lots of little motors.  Depending on what results I can get out of, say, 25 motors on the initial prototype, I may decide that I'm done, or that it needs more motors.  I also don't have an enormous budget.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So the question is, is Arduino a good fit for a project like this?  Is it feasible to get that many motors working off the same controller?  I know some of the Arduino boards have up to 50-something serial outputs, but from what I can tell, that may only translate to 25 or so motors, so I'd need a way to extend the board with more serial outputs if I wanted to try more.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Additionally, if Arduino isn't a good fit, what would be better?  Could I try something directly out of a serial port on my PC?  I've never tried to home-cook a robotics application before, so I'm not really aware of the options.&lt;/p&gt;&#xA;" OwnerUserId="1031" LastEditorUserId="1031" LastEditDate="2013-03-14T11:26:43.380" LastActivityDate="2013-03-27T16:33:15.337" Title="Prototyping a device with 25-100 small DC 3.0V motors, is Arduino a good fit?" Tags="&lt;arduino&gt;&lt;motor&gt;" AnswerCount="2" FavoriteCount="1" />
  <row Id="1065" PostTypeId="2" ParentId="1064" CreationDate="2013-03-14T13:45:02.763" Score="3" Body="&lt;p&gt;The issue may not be what micro is the best choice. Note 25 to 50 IO can be expensive if implemented on the micro itself. A ATmega2560 with the most pins is significantly more in price then a 328 or Tiny. Same goes for other chips. All those additional pins may not have the function you need. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can use the micro's SPI (or I2C) port to shift out the IO. For SPI you could daisy chain as many 74HC595 as you need until you get your desired amount of Digital Output. There are equivalents for Input. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;And if you wanted to control the intensity of the motor, you can use PWM. And there are SPI or I2C chips for these too.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note a big problem will be power. If you were to connect 25 motors to a single micro the initial inrush if not the continuous load of turning on all the motors would likely brown out the micro as each IO may individually support the supply for the motor. Combined they all need to feed through the chips VCC pins. Hence breaking it up to individual 74HC595 would spread out the heat and load away from the micro. These are cheap chips and easily ported to any micro. You can even get evals of them on break out PCB's.&lt;/p&gt;&#xA;" OwnerUserId="821" LastActivityDate="2013-03-14T13:45:02.763" CommentCount="1" />
  <row Id="1066" PostTypeId="1" CreationDate="2013-03-14T15:20:22.533" Score="2" ViewCount="183" Body="&lt;p&gt;I currently have a working kinematic chain made by a set of ten links in &lt;a href=&quot;http://en.wikipedia.org/wiki/Denavit%E2%80%93Hartenberg_parameters&quot; rel=&quot;nofollow&quot;&gt;D-H convention&lt;/a&gt; (with usual parameters [ $A_i, D_i, \alpha_i, \theta_i$]).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But my task currently requires the inversion of some of them. Basically, I would have a part of the chain that is read from the end-effector to the origin, using the same links (and thus the same parameters). Is it possible? How to do so?&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Please notice that this is not related to the &lt;a href=&quot;http://robotics.stackexchange.com/q/299/37&quot;&gt;inversion of the kinematic chain&lt;/a&gt;. It's more basic: &lt;em&gt;I want to find the dh parameters of the inverted forward kinematic chain&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Let's put it simple: I have dh parameters for a 2 link planar chain from joint 0 to joint 1, so I can compute its direct kinematics. But what if I want to compute the direct kinematics from joint 1 to joint 0?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Given DH parameters [ $A_i, D_i, \alpha_i, \theta_i$], I can retrieve the transform matrix with this formula:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$G = \left[\begin{matrix}&#xA;cos(\theta) &amp;amp; -sin(\theta)*cos(\alpha) &amp;amp;  sin(\theta)*sin(\alpha) &amp;amp; cos(\theta)*a \\&#xA;sin(\theta) &amp;amp;  cos(\theta)*cos(\alpha) &amp;amp; -cos(\theta)*sin(\alpha) &amp;amp; sin(\theta)*a \\&#xA;          0 &amp;amp;              sin(\alpha) &amp;amp;              cos(\alpha) &amp;amp;             d \\&#xA;          0 &amp;amp;                        0 &amp;amp;                        0 &amp;amp;             1&#xA;\end{matrix} \right]$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is the transform matrix from the i-th link to the (i+1)-th link. Thus, I can invert it to obtain the transform matrix from the (i+1)-th link to the i-th link, but the problem is that this is not working. I believe that the reason is related to the fact that the DH convention doesn't work any more &lt;strong&gt;as it is&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any help?&lt;/p&gt;&#xA;" OwnerUserId="1033" LastEditorUserId="1033" LastEditDate="2013-03-27T13:44:12.367" LastActivityDate="2013-09-06T09:29:25.550" Title="How to invert D-H parameters" Tags="&lt;control&gt;&lt;inverse-kinematics&gt;&lt;kinematics&gt;" AnswerCount="1" CommentCount="0" />
  <row Id="1067" PostTypeId="2" ParentId="1056" CreationDate="2013-03-14T17:18:11.607" Score="2" Body="&lt;p&gt;Tripod gait is a stable gait. Moreover, it is a statically stable gait, meaning that if you lock the joints with 3 legs down and turn the power off, the robot will not topple. This implies that you don't need to dynamically balance the robot while walking. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The reason when a legged robot falls down is that its center of gravity does not fall on its support polygon (in tripod gait case, it is a triangle with each corner on one leg that's touching the ground). So what you should do is to measure the center of gravity and guarantee that it never leaves the support polygon of your robot while walking via adjusting your leg motion. Of course, this is all for a statically stable gait. Dynamically stable gaits allow the center of gravity to leave the support polygon in a controlled manner. But as I said, the tripod gait is statically stable. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm assuming that you are using naked DC motors without encoders or gear trains. There are two issues about this:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;First, make sure that you are getting enough total torque at each leg triplet that lift the robot. It may be the case that the DC motors cannot lift the robot on their own without a gear train. &lt;/li&gt;&#xA;&lt;li&gt;Second, errors tend to grow without bound when performing such a task, angular position errors being one example. This is simply due to noise and imperfect modeling of the motor. So in a sense, DC motors are not actually &quot;controlled&quot;, you just apply an input while not knowing what the output is. You must apply closed loop control, which is done via getting feedback from an encoder. Then, you can sense what the angular position on your motor is, determine your error, and apply an input to correct that error.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Both of these problems are addressed in a servomotor, which is basically a DC motor, a gear train to increase torque and reduce angular velocity, and an encoder. I very much suggest using servos for your leg joints. &lt;/p&gt;&#xA;" OwnerUserId="1000" LastEditorUserId="1000" LastEditDate="2013-03-14T20:24:46.920" LastActivityDate="2013-03-14T20:24:46.920" CommentCount="2" />
  <row Id="1068" PostTypeId="1" CreationDate="2013-03-15T01:42:18.520" Score="3" ViewCount="28" Body="&lt;p&gt;I am trying to run a nxt motor using the mindsensors motor multiplexer at a slow speed.  When I turn it on, it tends to jump approx 20 to 40 degrees before moving at a slow speed.  Has anyone seen this behavior?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am using NXT 1.0 with firmware down loaded from &lt;code&gt;lms_arm_mindsensors_129.rfw&lt;/code&gt;.  Sample code in NXC (I am using Bricx Command Center as my IDE) is as follows:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;MMX_Run_Degrees (SensorPort, Addr, MMX_Motor_2, MMX_Direction_Reverse,&#xA;     MMX_Speed_Slow, 220, MMX_Completion_Wait_For, MMX_Next_Action_Brake);&#xA;Wait(500);&#xA;&#xA;MMX_Run_Unlimited( SensorPort, Addr, MMX_Motor_2,MMX_Direction_Forward, 5);&#xA;// The jump happens here.&#xA;while(Sensor(IN_2)&amp;lt; SENSORTHRESHOLD);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="572" LastEditorUserId="37" LastEditDate="2013-03-15T19:48:41.803" LastActivityDate="2013-03-15T19:48:41.803" Title="Mindsensor Motor Multiplexer jump on run_unlimited" Tags="&lt;nxt&gt;" CommentCount="0" />
  <row Id="1069" PostTypeId="1" AcceptedAnswerId="1071" CreationDate="2013-03-15T13:23:35.370" Score="2" ViewCount="431" Body="&lt;p&gt;Is there a way to use a single dc motor output for two different loads (by using gears, relays etc) ? Please see the illustration below:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://oi50.tinypic.com/2z5sjdx.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To clarify the illustration, I get the dc motor power at &quot;output 1&quot; gear which is extended over an idler gear to output 2 gear. All three are in contact (though the picture doesn't quite show it). Load 1 and Load 2 are two separate gears connected to different loads (wheels etc) and initially not in contact with the bottom gears. On switching on the relays 1, 2 - the load bearing gears, move towards the output1 and output2 and mesh with them to drive Load 1, 2.&lt;/p&gt;&#xA;" OwnerUserId="1041" LastEditorUserId="1041" LastEditDate="2013-03-15T14:09:20.443" LastActivityDate="2013-03-22T18:08:50.880" Title="Is there a way to use a single dc motor output for two different loads?" Tags="&lt;motor&gt;" AnswerCount="3" CommentCount="2" />
  <row Id="1070" PostTypeId="2" ParentId="1069" CreationDate="2013-03-15T14:08:10.233" Score="1" Body="&lt;p&gt;Well, You question is unclear, But as far as I understand You can drive two different load from a single motor by making a correct mechanical gear box assembly. You can rotate two wheels into two different directions with the use of proper gear system. &lt;/p&gt;&#xA;" OwnerUserId="1015" LastActivityDate="2013-03-15T14:08:10.233" CommentCount="1" />
  <row Id="1071" PostTypeId="2" ParentId="1069" CreationDate="2013-03-15T14:10:19.167" Score="4" Body="&lt;p&gt;Absolutely. Think of how your car works. The engine/motor drives two (or more) wheels at the same time. And the loads presented by the independent wheels are often of very different magnitudes. For instance when the car is turning or when one wheel is slipping.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What you need to split the power is a &lt;a href=&quot;http://www.howstuffworks.com/differential.htm&quot; rel=&quot;nofollow&quot;&gt;differential&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;h1&gt;What is a Differential?&lt;/h1&gt;&#xA;  &#xA;  &lt;p&gt;The differential is a device that splits the engine torque two ways,&#xA;  allowing each output to spin at a different speed.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.platinumautoservice.com/differential&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/588yj.jpg&quot; alt=&quot;differential&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This would split the motor load equally. It would allow both outputs to spin at the same speed if their loads are equal. If one load increases or is greater, it will slow down without affecting the speed of the other load.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If the loads are nominally different and you need them to spin at the same speed or if the loads are equal and you need them to spin at different speeds, then you can just add speed change gears to one of the outputs.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://enginemechanics.tpub.com/14037/css/14037_41.htm&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/r0rLE.jpg&quot; alt=&quot;gears used to change speed&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Where your output speed would equal your input speed times the difference in the numbers of teeth on the gears:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$S_2 = S_1 \times \dfrac{T_1}{T_2}$$&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Edit to answer comment on meshing gears:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Your intuition isn't that far off. Using a solenoid to engage and disengage a load is how part time four-wheel drive works. The solenoid engages and disengages the locking hubs to connect and disconnect the load. But simpler designs will cause a sudden increase in torque demand resulting in some jerk if the motor can't compensate for it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You would be better off using a &lt;a href=&quot;http://auto.howstuffworks.com/clutch.htm&quot; rel=&quot;nofollow&quot;&gt;clutch&lt;/a&gt; to gradually apply the load:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.infomanejo.com/How-does-the-clutch-work.html&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/OYHcs.png&quot; alt=&quot;clutch load application&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="142" LastEditorUserId="142" LastEditDate="2013-03-15T15:02:50.627" LastActivityDate="2013-03-15T15:02:50.627" CommentCount="4" />
  <row Id="1072" PostTypeId="1" CreationDate="2013-03-15T14:16:49.523" Score="2" ViewCount="291" Body="&lt;p&gt;This question was asked in &lt;a href=&quot;http://electronics.stackexchange.com/questions/61014/real-time-location-sensor-for-following-a-kite-in-the-air?noredirect=1#comment117178_61014&quot;&gt;electronics stackexchange&lt;/a&gt;. I want to know if is it possible to make a robot that can fly kites. Is this idea practical? I was thinking that making a kite is just like making some flying quadcopter or helicopter. I just want to know is this idea really implementable?  Is there an example or similar work in reference to this?     &lt;/p&gt;&#xA;" OwnerUserId="1015" LastEditorUserId="350" LastEditDate="2013-03-17T20:07:53.427" LastActivityDate="2013-07-29T19:49:51.947" Title="Is it possible to make Kite flying robot?" Tags="&lt;control&gt;&lt;quadcopter&gt;&lt;radio-control&gt;" AnswerCount="5" CommentCount="8" />
  <row Id="1073" PostTypeId="2" ParentId="1060" CreationDate="2013-03-15T20:03:13.373" Score="3" Body="&lt;p&gt;My understanding of your problem is that you would like to discover and navigate a 2D maze of irregular obstacles with a non-&lt;a href=&quot;http://en.wikipedia.org/wiki/Holonomic_%28robotics%29&quot; rel=&quot;nofollow&quot;&gt;holonomic&lt;/a&gt; robot using a single forward-looking ultrasonic range sensor and wheel odometry.  This is a hard problem.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;&quot;Best&quot; solution&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Although a &quot;best&quot; or &quot;optimal&quot; solution to this problem possibly &lt;em&gt;could&lt;/em&gt; be implemented on an 8-bit microcontroller, it is made up of 3 problems -- each nontrivial and frequently left to full-fledged  computing systems:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Enhancing your ultrasonic sensor to be able &lt;a href=&quot;http://www.sciencedirect.com/science/article/pii/S0921889099000597&quot; rel=&quot;nofollow&quot;&gt;to differentiate between walls and corners&lt;/a&gt;, because echoes from a maze-like environment can confuse your sensor.&lt;/li&gt;&#xA;&lt;li&gt;Exploring and mapping the space, typically done with a &lt;a href=&quot;http://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping&quot; rel=&quot;nofollow&quot;&gt;SLAM algorithm&lt;/a&gt;.  (This will assume that you get near-perfect localization information from your odometry approach to navigation.)&lt;/li&gt;&#xA;&lt;li&gt;Using your map, compute a solution using a &lt;a href=&quot;http://en.wikipedia.org/wiki/Maze_solving_algorithm&quot; rel=&quot;nofollow&quot;&gt;maze-solving algorithm&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;h2&gt;Achievable Solutions&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Since the &quot;best&quot; solution is a tall order for an 8-bit microcontroller, focus on a &quot;dumb&quot; solution that actually works: &lt;a href=&quot;http://botbrain.com/Curriculum/CurriculumWeb/maze_solving.htm&quot; rel=&quot;nofollow&quot;&gt;use whisker sensors and the right-hand rule&lt;/a&gt;.&lt;a href=&quot;http://i.stack.imgur.com/5sYnl.jpg&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/5sYnlm.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Going further, you could add a compass/accelerometer for navigation, use infrared sensors to  detect obstacles, and use a regular 2D grid with large gird squares.  That would be similar to the &lt;a href=&quot;http://en.wikipedia.org/wiki/Micromouse&quot; rel=&quot;nofollow&quot;&gt;Micromouse&lt;/a&gt; competition (&lt;a href=&quot;http://www.apec-conf.org/participating-in-apec-mainmenu-261/participating-in-micromouse-mainmenu-242&quot; rel=&quot;nofollow&quot;&gt;for example, this one&lt;/a&gt;), which also uses microcontrollers for maze solving.&#xA;&lt;a href=&quot;http://www.youtube.com/watch?v=A4hzCcFikm0&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/L5e2om.png&quot; alt=&quot;Micromouse competition&quot;&gt;&lt;/a&gt;&#xA;&lt;a href=&quot;http://i.stack.imgur.com/48k2f.png&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/48k2fm.png&quot; alt=&quot;Micromouse robot&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-03-16T17:22:04.157" LastActivityDate="2013-03-16T17:22:04.157" />
  <row Id="1074" PostTypeId="1" AcceptedAnswerId="1076" CreationDate="2013-03-16T12:37:15.563" Score="3" ViewCount="284" Body="&lt;p&gt;I'm building a quadcopter and I've received my motors and propellers.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What's the right way to assemble those together?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm not confident with what I've done, as I'm not sure the propeller would stay in place on a clockwise rotating motor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I mean, if the motor rotates clockwise, will the screw stay tightly in place, even with the prop's inertia pushing counter-clockwise?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here's what I've done (of course i'll tighten the screw...) :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/mN36U.jpg&quot; alt=&quot;Motor and propeller&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="943" LastActivityDate="2013-03-22T01:57:24.380" Title="How to assemble brushless motors and propellers?" Tags="&lt;brushless-motor&gt;" AnswerCount="2" />
  <row Id="1075" PostTypeId="2" ParentId="1072" CreationDate="2013-03-17T11:52:31.130" Score="2" Body="&lt;p&gt;Of course it's possible. Here's how I would try it out.&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;This would work best if the kite had some sort of sensor on it. GPS would work, but better would be some sort of local GPS function. This would allow the robot to know where the kite was easily. It would also be helpful to have a rate sensor to give a better overall picture of what is happening.&lt;/li&gt;&#xA;&lt;li&gt;The robot would have to be able to pick up the kite somehow, and move a far enough distance away. &lt;/li&gt;&#xA;&lt;li&gt;The robot would also need to know wind speed, to figure out where to go.&lt;/li&gt;&#xA;&lt;li&gt;When the robot was an appropriate distance away, it could simply reel in the string, probably from an elevated position.&lt;/li&gt;&#xA;&lt;li&gt;When the robot sensed that the kite was getting higher, it could stop pulling back.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;It would not be a simple robot by any means, but it should be possible. &lt;/p&gt;&#xA;" OwnerUserId="620" LastEditorUserId="620" LastEditDate="2013-03-17T16:46:12.347" LastActivityDate="2013-03-17T16:46:12.347" CommentCount="2" />
  <row Id="1076" PostTypeId="2" ParentId="1074" CreationDate="2013-03-17T12:55:35.417" Score="2" Body="&lt;p&gt;This is correct. Just make sure to insert a lever into the hole at the top to really tighten the nut!&lt;/p&gt;&#xA;" OwnerUserId="1048" LastActivityDate="2013-03-17T12:55:35.417" CommentCount="5" />
  <row Id="1077" PostTypeId="2" ParentId="1060" CreationDate="2013-03-17T16:20:02.587" Score="3" Body="&lt;p&gt;You might want to have a look at my maze solving robot solution (&lt;a href=&quot;http://www.benaxelrod.com/robots/maze/index.html&quot; rel=&quot;nofollow&quot;&gt;http://www.benaxelrod.com/robots/maze/index.html&lt;/a&gt;).  I used a Lego RCX which is more powerful than an 8bit microcontroller, but is still pretty resource constrained.  I abstracted away most of the hardware problems to focus on the algorithm.  It uses a flood-fill or A* type algorithm.&lt;/p&gt;&#xA;" OwnerUserId="110" LastActivityDate="2013-03-17T16:20:02.587" CommentCount="1" />
  <row Id="1078" PostTypeId="1" CreationDate="2013-03-17T17:38:49.310" Score="5" ViewCount="106" Body="&lt;p&gt;For a pet project, I am trying to fly a kite using my computer.  I need to measure how far a cord extends from a device.  I also need to somehow read out the results on my computer. So I need to connect this to my pc, preferably using something standard like USB.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Since the budget is very small, it would be best if I could get it out of old home appliances or build it myself.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What technology do I need to make this measurement?&lt;/p&gt;&#xA;" OwnerUserId="1050" LastEditorUserId="350" LastEditDate="2013-03-17T20:13:44.307" LastActivityDate="2013-03-28T06:48:06.923" Title="How do I measure the distance that a cord (string) has moved?" Tags="&lt;wheel&gt;&lt;usb&gt;&lt;encoding&gt;" AnswerCount="3" CommentCount="0" />
  <row Id="1079" PostTypeId="2" ParentId="1078" CreationDate="2013-03-17T17:41:45.777" Score="2" Body="&lt;p&gt;Maybe you could take one from an old computer mouse, and count the light pulses directly from the mouse board so you could tell the length of the cord.&lt;/p&gt;&#xA;" OwnerUserId="943" LastEditorUserId="350" LastEditDate="2013-03-17T20:17:56.543" LastActivityDate="2013-03-17T20:17:56.543" CommentCount="2" />
  <row Id="1080" PostTypeId="2" ParentId="1078" CreationDate="2013-03-17T17:58:29.800" Score="4" Body="&lt;p&gt;Sure, here are a couple of choices for you:&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;For high end, you can look at a 200 counts per revolution rotary encoder like this one:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$30 &lt;a href=&quot;https://www.sparkfun.com/products/10790&quot; rel=&quot;nofollow&quot;&gt;Sparkfun 200 Counts Per Revolution Rotary Encoder&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/qKLcL.jpg&quot; alt=&quot;Rotary Encoder&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You'll need a microcontroller like an Arduino to count the rotations, there's some sample code to play with.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;$5 &lt;a href=&quot;https://www.adafruit.com/products/377&quot; rel=&quot;nofollow&quot;&gt;Adafruit 24 Counts Per Revolution Rotary Encoder&lt;/a&gt;&#xA;&lt;img src=&quot;http://i.stack.imgur.com/ECKLe.jpg&quot; alt=&quot;24 CPR Rotary Encoder&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cheaper, not quite as much community support in comments.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;For a little more fun, you can combine the rotary encoder with a gearmotor so you could control the kite string with one piece of equipment.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$40 &lt;a href=&quot;http://www.pololu.com/catalog/product/1447&quot; rel=&quot;nofollow&quot;&gt;Pololu 64 Counts Per Revolution Encoder + Gearmotor&lt;/a&gt;&#xA;&lt;img src=&quot;http://i.stack.imgur.com/NPwGc.jpg&quot; alt=&quot;Pololu Gearmotor with encoder&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="35" LastActivityDate="2013-03-17T17:58:29.800" CommentCount="2" />
  <row Id="1081" PostTypeId="2" ParentId="1005" CreationDate="2013-03-17T21:32:00.817" Score="3" Body="&lt;p&gt;You can use a MOSFET instead of relays. MOSFET replies faster so you can achieve your goal.. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here is a simple schematic of a shooting system using solenoids.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/MFHJ3.jpg&quot; alt=&quot;Shooting using MOSFETs&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note that the solenoid is the L1 Inductor in the schematic and I've used the push-pull mechanism for putting diodes in the schematic which are necessary for this system... You can see wikipedia for further info. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;And the Optocoupler is used to translate micrcontroller's signals.. ( The microcontroller's logic one is 5v while this system's logic one (VS) is 16v.) &lt;/p&gt;&#xA;&#xA;&lt;p&gt;And surely you need to put parallel capacitors between GNDHV and VS for the shooting system to work. ( Not present in this schematic. )&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Legend : &#xA;GNDHV: Voltage supply's ground ( the ground that comes in to your circuit )&#xA;VS : Voltage supply&#xA;GND: The low voltage ground which is used to power up the micro controller.&#xA;Kick: The kick signal.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note: This system kicks when the Kick is set to zero.  &lt;/p&gt;&#xA;" OwnerUserId="21" LastActivityDate="2013-03-17T21:32:00.817" />
  <row Id="1082" PostTypeId="1" AcceptedAnswerId="1084" CreationDate="2013-03-18T01:08:24.437" Score="6" ViewCount="139" Body="&lt;p&gt;I have a 4-bar linkage arm (or similar design) for a telerobot used in the &lt;a href=&quot;http://vexrobotics.com&quot; rel=&quot;nofollow&quot;&gt;VEX Robotics Competition&lt;/a&gt;.  I want to be able to press buttons on my PS3-style controller to have the arm raise to certain angles.  I have a potentiometer to measure the 4-bar's angle.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The potentiometer measures the angle of one of the joints in the shoulder of the mechanism, which is similar to this:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/CwnAQ.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What type of control should I use to stabilize the arm at these angles?&lt;/p&gt;&#xA;" OwnerUserId="314" LastEditorUserId="37" LastEditDate="2013-03-19T17:09:03.350" LastActivityDate="2013-03-19T17:09:03.350" Title="Stabilizing a Robot Arm at a Specified Height" Tags="&lt;mobile-robot&gt;&lt;control&gt;&lt;arm&gt;" AnswerCount="1" CommentCount="0" />
  <row Id="1083" PostTypeId="1" CreationDate="2013-03-18T07:04:22.903" Score="4" ViewCount="117" Body="&lt;p&gt;The textbook I'm using doesn't have the answers to the practice questions, so I'm not sure how I'm doing. Are the following DH parameters correct given the frames I assigned?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The original question is as follows:&#xA;The arm with 3DOF shown below is like the one in example 3.3, except that joint 1's axis is not parallel to the other two. Instead, there is a twist of 90 degrees in magnitude between axes 1 and 2. Derive link parameters and the kinematic equations for $^bT_w$ (where b means base frame and w means wrist frame).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Link Parameters: &lt;img src=&quot;http://i.stack.imgur.com/tuo7v.jpg&quot; alt=&quot;Link Parameters&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$\begin{array}{ccc}&#xA;  &amp;amp; const.        &amp;amp; and      &amp;amp;     &amp;amp;               \\&#xA;  &amp;amp; angle         &amp;amp; distance &amp;amp;     &amp;amp;               \\&#xA;i &amp;amp; \alpha_{i-1}  &amp;amp; a_{i-1}  &amp;amp; d_i &amp;amp; \bf{\theta_i} \\&#xA;\\&#xA;1 &amp;amp; 0             &amp;amp; 0        &amp;amp; 0   &amp;amp; \theta_1      \\&#xA;2 &amp;amp; -90           &amp;amp; L_1      &amp;amp; 0   &amp;amp; \theta_2      \\&#xA;3 &amp;amp; 0             &amp;amp; L_2      &amp;amp; 0   &amp;amp; \theta_3      \\&#xA;\end{array}$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Frame Assignments: &lt;img src=&quot;http://i.stack.imgur.com/I6XKZ.jpg&quot; alt=&quot;Frame Assignments&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="916" LastEditorUserId="37" LastEditDate="2013-03-19T00:43:09.153" LastActivityDate="2014-01-02T22:55:14.787" Title="Assigning Frames and Deriving Link Parameters" Tags="&lt;inverse-kinematics&gt;&lt;kinematics&gt;&lt;forward-kinematics&gt;" AnswerCount="1" CommentCount="2" />
  <row Id="1084" PostTypeId="2" ParentId="1082" CreationDate="2013-03-18T15:48:28.377" Score="6" Body="&lt;p&gt;This sounds like a classic case for a &lt;a href=&quot;http://en.wikipedia.org/wiki/PID_controller&quot;&gt;PID controller&lt;/a&gt;.  The &quot;derivative&quot; part of this controller will help prevent the arm from oscillating as you move to a new angle, and the &quot;integral&quot; part will help counteract the force of gravity acting on the arm.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-03-18T15:48:28.377" />
  <row Id="1085" PostTypeId="2" ParentId="1033" CreationDate="2013-03-19T00:14:09.130" Score="3" Body="&lt;h2&gt;motor controllers&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;what is the actuated quantity&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Yes, the output of the control electronics and the input of the motor, in the simplest case -- DC permanent-magnet motors -- is the &lt;em&gt;voltage applied to the motor&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In other cases, the output of the control electronics is the duty cycle of a PWM voltage applied directly to the motor or indirectly to the &quot;signal&quot; wire of a &lt;a href=&quot;http://en.wikipedia.org/wiki/Servo_%28radio_control%29&quot; rel=&quot;nofollow&quot;&gt;radio control servo&lt;/a&gt;.&#xA;They work a little differently.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In yet other cases, many people control position using &lt;a href=&quot;http://reprap.org/wiki/stepper_motor&quot; rel=&quot;nofollow&quot;&gt;stepper motors&lt;/a&gt;.&#xA;They work very differently than DC permanent-magnet motors.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;motors&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;the actuated quantity gets turned into&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Your suggestion of &quot;&lt;em&gt;torque control&lt;/em&gt;&quot; is approximately true when motor very slow or stopped.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The so-called &quot;back-EMF&quot; generated by the motor by &quot;generator action&quot; is proportional to its angular velocity.&#xA;This back-EMF allows motors to be used as generators, such as the motor/generators used in a few cars and the regenerative breaking used in a few vehicles.&#xA;(Part of the back-EMF is caused by the &quot;autoinductance&quot; of the windings, but that part is usually negligible, so I will not mention it further -- &lt;a href=&quot;http://www.inf.fu-berlin.de/lehre/SS05/Robotik/motors.pdf&quot; rel=&quot;nofollow&quot;&gt;the article you mentioned&lt;/a&gt; has a good explanation).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;At any instant, the electrical current in the motor is proportional to the applied voltage minus the back-EMF.&#xA;Meanwhile, the mechanical torque generated by the motor is approximately proportional to that electric current.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Therefore at low speeds the mechanical torque generated by the motor is proportional to the applied voltage.&#xA;But at high positive speeds, the torque generated by the max positive voltage is less; the &quot;max speed&quot; is often defined as the speed where the max positive voltage gives zero torque.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;PID&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;assume that the servo is holding a weight at a distance (so it is acting against gravity), which means an approximately constant torque load. In this case, if the position error is zero and the servo is at rest, then each of P, I and D components are zero, which means the exerted torque is zero. This would cause the weight to sink, which is countered by the error in its position causing P,I components to increase. Wouldn't this situation cause the lifted weight to oscillate and balance at a constant position which is significantly different from the goal position?&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are 2 different cases: the short-term state immediately after some heavy load is applied, and the long-term state after the arm is allowed to settle.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Please tell the person who told you that &quot;if the position error is zero and the servo is at rest, then the I component is zero&quot; to experiment with a PID controller, or read a little more about control systems (&lt;a href=&quot;http://en.wikipedia.org/wiki/control_system&quot; rel=&quot;nofollow&quot;&gt;a&lt;/a&gt;, &lt;a href=&quot;http://ftcforum.usfirst.org/showthread.php?1359-Problem-holding-motor-in-fixed-position-for-jointed-arm&quot; rel=&quot;nofollow&quot;&gt;b&lt;/a&gt;, &lt;a href=&quot;http://www.coactionos.com/embedded-design/39-motor-control.html&quot; rel=&quot;nofollow&quot;&gt;c&lt;/a&gt;, &lt;a href=&quot;http://www.seattlerobotics.org/encoder/200011/SmallRobotMotionControl.htm&quot; rel=&quot;nofollow&quot;&gt;d&lt;/a&gt;, &lt;a href=&quot;http://letsmakerobots.com/node/36435&quot; rel=&quot;nofollow&quot;&gt;e&lt;/a&gt;), or both, to fill in the gaping hole in his knowledge of what the I component does in a PID controller.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;PID with near-zero I component&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the short term, the P, I, and D components start out at approximately zero,&#xA;and so the exerted torque is approximately zero.&#xA;When Fred suddenly applies a heavy load, there is not enough torque to hold it in position, so it sinks.&#xA;The error in its position causes the P,I components to increase.&#xA;If, hypothetically, one had a controller where the I component was &lt;em&gt;completely ignored&lt;/em&gt;,&#xA;then the arm would settle at some constant position, as you mentioned.&#xA;The arm would stabilize at the position where the voltage supplied by the controller (proportional to P, the error in position) was exactly enough to hold up the weight.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;PID with significant I component&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, with the &lt;a href=&quot;http://en.wikipedia.org/wiki/PID_controller&quot; rel=&quot;nofollow&quot;&gt;PID controller&lt;/a&gt; you mentioned, the I component increases as long as there is &lt;em&gt;any&lt;/em&gt; error.&#xA;Eventually there would be enough I component accumulated that the controller would increase the voltage more than enough to hold up the weight, pushing the weight back up towards the zero-error point.&#xA;Whether the weight overshoots or not depends on how the PID controller is tuned, but as long as the P,I,D components are anywhere close to a reasonable value, the PID controller will eventually settle down to the state where:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;the arm is stable at almost exactly the goal position (with practically zero error)&lt;/li&gt;&#xA;&lt;li&gt;therefore the P and D components are practically zero&lt;/li&gt;&#xA;&lt;li&gt;The I component is not zero -- it still has some large value that accumulated previously when the arm was below the desired position.&lt;/li&gt;&#xA;&lt;li&gt;the control electronics (because the I component is not zero) drive the motor with some voltage&lt;/li&gt;&#xA;&lt;li&gt;the motor converts that voltage into some torque that holds the weight up at the goal position.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Many robotic control systems are quick enough that they converge on this final state within a tenth of a second.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When Fred (that prankster!) yanks the weight off the arm,&#xA;even though the arm is already at the goal position,&#xA;the high accumulated I component causes the arm to pop up.&#xA;That small error causes the accumulated I component to bleed off,&#xA;and (hopefully soon) the arm returns to almost exactly the goal position (with practically zero error).&lt;/p&gt;&#xA;" OwnerUserId="187" LastActivityDate="2013-03-19T00:14:09.130" CommentCount="1" />
  <row Id="1086" PostTypeId="1" AcceptedAnswerId="1087" CreationDate="2013-03-19T08:15:53.780" Score="4" ViewCount="195" Body="&lt;p&gt;How do I increase the rotation range of a standard servo? Most servos have a rotation range of ~ 180 degrees. I would like to access the entire 360 degree range on the servo, partially because I would be attaching the servo's shaft to the robotic wheel and would like it to be able to make full rotations. Or is that not possible? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would not like to however lose the 'encoder' part of the servo which allows me to clearly specify which angular position the wheel should stop at. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If I use gears in order to transform this system range, would it lead to loss of precision?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In addition, would such a transform allow the wheels to continuously rotate in one direction? From what I understand, this won't work.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Would a stepper motor with an external encoder or a dc motor with an external encoder work?&lt;/p&gt;&#xA;" OwnerUserId="333" LastEditorUserId="37" LastEditDate="2013-05-21T11:47:25.057" LastActivityDate="2013-05-21T11:47:25.057" Title="Increasing the rotation range of a servo motor" Tags="&lt;motor&gt;&lt;rcservo&gt;" AnswerCount="1" CommentCount="0" FavoriteCount="1" />
  <row Id="1087" PostTypeId="2" ParentId="1086" CreationDate="2013-03-19T08:36:30.283" Score="3" Body="&lt;p&gt;It is possible to do it. Take a look at this &lt;a href=&quot;http://www.acroname.com/robotics/info/ideas/continuous/continuous.html&quot; rel=&quot;nofollow&quot;&gt;link&lt;/a&gt;.&#xA;Of course you will not have the encoder possibility with that servo. But you dont have it currently either. You have to solder middle pin from rotary encoder (resistor) and read the value of resistance to determine current position of shaft.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you need positioning i would suggest DC motor with encoder or stepper. With stepper you can count steps made. That is only rough estimation on distance made by robot as you dont have feedback if motor has actually turn or not.&lt;/p&gt;&#xA;" OwnerUserId="973" LastActivityDate="2013-03-19T08:36:30.283" />
  <row Id="1088" PostTypeId="2" ParentId="1036" CreationDate="2013-03-19T08:43:29.430" Score="0" Body="&lt;p&gt;The Rock framework has such a widget (based on OpenPilot/GCS).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;package&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://rock-robotics.org/master/pkg/gui/map2d/index.html&quot; rel=&quot;nofollow&quot;&gt;http://rock-robotics.org/master/pkg/gui/map2d/index.html&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;code&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://gitorious.org/rock-gui/map2d&quot; rel=&quot;nofollow&quot;&gt;http://gitorious.org/rock-gui/map2d&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="56" LastActivityDate="2013-03-19T08:43:29.430" />
  <row Id="1089" PostTypeId="1" CreationDate="2013-03-19T12:29:31.630" Score="2" ViewCount="93" Body="&lt;p&gt;I have two quaternions that indicate the initial orientation of a four wheel robot, each one in relative to one reference systems. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The robot's orientation given by a quaternion q is not the same in the two reference systems: For one reference system the quaternion q1 might refer to the robot looking at positive x while the same quaternion components q1 in the second reference system might refer to the robot looking at the negative x.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have two matrices which indicate the position of the robot in time in its correspondent reference system.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I want to find the correspondent points of the first matrix in to the second reference system. Each matrix is built with a different sensor, so the results will be similar but not exactly the same.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I think I should find the transformation from the first reference system to the second and then apply it for each point of the first matrix. How can I find this transformation? The translation part I think is clear, but the rotation not at all.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Edit:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;@WildCrustacean&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The solution proposed does not solve the problem, I think that the reason is because each system represents the robot in a different way. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the initial one (A) the robot moving forward with no rotation would increase in the X axis. In the goal referential system (B) the robot moving forward with no rotation would increase in the Z axis. (See figure for more details) &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;First system (A)&#xA; ______&#xA;|\  T  \&#xA;| \_____\     z&#xA;|B |    | : y ^&#xA; \ | R  |    \|&#xA;  \|____|     +--&amp;gt; x&#xA;&#xA;&#xA;Second system (B)&#xA; ______&#xA;|\  T  \&#xA;| \_____\     x&#xA;|B |    | :   ^&#xA; \ | R  |     |&#xA;  \|____|     +--&amp;gt; z&#xA;               \&#xA;                y&#xA;&#xA;R: Right side&#xA;B: Back side&#xA;T: Top&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I think I have to apply an extra rotation to change the initial quaternion that belongs to the first system to be in accordance with the second system before applying the transformation of your post.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One rotation of 180 degrees around x followed by one of 90 around y. Would rotate from A to B &lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is how I tried to solve it:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;# Quaternion to adjust reference system&#xA;first_quat = make_quaternion(unitary_x, pi) # Generates the quaternion that rotates pi around X &#xA;second_quat = make_quaternion(unitary_y, pi/2.0) # Generates the quaternion that rotates pi/2 around Y &#xA;composed_fs_q = first_quat*second_quat &#xA;&#xA;# Quaternion to rotate from one reference system to the other&#xA;quaternion_ini_A = quaternion_ini_A*composed_fs_q&#xA;A2B_quaternion = quaternion_ini_B*(quaternion_ini_A.inverse())&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;A2B_quaternion is the quaternion that I use for the rotation but still doesn't perform the right rotation. Any idea?&lt;/p&gt;&#xA;" OwnerUserId="1058" LastEditorUserId="1058" LastEditDate="2013-03-27T16:13:06.097" LastActivityDate="2013-03-28T16:17:21.460" Title="How to perform this reference system transformation?" Tags="&lt;mobile-robot&gt;&lt;localization&gt;&lt;odometry&gt;" AnswerCount="2" CommentCount="1" />
  <row Id="1090" PostTypeId="2" ParentId="1089" CreationDate="2013-03-19T13:42:43.740" Score="2" Body="&lt;p&gt;So you need to find the rotation that gets you from the first coordinate system to the second, and then combine that with the translation to get the final transformation matrix. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Since you have quaternions q1 and q2, you can write this rotation as:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$q = q_2 * q_1^{-1}$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can then convert from the quaternion form to a rotation matrix to make the final transformation matrix, there are &lt;a href=&quot;http://en.wikipedia.org/wiki/Rotation_formalisms_in_three_dimensions#Rotation_matrix_.E2.86.94_quaternion&quot; rel=&quot;nofollow&quot;&gt;equations for this&lt;/a&gt;. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The final transformation would be of the form:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$\begin{bmatrix}\boldsymbol{R} &amp;amp; \boldsymbol{t}\\\boldsymbol{0} &amp;amp; 1\end{bmatrix}$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Where $\boldsymbol{R}$ is the 3x3 rotation matrix and $\boldsymbol{t}$ is the 3x1 translation vector.&lt;/p&gt;&#xA;" OwnerUserId="479" LastEditorUserId="479" LastEditDate="2013-03-19T13:49:36.093" LastActivityDate="2013-03-19T13:49:36.093" />
  <row Id="1091" PostTypeId="1" CreationDate="2013-03-19T20:30:43.727" Score="4" ViewCount="349" Body="&lt;p&gt;I'm building a motion detection and object recognition camera with feedback control for a hexy robot. Fortunately most of the servo control is handled by the analog servo controls and the high-level logic can be implemented in python on a raspberry pi. What's the right combination of python modules to implement:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;a daemon/service to trigger and execute image capture and processing&lt;/li&gt;&#xA;&lt;li&gt;a daemon/service to regularly update the hexy with the latest motion plan and servo setpoints&lt;/li&gt;&#xA;&lt;li&gt;the image processing for recognition and tracking of objects from the webcam&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;I'm currently using python-daemon for the services and comparing the various pypi opencv libraries to see if any of them look promising. Anyone have experience with these on a raspberry pi or ARM processor in a robotics application? &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;remotecv                  - remotecv is an OpenCV server for face recognition&lt;/li&gt;&#xA;&lt;li&gt;ctypes-opencv             - ctypes-opencv - A Python wrapper for OpenCV using ctypes&lt;/li&gt;&#xA;&lt;li&gt;pyopencv                  - PyOpenCV - Boost.Python and NumPy&lt;/li&gt;&#xA;&lt;li&gt;opencv-cython             - An alternative OpenCV wrapper&lt;/li&gt;&#xA;&lt;li&gt;CVtypes                   - Python OpenCV wrapper using ctypes&lt;/li&gt;&#xA;&lt;li&gt;Tippy                     - another Toolbox for Image Processing, based on OpenCV&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;These each depend on a deep list of low-level libraries and/or compilers like Boost-&gt;numpy-&gt;gfortran or cython-&gt;gcc or ctypes. I'm concerned about compatibility and performance of these lowlevel libraries on Raspbian and an ARM processor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Anyone with a known working architecture for image processing and real-time control in python on an ARM processor will get their answer upvoted and/or accepted.&lt;/p&gt;&#xA;" OwnerUserId="1060" LastEditorUserId="1060" LastEditDate="2013-03-20T20:18:46.863" LastActivityDate="2013-03-21T17:25:45.787" Title="Python libraries for image processing and feedback control on raspberry pi" Tags="&lt;raspberry-pi&gt;&lt;real-time&gt;" AnswerCount="1" CommentCount="2" />
  <row Id="1092" PostTypeId="1" AcceptedAnswerId="1094" CreationDate="2013-03-19T21:26:07.550" Score="4" ViewCount="139" Body="&lt;p&gt;Are there any decent python numerical package libraries besides numpy for python? Numpy relies on gfortan which itself must be compiled correctly for your platform to avoid hidden/insidious numerical errors in numpy. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I need a matrix algebra package to do kinematics, path planing, and machine learning in python that isn't sensitive to  gfortran version and compiler options.&lt;/p&gt;&#xA;" OwnerUserId="1060" LastEditorUserId="479" LastEditDate="2013-03-20T14:13:39.350" LastActivityDate="2013-03-20T14:13:39.350" Title="Numpy alternatives for linear algebra and kinematics in python?" Tags="&lt;kinematics&gt;&lt;python&gt;" AnswerCount="1" CommentCount="0" />
  <row Id="1093" PostTypeId="2" ParentId="654" CreationDate="2013-03-20T08:23:59.003" Score="2" Body="&lt;p&gt;From Microsoft site:&#xA;What's the difference between the Kinect for Windows sensor and the Kinect for Xbox 360 sensor?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The Kinect for Windows sensor is a fully-tested and supported Kinect experience on Windows with features such as “near mode,” skeletal tracking control, API improvements, and improved USB support across a range of Windows computers and Windows-specific 10’ acoustic models.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The sensor was specifically designed to be used with computers, and includes a shortened USB cable to ensure reliability across a broad range of computers. Kinect for Xbox 360 was built for and tested with the Xbox 360 only, not with any other platform, which is why it is not licensed for general commercial use, supported, or under warranty when used on any other platform.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Kinect for Xbox 360, on the other hand, was built for and tested with the Xbox 360 only, not with any other platform, which is why it is not licensed for general commercial use, supported, or under warranty when used on any other platform.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Microsoft has a large team of engineers that is dedicated to continual improvements of the hardware and software associated with Kinect for Windows, and is committed to providing ongoing access to Microsoft's deep investment in human tracking and speech recognition.&lt;/p&gt;&#xA;" OwnerUserId="1061" LastActivityDate="2013-03-20T08:23:59.003" />
  <row Id="1094" PostTypeId="2" ParentId="1092" CreationDate="2013-03-20T14:08:55.093" Score="1" Body="&lt;p&gt;&lt;a href=&quot;http://docs.opencv.org/modules/refman.html&quot; rel=&quot;nofollow&quot;&gt;OpenCV&lt;/a&gt; is available with python bindings. It's not geared at strictly numerical applications, but it might be sufficient. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;It includes some &lt;a href=&quot;http://docs.opencv.org/modules/core/doc/operations_on_arrays.html&quot; rel=&quot;nofollow&quot;&gt;matrix math&lt;/a&gt; and &lt;a href=&quot;http://docs.opencv.org/modules/ml/doc/ml.html&quot; rel=&quot;nofollow&quot;&gt;machine learning&lt;/a&gt; algorithms.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I can't say you won't ever experience numerical problems, but it's not based on gfortran.&lt;/p&gt;&#xA;" OwnerUserId="479" LastActivityDate="2013-03-20T14:08:55.093" CommentCount="1" />
  <row Id="1095" PostTypeId="2" ParentId="1091" CreationDate="2013-03-21T13:15:40.553" Score="1" Body="&lt;p&gt;You could just &lt;a href=&quot;http://eduardofv.com/read_post/185-Installing-OpenCV-on-the-Raspberry-Pi&quot; rel=&quot;nofollow&quot;&gt;install OpenCV on a Raspberry Pi board&lt;/a&gt; and run your own performance tests.  What counts as &quot;real-time control&quot; and image processing will depend on your specific application, so if OpenCV can't handle it then you should post another question with more concrete performance requirements.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A colleague of mine says that:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;OpenCV runs fine [on a Raspberry Pi], and is easy to install (sudo apt-get install libopencv-dev). I found the board quite capable and not far behind performance of the Beagle Board. As an example, Apriltags (&lt;a href=&quot;http://people.csail.mit.edu/kaess/apriltags/&quot; rel=&quot;nofollow&quot;&gt;http://people.csail.mit.edu/kaess/apriltags/&lt;/a&gt;) runs at 3.5fps at 320x240 from a USB camera&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-03-21T17:25:45.787" LastActivityDate="2013-03-21T17:25:45.787" CommentCount="1" />
  <row Id="1096" PostTypeId="2" ParentId="1069" CreationDate="2013-03-21T18:15:17.073" Score="3" Body="&lt;p&gt;The gear trains in many printers and multifunction devices, and in some scanners, have a transfer gear that drives two different gears, depending on which way the drive motor is running.  The pictures below show several such transfer gears in the left-side gear train of a Brother MFC-1970MC (&lt;a href=&quot;http://reviews.cnet.com/multifunction-devices/brother-mfc-1970mc/4507-3181_7-4842717.html&quot; rel=&quot;nofollow&quot;&gt;1&lt;/a&gt;, &lt;a href=&quot;http://www.brother-usa.com/mfc/discontinued.aspx?ProductID=MFC1970MC#.UUkkblEVlkp&quot; rel=&quot;nofollow&quot;&gt;2&lt;/a&gt;), a 1998-vintage fax/copier/printer/scanner/answering machine multifunction device.  The right-side gear train only has half-a-dozen gears in it and isn't shown.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The 1970MC has one drive motor to power four different operations: printer paper pickup, printer paper drive, scan sheet pickup, and scan sheet drive.  I suspect that the solenoid (shown in first and last pictures) selects between printer and scanner operation, and that the swinging transfer gears (some of which appear in all pictures) select between paper pickup and paper drive.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/7XqCF.jpg&quot; alt=&quot;overview, left-side gear train&quot;&gt;&#xA;&lt;img src=&quot;http://i.stack.imgur.com/ry4aS.jpg&quot; alt=&quot;closeup, rear transfer gear, CCW&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Above: When A turns CW (clockwise), D is driven by the transfer gear C.  Gears A and C go CW while B and D go CCW.  The turning resistance of C causes the arm to swing to the left.  When C encounters D, B continues forcing C to the left so that C and D mesh strongly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Below: When A turns CCW, E is driven by the transfer gear C.  Gears A and C go CCW while B and E turn CW.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(Note, there is a one-way clutch or ratchet beneath the black gear E; when E is driven, the white gear beneath E does not turn.  When D is driven, it drives the two gears at very top center in picture, so driving the white gear beneath E.  Thus E rotates CW whenever A rotates.  D rotates CCW when A goes CW.  D does not rotate when A goes CCW.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/2ZGiH.jpg&quot; alt=&quot;closeup, rear transfer gear, CW&quot;&gt;&#xA;&lt;img src=&quot;http://i.stack.imgur.com/ND0Uh.jpg&quot; alt=&quot;closeup, front transfers, solenoid, and motor&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;At the center of the picture above are two swing transfer gears, labeled P and Q.  When the solenoid is out (not energized) the hook at the end of arm R prevents Q from swinging.  Also, a hook on P (more visible in first photo) slides over end of R so if P is operating Q cannot.  When the solenoid is in, Q can swing, and the hook on P hits the end of R, so if Q is operating P cannot engage the gear to its right.&lt;/p&gt;&#xA;" OwnerUserId="478" LastEditorUserId="478" LastEditDate="2013-03-22T18:08:50.880" LastActivityDate="2013-03-22T18:08:50.880" CommentCount="3" />
  <row Id="1097" PostTypeId="1" AcceptedAnswerId="1104" CreationDate="2013-03-22T01:46:47.187" Score="6" ViewCount="83" Body="&lt;p&gt;Shall I filter (kalman/lowpass) after getting the raw values from a sensor or after converting the raw values to a usable data? Does it matter? If so, why? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Example:&#xA;Filter after getting raw values from IMU&#xA;or &#xA;filter after converting raw values to a usable data eg. flight dynamics parameters.&lt;/p&gt;&#xA;" OwnerDisplayName="user697" LastEditorDisplayName="user697" LastEditDate="2013-03-22T02:58:28.477" LastActivityDate="2013-03-23T04:29:14.803" Title="At which stage should filtering be applied to the sensors data?" Tags="&lt;kalman-filter&gt;&lt;imu&gt;" AnswerCount="2" />
  <row Id="1098" PostTypeId="2" ParentId="1074" CreationDate="2013-03-22T01:57:24.380" Score="0" Body="&lt;p&gt;The ring should be below the propeller. It is designed to keep the three screws in place in case some of the screws come out during the flight.&lt;/p&gt;&#xA;" OwnerDisplayName="user697" LastActivityDate="2013-03-22T01:57:24.380" CommentCount="3" />
  <row Id="1099" PostTypeId="2" ParentId="921" CreationDate="2013-03-22T02:15:04.173" Score="2" Body="&lt;p&gt;You have different options (priority by difficulty level):&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;Using a smartphone as a camera.&#xA;There are actually apps for this. If you can attach one phone to your robot then you can stream the live video either on another phone or on the web. However the phone attached to the robot should have an internet connection(3G or even Edge). Search for &quot;live stream&quot; in App store or Google Play. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Using an &lt;a href=&quot;http://en.wikipedia.org/wiki/IP_camera&quot; rel=&quot;nofollow&quot;&gt;IP Camera&lt;/a&gt;. &#xA;This option is quite simple and requires you to have an IP camera wich then can be controlled by the Arduino. The IP camera can transmit video wirelessly to your Router or A Raspberry pie. You can then connect another phone or computer to the router to see the live image. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Using a Raspberry Pi. &#xA;Id normally would not do video or image manipulations in the Arduino platform because of the low performance it has got. You could connect a Raspberry pi to the Arduino. And a good camera to Raspberry pi. Arduino can send commands to Raspberry pi on when to start transmitting and so on. You can then do image manipulations on the Pi as well. And Since Raspberry pi can work as a router you could connect you smartphone to the raspberry pi through wifi or even Bluetooth. You will get a nice and high FPS video even with text/color manipulations.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;You could use the &lt;a href=&quot;http://developer.android.com/tools/adk/index.html&quot; rel=&quot;nofollow&quot;&gt;Android ADK&lt;/a&gt; as your main controller. And then the Arduino is set up as an accessory. In this way the Arduino can command Android what to do. A cheap android based mobile phone will cost you around 100USD and you will get lots of features for the price. Like GPS, Camera, Battery etc. Most modern smart phone have the ability of creating a wifi hotspot. You can then connect any other wifi platform to that hotspot and control the robot or in your case viewing a live stream video. This is by the most elegant method in my opinion.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerDisplayName="user697" LastEditorDisplayName="user697" LastEditDate="2013-03-22T23:24:17.057" LastActivityDate="2013-03-22T23:24:17.057" CommentCount="1" />
  <row Id="1100" PostTypeId="1" AcceptedAnswerId="1101" CreationDate="2013-03-22T02:46:07.920" Score="7" ViewCount="200" Body="&lt;p&gt;The definition of a robot is as follow: &quot;A robotic paradigm can be described by the relationship between the three primitives of robotics: Sense, Plan, and Act.&quot;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;An example could be the famous &quot;Kuka Robots&quot;. The Kuka robot is preprogrammed and does mainly one loop over and over again. Some of them could have measurement sensors but that is all. They do not think or plan nor do they make decisions. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;An automatic door opener, used in a building is not a robot either but according to the robotic paradigm definition they are more a robot than a Kuka machine. They actually get some data from a sensor followed by planning and acting. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So why are Kuka machines called robots?&lt;/p&gt;&#xA;" OwnerDisplayName="user697" LastEditorUserId="37" LastEditDate="2013-03-26T01:54:56.927" LastActivityDate="2013-04-03T00:21:39.563" Title="Why are industrial machines called robots?" Tags="&lt;industrial-robot&gt;" AnswerCount="3" FavoriteCount="1" />
  <row Id="1101" PostTypeId="2" ParentId="1100" CreationDate="2013-03-22T08:12:49.960" Score="10" Body="&lt;p&gt;No, that's the definition of &quot;robotic paradigm&quot;, which is basically a class of paradigms for designing complex robots. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The definition of &quot;robot&quot;, in this context, is:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;A robot is a mechanical or virtual artificial agent, usually an electro-mechanical machine that is guided by a computer program or electronic circuitry.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;or &lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;A machine capable of carrying out a complex series of actions automatically.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;(&quot;complex&quot; is ambiguous here)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Robot#Defining_characteristics&quot;&gt;This Wikipedia section&lt;/a&gt; confirms that there is an ambiguity:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;While there is no single correct definition of robot, a typical robot will have several, or possibly all, of the following characteristics.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;It is an electric machine which has some ability to interact with physical objects and to be given electronic programming to do a specific task or to do a whole range of tasks or actions. It &lt;strong&gt;may&lt;/strong&gt; also have some ability to perceive and absorb data on physical objects, or on its local physical environment, or to process data, or to respond to various stimuli. This is in contrast to a simple mechanical device such as a gear or a hydraulic press or any other item which has no processing ability and which does tasks through purely mechanical processes and motion.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;(emphasis mine)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the end, almost any mechanical device of some level of complexity can be classified as a robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, note that Kuka robots will have a small amount of sensors for fine-tuning (even if the bot is just picking up an object off a pedestal, it needs to correct its trajectory to align perfectly with the object)&lt;/p&gt;&#xA;" OwnerUserId="126" LastActivityDate="2013-03-22T08:12:49.960" CommentCount="7" />
  <row Id="1102" PostTypeId="2" ParentId="921" CreationDate="2013-03-22T11:43:15.067" Score="0" Body="&lt;p&gt;here's how i managed to solve my problem, i got my old wildfire installed &lt;a href=&quot;https://play.google.com/store/apps/details?id=com.pas.webcam&quot; rel=&quot;nofollow&quot;&gt;IP Webcam&lt;/a&gt;, set-up a wifi hotspot from my nexus4, connected to it from the wildfire, took the wildfire's ip and put it in the nexus4's web viewer.&lt;/p&gt;&#xA;" OwnerUserId="888" LastActivityDate="2013-03-22T11:43:15.067" />
  <row Id="1103" PostTypeId="2" ParentId="1097" CreationDate="2013-03-22T12:43:33.213" Score="0" Body="&lt;p&gt;Filter the raw data.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Filtering weeds out (hopefully) most noise and errors. Raw data usually is not so useful.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Gyros drift, compasses has a lot of noise. Kalman can remove both.&lt;/p&gt;&#xA;" OwnerUserId="61" LastEditorUserId="61" LastEditDate="2013-03-22T12:53:23.597" LastActivityDate="2013-03-22T12:53:23.597" CommentCount="1" />
  <row Id="1104" PostTypeId="2" ParentId="1097" CreationDate="2013-03-22T15:02:00.607" Score="0" Body="&lt;p&gt;The KF estimates the robot pose based on all sensor inputs &lt;em&gt;and the sensor correlation&lt;/em&gt;. If you do an EKF on the compass data, you'd really need the robot pose to determine how likely a given compass reading &lt;em&gt;is&lt;/em&gt;. Without that, you are &#xA;just low-pass filtering (not using a probabilistic filter like the KF).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you filter before you put everything in the same frame, then I don't know what information you'd have to do filtering &lt;em&gt;on&lt;/em&gt;.&#xA;Since I don't know exactly what you mean by &quot;usable&quot; I assume you have converted all sensor data into the coordinate frame of the robot. In that case, filtering is very easy since you can put all the sensor readings directly into one EKF. In fact, this is the &quot;normal&quot; way to do filtering, that I'm familiar with.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;:&#xA;Let's say your IMU is attached to a robot. The IMU will be used in estimating the pose of the robot. It doesn't matter what &lt;em&gt;units&lt;/em&gt; you use as long as the IMU is telling you something about how the robot is moving. Then you can use the &lt;em&gt;corellation&lt;/em&gt; of the IMU to other things that measure movement, such as the compass or odometers. That is what the KF is for. The KF is &lt;em&gt;not&lt;/em&gt; a sensor filter like a bandpass filter or something.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is a very relevant answer &lt;a href=&quot;http://robotics.stackexchange.com/q/277/163&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="163" LastEditorUserId="163" LastEditDate="2013-03-23T04:29:14.803" LastActivityDate="2013-03-23T04:29:14.803" CommentCount="3" />
  <row Id="1105" PostTypeId="2" ParentId="433" CreationDate="2013-03-23T17:38:19.233" Score="1" Body="&lt;p&gt;Have a look at &lt;a href=&quot;http://www.cvlibs.net/datasets/kitti/eval_odometry.php&quot; rel=&quot;nofollow&quot;&gt;KITTI Visual Odometry Benchmark/Evaluation&lt;/a&gt;. Its a recent and nice evaluation of different stereo visual odometry algorithms on some large outdoor urban scenes. They compare it against ground truth (GPS). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would say Visual Odometry are quite accurate and elegant perception systems. And its much better option than the IMU/GPS alone (even the high end ones).&lt;/p&gt;&#xA;" OwnerUserId="674" LastActivityDate="2013-03-23T17:38:19.233" />
  <row Id="1106" PostTypeId="2" ParentId="840" CreationDate="2013-03-24T11:16:50.043" Score="2" Body="&lt;p&gt;You can use SolidWorks, ADAMS or CATIA software.&#xA;You can design your platform and analyses or make formula for that with these software s.&lt;/p&gt;&#xA;" OwnerUserId="1071" LastActivityDate="2013-03-24T11:16:50.043" />
  <row Id="1107" PostTypeId="2" ParentId="826" CreationDate="2013-03-24T11:22:16.177" Score="0" Body="&lt;p&gt;If you want to Design your robot you can use SolidWork, CATIA or ADAMS software then you can animate your robot. But you can use Aldebaran standard platform robot (NAO) simulator. This simulator can be helpful for you but NAO robot is a kid size robot with good sensors.&lt;/p&gt;&#xA;" OwnerUserId="1071" LastActivityDate="2013-03-24T11:22:16.177" />
  <row Id="1108" PostTypeId="2" ParentId="1051" CreationDate="2013-03-25T23:33:10.373" Score="2" Body="&lt;p&gt;I think you could use &lt;em&gt;bearing&lt;/em&gt; (or &lt;em&gt;azimuth&lt;/em&gt; or &lt;em&gt;right ascension&lt;/em&gt;) and &lt;em&gt;mark&lt;/em&gt; (or &lt;em&gt;altitude&lt;/em&gt; or &lt;em&gt;declination&lt;/em&gt;). For example 0 mark 0 is straight ahead and on the horizon. 30 mark 30 is 30 degrees to the right and 30 degrees above the horizon. -90 mark -90 would be 90 degrees to the left and then face down into the ground.  These could be relative to your current position and orientation or relative to some reference such as true north or magnetic north and the horizon. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is the system astronomer's use.&lt;/p&gt;&#xA;" OwnerUserId="1075" LastEditorUserId="1075" LastEditDate="2013-03-25T23:43:50.693" LastActivityDate="2013-03-25T23:43:50.693" />
  <row Id="1109" PostTypeId="2" ParentId="1064" CreationDate="2013-03-27T16:33:15.337" Score="1" Body="&lt;blockquote&gt;&#xA;  &lt;p&gt;&quot;I'm going to need analogue control&quot;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;This is almost always done by rapidly connecting and disconnecting the motor to power, using PWM or something similar.&#xA;The switching is faster than the motor can respond, and often the designer picks a switching frequency faster than the 20 kHz humans can hear.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;generating PWM signals&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;There are 3 popular methods of generating PWM signals: ( &lt;a href=&quot;http://electronics.stackexchange.com/questions/6676/which-sipo-chip-is-better-74hc4094-or-74hc595-or-something-else&quot;&gt;a&lt;/a&gt;, &lt;a href=&quot;http://electronics.stackexchange.com/questions/11633/pov-globe-speed-questions/11664#11664&quot;&gt;b&lt;/a&gt; )&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Generate the PWM in software (&quot;Bit-banging Pulse Width Modulation&quot;). Typically this is the lowest-cost approach. With enough 74HC595 or TPIC6595 chips, one Arduino can control any number of motors. (But I doubt you'll be able to get 20 kHz PWM frequency this way).&lt;/li&gt;&#xA;&lt;li&gt;Generate the PWM using on-chip PWM hardware on the microcontroller. With enough Arduinos, you can control any number of motors at a high PWM frequency with 3 or 4 motors per Arduino.&lt;/li&gt;&#xA;&lt;li&gt;Generate the PWM using dedicated PWM peripheral chips such as the TLC5947, which the microcontroller occasionally loads with a new PWM duty cycle. With enough TLC5947 chips, one Arduino can control any number of motors and still maintain a high PWM frequency.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;Converting PWM signals into something that can drive a motor&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;It appears your motors are rated at 85 mA start, 75 mA continuous.&#xA;That is really tiny for a motor.&#xA;But it's still more power than most digital logic chips can drive directly.&#xA;As you can see from this list, only one of the chips mentioned above (the TPIC6595) is really designed to directly drive that amount of power:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;TPIC6595 datasheet: test conditions ... 250 mA continuous sink current capability.&lt;/li&gt;&#xA;&lt;li&gt;TLC5947 datasheet: test conditions ... 30 mA continuous sink current&lt;/li&gt;&#xA;&lt;li&gt;ATmega328P datasheet: &quot;test conditions ... 20 mA at VCC = 5V, 10 mA at VCC = 3V... Pins are not guaranteed to source current greater than the listed test condition.&quot;&lt;/li&gt;&#xA;&lt;li&gt;74HC595 datasheet: test conditions ... 7.8 mA.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;We typically use some kind of &quot;buffer&quot; between the digital logic chips (any of the above chips) and a motor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For motors that we only need to turn in one direction, we typically we use flyback diode and either a nFET or a npn transistor as the &quot;buffer&quot;:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ULN2803A or ULQ2803A (transistor + flyback diode array) datasheet: test conditions ... over 150 mA continuous.&lt;/li&gt;&#xA;&lt;li&gt;There are thousands of discrete transistors and diodes that can easily handle: 10 V, 1 A. ( &lt;a href=&quot;http://electronics.stackexchange.com/questions/57831/how-to-determine-what-transistor-is-needed&quot;&gt;a&lt;/a&gt; )&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;For motors that we need to turn both &quot;forwards&quot; and &quot;reverse&quot;, we typically use 4 transistors arranged in a H bridge as the &quot;buffer&quot;:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;L293D H bridge datasheet: test conditions ... 600 mA.&lt;/li&gt;&#xA;&lt;li&gt;There are thousands of discrete transistors and diodes that can easily handle: 10 V, 1 A.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="187" LastActivityDate="2013-03-27T16:33:15.337" CommentCount="3" />
  <row Id="1110" PostTypeId="1" AcceptedAnswerId="1112" CreationDate="2013-03-27T17:43:01.053" Score="3" ViewCount="57" Body="&lt;p&gt;I am trying to implement a mechanism to make robots avoid being too close (Say in a distance less than &lt;code&gt;d&lt;/code&gt;). I am not familiar with those systems and I have to implement a strategy to avoid robots being too close to each other. Could anyone recommend me some readings for such a problem or a set of keywords to search for? I don't know yet how to start.&lt;/p&gt;&#xA;" OwnerUserId="1082" LastEditorUserId="158" LastEditDate="2013-03-28T17:05:31.667" LastActivityDate="2013-03-28T17:33:39.733" Title="Robots minimum distance" Tags="&lt;algorithm&gt;&lt;movement&gt;" AnswerCount="3" CommentCount="1" />
  <row Id="1111" PostTypeId="2" ParentId="1110" CreationDate="2013-03-27T18:12:55.970" Score="3" Body="&lt;p&gt;A good place to start is with the work by &lt;a href=&quot;http://arl.cs.utah.edu&quot; rel=&quot;nofollow&quot;&gt;Dr. Jur van den Berg and his colleagues&lt;/a&gt;. Check out the &lt;a href=&quot;http://arl.cs.utah.edu/pubs/index.html&quot; rel=&quot;nofollow&quot;&gt;publications&lt;/a&gt; velocity obstacles and reciprocal collision avoidance. You could start with the latest paper, &lt;a href=&quot;http://arl.cs.utah.edu/pubs/ICRA2013-2.pdf&quot; rel=&quot;nofollow&quot;&gt;Reciprocal Collision Avoidance for Robots with Linear Dynamics using LQR-Obstacles&lt;/a&gt;, they have released on the subject and use the citations to find more related material.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-03-27T18:12:55.970" CommentCount="1" />
  <row Id="1112" PostTypeId="2" ParentId="1110" CreationDate="2013-03-27T21:18:12.293" Score="2" Body="&lt;p&gt;Do you mean too close to each other?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It sounds like you might be referring to the sorts of steering behaviours that Craig Reynold's refers to in his &lt;a href=&quot;http://www.red3d.com/cwr/boids/&quot; rel=&quot;nofollow&quot;&gt;Boids project&lt;/a&gt;. He describes some behaviours that exhibit as &lt;em&gt;flocking&lt;/em&gt; or &lt;em&gt;herding&lt;/em&gt; because of the way the participants avoid each other, yet stick together.  He uses the terms 'separation', 'alignment' and 'cohesion' to describe the algorithms involved. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Craig applies these to computer simulations, but you could just as well apply the concepts to robots.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Other searches that may prove beneficial: 'flock simulation', 'crowd modelling'.&lt;/p&gt;&#xA;" OwnerUserId="1075" LastEditorUserId="1075" LastEditDate="2013-03-28T17:33:39.733" LastActivityDate="2013-03-28T17:33:39.733" CommentCount="3" />
  <row Id="1113" PostTypeId="1" AcceptedAnswerId="1122" CreationDate="2013-03-28T06:17:54.370" Score="2" ViewCount="736" Body="&lt;p&gt;I was looking up the motor parameters for some stepper motor where they listed the torque of the motor at different current/voltage but the torque they listed was in kg/cm.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How is kg/cm even a remotely acceptable unit for torque?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How do I calculate the torque in Nm from kg/cm?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Clarity note: Its not kgcm which represents [0.098 kilogram force = 1 Nm.]&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.nex-robotics.com/products/motors-and-accessories/high-torque-bipolar-stepper-motor.html&quot; rel=&quot;nofollow&quot;&gt;Website&lt;/a&gt; where this happens.&lt;/p&gt;&#xA;" OwnerUserId="333" LastActivityDate="2013-04-02T04:52:10.860" Title="Torque in kg/cm?" Tags="&lt;stepper-motor&gt;&lt;torque&gt;" AnswerCount="3" />
  <row Id="1114" PostTypeId="2" ParentId="1113" CreationDate="2013-03-28T06:37:46.927" Score="1" Body="&lt;pre&gt;&lt;code&gt;Y[Nm]=X[kg-cm]*9.81[m/s^2]/100[cm]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;1kg multiplyed with gravitational constant will give you 10N and normalizing the cm to m by multiplying it with 0.01.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Basically, unit in their table is wrong. It is not kg/cm but rather kg-cm. Kg/cm would mean normalized linear pressure, which makes no sense for torque.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, what you have mentioned that 0.02 Nm is small torque. It is but not for 0.1A and 0.4V. If you take a look at torque for 1.5A, it is 0.18Nm for 9W of power.&lt;/p&gt;&#xA;" OwnerUserId="973" LastEditorUserId="973" LastEditDate="2013-03-28T08:14:06.697" LastActivityDate="2013-03-28T08:14:06.697" CommentCount="4" />
  <row Id="1115" PostTypeId="2" ParentId="1078" CreationDate="2013-03-28T06:48:06.923" Score="1" Body="&lt;p&gt;I like @kramer65's answer but because you indicated you might like to make an encoder, I thought I'd share some information on that.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.societyofrobots.com/sensors_encoder.shtml&quot; rel=&quot;nofollow&quot;&gt;http://www.societyofrobots.com/sensors_encoder.shtml&lt;/a&gt; shows a very common way of making a rotary encoder. You attach a disk with evenly spaced holes or reflective surfaces depending on implementation to your shaft. You align a light sensor with the holes and count the number of holes that pass to determine how much the shaft has turned. This has the disadvantage of not being able to determine direction but there was ways to modify the design to add that feature. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/254ew.jpg&quot; alt=&quot;An example of a homemade encoder.&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;More information can be found in these places:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://groups.csail.mit.edu/mac/users/pmitros/encoder/&quot; rel=&quot;nofollow&quot;&gt;http://groups.csail.mit.edu/mac/users/pmitros/encoder/&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://thedenneys.org/pub/robot/encoders/&quot; rel=&quot;nofollow&quot;&gt;http://thedenneys.org/pub/robot/encoders/&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1125" LastActivityDate="2013-03-28T06:48:06.923" />
  <row Id="1116" PostTypeId="2" ParentId="1110" CreationDate="2013-03-28T09:04:06.963" Score="0" Body="&lt;p&gt;I'd  like to suggest that you start with a book or a course in principles of robotic motion for this topic. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://rads.stackoverflow.com/amzn/click/0262033275&quot; rel=&quot;nofollow&quot;&gt;Principles of Robotic Motion&lt;/a&gt; Provides a very detailed introduction to this topic starting chapter 3 onwards.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Alternatively, you might want to look for how to make efficient configuration spaces for robots to traverse.&lt;/p&gt;&#xA;" OwnerUserId="333" LastActivityDate="2013-03-28T09:04:06.963" />
  <row Id="1117" PostTypeId="1" AcceptedAnswerId="1118" CreationDate="2013-03-28T09:18:05.097" Score="1" ViewCount="70" Body="&lt;p&gt;I am currently reading into the topic of stereo vision, using the book of Hartley&amp;amp;Zimmerman alongside some papers, as I am trying to develop an algorithm capable of creating elevation maps from two images.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am trying to come up with the basic steps for such an algorithm. This is what I think I have to do:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If I have two images I somehow have to find the fundamental matrix, F, in order to find the actual elevation values at all points from triangulation later on. If the cameras are calibrated this is straightforward if not it is slightly more complex (plenty of methods for this can be found in H&amp;amp;Z).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It is necessary to know F in order to obtain the epipolar lines. These are lines that are used in order to find image point x in the first image back in the second image.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now comes the part were it gets a bit confusing for me: Now I would start taking a image point x_i in the first picture and try to find the corresponding point x_i’ in the second picture, using some matching algorithm. Using triangulation it is now possible to compute the real world point X and from that it’s elevation. This process will be repeated for every pixel in the right image.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the perfect world (no noise etc) triangulation will be done based on&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;x1=P1X &#xA;x2=P2X&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;In the real world it is necessary to find a best fit instead.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Doing this for all pixels will lead to the complete elevation map as desired, some pixels will however be impossible to match and therefore can't be triangulated.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What confuses me most is that I have the feeling that Hartley&amp;amp;Zimmerman skip the entire discussion on how to obtain your point correspondences (matching?) and that the papers I read in addition to the book talk a lot about disparity maps which aren’t mentioned in H&amp;amp;Z at all. However I think I understood correctly that the disparity is simply the difference x1_i- x2_i?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is this approach correct, and if not where did I make mistakes?&lt;/p&gt;&#xA;" OwnerUserId="1085" LastEditorUserId="95" LastEditDate="2013-03-28T15:41:51.613" LastActivityDate="2013-04-05T12:26:40.877" Title="How to obtain stereo correspondences and what exactly is a disparity map?" Tags="&lt;computer-vision&gt;&lt;stereo-vision&gt;" AnswerCount="1" />
  <row Id="1118" PostTypeId="2" ParentId="1117" CreationDate="2013-03-28T14:45:18.687" Score="1" Body="&lt;p&gt;&lt;strong&gt;How to obtain your point correspondences&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are many ways to do it, which can basically be classified into two categories: feature-based and dense matching.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Feature-based methods include using corner detectors, SIFT/SURF/ORB descriptors and other similar feature detectors that provide point to point correspondences. A few of those methods that are implemented in OpenCV are compared &lt;a href=&quot;http://computer-vision-talks.com/2011/07/comparison-of-the-opencvs-feature-detection-algorithms-ii/&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Dense-matching methods usually involve some kind of comparison between sliding windows in both images. The most used approach is SSD or variants. A few of these variants are listed &lt;a href=&quot;http://siddhantahuja.wordpress.com/tag/sum-of-squared-differences/&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What are disparity maps&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Your intuition is right: disparity, in a rectified image, is defined as the difference between the x coordinate of a point in two images. It had a neat relationship from projective geometry: disparity = 1/depth. &lt;a href=&quot;http://stackoverflow.com/questions/7337323/definition-of-a-disparity-map&quot;&gt;This stackoverflow answer&lt;/a&gt; has a few pointers about it. Disparity maps are basically images where each pixel value is the disparity of that point, so it gives you a sense of depth - the further away from the camera, the darker.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;EDIT:&lt;/strong&gt; Yes, in general terms your approach is correct AFAIK. Your description lacks detail, but as you mentioned you can find out how to do each of these pieces in H&amp;amp;Z.&lt;/p&gt;&#xA;" OwnerUserId="95" LastEditorUserId="95" LastEditDate="2013-04-05T12:26:40.877" LastActivityDate="2013-04-05T12:26:40.877" CommentCount="3" />
  <row Id="1119" PostTypeId="2" ParentId="1089" CreationDate="2013-03-28T16:17:21.460" Score="0" Body="&lt;p&gt;In your particular case, isn't it easiest to just transpose the axes:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;Bx =  Az&#xA;By = -Ay&#xA;Bz =  Ax&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Or if you want to write that as a matrix transform:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;B = A * [ [  0,  0,  1  ],&#xA;          [  0, -1,  0  ],&#xA;          [  1,  0,  0  ] ]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="1075" LastActivityDate="2013-03-28T16:17:21.460" />
  <row Id="1120" PostTypeId="1" CreationDate="2013-03-28T16:42:32.603" Score="5" ViewCount="264" Body="&lt;p&gt;And if so, what was the highest score so far?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some news articles suggest only parts of tests were aced.&lt;/p&gt;&#xA;" OwnerUserId="1086" LastActivityDate="2013-04-17T16:54:29.547" Title="Has a robot ever taken a complete IQ test?" Tags="&lt;artificial-intelligence&gt;" AnswerCount="3" CommentCount="1" FavoriteCount="1" />
  <row Id="1121" PostTypeId="2" ParentId="1120" CreationDate="2013-03-28T18:55:58.453" Score="2" Body="&lt;p&gt;To the best of my knowledge no robot has ever been subjected to an IQ test. This is in part because the IQ test is not considered a valid test of intelligence amongst. It was originally developed as a test to determine whether any given child needed special attention in school and was later altered to apply to adults. Since then it has been shown to really only measure awareness of social norms. Some have argued that this awareness is indicative of intelligence but it's not generally accepted. &lt;a href=&quot;http://www.rolfpfeifer.com/&quot; rel=&quot;nofollow&quot;&gt;Dr. Rolf Pfeifer's&lt;/a&gt; book &lt;a href=&quot;https://www.google.com/search?client=ubuntu&amp;amp;channel=fs&amp;amp;q=understanding+intelligence&amp;amp;ie=utf-8&amp;amp;oe=utf-8&quot; rel=&quot;nofollow&quot;&gt;Understanding Intelligence&lt;/a&gt; has a great discussion of this topic in chapter 1.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-03-28T18:55:58.453" CommentCount="3" />
  <row Id="1122" PostTypeId="2" ParentId="1113" CreationDate="2013-03-28T19:11:51.763" Score="2" Body="&lt;p&gt;It is most likely kgf-cm, as kg/cm is not a valid unit for torque.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Apparently &lt;a href=&quot;http://electronics.stackexchange.com/questions/2749/stall-torque-for-servo-kg-cm&quot;&gt;writing kg/cm when kgf-cm is meant is a common mistake made on datasheets&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;According to &lt;a href=&quot;http://www.convertunits.com/from/newton+meter/to/kgf+cm&quot; rel=&quot;nofollow&quot;&gt;this conversion of kgf-cm to Nm&lt;/a&gt;, 28 kgf-cm of torque is 2.7 Nm, and 150 kgf-cm of torque is 14.7 Nm.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-03-29T21:13:40.743" LastActivityDate="2013-03-29T21:13:40.743" CommentCount="2" />
  <row Id="1123" PostTypeId="2" ParentId="826" CreationDate="2013-03-28T20:05:45.130" Score="3" Body="&lt;p&gt;The short answer is that I don't think a good standardized motion file format exists and I don't think there are any good generic wysiwyg robot posing tools.  Some level of custom programming is going to be required.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;RE: Standard file formats for robot motion&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/COLLADA&quot; rel=&quot;nofollow&quot;&gt;Collada&lt;/a&gt; is meant as a standardized 3D data interchange file format, and it has support for storing basic animation and physics type information with a model. Support is not consistent across tools though, especially for the animation/physics data.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Beyond that, it's unlikely you'll find any general use file formats for storing robotic animation.  (Although not 100% comparable, check out the &lt;a href=&quot;http://en.wikipedia.org/wiki/List_of_motion_and_gesture_file_formats&quot; rel=&quot;nofollow&quot;&gt;wikipedia list of motion/gesture file formats&lt;/a&gt;.)  Everything I have seen is specific to the platform and/or proprietary. Consider that the game and CAD industries are orders of magnitude larger and more specific than robotics. They have similar requirements, yet there is no defacto file format.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are interested in a more programmatic view of the data by these proprietary systems though, then looking at the specialized tools used by these industries &lt;em&gt;might&lt;/em&gt; give you some additional options and ideas. Examples:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.autodesk.com/products/motionbuilder/overview&quot; rel=&quot;nofollow&quot;&gt;Autodesk MotionBuilder and API&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.unrealengine.com/en/features/animation/&quot; rel=&quot;nofollow&quot;&gt;The Unreal Animation System&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://help.solidworks.com/2012/English/SolidWorks/SWHelp_List.html?id=15af46b4cbfc4971a5c3a0a6a47245f9#Pg0&quot; rel=&quot;nofollow&quot;&gt;SolidsWorks Motion Studies&lt;/a&gt; &amp;amp; &lt;a href=&quot;http://help.solidworks.com/2013/English/api/sldworksapiprogguide/GettingStarted/SolidWorks_API_Getting_Started_Overview.htm&quot; rel=&quot;nofollow&quot;&gt;SolidWorks API&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The creation, storage, and execution of character animation (often humanoid), in particular, is well represented and very advanced in the game development industry. For a price. I believe most of the larger studios have an entire team dedicated to doing nothing more than converting data from one system to another and feeding it through a production pipeline.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One recurring problem with using game development tools (or creative type 3D tools in general) for robotics is that in games/movies, is that it's usually okay if the animation doesn't model reality exactly. That can cause issues when applied to real world robots.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;RE: Posing Tools&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Robotic simulators (like &lt;a href=&quot;http://www.coppeliarobotics.com/&quot; rel=&quot;nofollow&quot;&gt;Coppelia's V-REP&lt;/a&gt; or even &lt;a href=&quot;http://www.microsoft.com/robotics/&quot; rel=&quot;nofollow&quot;&gt;MS Robotics Studio&lt;/a&gt;) might be of use &lt;em&gt;if&lt;/em&gt; they provided an API/export of some sort &lt;em&gt;and&lt;/em&gt; were able to simulate humanoid type robots. I don't know of any that support a full humanoid model though. Most are just for modelling arms and wheeled robots. Still, perhaps you could model your humanoid movements as an collection of independent arm subsystems? i.e. The left leg is one robotic arm.  If so, then a few more wsyiwyg tools would be open to you.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.dsprobotics.com&quot; rel=&quot;nofollow&quot;&gt;Flowstone&lt;/a&gt; is another visual tool that could be used for posing, but probably not the wysiwyg that you had in mind.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you don't need WYSIWYG and are open to some programming, you might want to check out &lt;a href=&quot;https://code.google.com/p/arbotix/wiki/PyPose&quot; rel=&quot;nofollow&quot;&gt;PyPose&lt;/a&gt; and &lt;a href=&quot;https://code.google.com/p/arbotix/wiki/NukeIntro&quot; rel=&quot;nofollow&quot;&gt;Nuke&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Similarly, but requiring more advanced programming, various physics engines might be of interest for taking in all the inputs (3D models and associated parameters) and then providing movement results by applying forces and inverse kinematics. Examples include &lt;a href=&quot;http://ode.org/ode-latest-userguide.html#sec_7_3_0&quot; rel=&quot;nofollow&quot;&gt;ODE&lt;/a&gt; and &lt;a href=&quot;http://bulletphysics.org/Bullet/phpBB3/viewtopic.php?f=9&amp;amp;t=5341&amp;amp;view=previous&quot; rel=&quot;nofollow&quot;&gt;Bullet physics&lt;/a&gt;. A similar programmatic slanted option would be to use ROS. I've seen a &lt;a href=&quot;http://www.ros.org/wiki/humanoid_walk&quot; rel=&quot;nofollow&quot;&gt;few projects&lt;/a&gt; and &lt;a href=&quot;http://www.informatik.uni-freiburg.de/~hornunga/pub/hornung12roscon.pdf&quot; rel=&quot;nofollow&quot;&gt;notes&lt;/a&gt; regarding potential ROS support for humanoid type motions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;All that said... although difficult to learn, I still think Blender3D has &lt;em&gt;potential&lt;/em&gt; to be one of the better all around options for advanced hobbiest type robotics posing and motion work, particularly due to it's tight integration with the Python programming language.  Someone already pointed out the &lt;a href=&quot;http://wiki.blender.org/index.php/Community%3aScience/Robotics&quot; rel=&quot;nofollow&quot;&gt;Blender Robotics wiki&lt;/a&gt; in the comments. You should also review &lt;a href=&quot;http://www.youtube.com/watch?v=YMA0cqFAekY&quot; rel=&quot;nofollow&quot;&gt;Grantlo321's YouTube video&lt;/a&gt; using blender to control servos playing a piano, as well as the &lt;a href=&quot;http://justindailey.blogspot.com/2011/03/real-time-controlled-robotic-arm.html&quot; rel=&quot;nofollow&quot;&gt;blog post by Justin Daily&lt;/a&gt; where he describes using Blender/Python for servo control.  I agree that Blender3D is hard to learn, but that is likely going to be true with almost any 3D wysiwyg type software unless it's focus is very narrow.&lt;/p&gt;&#xA;" OwnerUserId="167" LastEditorUserId="167" LastEditDate="2013-03-28T20:19:07.937" LastActivityDate="2013-03-28T20:19:07.937" />
  <row Id="1124" PostTypeId="2" ParentId="1047" CreationDate="2013-03-28T23:15:42.677" Score="3" Body="&lt;p&gt;If you are looking for a source to get an intuitive feeling for what the Kalman Filter is actually doing I would suggest going through lesson 2 of Udacity's Artificial Intelligence for Robotics course found here:&#xA;&lt;a href=&quot;https://www.udacity.com/course/cs373&quot; rel=&quot;nofollow&quot;&gt;https://www.udacity.com/course/cs373&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The course is free and it has video lectures and simple code examples. The explanation given is a little simplistic but it does help to build an intuition for how and why the filter works.&lt;/p&gt;&#xA;" OwnerUserId="983" LastActivityDate="2013-03-28T23:15:42.677" />
  <row Id="1125" PostTypeId="2" ParentId="1032" CreationDate="2013-03-28T23:31:01.950" Score="2" Body="&lt;p&gt;In industry, this type of control is still generally referred to as PID control and I've seen many applications of it. It's main benefit stems from the fact that it removes the &quot;derivative kick&quot; caused by an abrupt change in set point and thus is useful for applications where set point tracking is most important (rather than fast disturbance rejection). See &lt;a href=&quot;http://www.controlguru.com/wp/p76.html&quot; rel=&quot;nofollow&quot;&gt;http://www.controlguru.com/wp/p76.html&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Image showing difference in derivative kick of PID and PIV&#xA;&lt;a href=&quot;http://www.controlguru.com/postpics/pidkickbig.jpg&quot; rel=&quot;nofollow&quot;&gt;http://www.controlguru.com/postpics/pidkickbig.jpg&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="983" LastEditorUserId="983" LastEditDate="2013-03-28T23:36:31.150" LastActivityDate="2013-03-28T23:36:31.150" />
  <row Id="1126" PostTypeId="2" ParentId="1100" CreationDate="2013-03-29T04:22:35.040" Score="3" Body="&lt;p&gt;The problem is, there is no set standard definition on what a robot is. In our perspective, a robot should be like &quot;Honda's ASIMO.&quot; Which is not the case. It is much more complex. Robots can be controlled by humans and not controlled by humans, either definition is perfectly acceptable.&lt;/p&gt;&#xA;" OwnerUserId="1089" LastActivityDate="2013-03-29T04:22:35.040" />
  <row Id="1127" PostTypeId="2" ParentId="1120" CreationDate="2013-03-29T05:49:30.263" Score="4" Body="&lt;p&gt;Well, there have been many AI programs written specifically to ace IQ tests. Like &lt;a href=&quot;http://www.csse.monash.edu.au/~dld/Publications/2003/Sanghi+Dowe_IQ_Paper_JIntConfCogSci2003.pdf&quot; rel=&quot;nofollow&quot;&gt;this one&lt;/a&gt; and &lt;a href=&quot;http://www.futurepundit.com/archives/008514.html&quot; rel=&quot;nofollow&quot;&gt;this one&lt;/a&gt;. I don't think there have been any &lt;em&gt;robots&lt;/em&gt; (computer programs which control mechanical components) which have been administered an IQ test, but, TBH, you don't &lt;em&gt;need&lt;/em&gt; a robot for this -- just a program.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Update: looks like I'm wrong, &lt;a href=&quot;http://users.dsic.upv.es/~flip/papers/IQnotuniversal.pdf&quot; rel=&quot;nofollow&quot;&gt;this 2012 paper&lt;/a&gt; says (I've only skimmed) that while AI may be able to be written to solve certain types of IQ problems, others are beyond our current reach.&lt;/p&gt;&#xA;" OwnerUserId="126" LastEditorUserId="126" LastEditDate="2013-04-01T05:49:14.793" LastActivityDate="2013-04-01T05:49:14.793" CommentCount="7" />
  <row Id="1128" PostTypeId="1" CreationDate="2013-03-29T08:26:32.630" Score="1" ViewCount="48" Body="&lt;p&gt;From an old dust buster I've got this electro motor, the included battery pack and the charger:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/hVLhe.jpg&quot; alt=&quot;enter image description here&quot;&gt;&#xA;&lt;img src=&quot;http://i.stack.imgur.com/0nFln.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I ripped everything apart (the dust buster was broken) and the motor still works. After playing around with it for a while and letting it lying around for about two weeks it suddenly revs a lot slower. I supposed the battery pack was drained so I hooked up the battery pack to the charger and let it charge for a night. Unfortunately the motor still turns very slow.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Since I want to use this motor for my first home robotics project (making a kite fly with my computer), off I went to the local electronics store where they measured the charger to give 16V (even though it says 21V) and the battery pack to give about 5V. I then hooked up the motor directly to the charger, but unfortunately it doesn't even move an inch then.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So now I wonder:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Why doesn't the motor spin at all when hooking it up to the charger? (Could that be because the 250mA is too low?)&lt;/li&gt;&#xA;&lt;li&gt;Why doesn't the battery pack charge at all? (this bothers me the most!)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;All tips are welcome!&lt;/p&gt;&#xA;" OwnerUserId="1050" LastEditorUserId="1050" LastEditDate="2013-03-29T08:33:37.157" LastActivityDate="2013-03-30T01:08:47.510" Title="Why is this electro motor going slower?" Tags="&lt;motor&gt;&lt;batteries&gt;" AnswerCount="2" />
  <row Id="1129" PostTypeId="2" ParentId="1128" CreationDate="2013-03-29T10:55:28.780" Score="2" Body="&lt;p&gt;250mA states the maximum output current to drive the load. So check what the current rating of the 5V regulator is.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Check whether there is a voltage drop before reaching the motor. It might be that the motor is not spinning because of insufficient supply.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Change the adapter you are using. If it is marked 21V, the output from adapter will be around 20.5V to 21.5V.&lt;/p&gt;&#xA;" OwnerUserId="1092" LastEditorUserId="131" LastEditDate="2013-03-30T01:08:47.510" LastActivityDate="2013-03-30T01:08:47.510" />
  <row Id="1130" PostTypeId="1" CreationDate="2013-03-29T15:29:11.317" Score="3" ViewCount="78" Body="&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/Wl3uH.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am trying to find a joint like these for a robot I'm building. It is often called a swivel joint or a universal joint, but with a modified spider. I can't find one anywhere and would prefer not to make it. Searching for 'universal joint' returns the standard automotive type. Any help would be appreciated&lt;/p&gt;&#xA;" OwnerUserId="1094" LastEditorUserId="350" LastEditDate="2013-03-29T21:11:39.483" LastActivityDate="2013-04-01T19:17:17.360" Title="What is the name of this mechanical linkage?" Tags="&lt;joint&gt;" AnswerCount="2" CommentCount="2" />
  <row Id="1131" PostTypeId="2" ParentId="1128" CreationDate="2013-03-29T21:33:24.053" Score="1" Body="&lt;p&gt;If your charger is running at 16V instead of the 21V it's supposed to be operating at, then that is your problem.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Why your charger won't run the motor&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Your charger should be fairly underpowered for running the motor.  Most batteries strong enough to power motors are not meant to be charged as fast as they can discharge.  This can be for several reasons, including:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Safety: some batteries will explode if charged with too much current&lt;/li&gt;&#xA;&lt;li&gt;Longevity: some batteries will degrade if charged beyond what the chemistry can handle&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;A power supply capable of running the motor would be damaging (if not dangerous) to connect directly to the battery.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Other things to check:&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;It's possible that your batteries are running near the end of their lifetime (they have a finite number of cycles).  When charged overnight and unplugged, are their voltages below what they should be?  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;It could also be that the problem is mechanical.  Has debris been introduced into the motor assembly, or is it poorly lubricated?  &lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-03-29T21:33:24.053" />
  <row Id="1132" PostTypeId="1" CreationDate="2013-03-29T23:14:45.093" Score="9" ViewCount="694" Body="&lt;p&gt;I am a high school student, doing a research project in AI and Robotics. How should I choose a robotics kit (for example, will it be better to learn the basics by using a hexapod or robotic arm?)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I know C at good level.&lt;/p&gt;&#xA;" OwnerDisplayName="Mad Applelover" LastEditorUserId="35" LastEditDate="2013-04-04T14:18:45.703" LastActivityDate="2013-09-18T09:20:47.267" Title="How Should I Choose an Educational Robotics Kits for Beginner Programmers?" Tags="&lt;arduino&gt;&lt;artificial-intelligence&gt;&lt;beginner&gt;" AnswerCount="5" CommentCount="2" FavoriteCount="5" />
  <row Id="1133" PostTypeId="2" ParentId="1132" CreationDate="2013-03-29T23:30:27.693" Score="4" Body="&lt;p&gt;I would recommend you get yourself a &lt;a href=&quot;http://arduino.cc/en/&quot; rel=&quot;nofollow&quot;&gt;Arduino&lt;/a&gt;. They are open source, there is loads of material online to get your started and they are relativity cheap to buy. &lt;/p&gt;&#xA;" OwnerUserId="1097" OwnerDisplayName="Tom Squires" LastActivityDate="2013-03-29T23:30:27.693" CommentCount="5" />
  <row Id="1134" PostTypeId="2" ParentId="1132" CreationDate="2013-03-29T23:37:54.950" Score="2" Body="&lt;p&gt;&lt;a href=&quot;http://www.vexrobotics.com/&quot; rel=&quot;nofollow&quot;&gt;VEX Robotics have some good kits for beginners.&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1100" OwnerDisplayName="Peter K." LastActivityDate="2013-03-29T23:37:54.950" CommentCount="4" />
  <row Id="1135" PostTypeId="2" ParentId="975" CreationDate="2013-03-30T01:30:39.740" Score="-2" Body="&lt;p&gt;In chemistry, you will learn the composition of matter there they have thought you about properties of certain metals/non-metals. They have certain limits, such as melting point/freezing point.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Temperature does matter in electronics. When you overclock your computer, you need liquid nitrogen to cool down your chip. Same is true for any other device. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The electronics that go into space does not only face this problem but also they must be cautious about radiations which can corrupt data. Thus, usually rovers carry additional chips/batteries for backup. The data they collect there is of great importance.&lt;/p&gt;&#xA;" OwnerUserId="1089" LastActivityDate="2013-03-30T01:30:39.740" />
  <row Id="1137" PostTypeId="2" ParentId="975" CreationDate="2013-03-30T07:56:51.853" Score="2" Body="&lt;p&gt;I would put forward three main points for the temperature sensitivity of electronics, electronic components and mechanical parts: &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;All batteries are quite &lt;a href=&quot;http://chemistry.about.com/od/howthingsworkfaqs/f/coldbattery.htm&quot; rel=&quot;nofollow&quot;&gt;sensitive&lt;/a&gt; when it comes to temperature. Chemical reaction rates are reduced, and leakage current is increased.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Silicon chips usually don't have a problem with low temperatures. What does is the packaging and the PCB substrates and bonds. And even here the actual problem is not the low temperature, but the temperature range. The reason for this is that the materials have different thermal properties, like thermal conductivity and expansion. The packaged chips as well as the bonds with the PCB will generate mechanical stress which increases the chances of micro-fractures in the conductive materials. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Moving mechanical parts like motors and gears often need lubricants to work. The mechanical properties of those lubricants are very temperature sensitive. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;As far as I know the lowest you can go with primary batteries is something like -50C. Secondaries are even worse. So there is really no other option than to insulate and heat. The electronics you can make work at low temperatures, by using PCB materials which have a similar expansion to silicon, and directly mount the silicon chips onto the substrate without the classical chip packaging. &lt;/p&gt;&#xA;" OwnerUserId="127" LastEditorUserId="127" LastEditDate="2013-03-30T08:04:08.853" LastActivityDate="2013-03-30T08:04:08.853" CommentCount="2" />
  <row Id="1138" PostTypeId="2" ParentId="975" CreationDate="2013-03-30T13:27:29.337" Score="2" Body="&lt;p&gt;One factor in this that hasn't been mentioned in the other questions is that different materials change their volumes in different ways in response to temperature fluctuations.  This is the concept behind bimetallic strips in thermostats, why pipes burst when frozen, and why your food gets &quot;freezer burned&quot;.  So, although semiconductors may be fairly resilient to cold temperatures, mechanical parts with a variety of materials (different alloys, different lubricants) will be less so.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To have a mechanical part that works at an extreme temperature (like -100C), presumably it would need to be fabricated at that temperature, integrated into the main component at that temperature, and kept cold until it reached space.  &lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-04-01T19:22:00.160" LastActivityDate="2013-04-01T19:22:00.160" />
  <row Id="1139" PostTypeId="2" ParentId="1072" CreationDate="2013-03-30T20:41:47.360" Score="3" Body="&lt;p&gt;I read a magazine article many months ago about an automated system of power generation for isolated areas like disaster relief and such where a kite was used instead of a propeller driven wind turbine.  The write-up was not particularly technical but there was a picture of the ground unit and it looked like a winch with a boom like a fishing rod or something in that vein.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I understood it would allow the kite to pull away in the wind and generate power by running the winch motor as a generator and then it would control the kite to either loose drag or swing broadside to the wind so it could be reeled in for much less power draw, to be repeated while the wind lasted.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So it does seem possible to at least partly control kite operation via automation.&lt;/p&gt;&#xA;" OwnerUserId="1098" LastEditorUserId="37" LastEditDate="2013-05-16T09:25:06.193" LastActivityDate="2013-05-16T09:25:06.193" />
  <row Id="1140" PostTypeId="2" ParentId="1130" CreationDate="2013-03-31T03:20:27.640" Score="2" Body="&lt;p&gt;Another name is pin and block - &lt;a href=&quot;http://www.mcmaster.com/#&quot; rel=&quot;nofollow&quot;&gt;mcmaster carr&lt;/a&gt; is a go to place for many different fasteners, and mechanical doo-dads&lt;/p&gt;&#xA;" OwnerUserId="93" LastActivityDate="2013-03-31T03:20:27.640" />
  <row Id="1141" PostTypeId="2" ParentId="1130" CreationDate="2013-03-31T03:25:46.533" Score="2" Body="&lt;p&gt;The closest I can find are &lt;a href=&quot;http://www.1mta.com/products/386/&quot; rel=&quot;nofollow&quot;&gt;this&lt;/a&gt; and &lt;a href=&quot;http://www.c-rmfg.com/cnc-machining-aluminum-swivwl-joint.html&quot; rel=&quot;nofollow&quot;&gt;this&lt;/a&gt;: &quot;Swivel Joint&quot;.&lt;/p&gt;&#xA;" OwnerUserId="1100" LastEditorUserId="350" LastEditDate="2013-04-01T19:17:17.360" LastActivityDate="2013-04-01T19:17:17.360" />
  <row Id="1142" PostTypeId="2" ParentId="1113" CreationDate="2013-04-01T16:31:02.343" Score="1" Body="&lt;p&gt;The motor they listed apparently has 1.548 kg·cm of torque at 4.8 V.&#xA;(As Ian pointed out, on this website -- like too many &lt;a href=&quot;http://robosapiensindia.com/robomart/index.php?page=shop.product_details&amp;amp;flypage=flypage.tpl&amp;amp;product_id=238&amp;amp;category_id=42&amp;amp;option=com_virtuemart&amp;amp;Itemid=64&amp;amp;vmcchk=1&amp;amp;Itemid=64&quot; rel=&quot;nofollow&quot;&gt;other websites&lt;/a&gt; -- &quot;kg·cm&quot; is often misspelled as &quot;Kg/cm&quot;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It is apparently a NEMA 17 motor.&#xA;From the photo, it looks about half as long as a typical NEMA 17 motor,&#xA;so I'm not surprised it has about half the torque of a typical NEMA 17 motor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A torque of 1.548 kg·cm is more than adequate for many robots --&#xA;&lt;a href=&quot;http://reprap.org/wiki/stepper_motor&quot; rel=&quot;nofollow&quot;&gt;1.4 kg·cm of torque is adequate&lt;/a&gt; for axis motors on a RepRap.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;They use this unit only for the stepper motors and not for the DC&#xA;  motors&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Huh? &lt;s&gt;Every motor&lt;/s&gt; &lt;a href=&quot;http://www.nex-robotics.com/motors-and-accessories.html&quot; rel=&quot;nofollow&quot;&gt;Several motors listed on that site&lt;/a&gt;, both stepper and DC motor ( &lt;a href=&quot;http://www.nex-robotics.com/products/motors-and-accessories/75-rpm-dual-shaft-plastic-gear-motor.html&quot; rel=&quot;nofollow&quot;&gt;a&lt;/a&gt; &lt;a href=&quot;http://www.nex-robotics.com/products/motors-and-accessories/300-rpm-centre-shaft-economy-series-dc-motor.html&quot; rel=&quot;nofollow&quot;&gt;b&lt;/a&gt; ), are rated using the &quot;Kg/cm&quot; unit, which in every case is a misspelling of &quot;kg·cm&quot;.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;0.222 ... its absurdly low again.Most DC motors on the website&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;The &quot;0.222 kg·cm&quot; applies when driven at 0.4 V. That's a small fraction of its rated voltage, which is 6 V where the motor gives 1.869 kg·cm.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As far as I can tell, all the DC motors on that website include a gear box, which multiplies the torque.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It is unfair to compare motors by comparing only the torque at the output of a torque-multiplying gear box of one motor driven at its full rated voltage, to the torque of some other motor without a gearbox and when driven at a small fraction of its rated voltage.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On the other hand, I have to laugh when this website calls this a &quot;High torque&quot; motor when it is almost the lowest-torque NEMA 17 motor I've ever seen.&#xA;It reminds me of the &quot;Schnell-Bahn&quot; (literally &quot;fast train&quot;), which are the slowest trains still operating in Germany.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT:&#xA;I shouldn't have said &quot;every motor&quot;; most of the motors are rated in &quot;Kg-cm&quot; or &quot;kg-cm&quot;, which is close enough to &quot;kg·cm&quot;.&lt;/p&gt;&#xA;" OwnerUserId="187" LastEditorUserId="187" LastEditDate="2013-04-02T04:52:10.860" LastActivityDate="2013-04-02T04:52:10.860" CommentCount="3" />
  <row Id="1143" PostTypeId="1" AcceptedAnswerId="1144" CreationDate="2013-04-02T00:22:47.170" Score="0" ViewCount="88" Body="&lt;p&gt;This is a follow-up to this question:  &lt;a href=&quot;http://robotics.stackexchange.com/questions/1064/prototyping-a-device-with-25-100-small-dc-3-0v-motors-is-arduino-a-good-fit&quot;&gt;Prototyping a device with 25-100 small DC 3.0V motors, is Arduino a good fit?&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've decided based on the answer that sending the control signals through multiple TLC5947 chips, then sending the PWM signal to the motors is the best way to go.  What I need to know is how to turn the PWM signals into something of the required power, since the TLC5947's won't be able to drive the motors by themselves.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm guessing an amplifier is what I'll need to make, but what's the best way to boost that many signals?&lt;/p&gt;&#xA;" OwnerUserId="1031" LastActivityDate="2013-04-02T08:04:12.563" Title="How do I interface a TLC5947 with small motors?" Tags="&lt;motor&gt;&lt;power&gt;&lt;pwm&gt;" AnswerCount="1" />
  <row Id="1144" PostTypeId="2" ParentId="1143" CreationDate="2013-04-02T07:37:55.420" Score="1" Body="&lt;p&gt;The &lt;a href=&quot;http://robotics.stackexchange.com/a/1109/478&quot;&gt;accepted answer&lt;/a&gt; to your previous question presents several ways of developing enough drive for the vibrating motor, in its section called “Converting PWM signals into something that can drive a motor”.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;One of the most direct ways is using one ULN2803 device per 8 motors, or one ULN2003 per 7 motors.  In some packages these devices support up to 500 mA/channel when properly heatsinked; other packages allow less but should have no problem with the 85 mA start current and 75 mA run current of the vibration motor (&lt;a href=&quot;http://www.cutedigi.com/robotics/vibration-motor.html&quot; rel=&quot;nofollow&quot;&gt;1&lt;/a&gt;, &lt;a href=&quot;http://www.cutedigi.com/pub/Robot/310-101_datasheet.pdf&quot; rel=&quot;nofollow&quot;&gt;2&lt;/a&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;An alternative is to substitute LED drivers with higher drive capability in place of the TLC5947. For example, the 16-channel &lt;a href=&quot;http://www.toshiba-components.com/products/DriverLSI/LEDDrivers.html&quot; rel=&quot;nofollow&quot;&gt;Toshiba TC62D722&lt;/a&gt; allows up to 90mA/channel.  (I don't know what the availability of these parts is.)  Like the TI  TLC5947, the TC62D722 has per-channel PWM settings.  Both parts use an external current-limit-setting resistor and the TC62D722 also has an 8-bit (256 level) output current gain control.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note that TLC5947 channels can be paralleled.  On page 7 the &lt;a href=&quot;http://www.ti.com/lit/ds/sbvs114a/sbvs114a.pdf&quot; rel=&quot;nofollow&quot;&gt;data sheet&lt;/a&gt; says multiple outputs can be tied together to increase the constant current capability.  Thus you could use each TLC5947 to drive eight 90mA devices; or could use a 25mA-setting resistor and parallel 3 outputs to get 75mA.  Anyhow, &lt;em&gt;n&lt;/em&gt; TLC5947's, daisy-chained together, would drive &lt;em&gt;n&lt;/em&gt;·24/3 = 8·&lt;em&gt;n&lt;/em&gt; vibration motors.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you have motors on hand, you could use a 12V power supply in series with a 166 ohm resistor (or 150 or 200 ohms for other testing) to run about 60mA through a motor and see if it starts and runs satisfactorily.  If so, you might be able to use two TLC5947 channels instead of three per motor.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Drivers like ULN2003 or ULN2803 have internal clamp diodes so they can drive inductive loads without needing such diodes added on.  As an LED driver, the TLC5947 doesn't include clamp diodes for high-going voltage excursions since LED's are not much of an inductive load.  (The output diagram on page 8 of specs shows a diode from ground to OUT_n for OUT0 through OUT23, which would clamp negative-going voltages, but no rating is shown for the diode.)  You probably would need to add one clamp diode per motor.  However, it certainly is possible that you could run motor tests and find that the motor transients don't exceed the 33 volt output ratings of the TLC5947 – whenever you test it on the bench.&lt;/p&gt;&#xA;" OwnerUserId="478" LastEditorUserId="478" LastEditDate="2013-04-02T08:04:12.563" LastActivityDate="2013-04-02T08:04:12.563" CommentCount="1" />
  <row Id="1145" PostTypeId="1" AcceptedAnswerId="1147" CreationDate="2013-04-02T07:50:25.177" Score="5" ViewCount="178" Body="&lt;p&gt;I'm trying to handle food grains like rice, wheat in an automated way (to cook simple dishes). For this I have to transfer grain from a larger container to a weighing scale. I know I can use solenoid valves for liquids but all solid handling valves seem to be too big (gate valves etc) and for larger applications. Is there any better way to do this ? &lt;/p&gt;&#xA;" OwnerUserId="1041" LastActivityDate="2013-04-18T12:09:10.237" Title="What would be the best way to handle food grains?" Tags="&lt;automatic&gt;" AnswerCount="3" FavoriteCount="1" />
  <row Id="1146" PostTypeId="2" ParentId="1145" CreationDate="2013-04-02T12:19:18.413" Score="1" Body="&lt;p&gt;Mechanism could be similar to bubble-gum machine. Container fills up the cup (for which you know the mass of grains). With motor you need to rotate shaft with few cups from filling to spilling :) This would give you the resolution of mass that fills the cup. From there you can transfer that grains with conveyor to wherever you need.&lt;/p&gt;&#xA;" OwnerUserId="973" LastActivityDate="2013-04-02T12:19:18.413" CommentCount="2" />
  <row Id="1147" PostTypeId="2" ParentId="1145" CreationDate="2013-04-02T16:52:10.473" Score="5" Body="&lt;p&gt;I suggest experimenting with a &lt;a href=&quot;http://www.ptonline.com/kc/articles/focus-on-material-handling/cone&quot; rel=&quot;nofollow&quot;&gt;rotating cone&lt;/a&gt; feeder.  If you make the rotation-speed and the cone's axis-angle adjustable, users could set it differently for different materials.  The cone should be made easily removable, to allow easy cleaning and perhaps substitution of shorter, wider, or longer cones for different materials.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.ptonline.com/kc/articles/focus-on-material-handling/cone&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/KqsYp.jpg&quot; alt=&quot;Rotating Cone Feeder&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the diagram, the axis of the cone is horizontal.  The  “natural angle of repose” referred to in the text is material-dependent and rotation-speed dependent.  Up to some point, faster rotation delivers material faster.  Some cone systems periodically reverse the direction of rotation.  If the axis is horizontal, some given amount of material remains in the cone when it stops rotating, which might or might not matter in your process.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For other ideas, also see the &lt;a href=&quot;http://encyclopedia.che.engin.umich.edu/Pages/MaterialsHandling/Mixers/Mixers.html&quot; rel=&quot;nofollow&quot;&gt;Mixers&lt;/a&gt; page in the University of Michigan  “Encyclopedia of Chemical Engineering Equipment”, and see the  “Funnel Flow” section near the middle of the &lt;a href=&quot;http://encyclopedia.che.engin.umich.edu/Pages/MaterialsHandling/Hoppers/Hoppers.html&quot; rel=&quot;nofollow&quot;&gt;Hoppers&lt;/a&gt; page.  As seen in the video there, the fairly coarse mixture in the hopper stops running a couple of times, until the mechanism is shaken back and forth.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A vibrating-screen device is shown in &lt;a href=&quot;http://www.youtube.com/watch?v=IZaLZApoG6I&quot; rel=&quot;nofollow&quot;&gt;Vibrating Sieve Machine&lt;/a&gt;, Murat Model IV.  A large rotating spiral brush is shown in &lt;a href=&quot;http://www.youtube.com/watch?v=dwgf0DAfkxM&quot; rel=&quot;nofollow&quot;&gt;AyrKing Breader/Blender/Sifter&lt;/a&gt;. An old Gyro-sifter machine appears in &lt;a href=&quot;http://www.youtube.com/watch?v=UW_Wx1slexI&quot; rel=&quot;nofollow&quot;&gt;The Gyro-Sifter Machine! Odd&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="478" LastEditorUserId="37" LastEditDate="2013-04-18T12:09:10.237" LastActivityDate="2013-04-18T12:09:10.237" />
  <row Id="1148" PostTypeId="1" CreationDate="2013-04-02T23:13:52.470" Score="2" ViewCount="155" Body="&lt;p&gt;The dynamic programming algorithm refers to the &lt;a href=&quot;http://en.wikipedia.org/wiki/Bellman_equation&quot; rel=&quot;nofollow&quot;&gt;Bellman equation&lt;/a&gt;. An open-loop control decides movement at the initial point while a closed-loop control decides control during the movement. Now most robotic application looks like closed-loop control: in every point, it checks how it is doing with respect to some reward function, this is my thinking. Now most participants in threads such as &lt;a href=&quot;http://robotics.stackexchange.com/questions/128/how-mature-is-real-time-programming-in-robotics&quot;&gt;How mature is real-time programming in robotics?&lt;/a&gt; do not differentiate their scope, perhaps they haven't thought about it. Anyway, I am interested to know:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;How is dynamic programming used in robotics? Is there any research about DP usage in robotics?&lt;/strong&gt;&lt;/p&gt;&#xA;" OwnerUserId="640" LastEditorUserId="350" LastEditDate="2013-04-02T23:37:13.823" LastActivityDate="2013-04-02T23:49:37.107" Title="Dynamic programming algorithm aka Bellman equation in Robotics?" Tags="&lt;research&gt;&lt;dynamic-programming&gt;" AnswerCount="1" CommentCount="3" FavoriteCount="1" />
  <row Id="1149" PostTypeId="2" ParentId="1148" CreationDate="2013-04-02T23:35:12.210" Score="1" Body="&lt;p&gt;I won't answer directly how Bellman equation is used in robotics but DP is used in many areas, see the below. Even though we have a dynamic system with velocity/acceleration, we can still use linear-approximation like linear-programming algorithms &lt;a href=&quot;http://www.ensta-bretagne.fr/jaulin/robotetas.pdf&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;. I provide below some material and lectures about Dynamic programming and robotics. This is pretty interdisciplinary area so hard to find concise description. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Areas&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;ul&gt;&#xA;  &lt;li&gt;path-planning&lt;/li&gt;&#xA;  &lt;li&gt;vision such as stereo-vision&lt;/li&gt;&#xA;  &lt;li&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Constraint_satisfaction_problem&quot; rel=&quot;nofollow&quot;&gt;CSP&lt;/a&gt; and VCSP problems (see the cognitive robotics below)&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Alert about terminology!&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The term &lt;em&gt;&quot;dynamic programming&quot;&lt;/em&gt; is a special term referring to special class of mathematical problems. The term &lt;em&gt;&quot;dynamic&quot;&lt;/em&gt; system in physics refers to problems in continuum mechanics where objects are not in rest or in constant motion but they can accelerate. Then again &lt;a href=&quot;http://en.wikipedia.org/wiki/Statics&quot; rel=&quot;nofollow&quot;&gt;Statics&lt;/a&gt; considers problems in stable equilibrium.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;The term &lt;em&gt;&quot;dynamic programming&quot;&lt;/em&gt; is programming for historical reasons but the basic idea is to break the large problem into small problems. It has analogues to fields such as Economics (for example sub-game-perfect equilibrium in game-theory).&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Material&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;&lt;strong&gt;Path-planning&lt;/strong&gt;&lt;/p&gt;&#xA;  &#xA;  &lt;ul&gt;&#xA;  &lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://www.cc.gatech.edu/fac/Chris.Atkeson/legs/xmorimo.pdf&quot; rel=&quot;nofollow&quot;&gt;http://www.cc.gatech.edu/fac/Chris.Atkeson/legs/xmorimo.pdf&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://www.cs.ubc.ca/~mitchell/Papers/publishedCDC08.pdf&quot; rel=&quot;nofollow&quot;&gt;http://www.cs.ubc.ca/~mitchell/Papers/publishedCDC08.pdf&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;amp;arnumber=1104317&amp;amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D1104317&quot; rel=&quot;nofollow&quot;&gt;http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;amp;arnumber=1104317&amp;amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D1104317&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://ramp.ensc.sfu.ca/fmmtutorial/slides/mitchell.pdf&quot; rel=&quot;nofollow&quot;&gt;http://ramp.ensc.sfu.ca/fmmtutorial/slides/mitchell.pdf&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;  &#xA;  &lt;p&gt;&lt;strong&gt;Vision, Stereo vision and Dynamic programming&lt;/strong&gt;&lt;/p&gt;&#xA;  &#xA;  &lt;ul&gt;&#xA;  &lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://www.cipprs.org/papers/VI/VI1999/pp117-124-Gonzalez-et-al-1999.pdf&quot; rel=&quot;nofollow&quot;&gt;http://www.cipprs.org/papers/VI/VI1999/pp117-124-Gonzalez-et-al-1999.pdf&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;[popularly citated paper] &lt;a href=&quot;http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;amp;arnumber=4767639&amp;amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D4767639&quot; rel=&quot;nofollow&quot;&gt;http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;amp;arnumber=4767639&amp;amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D4767639&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;  &#xA;  &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://search.mit.edu/search?site=ocw&amp;amp;client=mit&amp;amp;getfields=%2a&amp;amp;output=xml_no_dtd&amp;amp;proxystylesheet=http%3A%2F%2Focw.mit.edu%2Fsearch%2Fgoogle-ocw.xsl&amp;amp;proxyreload=1&amp;amp;as_dt=i&amp;amp;oe=utf-8&amp;amp;departmentName=web&amp;amp;courseName=&amp;amp;q=robotics+dynamic+programming&amp;amp;btnG.x=-595&amp;amp;btnG.y=-267&quot; rel=&quot;nofollow&quot;&gt;Lectures&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;  &#xA;  &lt;ul&gt;&#xA;  &lt;li&gt;&lt;p&gt;Underactuated robotics in MIT &lt;a href=&quot;http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-832-underactuated-robotics-spring-2009/&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;&#xA;  -- this lecture &lt;a href=&quot;http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-832-underactuated-robotics-spring-2009/video-lectures/lecture-5-numerical-optimal-control-dynamic-programming/&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;&#xA;  about DP&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Cognitive robotics has some tasks about DP &lt;a href=&quot;http://ocw.mit.edu/courses/aeronautics-and-astronautics/16-412j-cognitive-robotics-spring-2005/assignments/ps2.pdf&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="640" LastEditorUserId="640" LastEditDate="2013-04-02T23:49:37.107" LastActivityDate="2013-04-02T23:49:37.107" />
  <row Id="1150" PostTypeId="5" CreationDate="2013-04-02T23:59:30.967" Score="0" ViewCount="2" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2013-04-02T23:59:30.967" LastActivityDate="2013-04-02T23:59:30.967" />
  <row Id="1151" PostTypeId="4" CreationDate="2013-04-02T23:59:30.967" Score="0" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2013-04-02T23:59:30.967" LastActivityDate="2013-04-02T23:59:30.967" />
  <row Id="1152" PostTypeId="2" ParentId="975" CreationDate="2013-04-03T00:05:05.480" Score="3" Body="&lt;p&gt;Because there is not enough research and development done in the manufacturing process of electronic components in low temperatures. And the probes must be reliable.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can not make parts in i.e. 250'C and expect them to work in -100'C because for example a chip has silicon parts as well as tungsten parts. These two have different temperature versus extension characteristics, so the parts would simply fall apart.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In low temperatures you can't use tin for soldering &lt;a href=&quot;http://en.wikipedia.org/wiki/Tin_pest&quot; rel=&quot;nofollow&quot; title=&quot;see tin pest&quot;&gt;see tin pest&lt;/a&gt;.  &lt;/p&gt;&#xA;" OwnerUserId="1114" LastActivityDate="2013-04-03T00:05:05.480" />
  <row Id="1153" PostTypeId="1" CreationDate="2013-04-03T00:16:19.533" Score="8" ViewCount="755" Body="&lt;p&gt;FPGA has good points such as a lot of IO points but then again you need to think things on very low level with flip-flops and pioneer on areas where things are not yet mature -- for example see this question &lt;a href=&quot;http://electronics.stackexchange.com/questions/3107/looking-for-open-source-fpga-hardware-and-dev-tools&quot;&gt;here&lt;/a&gt; about development-tools on FPGAs -- this is my understanding currently! Now FPGA has been used to create excellent dexterity in robotic hands like &lt;a href=&quot;http://www.youtube.com/watch?v=6rhH4YlObkM&quot;&gt;here&lt;/a&gt;. Now some people market FPGA for fast prototyping and &lt;em&gt;&quot;forward looking&quot;&lt;/em&gt; designs like &lt;a href=&quot;http://www.rtcmagazine.com/articles/view/101763&quot;&gt;here&lt;/a&gt;, I don't fully understand them: if you don't need a lot of IO points for things such as sensors, why to choose FPGA for a robot? So&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;When should FPGA be chosen for a project in robotics?&lt;/strong&gt;&lt;/p&gt;&#xA;" OwnerUserId="640" LastEditorUserId="1013" LastEditDate="2013-04-06T11:02:11.530" LastActivityDate="2013-04-07T09:46:04.990" Title="When should FPGAs be used in Robotics?" Tags="&lt;design&gt;&lt;research&gt;&lt;logic-control&gt;" AnswerCount="3" CommentCount="1" FavoriteCount="5" />
  <row Id="1154" PostTypeId="2" ParentId="1100" CreationDate="2013-04-03T00:21:39.563" Score="0" Body="&lt;p&gt;The definition of &lt;code&gt;robot&lt;/code&gt; is as follows:  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;&quot;A machine built to carry out some complex task or group of tasks, especially one which can be programmed&quot;&lt;/em&gt;&lt;br&gt;&#xA;&lt;a href=&quot;http://en.wiktionary.org/wiki/robot&quot; rel=&quot;nofollow&quot;&gt;wiktionary&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So a robot is a tool which can be programmed. The KUKA robot fits in this definition. But a hammer can not be programmed, so a hammer is not a robot.&lt;/p&gt;&#xA;" OwnerUserId="1114" LastActivityDate="2013-04-03T00:21:39.563" />
  <row Id="1155" PostTypeId="2" ParentId="975" CreationDate="2013-04-03T12:08:58.557" Score="2" Body="&lt;p&gt;I would suggest that the key reason is reliability - once a probe has been launched into space, it &lt;strong&gt;HAS&lt;/strong&gt; to work.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As such, it is a lot safer to heat up a known, reliable, material that has been subject to extensive testing, than it is to &quot;invent&quot; a new material that cannot be fully tested on Earth.&lt;/p&gt;&#xA;" OwnerUserId="134" LastActivityDate="2013-04-03T12:08:58.557" />
  <row Id="1156" PostTypeId="2" ParentId="1153" CreationDate="2013-04-03T13:05:08.557" Score="4" Body="&lt;p&gt;I'm not sure what in the linked question about development tools makes you think that they are not mature. It is true that most of them are proprietary and not open source. But I thought that the tools were quite mature even back when that question was asked three years ago. Today &lt;a href=&quot;http://www.xilinx.com/support/download/index.html/content/xilinx/en/downloadNav/design-tools.html&quot;&gt;Xilinx&lt;/a&gt;, &lt;a href=&quot;http://www.altera.com/literature/po/ss_quartussevswe.pdf&quot;&gt;Altera&lt;/a&gt;, and &lt;a href=&quot;http://www.latticesemi.com/products/designsoftware/diamond/downloads.cfm&quot;&gt;Lattice&lt;/a&gt; all have freely available development environments that run on Windows and Linux with 32 and 64-bit support. If you insist on open source &lt;a href=&quot;http://iverilog.icarus.com/&quot;&gt;Icarus Verilog&lt;/a&gt; can do quite a bit. But I'd personally stick with the vendor specific tools.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;FPGA's are more than just a bunch of configurable flip flops. Consider the &lt;a href=&quot;http://www.alterawiki.com/wiki/Nios&quot;&gt;Altera NIOS II&lt;/a&gt;. A 32-bit soft-core processor capable of running Linux. Mix and match communications and other peripherals from &lt;a href=&quot;http://opencores.org/projects&quot;&gt;OpenCores&lt;/a&gt; or from &lt;a href=&quot;http://www.xilinx.com/products/intellectual-property/index.htm&quot;&gt;Xilinx&lt;/a&gt;, &lt;a href=&quot;http://www.altera.com/products/ip/ip-index.jsp&quot;&gt;Altera&lt;/a&gt;, or &lt;a href=&quot;http://www.latticesemi.com/products/intellectualproperty/index.cfm?source=topnav&quot;&gt;Lattice&lt;/a&gt; and you've built a custom microcontroller with everything you need and nothing you don't. You can even write C code for the NIOS II processor and have certain functions &lt;a href=&quot;http://electronics.stackexchange.com/questions/63690/from-c-to-silicon-how-to-implement-software-firmware-solution-as-hardware/63704#63704&quot;&gt;implemented directly in the FPGA hardware&lt;/a&gt; if you need the speed. Is that high level enough thinking for you?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;FPGA's have a high initial investment cost. But it's cheaper and easier to add functionality later in the design process. That's what's meant by &quot;forward looking&quot; designs. Consider a project where you want to add some additional motors to your robot but you've run out of PWM generators on your microcontroller. What do you do? Add another microcontroller? Buy separate PWM chips and connect them to a communications interface? What if all your communications interfaces are in use? With an FPGA, this is reduced almost entirely to a copy and paste operation. It's a lot easier, cheaper, and quicker to scale a design to include new functionality without buying as much additional hardware with an FPGA.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But probably the biggest reason to use an FPGA is speed. I'm not talking about pure clock speed. But when you need a lot of things to happen simultaneously. As Gossamer mentioned, parallelism is what FPGA's are really good at. Filter designs especially benefit from this kind of parallel architecture. If you need to filter and respond to a rapidly changing sensor, then you need an FPGA. They are also quite good at video processing as this too benefits from parallel processing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Take for instance &lt;a href=&quot;http://www.virtualworldlets.net/Resources/Hosted/Resource.php?Name=HighSpeedRobotDexterity&quot;&gt;this high-speed hand robot&lt;/a&gt;. It needs to process the video from the high-speed (1000 frames per second) machine vision camera as well as the tactile sensors and respond by manipulating numerous actuators in only a few milliseconds. This type of project is when you &lt;em&gt;need&lt;/em&gt; to choose FPGAs.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/K491N.png&quot; alt=&quot;massively parallel vision processing&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="142" LastActivityDate="2013-04-03T13:05:08.557" CommentCount="10" />
  <row Id="1157" PostTypeId="2" ParentId="1132" CreationDate="2013-04-03T15:17:50.863" Score="11" Body="&lt;h1&gt;Make your own&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;@Tom Squires's suggestion to start with an Arduino is a good one.  Choose a Leonardo for best combination of ease of use and compatibility.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Get yourself an inexpensive base kit that's compatible with your Arduino.  Don't invest too much.  Robot bases are like motorcycles -- you're going to replace the first one you buy within a year after you discover what you 'really want'.  I'd suggest a &lt;a href=&quot;http://www.pololu.com/catalog/product/1418&quot;&gt;Pololu Zumo&lt;/a&gt; or &lt;a href=&quot;http://www.parallax.com/Store/Robots/AllRobots/tabid/128/CategoryID/3/List/0/SortField/0/Level/a/ProductID/601/Default.aspx&quot;&gt;Parallax Stingray&lt;/a&gt;.  You'll need a motor shield for your Arduino.  A nice choice is the &lt;a href=&quot;http://www.pololu.com/catalog/product/2504&quot;&gt;Zumo Shield&lt;/a&gt; from Pololu.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You'll need lots of farkles and bling -- sensors, actuators, blinking lights, etc.  You'll have no idea which ones you need until you start to figure things out.  I'd recommend setting yourself a monthly budget and getting to know sites like &lt;a href=&quot;http://www.parallax.com/&quot;&gt;Parallax&lt;/a&gt;, &lt;a href=&quot;https://www.sparkfun.com/&quot;&gt;Sparkfun&lt;/a&gt;, &lt;a href=&quot;http://www.pololu.com/&quot;&gt;Pololu&lt;/a&gt;, &lt;a href=&quot;http://www.adafruit.com/&quot;&gt;Adafruit&lt;/a&gt;, &lt;a href=&quot;http://www.robotmarketplace.com/store.html&quot;&gt;Robot Marketplace&lt;/a&gt;, &lt;a href=&quot;http://www.trossenrobotics.com/&quot;&gt;Trossen Robotics&lt;/a&gt;, and &lt;a href=&quot;http://www.servocity.com/&quot;&gt;Servo City&lt;/a&gt;.  Be prepared, robotics can be a spendy hobby if you're not careful with your budget.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You'll need to teach yourself the basics of electronics and mechanical engineering.  A great introduction to electronics is the book &lt;a href=&quot;http://www.makershed.com/Make_Electronics_book_by_Charles_Platt_p/9780596153748.htm&quot;&gt;Make: Electronics&lt;/a&gt;, this will cover in decent depth and breadth in an accessible style.  It has matching electronics components packs you can buy to get hands on experience while you read.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You'll need to learn how to solder.  Lots of great resource on the internet, my favorite for teaching new enthusiasts is &lt;a href=&quot;http://mightyohm.com/blog/2011/04/soldering-is-easy-comic-book/&quot;&gt;Soldering is Easy&lt;/a&gt;.  You'll want a &lt;a href=&quot;http://www.adafruit.com/products/1204&quot;&gt;mid end soldering iron&lt;/a&gt; (~$100 soldering station from Hakko or Weller) with a good tip (small conical or screwdriver) -- this makes a &lt;em&gt;world&lt;/em&gt; of difference.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For basic mechanical engineering, my favorite book is &lt;a href=&quot;http://rads.stackoverflow.com/amzn/click/0071408509&quot;&gt;Building Robot Drive Trains&lt;/a&gt;.  This will get you enough information to get started selecting motors and building a custom chassis as you gain experience.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Enjoy!  It's a great hobby with a world of possibilities out there.  Don't settle for a kit that will narrow your thinking and possibilities -- choose the best of the best and find your own path.&lt;/p&gt;&#xA;" OwnerUserId="35" LastEditorUserId="35" LastEditDate="2013-04-04T00:21:28.917" LastActivityDate="2013-04-04T00:21:28.917" CommentCount="2" />
  <row Id="1158" PostTypeId="1" AcceptedAnswerId="1159" CreationDate="2013-04-03T18:42:03.497" Score="2" ViewCount="82" Body="&lt;p&gt;Some vector math is involved here so prepare yourself.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am developing a robotic arm that moves in two dimensions.  It is a rotary-rotary design which looks roughly like the picture in this post:&#xA;&lt;a href=&quot;http://robotics.stackexchange.com/questions/869/building-robotic-arm-joint&quot;&gt;Building Robotic arm joint&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am now trying to limit the speed of the end-effector.  I am using Simulink and believe that the best way to limit the speed is the limit the rate of change of the X and Y coordinates that I tell it to move to.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now, I also want the end-effector to be able to move in a straight line and believe that I can accomplish this by defining functions that calculate the maximum rate for movement in the X or Y direction based on the distance the arm is trying to travel.  The equasion I came up with is this :&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;xRate = (abs(currentX - nextX) / max(abs(currentX - nextX), abs(currentY - nextY))&#xA;yRate = (abs(currentY - nextY) / max(abs(currentX - nextX), abs(currentY - nextY))&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;So basically, XRate: distance in x / max between distance in X and distance in Y.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Now, for the actual problem.  Because this limits the speed in both X and Y, the end-effector can travel (for instance) 1 in./sec in both directions at the same time.  Meaning that it is travelling at OVER 1 in./sec overall.  If, however, it is only moving in ONE direction then it will only move at that 1 in./sec speed because there is no second component.  It boils down to the fact that the max speed the arm can move is 'sqrt(2)' and the minimum is '1'.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;My main question is&lt;/strong&gt;:  Given that I need to calculate a max xRate and a max yRate, how can I limit the overall speed of the end-effector?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Secondarily, is there a way for me to implement a rate control that will limit the overall rate instead of limiting X and Y independantly using Simulink?&lt;/p&gt;&#xA;" OwnerUserId="852" LastActivityDate="2013-04-03T19:53:07.270" Title="Equation to limit rate of change of end-effector in X and Y coordinates" Tags="&lt;design&gt;" AnswerCount="1" />
  <row Id="1159" PostTypeId="2" ParentId="1158" CreationDate="2013-04-03T19:53:07.270" Score="2" Body="&lt;p&gt;Rather than trying to limit the 'x' and 'y' velocities separately, you should be limiting the overall velocity and calculating the component velocities from that overall velocity. In other words, something like:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;dx = currentX - nextX&#xA;dy = currentY - nextY&#xA;rate = min (maxRate, maxRate / sqrt( dx^2 + dy^2 )&#xA;xRate = dx * rate&#xA;yRate = dy * rate&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;So for moving only in X:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;dx = currentX - nextX                              = 1&#xA;dy = currentY - nextY                              = 0&#xA;rate = min (maxRate, maxRate / sqrt( dx^2 + dy^2 ) = maxRate&#xA;xRate = 1 * rate                                   = maxRate&#xA;yRate = 0 * rate                                   = 0&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;While moving only in Y:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;dx = currentX - nextX                              = 0&#xA;dy = currentY - nextY                              = 1&#xA;rate = min (maxRate, maxRate / sqrt( dx^2 + dy^2 ) = maxRate&#xA;xRate = 0 * rate                                   = 0&#xA;yRate = 1 * rate                                   = maxRate&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;And for the diagonal movement you suggested:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;dx = currentX - nextX                              = 1&#xA;dy = currentY - nextY                              = 1&#xA;rate = min (maxRate, maxRate / sqrt( dx^2 + dy^2 ) = maxRate / sqrt(2)&#xA;xRate = dx * rate                                  = maxRate / sqrt(2)&#xA;yRate = dy * rate                                  = maxRate / sqrt(2)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="37" LastActivityDate="2013-04-03T19:53:07.270" CommentCount="3" />
  <row Id="1160" PostTypeId="1" CreationDate="2013-04-03T23:23:01.653" Score="3" ViewCount="235" Body="&lt;p&gt;I have an old gamecube that doesn't work and I want to gut it and fill it with Arduino boards and/or Raspberry Pi if necessary.  I want the project to eventually have some kind of AI aspect, but I'm also toying with the idea of using a &lt;a href=&quot;http://en.wikipedia.org/wiki/WaveBird_Wireless_Controller&quot; rel=&quot;nofollow&quot;&gt;wireless GameCube remote and wavebird&lt;/a&gt; to issue commands at the push of a button.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I guess this would be mostly good for testing purposes, but I'm mostly curious if and how I would go about making my RaspberryPi understand Gamecube remote input.  Furthermore, would this kind of idea be feasible?&lt;/p&gt;&#xA;" OwnerUserId="1121" LastEditorUserId="350" LastEditDate="2013-04-04T16:26:00.897" LastActivityDate="2013-05-04T19:14:13.160" Title="Can I use the RaspberryPi to receive the GameCube remote's RF signals?" Tags="&lt;control&gt;&lt;arduino&gt;&lt;raspberry-pi&gt;" AnswerCount="2" />
  <row Id="1161" PostTypeId="2" ParentId="1160" CreationDate="2013-04-04T11:20:58.590" Score="0" Body="&lt;p&gt;Yes, it's definitely feasible. I realize this won't be a &quot;complete&quot; answer according to the rules here, but either way here's some links to point you in the (hopefully) right direction:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.raphnet.net/electronique/gc_n64_usb/index_en.php&quot; rel=&quot;nofollow&quot;&gt;Rather complete tutorial on making a GameCube controller to USB converter&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.raphnet-tech.com/products/gc_n64_usb_adapters/index.php&quot; rel=&quot;nofollow&quot;&gt;The same adapter ready to go for $30CAD&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://forum.allaboutcircuits.com/showthread.php?t=41524&quot; rel=&quot;nofollow&quot;&gt;Short forum discussion about GameCube serial interface&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="95" LastActivityDate="2013-04-04T11:20:58.590" />
  <row Id="1162" PostTypeId="2" ParentId="1160" CreationDate="2013-04-04T18:15:53.613" Score="1" Body="&lt;p&gt;If you can convert the GameCube interface to be a USB game controller, this should go fairly smoothly.  I used to buy used USB Xbox and Playstation2 controllers to control our underwater vehicles, and use &lt;a href=&quot;http://www.pygame.org/docs/ref/joystick.html&quot; rel=&quot;nofollow&quot;&gt;Python's pygame library for joystick support&lt;/a&gt; to read the input from it.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://i.stack.imgur.com/AX8JM.jpg&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/AX8JMm.jpg&quot; alt=&quot;joysticking in the ocean&quot;&gt;&lt;/a&gt;&#xA;&lt;a href=&quot;http://i.stack.imgur.com/qZWuz.jpg&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/qZWuzm.jpg&quot; alt=&quot;joysticking with live video&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pygame makes it pretty easy.  For example, &lt;a href=&quot;http://rosettacode.org/wiki/Joystick_position#Python&quot; rel=&quot;nofollow&quot;&gt;this script to show joystick position&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-04-04T18:15:53.613" />
  <row Id="1163" PostTypeId="1" AcceptedAnswerId="1166" CreationDate="2013-04-04T18:45:28.617" Score="3" ViewCount="195" Body="&lt;p&gt;I'm building a quadcopter and I've seen that a Li-Po battery must not be entirely discharged, otherwise it could damage it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How do you know when you have to stop your quadcopter or robot in order to prevent damages, since the voltage doesn't drop? Which part should control the battery charge? ESCs? BEC? Flight controller?&lt;/p&gt;&#xA;" OwnerUserId="943" LastActivityDate="2013-04-05T02:12:38.303" Title="How to know when a Li-Po battery is discharged?" Tags="&lt;battery&gt;" AnswerCount="3" CommentCount="5" />
  <row Id="1164" PostTypeId="2" ParentId="1163" CreationDate="2013-04-04T19:05:05.400" Score="2" Body="&lt;p&gt;Lithium polymer batteries &lt;em&gt;do&lt;/em&gt; have a drop in their voltage as they discharge.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Use a simple zener/opamp circuit (&lt;a href=&quot;http://www.reuk.co.uk/12-Volt-Battery-Low-Indicator-LM741.htm&quot; rel=&quot;nofollow&quot;&gt;this&lt;/a&gt; is a good example of one), or just analogRead from a resistor system parallel to the battery. Determine what your definition of &quot;low battery&quot; is (some experimentation may help, see what values you get for a discharged battery), and set your processor to understand that.&lt;/p&gt;&#xA;" OwnerUserId="126" LastActivityDate="2013-04-04T19:05:05.400" CommentCount="1" />
  <row Id="1165" PostTypeId="2" ParentId="1163" CreationDate="2013-04-04T19:45:13.110" Score="2" Body="&lt;p&gt;There are a number of off-the-shelf battery monitors that will notify you when the battery voltage has dropped to a critical point. In our lab we use one that emits a loud noise (as an example see the &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/__7223__Hobby_King_Battery_Monitor_3S.html&quot; rel=&quot;nofollow&quot;&gt;Hobby King Battery Monitor 3S&lt;/a&gt;).&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-04-04T19:45:13.110" CommentCount="2" />
  <row Id="1166" PostTypeId="2" ParentId="1163" CreationDate="2013-04-04T21:41:12.610" Score="2" Body="&lt;p&gt;You can tell by the voltage.  LiPo batteries have a distinct &quot;knee&quot; in their performance, generally around 3.4V-3.6V:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://www.rctoys.com/pr/pr-images/tp-extreme-5000-discharge-curve-graph.gif&quot; alt=&quot;lithium ion voltage discharge curve&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It will be slightly different depending on the exact battery, and how you've arranged them in your battery packs (you need to account for the current load when measuring the voltage) -- so it makes sense to characterize your own battery first.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Since your batteries will be in a quadcopter, the best solution will depend on whether you favor the safety of the battery (immediate hardware shutoff) or the safety of the platform (warn the autonomy, allow it to land safely before it shuts itself down in software).  &lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-04-05T02:12:38.303" LastActivityDate="2013-04-05T02:12:38.303" />
  <row Id="1167" PostTypeId="1" AcceptedAnswerId="1169" CreationDate="2013-04-05T04:02:25.527" Score="2" ViewCount="464" Body="&lt;p&gt;I'm building an arduino controlled pump system to be able to move fluids around. I need this to be fairly accurate, but extreme precision isn't required. Since there will be a variety of liquids moved through the pump, I've determined a peristaltic pump the best fit. But I don't think I fully understand them, and had a few questions..&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;Since I'll need to purge the system... Can a peristaltic pump push air? Let's assume you have a 2m of tubing, and you pump a bunch of water through it. Can you remove the tube from the water reservoir so it is open to the air, and effectively purge the system of any remaining water?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Since I want to fairly accurately measure flow, could I simply count milliseconds instead of using a flowmeter? ... Will a peristaltic pump ALWAYS pump at a constant rate, regardless of the viscosity of the fluid? That is, will maple syrup come out at the same rate as water?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Shopping question, ignore I suppose ... Anyone know where I may find a fast/high flow peristaltic pump? I'm looking to be able to pump, at a minimum, .5oz/sec&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Would be determinant upon #3 ... What sort of relay would I want for toggling this on/off with an arduino?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="1128" LastEditorUserId="350" LastEditDate="2013-04-07T22:34:09.157" LastActivityDate="2013-10-25T04:29:01.403" Title="Can the rate of peristaltic pump's flow be accurate across changes in fluid viscosity?" Tags="&lt;arduino&gt;" AnswerCount="2" CommentCount="2" />
  <row Id="1168" PostTypeId="2" ParentId="1072" CreationDate="2013-04-05T14:24:08.893" Score="3" Body="&lt;p&gt;I'm the author of &lt;a href=&quot;http://electronics.stackexchange.com/q/61014&quot;&gt;the question you refer to&lt;/a&gt; and I will tell you; it is in fact possible. But unfortunately not easy.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is quite some heavy development going on now, since it seems to be the next promis of wind energy. This is because at higher altitudes, winds are stronger and more constant. In addition to that, there is no need for large constructions (like conventional wind turbines) and the setup is highly mobile (which indeed makes it ideal for emergency situations or developing countries). Lastly, there is less &quot;view pollution&quot; as we more or less call it in Dutch. This is the concept that everyone wants to use green wind energy in their homes, but no one wants a humongous wind turbine in their backyard because of the noise and the view. A kite however, can be a thousand square meters, but if its 5 kilometers up in the air, you just see a string going up in the air.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Next to the advantages, there are some severe challenges as well though. These are of course in some hardware related parts. For example; how do you reliably track the kite in the air (which was exactly my issue with my other question), but also; how do you measure wind speed at kite height without the kite its wind disturbance, and how do you overcome the rope weight when the rope becomes 5 kilometers long?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The software issues seem to be a way bigger issue than the hardware ones though. It appears to be not so easy to fly a kite reliably in a figure 8. This is because you're dealing with quite an unstable environment; changing wind direction, varying speed, and incidental wind gusts. Kite deformations and the different reactions of the kite in different parts within and outside the so called &quot;wind power zone&quot; are very different. A simple PID controller is not the easy solution apparantly. In addition to these things, heavy wind gusts can also be a danger in that it can break the kite's rope. So the kite must be able to quickly depower itself when a windgust comes up, which needs some kind of feed-forward loop. Finally, if the wireless data connection between the kite and the ground station breaks (for whatever reason) how can the kite control itself to decent to make a safe landing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The reason I'm so into this is because I'm looking into doing a PhD at the Delft University to develop a evolutionary based self learning kite control system for the &lt;a href=&quot;http://kitepower.eu/&quot; rel=&quot;nofollow&quot;&gt;currect kitepower project&lt;/a&gt; they have there.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Although I'm not very experienced with the hardware side of the story, I thought why not start myself while I haven't started at the TU Delft yet? So I set out to find what I need for all of this. By now I have a good grasp of my first plans. I am now able to do some motor controlling and I am currently in the process of collecting some parts I need.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you also want to try building one that would be great. The more people in it, the more experience that is gained.. :)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cheers&lt;/p&gt;&#xA;" OwnerUserId="1050" LastEditorUserId="350" LastEditDate="2013-07-29T19:49:51.947" LastActivityDate="2013-07-29T19:49:51.947" />
  <row Id="1169" PostTypeId="2" ParentId="1167" CreationDate="2013-04-05T17:31:39.337" Score="3" Body="&lt;p&gt;The answers to &quot;will it work&quot; and &quot;will viscosity affect flow rate&quot; is really &quot;it depends&quot;.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.wmcpumps.com/series_810.htm&quot; rel=&quot;nofollow&quot;&gt;Peristaltic pumps that push air&lt;/a&gt; exist.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;All pumps work by using low pressure to pull in fluid and high pressure to push it out.  In this case, the low pressure is the suction created when the flexible tube tries to retain its shape after being pressed by the roller.  The high pressure is created by the roller moving forward, like you would do with a tube of toothpaste.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here's where it gets interesting.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Completely flattening the tube is a foolproof way to pump, but it shortens the life of the tube.  So, a lot of pumps take advantage of the &lt;strong&gt;viscosity&lt;/strong&gt; of the fluid (the slowing down of the fluid near the walls of the tube).  All the rollers really need to do is make it easier for the fluid to flow forward than backwards.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, the pump is actually balancing the following factors:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The ability of the tubing to regain its shape (springy-ness of the tube, affected by the fluid viscosity)&lt;/li&gt;&#xA;&lt;li&gt;The pressure of the fluid at the pump exit&lt;/li&gt;&#xA;&lt;li&gt;The resistance of the fluid to flowing backwards through the restricted tube (fluid viscosity, affected by the extent that the tube is constricted by the roller)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;You'll have to find out whether your pump is completely flattening the tube, or just relying on water's higher viscosity in order to increase the life of the tubing.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-04-05T17:31:39.337" CommentCount="1" />
  <row Id="1170" PostTypeId="1" CreationDate="2013-04-05T18:05:17.580" Score="2" ViewCount="68" Body="&lt;p&gt;I'm starting out with Gazebo (1.5) at the moment and am following &lt;a href=&quot;http://bramridder.com/ai-blog.php/integrating-ros-with-gazebo&quot; rel=&quot;nofollow&quot;&gt;a tutorial&lt;/a&gt; off the internet. In order to get Gazebo to find the model, the author advocates manually exporting the &lt;code&gt;GAZEBO_MODEL_PATH&lt;/code&gt; environment variable via &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;export GAZEBO_MODEL_PATH=[...]/models:$GAZEBO_MODEL_PATH&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;But that will only work for the current terminal. So I wanted to change the environment variable permanently. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The &lt;a href=&quot;http://gazebosim.org/user_guide/started__components__env.html&quot; rel=&quot;nofollow&quot;&gt;Gazebo User Guide&lt;/a&gt; claims that &lt;code&gt;GAZEBO_MODEL_PATH&lt;/code&gt;, along with all the other environment variables, is set by &lt;code&gt;/usr/share/gazebo-1.5/setup.sh&lt;/code&gt; but my (virgin) Gazebo install doesn't list it:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;export GAZEBO_MASTER_URI=http://localhost:11345&#xA;export GAZEBO_MODEL_DATABASE_URI=http://gazebosim.org/models&#xA;export GAZEBO_RESOURCE_PATH=/usr/share/gazebo-1.5:/usr/share/gazebo_models&#xA;export GAZEBO_PLUGIN_PATH=/usr/lib/gazebo-1.5/plugins&#xA;export LD_LIBRARY_PATH=/usr/lib/gazebo-1.5/plugins:${LD_LIBRARY_PATH}&#xA;export OGRE_RESOURCE_PATH=/usr/lib/i386-linux-gnu/OGRE-1.7.4&#xA;&#xA;# This line is needed while we're relying on ROS's urdfdom library&#xA;export LD_LIBRARY_PATH=/opt/ros/fuerte/lib:${LD_LIBRARY_PATH}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;But when I start Gazebo, &lt;code&gt;GAZEBO_MODEL_PATH&lt;/code&gt; is already set to &lt;code&gt;$HOME/.gazebo/models&lt;/code&gt;, so it must be set somewhere. I guess I could probably simply add &lt;code&gt;GAZEBO_MODEL_PATH&lt;/code&gt; to the &lt;code&gt;setup.sh&lt;/code&gt; script, but since it is set somewhere, I'd still like to know where and whether it is better practice to set it in there.&lt;/p&gt;&#xA;" OwnerUserId="131" LastEditorUserId="158" LastEditDate="2014-01-10T10:51:11.883" LastActivityDate="2014-01-10T10:51:11.883" Title="Where does Gazebo set the GAZEBO_MODEL_PATH environment variable?" Tags="&lt;gazebo&gt;" AnswerCount="0" />
  <row Id="1171" PostTypeId="2" ParentId="1153" CreationDate="2013-04-05T21:39:04.950" Score="2" Body="&lt;p&gt;I think there might be a misconception around what an FPGA actually is and when it is used in designs.  So let me try to explain that part first.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;FPGAs and when one might want to have one...&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;At risk of simplication, an FPGA is little more than a processor that happens to be 'reconfigurable'.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Why would someone want a 'reconfigurable' microprocessor?  Well, because it costs far too much to fabricate a silicon processor to afford to do it for one, two, or even two hundred chips.  You'd need to be running batches of thousands of chips to make it economically feasible.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Since no design is ever bug-free the first time round, going the silicon route effectively commits a company to at least two if not more test runs, all at huge fabrication costs.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Which essentially means that very few commercial companies are going to be interested in designing and bringing to fabrication anything other than chip with broad enough commercial appeal.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, if you come up with a brilliant design that justifies a custom microprocessor, then you &lt;em&gt;might&lt;/em&gt; try to bring your idea to life on a shoestring budget by implementing it in an FPGA, where the actual chip is simply a collection of gates, and a 'program' (typically VHDL or Verilog) arranges those gates into an actual microprocessor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But that's quite a ways down an entirely different (microprocessor design!) road...&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Which leads me to suggest that&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;... FPGAs are &lt;em&gt;not&lt;/em&gt; essential to robotics -- at least at the outset&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What you need for robotics is a &lt;em&gt;processor&lt;/em&gt;.  An FPGA is just a special kind of processor (reconfigurable). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;You ask whether you 'should'?  Well that depends on your knowledge as well as where your real interests lie -- microprocessor design first or robotics first?  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If microprocessors are your passion, then by all means!  And robotics is a great application area for custom microprocessors -- perhaps a vision cortex with many parallel decision pathways handled directly in hardware, or special tensor multiplication in hardware -- basically anything that generic processors can't handle well off-the-shelf.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But if you're going to microprocessor designs in FPGAs, well, then of course you'll need to have all of that low level knowledge you mention, and more -- because fundamentally you'll be designing your own processor.  Which has nothing really to do with robotics, even though your target application might be robotics.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Most designers can probably find an existing processor that will do most of what they'll ever need.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So I think you probably &lt;em&gt;don't&lt;/em&gt; need an FPGA.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;A starter roadmap: from commercial capabilities to (maybe) an FPGA...&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;First goal in my opinion is to try to get all of your creative concepts built up into a working robot (quite an intensive challenge in itself).  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you find that you've got specific and significant processing bottlenecks in your design, then the next goal is optimising the selection / design of your processors, still commercially available chips.  Maybe bigger, faster (trade-off with power draw, heat dissipation).  Maybe smaller, dedicated chips handling specific tasks and interfacing with the main brain (trade-off with algorithm / logic complications).  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Only if there's capabilities that you just won't be able to get commercial chips to handle, then you might consider implementing a specialised processor inside an FPGA because at that point there will be very clear advantages that you hope to gain by 'rolling your own', and you can focus on just implementing those capabilities, with the right interfaces to rest of your design.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Otherwise, you're likely to get side-tracked from your main goal (which I'm going to assume is to actually build a robot!)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Bottom line: FPGAs are a distraction from getting started in robotics --- until you're quite a ways down the robotics road -- and have gained some strong chops in digital electronics / microprocessor design somewhere along the way.&lt;/strong&gt;&lt;/p&gt;&#xA;" OwnerUserId="1013" LastEditorUserId="1013" LastEditDate="2013-04-07T09:46:04.990" LastActivityDate="2013-04-07T09:46:04.990" CommentCount="2" />
  <row Id="1173" PostTypeId="2" ParentId="1153" CreationDate="2013-04-06T18:06:25.877" Score="1" Body="&lt;p&gt;Having worked with both FPGAs and Microcontrollers in robotics projects, I would actually say now: whatever the person implementing the task has the most experience with. If you know both equally well, you wouldn't be asking yourself the question. If you don't know either well, than these would be the points to go by:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Is there complex timing on I/O ports required? 3-Phase motor control can have such requirements. FPGAs have a slight advantage here.&lt;/li&gt;&#xA;&lt;li&gt;Can you parallelize your super low latency algorithm? Here the FPGA doesn't really compete with microcontrollers, but more with embedded PCs. Most things I would go for the embedded PC, but you may have an advantage with an FPGA for some specific applications. Dense stereo processing for example is often done in FPGAs. Lots of cameras use FPGAs for processing the data stream.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;What is also often used are hybrid solutions. Either with two chips, so one microcontroller for the program code, and an FPGA for IO or some other task. There also are a number of FPGAs that actually have a microcontroller embedded.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I wouldn't be so harsh on FPGAs like some other posts, but would also generally argue, that unless you know your VHDL well, you will be better off using microcontroller, or even better still embedded PCs.&lt;/p&gt;&#xA;" OwnerUserId="127" LastActivityDate="2013-04-06T18:06:25.877" CommentCount="1" />
  <row Id="1174" PostTypeId="1" CreationDate="2013-04-08T02:12:39.543" Score="2" ViewCount="48" Body="&lt;p&gt;See the video below of my balancing robot.&lt;br&gt;&#xA;&lt;a href=&quot;http://www.youtube.com/watch?v=Rjp8yoTVUcY&quot; rel=&quot;nofollow&quot;&gt;Balancing robot&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I was having trouble getting it to balance on hard surfaces but finally got it after playing with the PID gains a lot.  Previously it was balancing just fine on carpet.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I set the PID gains by just picking a Kp, then increasing Ki until the robot oscillated very badly and tried to smash it's self into the ground,  then increasing Kd until it was finally stable. Here's the gains I'm using in the video.&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;  Kp=20, Ki=4.5, Kd=45;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;It will sit in one spot balancing without any problem.  You can see in the video that it can even stop from falling after I give it a pretty good kick.  The problem is that it stops from falling over but then greatly overshoots the other direction.  In the video you can see when I give it just a small tap it runs the other way for a while before finally becoming stable again.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any suggestions on what to try next?&lt;/p&gt;&#xA;" OwnerUserId="529" LastActivityDate="2013-04-08T02:12:39.543" Title="PID tuning to make my balancing robot better" Tags="&lt;pid&gt;" CommentCount="3" ClosedDate="2013-04-08T15:34:20.337" />
  <row Id="1175" PostTypeId="1" CreationDate="2013-04-08T09:49:43.440" Score="1" ViewCount="139" Body="&lt;p&gt;In a quadrotor we need to change each motor's speed depends on its position in space. More frequency will result more stability ( I mean if we can change motor's speed 400 times per second instead of 100 times per second we may stabilize our UAV quadrotor far better ).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now my question targeting people who made a UAV quadrotor before or have any information about ESCs. I wanna know whats the minimum refresh rate for ESCs in a quadrotor to make it stable ? For example may an ESC with 50hz refresh rate enough for stabilizing quadrotor or not ? I'm asking this question because high speed ESCs are more expensive than lower speed ones.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have &lt;a href=&quot;http://www.emaxmodel.com/views.asp?hw_id=21&quot; rel=&quot;nofollow&quot;&gt;this one&lt;/a&gt;. May it work ?&lt;/p&gt;&#xA;" OwnerUserId="1137" LastEditorUserId="1137" LastEditDate="2013-04-08T13:53:47.473" LastActivityDate="2013-04-08T13:53:47.473" Title="Minimum speed controller refresh rate" Tags="&lt;quadrotor&gt;&lt;quadcopter&gt;&lt;esc&gt;" AnswerCount="1" CommentCount="6" ClosedDate="2013-04-15T11:43:32.973" />
  <row Id="1176" PostTypeId="2" ParentId="1175" CreationDate="2013-04-08T10:46:08.833" Score="0" Body="&lt;p&gt;In case you need to do such an analysis, you should build up a Simulink/xcos model and derive such an analysis from that rather than make assumptions about such things which may or may not be directly correlated.&lt;/p&gt;&#xA;" OwnerUserId="333" LastActivityDate="2013-04-08T10:46:08.833" />
  <row Id="1177" PostTypeId="2" ParentId="521" CreationDate="2013-04-08T11:05:25.210" Score="-1" Body="&lt;p&gt;I think your mistake is that you didn't change the a' for each DOF, that's why they look all the same.&lt;/p&gt;&#xA;" OwnerUserId="1138" LastActivityDate="2013-04-08T11:05:25.210" CommentCount="1" />
  <row Id="1178" PostTypeId="1" CreationDate="2013-04-08T14:37:25.750" Score="1" ViewCount="231" Body="&lt;p&gt;I need a microcontroller that can process minimum 2mb data per second.&#xA;How do I determine what processors will be able to do this?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also how can I calculate the processing speed in per second of any microcontroller?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am very much scared with my college project and I need help.&lt;/p&gt;&#xA;" OwnerUserId="1140" LastEditorUserId="350" LastEditDate="2013-04-08T15:20:42.263" LastActivityDate="2013-04-08T16:12:41.950" Title="How can I calculate processing speed of microcontroller" Tags="&lt;microcontroller&gt;" AnswerCount="1" CommentCount="6" />
  <row Id="1179" PostTypeId="2" ParentId="1178" CreationDate="2013-04-08T16:06:08.213" Score="3" Body="&lt;p&gt;You need to consult the specifications. There is absolutely no other way unless you buy the micro, code it and run tests.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So first, you need to define what exactly processing means. Best way to do it is to write the program that does the processing, in assembly. Let's take a hypothetical program in a hypothetical assembly:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;load R1, portA&#xA;add R1, R1, 1&#xA;store portB, R1&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;First thing you need to know is how many cycles it takes the microcontroller to execute this code. Again, you need to consult the data sheet of the micro. Hypothetical numbers:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Load takes 3 cycles&lt;/li&gt;&#xA;&lt;li&gt;Load from PortA adds 2 cycles overhead&lt;/li&gt;&#xA;&lt;li&gt;Add takes 1 cycle&lt;/li&gt;&#xA;&lt;li&gt;Store takes 2 cycles&lt;/li&gt;&#xA;&lt;li&gt;Store to PortB adds 4 cycles overhead&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;So you would know that for each piece of data you read (hypothetically, 1 byte) you need 12 cycles to process them, assuming the micro is stupid enough to not use pipelines, prefetching of any sort etc.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you read the specifications well, you will know get a good estimate of the speed of the micro for your task. In our hypothetical example, 1 byte per 12 cycles.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So to address your first question, how to know if the micro is good enough for your task, it's quite simple. You want &lt;code&gt;X&lt;/code&gt; bytes of data per second so it takes &lt;code&gt;12X&lt;/code&gt; cycles to do that. All you need to know is how many cycles per second the micro runs (let's say &lt;code&gt;Y&lt;/code&gt;). So if &lt;code&gt;Y &amp;gt; 12X&lt;/code&gt; you're good.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Your second question is also simple to answer. You already have the speed in terms of &quot;per cycle&quot;. To calculate the speed in terms of &quot;per second&quot;, you just multiply the per-cycle speed by cycles/second of the microcontroller (again, found in the data sheet). In our hypothetical example:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;speed (byte/cycle) = 1/12&#xA;speed (byte/second) = 1/12 * Y&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Once you define your task, so it would be clear how heavy the computation is, probably higher grade students or even vendors would be able to help you pick up a suitable micro.&lt;/p&gt;&#xA;" OwnerUserId="158" LastEditorUserId="158" LastEditDate="2013-04-08T16:12:41.950" LastActivityDate="2013-04-08T16:12:41.950" />
  <row Id="1180" PostTypeId="1" AcceptedAnswerId="1185" CreationDate="2013-04-08T23:18:35.460" Score="3" ViewCount="110" Body="&lt;p&gt;I read many sources about kalman filter, yet no about the other approach to filtering, where canonical parametrization instead of moments parametrization is used. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What is the difference?&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Other questions:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;Using IF I can forget KF,but have to remember that prediction is more complicated &lt;a href=&quot;http://en.wikipedia.org/wiki/Kalman_filter#Information_filter&quot; rel=&quot;nofollow&quot;&gt;link&lt;/a&gt; &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;How can I imagine uncertainty matrix turning into an ellipse? (generally I see, area is uncertainty, but I mean boundaries) &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Simple addition of information in IF was possible only under assumption that each sensor read a different object? (hence no association problem, which I posted &lt;a href=&quot;http://robotics.stackexchange.com/questions/1181/object-level-sensor-fusion-for-multiobject-tracking&quot;&gt;here&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="1012" LastEditorUserId="187" LastEditDate="2013-04-14T08:37:24.787" LastActivityDate="2013-04-16T15:54:47.827" Title="information filter instead of kalman filter approach" Tags="&lt;kalman-filter&gt;&lt;algorithm&gt;&lt;sensor-fusion&gt;" AnswerCount="1" CommentCount="2" />
  <row Id="1181" PostTypeId="1" AcceptedAnswerId="1186" CreationDate="2013-04-08T23:25:40.900" Score="4" ViewCount="90" Body="&lt;p&gt;I want to fuse objects coming from several sensors, with different (sometimes overlapping!) fields of view. Having object lists, how can I determine whether some objects observed by different sensors are in fact the same object? Only then I can truly write an algorithm to predict future state of such an object. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;From literature I read those 4 steps:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Plot to track association (first update tracks estimates and then associate by &quot;acceptance gate&quot; or by statistical approach PDAF or JPDAF)&lt;/li&gt;&#xA;&lt;li&gt;Track smoothing (lots of algorithms for generating new improved estimate, e.g.: EKF, UKF, PF)&lt;/li&gt;&#xA;&lt;li&gt;Track initiation (create new tracks from unassociated plots)&lt;/li&gt;&#xA;&lt;li&gt;Track maintenance (delete a track if was not associated for last M turns. also: predict those tracks that were associated, their new location based on previous heading and speed)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;So basically I am questioning point 1, acceptance gate. For a single sensor I can imagine it can be just a comparison of xy position of object and sensor measurement, velocity with heading eventually. My case is however, I have already ready object lists from each sensor in every cycle, there are some algorithms how to merge informations about an object collected by different sensors (great source is e.g. here: &lt;a href=&quot;http://www.mathworks.de/matlabcentral/fileexchange/37807-measurement-fusion-state-vector-fusion&quot; rel=&quot;nofollow&quot;&gt;http://www.mathworks.de/matlabcentral/fileexchange/37807-measurement-fusion-state-vector-fusion&lt;/a&gt;), but question is how to decide which objects should be fused, and which left as they were? Fields of view may overlap partly, not totally.&lt;/p&gt;&#xA;" OwnerUserId="1012" LastEditorUserId="1012" LastEditDate="2013-04-11T07:58:28.407" LastActivityDate="2013-04-11T07:58:28.407" Title="object level sensor fusion for multiobject tracking" Tags="&lt;kalman-filter&gt;&lt;algorithm&gt;&lt;sensor-fusion&gt;" AnswerCount="2" CommentCount="1" FavoriteCount="2" />
  <row Id="1182" PostTypeId="1" AcceptedAnswerId="1187" CreationDate="2013-04-09T12:52:45.160" Score="5" ViewCount="92" Body="&lt;p&gt;These days, one often hears of &lt;a href=&quot;http://en.wikipedia.org/wiki/Cyber-physical_system&quot; rel=&quot;nofollow&quot;&gt;cyber-physical systems&lt;/a&gt;. Reading on the subject, though, it is very unclear how those systems differ from distributed and/or embedded systems. Examples from Wikipedia itself only make them look more like traditional distributed systems. For example:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;A real-world example of such a system is the Distributed Robot Garden at MIT in which a team of robots tend a garden of tomato plants. This system combines distributed sensing (each plant is equipped with a sensor node monitoring its status), navigation, manipulation and wireless networking.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Obviously, &lt;em&gt;any&lt;/em&gt; distributed system consists of sensing, actuations (which can easily include navigation) and networking.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My question is, how exactly does cyber-physical systems differ from traditional distributed systems? Is it just a fancy name, or is there something considerably different with it?&lt;/p&gt;&#xA;" OwnerUserId="158" LastEditorUserId="131" LastEditDate="2013-04-10T14:19:25.597" LastActivityDate="2013-04-10T14:20:40.053" Title="Shedding light on &quot;cyber-physical systems&quot;" Tags="&lt;distributed-systems&gt;&lt;embedded-systems&gt;" AnswerCount="2" />
  <row Id="1183" PostTypeId="2" ParentId="1182" CreationDate="2013-04-09T19:06:01.423" Score="3" Body="&lt;p&gt;It's just a fancy (and awkward) name. Also known as robotics, cybernetics, embedded systems, control systems and so on. I'm guessing there is some dissatisfaction with either the implications or specificity of those other related categories:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Robotics - Makes people think of rovers and industrial material handling equipment.&lt;/li&gt;&#xA;&lt;li&gt;Embedded systems - Too unspecific, doesn't necessarily have much physical interaction with the world outside of buttons and displays. &lt;/li&gt;&#xA;&lt;li&gt;Control systems - Mostly is used to refer to deterministic and non-distributed control loops. More Z-transform, less AI.&lt;/li&gt;&#xA;&lt;li&gt;Cybernetics - probably the closest in meaning, but over time the cyber-x has come to mean things that are purely virtual (cyberspace, cybersecurity, etc) instead of the original control system meaning. Thus the need to tack on a somewhat redundant &quot;physical&quot; to remind people that this involves atoms and not just bits.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="223" LastActivityDate="2013-04-09T19:06:01.423" CommentCount="3" />
  <row Id="1184" PostTypeId="2" ParentId="1181" CreationDate="2013-04-09T20:46:36.033" Score="1" Body="&lt;p&gt;This depends on a lot of things.  What kind of sensors? Are they stationary? Are they at least fixed with respect to each other?  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, if you have a system of multiple cameras that are fixed with respect to each other, you can calibrate them, so that you know their relative positions and orientations.  Then not only will you be able to determine whether two detections in different cameras are the same object, but you will be able to determine its position in 3D.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here is the classic paper on &lt;a href=&quot;http://research.microsoft.com/en-us/um/people/zhang/papers/TR98-71.pdf&quot; rel=&quot;nofollow&quot;&gt;camera calibration&lt;/a&gt;. To actually do the calibration you can either use OpenCV or the &lt;a href=&quot;http://www.vision.caltech.edu/bouguetj/calib_doc/&quot; rel=&quot;nofollow&quot;&gt;Caltech Camera Calibration Toolbox for Matlab&lt;/a&gt;. OpenCV has an example application for camera calibration which is easier to use than the Caltech toolbox.&lt;/p&gt;&#xA;" OwnerUserId="1115" LastEditorUserId="1115" LastEditDate="2013-04-10T15:53:38.287" LastActivityDate="2013-04-10T15:53:38.287" CommentCount="4" />
  <row Id="1185" PostTypeId="2" ParentId="1180" CreationDate="2013-04-10T04:21:56.233" Score="5" Body="&lt;p&gt;They are exactly the same. Information matricies (aka precision matricies) are the inverse of covariance matricies. Follow &lt;a href=&quot;http://en.wikipedia.org/wiki/Kalman_filter&quot; rel=&quot;nofollow&quot;&gt;this&lt;/a&gt;. The covariance update $$P_{+} = (I-KH)P$$ can be expanded by the definition of $K$ to be&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$ P_{+} = P - KHP $$&#xA;$$ P_{+} = P - PH^T (HPH^T+R)^{-1} HP $$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now apply the &lt;a href=&quot;http://en.wikipedia.org/wiki/Woodbury_matrix_identity&quot; rel=&quot;nofollow&quot;&gt;matrix inversion lemma&lt;/a&gt;, and we have:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$ P_{+} = P - PH^T (HPH^T+R)^{-1} HP $$&#xA;$$ P_{+} = (P^{-1} + H^TR^{-1}H)^{-1} $$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Which implies:&#xA;$$ P_{+}^{-1} = P^{-1} + H^TR^{-1}H $$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The term $P^{-1}$ is called the prior information, $H^TR^{-1}H$ is the sensor information (inverse of sensor variance), and this gives us $P^{-1}_+$, which is the posterior information. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm glossing over the actual state estimate, but it's straightforward. The best intro I've seen on this is &lt;em&gt;not&lt;/em&gt; Thrun's book, but Ben Grocholsky's PhD thesis. (Just the intro material). It's called &lt;strong&gt;Information Theoretic Control of Multiple Sensor Platforms&lt;/strong&gt;. Here's a &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.58.5090&quot; rel=&quot;nofollow&quot;&gt;link&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;EDITS&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To answer the questions posed.&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;It is not more complicated to predict, it is more computationally costly, since you must invert the $n \times n$ covariance matrix to get the true state output. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;To view the ellipse from a covariance matrix, just note that the covariance matrix has a nice &lt;a href=&quot;http://en.wikipedia.org/wiki/Singular_value_decomposition&quot; rel=&quot;nofollow&quot;&gt;Singular Value Decomposition&lt;/a&gt;. The square root of the eigenvalues of the ellipse, or the square root of the singular values of the ellipse, will define the principal axes of the ellipse.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;No, addition of information depends only on the assumption of independence of measurement noise. If you want to use two information filters to track two objects, that's fine. Or if you want to use an IF to track two objects, that's also fine. All you need is the correct &lt;em&gt;association&lt;/em&gt; of measurements, so that you know which part of the state (object 1 or object 2) to update.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="163" LastEditorUserId="163" LastEditDate="2013-04-16T15:54:47.827" LastActivityDate="2013-04-16T15:54:47.827" CommentCount="3" />
  <row Id="1186" PostTypeId="2" ParentId="1181" CreationDate="2013-04-10T04:29:50.160" Score="3" Body="&lt;p&gt;This is called &quot;data association&quot; in tracking literature. When you measure the position of an object, you need to know which object it was you measured. If you can estimate this probability, then you are free to choose the most likely association. This is a heavily researched topic, but boils down to Bayesian analysis. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here's a simple way:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Assume we have two objects $o_1$ and $o_2$, an estimate of their position $x_1$ and $x_2$, and a measurement $z$. Suppose $z$ is just a position measurement. We'd like to update $o_1$ &lt;strong&gt;or&lt;/strong&gt; $o_2$'s estimated position, but we have no idea with object we just measured. So, we find the &lt;em&gt;most likely&lt;/em&gt; object, and update that.&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;Estimate $p(z|x_1)$ and $p(z|x_2)$. The Kalman filter gives you the tools to do this.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;IF $p(z|x_1)&amp;gt;p(z|x_2)$ AND $p(z|x_1)&amp;gt;\gamma$, then update $x_1$ using $z$, the Kalman filter gives you the tools to do this as well. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;ELSE IF $p(z|x_2)&amp;gt;p(z|x_1)$ AND $p(z|x_2)&amp;gt;\gamma$, then update $x_2$ using $z$, the Kalman filter gives you the tools to do this as well. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;ELSE, no probability is greater than $\gamma$, so we drop the measurement. You can set $\gamma$ to zero if you don't care. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Two things: First, you also need to know how to &lt;em&gt;initialize&lt;/em&gt; an object. That's why $\gamma$ is important. If the measurement doesn't &lt;em&gt;seem&lt;/em&gt; to match any known estimates, you might have just detected a new object.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Second, I have a suspicion that your question will be heavily edited, so I'm not putting a lot of details in just now.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;EDIT&lt;/strong&gt;&#xA;To address your newer, revised question:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You have a different problem, but it is totally related. First, you want to fuse objects. This is as simple as estimating the probability that all measurements of object 1 and all measurements of object 2 are in fact of the same object.  The algorithm is simple, but nearly intractable computationally. This is the same as track merger.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To really do this with objects in 3D, you need a model of the object which allows you to estimate the probability that two partially overlapping (or possibly just nearby) objects are in fact the same object). But this is exactly the same as the acceptance gate approach.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;note&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are only a few really useful ways to mere measurements, and they are well defined. I strongly suggest if you wish to continue with abstract tracking and estimation tasks that you read Bar-Shalom's &lt;a href=&quot;http://rads.stackoverflow.com/amzn/click/047141655X&quot; rel=&quot;nofollow&quot;&gt;Tracking and Estimation book&lt;/a&gt;. Please get it from a library if you can. I just don't know of a better reference.&lt;/p&gt;&#xA;" OwnerUserId="163" LastEditorUserId="163" LastEditDate="2013-04-10T14:13:15.793" LastActivityDate="2013-04-10T14:13:15.793" CommentCount="1" />
  <row Id="1187" PostTypeId="2" ParentId="1182" CreationDate="2013-04-10T12:48:54.290" Score="4" Body="&lt;p&gt;Reading through some of the articles linked to in the Wikipedia article, I'll respectfully disagree with &lt;a href=&quot;http://robotics.stackexchange.com/a/1183/37&quot;&gt;@Theran&lt;/a&gt;. The distinction seems quite well grounded, although Wikipedia does a poor job of making it. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The term &lt;em&gt;embedded systems&lt;/em&gt; (ES) has been around since the 60s and can, arguably, refer to anything from an airplane to a Furby. I think the term &lt;em&gt;cyber-physical systems&lt;/em&gt; (CPS) was coined to distinguish it from what are traditionally thought of as embedded systems, namely closed-loop, non-networked &quot;boxes&quot; that operate in a very well-defined and constrained domain with a limited power to affect physical systems. CPS, on the other hand, embody the idea of &lt;em&gt;think globally, act locally&lt;/em&gt; (my apologies to &lt;a href=&quot;https://en.wikipedia.org/wiki/Think_Globally,_Act_Locally#Origin_in_town_planning&quot; rel=&quot;nofollow&quot;&gt;Patrick Geddes&lt;/a&gt;), that is, they are usually highly networked systems that bring about change in a local physical system dependent on the state and actions of other entities in the wider network. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;While many robotic applications fit this definition, and can therefore be termed cyber-physical systems, many are not. What bestows the honour on MIT's robotic garden, I believe, is the fact that the robots form &lt;a href=&quot;https://www2.lirmm.fr/lirmm/interne/BIBLI/CDROM/ROB/2009/IROS_2009/papers/1119.pdf&quot; rel=&quot;nofollow&quot;&gt;part of a wider, decentralised system&lt;/a&gt; (PDF). It is the plants, equipped with sensors, that decide when to request watering or other services from the robots, while it is the robots that then decide between them which one will fulfil that request. Furthermore, not all CPS are thought of as &quot;robotic&quot;, for example, an intelligent power grid.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Cybernetics&quot; rel=&quot;nofollow&quot;&gt;Cybernetics&lt;/a&gt;, as @Theran has noted, is occupied with the study of control systems, and so will form a core part of studying CPS, but also has a broader range of applications in fields such as mathematics, economics, and sociology, for example.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This &lt;a href=&quot;http://www.eecs.berkeley.edu/Pubs/TechRpts/2008/EECS-2008-8.pdf&quot; rel=&quot;nofollow&quot;&gt;report on cyber-physical systems&lt;/a&gt; (PDF), by Edward Lee from UC Berkeley, makes clear that CPS are a next step in the evolution of embedded systems with many of the same constraints (real-time capabilities, reliability) plus a few extra ones (robustness, adaptability, intelligence, interconnectedness). As such, the field of CPS is, in parts, concerned with developing completely new approaches to hard- and software architecture. For example:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;But I believe that to realize its full potential, CPS systems will require fundamentally new technologies [...] One approach that is very much a bottom-up approach is to modify computer architectures to deliver precision timing [...] Complementing bottom-up approaches are top-down solutions that center on the concept of model-based design [...] In this approach, &quot;programs&quot; are replaced by &quot;models&quot; that represent system behaviors of interest. Software is synthesized from the models. &lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Lee's thoughts are echoed in this &lt;a href=&quot;http://www.jiafuwan.net/download/cyber_physical_systems.pdf&quot; rel=&quot;nofollow&quot;&gt;Embedded Computing column&lt;/a&gt; (PDF) by Wayne Wolf of Georgia Tech.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;After all, we've had computers attached to stuff for a long time. Why, you may ask, do we need a new term to describe what we've been doing for years? [...] We have a surprisingly small amount of theory to tell us how to design computer-based control systems. Cyber-physical systems theory attempts to correct this deficiency. [...] Cyber-physical systems actively engage with the real world in real time and expend real energy. This requires a new understanding of computing as a physical act—a big change for computing.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;I recommend reading both articles for a good view on how CPS are different from &quot;mere&quot; embedded systems. &lt;a href=&quot;http://cyberphysicalsystems.org&quot; rel=&quot;nofollow&quot;&gt;Cyberphysicalsystems.org&lt;/a&gt; has a concept map of CPS on their homepage that nicely illustrates many of the aspects involved in developing CPS. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;As for the origin of the term, none of the sources I found attributed it to anyone. Many papers defined it without attribution while clearly not being the first to use them. The term first crops up in the literature in &lt;a href=&quot;http://scholar.google.com/scholar?q=%22cyber-physical+systems%22&amp;amp;hl=en&amp;amp;as_sdt=0%2C5&amp;amp;as_ylo=&amp;amp;as_yhi=2006&quot; rel=&quot;nofollow&quot;&gt;2006&lt;/a&gt; but, by that time, the US National Science Foundation had already organised a &lt;a href=&quot;http://varma.ece.cmu.edu/cps/&quot; rel=&quot;nofollow&quot;&gt;Workshop on Cyber-Physical Systems&lt;/a&gt;, suggesting that the term was already in use by then.&lt;/p&gt;&#xA;" OwnerUserId="131" LastEditorUserId="37" LastEditDate="2013-04-10T14:20:40.053" LastActivityDate="2013-04-10T14:20:40.053" />
  <row Id="1188" PostTypeId="2" ParentId="908" CreationDate="2013-04-10T19:28:37.653" Score="5" Body="&lt;p&gt;It's a clever and attractive design, but it's mechanically weak.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The mating area between the screw and grooves is small, so the pitch angle of the threads isn't as much of a problem. The grooves on opposite sides are offset by half a thread so the screw has less of a tendency to tilt. Mechanical clearance and deformation of the parts is enough to compensate for the remaining geometric mismatch.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The screw will have a strong tendency to strip out the grooves when torqued. This is already a problem with threading into softer materials like aluminum; that's why they invented threaded inserts. It's even worse when only a small fraction of each thread carries any load. The grooves should only be considered suitable for light loading and gentle torquing. &lt;/p&gt;&#xA;" OwnerUserId="223" LastActivityDate="2013-04-10T19:28:37.653" CommentCount="1" />
  <row Id="1189" PostTypeId="2" ParentId="230" CreationDate="2013-04-10T22:36:09.943" Score="3" Body="&lt;p&gt;An experimental repository has just been populated with ROS Groovy packages for Raspbian (wheezy), instructions to use it can be found here:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.ros.org/wiki/groovy/Installation/Raspbian&quot; rel=&quot;nofollow&quot;&gt;http://www.ros.org/wiki/groovy/Installation/Raspbian&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The repository has 350+ packages and the core ROS packages can be installed in a matter of minutes on a fresh Raspbian install.&lt;/p&gt;&#xA;" OwnerUserId="1149" LastActivityDate="2013-04-10T22:36:09.943" />
  <row Id="1191" PostTypeId="2" ParentId="93" CreationDate="2013-04-12T18:29:49.010" Score="2" Body="&lt;p&gt;Sometimes they are called linear halls.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A company called Eltrol used to make drives for these. I used them in the past in combination with Anorad Linear motors. Nowadays they are still available from PeakServo.&#xA;The drives drive the linear (or sine) hall and receive the two halll signal (which are 120 degrees apart).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.peakservo.com/series-45-linear-hall-sine-servo-amplifier/&quot; rel=&quot;nofollow&quot;&gt;http://www.peakservo.com/series-45-linear-hall-sine-servo-amplifier/&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1157" LastActivityDate="2013-04-12T18:29:49.010" />
  <row Id="1192" PostTypeId="1" CreationDate="2013-04-13T02:28:07.487" Score="4" ViewCount="397" Body="&lt;p&gt;I'm planning on programming a prebuilt robot to solve a maze as fast as possible.  The robot has forward obstacle sensors (no side sensors) and 3-axis accelerometer.  I'm planning on using the wall following algorithm.  Is this the fastest possible algorithm?  Also, since there are no side sensors, the robot needs to continuously turn to check if there is a wall on its side, so is there a clever way to use the accelerometer and sensors?&lt;/p&gt;&#xA;" OwnerUserId="1159" LastActivityDate="2013-04-14T03:09:29.227" Title="Fastest maze algorithm for robot" Tags="&lt;mobile-robot&gt;" AnswerCount="2" CommentCount="5" />
  <row Id="1193" PostTypeId="2" ParentId="1192" CreationDate="2013-04-13T15:24:13.373" Score="1" Body="&lt;p&gt;You can't say much about solving a maze unless you are allowed to explore first, or know the maze before-hand. Otherwise, it is easy to build a maze that will take arbitrarily long to solve using wall-following, but which has a simple solution. See the following example.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/8fbnF.png&quot; alt=&quot;Oops! We followed the wrong wall&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In this case, it is faster &lt;em&gt;on average&lt;/em&gt; to just chose turns randomly. So maybe this is a tough problem that requires a little more thought.&#xA;In some contexts, an iterative-deepening approach isn't bad. Start your research there, and come back when you have specific questions.&lt;/p&gt;&#xA;" OwnerUserId="163" LastActivityDate="2013-04-13T15:24:13.373" CommentCount="2" />
  <row Id="1194" PostTypeId="2" ParentId="1192" CreationDate="2013-04-14T03:09:29.227" Score="1" Body="&lt;p&gt;The wall following algorithm will benefit more from sensors on a side. Since you follow the side until you find a gap then you turn into that gap. You could then use the accelerometer to sense a bump when you hit the wall in front. However not sure how you can determine that you are out of the maze (in case you need to do that). Just an idea...&lt;/p&gt;&#xA;" OwnerUserId="1161" LastActivityDate="2013-04-14T03:09:29.227" />
  <row Id="1195" PostTypeId="1" CreationDate="2013-04-15T23:42:00.593" Score="2" ViewCount="40" Body="&lt;p&gt;I am looking for A3 size poster of Mars Exploration Rover Spirit/Opportunity for robotic education. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;www.sunstartoys.com gives a little postcard-size of the MER along with its components on board when you buy the toy. But this is not large enough for classroom purpose.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Does anyone know where to buy A3 size poster of these MER for robotic education?&lt;/p&gt;&#xA;" OwnerUserId="1167" LastActivityDate="2013-04-15T23:42:00.593" Title="Where can I get A3 poster size of Mars Exploration Rover Spirit/Opportunity?" Tags="&lt;wheeled-robot&gt;" CommentCount="1" FavoriteCount="1" ClosedDate="2013-04-16T14:16:48.677" />
  <row Id="1197" PostTypeId="2" ParentId="1120" CreationDate="2013-04-17T16:54:29.547" Score="0" Body="&lt;p&gt;Just FYI since this is not about exactly the &lt;code&gt;IQ&lt;/code&gt; test and also this might be more suitable for computer science community, but Japanese researchers have started a project &quot;&lt;a href=&quot;http://blogs.wsj.com/japanrealtime/2012/09/12/can-a-robot-get-into-japans-most-prestigious-university/&quot; rel=&quot;nofollow&quot;&gt;Can a Robot Pass the University of Tokyo Entrance Exam?&lt;/a&gt;&quot; where by 2021 they aim to achieve the goal.&lt;/p&gt;&#xA;" OwnerUserId="60" LastActivityDate="2013-04-17T16:54:29.547" />
  <row Id="1198" PostTypeId="1" AcceptedAnswerId="1204" CreationDate="2013-04-17T17:06:16.400" Score="4" ViewCount="91" Body="&lt;p&gt;I'm a newbie in robotics, and I'm doing a project on dynamic Braille interface. Basically it's a 8*8 array of pins, which can be either totally up or down. How to use least motor as possible?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm thinking of using Arduino for easy interface with computer.&lt;/p&gt;&#xA;" OwnerUserId="1171" LastActivityDate="2013-04-18T23:18:49.453" Title="Dynamic braille interface" Tags="&lt;design&gt;" AnswerCount="1" CommentCount="3" />
  <row Id="1199" PostTypeId="2" ParentId="1145" CreationDate="2013-04-18T06:36:23.237" Score="3" Body="&lt;p&gt;There are all sorts of mechanisms for handling dry goods. If you want to do it on a small scale, look to industrial devices for inspiration, but consumer and retail devices for quick solutions. For example, there are quite a few cereal dispensers on on the market like &lt;a href=&quot;http://www.zevro.com/smartspace-dry-food-dispenser-single-canister/&quot; rel=&quot;nofollow&quot;&gt;this Zevro cereal dispenser&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/5tc5h.jpg&quot; alt=&quot;Zevro cereal dispenser&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Industrial systems often use augers to measure and move dry materials. I don't see why you couldn't build a small scale delivery device using &lt;a href=&quot;http://www.harborfreight.com/7-piece-auger-bit-set-68166.html&quot; rel=&quot;nofollow&quot;&gt;a cheap auger bit&lt;/a&gt; rotating inside a pipe sized to fit the bit:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/Otdae.jpg&quot; alt=&quot;auger bit set&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Dry goods are often measured by weight, so you might want to think about ways to weigh grains and similar materials. There are lots of cheap digital scales with a range of about 0-5kg and accurate down to a few grams. You could try to integrate one of those into your project directly, or cannibalize it for its load sensor, or even &lt;a href=&quot;http://forums.parallax.com/showthread.php/108049-Make-your-own-load-cell-%28force-sensor%29-from-stuff-you-already-have.&quot; rel=&quot;nofollow&quot;&gt;build your own load sensor&lt;/a&gt;. It'd be easy to put a small hopper on a scale to measure the material, use a simple gate to start and stop the flow of material into the hopper, and a solenoid to dump the hopper into a chute that delivers it for preparation.&lt;/p&gt;&#xA;" OwnerUserId="1174" LastActivityDate="2013-04-18T06:36:23.237" CommentCount="2" />
  <row Id="1200" PostTypeId="1" AcceptedAnswerId="1201" CreationDate="2013-04-18T08:17:48.590" Score="0" ViewCount="149" Body="&lt;p&gt;I am looking for a specific name of the wire used for the robotic arm movement control and where can I find some of this online. I want to control it using the micro controller so please suggest some good development kit.&lt;/p&gt;&#xA;" OwnerUserId="1176" LastActivityDate="2013-04-18T12:19:29.927" Title="What is the wire used for hand movement of robot called ? where can I find it online ?" Tags="&lt;microcontroller&gt;&lt;robotic-arm&gt;&lt;movement&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="1201" PostTypeId="2" ParentId="1200" CreationDate="2013-04-18T09:13:31.747" Score="5" Body="&lt;p&gt;If I understood correctly, you are referring to &lt;code&gt;robotic tendons&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/RyYGi.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is a lot of material on the subject if you search google.&lt;/p&gt;&#xA;" OwnerUserId="158" LastEditorUserId="158" LastEditDate="2013-04-18T12:19:29.927" LastActivityDate="2013-04-18T12:19:29.927" />
  <row Id="1202" PostTypeId="1" CreationDate="2013-04-18T10:21:39.047" Score="5" ViewCount="123" Body="&lt;p&gt;We have an air bearing for a planar xy motion. Today it consists of four pockets according to picture. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/dET39.png&quot; alt=&quot;Current design&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the current design there are no sealings around the peripheries of the pockets and we suspect that is the reason we get vibrations. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the current design we control the pressure, same for all for recesses. The flow is adjustable individually for each recess. In practice it is very hard to tune it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For the non recess surfaces we have used &lt;a href=&quot;http://www.tss.trelleborg.com/remotemedia/media/globalformastercontent/downloadsautomaticlycreatedbyscript/catalogs/turcite_b_slydway_gb_en.pdf&quot; rel=&quot;nofollow&quot;&gt;Slydway&lt;/a&gt; as we need to be able to operate it without pressure occasionally.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To try to solve the problem we plan to develop a prototype where we can try out the effect of using sealings around the periphery of the pockets. The idea is something like this:&#xA;&lt;img src=&quot;http://i.stack.imgur.com/7yKuf.png&quot; alt=&quot;Idea for new design&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Questions&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Is the idea with adding sealings good? (sanity check)&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Suggestions for sealings? (I'm thinking a porous material like felt or cigarette filter) &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Of course all suggestions are welcome.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Edit&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm going to try and add grooves around the recesses to evaquate the air that leaks. My thinking is that this will give us a more defined area under pressure.&lt;/p&gt;&#xA;" OwnerUserId="786" LastEditorUserId="786" LastEditDate="2013-04-19T08:21:04.887" LastActivityDate="2013-04-19T08:21:04.887" Title="Problem with vibrations in air bearing" Tags="&lt;linear-bearing&gt;" AnswerCount="1" CommentCount="0" />
  <row Id="1203" PostTypeId="2" ParentId="1202" CreationDate="2013-04-18T11:33:29.053" Score="3" Body="&lt;p&gt;Non of the commercial air bearings I've seen have attempted to &lt;em&gt;seal&lt;/em&gt; like this, so I think that your problems with vibration may lie elsewhere.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;The problems I have seen with air-bearing systems have been related to mechanical &lt;a href=&quot;http://forums.reprap.org/read.php?14,131155,131155&quot; rel=&quot;nofollow&quot;&gt;over constraint&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A high performance linear bearing stage I once worked on used six bearings like these:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.nelsonair.com/NA_prods_flatpad_fp.htm&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/gHOsJ.gif&quot; alt=&quot;Copyright of Nelson Air Corp assumed, Image used without permission but with attribution.&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Arranged in 3 pairs like this: &lt;code&gt;/\em_&lt;/code&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Where &lt;code&gt;/&lt;/code&gt;, &lt;code&gt;\&lt;/code&gt; &amp;amp; &lt;code&gt;_&lt;/code&gt; are a pair of bearings (side by side along the track), &lt;code&gt;e&lt;/code&gt; was the encoder strip and &lt;code&gt;m&lt;/code&gt; was a linear motor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The problem that we had was that no matter how we tuned the servo loop, if it was tightly tuned enough to get up to the speed and acceleration we needed (3m/s &amp;amp; 2g) then the system would often get into a &lt;a href=&quot;http://en.wikipedia.org/wiki/Limit_cycle&quot; rel=&quot;nofollow&quot;&gt;limit cycle&lt;/a&gt; (sometimes erroneously called &lt;a href=&quot;http://en.wikipedia.org/wiki/Resonance&quot; rel=&quot;nofollow&quot;&gt;resonance&lt;/a&gt;) when stopping (i.e. it would sit humming).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The way we solved this was to remove one of the air bearings on the &lt;code&gt;/&lt;/code&gt; row, relocating it to the middle:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;   Front view       Side&#xA;Unstable   Stable   view&#xA;  o o       o o      |o&#xA;   m         m       |m&#xA;   e         e       |e&#xA;  o o       o o      \o&#xA;  o o        o       /o&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;By removing the excess constraint, we appeared to remove the tendency for a perturbation in one air bearing to affect another bearing and then ripple through to the other bearings.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Depending on your typical direction of motion and the flatness of your surface, you may find that a three point bearing system may work better for your system:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.newwayairbearings.com/design/technical-resources/new-way-technical-reports/tech-report-2-vacuum-preloaded-x-y-stage&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/JzlXh.jpg&quot; alt=&quot;Copyright of New Way Air Bearings, Image used without permission but with attribution.&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You may also want to consider purchasing commercial air-bearing modules and attaching them to a frame (at least for a prototype) rather than attempting to manufacture your own air bearings. That way you can leverage the knowledge and support provided by the air-bearing manufacturer.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One other point is that we used ordinary &lt;a href=&quot;http://en.wikipedia.org/wiki/Polyimide&quot; rel=&quot;nofollow&quot;&gt;Polyimide&lt;/a&gt; tape on our air bearings. We considered various more permanent methods, but in the end decided that being able to easily remove old, scarred or scored tape and replace it with fresh tape quickly and easily made the most sense for our application.&lt;/p&gt;&#xA;" OwnerUserId="37" LastEditorUserId="37" LastEditDate="2013-04-18T11:59:44.950" LastActivityDate="2013-04-18T11:59:44.950" CommentCount="1" />
  <row Id="1204" PostTypeId="2" ParentId="1198" CreationDate="2013-04-18T23:18:49.453" Score="1" Body="&lt;p&gt;With a \$100-200 budget it's unlikely you can duplicate the functionality of a \$695 commercially-produced product.  Your device may be slower, bulkier, noisier, less reliable.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One possible approach is to use dot matrix printer print-heads to drive pins.  See example of pins being driven in a &lt;a href=&quot;http://vimeo.com/12648709&quot; rel=&quot;nofollow&quot;&gt;vimeo.com&lt;/a&gt; video called  “Dot Matrix Print Head - Testing”.  You might need to replace the pins with push wires so that you could go from a 3-by-9 pin layout to a 4-by-4 or 4-by-5 arrangement.  Some fairly old (and bulky) print-heads already contain push wires.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If the print-head pins are driven ballistically they might not be able to work with the high duty cycle that a Braille dot would require.  If you use push wires, you could have a cam that moves a latch plate back and forth, alternately latching wires in place or releasing them so they can move up or down.  Or you could have a cam that lifts all the  Braille pins at once, and a print head that drives some latch pins sideways to catch those Braille pins that that should remain up.  Another cam would clear all the latch pins at the beginning of each character cycle. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are miniature solenoids as shown below with roughly 1cm square cross-section, with a 1.5mm diameter pin that moves about 3mm.  (Listed on ebay as “Miniature Electric Solenoid - 9 V - Push Type - 2 oz. Force - 3 mm Stoke”, about \$7.)  The duty cycle of this solenoid is 10%, so like a ballistic print head it would require some latch mechanism, as well as a spring or gravity return.  You would need to attach push wires to the end of the shaft because the solenoids won't cluster closely enough.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/VvxM2.jpg&quot; alt=&quot;Miniature Electric Solenoid - 9 V - Push Type&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="478" LastActivityDate="2013-04-18T23:18:49.453" />
  <row Id="1205" PostTypeId="1" CreationDate="2013-04-19T03:42:53.730" Score="3" ViewCount="80" Body="&lt;p&gt;I would like to prevent a shaft from being pulled through it's bearings - that is, press a plastic ring around it on either side.  What are these rings called? They're not bearings or hubs.  And where can I find them?&lt;/p&gt;&#xA;" OwnerUserId="1183" LastActivityDate="2013-04-24T20:31:18.450" Title="Plastic shaft supports" Tags="&lt;mechanism&gt;" AnswerCount="2" />
  <row Id="1206" PostTypeId="2" ParentId="1205" CreationDate="2013-04-19T05:13:42.327" Score="3" Body="&lt;p&gt;Many shafts and spindles have shoulders (ie, a ring-shaped surface at the junction of different shaft diameters) turned on them to serve such a purpose.  If there is no diameter change in the shaft you are working with, &lt;em&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Shaft_collar&quot; rel=&quot;nofollow&quot;&gt;shaft collars&lt;/a&gt;&lt;/em&gt; sometimes are used to keep the shaft from sliding back and forth.  The wikipedia article mentions several kinds of collars.  &lt;a href=&quot;http://www.amazon.com/b?ie=UTF8&amp;amp;node=16411911&quot; rel=&quot;nofollow&quot;&gt;Amazon&lt;/a&gt; and &lt;a href=&quot;http://www.ebay.com/sch/i.html?_trksid=p2050601.m570.l1313.TR0.TRC0&amp;amp;_nkw=Shaft+collar&amp;amp;_sacat=0&amp;amp;_from=R40&quot; rel=&quot;nofollow&quot;&gt;Ebay&lt;/a&gt; sellers list quite a few medium to large sizes.  If the shaft you are working with is small-diameter, eg 1/16&quot;–3/16&quot;, then look for shaft collars among model airplane supplies.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm not aware of any suppliers of shaft collars made of plastic.  If you are referring to bushings or to grommets, they won't resist sliding unless they are fastened with a band clamp or a collet.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://www.google.com/search?q=shaft+grommet&amp;amp;hl=en&amp;amp;tbm=isch&amp;amp;tbo=u&amp;amp;source=univ&amp;amp;sa=X&amp;amp;ei=fsxwUbLpIOP5iwKqmoG4Cw&amp;amp;ved=0CDsQsAQ&amp;amp;biw=1052&amp;amp;bih=553#hl=en&amp;amp;tbm=isch&amp;amp;q=snap+ring&amp;amp;revid=1540968864&amp;amp;sa=X&amp;amp;ei=FtJwUePVEMKRiQKMqYCwAQ&amp;amp;ved=0CE8QgxY&amp;amp;bav=on.2,or.r_qf.&amp;amp;bvm=bv.45373924,d.cGE&amp;amp;fp=d610fbf3756a904e&amp;amp;biw=1052&amp;amp;bih=553&quot; rel=&quot;nofollow&quot;&gt;Snap rings&lt;/a&gt; also are used to keep shafts from sliding.  Snap rings fit into a thin shallow groove around the shaft.&lt;/p&gt;&#xA;" OwnerUserId="478" LastActivityDate="2013-04-19T05:13:42.327" />
  <row Id="1207" PostTypeId="1" CreationDate="2013-04-19T06:31:23.970" Score="2" ViewCount="1095" Body="&lt;p&gt;I have a 9 channel RF RX/TX and want to connect 3 motors to it.  I am able to connect channel 1 with motor 1 but unable to connect channel 2 with motor 2 simultaneously with arduino.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here is the code I am currently using:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;int motor1Left = 7;// defines pin 5 as connected to the motor&#xA;int motor1Right= 9;// defines pin 6 as connected to the motor&#xA;int motor2Left = 22;// defines pin 7 as connected to the motor&#xA;int motor2Right = 26;// defines pin 8 as connected to the motor&#xA;int enable = 5;&#xA;int enable2 = 10;&#xA;int channel1 = 2; // defines the channels that are connected&#xA;int channel2 = 3;// to pins 9 and 10 of arduino respectively&#xA;&#xA;int Channel1 ; // Used later to &#xA;int Channel2 ; // store values&#xA;&#xA;void  setup ()&#xA;{&#xA;  pinMode (motor1Left, OUTPUT);// initialises the motor pins&#xA;  pinMode (motor1Right, OUTPUT);&#xA;  pinMode (motor2Left, OUTPUT);&#xA;  pinMode (motor2Right, OUTPUT);// as outputs&#xA;  pinMode (channel1, INPUT);// initialises the channels&#xA;  pinMode (channel2, INPUT);// as inputs&#xA;&#xA;  Serial.begin (9600); // Sets the baud rate to 9600 bps&#xA;}&#xA;&#xA;void  loop ()&#xA;{&#xA;  Channel1 = (pulseIn (channel1, HIGH)); // Checks the value of channel1&#xA;  Serial.println (Channel1); //Prints the channels value on the serial monitor&#xA;  delay(1000);&#xA;&#xA;  Channel2 = (pulseIn (channel2, HIGH)); // Checks the value of channel1&#xA;  Serial.println (Channel2); //Prints the channels value value on the serial monitor&#xA;  delay(1000);&#xA;&#xA;  if (Channel1 &amp;gt; 1470 &amp;amp;&amp;amp; Channel1 &amp;lt; 1500) /*These are the values that I got from my transmitter, which you may customize according to your transmitter values */&#xA;  {&#xA;    digitalWrite (motor1Left, LOW); // Sets both the&#xA;    digitalWrite (motor1Right, LOW);// motors to low&#xA;    analogWrite(enable, 100);  &#xA;  }&#xA;&#xA;  if (Channel1 &amp;lt; 1460) // Checks if Channel1 is lesser than 1300&#xA;  {&#xA;    digitalWrite (motor1Left, HIGH);// Turns the left&#xA;    digitalWrite (motor1Right, LOW); // motor forward&#xA;    analogWrite(enable, 100);&#xA;  }&#xA;&#xA;  if (Channel1 &amp;gt; 1510) // Checks if Channel1 is greater than 1500&#xA;  {&#xA;    digitalWrite (motor1Left, LOW);// Turns the right&#xA;&#xA;    digitalWrite (motor1Right, HIGH);// motor forward&#xA;    analogWrite(enable, 70);&#xA;  }&#xA;&#xA;  if (Channel2 &amp;gt; 1480 &amp;amp;&amp;amp; Channel1 &amp;lt; 1500 )&#xA;  {&#xA;    digitalWrite (motor2Left, LOW);// Sets both the&#xA;    digitalWrite (motor2Right, LOW);// motors to low&#xA;    analogWrite (enable2, 100);&#xA;  }&#xA;&#xA;  if (Channel2 &amp;lt; 1300) // Checks if Channel2 is lesser than 1300&#xA;  {&#xA;    digitalWrite (motor2Left, LOW);// Turns the left&#xA;    digitalWrite (motor2Right, HIGH);// motor backward&#xA;    analogWrite (enable2, 100);&#xA;  }&#xA;&#xA;  if (Channel2 &amp;gt; 1500) // Checks if Channel2 is greater than 1500&#xA;  {&#xA;    digitalWrite (motor2Left, HIGH);// Turns the right&#xA;    digitalWrite (motor2Right, LOW);// motor backward&#xA;    analogWrite (enable2, 100);&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="1184" LastEditorUserId="478" LastEditDate="2013-04-20T23:39:48.617" LastActivityDate="2013-12-31T03:19:19.427" Title="Read Multiple Channels of RX-TX with arduino" Tags="&lt;arduino&gt;" AnswerCount="2" CommentCount="3" />
  <row Id="1208" PostTypeId="2" ParentId="519" CreationDate="2013-04-19T17:55:26.907" Score="4" Body="&lt;p&gt;I just see your post now and it is maybe too late to really help you...but in case you are still interested in this: I think that i identified your problem.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You write the innovation covariance matrix in the following way:&#xA;E=jacobian measure * P * jacobian measure '&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It might be alright in theory but what happens is that if your algorithm is effective and especially if you are working on a simulation : the uncertainties will decrease, especially in the directions of your measurement. So E will tend to [[0,0][0,0]].&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To avoid this problem what you can do is to add a measurement noise corresponding to the uncertainties in the measurement and your innovation covariance becomes:&#xA;E= Jac*P*Jac'+R&#xA;where are is the covariance of the measurement noise (diagonal matrix where the terms on diagonal are the squares of the standard deviation of the noise). If you actually don't want to consider noise you can make it as small as you want.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I also add that your covariance update seems strange to me the classical formula is:&#xA;P=P - K * jacobian measure * P&#xA;I never saw your formula written anywhere else, I might be correct but if you are not sure of it you should check it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I hope it helps&lt;/p&gt;&#xA;" OwnerUserId="1187" LastEditorUserId="1187" LastEditDate="2013-04-19T18:06:02.797" LastActivityDate="2013-04-19T18:06:02.797" CommentCount="1" />
  <row Id="1209" PostTypeId="1" CreationDate="2013-04-19T18:11:12.437" Score="6" ViewCount="1965" Body="&lt;p&gt;Today was my quadcopter's first &quot;flight&quot;. I'm running megapirate on a Crius AIOP v2 with a Turnigy Talon v2 frame.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I only touched the throttle stick on my remote, nothing else. When I felt the quadcopter was about to take off, I pushed the throttle just a little bit more, and the quadcopter oscillated 2 or 3 times and the just flipped over, landing on the propellers.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, I broke 2 props, my frame feels a bit loose, I'll probably have to tighten the screws (I hope...). How can I tune the software so it will stabilize nicely after take off?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Edit :&lt;br&gt;&#xA;I don't know if it was true oscillation or just random air flows making it unstable. I made some more tests yesterday and it was quite OK (even if I crashed a few times). This time, it was really oscillating but it was quite windy outside and the quadcopter managed to stabilize after all. So i'll probably have to tune my PIDs and find a way to do it without crashing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Edit 2 : After some PID tuning, I managed to stabilize my quadcopter pretty well but it's still oscillating just a little bit. I guess I'll have to slightly change the values to get a perfect stabilization.&lt;/p&gt;&#xA;" OwnerUserId="943" LastEditorUserId="943" LastEditDate="2013-04-23T09:24:27.643" LastActivityDate="2014-01-12T05:12:04.140" Title="How to stabilize a quadcopter" Tags="&lt;quadcopter&gt;&lt;stability&gt;" AnswerCount="2" CommentCount="7" FavoriteCount="3" />
  <row Id="1211" PostTypeId="1" AcceptedAnswerId="1213" CreationDate="2013-04-21T13:33:17.253" Score="7" ViewCount="247" Body="&lt;p&gt;I have a small device that's picking up small rocks from a pile and moving them to another place. Its a kind of crude way of trying to push the whole pile onto a bigger gear and hoping one of them are pushed to one of the spaces between gears and taken around and falls off on the other side of the spinning gear. Here i want to know if the machine successfully got a rock here, if not it should spin the gear until it turns up a single rock on the other side of it. If a rock is present at the spot, the gear should stop spinning until the rock is taken care of by the rest of the machine. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What kind of device can I use to sensor if I successfully succeeded in getting a rock on the other side of the gear? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/JEHag.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is just a part of a bigger system, to sum up, I need the sensor to signal when a rock is signalled out and separated from the rest so it can continue work on that single rock.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am building this using an ardiuno to move the gear around, so the sensor need to be something that can be controlled by an arduino&lt;/p&gt;&#xA;" OwnerUserId="689" LastEditorUserId="158" LastEditDate="2013-04-22T18:53:51.083" LastActivityDate="2013-05-15T14:29:41.487" Title="What kind of sensor do i need for knowing that something is placed at a position?" Tags="&lt;motor&gt;&lt;sensors&gt;" AnswerCount="4" CommentCount="1" FavoriteCount="1" />
  <row Id="1212" PostTypeId="2" ParentId="1211" CreationDate="2013-04-21T18:50:50.953" Score="2" Body="&lt;p&gt;Try an IR sender and receiver, facing each other, and the connection is obstructed by the rock.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/uO3Vi.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="583" LastEditorUserId="583" LastEditDate="2013-04-23T23:09:46.100" LastActivityDate="2013-04-23T23:09:46.100" CommentCount="4" />
  <row Id="1213" PostTypeId="2" ParentId="1211" CreationDate="2013-04-22T01:35:31.983" Score="5" Body="&lt;p&gt;There are numerous options that could/should work here.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As &lt;a href=&quot;http://robotics.stackexchange.com/a/1212/37&quot;&gt;mentioned by Elias&lt;/a&gt;, an IR sender/receiver is a good choice. This is similar to a &quot;break beam&quot; sensor. Essentially, when the beam of light between the transmitter and receiver is broken, the controller knows to do something about it. Similar to this would be an IR distance sensor, which records the distance from the sensor to an object by way of the angle of the light reflections. The problem with any sort of sensor based around light (such as IR) is that it can be &quot;corrupted&quot; easily by ambient light: the sun, light bulbs, camera flash, etc. The way to get around this is to pulse the light, only looking for light of a specific frequency (this is how IR TV remotes work). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Example sensors: &lt;a href=&quot;http://www.acroname.com/robotics/info/articles/sharp/sharp.html&quot; rel=&quot;nofollow&quot;&gt;http://www.acroname.com/robotics/info/articles/sharp/sharp.html&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are also things such as ultrasonic rangefinders which use sound instead of light:&#xA;&lt;a href=&quot;http://www.acroname.com/robotics/parts/R335-SRF06.html&quot; rel=&quot;nofollow&quot;&gt;http://www.acroname.com/robotics/parts/R335-SRF06.html&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;At the most complicated level, you could have a camera mounted that detects when a rock has been moved.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Alternatively, you could use a physical sensor to tell when a rock has been moved. This can be as simple as a push button platform - the button is pushed down when a rock is placed on top of it. Of course, this would only work if the rocks weighed enough to counteract the spring inside of a push button switch.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As far as the type of sensor that can be used: Arduino is based around an AVR microcontroller. Microcontrollers can be used with pretty much any kind of sensor you can imagine, although some may be too fast to be handled by the slower clock of an micro-controller versus a micro-processor or require more processing power than is available. &lt;/p&gt;&#xA;" OwnerUserId="1197" LastEditorUserId="37" LastEditDate="2013-04-23T09:27:03.460" LastActivityDate="2013-04-23T09:27:03.460" CommentCount="5" />
  <row Id="1214" PostTypeId="1" AcceptedAnswerId="1215" CreationDate="2013-04-22T12:04:46.710" Score="4" ViewCount="139" Body="&lt;p&gt;In order to build and operate a &lt;a href=&quot;http://en.wikipedia.org/wiki/Space_elevator&quot; rel=&quot;nofollow&quot;&gt;space elevator&lt;/a&gt; moving crafts and people into space, there are two big challenges that have not been solved yet:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Finding a cable with enough &lt;a href=&quot;http://simple.wikipedia.org/wiki/Tensile_strength&quot; rel=&quot;nofollow&quot;&gt;tensile strength&lt;/a&gt;,&lt;/li&gt;&#xA;&lt;li&gt;Moving stuff along the cable at a reasonnable speed.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Apart from those two ones, what are the other technical challenges to solve, especially things that do not exist yet in robotics, and need to be invented?&lt;/p&gt;&#xA;" OwnerUserId="1198" LastActivityDate="2013-04-23T07:48:36.200" Title="Space elevator: What is still needed, apart from the cable and propulsion?" Tags="&lt;mobile-robot&gt;&lt;research&gt;" AnswerCount="1" FavoriteCount="1" />
  <row Id="1215" PostTypeId="2" ParentId="1214" CreationDate="2013-04-22T15:55:21.807" Score="4" Body="&lt;p&gt;I don't think there would be parts not yet existent in robotics. The elevator itself is pretty much a cabin moving on a rail. It may not be built from off-the-shelf components, but building it shouldn't be difficult.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are other reasons however, some of which are mentioned in the same Wikipedia article you have linked to. So additional to &quot;not having cables strong enough&quot; and &quot;the slow speed&quot;:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Cable wear: The cable used for the elevator will be partially below the clouds (subject to &lt;strong&gt;warmth&lt;/strong&gt;, &lt;strong&gt;dry air&lt;/strong&gt;, &lt;strong&gt;rain&lt;/strong&gt;, &lt;strong&gt;snow&lt;/strong&gt;, &lt;strong&gt;wind&lt;/strong&gt;, &lt;strong&gt;tornadoes&lt;/strong&gt; etc), partially in and above clouds (&lt;strong&gt;Humid&lt;/strong&gt;, &lt;strong&gt;Cold&lt;/strong&gt;), partially in vacuum (&lt;strong&gt;extreme cold&lt;/strong&gt;, &lt;strong&gt;no air pressure&lt;/strong&gt;), sometimes in the sun (&lt;strong&gt;extremely hot&lt;/strong&gt; outside atmosphere), sometimes in the shade (&lt;strong&gt;near 0 degrees&lt;/strong&gt; outside atmosphere) etc. So any cable used for the elevator should be able to resist &lt;em&gt;all&lt;/em&gt; these environments.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The situation is made worse by considering the &lt;strong&gt;friction&lt;/strong&gt; between the &quot;wheels&quot; of the elevator and the track, &lt;strong&gt;chemical reactions&lt;/strong&gt; with the environment, &lt;strong&gt;radiation&lt;/strong&gt;, &lt;strong&gt;solar flares&lt;/strong&gt; and even &lt;strong&gt;biological&lt;/strong&gt; reasons (for example an eagle deciding he doesn't like the cable, or a sort of moss evolving to take advantage (aka eat) the material)&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;Cable repair: Sooner or later, the cable needs repair. There is no such thing as &quot;indestructible&quot;. Now imagine, how would you repair such a long cable? Surely, you can't just cut the bad parts and patch it, because the &quot;welded&quot; parts would probably not be strong enough. Replacing the whole cable would be an option which is quite expensive, given the special tough material and the long length. So, at least this issue would delay building the space elevator until they are sure it's doable.&lt;/li&gt;&#xA;&lt;li&gt;Safety of the elevator: One challenge is to be able to provide safety for the elevator. For example, how would you prevent asteroids from damaging it?&lt;/li&gt;&#xA;&lt;li&gt;Safety of the passengers: Another challenge is to provide safety for the passengers. With a slow speed, passing through the &lt;a href=&quot;http://en.wikipedia.org/wiki/Van_Allen_radiation_belts&quot; rel=&quot;nofollow&quot;&gt;Allen radiation belts&lt;/a&gt; is not healthy. This means that there should be adequate radiation shielding on the elevator, adding weight to it and making it harder to build.&lt;/li&gt;&#xA;&lt;li&gt;Safety of others: Yet another issue is providing safety for others, such as airplanes or space satellites. Most probably they would all need to become aware of the existence of this new concept, involving reprogramming a large number of air/space-crafts.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;In conclusion, probably the most important thing hindering the construction of the space elevator is the construction of the cable. Not only should it be strong enough to withhold the stress, but it should be practically able to withstand any kind of environment. Other reasons would be minor nuisance in comparison, but still they are and would further delay the deployment of the space elevator.&lt;/p&gt;&#xA;" OwnerUserId="158" LastEditorUserId="158" LastEditDate="2013-04-23T07:48:36.200" LastActivityDate="2013-04-23T07:48:36.200" CommentCount="7" />
  <row Id="1216" PostTypeId="2" ParentId="1209" CreationDate="2013-04-22T19:49:16.897" Score="10" Body="&lt;p&gt;The answer to the larger question here is that when running the initial test of any vehicle that has the capability to harm itself, it should be sufficiently restrained until you are satisfied that it can be kept under control.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the case of a quadcopter, this would involve tying a bit of string to the corners, leaving enough slack so that it can rise 6-12 inches, but not enough slack for it to flip over.&#xA;&lt;img src=&quot;http://www.globalaviationresource.com/reports/2010/harrierhistory/images/22.jpg&quot; alt=&quot;Harrier testing&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Once you do that, you'll be able to test and troubleshoot with impunity.  Being scared to run a test is the fastest way to run no tests and get nothing done.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you're suspicious of random air flows being to blame, you can try taking off from a wire mesh instead of a solid surface.  Try swapping the motor polarity on purpose, just to see how that affects the behavior.  Every experiment you can run in the controlled environment to understand the parameters of the system will help you troubleshoot more complicated control problems that arise later.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-04-22T19:49:16.897" CommentCount="2" />
  <row Id="1217" PostTypeId="2" ParentId="1211" CreationDate="2013-04-23T07:01:49.923" Score="2" Body="&lt;p&gt;I would put the whole conveyor belt on two axis, and:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Have the right axis as a pivot.&lt;/li&gt;&#xA;&lt;li&gt;Have the left part's axis rely on a switch button.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Because of the height between the spinning gear and the belt, the rock's impact will be powerful, making it easy to find a switch button that can detect it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It is very cheap and robust to dust/misplacement.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/4P5vC.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="1198" LastActivityDate="2013-04-23T07:01:49.923" />
  <row Id="1218" PostTypeId="1" AcceptedAnswerId="1245" CreationDate="2013-04-23T14:54:11.400" Score="2" ViewCount="237" Body="&lt;p&gt;This is part two of my larger robot, it follows up what happens with the small rocks here: &lt;a href=&quot;http://robotics.stackexchange.com/questions/1211/what-kind-of-sensor-do-i-need-for-knowing-that-something-is-placed-at-a-position&quot;&gt;What kind of sensor do i need for knowing that something is placed at a position?&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now i am taking the rocks down a tube for placement. In the case they need to be altered so they always will stand up before they enter the tube. Obvioulsy a rectangular rock wont fit if it comes in sideways. The dimensions here are pretty small. The rocks are about 15 mm x 10 mm. The tube i use is actually a plastic drinking straw. And the material i use for the rest of the robot is Lego powered by step motors which draw the conveyor belts to move the rocks. The control is Arduino.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/J5nzR.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(sorry for the lousy illustration, if you know a good paint program for mac like the one used to draw the picture in my other post, please tell me :-))&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The rocks will always enter one at a time and have as much time they need to be adjusted to fit and enter the tube so the fall down. The question is, how to ensure all rocks are turned the right way when they get to the straw. Im not sure if using Lego when building the robot is off topic here, but a solution involving lego is preferable. And it has to be controlled by an Arduino. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;General tips in how to split a complex task into subtasks robots can do is also good, is there any theory behind the most common sub tasks a job requires when designing multiple robots to do it?&lt;/p&gt;&#xA;" OwnerUserId="689" LastEditorUserId="350" LastEditDate="2013-04-28T19:42:38.863" LastActivityDate="2013-04-30T18:23:25.913" Title="How do I adjust objects on a conveyor belt into the proper orientation?" Tags="&lt;arduino&gt;&lt;motor&gt;&lt;microcontroller&gt;&lt;motion&gt;" AnswerCount="1" CommentCount="2" />
  <row Id="1219" PostTypeId="1" AcceptedAnswerId="1238" CreationDate="2013-04-23T15:56:36.040" Score="6" ViewCount="249" Body="&lt;p&gt;Imagine a &quot;drone&quot; and a target point on a 2d plane. Assuming the target is stationary, there are eight parameters:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;P = my position&#xA;Q = target's position&#xA;V = my velocity&#xA;I = my moment of inertia&#xA;w = my angular velocity&#xA;s = my angular position&#xA;T = max thrust&#xA;U = max torque&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;The drone's job is to get to the target as fast as possible, obeying max torque and max thrust. There are only two ways to apply the torque, since this is only in a 2d plane. Thrust is restricted to only go in one direction relative to the orientation of the craft, and cannot be aimed without rotating the drone. Neglect any resistance, you can just pretend it is floating around in 2d outer space. Let's say the drone checks an equation at time interval &lt;code&gt;t&lt;/code&gt; (maybe something like every .01 seconds), plugs in the parameters, and adjusts its torque and thrust accordingly.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;What should the equations for thrust and torque be?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h3&gt;What have we tried?&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;We know that the time it takes for the drone to reach the target in the x-direction has to be the same for the same time in the y-direction. There is going to have to be some integral over time in each dimension to account for the changing thrust based on total thrust, and total thrust in each direction given the changing angular position. I have no idea how to tie the torque and thrust together in a practical way where a function can just be called to give what thrust and torque should be applied over the interval &lt;code&gt;t&lt;/code&gt; unless there is some other technique.&lt;/p&gt;&#xA;" OwnerUserId="1204" LastEditorUserId="37" LastEditDate="2013-06-20T14:23:33.983" LastActivityDate="2013-06-20T14:23:33.983" Title="Drone targeting" Tags="&lt;design&gt;&lt;algorithm&gt;&lt;kinematics&gt;&lt;navigation&gt;" AnswerCount="2" CommentCount="3" />
  <row Id="1221" PostTypeId="1" AcceptedAnswerId="1239" CreationDate="2013-04-24T11:22:53.977" Score="6" ViewCount="244" Body="&lt;p&gt;We are using &lt;a href=&quot;http://code.google.com/p/ardu-imu/&quot; rel=&quot;nofollow&quot;&gt;ArduIMU (V3)&lt;/a&gt; as our Quadrotor's inertial measurement unit. (we have a separate board to control all motors, not with ArduIMU itself). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;As mentioned &lt;a href=&quot;http://code.google.com/p/ardu-imu/wiki/Output#Output_Rate&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt; , the output rate of this module is only at about 8hz. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Isn't it super slow to control a quadrotor ? I'm asking because as mentioned in &lt;a href=&quot;http://robotics.stackexchange.com/a/246/1137&quot;&gt;this answer&lt;/a&gt; a quadrotor needs at least 200hz of control frequency to easily stay in one spot, and our ESCs is configured to work with 450hz of refresh rate. Any working PID controller I saw before for Quadrotors used at least 200-400hz of control frequency.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I asked similar question before from Ahmad Byagowi (one of the developers of ArduIMU ) and he answered:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The arduimu calculates the dcm matrices and that makes it so slow. If&#xA;  you disable the dcm output, you can get up to 100 hz gyro, acc and so&#xA;  on.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;So, what will happen if I disable DCM from the firmware ? Is it really important ? We did a simulation before and our PID controller works pretty well without DCM.&lt;/p&gt;&#xA;" OwnerUserId="1137" LastEditorUserId="1137" LastEditDate="2013-04-27T06:59:51.280" LastActivityDate="2013-06-21T06:32:11.760" Title="Quadrotor control using ArduIMU" Tags="&lt;arduino&gt;&lt;quadrotor&gt;&lt;imu&gt;&lt;pid&gt;&lt;quadcopter&gt;" AnswerCount="1" />
  <row Id="1223" PostTypeId="2" ParentId="1205" CreationDate="2013-04-24T20:31:18.450" Score="2" Body="&lt;p&gt;Shafts can be constrained with e-clips, snap rings, shaft collars, set screws, spacers or threaded holes at the end of the shaft with washers.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;McMaster.com is usually a good place to look for different shaft collars and mechanisms, especially if you don't know the exact name.  They have an excellent picture reference and sorting feature for sizes and materials.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;My advice is to go with a &quot;clamp-on shaft collar&quot;.&lt;br&gt;&#xA;&lt;a href=&quot;http://www.mcmaster.com/#shaft-collars/=mgq5da&quot; rel=&quot;nofollow&quot;&gt;http://www.mcmaster.com/#shaft-collars/=mgq5da&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Clamp-on shaft collars typically do not leave marks and are easy to assemble compared to other shaft constraint methods.   E-clips and snap rings typically require the shaft to be modified to allow for the insert of the clip.  &quot;Set screw shaft collars&quot; will leave an indentation on the shaft from the screw.  &lt;/p&gt;&#xA;" OwnerUserId="68" LastActivityDate="2013-04-24T20:31:18.450" />
  <row Id="1227" PostTypeId="1" AcceptedAnswerId="1240" CreationDate="2013-04-25T17:21:33.500" Score="5" ViewCount="1700" Body="&lt;p&gt;I'm in the planning stages for a project using the Arduino Uno to control 8 distance sensors, and have run into a little road block, the Uno only has six input pins. So I'm wondering, is there any way for this to work? If so, how?&lt;/p&gt;&#xA;" OwnerUserId="498" LastActivityDate="2013-04-26T16:56:09.260" Title="Connecting More Than Six Analog Input Pins to arduino" Tags="&lt;arduino&gt;&lt;microcontroller&gt;&lt;input&gt;" AnswerCount="2" />
  <row Id="1228" PostTypeId="2" ParentId="1227" CreationDate="2013-04-25T17:34:59.623" Score="4" Body="&lt;p&gt;Whenever you have more signals than appropriate inputs in a digital system, you likely need a multiplexer or simply mux. An M-to-N mux is a circuit that enables you to select which of M input signals you want to output to N mux outputs, usually using digital pins to make that selection.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Googling quickly, I found this solution for the Arduino Uno: a &lt;a href=&quot;http://mayhewlabs.com/products/mux-shield-2&quot; rel=&quot;nofollow&quot;&gt;Mux Shield&lt;/a&gt;. Hope that helps!&lt;/p&gt;&#xA;" OwnerUserId="95" LastActivityDate="2013-04-25T17:34:59.623" CommentCount="1" />
  <row Id="1229" PostTypeId="1" CreationDate="2013-04-14T21:02:41.447" Score="4" ViewCount="652" Body="&lt;p&gt;I have a robot with two wheels/motors and each has a quadrature encoder for odometry.  Using the &lt;a href=&quot;http://www.pololu.com/catalog/product/1218&quot; rel=&quot;nofollow&quot;&gt;wheel/motor/encoder combo from Pololu&lt;/a&gt;, I get 48 transition changes per rotation and my motors give me a max of 400RPM.  I've found it seems to miss some of the encoder state changes with the &lt;a href=&quot;https://github.com/pololu/libpololu-avr/tree/master/src/PololuWheelEncoders&quot; rel=&quot;nofollow&quot;&gt;Pololu wheel encoder library&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Would I run into issues or limitations on my Arduino Uno using interrupts to track the quadrature encoders while using PWM to drive my motors through an H-bridge chip?  &lt;/p&gt;&#xA;" OwnerUserId="1148" OwnerDisplayName="Robert" LastEditorUserId="126" LastEditDate="2013-04-25T21:31:54.767" LastActivityDate="2013-07-08T05:03:09.690" Title="Limits of PWM, Timers and Interrupts?" Tags="&lt;arduino&gt;&lt;pwm&gt;&lt;encoding&gt;&lt;interrupts&gt;" AnswerCount="3" CommentCount="1" />
  <row Id="1230" PostTypeId="2" ParentId="1229" CreationDate="2013-04-14T22:54:57.107" Score="1" Body="&lt;p&gt;&lt;strong&gt;Yes you would: no current [Arduino] on the market (that I know of) can effectively track the state changes without missing a few state changes.&lt;/strong&gt; (Maybe the Due would be better or another board with a higher clock rate.) &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Interrupts can help a little, but:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I believe it stops &lt;em&gt;everything&lt;/em&gt; else on the chip; the motors might stop slightly when the interrupt is triggered.&lt;/li&gt;&#xA;&lt;li&gt;You may have problems if two interrupts fire at the same time&lt;/li&gt;&#xA;&lt;li&gt;After the code is processed, I believe I read it has a little delay before returning to what it was doing.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Interrupts are not the best solution for this problem, but that is the only thing you can do with modern technology. However, if you wanted to still wanted interrupts, you &lt;em&gt;could&lt;/em&gt; have another &lt;code&gt;ATmel328&lt;/code&gt; running on the breadboard, with interrupts, that when the main chip sends a message, it can send the number of turns for each wheel since it sent it last. I don't know how it would work when a interrupt is called, but maybe if you used a developed library, such as &lt;a href=&quot;http://arduino.cc/en/Reference/Wire&quot; rel=&quot;nofollow&quot;&gt;Arduino's Wire Library&lt;/a&gt;, it might fix the kinks when it is called.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Good luck.&lt;/p&gt;&#xA;" OwnerUserId="824" OwnerDisplayName="Annonomus Person" LastActivityDate="2013-04-14T22:54:57.107" CommentCount="5" />
  <row Id="1231" PostTypeId="2" ParentId="1229" CreationDate="2013-04-15T17:03:11.473" Score="1" Body="&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Interrupt_handler&quot; rel=&quot;nofollow&quot;&gt;Interrupt service routines&lt;/a&gt; should always do the &lt;strong&gt;absolute minimum&lt;/strong&gt;. Remember that while your MCU is servicing an interrupt, it is doing &lt;strong&gt;nothing else&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For a simple quadrature encoder, it should be possible to have a pair of ISR's, one triggered by a change on the A channel, the other triggered by a change on the B channel.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pretty much the only thing these ISRs should do is identify whether that change means the position variable should be incremented or decremented, then update the position and end the ISR and &lt;em&gt;possibly&lt;/em&gt; update a state transition time (if you are using this information to better estimate velocity&lt;sup&gt;&amp;dagger;&lt;/sup&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&amp;dagger;&lt;sub&gt; See &lt;a href=&quot;http://www.mate.tue.nl/mate/pdfs/10617.pdf&quot; rel=&quot;nofollow&quot;&gt;&lt;em&gt;Velocity and acceleration estimation for optical incremental encoders&lt;/em&gt; by R.J.E. Merry, M.J.G. van de Molengraft, M. Steinbuch&lt;/a&gt;&lt;/sub&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;With a pair of standard quadrature encoders, 48 transition changes per rotation and a maximum of 400RPM, your cross channel interrupts shouldn't be more frequent than 640 times a second, which should be well within the capability of a 16MHz processor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;An individual channel may produce more interrupts more frequently than that (for instance when the detector is sat on the edge) but missing those state changes does not have to affect the final position value, and there will always be a clear 1.5ms between that channel stabilising and the other channel activating.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, as long as you can service every A/B and B/A transition, it doesn't matter if you occasionally fail to process an A/A or B/B transition as long as the state of both A and B is taken into account at the next A/B or B/A transition.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note that if you don't need to calculate the time for your A-B and B-A transition (to calculate velocity more responsively with low resolution encoders) then you would probably be batter off having a fixed 640Hz/1.5ms timer based interrupt service routine that looks at both A and B channels, as suggested by &lt;a href=&quot;http://robotics.stackexchange.com/a/1536/37&quot;&gt;Tim Wescott&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="37" OwnerDisplayName="Mark Booth" LastEditorUserId="37" LastEditDate="2013-07-04T17:19:40.403" LastActivityDate="2013-07-04T17:19:40.403" />
  <row Id="1232" PostTypeId="1" CreationDate="2013-04-10T17:53:49.733" Score="10" ViewCount="1932" Body="&lt;p&gt;I would like to create an Arduino based robot with 2 wheels, quadrature encoders on each wheel, a H-bridge driver chip (or motor controller) and a caster.  I want to use the PID library to ensure the speed is proportional to the distance to travel.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;At a conceptual level, (assuming the motors do not respond identically to PWM levels) how can I implement the PID control so that it travels in a straight line and at a speed proportional to the distance left to travel? &lt;/p&gt;&#xA;" OwnerUserId="1148" OwnerDisplayName="Robert" LastEditorUserId="126" LastEditDate="2013-04-25T21:31:16.747" LastActivityDate="2013-08-06T14:49:02.063" Title="How can I use the Arduino PID library to drive a robot in a straight line?" Tags="&lt;arduino&gt;&lt;pid&gt;&lt;driver&gt;&lt;encoding&gt;" AnswerCount="2" CommentCount="1" FavoriteCount="1" />
  <row Id="1233" PostTypeId="2" ParentId="1232" CreationDate="2013-04-10T18:50:03.143" Score="1" Body="&lt;p&gt;If you're not using a single axle to drive both wheels, the only solutions I can see are to add either a 3-axis accelerometer or another sensor to detect the orientation of the robot, and adjust the signals to each motor accordingly.&lt;/p&gt;&#xA;" OwnerDisplayName="John" LastActivityDate="2013-04-10T18:50:03.143" />
  <row Id="1234" PostTypeId="2" ParentId="1232" CreationDate="2013-04-11T11:02:58.220" Score="9" Body="&lt;h1&gt;Specifics&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;Looking at the &lt;a href=&quot;http://playground.arduino.cc//Code/PIDLibaryBasicExample&quot; rel=&quot;nofollow&quot;&gt;PID Basic Example&lt;/a&gt; I think that you just need to instantiate two copies of PID controller, one for each wheel, encoder and pwm:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;PID leftPID(&amp;amp;InputLeft, &amp;amp;OutputLeft, &amp;amp;SetpointLeft,2,5,1, DIRECT);&#xA;PID rightPID(&amp;amp;InputRight, &amp;amp;OutputRight, &amp;amp;SetpointRight,2,5,1, DIRECT);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Then, in your &lt;code&gt;loop()&lt;/code&gt; equivalent, you just read both encoders, pass each encoder value to the relevant &lt;code&gt;PID&lt;/code&gt; and finally write out both PWM values.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For now &lt;code&gt;SetpointLeft&lt;/code&gt; and &lt;code&gt;SetpointRight&lt;/code&gt; can actually point at the same value, but defining them separately like this allows you to add the capability to turn later.&lt;/p&gt;&#xA;&#xA;&lt;h1&gt;Concepts&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;While this may work for the basic case, whether it is enough really depends on how accurate you need your straight line to be.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Dead_reckoning&quot; rel=&quot;nofollow&quot;&gt;Dead reckoning&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Given that you have encoders on each wheel, if you run two PID loops and compare each wheels' &lt;a href=&quot;http://www.answers.com/topic/following-error&quot; rel=&quot;nofollow&quot;&gt;following error&lt;/a&gt;, then you can potentially calculate your maximum &lt;a href=&quot;http://en.wikipedia.org/wiki/Abbe_error&quot; rel=&quot;nofollow&quot;&gt;abbe error&lt;/a&gt; over the distance, assuming your wheels don't slip. If that error is smaller than your requirements, then &lt;em&gt;dead reckoning&lt;/em&gt; is all you need.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If your wheels are prone to slipping however, then you may have hidden following error that your control system can't detect and you will need some way to detect a slip or calculate position independently of your wheel encoders and then use higher level software to correct demanded wheel positions/velocities to maintain a straight line.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Relative position determination&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;As &lt;a href=&quot;http://robotics.stackexchange.com/a/1233/37&quot;&gt;John suggests&lt;/a&gt;, you may be able to use an accelerometer to determine position, but given their accuracy and the effect of accumulated errors over time, you may be better off using the accelerometer data to detect and correct for wheel slippage.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In mobile robotics, &lt;a href=&quot;http://robotics.stackexchange.com/questions/tagged/kalman-filter&quot;&gt;Kalman filtering&lt;/a&gt; techniques are commonly used to fuse the data from multiple sources, such as an accelerometer and the wheel encoders to better determine current position.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Whatever you do with relative position determination however, over time the position you believe yourself to be in &lt;strong&gt;will&lt;/strong&gt; drift away from your actual physical position.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Absolute position determination&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;The only way to get around this is to have a reference point outside of your vehicles frame of reference.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A roomba for instance generally uses dead reckoning for moving around a room, but whenever it needs to dock, it looks for a beam of infra-red light sent out by the charging dock. As the roomba randomly moves through that beam, it detects it, locks onto the beam and follows it back to its source. In combination with it's bump sensors, it can position itself accurately on the charging contacts.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For your robot, it might have a home position, where it can move back to and detect that it is at that known location. At that point it knows exactly where it is and can report how far it's calculated position is from it's actual position.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another option, if you need your robot to travel in a straight line over hundreds of meters would be to switch to a different technique, such as adding an &lt;a href=&quot;https://www.sparkfun.com/products/10710&quot; rel=&quot;nofollow&quot;&gt;Arduino GPS shield&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;A combination of techniques&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Ultimately, depending on your accuracy requirements, you may need to use a combination of these techniques.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If a guide beam is possible, you may be able to do what you want very simply with an invisible &lt;a href=&quot;http://robotics.stackexchange.com/a/1527/37&quot;&gt;line following technique&lt;/a&gt;. If you need to move in any arbitrary straight line in an constrained area, then like the roomba you may be able to use a pair of guide beams (at right angles to each other) to allow you to correct your synthesised position in one Cartesian axis every time the robot passes one of the beams.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are lots of options here, and what you chose will depend on what you need.&lt;/p&gt;&#xA;" OwnerUserId="37" OwnerDisplayName="Mark Booth" LastEditorUserId="37" LastEditDate="2013-08-06T14:49:02.063" LastActivityDate="2013-08-06T14:49:02.063" />
  <row Id="1235" PostTypeId="1" AcceptedAnswerId="1241" CreationDate="2013-04-25T22:40:55.590" Score="6" ViewCount="420" Body="&lt;p&gt;How does rocker-bogie mechanism keep the body flat / keep the solar panel almost flat all the time? I know there is an differential system that connect both rocker bogie (left and right) together. But how does it actually work?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;Edited:&lt;/em&gt;&lt;/strong&gt; Please provide relevant references.&lt;/p&gt;&#xA;" OwnerUserId="1167" LastEditorUserId="1167" LastEditDate="2013-04-26T04:08:10.413" LastActivityDate="2013-10-01T21:52:42.430" Title="How does rocker bogie keep the body almost flat?" Tags="&lt;wheeled-robot&gt;" AnswerCount="1" FavoriteCount="1" />
  <row Id="1238" PostTypeId="2" ParentId="1219" CreationDate="2013-04-26T05:41:29.560" Score="4" Body="&lt;p&gt;You need to do a bit of Calculus.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;First a note about your input parameters:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Actually acceleration depends on Force and mass. You don't specify what units your max. thrust is in so let's assume your max. thrust &lt;em&gt;is&lt;/em&gt; your acceleration. We can do the same thing with your max. torque then and assume that it is also your acceleration (angular) and forget about moment of inertia. Actually you would divide torque by moment of inertia to get your angular acceleration, &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So you can simplify by giving your drone two static properties:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt; thrust as max acceleration&#xA; and torque as max angular acceleration&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;instead of giving it four properties&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;Force and mass&#xA;and Torque and MoI.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;And now crunch the numbers:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now you have your drone's Position: Px, Py, S -- it's first derivative, velocity: Vx, Vy, W -- and it's second derivative, acceleration: Ax, Ay, U&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Actually Ax, Ay will be calculated from S (angular position) and T (acceleration) by:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;Ax = T ×  cos(S)&#xA;Ay = T × -sin(S)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;That should get you a good way towards generating your formulas. Now you want to project a line from P that intersects Q in the least amount of time. Of course, it'll be a curve, not a straight line, so you'll have to use Calculus.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;You could try asking the same question on &lt;a href=&quot;http://math.stackexchange.com&quot;&gt;math.stackexchange.com&lt;/a&gt; for specific formulas.&lt;/p&gt;&#xA;" OwnerUserId="1075" LastEditorUserId="1075" LastEditDate="2013-04-26T21:19:34.767" LastActivityDate="2013-04-26T21:19:34.767" />
  <row Id="1239" PostTypeId="2" ParentId="1221" CreationDate="2013-04-26T13:25:38.780" Score="4" Body="&lt;p&gt;I updated ArduIMU's firmware and successfully got 100hz of output without disabling normalization.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks to Kalman filter firmware of ArduIMU I got up to 180hz of output plus removing all noises.&lt;/p&gt;&#xA;" OwnerUserId="1137" LastEditorUserId="1137" LastEditDate="2013-06-21T06:32:11.760" LastActivityDate="2013-06-21T06:32:11.760" />
  <row Id="1240" PostTypeId="2" ParentId="1227" CreationDate="2013-04-26T16:56:09.260" Score="4" Body="&lt;p&gt;There's more than one way to do it (&lt;a href=&quot;http://en.wikipedia.org/wiki/There%27s_more_than_one_way_to_do_it&quot; rel=&quot;nofollow&quot;&gt;TMTOWTDI&lt;/a&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are a several ways to connect 8 analog inputs to an Arduino.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Add an analog multiplexer, as georgebrindeiro suggested. Such as: &lt;a href=&quot;http://shieldlist.org/appliedplatonics/analoginput&quot; rel=&quot;nofollow&quot;&gt;(a)&lt;/a&gt;, &lt;a href=&quot;http://shieldlist.org/mayhewlabs/mux&quot; rel=&quot;nofollow&quot;&gt;(b)&lt;/a&gt;, &lt;a href=&quot;http://shieldlist.org/criticalvelocity/monstermux&quot; rel=&quot;nofollow&quot;&gt;(c)&lt;/a&gt;, &lt;a href=&quot;http://blueberryde.com/shop/24-channel-analog-expander-shield/&quot; rel=&quot;nofollow&quot;&gt;(d)&lt;/a&gt;, etc.&lt;/li&gt;&#xA;&lt;li&gt;Replace the Arduino with one that has enough analog inputs already built-in. Such as the Arduino Mini with 8 analog inputs, the Arduino Due with 12 analog inputs &lt;a href=&quot;http://arduino.cc/en/Main/ArduinoBoardDue&quot; rel=&quot;nofollow&quot;&gt;(b)&lt;/a&gt;, &lt;a href=&quot;http://arduino.cc/en/Main/ArduinoBoardMini&quot; rel=&quot;nofollow&quot;&gt;(a)&lt;/a&gt; the Arduino Mega with 16 analog inputs &lt;a href=&quot;http://arduino.cc/en/Main/arduinoBoardMega&quot; rel=&quot;nofollow&quot;&gt;(b)&lt;/a&gt;, the Teensy 3.0 with 14 analog inputs &lt;a href=&quot;http://forum.jeelabs.net/node/1429.html&quot; rel=&quot;nofollow&quot;&gt;(c)&lt;/a&gt;, etc.&lt;/li&gt;&#xA;&lt;li&gt;Add one or more external ADCs, and connect it to digital pins of your CPU. Such as: Arduino 4-20mA Shield with 16-bit ADC &lt;a href=&quot;http://erdosmiller.com/products/arduino-4-20ma-shield&quot; rel=&quot;nofollow&quot;&gt;(a)&lt;/a&gt;; ADS1115 16-Bit ADC -- with 4 of these boards, 2 digital pins from the Arduino are used to read 16 analog inputs &lt;a href=&quot;http://learn.adafruit.com/adafruit-4-channel-adc-breakouts&quot; rel=&quot;nofollow&quot;&gt;(b)&lt;/a&gt;; MCP3208 8 channel 12 bit SPI ADC &lt;a href=&quot;http://arduino.cc/forum/index.php/topic,18827.0.html&quot; rel=&quot;nofollow&quot;&gt;(c)&lt;/a&gt;; 8-channel 16-bit Raspi analog board &lt;a href=&quot;http://hackaday.com/2012/09/14/a-truly-professional-raspi-analog-input/&quot; rel=&quot;nofollow&quot;&gt;(d)&lt;/a&gt;; Arduino and the LTC2440 24bit ADC &lt;a href=&quot;http://blog.arduino.cc/2012/07/11/arduino-and-the-ltc2440-24bit-adc/&quot; rel=&quot;nofollow&quot;&gt;(e)&lt;/a&gt; &lt;a href=&quot;http://blog.arduino.cc/2010/11/29/tired-of-a-10-bit-res-hook-up-a-better-analog-to-digital-converter/&quot; rel=&quot;nofollow&quot;&gt;(f)&lt;/a&gt;; &quot;The Brick&quot; 8 Single Ended 16 Bit Analog Inputs &lt;a href=&quot;http://arduino.cc/forum/index.php?topic=69358.0&quot; rel=&quot;nofollow&quot;&gt;(g)&lt;/a&gt;; etc.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;p.s.: Multiplexing analog inputs requires an &quot;analog multiplexer&quot; -- most multiplexers are &quot;digital muxes&quot; which won't work with analog inputs.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;p.p.s.:&#xA;All the ultrasonic distance sensors I've used only require digital I/O pins.&#xA;What kind of distance sensors are you using?&lt;/p&gt;&#xA;" OwnerUserId="187" LastActivityDate="2013-04-26T16:56:09.260" CommentCount="1" />
  <row Id="1241" PostTypeId="2" ParentId="1235" CreationDate="2013-04-26T21:01:48.730" Score="9" Body="&lt;p&gt;I was looking for something similar, and I found &lt;a href=&quot;http://www.alicesastroinfo.com/2012/07/mars-rover-rocker-bogie-differential/&quot; rel=&quot;nofollow&quot;&gt;Mars Rover Rocker-Bogie Differential&lt;/a&gt; to be really helpful.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;With my level of understanding it took me a while. But the link my professor provided me with really helped me, it has decent animations to help understanding the concept. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Okay so here's my understanding of the mechanism. &#xA;The differential system essentially could consist of either of these two mechanisms:&#xA;The Differential Gearbox and the Differential Bar.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The differential Gearbox consists of three gears. The one in the middle (2) is connected to the body, while the ones on the side (1) rockers of the system.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/sZMdI.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you were to pick the rocker bogie up and hold the body intact, and tilt one of the side rocker downwards, the gears in the gearbox would make the rocker on the other side tilt upward. If you tilt it upwards, the other one would tilt it downwards. More complex system use more gears to make the whole system more sensitive to the movements.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As for the Differential bar, it's not used on the rover as it interferes with the solar panel, but it works in a similar way. Except its rod that connects the two rockers. And this rod is pivoted in the middle onto the body. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, as far as my understanding goes, look at the picture and consider the gears on either side (Gears numbered 1). If one of the gear(let's say the top one) is turning clockwise, it would make Gear no. 2 (which sits in the grove of both of the other gears.) move anti-clockwise. Which in turn would make the other No.1 Gear turn anti-clock wise.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; ALL THE GEARS FIT INTO THE GROOVE OF EACH OTHER. So any rotation that takes place in this system affects the other two gears. And the gears are attached or arranged in such a way that No.1's are running in the opposite direction of each other. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/icHbj.jpg&quot; alt=&quot;Here's the differential Bar on Curiosity&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here you can see the differential Bar on Curiosity.&lt;/p&gt;&#xA;" OwnerUserId="1213" LastEditorUserId="1106" LastEditDate="2013-10-01T21:52:42.430" LastActivityDate="2013-10-01T21:52:42.430" CommentCount="7" />
  <row Id="1245" PostTypeId="2" ParentId="1218" CreationDate="2013-04-28T19:52:52.320" Score="4" Body="&lt;p&gt;One way to do this is complicated, involving computer vision and a robot arm or other manipulator that can directly affect the orientation of each rock.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The low-tech way to do it would be to use a separate conveyor that gave you one rock at a time, and use walls to funnel it into a gate that matches the internal dimensions of the straw.  You would then just detect when the rock begins to push on the funnel walls (instead of travelling through) and knock it backwards to try again.  After a few tries, it should end up in the proper orientation (or you can give up and reject it at that point).  An even simpler way would be to skip the detection and just oscillate the funnel continuously, which would be safe if you're assured that each rock is guaranteed to have a working orientation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It's similar to &lt;a href=&quot;http://www.faqs.org/patents/app/20130075226&quot; rel=&quot;nofollow&quot;&gt;this patent&lt;/a&gt; which suggests a single wall, with the other side being open for improperly-aligned objects to fall off the belt.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-04-30T18:23:25.913" LastActivityDate="2013-04-30T18:23:25.913" />
  <row Id="1246" PostTypeId="1" AcceptedAnswerId="1247" CreationDate="2013-04-29T04:41:07.797" Score="4" ViewCount="1000" Body="&lt;p&gt;So I have a quadrocopter, it does come with a remote but I intend to run certain modifications to the copter, like installing a camera, a mechanical manipulator, and other random modifications. The remote that comes with the copter isn't flexible enough to help with such functions and plus it lacks any more buttons. I was wondering if I could somehow program the quadrocopter to respond to my Xbox controller. I was planning on using my laptop's Bluetooth connection to talk to copter. The Xbox controller which is connected to the computer would be then used to control the quadrocopter. So my question is, how exactly do I program the controller? How do I go about making all of this possible? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I understand this question is really vague and that there are too many options out there, but I do need help figuring this out. &lt;/p&gt;&#xA;" OwnerUserId="1213" LastEditorUserId="1213" LastEditDate="2013-04-29T06:19:11.237" LastActivityDate="2013-09-05T19:47:06.317" Title="Using an Xbox controller to fly a Quadrocopter" Tags="&lt;quadcopter&gt;" AnswerCount="3" CommentCount="2" />
  <row Id="1247" PostTypeId="2" ParentId="1246" CreationDate="2013-04-29T05:55:19.303" Score="5" Body="&lt;p&gt;Yes, in general this idea is perfectly plausible. However the method is going to be specific to your setup. I.e. the operating system you are using on your control computer and the onboard controller that you are employing. In our lab we use an &lt;a href=&quot;http://store.diydrones.com/ArduPilot_Mega_kit_p/kt-apm-01.htm&quot;&gt;Ardupilot Mega&lt;/a&gt; as our onboard controller for some of our quadrotors. To solve this problem I used the &lt;a href=&quot;https://www.kernel.org/doc/Documentation/input/joystick-api.txt&quot;&gt;Linux joystick API&lt;/a&gt; to acquire the data from the Xbox controller (or a PS3 controller for that matter). I can then send this data to an Arduino that I have used to replace the RC receiver or I can send it directly to the Ardupilot via Xbee using the &lt;a href=&quot;http://qgroundcontrol.org/mavlink/start&quot;&gt;Mavlink protocol&lt;/a&gt;. If you can provide more detail about your setup then I may be able to provide a more detailed response.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-04-29T05:55:19.303" />
  <row Id="1248" PostTypeId="2" ParentId="1246" CreationDate="2013-04-29T13:24:20.040" Score="3" Body="&lt;p&gt;This is easy actually!&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;(ROS + Joy package) -- &lt;a href=&quot;http://www.ros.org&quot; rel=&quot;nofollow&quot;&gt;http://www.ros.org&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Xbee (as mentioned by @DaemonMaker)&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;A simple program that takes the joy_node publications and sends them out over xbee. This could be as simple as 'rostopic echo /joy &gt;&gt; /dev/ttyS0' or such, depending on how much control you have over the receiving end.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Note: We use playstation controllers on all our robots. Highly recommended.&lt;/p&gt;&#xA;" OwnerUserId="163" LastActivityDate="2013-04-29T13:24:20.040" />
  <row Id="1249" PostTypeId="1" CreationDate="2013-04-29T13:26:58.007" Score="3" ViewCount="199" Body="&lt;p&gt;Expanding upon the title, I am querying the use of robotic skeletons to augment human strength and speed. If such a robot had the capacity for example to bear weight 5 times heavier than the wearer and move its robotic limbs twice as fast as the wearer, is there not a danger because such powerful and sharp movements could break their bones and seriously injure them because it moves beyond their human capabilities?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The robots means of producing movement I would think is important here but unsure how so. The nature of passive or actively powered movement and when each mode is used will also determine performance of the exoskeleton. I am not well versed in this area so will appreciate any feedback.&lt;/p&gt;&#xA;" OwnerUserId="1233" LastEditorUserId="158" LastEditDate="2013-04-29T17:00:50.897" LastActivityDate="2013-04-29T17:15:03.000" Title="Would the strength and speed of a robot skeleton be a danger to its wearer?" Tags="&lt;mobile-robot&gt;" AnswerCount="1" CommentCount="2" FavoriteCount="1" />
  <row Id="1250" PostTypeId="2" ParentId="1249" CreationDate="2013-04-29T17:15:03.000" Score="6" Body="&lt;p&gt;&lt;strong&gt;Yes&lt;/strong&gt;, an exoskeleton would definitely be a danger to its wearer, &lt;strong&gt;if it were not properly controlled&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In science fiction this problem is solved by the system requiring the human wearer to bear some of the weight themselves. Thus the 5x multiplier would still require the wearer of the exoskeleton to exert their full effort to lift the 1/5 of the weight themselves.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Similarly, the user would only be able to move more quickly because it is less effort to move a light weight than a heavy one, so in this case the exoskeleton is reducing the apparent weight to allow it to be moved more quickly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any control system which allowed the wearer of the exoskeleton to be injured through normal use of the exoskeleton would not be considered safe and would require the control system to undergo another risk assessment and the problems with the control system to be removed.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Incidentally, this is no different to a robot being strong enough to damage itself. I once worked on a robot which was more than capable of ripping straight through the protective cage which surrounded it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The cage was not there to protect humans outside of the cage from an &lt;em&gt;out of control robot&lt;/em&gt;, as this was considered a very low risk. It was primarily to prevent humans getting into the working envelope of a properly controlled robot, because &lt;em&gt;out of control humans&lt;/em&gt; were considered a &lt;strong&gt;much greater risk&lt;/strong&gt; (mostly to themselves *8').&lt;/p&gt;&#xA;" OwnerUserId="37" LastActivityDate="2013-04-29T17:15:03.000" CommentCount="3" />
  <row Id="1251" PostTypeId="2" ParentId="1246" CreationDate="2013-04-29T19:40:02.837" Score="3" Body="&lt;p&gt;Xbox and PS3 controllers are very versatile, it is true, but don't forget about range. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Bluetooth was only intended for short range operations out to about 10m (33ft.) for class 2 devices (xbox and ps3 controllers have class 2 transmitters) and 100m(330ft) for class 1 devices. Flying devices could most certainly go beyond that very quickly and you will risk losing control.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You're better off using an RC radio. Even though they use the same part of the RF spectrum (2.4GHz), RC radios typically have more power and are good for a couple of miles in good weather. You &lt;strong&gt;can&lt;/strong&gt; get RC controllers with 8 channels and more, thereby offering greater flexibility of number of controlled devices.&lt;/p&gt;&#xA;" OwnerUserId="1075" LastEditorUserId="1075" LastEditDate="2013-09-05T19:47:06.317" LastActivityDate="2013-09-05T19:47:06.317" />
  <row Id="1253" PostTypeId="1" AcceptedAnswerId="1254" CreationDate="2013-04-30T11:34:27.403" Score="3" ViewCount="100" Body="&lt;p&gt;While doing a literature review of mobile robots in general and mobile hexapods in particular I came across a control system defined as &quot;Task level open loop&quot; and &quot;Joint level closed loop&quot; system.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The present prototype robot has no external sensors by&#xA;  which its body state may be estimated. Thus, in our simulations and experiments, we have used joint space closed&#xA;  loop (“proprioceptive”) but task space open loop control&#xA;  strategies.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;The relevant paper is &lt;a href=&quot;http://ai.eecs.umich.edu/RHex/Papers/ijrr2001.pdf&quot; rel=&quot;nofollow&quot;&gt;A simple and highly mobile hexapod&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What is the meaning of the terms &quot;joint-level&quot; and &quot;task-level&quot; in the context of the Rhex hexapod?&lt;/p&gt;&#xA;" OwnerUserId="333" LastEditorUserId="350" LastEditDate="2013-04-30T18:09:05.557" LastActivityDate="2013-04-30T18:18:07.993" Title="What is the difference between Task-Level and Joint-Level Control Systems?" Tags="&lt;mobile-robot&gt;&lt;control&gt;&lt;hexapod&gt;" AnswerCount="1" CommentCount="5" />
  <row Id="1254" PostTypeId="2" ParentId="1253" CreationDate="2013-04-30T18:18:07.993" Score="4" Body="&lt;p&gt;These are just terms to describe the &quot;layers&quot; of control on the robot.  The &quot;joint level&quot; means the position of each actuator (leg), and the &quot;task level&quot; means the current goal of the robot (like go forward, go east, go to location X, etc).  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;This paragraph is about sensing.  There are (apparently) position sensors in all of the leg joints, so the robot is capable of &lt;a href=&quot;http://en.wikipedia.org/wiki/PD_controller&quot; rel=&quot;nofollow&quot;&gt;closed loop&lt;/a&gt; control at that level -- no user intervention needed.  (&quot;Proprioceptive&quot; is a $5 word for &quot;I know where my legs are because I can sense them&quot;.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, having no external sensors means that the robot can't tell where it is in relation to the world and as a result it can't determine what action it should take to accomplish its goals.  So, it must run as &lt;a href=&quot;http://en.wikipedia.org/wiki/Open-loop_controller&quot; rel=&quot;nofollow&quot;&gt;open loop&lt;/a&gt;.  Presumably this means that they are either giving it a pre-scripted set of actions, or directing it via remote control.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, the task-level control handles the &quot;go forward&quot; concept, but the joint-level control handles the uneven terrain underfoot.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-04-30T18:18:07.993" CommentCount="2" />
  <row Id="1255" PostTypeId="2" ParentId="1219" CreationDate="2013-04-30T22:32:37.103" Score="3" Body="&lt;p&gt;The solution is actually not quite linear. There are at least two cases:&#xA;1) The fastest solution does not require maximum turning at all times.&#xA;2) The fastest solution does require maximum turning at all times.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For an example of 1), consider the goal is straight ahead of the drone.&#xA;For an example of 2), consider the goal is very close, but straight behind the drone; the fastest solution is a circle-like path.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Finally, the problem is somewhat under-specified, unless you also add desired velocity/spin at the time of arrival.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, the problem, as stated (even with adding mass), requires solving discontinuous differential equations in an underspecified problem system. There may exist a closed form solution to this, but when I've had to do this (in simulation systems, not real-world systems) I've ended up using simple planners and PID-type beahviors, rather than finding the &quot;optimal&quot; solution.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, one simple planner could be to first apply torque in a closed form to turn to face the desired target point at spin zero (this is a simple quadratic equation) and then turn on max thrust; you will get to the point (at a pretty high velocity.)&#xA;If you want to get to the point with velocity 0, then you have to reverse thrust at the middle of the trajectory.&lt;/p&gt;&#xA;" OwnerUserId="88" LastActivityDate="2013-04-30T22:32:37.103" />
  <row Id="1256" PostTypeId="2" ParentId="1207" CreationDate="2013-04-30T22:46:54.443" Score="1" Body="&lt;p&gt;You cannot use the synchronous &quot;pulseIn()&quot; function to read multiple parallel inputs.&#xA;In general, in embedded systems, you will end up writing a loop that runs as fast as possible, over and over, and does the following:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;1) read inputs&#xA;2) calculate updates to state&#xA;3) write outputs&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ideally, this loop runs many thousands of times per second.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm assuming from context that by &quot;RX/TX&quot; you mean RC-hobby-radio-control PWM pulses.&#xA;The problem you're having is reading the width of more than one pulse at the same time.&#xA;There are two ways to approach this:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;1) Each time through the loop, read both input pins. If a pin is high and was previously low, write the current time (in microseconds) to a variable tracking that pin. If the pin is low and was previously high, write the difference between current time, and the value in the tracking variable, to a variable tracking &quot;last length for pin X.&quot;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;2) Install pin change interrupt handlers for the input pins. Each time one of the pins change, run the algorithm above, from within the interrupt handler. Because of possible race conditions, you need to check both pins for each pin change interrupt.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You will note with both these approaches that precision is pretty crummy in the Arduino environment. There are a few reasons for this, including interrupts used to run the milliseconds timer, and significant overhead in the digitalRead() function as compared to reading ports directly. To get high-quality input, you may need to read ports directly (check the Atmega data sheets for how) and you may also want to poll all the way until the pulse goes low in the interrupt handler (beware that a second pin may go high while the first pin is already high.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This may sound complex if you're new to programming microcontrollers, but it's really the kind of thing that's done every day by those who actual work with this. This is one of several reasons why you need a fair bit of education and experience to become a seasoned developer ;-)&lt;/p&gt;&#xA;" OwnerUserId="88" LastActivityDate="2013-04-30T22:46:54.443" />
  <row Id="1257" PostTypeId="1" CreationDate="2013-05-02T13:13:34.547" Score="3" ViewCount="795" Body="&lt;p&gt;I have tried following a number of guides on the internet but most of them fall down as libfreenect does not exist in opkg, which is the apt-get of Angstrom. Has anyone got it working and if so what is the method?&lt;/p&gt;&#xA;" OwnerUserId="925" LastActivityDate="2013-07-17T15:35:38.870" Title="How can I get Windows Kinect working on Angstrom on Beaglebone?" Tags="&lt;kinect&gt;" AnswerCount="3" />
  <row Id="1258" PostTypeId="2" ParentId="1257" CreationDate="2013-05-02T16:42:56.500" Score="1" Body="&lt;p&gt;Would it be possible to build it from source?  &lt;a href=&quot;https://groups.google.com/forum/#!msg/beagleboard/so6aGYf7Two/Ve0wLqQPetsJ&quot; rel=&quot;nofollow&quot;&gt;This thread on Google Groups&lt;/a&gt; talks about how to do that on Ubuntu 10.10 (although it doesn't work on future versions):&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Install Libfreenect0.0: &lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&lt;code&gt;sudo apt-get install libc6 libusb-1.0-0 udev libglu1-mesa libgl1-mesa- &#xA;  glx libsm6 libice6 libx11-6 libxext6 libglut3 libxmu6 libxi6 libstdc+ &#xA;  +6 libgcc1&lt;/code&gt; &lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&lt;code&gt;wget http://ftp.us.debian.org/debian/pool/main/libf/libfreenect/libfreenect0.0_0.0.1+20101211+2-2_armel.deb&lt;/code&gt; &lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&lt;code&gt;sudo dpkg -i libfreenect0.0_0.0.1+20101211+2-2_armel.deb&lt;/code&gt; &lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;install libfreenect-dev: &lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&lt;code&gt;sudo apt-get install libglut3-dev libxi-dev libxmu-dev libc6-dev &#xA;  libglu1-mesa-dev libgl1-mesa-dev libsm-dev libice-dev libx11-dev &#xA;  libxext-dev libstdc++6-4.5-dev libusb-1.0-0-dev pkg-config&lt;/code&gt; &lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&lt;code&gt;wget http://ftp.us.debian.org/debian/pool/main/libf/libfreenect/libfreenect-dev_0.0.1+20101211+2-2_armel.deb&lt;/code&gt;&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&lt;code&gt;sudo dpkg -i libfreenect-dev_0.0.1+20101211+2-2_armel.deb&lt;/code&gt;&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;install libfreenect-demos: &lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&lt;code&gt;sudo apt-get install freeglut3 libgcc1 libgl1-mesa-glx libgl1 libglu1- &#xA;  mesa libglu1 libice6 libsm6 libstdc++6 libx11-6 libxext6 libxi6 &#xA;  libxmu6 libglut3&lt;/code&gt; &lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&lt;code&gt;wget http://ftp.us.debian.org/debian/pool/main/libf/libfreenect/libfreenect-demos_0.0.1+20101211+2-2_armel.deb&lt;/code&gt;&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&lt;code&gt;sudo dpkg -i libfreenect-demos_0.0.1+20101211+2-2_armel.deb&lt;/code&gt;&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;install freenect &lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&lt;code&gt;wget http://ftp.us.debian.org/debian/pool/main/libf/libfreenect/freenect_0.0.1+20101211+2-2_armel.deb&lt;/code&gt;&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&lt;code&gt;sudo dpkg -i freenect_0.0.1+20101211+2-2_armel.deb&lt;/code&gt;&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&lt;code&gt;sudo cp /lib/udev/rules.d/51-kinect.rules /etc/udev/rules.d/51- &#xA;  kinect.rules&lt;/code&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-05-02T16:42:56.500" />
  <row Id="1259" PostTypeId="1" AcceptedAnswerId="1261" CreationDate="2013-05-03T07:44:58.167" Score="2" ViewCount="344" Body="&lt;p&gt;I've been watching too much &lt;a href=&quot;http://science.discovery.com/tv-shows/how-its-made&quot; rel=&quot;nofollow&quot;&gt;How It's Made&lt;/a&gt;, and I've been wondering how they build devices that spray/inject/dispense a finite amount of liquid (to within some amount of error).  I wanted to try this for a hobby project. I'm working on that dispenses dry goods in the amount I specify.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Do I use some kind of special nozzle/valve which can open and close at high speeds? How can I dispense a known quantity from a reservoir of a fluid substance onto each individual unit passing along an assembly line, or an amount specified by the user into another container?&lt;/p&gt;&#xA;" OwnerUserId="1253" LastEditorUserId="1406" LastEditDate="2013-05-31T17:27:39.453" LastActivityDate="2013-05-31T17:27:39.453" Title="How to measure and dispense a finite amount of powder or liquid" Tags="&lt;mechanism&gt;&lt;manufacturing&gt;" AnswerCount="1" CommentCount="2" FavoriteCount="1" />
  <row Id="1260" PostTypeId="2" ParentId="1257" CreationDate="2013-05-03T09:37:44.613" Score="1" Body="&lt;p&gt;This is the method I have found to build the libfreenect for beaglebone:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://elinux.org/ECE497_Project_BeagleBoard_Kinect_with_Usable_Framerates&quot; rel=&quot;nofollow&quot;&gt;http://elinux.org/ECE497_Project_BeagleBoard_Kinect_with_Usable_Framerates&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Summarised below:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Kinect Drivers--libfreenect&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Full information about libfreenect and its installation can be found at &lt;a href=&quot;http://openkinect.org/wiki/Main_Page&quot; rel=&quot;nofollow&quot;&gt;its site, here&lt;/a&gt;. &#xA;  Here I've reproduced just the sections that are useful for getting the drivers set up and working on the BeagleBoard&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Clone the git repository with all of the libfreenect source code in it&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&lt;code&gt;git clone git://github.com/OpenKinect/libfreenect.git&lt;/code&gt;&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;If you don't have git already installed on your BeagleBoard, install it with the following command&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&lt;code&gt;opkg install git&lt;/code&gt;&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Get all of the packages you need for building the drivers&#xA;  To get the basic drivers compiled, you'll need the cmake and libusb-1.0-0 packages. Use the following command to install these packages to your BeagleBoard&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&lt;code&gt;opkg install cmake libusb-1.0-0&lt;/code&gt;&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;NOTE: For some reason on our system the cmake package failed to install the first time, it's some issue with ncurses and dependent libraries. We just reran the command to install cmake and it worked the second time.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Run the cmake utility to generate the necessary makefiles&#xA;  Go into your libfreenect directory and create a subdirectory named build&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&lt;code&gt;cd libfreenect&lt;/code&gt;&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&lt;code&gt;mkdir build&lt;/code&gt;&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Run cmake&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&lt;code&gt;cmake ..&lt;/code&gt;&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Make the tiltdemo&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&lt;code&gt;make tiltdemo&lt;/code&gt;&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;NOTE: If you try to make everything, by just running make like it says in the libfreenect instructions, your make will fail with a bunch of linker errors. This is because there is no GLUT library for the BeagleBoard, so the video demos fail when they try to link against GLUT. We'll be solving this problem later by replacing GLUT calls with PVR calls, but for now, go ahead and make the tiltdemo to be sure you have connectivity with the Kinect&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Run the tiltdemo&#xA;  Go to the bin folder and&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&lt;code&gt;./tiltdemo&lt;/code&gt;&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;NOTE: You may have to&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&lt;code&gt;chmod +x tiltdemo&lt;/code&gt;&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;to get it to run. Now you should see the Kinect tilting up and down and cycling through the various LED options (Red, Green, Blink, Off). Press ctrl+c to exit the demo&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="925" LastEditorUserId="350" LastEditDate="2013-07-17T15:35:38.870" LastActivityDate="2013-07-17T15:35:38.870" CommentCount="4" />
  <row Id="1261" PostTypeId="2" ParentId="1259" CreationDate="2013-05-04T15:25:08.137" Score="2" Body="&lt;p&gt;Flow-rate meters based on measuring Coriolis-force reactions are widely used in process control systems. &#xA;The measurement principles are mentioned or illustrated at numerous web sites, including youtube video e2NGvrkmP8Y, &lt;a href=&quot;http://www.youtube.com/watch?feature=player_embedded&amp;amp;v=e2NGvrkmP8Y&quot; rel=&quot;nofollow&quot;&gt;Back to Basics: Flow Measurement (Corilolis)&lt;/a&gt; (via oscillating-tube phase changes) and Schenck Americas' &lt;a href=&quot;http://www.schenckamericas.com/prod_solidsflowmeters.html&quot; rel=&quot;nofollow&quot;&gt;Solids Flow Meters&lt;/a&gt; page, Coriolis Principle section (via vaned-rotor reaction forces) .  Coriolis-based meters measure the delivered mass of solids, liquids, and gases.  Delivered volume can be calculated if density is known.  Purchase of a Coriolis-based meter seems far more feasible than building one from scratch.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The Schenck page also illustrates impact-plate-based measuring systems and deflection-chute-based measuring systems.  These integrate impulses or deflection force to measure flow.  Again, purchase seems more feasible than building one yourself.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;At a hobby level, I think two approaches should be considered first:  (A) calibrate a constant-flow-rate system, and control delivery time; (B) implement a fill-and-dump system, and control number of cycles.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(A) Using a method from previous questions (&lt;a href=&quot;http://robotics.stackexchange.com/questions/1145/what-would-be-the-best-way-to-handle-food-grains&quot;&gt;1&lt;/a&gt;,&lt;a href=&quot;http://robotics.stackexchange.com/questions/1167/can-the-rate-of-peristaltic-pumps-flow-be-accurate-across-changes-in-fluid-visc&quot;&gt;2&lt;/a&gt;) set up a system that moves your substance at a reasonably constant rate; measure that rate; thereafter, control how long or how fast the system runs to deliver a desired amount of substance.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(B) Again using methods from previous questions, set up a system to fill a cup, box, chute, or transfer bin some number of times, and dump it into a receiver.  Issues like detecting when the cup is full, preventing or recycling overflow of the cup, and dumping the cup arise but can be resolved.  The issue of limited resolution (where the delivered amount is an integer multiple of cup size) can be treated by using a smaller cup, or using different cups for different jobs, or using a box with an adjustable side or bottom, or having the box sit on a load cell during filling.&lt;/p&gt;&#xA;" OwnerUserId="478" LastActivityDate="2013-05-04T15:25:08.137" CommentCount="1" />
  <row Id="1262" PostTypeId="2" ParentId="1207" CreationDate="2013-05-05T08:36:18.810" Score="3" Body="&lt;p&gt;I'm assuming you have a standard 9-channel hobby RC transmitter (with the little joysticks you move with your fingers) and a corresponding 9-channel hobby RC receiver intended to go into a RC car or airplane with standard servo 3-pin headers (9 of them).&#xA;And you have your Arduino, and a few motors you want to control with it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Your program has better-than-average comments, but some are still mystifying, such as:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;int motor1Left = 7;// defines pin 5 as connected to the motor&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Really?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would break this problem into (at least) two parts, try to get each part working independently, and then try to get everything working together.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One way to break it up into parts is to have an array something like&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;int pulseWidth[9];&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I might write one program that &lt;em&gt;only&lt;/em&gt; reads pulse widths from the RC receiver and prints them out the serial port.&#xA;Then I might extend that program to store those pulse widths into that array,&#xA;and then print out the values in that array.&#xA;Then I might write a completely separate program that sets each value in that array to a different constant,&#xA;and then uses the values in that array to control the motors.&#xA;Only after I got both programs working would I combine them into one program.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Reading the pulse widths is definitely the trickiest part,&#xA;but I hear that several people have gotten that to work adequately for them.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The two basic approaches to reading pulse widths that I've seen are:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;(a) Get &lt;a href=&quot;http://blog.ilektronx.com/2013/01/hacking-cheap-hobbyking-6-channel.html&quot; rel=&quot;nofollow&quot;&gt;all the signals on one wire&lt;/a&gt;, sometimes called &quot;the PPM stream&quot; (i.e., if it uses a 4017 IC for splitting, attach the wire to the &quot;CLK&quot; pin 14; if it uses a 4015 IC for splitting, attach the wire to the &quot;CLK&quot; pin 9), and feed that one wire into a single Arduino input. Or,&lt;/li&gt;&#xA;&lt;li&gt;(b) Feed each output pin that you care about to separate input pins on the Arduino. (It may help if you use an O'scope to figure out which order the &quot;RC receiver&quot; pulses those pins.)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Have you tried maybe running program listed at&#xA;&lt;a href=&quot;https://www.sparkfun.com/tutorials/348&quot; rel=&quot;nofollow&quot;&gt;&quot;RC Hobby Controllers and Arduino&quot;&lt;/a&gt;&#xA;without any changes at all?&#xA;Does that much work on your hardware?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Other people connecting a hobby RC receiver to an Arduino include (in no particular order):&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://arduino.cc/forum/index.php?topic=91909.0&quot; rel=&quot;nofollow&quot;&gt;&quot;reading 6-channel RC receiver PWM signal&quot;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://musingsandhobbies.blogspot.com/2009/11/arduino-vex-receiver-and-signal.html&quot; rel=&quot;nofollow&quot;&gt;&quot;Arduino, Vex receiver and signal splitter&quot;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://arduino.cc/forum/index.php/topic,20286.0.html&quot; rel=&quot;nofollow&quot;&gt;&quot;Arduino: Read PWM Signal from a RC-Receiver&quot;&lt;/a&gt; &lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://arduino.cc/forum/index.php/topic,42462.0.html&quot; rel=&quot;nofollow&quot;&gt;&quot;Arduiono: 3 axis auto stabilized platform&quot;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://autosysprogs.blogspot.com/2011/04/arduino-and-txrx-system.html&quot; rel=&quot;nofollow&quot;&gt;&quot;Arduino and Tx/Rx system&quot;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.rcgroups.com/forums/showthread.php?t=1227935&quot; rel=&quot;nofollow&quot;&gt;&quot;Arduino Receiver&quot;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://rcarduino.blogspot.com/2012/04/how-to-read-multiple-rc-channels-draft.html&quot; rel=&quot;nofollow&quot;&gt;&quot;RCArduino: How To Read Multiple RC Channels&quot;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://rcarduino.blogspot.com/2012/11/how-to-read-rc-receiver-ppm-stream.html&quot; rel=&quot;nofollow&quot;&gt;&quot;How To Read RC Receiver PPM Stream&quot;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://arduino.cc/forum/index.php/topic,7167.0.html&quot; rel=&quot;nofollow&quot;&gt;&quot;Arduino: Read PPM signals from RC receiver or Control&quot;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://playground.arduino.cc/Code/ReadReceiver&quot; rel=&quot;nofollow&quot;&gt;&quot;Arduino: Read Receiver&quot;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://diydrones.com/profiles/blogs/705844%3aBlogPost:38393&quot; rel=&quot;nofollow&quot;&gt;&quot;How to hack the PPM signal from any receiver (Futaba) with Arduino&quot;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.elenafrancesco.org/old/arduino/ppmmixer/&quot; rel=&quot;nofollow&quot;&gt;&quot;PPMMixer: Arduino Radio R/C PPM Mixer Programmable&quot;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.rcgroups.com/forums/showthread.php?t=1808432&quot; rel=&quot;nofollow&quot;&gt;&quot;Arduino ppm signal reader and generator&quot;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://github.com/kiuz/PPM-Signal-Reader-ARDUINO&quot; rel=&quot;nofollow&quot;&gt;&quot;Arduino PPM signal reader/decoder Library&quot;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;P.S.: often you get &lt;a href=&quot;http://www.chiark.greenend.org.uk/~sgtatham/bugs.html&quot; rel=&quot;nofollow&quot;&gt;better answers&lt;/a&gt; to problems like this if you write all three parts: (1) what you want to happen, (2) the complete program listing, and (3) what actually happens when you run the program&amp;nbsp;— &quot;Motor 2 never moves, no matter how I move the control stick&quot;, or &quot;Motor 2 always moves exactly like motor 1 moves&quot;, or whatever it is you actually observe.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You did great with part (2), but without (1) and (3) it's difficult for anyone to help you.&lt;/p&gt;&#xA;" OwnerUserId="187" LastEditorUserId="1177" LastEditDate="2013-12-31T03:19:19.427" LastActivityDate="2013-12-31T03:19:19.427" />
  <row Id="1263" PostTypeId="1" AcceptedAnswerId="1265" CreationDate="2013-05-05T21:22:41.277" Score="1" ViewCount="149" Body="&lt;p&gt;The latest OSX documentation I found on the website is from 2011, and the latest build is from over a year ago. I'm a complete n00b to all things ROS and wanted to start playing with it. What is the easiest way?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Edit:&lt;/strong&gt; &lt;a href=&quot;http://www.ros.org/wiki/groovy/Installation/OSX/Homebrew/Source&quot; rel=&quot;nofollow&quot;&gt;this version&lt;/a&gt; of the installation instructions is more recent (April 2013), but it says that&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;OSX is not officially supported by ROS and the installation might fail for several reasons. This page does not (yet) contain instructions for most higher level ROS packages, only for the base system. This includes the middleware and command line tools but not much more.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;&quot;Does not contain instructions&quot; also means it doesn't work? What do OSX users who work on ROS usually do? Run it on an Ubuntu VM? Install it just fine on their own on OSX, even though there aren't detailed instructions on the website?&lt;/p&gt;&#xA;" OwnerUserId="1264" LastEditorUserId="1264" LastEditDate="2013-05-05T21:43:47.563" LastActivityDate="2013-05-07T18:41:40.007" Title="What is the easiest way to install ROS on OSX Mountain Lion?" Tags="&lt;ros&gt;" AnswerCount="2" CommentCount="2" />
  <row Id="1264" PostTypeId="2" ParentId="1263" CreationDate="2013-05-06T18:05:00.273" Score="3" Body="&lt;p&gt;Installing ROS is one thing, but the question you should really be asking is about maintaining  ROS.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It's certainly possible to install ROS on any *nix system if you satisfy all the dependencies, but since those dependencies are constantly being updated to new versions the maintenance quickly becomes a nightmare.  The OSX install tips on their wiki (&lt;a href=&quot;http://www.ros.org/wiki/groovy/Installation/OSX/Homebrew/Source&quot; rel=&quot;nofollow&quot;&gt;Homebrew&lt;/a&gt; or &lt;a href=&quot;http://www.ros.org/wiki/groovy/Installation/OSX/MacPorts/Source&quot; rel=&quot;nofollow&quot;&gt;MacPorts -- noting the lack of instruction for higher-level libraries&lt;/a&gt;) give some hints of this.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Virtualbox is (unfortunately) the easiest method -- &quot;unfortunately&quot;, because technically you're installing ROS on the guest OS, not OSX.  But on the upside, it's the supported way to go.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-05-07T18:41:40.007" LastActivityDate="2013-05-07T18:41:40.007" />
  <row Id="1265" PostTypeId="2" ParentId="1263" CreationDate="2013-05-06T23:34:44.253" Score="1" Body="&lt;p&gt;From experience, I suggest you only install ROS on Ubuntu (the only supported platform at the moment). As previously mentioned, Virtualbox or, in my case, VMware Fusion, is how you'd get it to run as a guest in OSX. I'd suggest you dual-boot to Ubuntu for running ROS, though, mainly due to the computational requirements of some packages and workflows.&lt;/p&gt;&#xA;" OwnerUserId="295" LastActivityDate="2013-05-06T23:34:44.253" />
  <row Id="1266" PostTypeId="1" AcceptedAnswerId="1371" CreationDate="2013-05-07T13:25:22.977" Score="10" ViewCount="312" Body="&lt;p&gt;Let's think of the following situations:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;You are teaching a robot to play ping pong&lt;/li&gt;&#xA;&lt;li&gt;You are teaching a program to calculate square root&lt;/li&gt;&#xA;&lt;li&gt;You are teaching math to a kid in school&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;These situations (i.e. supervised learning), and many others have one thing (among others) in common: the learner gets a reward based on its performance.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My question is, what should the reward function look like? Is there a &quot;best&quot; answer, or does it depend on the situation? If it depends on the situation, how does one determine which reward function to pick?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, take the following three reward functions:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/UvrHs.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Function &lt;code&gt;A&lt;/code&gt; says:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;below a certain point, bad or worse are the same: you get nothing&lt;/li&gt;&#xA;&lt;li&gt;there is a clear difference between almost good and perfect&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;Function &lt;code&gt;B&lt;/code&gt; says:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;you get reward linearly proportional to your performance&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;Function &lt;code&gt;C&lt;/code&gt; says:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;if your performance is bad, it's ok, you did your best: you still get some reward&lt;/li&gt;&#xA;&lt;li&gt;there is not much difference between perfect and almost good&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Intuitively, I'd think &lt;code&gt;A&lt;/code&gt; would make the robot very focused and learn the exact pattern, but become stupid when dealing with similar patterns, while &lt;code&gt;C&lt;/code&gt; would make it more adaptable to change at the cost of losing perfection.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One might also think of more complex functions, just to show but few:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/eCS4R.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, how does one know which function to pick? Is it known which behavior would emerge from (at least) the basic &lt;code&gt;A&lt;/code&gt;, &lt;code&gt;B&lt;/code&gt; and &lt;code&gt;C&lt;/code&gt; functions?&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;A side question is would this be fundamentally different for robots and human kids?&lt;/p&gt;&#xA;" OwnerUserId="158" LastActivityDate="2013-11-08T18:13:25.833" Title="What reward function results in optimal learning?" Tags="&lt;machine-learning&gt;" AnswerCount="5" CommentCount="4" FavoriteCount="4" />
  <row Id="1267" PostTypeId="2" ParentId="1266" CreationDate="2013-05-07T15:38:10.863" Score="3" Body="&lt;p&gt;These issues are addressed, to some extent, by the study of &lt;a href=&quot;http://en.wikipedia.org/wiki/Utility&quot; rel=&quot;nofollow&quot;&gt;utility functions&lt;/a&gt; in economics.  A utility function expresses effective or perceived values of one thing in terms of another.  (While the curves shown in the question are reward functions and express how much reward will be tendered for various performance levels, similar-looking utility functions could express how much performance results from various reward levels.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What reward function will work best depends on equilibria between the payer and the performer.  The wikipedia &lt;em&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Contract_curve&quot; rel=&quot;nofollow&quot;&gt;contract curve&lt;/a&gt;&lt;/em&gt; article illustrates with &lt;a href=&quot;http://en.wikipedia.org/wiki/Edgeworth_box&quot; rel=&quot;nofollow&quot;&gt;Edgeworth boxes&lt;/a&gt; how to find &lt;a href=&quot;http://en.wikipedia.org/wiki/Pareto_efficient&quot; rel=&quot;nofollow&quot;&gt;Pareto efficient&lt;/a&gt; allocations.  The &lt;a href=&quot;http://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem&quot; rel=&quot;nofollow&quot;&gt;Von Neumann–Morgenstern utility theorem&lt;/a&gt; delineates conditions that ensure that an agent is VNM-rational and can be characterized as having a utility function.  The  “Behavioral predictions resulting from HARA utility” section of the &lt;a href=&quot;http://en.wikipedia.org/wiki/Hyperbolic_absolute_risk_aversion#Behavioral_predictions_resulting_from_HARA_utility&quot; rel=&quot;nofollow&quot;&gt;Hyperbolic absolute risk aversion&lt;/a&gt; article in wikipedia describes behavioral consequences of certain utility functions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Summary: These topics have been the subject of tremendous amounts of study in economics and microeconomics.  Unfortunately, extracting a brief and useful summary that answers your question might also call for a tremendous amount of work, or the attention of someone rather more expert than me.&lt;/p&gt;&#xA;" OwnerUserId="478" LastActivityDate="2013-05-07T15:38:10.863" CommentCount="1" />
  <row Id="1268" PostTypeId="2" ParentId="1266" CreationDate="2013-05-07T18:13:24.837" Score="0" Body="&lt;p&gt;Any form of supervised learning is a directed search in policy space. You try to find the policy -- so which action to take -- which provides the maximum reward expectation. In your question you give reward as a function of performance. As long as this function is monotonic any method which converges will ultimately end up giving you maximum performance (too stay with your terminology).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How fast the method converges is another matter, and may well depend on the curve. But I think this will differ from method to method.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;An entirely different problem is that for more complex scenarios performance is not a simple scalar, and defining it can be pretty difficult. What's the reward function for being good at math?&lt;/p&gt;&#xA;" OwnerUserId="127" LastActivityDate="2013-05-07T18:13:24.837" CommentCount="1" />
  <row Id="1269" PostTypeId="2" ParentId="1266" CreationDate="2013-05-07T18:40:45.283" Score="6" Body="&lt;p&gt;&quot;Optimal learning&quot; is a very vague term, and it is completely dependent on the specific problem you're working on.  The term you're looking for is &quot;&lt;a href=&quot;http://en.wikipedia.org/wiki/Overfitting&quot;&gt;overfitting&lt;/a&gt;&quot;:&#xA;&lt;img src=&quot;http://i.stack.imgur.com/702pw.gif&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(The green line is the error in predicting the result on the training data, the purple line the quality of the model, and the red line is the error of the learned model being used &quot;in production&quot;)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In other words: when it comes to adapting your learned behavior to similar problmes, how you rewarded your system is less important than &lt;em&gt;how many times&lt;/em&gt; you rewarded it -- you want to reduce errors in the training data, but not keep it in training so long that it loses the ability to work on similar models.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One method of addressing this problem is to cut your training data in half: use one half to learn on and the other half to to validate the training.  It helps you identify when you begin to over-fit.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Non-linear reward functions&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Most supervised learning algorithms expect that application of the reward function will produce a convex output.  In other words, having local minima in that curve will prevent your system from converging to the proper behavior.  &lt;a href=&quot;http://www.youtube.com/watch?v=UMthAqRNqMw&quot;&gt;This video shows a bit of the math behind cost/reward functions&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-05-09T19:50:57.800" LastActivityDate="2013-05-09T19:50:57.800" />
  <row Id="1270" PostTypeId="1" CreationDate="2013-05-07T21:49:46.780" Score="4" ViewCount="1180" Body="&lt;p&gt;How can I detect when a stepper motor has stalled?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A google search led me to some people who say that&#xA;when the stepper motor stalls, the current spikes up,&#xA;which is easily detectable with a Hall sensor.&#xA;(Or, I suppose, by any of the other current sensors mentioned at&#xA;&lt;a href=&quot;http://electronics.stackexchange.com/questions/17246/how-can-i-sense-the-motors-current&quot;&gt;&quot;How can I sense the motor's current?&quot;&lt;/a&gt;&#xA;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, I measured the current through (one of the 4 wires of) my stepper motor,&#xA;and it's always within a few percent of 0.5 A, whether my stepper driver is holding one position, moving it normally (which in my application is very slowly), or the stepper driver thinks it is telling the stepper to move normally, but the motor has pegged out against the hard limit.&#xA;Measuring the current in the +12V power supply going to the stepper motor driver, also seemed to give a fairly constant current.&#xA;This may be because I turned down the current limit to that amount on my &quot;chopper&quot; stepper motor driver.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Am I missing some key detail in the &quot;measure the current&quot; approach?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A google search led me to some other people that measure the back-EMF (BEMF) in one coil of the stepper during the time the stepper driver is only driving the other coil.&#xA;But that only seems to distinguish between &quot;a motor moving quickly&quot; vs &quot;a motor stopped&quot;, and doesn't seem to distinguish between my case of &quot;a motor moving slowly&quot; vs &quot;a motor stopped&quot;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there some way to apply the BEMF approach even in a system where I always drive the stepper slowly, and never spin it quickly?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm currently using &lt;a href=&quot;http://www.pololu.com/catalog/product/2132&quot; rel=&quot;nofollow&quot;&gt;a stepper driver board&lt;/a&gt; with the TI DRV8825 chip on it, and I hoped the &quot;fault&quot; pin would tell me when the stepper motor has stalled against my hard stop.&#xA;But it doesn't seem to be doing anything -- is it supposed to tell me about a stall, but I just have it wired up wrong?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there some other chip or drive technique that detects when the stepper has stalled out against the hard stop?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there some other technique for detecting a hard stall that I can &quot;add on&quot; to a system using an off-the-shelf stepper motor driver?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(Is there some other StackExchange site that is more appropriate for questions about motors and motor drivers?)&lt;/p&gt;&#xA;" OwnerUserId="187" LastActivityDate="2013-05-31T00:53:53.060" Title="How to detect when a stepper motor has stalled?" Tags="&lt;stepper-motor&gt;&lt;stepper-driver&gt;&lt;force-sensor&gt;" AnswerCount="3" CommentCount="1" />
  <row Id="1271" PostTypeId="2" ParentId="1270" CreationDate="2013-05-07T23:23:02.493" Score="4" Body="&lt;p&gt;One option is a stepper motor driver which uses sensorless stall system, such as the &lt;a href=&quot;http://www.st.com/web/catalog/sense_power/FM142/CL851/SC1794/SS1498/LN1723/PF248592&quot; rel=&quot;nofollow&quot;&gt;STMicroelectronics L6470 dSPIN: Fully integrated microstepping motor driver with motion engine and SPI&lt;/a&gt;. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Once calibrated it can detect a stall condition and raise the FLAG pin high to alert to the uC of the problem.&lt;/p&gt;&#xA;" OwnerDisplayName="user797" LastEditorUserId="37" LastEditDate="2013-05-08T11:59:20.043" LastActivityDate="2013-05-08T11:59:20.043" CommentCount="1" />
  <row Id="1272" PostTypeId="2" ParentId="1270" CreationDate="2013-05-08T02:57:29.857" Score="2" Body="&lt;p&gt;Unfortunately, as you've discovered, it is difficult to tell if a stepper motor is stalled because the current through the coils of a stepper motor is roughly the same if it is stalled (can't step), holding position, or stepping normally.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You could definitely detect a stall with ease if you added an encoder or used a stepper motor that already had one.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Why do you want to detect the stepper motor stall? Unlike a brushed DC motor, stalling a stepper motor is typically not bad for it. Could you achieve the same purpose with a limit switch?&lt;/p&gt;&#xA;" OwnerUserId="1275" LastActivityDate="2013-05-08T02:57:29.857" CommentCount="1" />
  <row Id="1273" PostTypeId="2" ParentId="970" CreationDate="2013-05-08T03:12:20.987" Score="0" Body="&lt;p&gt;You might be able to do &quot;hard iron&quot; calibrations to cancel out the effects of the magnets if they are fixed in relation to the magnetometer. One strategy people use to avoid interference is to make a mast and put the magnetometer at the top of the mast away from the other electronics.&lt;/p&gt;&#xA;" OwnerUserId="1275" LastActivityDate="2013-05-08T03:12:20.987" />
  <row Id="1274" PostTypeId="1" AcceptedAnswerId="1275" CreationDate="2013-05-08T13:30:52.200" Score="1" ViewCount="178" Body="&lt;p&gt;I bought my kid a &lt;a href=&quot;http://www.gigo.com.tw/english/_toy/detail.php?MID=100&amp;amp;SID=101&amp;amp;ID=974&quot; rel=&quot;nofollow&quot;&gt;robotics kit&lt;/a&gt; with several motors and an infrared remote control (you can steer the robot using IR remote control).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now I want to take it to the next level and control the robots from a PC or a Raspberry Pi.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What is the simplest approach to do this?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am thinking about 2 possible ways:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Find out the protocol the existing remote control uses and then emulate the IR signals using Arduino (Arduino is sending the IR signals).&lt;/li&gt;&#xA;&lt;li&gt;Find a piece of hardware, which presses the buttons on the remote control and control it via to Arduino (Arduino is sending signals to the button pushers, the remote control is sending the IR signals to the robot).&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="1277" LastActivityDate="2013-05-08T19:17:13.590" Title="How to connect an infrared remote control to PC or Arduino or Raspberry Pi?" Tags="&lt;mobile-robot&gt;&lt;arduino&gt;&lt;raspberry-pi&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="1275" PostTypeId="2" ParentId="1274" CreationDate="2013-05-08T14:23:40.063" Score="3" Body="&lt;p&gt;Read &lt;a href=&quot;http://learn.adafruit.com/ir-sensor&quot; rel=&quot;nofollow&quot;&gt;Ada Fruits Tutorial&lt;/a&gt; along with many other sources of IR tutorials out there.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then for an Arduino I would use (and have used) &lt;a href=&quot;http://www.righto.com/2009/08/multi-protocol-infrared-remote-library.html&quot; rel=&quot;nofollow&quot;&gt;Ken's IRremote Library&lt;/a&gt; as it has several examples, several device protocols and requires only a &lt;a href=&quot;https://www.sparkfun.com/products/10266&quot; rel=&quot;nofollow&quot;&gt;TSOP38238&lt;/a&gt;. And is quickly adaptable to others.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Look at the GitHub Network of Forks, as there are others who have added other device protocols.&lt;/p&gt;&#xA;" OwnerUserId="821" LastEditorUserId="821" LastEditDate="2013-05-08T19:17:13.590" LastActivityDate="2013-05-08T19:17:13.590" CommentCount="0" />
  <row Id="1276" PostTypeId="1" AcceptedAnswerId="1278" CreationDate="2013-05-08T17:33:04.103" Score="1" ViewCount="72" Body="&lt;p&gt;I have a three wheeled vehicle in a tricycle configuration attached to a fixed frame. Each wheel is powered by an AC electric motor. The AC motors are fed by motor controllers that take a speed demand. The single main wheel (which is also steerable) has a lower gear ratio than the rear wheels so it has a theoretical higher top speed. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;When the vehicle drives in a straight line each of the motor controllers are given identical speed requests. Unfortunately feedback from the controller indicates that some motors are pushing while some are pulling. In particular we have a common scenario where one rear wheel is pushing while the front wheel is trying to slow down. The third wheel will often have almost no current. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What can be done to make all three motors work together and avoid situations where they fight?  Is there a way to change the request to the motor controller to encourage the drives to work together? Do we have to switch from a speed request setup to a current control setup? If so what is the appropriate way to control the motors then? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Let me know if I haven't included any important details and I will update my question.&lt;/p&gt;&#xA;" OwnerUserId="201" LastActivityDate="2013-05-08T18:57:53.090" Title="How can a load be balanced between multiple AC electric drive motors?" Tags="&lt;control&gt;&lt;motor&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="1277" PostTypeId="1" AcceptedAnswerId="1280" CreationDate="2013-05-08T18:52:41.650" Score="1" ViewCount="182" Body="&lt;p&gt;I am developing a robot which paints using an airbrush (3D painting). I intend to use several colors as a CMYK printer, but I do not know how to do the conversion of RGB colors in the computer to the dosage of colors in CMYK.&lt;/p&gt;&#xA;" OwnerUserId="1280" LastEditorUserId="37" LastEditDate="2013-05-08T23:55:57.460" LastActivityDate="2013-05-31T01:06:07.433" Title="How can I convert RGB colors to CMYK for my airbrush robot?" Tags="&lt;robotic-arm&gt;" AnswerCount="2" />
  <row Id="1278" PostTypeId="2" ParentId="1276" CreationDate="2013-05-08T18:57:53.090" Score="2" Body="&lt;p&gt;You're facing a problem that's normally solved mechanically, with 2 or 4 wheels, by a &lt;a href=&quot;http://en.wikipedia.org/wiki/Differential_%28mechanical_device%29&quot; rel=&quot;nofollow&quot;&gt;differential gearbox&lt;/a&gt;.  Technically, you'd be able to adapt a 4WD differential to a 3WD case, but you'd have to use a single motor for that.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The concept you're looking for is an &lt;a href=&quot;http://en.wikipedia.org/wiki/Electronic_differential&quot; rel=&quot;nofollow&quot;&gt;electronic differential&lt;/a&gt;, although I'm not sure where to find resources on building and calibrating your own.  It might be as simple as switching your motor controllers to just set identical torque, based on a desired average speed between the 3 of them.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The bottom line, though, is that you can't expect to set 3 motors to the same speed and have them follow 3 paths of different lengths while maintaining the same distance from each other.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-05-08T18:57:53.090" CommentCount="1" />
  <row Id="1279" PostTypeId="1" CreationDate="2013-05-08T20:57:52.400" Score="3" ViewCount="668" Body="&lt;p&gt;I am interested in building a robot like the &lt;strong&gt;&lt;a href=&quot;http://www.ez-robot.com/Shop/AccessoriesDetails.aspx?prevCat=100&amp;amp;productNumber=40&quot; rel=&quot;nofollow&quot;&gt;EZ-B&lt;/a&gt;&lt;/strong&gt;, sold by &lt;a href=&quot;http://ez-robot.com&quot; rel=&quot;nofollow&quot;&gt;ez-robot.com&lt;/a&gt;. It comes with an SDK for &lt;a href=&quot;http://en.wikipedia.org/wiki/Microsoft_Visual_Studio&quot; rel=&quot;nofollow&quot;&gt;Visual Studio&lt;/a&gt; and has direct scripting in runtime through a USB, Bluetooth, Wi-Fi, &lt;a href=&quot;http://en.wikipedia.org/wiki/Internet_Relay_Chat&quot; rel=&quot;nofollow&quot;&gt;IRC&lt;/a&gt; or &lt;a href=&quot;http://en.wikipedia.org/wiki/HTTP_Secure&quot; rel=&quot;nofollow&quot;&gt;HTTPS&lt;/a&gt; connection.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If I get a regular &lt;a href=&quot;http://en.wikipedia.org/wiki/Arduino&quot; rel=&quot;nofollow&quot;&gt;Arduino&lt;/a&gt; board, will I be able to control it remotely in the same way? From what I've read, an Arduino needs to hold the instructions in its own memory, but I would rather have the brain in the computer, feeding signals back and forth to the microcontroller.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, is Arduino alone, a step down as the website niceley puts it?&lt;/p&gt;&#xA;" OwnerUserId="1281" LastEditorUserId="1906" LastEditDate="2013-11-06T23:40:39.057" LastActivityDate="2013-11-06T23:40:54.243" Title="How can I create a robot like the EZ-B using a regular Arduino?" Tags="&lt;arduino&gt;&lt;microcontroller&gt;&lt;research&gt;&lt;machine-learning&gt;&lt;artificial-intelligence&gt;" AnswerCount="4" FavoriteCount="1" />
  <row Id="1280" PostTypeId="2" ParentId="1277" CreationDate="2013-05-08T22:02:53.733" Score="2" Body="&lt;p&gt;According to &lt;a href=&quot;http://www.rapidtables.com/convert/color/rgb-to-cmyk.htm&quot; rel=&quot;nofollow&quot;&gt;rapidtables.com&lt;/a&gt;, the following formulae convert [24-bit] RGB color to CMYK:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The R,G,B values are divided by 255 to change the range from 0..255 to 0..1:&lt;br&gt;&#xA;  R' = R/255&lt;br&gt;&#xA;  G' = G/255&lt;br&gt;&#xA;  B' = B/255  &lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;The black key (K) color is calculated from the red (R'), green (G') and blue (B') colors:&lt;br&gt;&#xA;  K = 1-max(R', G', B')  &lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;The cyan color (C) is calculated from the red (R') and black (K) colors:&lt;br&gt;&#xA;  C = (1-R'-K) / (1-K)  &lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;The magenta color (M) is calculated from the green (G') and black (K) colors:&lt;br&gt;&#xA;  M = (1-G'-K) / (1-K)&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;The yellow color (Y) is calculated from the blue (B') and black (K) colors:&lt;br&gt;&#xA;  Y = (1-B'-K) / (1-K)&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Formulae at &lt;a href=&quot;http://www.javascripter.net/faq/rgb2cmyk.htm&quot; rel=&quot;nofollow&quot;&gt;javascripter.net&lt;/a&gt; appear to be equivalent, although complements are computed in a different order.&lt;/p&gt;&#xA;" OwnerUserId="478" LastActivityDate="2013-05-08T22:02:53.733" CommentCount="2" />
  <row Id="1282" PostTypeId="2" ParentId="1279" CreationDate="2013-05-09T17:10:33.967" Score="3" Body="&lt;p&gt;Unfortunately, I have no experience with &lt;strong&gt;ez-b&lt;/strong&gt;, but I have looked over the site a little bit. I do, however, have lots of Arduino experience. The program is, indeed, stored on the board's local memory. However, it is very possible to write a program that can interact with your computer. With my Arduino, I often write programs that communicate with my computer over USB. To communicate over Wifi will require additional hardware. There is a Wifi &quot;shield&quot; that can be attached to your Arduino, but this runs at around $60.&lt;/p&gt;&#xA;" OwnerUserId="1287" LastActivityDate="2013-05-09T17:10:33.967" CommentCount="5" />
  <row Id="1283" PostTypeId="2" ParentId="865" CreationDate="2013-05-09T18:44:10.113" Score="0" Body="&lt;p&gt;To detect if your steppers have stalled check this question&lt;a href=&quot;http://robotics.stackexchange.com/questions/1270/how-to-detect-when-a-stepper-motor-has-stalled/1271?noredirect=1#comment2845_1271&quot;&gt;how to detect when a stepper motor has stalled&lt;/a&gt;. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you want to use absolute positioning you can create a linear potentiometer using a length of nichrome wire pulled across the axis, with the &quot;wiper&quot; touching where the bed/mill is moving. You will need some uC to report on the actual position of the system however a 10ADC should be enough for a small project.&lt;/p&gt;&#xA;" OwnerDisplayName="user797" LastActivityDate="2013-05-09T18:44:10.113" />
  <row Id="1284" PostTypeId="2" ParentId="446" CreationDate="2013-05-09T18:51:47.127" Score="0" Body="&lt;p&gt;The torque you need on a CNC machine is dependant on:&#xA;1) How much force the mill is expected to exert on the material&#xA;2) The resistance of the linear bearings used to move the axes&#xA;3) The type/style of cnc mill(i.e mills using a moving gantry need more torque than a xy table)&#xA;4) The drive system (i.e. belt driven machines needs more torque than lead screw)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ultimately the amount of torque depends on how much power (like watts power) you're pumping into your steppers. The rating on the steppers are based on their optimal; however you can over drive them. Also if you are running your machine slowly then you can escape with using less torque since there is less risk of stalling as opposed to a machine running at high speed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Further as stepper motors speed up they loose torque, unless they are BEMF compensated. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Try with your steppers; it may work in which case you're just over thinking the problem and if it doesn't work then you have an idea of how much torque you will need.&lt;/p&gt;&#xA;" OwnerDisplayName="user797" LastActivityDate="2013-05-09T18:51:47.127" CommentCount="1" />
  <row Id="1285" PostTypeId="2" ParentId="1279" CreationDate="2013-05-10T18:13:34.820" Score="2" Body="&lt;p&gt;We've written robotic software in C# for a school &#xA;project, called &lt;em&gt;&lt;a href=&quot;http://sourceforge.net/projects/netbotproject/&quot; rel=&quot;nofollow&quot;&gt;NetBotProject&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It works in the way you described. Instead of using an Arduino we used a self-soldered &lt;a href=&quot;http://www.atmel.com/devices/atmega8.aspx&quot; rel=&quot;nofollow&quot;&gt;ATmega8&lt;/a&gt; board with our own firmware. The communication is based on &lt;a href=&quot;http://en.wikipedia.org/wiki/RS-232&quot; rel=&quot;nofollow&quot;&gt;RS-232&lt;/a&gt; and on top of that our own protocol. The protocol (and the firmware) has commands for setting/getting &lt;a href=&quot;http://en.wikipedia.org/wiki/Input/output&quot; rel=&quot;nofollow&quot;&gt;I/O&lt;/a&gt; ports, powering servos, timer functions, etc.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To make a Wi-Fi connection, we used a cheap Fonera router, &lt;a href=&quot;http://de.wikipedia.org/wiki/La_Fonera#Fonera_.28FON2100_und_FON_2200.29&quot; rel=&quot;nofollow&quot;&gt;La Fonera 2100&lt;/a&gt;. It has RS-232 pins built in (connected to Atmega) and is running a socket server/client with &lt;a href=&quot;http://en.wikipedia.org/wiki/Netcat&quot; rel=&quot;nofollow&quot;&gt;Netcat&lt;/a&gt;. Our C# software also has a socket connection running, so we can send/receive the commands/signals to/from the ATmega over Wi-Fi.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;With a few modifications the firmware should be able to run on an Arduino board. The protocol and firmware has not yet commands for the &lt;a href=&quot;http://en.wikipedia.org/wiki/I%C2%B2C&quot; rel=&quot;nofollow&quot;&gt;I²C&lt;/a&gt; bus. So you have to implement that by your own if you want to control more than one microcontroller with the software.&lt;/p&gt;&#xA;" OwnerUserId="1292" LastEditorUserId="1906" LastEditDate="2013-11-06T23:40:54.243" LastActivityDate="2013-11-06T23:40:54.243" CommentCount="1" />
  <row Id="1286" PostTypeId="1" AcceptedAnswerId="1287" CreationDate="2013-05-10T21:09:58.213" Score="2" ViewCount="197" Body="&lt;p&gt;I noticed that some IMU units are tuned to be sensitive to small changes, other to large changes and some that can be adjusted between different sensitivities. I am familiar with the use of a Kalman filter to normalize readings, but I was wondering if my UAV could benefit from a second IMU where the two are set at high and low sensitivities to get even more accurate and timely information.&lt;/p&gt;&#xA;" OwnerUserId="1295" LastActivityDate="2013-05-12T23:15:37.837" Title="Is there a benefit to using 2 IMU units on a UAV set at different sensitivities?" Tags="&lt;kalman-filter&gt;&lt;quadcopter&gt;&lt;imu&gt;&lt;uav&gt;" AnswerCount="1" />
  <row Id="1287" PostTypeId="2" ParentId="1286" CreationDate="2013-05-11T18:05:28.830" Score="2" Body="&lt;p&gt;I think you're mixing two meanings of the word &quot;sensitive&quot;.  &lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Input Sensitivity&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;If you have an IMU that gives very raw (&quot;twitchy&quot;) readings, then you should be able to generate the output of a less input-sensitive IMU by simply computing a &lt;a href=&quot;https://en.wikipedia.org/wiki/Moving_average&quot; rel=&quot;nofollow&quot;&gt;moving average&lt;/a&gt; or using a Kalman filter on the output.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This will produce an effect similar to running a low-pass filter on the output signal; the ability of your filter to reject noise will determine how much accuracy you salvage in this process of subsampling.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Output Sensitivity&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Accelerometers produce analog output, and in many accelerometers you can adjust the number of $mV/g$ that the reading will be.  This is just the scale factor that lets you match the (expected) output of the IMU to the range of your ADC, in order to get the most precision.  So, your intuition is correct -- you could get 2 accelerometers and mix low and high sensitivity to get better precision when reading slight movements.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Whether It Matters&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Ultimately, an IMU that you can buy for less than $50,000 has a limit to its accuracy, and will never be accurate enough for you to use it without other navigational aids -- compasses, GPS units, etc.  Since your vehicle is really only able to react to a certain range of forces, its accelerometers should be tuned to that range.  So, if you have 2 different operating modes that involve 2 different ranges of forces then it might be a good idea to use multiple accelerometers; otherwise, it will produce data that is interesting but not practical (and give you one more source of noise to calibrate).&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-05-12T23:15:37.837" LastActivityDate="2013-05-12T23:15:37.837" CommentCount="1" />
  <row Id="1289" PostTypeId="2" ParentId="1279" CreationDate="2013-05-12T16:11:32.067" Score="2" Body="&lt;p&gt;It's great that you are taking an initiative in building/replicating one like EZ-Robot. I would like to add a few things which helps in building a robot:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;1) Simplicity.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;2) Cost Factor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;By simplicity I mean choosing the right hardware that actually helps your prototype to be built faster and the testing/debugging is easier. For instance, if you choose &lt;a href=&quot;http://en.wikipedia.org/wiki/Raspberry_Pi&quot; rel=&quot;nofollow&quot;&gt;Raspberry Pi&lt;/a&gt; with a Wi-Fi module (I saw one at Adafruit stores for around US$12), the whole setup may be build under US$50. Adding computer vision (I think this will boost up the investment price) since it already runs Linux on it, helps in achieving the ease in usability and development. Now you have a system that can be controlled by many components. Using a &lt;a href=&quot;http://en.wikipedia.org/wiki/Bluetooth&quot; rel=&quot;nofollow&quot;&gt;Bluetooth&lt;/a&gt; module with Raspberry Pi is much cheaper than you may think. Chinese modules are cheap, like US$5-US$10. Hereby you will have an independent robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But as you say, you wish to remotely control, the Arduino keeping your PC (since you mentioned Visual Studio), this can be done easily by adding a Wi-Fi module, but &lt;a href=&quot;http://en.wikipedia.org/wiki/XBee&quot; rel=&quot;nofollow&quot;&gt;Xbee&lt;/a&gt; costs are really high, and then use the &lt;a href=&quot;http://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol&quot; rel=&quot;nofollow&quot;&gt;HTTP&lt;/a&gt; protocol to control the robot. The Arduino will be fed with some input, like say numbers ranging from 1-100 that may accumulate 100 tasks. Like move left, right, up down, turn on the light, etc. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So essentially make sure, which development board may help you serve the purpose easily.&lt;/p&gt;&#xA;" OwnerUserId="1303" LastEditorUserId="1906" LastEditDate="2013-11-06T23:40:15.100" LastActivityDate="2013-11-06T23:40:15.100" />
  <row Id="1290" PostTypeId="1" CreationDate="2013-05-13T06:59:32.290" Score="2" ViewCount="192" Body="&lt;p&gt;I have arduino code for operating 2 servos, but we are using 4 servos and am having trouble getting the other 2 to talk. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The program so far as I can make out is that the angles for the servos that are calculated by the processing side are being sent out one after the other (shoulder, elbow, wrist, wrist2) then repeated. The arduino program gets this data and stores in into an array and then is written to the pin of the appropriate array segment. So 0 is shoulder, 1 is elbow, 2 is wrist and 3 is wirst2. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I can easily get 2 servos to run with no problem.  But when I try and add 1 or 2 more we get no response.  Can anyone please help me to get the other 2 servos to work?  My knowledge on this code is rather limited, so any help is appreciated.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;processing Data being sent to the arduino:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;byte out[] = new byte[4];&#xA;out[0] = byte(shoulderAngle);&#xA;out[1] = byte(elbowAngle);&#xA;out[2] = byte(wristAngle);&#xA;out[3] = byte(wrist2Angle);&#xA;port.write(out);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Arduino Code:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#include &amp;lt;Servo.h&amp;gt;&#xA;&#xA;//Declares the servos.&#xA;Servo shoulder;&#xA;Servo elbow;&#xA;Servo wrist;&#xA;Servo wrist2;&#xA;&#xA;//Setup servo positions.&#xA;int nextServo = 0;&#xA;int servoAngles[] = {0, 0};&#xA;&#xA;//Define pins for each servo.&#xA;void setup()&#xA;  {&#xA;  shoulder.attach(50);&#xA;  elbow.attach(51);&#xA;  wrist.attach(52);&#xA;  wrist2.attach(53);&#xA;&#xA;  Serial.begin(9600);&#xA;}&#xA;&#xA;void loop()&#xA;{&#xA;  if(Serial.available())&#xA;  {&#xA;    int servoAngle = Serial.read();  &#xA;&#xA;    servoAngles[nextServo] = servoAngle;  &#xA;    nextServo++;  &#xA;&#xA;    if(nextServo &amp;gt; 3)&#xA;    {&#xA;      nextServo = 0;  &#xA;    }&#xA;&#xA;    shoulder.write(servoAngles[0]);&#xA;    elbow.write(servoAngles[1]);&#xA;    wrist.write(servoAngles[2]);&#xA;    wrist2.write(servoAngles[3]);&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Sorry for the lengthy post but have been stuck for a while. &lt;/p&gt;&#xA;" OwnerUserId="1307" LastEditorUserId="350" LastEditDate="2013-05-13T14:20:32.990" LastActivityDate="2013-05-13T14:30:44.763" Title="Issues upgrading Arduino code for Kinect controlled arm from 2 servos to 4" Tags="&lt;arduino&gt;&lt;kinect&gt;&lt;robotic-arm&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="1292" PostTypeId="2" ParentId="1290" CreationDate="2013-05-13T14:30:44.763" Score="1" Body="&lt;p&gt;I can see two potential problems.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The first is that you're only declaring the servoAngles array to have two elements:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;int servoAngles[] = {0, 0};&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Your code is equivalent to this:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;int servoAngles[2];&#xA;servoAngles[0] = 0;&#xA;servoAngles[1] = 0;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Later, you're assigning values to &lt;code&gt;servoAngles[2]&lt;/code&gt; and &lt;code&gt;servoAngles[3]&lt;/code&gt;, which are out of the bounds of your original array -- this is very bad practice.  Instead, you should be declaring the servoAngles array the same way you're declaring and initializing your &lt;code&gt;byte out[]&lt;/code&gt; array -- it should be declared and/or initialized with 4 elements, as you require.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The other problem that I can see is that you're reading 1 &lt;code&gt;servoAngle&lt;/code&gt; value every time you loop, but you're writing all 4.  That means that every 4th byte is automatically going to be sent to the same servo, regardless of whether things get out of sync.  (You would recognize this problem as the proper angle being put at the wrong joint.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Normally, you'd read all 4 values at once (followed by a newline, or some special sequence of characters that indicates the end of the info) and write all 4 values at once.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-05-13T14:30:44.763" CommentCount="8" />
  <row Id="1294" PostTypeId="1" AcceptedAnswerId="1296" CreationDate="2013-05-14T19:46:34.603" Score="6" ViewCount="118" Body="&lt;p&gt;Concerning robots which rotate at high speed by spinning the drive motors in opposite directions, while still being able to simultaneously move in a direction (translate):&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As far as I know this originated with competitive fighting robots, where it is known as &quot;melty brain&quot; or &quot;tornado drive,&quot; according to wikipedia, and is based on alternately slowing down the motors on either side as they revolve around the centre of mass.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, with the whole body spinning so fast how is the current &quot;heading&quot; of the robot established and maintained?&lt;/p&gt;&#xA;" OwnerUserId="1316" LastActivityDate="2013-05-15T07:01:53.087" Title="What are the mechanics of translational drift?" Tags="&lt;navigation&gt;&lt;movement&gt;" AnswerCount="1" />
  <row Id="1295" PostTypeId="2" ParentId="1072" CreationDate="2013-05-15T06:56:56.820" Score="0" Body="&lt;p&gt;Another group that is working on Kite-flying robots is Professor Srikanth Saripalli's group at Arizona State University. Perhaps looking into that, their videos and contacting them would give you additional perspective.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://sese.asu.edu/person/srikanth-saripalli&quot; rel=&quot;nofollow&quot;&gt;Professor Srikanth Saripalli's Homepage&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://robotics.asu.edu/projects/autokite/&quot; rel=&quot;nofollow&quot;&gt;Kite-Flying Robot Team - Webpage and Videos&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="333" LastActivityDate="2013-05-15T06:56:56.820" />
  <row Id="1296" PostTypeId="2" ParentId="1294" CreationDate="2013-05-15T07:01:53.087" Score="3" Body="&lt;p&gt;Okay, so most(if not all) transational drift robots or meltys use an acceleorometer to indicate the heading of the robot. What this acceleorometer does is calculates the rate of rotation based on G-forces around a given radius. The data that is accumulated from the accelerometer is then used to light up an LED once per rotation - giving and indication of the heading of the robot. The driver or user then uses this LED to decide using the remote control the direction he wants to traverse to.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As for the moving, as mundane it might sound is done by switching the motor on and off. &#xA;The program or the control of the system turns a motor on when that motor is in the correct position to result in a net movement the direction the robot is indicated to go to.&#xA;So for example the LED is lit between 30 and 120 degrees it can be interpreted as the direction of the robot would be around 90 degrees.(Keep in mind that the indications of the heading using the LED is not a 100% accurate, the might be off by more than some tens of degrees. Usually because of the time taken for all the data processing and the time taken to switch the LED's on and off). If you wanted to move forward now, the motors would be needed to be on between 270 and 450(360+90) degrees during each rotation after which the net direction of travel will be 90 degrees.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Likewise if the robot wants to go to the left that is 180 degrees, but its current heading is 90. The motors will need to be on between 0 and 180 degrees. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Hope that helps.&lt;/p&gt;&#xA;" OwnerUserId="1213" LastActivityDate="2013-05-15T07:01:53.087" />
  <row Id="1297" PostTypeId="2" ParentId="1211" CreationDate="2013-05-15T14:29:41.487" Score="1" Body="&lt;p&gt;IR sensor are best used for detecting any thing but they are quite sensitive to IR lights and sunlight.So if in condition when you are not bothering about Ir rays and sunlight , you can always use a pair of IR LED and Photodiode to make a pair of IR sensor.&lt;/p&gt;&#xA;" OwnerUserId="1322" LastActivityDate="2013-05-15T14:29:41.487" CommentCount="1" />
  <row Id="1298" PostTypeId="2" ParentId="1279" CreationDate="2013-05-15T21:48:54.160" Score="2" Body="&lt;p&gt;Certainly you can.  You need a firmware for the Arduino that accepts remote control commands over the COM channel.  Take a look at &lt;a href=&quot;https://github.com/JayBeavers/Reflecta&quot; rel=&quot;nofollow&quot;&gt;Reflecta&lt;/a&gt; or &lt;a href=&quot;https://github.com/firmata/arduino&quot; rel=&quot;nofollow&quot;&gt;Firmata&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I made something like this called &lt;a href=&quot;http://blog.jaybeavers.org/2012/08/rocketbot-at-maker-faire-2012.html&quot; rel=&quot;nofollow&quot;&gt;RocketBot&lt;/a&gt; for Bay Area Maker Faire 2012.  This was a PC remote controlling two Arduinos which ran the motors, a pneumatic rocket launcher, plus a siren and a warning light.  I'll be posting a simpler version of this design that uses more off the shelf parts in a few weeks to the same blog.  This one will have a bluetooth connection to the Arduino in addition to USB.&lt;/p&gt;&#xA;" OwnerUserId="35" LastActivityDate="2013-05-15T21:48:54.160" />
  <row Id="1299" PostTypeId="1" CreationDate="2013-05-16T12:12:15.660" Score="2" ViewCount="944" Body="&lt;p&gt;I'm trying to send arduino sensor data to a server using a GPRS shield (sim900 shield from geeetech &lt;a href=&quot;http://www.geeetech.com/wiki/index.php/Arduino_GPRS_Shield&quot; rel=&quot;nofollow&quot;&gt;http://www.geeetech.com/wiki/index.php/Arduino_GPRS_Shield&lt;/a&gt;). I have this particular set up because the data will be updated to a website and the device will be roaming. I can't use &lt;a href=&quot;http://www.cosm.org&quot; rel=&quot;nofollow&quot;&gt;http://www.cosm.org&lt;/a&gt; because to the best of my knowledge that only updates every 15 minutes, I need to update about every 5-10 seconds.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In order to connect I tried the code below to form UDP connection but it does not get sent through to the receiving IP and port. I dont know why. No errors occur on the arduino side, and the server side has been shown to work with an iPhone app that sends a UDP message.&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;///connect&#xA;void connectUDP()&#xA;{&#xA; mySerial.println(&quot;AT+CSTT=\&quot;APN\&quot;&quot;);&#xA; delay(3000);&#xA; ShowSerialData();&#xA; mySerial.println(&quot;AT+CIICR&quot;);&#xA; delay(3000);&#xA; ShowSerialData();&#xA; mySerial.println(&quot;AT+CIFSR&quot;);&#xA; delay(3000);&#xA; ShowSerialData();&#xA; mySerial.println(&quot;AT+CIPSTART=\&quot;UDP\&quot;,\&quot;SERVER IP\&quot;,\&quot;SERVER PORT\&quot;&quot;);&#xA; delay(3000);&#xA; ShowSerialData();&#xA; mySerial.println();&#xA;&#xA;}&#xA;&#xA;&#xA;///send udp packet to server &#xA;void sendUDP()&#xA;{&#xA; for(int x = 0; x &amp;lt; 30; x++){&#xA;   mySerial.println(&quot;AT+CIPSEND&quot;); &#xA;   delay(100);&#xA;   ShowSerialData();&#xA;   mySerial.println(&quot;\&quot;hello world\&quot;&quot;);&#xA;   delay(100);&#xA;   ShowSerialData();&#xA;   mySerial.println((char)26);&#xA;   delay(1000);&#xA;   ShowSerialData();&#xA; }&#xA; mySerial.println();&#xA; //ShowSerialData();&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;The server side is as follows (written in python):&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;import SocketServer&#xA;&#xA;PORTNO = 14&#xA;&#xA;class handler(SocketServer.DatagramRequestHandler):&#xA;    def handle(self):&#xA;        newmsg = self.rfile.readline().rstrip()&#xA;    print (newmsg)&#xA;        self.wfile.write(self.server.oldmsg)&#xA;        self.server.oldmsg = newmsg&#xA;&#xA;s = SocketServer.UDPServer(('',PORTNO), handler)&#xA;print &quot;Awaiting UDP messages on port %d&quot; % PORTNO&#xA;s.oldmsg = &quot;This is the starting message.&quot;&#xA;s.serve_forever()&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I can see a possible solution might be to change it to a TCP connection, but I don't know how to do that...&lt;/p&gt;&#xA;" OwnerUserId="1328" LastEditorUserId="350" LastEditDate="2013-05-17T19:58:27.680" LastActivityDate="2013-05-17T19:58:27.680" Title="Send arduino sensor data to server with GPRS shield" Tags="&lt;arduino&gt;&lt;sensors&gt;&lt;raspberry-pi&gt;&lt;programming-languages&gt;&lt;python&gt;" CommentCount="5" />
  <row Id="1301" PostTypeId="1" CreationDate="2013-05-17T19:08:13.547" Score="5" ViewCount="601" Body="&lt;p&gt;I just got a kit and im not sure if its me or not but it appears one of the continuous servos might be broken. What happened first when I plugged it into the microcontroller, it made a humming sound when I sent it commands. The second continuous servo didnt work at all&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I played around with different ports on the aurdino based board, and to no avail, just a &lt;strong&gt;hum&lt;/strong&gt;.&#xA;Then I removed the humming servo altogether and just placed the second servo alone. the second continuous servo started to move in whatever direction I asked it to. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I plugged the first one in, only the second moved.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;then I tried spinning them by hand, the second has much resistance, while the first one has dramatically less resistance, maybe 60% easier to spin by hand.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is this something I can fix? Has anyone experienced these problems before?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks in advance, you guys are great!&lt;/p&gt;&#xA;" OwnerUserId="1281" LastEditorUserId="350" LastEditDate="2013-05-17T20:00:38.957" LastActivityDate="2013-06-01T12:33:10.207" Title="What are the signs that a servo might be broken?" Tags="&lt;arduino&gt;&lt;microcontroller&gt;&lt;servos&gt;&lt;wheeled-robot&gt;" AnswerCount="3" CommentCount="2" />
  <row Id="1302" PostTypeId="1" AcceptedAnswerId="1303" CreationDate="2013-05-18T04:01:29.997" Score="3" ViewCount="64" Body="&lt;p&gt;Following, the &lt;a href=&quot;http://robotics.stackexchange.com/questions/1235/how-does-rocker-bogie-keep-the-body-almost-flat&quot;&gt;previous question&lt;/a&gt;, I am trying to calculate how much one rocker would rotate when the other is being rotated. I attached my calculation here.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am trying calculate the rotation of gear B that connects to right rocket. Given gear A rotates at 0.05 rad, what is the rotation of gear B in rad? Gear ratio A:D is 4:1, and D:B is 1:4.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;At the end, I ended up with rotational gear A = gear B. This somewhat puzzles me. Is my calculation correct?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/HDtsx.jpg&quot; alt=&quot;My calculation given rotation of gear A that connects to left rocker&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="1167" LastActivityDate="2013-05-18T04:32:03.793" Title="Rotation ratio between left rocker and right rocker in rocker-bogie system" Tags="&lt;wheeled-robot&gt;" AnswerCount="1" FavoriteCount="1" />
  <row Id="1303" PostTypeId="2" ParentId="1302" CreationDate="2013-05-18T04:32:03.793" Score="3" Body="&lt;p&gt;Your calculation is correct in magnitude but incorrect in sign, because gear B rotates oppositely to A (when the axis of D is fixed and D is not locked).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If D is locked (ie, the gear is not free to rotate in its plane) then A and B are locked together and rotate identically.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If the body V to which the axis of D is fixed rotates during rotation of A, then the rotation rate of B will differ from that of A.  Example: Let rotation directions for A, B, and V be stated relative to a view from the left, and for D  relative to a view from above.  With V fixed, suppose A rotates CW at 40 rpm.  Then D rotates CCW at 10 rpm, driving B CCW at 40 rpm.  If V now begins to rotate CW  at 20 rpm, D's rotation rate drops to 5 rpm, so that B begins to rotate at -20 rpm relative to A, 0 rpm relative to V, and 20 rpm to the frame of reference.&lt;/p&gt;&#xA;" OwnerUserId="478" LastActivityDate="2013-05-18T04:32:03.793" CommentCount="3" />
  <row Id="1304" PostTypeId="2" ParentId="1301" CreationDate="2013-05-18T07:35:30.943" Score="7" Body="&lt;p&gt;&lt;strong&gt;How Servos Work&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Based on these details of your question:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;I just got a kit [...] continuous servos [...] plugged it into the&#xA;  microcontroller&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Combined with your &quot;Arduino&quot; tag, I'm betting that you are working with hobby (RC) servos modified for continuous rotation. Standard servos work by receiving a pulsed signal with a 20ms period (50Hz). Regular hobby servos will rotate to a specific angle based on the duty cycle (ON time) of the pulsed control signal. This on time can range from 500us to 2500us, but usually only a range of 1000us to 2000us is used so as to not damage the servo. The &quot;neutral pulse&quot; of 1500us will put the servo in the center position.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This &lt;a href=&quot;http://en.wikipedia.org/wiki/Servo_control&quot;&gt;Wikipedia article&lt;/a&gt; about servo control has a great picture regarding the pulsed control:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/j8bB5.jpg&quot; alt=&quot;Servo Pulses&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are a few different ways that the servo works, but the most common type I've seen in use by hobbyists is an analog servo. As the motor turns, an internal potentiometer is adjusted creating a feedback path for the internal circuitry. The servo will continue to rotate until the potentiometer is at the expected position for the given pulse width.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are &lt;em&gt;numerous&lt;/em&gt; different ways of modifying a standard hobby servo for continuous rotation, so I won't go into that, but essentially, this feedback path is tampered with such the servo never thinks it is in the correct position when it gets a non &quot;neutral&quot; pulse. A mechanical stop on the internal gears is also removed. Once this is done, sending a non neutral pulse will cause the servo to rotate completely, with the speed of rotation dependent upon the pulse width.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Your Issue&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When a non-modified servo is given a pulse, it will quickly rotate to the desired position and hold it as long as a pulse is being sent. It should be very difficult to manually turn the servo at this time, and doing so will cause the internal motor to hum as it draws excessive current trying to correct itself during this overload situation. If the servo is disabled (receiving no pulse) it can be manually manipulated with ease.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A modified servo will exhibit similar behavior when under too much of a load - it will hum loudly and draw excessive current. While your servo may not be overloaded, it is obviously exhibiting similar symptoms and is most likely defective. When being driven, manually turning the actuator or stopping it from turning in its desired direction/speed is not a good idea, so keep that in mind for your other servos.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When the defective servo tries to rotate, it is drawing so much current that the second servo cannot operate. That is why it worked fine once the defective servo was removed.&lt;/p&gt;&#xA;" OwnerUserId="1197" LastActivityDate="2013-05-18T07:35:30.943" CommentCount="1" />
  <row Id="1305" PostTypeId="1" CreationDate="2013-05-18T22:24:53.173" Score="2" ViewCount="237" Body="&lt;p&gt;I recently have been working on a little project. Unfortunately, I've ran into a bit of a road block with controlling servos using serial commands. The servos do appear to move when i put in any character into serial, but only a little. When i type in say, 90 characters of random gibberish, both servos connected to my arduino move several degrees. Here's my code:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#include &amp;lt;Servo.h&amp;gt;&#xA;Servo ULF; // Upper left front servo&#xA;Servo LLF; // Lower left front servo&#xA;byte index = 0;&#xA;int commandnum=1;&#xA;int steps = 0; // position of LLF servo&#xA;int partnum = 0; // unused for now&#xA;String command = &quot;&quot;; // the command we're building&#xA;void setup()&#xA;{&#xA;  LLF.attach(0);&#xA;  ULF.attach(1);&#xA;  Serial.begin(9600);&#xA;}&#xA;&#xA;void loop()&#xA;{&#xA;  while(Serial.available() &amp;gt; 0) { // while there are more than zero bytes to read&#xA;      char in = Serial.read();&#xA;      if(in=='!') {&#xA;             //! is escape character&#xA;       commandnum++;&#xA;       partnum = 0;&#xA;       Serial.println(&quot;New Command. Command #: &quot;+commandnum);&#xA;        break;&#xA;      }&#xA;      command+=in;&#xA;      if(in == ' ') {&#xA;        partnum++;&#xA;        //if we have a space, there's a new section to the command&#xA;      }&#xA;      if(command == &quot;LLF&quot;) {&#xA;        Serial.read(); //skip a space&#xA;&#xA;        Serial.println(&quot;Lower Left Foot Selected.&quot;);&#xA;        int angle = Serial.parseInt(); // find the angle we want&#xA;        Serial.println(&quot;ANGLE: &quot;+String(angle));&#xA;&#xA;        for(int pos = 0; pos &amp;lt; angle; pos++) // for loop through positions to reach goal&#xA;        {                                  &#xA;           LLF.write(pos); // write servo position&#xA;           delay(15);&#xA;        } &#xA;        for(int pos = angle; pos &amp;gt; 0; pos--) // for loop through positions to reach goal&#xA;        {                                  &#xA;           LLF.write(pos); // write servo position&#xA;           delay(15);&#xA;        } &#xA;      }&#xA;   }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Any help would be much appreciated.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT: Another note, nothing is printed in the serial monitor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, these are micro towerpro rc servos.&lt;/p&gt;&#xA;" OwnerUserId="498" LastEditorUserId="498" LastEditDate="2013-05-20T16:42:58.297" LastActivityDate="2013-06-12T19:07:24.833" Title="Controlling Robots Through Serial" Tags="&lt;arduino&gt;&lt;rcservo&gt;&lt;serial&gt;&lt;c++&gt;" AnswerCount="3" CommentCount="4" />
  <row Id="1306" PostTypeId="1" AcceptedAnswerId="1307" CreationDate="2013-05-19T04:25:44.473" Score="1" ViewCount="82" Body="&lt;p&gt;I was jogging the ABB IRB1410 and I noticed that the servo motors are humming even when the joints are not moving. The motor cuts off only when the guard switch in the flex pendant is released.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What kind of mechanism which require the drive motors to keep running even when the joints are not moving ?&lt;/strong&gt; I went through the manual but no luck. I suppose the holding torque is provided by some braking mechanism so I think I can rule it out.&lt;/p&gt;&#xA;" OwnerUserId="105" LastEditorUserId="37" LastEditDate="2013-05-20T15:33:38.593" LastActivityDate="2013-05-20T15:33:38.593" Title="Why are the IRB 1410's servos running even when the joints are not moving?" Tags="&lt;industrial-robot&gt;&lt;servomotor&gt;" AnswerCount="1" />
  <row Id="1307" PostTypeId="2" ParentId="1306" CreationDate="2013-05-19T12:26:44.450" Score="1" Body="&lt;p&gt;The motors in ABB robots have integrated brakes that are &lt;strong&gt;engaged when not energized&lt;/strong&gt;. They hold the position of the joint and prevent the arm from falling if power is lost. The flex pendant enable switch actually drives a relay in the controller that removes or applies all power to the motors. This is done for safety reasons, so that in the event of a mishap (i.e, you drop the pendant), the robot becomes completely de-engerized.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When you enable the robot for jogging, it disengages the brake, applies power to the servo, and uses the static torque to hold the joint position instead of the brake. When you release the switch or cut the power in some other way, the brakes engage again.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Search Google for &quot;Product manual Motor Unit MU10/20/30&quot; for more details.&lt;/p&gt;&#xA;" OwnerUserId="479" LastEditorUserId="479" LastEditDate="2013-05-19T14:33:59.070" LastActivityDate="2013-05-19T14:33:59.070" />
  <row Id="1308" PostTypeId="5" CreationDate="2013-05-20T15:31:02.507" Score="0" ViewCount="6" Body="&lt;p&gt;An &lt;a href=&quot;http://en.wikipedia.org/wiki/Servomechanism#RC_servos&quot; rel=&quot;nofollow&quot;&gt;rc or hobby servo&lt;/a&gt; is a closed-loop servomechanism, typically used in &lt;a href=&quot;http://en.wikipedia.org/wiki/Radio-controlled_model&quot; rel=&quot;nofollow&quot;&gt;radio control model&lt;/a&gt;, hobby or small-scale robotics applications. It usually consists of a motor coupled to a sensor (e.g. potentiometer) for position feedback, typically using a high ratio gearbox.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;sub&gt; See &lt;a href=&quot;http://meta.robotics.stackexchange.com/q/170/37&quot;&gt;What should we do about servo questions?&lt;/a&gt; &lt;/sub&gt;&lt;/p&gt;&#xA;" OwnerUserId="37" LastEditorUserId="37" LastEditDate="2013-05-20T16:21:55.543" LastActivityDate="2013-05-20T16:21:55.543" />
  <row Id="1309" PostTypeId="4" CreationDate="2013-05-20T15:31:02.507" Score="0" Body="An rc or hobby servo is a closed-loop servomechanism, typically used in radio control model, hobby or small-scale robotics applications. It usually consists of a motor coupled to a sensor (e.g. potentiometer) for position feedback, typically using a high ratio gearbox.&#xD;&#xA;" OwnerUserId="37" LastEditorUserId="37" LastEditDate="2013-05-20T16:21:55.543" LastActivityDate="2013-05-20T16:21:55.543" />
  <row Id="1310" PostTypeId="5" CreationDate="2013-05-20T15:31:56.337" Score="0" ViewCount="2" Body="&lt;p&gt;A &lt;a href=&quot;http://en.wikipedia.org/wiki/Servomotor&quot; rel=&quot;nofollow&quot;&gt;servomotor&lt;/a&gt; is a closed-loop servomechanism, typically used in industrial applications. It usually consists of a motor coupled to a sensor (e.g. encoder) for precision position feedback, typically using a low ratio gearbox or direct drive.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;sub&gt; See &lt;a href=&quot;http://meta.robotics.stackexchange.com/q/170/37&quot;&gt;What should we do about servo questions?&lt;/a&gt; &lt;/sub&gt;&lt;/p&gt;&#xA;" OwnerUserId="37" LastEditorUserId="37" LastEditDate="2013-05-20T15:31:56.337" LastActivityDate="2013-05-20T15:31:56.337" />
  <row Id="1311" PostTypeId="4" CreationDate="2013-05-20T15:31:56.337" Score="0" Body="A servomotor is a closed-loop servomechanism, typically used in industrial applications. It usually consists of a motor coupled to a sensor (e.g. encoder) for precision position feedback, typically using a low ratio gearbox or direct drive." OwnerUserId="37" LastEditorUserId="37" LastEditDate="2013-05-20T15:31:56.337" LastActivityDate="2013-05-20T15:31:56.337" />
  <row Id="1312" PostTypeId="5" CreationDate="2013-05-20T15:34:11.770" Score="0" ViewCount="6" Body="&lt;p&gt;A &lt;a href=&quot;http://en.wikipedia.org/wiki/Servomotor&quot; rel=&quot;nofollow&quot;&gt;servomotor&lt;/a&gt; is a closed-loop servomechanism. It usually consists of a motor coupled to a sensor (e.g. encoder) for precision position and/or speed feedback, typically using a low ratio gearbox or direct drive.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;sub&gt; See &lt;a href=&quot;http://meta.robotics.stackexchange.com/q/170/37&quot;&gt;What should we do about servo questions?&lt;/a&gt; &lt;/sub&gt;&lt;/p&gt;&#xA;" OwnerUserId="37" LastEditorUserId="2447" LastEditDate="2014-01-14T19:51:15.633" LastActivityDate="2014-01-14T19:51:15.633" />
  <row Id="1313" PostTypeId="4" CreationDate="2013-05-20T15:34:11.770" Score="0" Body="A servomotor is a closed-loop servomechanism, typically used in industrial applications. It usually consists of a motor coupled to a sensor (e.g. encoder) for precision position feedback, typically using a low ratio gearbox or direct drive." OwnerUserId="37" LastEditorUserId="37" LastEditDate="2013-05-20T15:34:11.770" LastActivityDate="2013-05-20T15:34:11.770" />
  <row Id="1314" PostTypeId="1" CreationDate="2013-05-22T21:22:13.977" Score="13" ViewCount="168" Body="&lt;p&gt;I am currently debugging and tuning an EKF (Extended Kalman Filter). The task is classical mobile robot pose tracking where landmarks are AR markers.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Sometimes I am surprised how some measurement affects the estimate. When I look at and calculate the numbers and matrices involved, I can work out how the update step got executed, what and why exactly happened, but this is very tedious. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So I wonder if anyone is using some technique, trick or clever visualization to get a better feel of what is happening in the EKF update step?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;UPDATE #1&lt;/strong&gt; (will be more specific and show first approximation of what I have in mind)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What I am looking for, is some way to visualize one update step in a way that gives me a feel of how each component of the measurement affects each component of the state.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My very first idea is to plot the measurement and it's prediction together with some vectors taken from the K matrix. The vectors from K represent how the innovation vector (measurement - measurement prediction, not plotted) will affect each component of the state.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Currently I am working with an EKF where the state is 2D pose (x,y,angle) and the measurements are also 2D poses.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://i.stack.imgur.com/9rLjB.png&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/9rLjB.png&quot; alt=&quot;Plot of update step&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the attached image(open it in new page/tab to see in full resolution), the (scaled) vector K(1,1:2) (MATLAB syntax to take a submatrix from 3x3 matrix) should give an idea how the first component of the EKF state will change with the current innovation vector, K(2,1:2) how the second component of EKF will change, etc. In this example, the innovation vector has a relatively large x component and it is aligned with vector K(2,1:2) - the second component of the state (y coordinate) will change the most.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One problem in this plot is that it does not give a feel of how the third component(angle) of the innovation vector affects the state. The first component of the state increases a bit, contrary to what K(1:1:2) indicates - the third component of the innovation causes this, but currently I can not visualize this.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;First improvement would be to visualize how the third component of the innovation affects the state. Then it would be nice to add covariance data to get a feel how the K matrix is created.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;UPDATE #2&lt;/strong&gt; Now the plot has vectors in state-space that show how each component of measurement changes the position. From this plot, I can see that the third component of the measurement changes the state most.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://i.stack.imgur.com/PfIEN.png&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/PfIEN.png&quot; alt=&quot;Added vectors corresponding to each component of measurement to state-space&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1350" LastEditorUserId="350" LastEditDate="2013-07-26T14:54:56.793" LastActivityDate="2013-12-25T20:35:45.613" Title="Visualizing and debugging an EKF" Tags="&lt;ekf&gt;&lt;visualization&gt;" AnswerCount="2" CommentCount="3" FavoriteCount="3" />
  <row Id="1315" PostTypeId="1" CreationDate="2013-05-23T03:00:11.017" Score="2" ViewCount="96" Body="&lt;p&gt;I am building 4-wheeled, knee-high robot with music and speakers on top that will follow a target person as the target moves around. I would like some help with the setup for tracking the target. The most obvious solutions are Ultrasound or Infrared sensors or some kind of vision tracking, but for this application, I don't want to use them. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Imagine that the robot is placed into a crowded area and asked to move towards a particular person in the area (for the sake of simplicity, assume the person is less than 5 meters away, but could be obscured by an object). Ideally, if someone walked between the target and the robot, the robot would not lose it's path (as would happen with vision-based sensing).&lt;br&gt;&#xA;Thanks!&lt;/p&gt;&#xA;" OwnerUserId="1354" LastEditorUserId="1354" LastEditDate="2013-05-23T03:19:51.517" LastActivityDate="2013-05-23T21:21:47.063" Title="Non-Vision Based Target Tracking" Tags="&lt;sensors&gt;&lt;computer-vision&gt;&lt;navigation&gt;" AnswerCount="2" CommentCount="4" />
  <row Id="1316" PostTypeId="2" ParentId="1315" CreationDate="2013-05-23T04:47:48.240" Score="1" Body="&lt;p&gt;There are a few ways you might handle this.  Although my knee-jerk response is to say &quot;transmit a radio signal from the target and triangulate it with 3 antennas on the robot&quot;, apparently the implementation of that is really difficult (&lt;a href=&quot;http://electronics.stackexchange.com/a/8693&quot;&gt;1&lt;/a&gt; &lt;a href=&quot;http://forums.hackaday.com/viewtopic.php?f=8&amp;amp;t=2420&quot; rel=&quot;nofollow&quot;&gt;2&lt;/a&gt; &lt;a href=&quot;http://www.eetimes.com/design/microwave-rf-design/4019032/Wireless-triangulation-using-RSSI-signals&quot; rel=&quot;nofollow&quot;&gt;3&lt;/a&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Although it sounds heavy-handed, the best way to do what you're describing is to put a GPS on both the robot and the target, and have the target communicate its location back to the robot.  Assuming that you don't lose wireless connectivity -- 5 meters is within the range of bluetooth, zigbee, wifi, and 3G -- obstacles will not hamper the ability of the robot to find its target; you just &lt;a href=&quot;http://www.movable-type.co.uk/scripts/latlong.html&quot; rel=&quot;nofollow&quot;&gt;use the haversine formula to draw a path between those two points&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Of course, if you're going to let a knee-high robot loose in a crowded area, it would be common courtesy for it to have adequate ultrasonic/vision sensors to be able to &lt;a href=&quot;http://stream1.gifsoup.com/view5/2689564/peter-skint-knee-o.gif&quot; rel=&quot;nofollow&quot;&gt;avoid bumping into passerby&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-05-23T04:47:48.240" />
  <row Id="1317" PostTypeId="2" ParentId="1314" CreationDate="2013-05-23T12:48:07.110" Score="0" Body="&lt;p&gt;Something that is often done is to plot the state variables over time as well as their 3-sigma intervals. Points where this interval shrinks are the updates, where you could possibly annotate the source of the measurements involved.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Besides errors in implementation which should be checked (not only wrong equations, but numerically unstable equations as well), the effect of updates is only directly affected by the difference between what is &quot;expected&quot; and &quot;measured&quot; and their respective uncertainties. So you might be interested in figuring out a way to visualize this balance in terms of the time progression in the first plot.&lt;/p&gt;&#xA;" OwnerUserId="95" LastActivityDate="2013-05-23T12:48:07.110" />
  <row Id="1318" PostTypeId="1" CreationDate="2013-05-23T00:48:32.153" Score="8" ViewCount="103" Body="&lt;p&gt;I am building a robot that will follow a target as the target moves around. I would like some help with the setup for tracking the target. The most obvious solutions are Ultrasound or Infrared sensors, but for this application, they won't work. Imagine that the robot is placed into a crowded area and asked to move towards a particular person in the area (for the sake of simplicity, assume the person is less than 5 meters away). Is there some kind of radar or radio solution to this, or anything?&lt;/p&gt;&#xA;" OwnerUserId="1354" OwnerDisplayName="RJackson" LastEditorUserId="314" LastEditDate="2013-05-23T17:39:43.370" LastActivityDate="2013-05-23T21:17:08.487" Title="Robotics Location Following and Tracking?" Tags="&lt;mobile-robot&gt;&lt;sensors&gt;&lt;electronics&gt;" AnswerCount="2" CommentCount="3" />
  <row Id="1319" PostTypeId="2" ParentId="1318" CreationDate="2013-05-23T02:23:14.050" Score="2" Body="&lt;p&gt;In a broad sense, there are a couple of ways to do this, but they basically boil down to the problem of &lt;em&gt;how do you know what person you're going towards?&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If it's feasible to give the person a flashlight or some light source (IR or visible), you could use light sensitive elements to determine where to go.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Magnetic fields could also be used, by giving the person in question a strong enough magnet.  (But it would have to be pretty strong, so I don't think this is as feasible...)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A final resort would be to attempt some form of a vision system.  For instance, if you gave the person a lime-green ball, a vision system could pick up on that, and treat it as a target.&lt;/p&gt;&#xA;" OwnerUserId="314" OwnerDisplayName="anorton" LastActivityDate="2013-05-23T02:23:14.050" CommentCount="2" />
  <row Id="1320" PostTypeId="1" AcceptedAnswerId="1325" CreationDate="2013-05-23T18:21:33.780" Score="0" ViewCount="250" Body="&lt;p&gt;I bought a new Roboduino atmega 328 board. Basically Roboduino is a modded version of Arduino UNO made by robokits.co.in. The problem is &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;On Windows Plaform:&lt;/strong&gt;&#xA;When I tried to upload a simple Blink program that's listed in the examples of Arduino IDE 1.0.4, I got error that &#xA;&lt;strong&gt;avrdude: stk500_getsync(): not in sync: resp=0x00&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I chose the correct COM port after verifying it with the Device manager. I installed the Prolific Drivers for the board. I selected the board as Arduino UNO in Arduino IDE.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The complete verbose for the upload is as follow:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;D:\Softwares\Installed Files\arduino-1.0.4\hardware/tools/avr/bin/avrdude -CD:\Softwares\Installed Files\arduino-1.0.4\hardware/tools/avr/etc/avrdude.conf -v -v -v -v -patmega328p -carduino -P\\.\COM10 -b115200 -D -Uflash:w:C:\Users\ANKITS~1\AppData\Local\Temp\build5865304215250534760.tmp\Blink.cpp.hex:i     &#xA;avrdude: Version 5.11, compiled on Sep  2 2011 at 19:38:36&#xA;         Copyright (c) 2000-2005 Brian Dean, http://www.bdmicro.com/&#xA;         Copyright (c) 2007-2009 Joerg Wunsch&#xA;         System wide configuration file is &quot;D:\Softwares\Installed Files\arduino-1.0.4\hardware/tools/avr/etc/avrdude.conf&quot;&#xA;Using Port                    : \\.\COM10&#xA;Using Programmer              : arduino&#xA;Overriding Baud Rate          : 115200&#xA;&#xA;avrdude: Send: 0 [30]   [20]   &#xA;avrdude: Send: 0 [30]   [20]    &#xA;avrdude: Send: 0 [30]   [20]    &#xA;avrdude: Recv:    &#xA;avrdude: stk500_getsync(): not in sync: resp=0x00&#xA;&#xA;avrdude done.  Thank you.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;When I plug in the board the power LED is on. The 13 pin LED blinks once. When the IDE shows uploading the 13 pin LED blinks 3-4 times and then the error appears on the screen. In between also sometimes it blinks randomly for 5-6 times. I also tried other example programs but the same follows.&#xA;I'm using 32 bit Windows 7 Ultimate and the baud rate is set to 9600.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;On Ubuntu 13.04:&lt;/strong&gt;&#xA;I downloaded the IDE from Software Center. I was added to the dialouts group on  the first run. After connecting the board to my pc I ran two commands &lt;code&gt;lsusb&lt;/code&gt; which returned following output:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;Bus 004 Device 003: ID 067b:2303 Prolific Technology, Inc. PL2303 Serial Port&#xA;Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub&#xA;Bus 002 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub&#xA;Bus 003 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub&#xA;Bus 004 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub&#xA;Bus 005 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;and then &lt;code&gt;dmesg&lt;/code&gt;. After this when I tried to upload the same program of blink, it gave me following error:&lt;strong&gt;avrdude: stk500_recv(): programmer is not responding&lt;/strong&gt;. I'm using 64 bit ubuntu 13.04 and selected Arduino UNO as the board.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thank you for reading this long. Please provide me suggestions for the problem.&lt;/p&gt;&#xA;" OwnerUserId="1359" LastActivityDate="2013-06-23T09:44:55.573" Title="Problem uploading to Roboduino AtMega328" Tags="&lt;arduino&gt;" AnswerCount="1" CommentCount="2" FavoriteCount="1" ClosedDate="2013-07-03T16:26:08.300" />
  <row Id="1321" PostTypeId="2" ParentId="1047" CreationDate="2013-05-23T20:58:25.673" Score="1" Body="&lt;p&gt;Once you have a real intuition for the Kalman equations you will easily be able to translate the equations / models into code.  I highly recommend working (by hand) the examples in the Lecture &lt;a href=&quot;http://www.cs.cornell.edu/Courses/cs4758/2012sp/materials/MI63slides.pdf&quot; rel=&quot;nofollow&quot;&gt;Subject MI63: Kalman Filter Tank Filling - Kalman Filter Applications&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The examples highlight how the system model can greatly affect the output of the Kalman filter and provide concrete examples of tracking random variables.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;More information on the derivation of the models used in the examples is given in &lt;a href=&quot;http://www.cs.unc.edu/~welch/kalman/media/pdf/kftool_models.pdf&quot; rel=&quot;nofollow&quot;&gt;UNC-Chapel Hill, COMP 145 - Team 18: The Kalman Filter Learning Tool - Dynamic and Measurement Models&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can implement the examples in something as simple as Excel or Matlab.  However, if you plan on implementing the Kalman equations in C++, I recommend use the Eigen software package like Josh previously mentioned.&lt;/p&gt;&#xA;" OwnerUserId="1361" LastEditorUserId="37" LastEditDate="2013-05-25T01:41:51.047" LastActivityDate="2013-05-25T01:41:51.047" CommentCount="1" />
  <row Id="1322" PostTypeId="2" ParentId="1318" CreationDate="2013-05-23T21:17:08.487" Score="0" Body="&lt;p&gt;The tricky part with what you want to do is that matching a person to some electronic representation of their &quot;signature&quot; is a very difficult task to do. Outside of some advanced facial recognition software, or tweaked vision software that could recognize a lime green shirt for example, there isn't much you can do.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I thought of something I haven't seen suggested elsewhere so I don't know if something like this exists or not but it seems like it could work for you with development. Perhaps using an thermal infrared camera to calibrate a thermal image of you putting in your height dimensions would work. Ultimately you are still getting into a vision based solution but a thermal camera would auto-greenscreen your whole body so to speak so you wouldn't have to worry about wearing the right color clothes or vibrantly colored clothes. It also wouldn't matter which direction you were facing. One caveat would be if you sat down or bent over, you wouldn't be properly height matched so something would have to account for that.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Anyways, just thought I'd throw that idea out there. It wouldn't work in a crowded area as well as you being the only one wearing vibrant green and color matching with a vision solution. Perhaps a combination of the two? Two cameras are better than one.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;The issue with any kind of field based approach is that the robot wouldn't know in which direction it was coming from without enough resolution which might force one to get expensive high resolution equipment. Also, the smaller the robot, the more expensive and higher res equipment one would need to triangulate a point of origin.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Alternatively, sound signatures could work. Sound waves are slower than electromagnetic waves and so would be easier to triangulate. You could also use a frequency that humans/animals cannot hear. You wouldn't need very high end equipment I don't think if you orient mics at appropriately far angles apart. Imagine a &quot;follow my voice&quot; kind of scenario.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Perhaps RF would work here too as mentioned but it does depend on the size/equipment.&lt;/p&gt;&#xA;" OwnerUserId="1349" LastActivityDate="2013-05-23T21:17:08.487" />
  <row Id="1323" PostTypeId="2" ParentId="1315" CreationDate="2013-05-23T21:21:47.063" Score="0" Body="&lt;p&gt;The issue with any kind of field based approach is that the robot wouldn't know in which direction it was coming from without enough resolution which might force one to get expensive high resolution equipment. Also, the smaller the robot, the more expensive and higher res equipment one would need to triangulate a point of origin.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Alternatively, sound signatures could work. Sound waves are slower than electromagnetic waves and so would be easier to triangulate. You could also use a frequency that humans/animals cannot hear. You wouldn't need very high end equipment I don't think if you orient mics at appropriately far angles apart. Imagine a &quot;follow my voice&quot; kind of scenario.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Perhaps RF would work here too as mentioned but it does depend on the size/equipment/software.&lt;/p&gt;&#xA;" OwnerUserId="1349" LastActivityDate="2013-05-23T21:21:47.063" />
  <row Id="1324" PostTypeId="1" AcceptedAnswerId="1326" CreationDate="2013-05-24T07:13:49.387" Score="1" ViewCount="65" Body="&lt;p&gt;How can I provide more power to a DC motor that is in series behind a receiver circuit hacked out of a cheap RC car without burning up the receiver board? The board runs off two AAs at about 3V. I'm replacing the stock motor with a slightly larger one (12V, taken from a printer) and remounting it on a chassis for a homebrew robotics project... just messing around to learn more. I imagine I could go safely to 4.5V or even 6V with the receiver but I don't want to go much higher since half the stuff is epoxied and I can't really tell what's in there.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What I'd like to be able to do is add an additional two AA batteries behind the receiver to run the receiver system at 6V but add another two 3V 123A batteries to have the motor at 12V with the ability to run with the higher current draw due to the heavier load the motor will handle on its fancy new chassis... but without pulling that current through the receiver circuit.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My first thought is to simply connect my 123As negative to the motor and positive to a common ground... but I'm really not sure and I want to be careful to not damage the circuit or batteries. My next thought is to simply build a single power supply out of my 123As and use a current divider but I've only read about them and never actually tried so.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've been doing some of those kiddie &quot;electronic playgrounds,&quot; a few books and probably cost Google an extra few bucks in energy costs and I'm still kinda at a loss.&lt;/p&gt;&#xA;" OwnerUserId="1362" LastEditorUserId="1362" LastEditDate="2013-05-24T07:22:15.450" LastActivityDate="2013-05-24T09:26:17.907" Title="Additional Power to DC Motor via Second Power Source" Tags="&lt;motor&gt;&lt;power&gt;" AnswerCount="1" />
  <row Id="1325" PostTypeId="2" ParentId="1320" CreationDate="2013-05-24T09:16:16.450" Score="1" Body="&lt;p&gt;I finally got the problem solved. The problem was that I had selected Arduino UNO. After checking out the datasheets for my board I found that it had the same specs as Arduino Duemilanove AtMega328. After selecting it I got the things right.&#xA;So the general solution is check out the data sheets if you are using any such modded boards and then select the appropriate board which matches the specs.&#xA;Now my board is working successfully on both windows and linux.&lt;/p&gt;&#xA;" OwnerUserId="1359" LastActivityDate="2013-05-24T09:16:16.450" />
  <row Id="1326" PostTypeId="2" ParentId="1324" CreationDate="2013-05-24T09:26:17.907" Score="1" Body="&lt;p&gt;It is safest to isolate the power supply for the motors from the electronics.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Normally, there is a single top-level power supply, eg. at 12V. This can supply the motors and other actuators directly. Because electronics normally run at 5V or 3V, a voltage regulator is often used to decrease the voltage (it taps into the 12V supply, and outputs a regulated 5V for the electronics). This is good, because the current motors draw can change quickly and may sometimes affect the power supply. In this case, if the voltage regulator is insufficient, capacitors may be added across the 12V supply, but this is not often required.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In your case, supposing you don't want to use a voltage regulator, you should have separate battery cells supply your electronics (at 3V), and another stack of cells at 12V to run your motors. You can then connect the ground of each circuit to each other to provide a common reference for your motor control signals. This setup again prevents the motors from affecting the voltage supplied to your electronics (assuming they draw a relatively constant, low current, won't require voltage regulation, although you might add a few capacitors to help with this - especially when you have op-amps or other switching electronics). Also, each cell in each battery stack will have the same current drawn from it. This avoids the some batteries in a stack having more charge than others, or having more current drawn.&lt;/p&gt;&#xA;" OwnerUserId="145" LastActivityDate="2013-05-24T09:26:17.907" />
  <row Id="1327" PostTypeId="1" AcceptedAnswerId="1331" CreationDate="2013-05-24T13:34:10.740" Score="2" ViewCount="146" Body="&lt;p&gt;I ran into confusion while reading about motors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Consider a motor with these specs:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Maximum motor voltage - 6VDC&lt;/li&gt;&#xA;&lt;li&gt;No load current - 250mA max.&lt;/li&gt;&#xA;&lt;li&gt;Stall current - around 1A&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;I am considering using the Texas Instruments L293D, with these specs:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Output Current - 600 mA Per Channel&lt;/li&gt;&#xA;&lt;li&gt;Peak Output Current - 1.2 A Per Channel&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;If I use the L293D to run 1 motor (back and forth), is this safe?  What would happen if my motor requires more than 600mA?  Does this simply mean I need different driver IC?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, the specs say that if I want to drive 2 motors then i'll need to compensate for the current. Is it current from my power supply or from the motor driver?&lt;/p&gt;&#xA;" OwnerUserId="1367" LastEditorUserId="350" LastEditDate="2013-05-26T01:08:15.397" LastActivityDate="2013-05-26T01:08:15.397" Title="How do I interpret these specs for a motor and motor driver?" Tags="&lt;mobile-robot&gt;&lt;motor&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="1329" PostTypeId="1" AcceptedAnswerId="1330" CreationDate="2013-05-24T17:32:40.517" Score="2" ViewCount="37" Body="&lt;p&gt;I used a &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/__8934__Turnigy_2200mAh_3S_25C_Lipo_Pack.html&quot; rel=&quot;nofollow&quot;&gt;Turnigy 2200mAh 3S 25C Lipo&lt;/a&gt; battery pack with &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/__7637__Turnigy_balancer_Charger_2S_3S.html&quot; rel=&quot;nofollow&quot;&gt;Turnigy balancer &amp;amp; Charger 2S-3S&lt;/a&gt; for about a month. Yesterday I left the battery plugged into four ESCs of my quadrocopter. Today I've found the battery totally discharged. When I tried to charge it, the charger showed it as faulty. After replugging it to the charger it showed it as fully charged.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How can I charge it now?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;P.S. I've got a multimeter, but I do not know what and how to measure... The battery pack has two plugs: one is connected to the charger and the other to the ESCs...&lt;/p&gt;&#xA;" OwnerUserId="1371" LastEditorUserId="37" LastEditDate="2013-05-25T01:49:14.463" LastActivityDate="2013-05-25T01:49:14.463" Title="Battery pack discharged" Tags="&lt;batteries&gt;&lt;battery&gt;" AnswerCount="1" />
  <row Id="1330" PostTypeId="2" ParentId="1329" CreationDate="2013-05-24T18:35:56.360" Score="2" Body="&lt;p&gt;You have to be very careful with those packs as they don't usually have under-voltage protection for themselves. You're pack is likely fine but the charger isn't seeing the minimum voltage required to begin charging and so it won't.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I found myself in nearly the same situation not too long ago and managed to bring the battery back to a visible voltage by charging it with a Pb charge algorithm of similar voltage for a few minutes.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The multiple plugs are because there are multiple cells in the pack and each one requires individual charging (in parallel - not in series). They all have a common ground so you put the black end of the multimeter in the 4 pin black hole and put the red end in each of the 3 other colored wires. You will get 3 different, but probably close voltages.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have this exact charger which is what I used to revive a similar pack: &lt;a href=&quot;https://www.sparkfun.com/products/10473&quot; rel=&quot;nofollow&quot;&gt;https://www.sparkfun.com/products/10473&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Edit:&#xA;If you wanted to get a littler risky with the battery, a NiMH charger could be used for a short period as you mentioned. It charges at an acceptably low rate but the cells differ a lot more than they do between Pb and Li. A multi-cell NiMH for instance can have all of it's cells charged at once while this is generally not possible for Pb/Li. This means that a 12v NiMH charger is not going to work for a 12v Li battery since each Li cell needs to be charged individually.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you happen to have an NiMH AA charger, you would retrofit that to be a 3v Li cell booster provided it slow-charges by putting two 1.5v terminals in series with the Li cell.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would highly suggest getting an inexpensive smart charger as it's uses are nearly endless and it could save you many headaches that dumb chargers often create.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Additionally, you may want to build in a low-voltage cutoff circuit into your design to prevent this issue in the future.&lt;/p&gt;&#xA;" OwnerUserId="1349" LastEditorUserId="1349" LastEditDate="2013-05-24T19:20:49.360" LastActivityDate="2013-05-24T19:20:49.360" CommentCount="4" />
  <row Id="1331" PostTypeId="2" ParentId="1327" CreationDate="2013-05-25T05:52:05.477" Score="2" Body="&lt;p&gt;For the motor, a stall current of 1A means that at stall, supplying 6V will cause the motor to draw 1A. The no-load current of 250mA means that supplying 6V will cause the motor to draw 250mA.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The half-bridge IC you have given has no current overload protection. Its peak current of 1.2A is high enough, but the 600mA continuous current is not. This can normally cause it to overheat, and possibly break. Under the absolute maximum ratings, it has a peak current of 1.2A for &amp;lt;100us. Normally, it may be possible to heat an IC a little more than recommended if a good heatsink is used. However, the &amp;lt;100us implies that this is not possible, because the heat would not be able to transmit through the package fast enough.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;These are your options:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;You can supply your own current foldback protection. By using a current sensor of some sort, you can detect when there is too much current flow, you can then scale down the voltage, possibly down to $6\times0.6\div1 = 3.6V$. Assuming a fast control circuit, this is probably fine (due to the peak current allowed).&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;You can run the motor at only 3.6V. This limits the stall current, torque and maximum no-load speed, but means that you do not have to do any current foldback.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;If you can measure the speed of the motor, and assuming you know the back EMF constant of your motor, you can convert speed to back EMF voltage. This is the additional voltage that you can supply to your motor (in addition to the 3.6V which gives 0.6A of current). This is because the amount of the back EMF voltage represents the voltage which will cause zero current to flow.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Note that when you run the motor at 3.6V, this is just the average voltage. Assuming you use pulse width modulation, this is equivalent to a power supply of 6V, with a duty cycle of 60%. Of course, the actual supply voltage must be within the operating condition of the device (36V).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You might be tempted to use two sets of half-bridges for each direction of the same motor. However, if you do this, you should be aware that it is quite difficult to control how much of the current comes from each parallel supply. Therefore, due to slight differences in transistor characteristics, one will supply more current than the other.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The specifications do not appear to mention anything about compensating current with two motors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Why don't you just use the L293 quad half-bridge drivers (which allow 1A continuous)?&lt;/p&gt;&#xA;" OwnerUserId="145" LastEditorUserId="145" LastEditDate="2013-05-25T08:50:14.053" LastActivityDate="2013-05-25T08:50:14.053" />
  <row Id="1332" PostTypeId="1" CreationDate="2013-05-26T19:15:22.503" Score="2" ViewCount="67" Body="&lt;p&gt;I would like to ask which is better to design the multicopter with odd or even number of propellers? and why?&lt;/p&gt;&#xA;" OwnerUserId="1378" LastEditorUserId="37" LastEditDate="2013-05-27T23:20:27.307" LastActivityDate="2013-05-27T23:20:27.307" Title="Multicopter odd or even" Tags="&lt;quadrotor&gt;" AnswerCount="1" CommentCount="0" ClosedDate="2013-05-27T23:13:55.907" />
  <row Id="1333" PostTypeId="2" ParentId="1332" CreationDate="2013-05-26T21:59:53.780" Score="1" Body="&lt;p&gt;Simply put, it is a trade off between control complexity vs. power requirements. You should probably go with an even number, 4 or greater. Nice explanation of all the technicalities:  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://robotics.stackexchange.com/questions/543/why-do-quadcopters-have-four-propellers-besides-the-name/544#544&quot;&gt;Why do quadcopters have four propellers?&lt;/a&gt;&lt;br&gt;&#xA;&lt;a href=&quot;http://robotics.stackexchange.com/questions/25/how-to-choose-the-right-propeller-motor-combination-for-a-quadcopter&quot;&gt;How to choose the right propeller/motor combination for a quadcopter?&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1330" LastEditorUserId="1330" LastEditDate="2013-05-27T00:48:51.497" LastActivityDate="2013-05-27T00:48:51.497" />
  <row Id="1334" PostTypeId="1" AcceptedAnswerId="1335" CreationDate="2013-05-27T10:38:08.170" Score="2" ViewCount="232" Body="&lt;p&gt;I bought an RC car about a year ago. A few days later I integrated an arduino nano into the vehicle. The only thing the arduino does is to receive the RC signal and pass it on to the esc/servo. So, basically it just does a big amount of NOTHING :)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Right now the wiring looks like this:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;[Remote] -&gt; [rc receiver] -&gt; [arduino] -&gt; [servo/esc/lights]&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;I added lights and I did some experiments with distance sensors and I will try to integrate car control via xbee + processing. This works via serial already.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What else could be possible with a setup like that? Here are some of my ideas:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;perhaps some sort of autonomic driving? The car is built for offroad and the suspension is not too bad but it is pretty fast (40 km/h) so a crash would be fatal.&lt;/li&gt;&#xA;&lt;li&gt;FPV (first person view) driving? I could add another servo to move a small camera.&lt;/li&gt;&#xA;&lt;li&gt;&quot;swarm intelligence&quot;? I have built two of those vehicles. Both feature the arduino nano, a zigbee and LED front lights.&lt;/li&gt;&#xA;&lt;li&gt;steering correction? I could integrate a gyro sensor to check if the car is not driving straight when it should.&lt;/li&gt;&#xA;&lt;li&gt;telemetry to another arduino? I could build some sort of arduino-zigbee-handheld that shows me some information for both cars like motor temperature, current speed, uptime, battery voltage, sensor values etc.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Any ideas, anyone? Right now it is just driving like it normally would. I integrated an arduino into an RC toy that does an awesome amount of NOTHING. Makes me feel pretty stupid.&lt;/p&gt;&#xA;" OwnerUserId="1383" LastEditorUserId="158" LastEditDate="2013-05-27T19:41:47.990" LastActivityDate="2013-05-27T21:45:56.220" Title="Arduino Controlled RC Car. What now?" Tags="&lt;arduino&gt;&lt;sensors&gt;&lt;radio-control&gt;&lt;automatic&gt;" AnswerCount="1" CommentCount="3" ClosedDate="2013-05-27T23:17:12.013" />
  <row Id="1335" PostTypeId="2" ParentId="1334" CreationDate="2013-05-27T21:45:56.220" Score="0" Body="&lt;ul&gt;&#xA;&lt;li&gt;Consider integrating an Android smartphone with the Arduino board, as then you get cameras, gps, accelorometers and even voice command.&lt;/li&gt;&#xA;&lt;li&gt;If you have 2 units and you want to build in a camera on one, why not have it automatically follow the other one. This should not be too hard if you put a marker / beacon on the one without the camera, or even a couple of different coloured markers so you can differentiate which side you are looking at. You could then have a 'robot cop' chase the user controlled car. &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="1330" LastActivityDate="2013-05-27T21:45:56.220" />
  <row Id="1336" PostTypeId="1" CreationDate="2013-05-28T13:13:10.447" Score="3" ViewCount="63" Body="&lt;p&gt;I have a matrix of M measurements and N objects. Each cell contains a cost of assignment a particular measurement to the object. I want to assign them optimally. As the condition, only one measurement can go to one object, and one measurement can go to only one object. I want to set some cost threshold, in effect there may be some measurement or object, which is not assigned at all.&#xA;How can I do it?&#xA;I was recently thinking of the auction algorithm, which however will never leave any unassigned measurement or object. If that is false, correct me please. Or help with some alternative solution. Thanks for your time!&lt;/p&gt;&#xA;" OwnerUserId="1012" LastEditorUserId="1012" LastEditDate="2013-05-29T08:08:54.397" LastActivityDate="2013-08-05T20:01:50.337" Title="Association of multiple measurements to multiple objects" Tags="&lt;artificial-intelligence&gt;&lt;sensor-fusion&gt;" AnswerCount="1" CommentCount="4" />
  <row Id="1338" PostTypeId="2" ParentId="1301" CreationDate="2013-05-28T14:08:51.583" Score="1" Body="&lt;p&gt;Eventually if it's under too much of a load, such as if it's holding a position and you force it in a different direction, or if its trying to adjust to a position and something is blocking it, it will burn out. As in a little puff of smoke will come out. This also happens with servos which eventually reach their end of life. You can generally smell the servo to know if it's dead. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In you're case, it hasn't died, but may be malfunctioning. You generally can't repair servos. If you had new electronics, you could, but unless its a $100+ motor, its generally not worth it. &lt;/p&gt;&#xA;" OwnerUserId="1386" LastActivityDate="2013-05-28T14:08:51.583" CommentCount="1" />
  <row Id="1339" PostTypeId="1" AcceptedAnswerId="1360" CreationDate="2013-05-29T00:41:05.047" Score="6" ViewCount="694" Body="&lt;p&gt;Okay, this might sound like a stupid question but, is there some sort of a permission in the US I might require to fly a quadcopter or a UAV for that matter? I couldn't find much help anywhere else.  &lt;/p&gt;&#xA;" OwnerUserId="1213" LastActivityDate="2013-06-21T20:05:32.797" Title="Permission to fly UAVs" Tags="&lt;quadcopter&gt;" AnswerCount="3" FavoriteCount="1" />
  <row Id="1340" PostTypeId="2" ParentId="1339" CreationDate="2013-05-29T01:06:43.480" Score="2" Body="&lt;p&gt;It is best to check with your local council - they will be able to inform you on general laws as well as local by-laws. Another good source would be your local model plane club.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As far as I know: UAV typically requires permission, depending on capabilities (they don't want unlicensed Predator drones flying around). Quadcopters typically don't, except at public events (like those camera quadcopters they use at some sport events). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Disclaimer : based on my personal understanding never having been to the states (they are pretty much standard the world over). I accept absolutely no reponsibility for any claims arising from usage of this info i.e. use at your own risk.&lt;/p&gt;&#xA;" OwnerUserId="1330" LastEditorUserId="1330" LastEditDate="2013-05-29T01:12:24.393" LastActivityDate="2013-05-29T01:12:24.393" />
  <row Id="1341" PostTypeId="2" ParentId="1047" CreationDate="2013-05-29T02:43:08.707" Score="1" Body="&lt;p&gt;I've been collecting books on Kalman filtering and target tracking for some years now.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Most approachable book I've found: Gelb's &lt;a href=&quot;http://rads.stackoverflow.com/amzn/click/0262570483&quot; rel=&quot;nofollow&quot;&gt;Applied Optimal Estimation&lt;/a&gt;.  It is widely considered a classic in the field.  It is also relatively inexpensive.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Second place goes to Brookner's &lt;a href=&quot;http://rads.stackoverflow.com/amzn/click/0471184071&quot; rel=&quot;nofollow&quot;&gt;Tracking and Kalman Filtering Made Easy&lt;/a&gt;.  It is aimed primarily at radar processing.  He goes to a good bit of trouble to explain simpler tracking filters first, then shows that the Kalman filter is nothing magic, just a more flexible way of coming up with the coefficients for the filter.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Neither of them tackle the association problem for multiple target tracking.  Blackman's &lt;a href=&quot;http://rads.stackoverflow.com/amzn/click/0890061793&quot; rel=&quot;nofollow&quot;&gt;Multiple Target Tracking with Radar Applications&lt;/a&gt; is a good start.  New, it is expensive, like all Artech House books.  Amazon says there are some inexpensive used copies available.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Unfortunately, I have yet to find anything that even remotely resembles an approachable explanation for Reid's &lt;a href=&quot;http://users.isr.ist.utl.pt/~alex/Resources/Reid_MHT_ieee_trans_ac_1979.pdf&quot; rel=&quot;nofollow&quot;&gt;Multiple Hypothesis Tracker&lt;/a&gt;, which you need if you are trying to do multiple-target tracking.  This is a robust approach to the problem of associating sensor reports with existing tracks and/or initiating new tracks if something new pops up.  You NEED to solve the association problem to do multiple target tracking.  Unfortunately, Reid's paper is almost incomprehensible, at least to me.  (Yes, there are simpler methods, but they are not nearly as robust.)&lt;/p&gt;&#xA;" OwnerUserId="1384" LastEditorUserId="1384" LastEditDate="2013-05-29T02:49:03.133" LastActivityDate="2013-05-29T02:49:03.133" />
  <row Id="1342" PostTypeId="1" CreationDate="2013-05-29T06:08:13.097" Score="0" ViewCount="67" Body="&lt;p&gt;I'm looking for a robot that is capable of moving around and has arms that can get objects in one place and drop in another. Something akin to what we see in most sci-fi movies, though much simpler. It may run on legs, wheels or tracks; it may have claws or hands. I'm looking for open-sourced design, schematics, specifications of the parts, coding - the whole package. It may be specific cases or projects/initiatives with a growing collection of robots.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As long as it can take out the trash, it's perfect. ;D&lt;/p&gt;&#xA;" OwnerUserId="1388" LastActivityDate="2013-05-29T12:30:36.200" Title="Open source &quot;sci-fi&quot;-like robot projects IRL" Tags="&lt;mobile-robot&gt;" AnswerCount="1" CommentCount="4" FavoriteCount="1" ClosedDate="2013-05-30T10:25:00.567" />
  <row Id="1343" PostTypeId="2" ParentId="1342" CreationDate="2013-05-29T11:33:47.533" Score="2" Body="&lt;p&gt;Regarding Open Source software for robots, check about the &lt;a href=&quot;http://en.wikipedia.org/wiki/Robot_Operating_System&quot; rel=&quot;nofollow&quot;&gt;ROS (robotics operating system)&lt;/a&gt; from &lt;a href=&quot;http://www.willowgarage.com/pages/software/ros-platform&quot; rel=&quot;nofollow&quot;&gt;willow garage&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="1394" LastEditorUserId="37" LastEditDate="2013-05-29T12:30:36.200" LastActivityDate="2013-05-29T12:30:36.200" CommentCount="1" />
  <row Id="1344" PostTypeId="1" AcceptedAnswerId="1366" CreationDate="2013-05-29T17:47:11.450" Score="1" ViewCount="283" Body="&lt;p&gt;So building a quadrocopter from scratch HAS a lot of decision making, and I need some input on the material choice. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have short listed Aluminum and Carbon Fiber for the Arms and support of the Quadrocopter. &#xA;I am a little short on cash to experiment with both of them. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So considering that I have enough money to buy either of those, and assuming that I have access to general tools like a Table Saw, Horizontal Band Saw, CNC Router and a Water jet. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What would be a better material to work with&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT:&lt;br&gt;&#xA;I will be deciding the specs around the frame so as to allow me some design liberty. So right now, my goal is to assemble a very durable, as-light-as possible frame, which can withstand a lot of experimentation on the electrical side.&lt;/p&gt;&#xA;" OwnerUserId="1213" LastEditorUserId="1213" LastEditDate="2013-05-29T18:43:24.467" LastActivityDate="2014-01-16T11:30:13.913" Title="Aluminum vs Carbon Fiber" Tags="&lt;design&gt;&lt;quadcopter&gt;" AnswerCount="7" CommentCount="1" FavoriteCount="0" />
  <row Id="1345" PostTypeId="2" ParentId="1344" CreationDate="2013-05-29T20:17:54.663" Score="2" Body="&lt;p&gt;Have you considered balsa or similar woods from the model airplane world?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are a LOT of balsa model airplanes flying.  Some of them are pretty big, and very strong.  (There's a picture of a 1/4 scale Piper J-3 Cub skeleton, pre-covering, with an elementary school kid sitting on the wing box, straddling the forward fuselage.  The airplane survived this particular elephant test just fine.)&lt;/p&gt;&#xA;" OwnerUserId="1384" LastActivityDate="2013-05-29T20:17:54.663" />
  <row Id="1346" PostTypeId="1" AcceptedAnswerId="1365" CreationDate="2013-05-29T20:19:28.193" Score="4" ViewCount="161" Body="&lt;p&gt;I am looking to upgrade the motors for SeaPerch underwater ROVs so we can carry heavier payloads and more equipment.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;My question is, should I look for motors which have a higher RPM and lower torque, or with lower RPM but higher torque to gain a substantial power increase? If the latter, what threshold of RPMs should I stay above to maintain speed?  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;We are currently running &lt;a href=&quot;http://www.jameco.com/Jameco/Products/ProdDS/232022.pdf&quot; rel=&quot;nofollow&quot;&gt;Jameco &lt;code&gt;PN 232022&lt;/code&gt; motors&lt;/a&gt; with ~1 1/2&quot; props (same setup as &lt;a href=&quot;http://robotics.stackexchange.com/a/313/1397&quot;&gt;here&lt;/a&gt;). They are mainly run at max power as our ESC currently consists of a fuse and a toggle switch.  &lt;/p&gt;&#xA;" OwnerUserId="1397" LastEditorUserId="1397" LastEditDate="2013-05-30T17:27:47.747" LastActivityDate="2013-06-10T20:28:42.737" Title="Upgrading the motors on a SeaPerch ROV - more torque, or more RPMs?" Tags="&lt;motor&gt;&lt;underwater&gt;" AnswerCount="1" CommentCount="0" FavoriteCount="2" />
  <row Id="1347" PostTypeId="2" ParentId="1344" CreationDate="2013-05-29T21:56:53.690" Score="1" Body="&lt;p&gt;Based on the experience others have had, it would appear that carbon fibre is a much better choice, because it is much lighter.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Because you need motors which can hold up the quadrocopter, weight is a primary consideration. By lightening it, you do not need as powerful motors, and you can carry less batteries - which of course, helps to lighten it further.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The main part of the frame, are the arms holding the rotors, so using carbon fibre for those would help significantly. I believe there are carbon fibre rods and tubes which can be purchased. The hollow tubes allow wiring through the centre.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, using carbon fibre may change the way things are mounted. In particular, drilling holes for mounting may be problematic - potentially causing cracking in the material. A good solution is to rely on clamping parts to the structure instead.&lt;/p&gt;&#xA;" OwnerUserId="145" LastActivityDate="2013-05-29T21:56:53.690" />
  <row Id="1348" PostTypeId="1" CreationDate="2013-05-29T22:11:39.623" Score="7" ViewCount="412" Body="&lt;p&gt;Some time ago I saw a demo of a small 'toy tank' with a single camera mounted on it. This tank was able to drive around the floor and detect objects and then move/steer to avoid them.&#xA;The interesting part was that it used a single camera vision system and as far as I remember was taking advantage of the floor being flat. and then using the rate a feature was moving in the scene relative to the motors and directions of travel to evaluate and hence map the scene.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can anyone send me pointers what to search for to get some more information on this, or some pointers to codebases that can do this.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The reason I ask is that this was a single camera system from a number of years ago (5+) and therefore (from what I remember) was a relatively low compute load.&#xA;I was intending to try this out on a Raspberry PI to build a car/tank that maps a room or set of rooms.&lt;/p&gt;&#xA;" OwnerUserId="1398" LastEditorUserId="804" LastEditDate="2013-09-17T21:01:14.387" LastActivityDate="2013-09-17T21:01:14.387" Title="Single camera vision and mapping system" Tags="&lt;raspberry-pi&gt;&lt;computer-vision&gt;" AnswerCount="3" CommentCount="1" FavoriteCount="2" />
  <row Id="1349" PostTypeId="1" CreationDate="2013-05-30T06:41:04.933" Score="2" ViewCount="199" Body="&lt;p&gt;I have an Autonomous Lawn mower(ALM) which can mow a certain lawn area when that area is bounded by a perimeter wire. Even when that perimeter wire is removed, it has to mow the above mentioned area accurately without slipping into a neighboring area.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Constraints and problems:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;The ALM is an open loop system.&lt;/li&gt;&#xA;&lt;li&gt;Differential GPS was tried, but it did not yield proper results.&lt;/li&gt;&#xA;&lt;li&gt;Any iterative pattern of area coverage can be used provided the error in each iteration is not added cumulatively which can result in unpredictable error in the end.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;I do not expect full fledged solution. But I need a starting point to understand motion planning particularly for unbounded robotics to solve this problem. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I searched on internet to know about the knowledge sources about motion planning but could not get good results. Can anyone guide me to know about such sources preferably books and articles on internet which can help me to solve this problem?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT:&#xA;Addition of information:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/a19Od.jpg&quot; alt=&quot;enter image description here&quot;&gt; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The above picture shows the irregular lawn area which does not have any enclosures and perimeter&#xA;wire&#xA;1.The red mark shows the center point of lawn .&lt;/p&gt;&#xA;&#xA;&lt;p&gt;2.The grey area is the initial scaled down area which resembles in shape to the larger area .I could not draw the grey area which exactly resembles the larger green area .&lt;/p&gt;&#xA;&#xA;&lt;p&gt;3.The grey lines are the contours which from the tracks to be followed by the lawn mower&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Idea description:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;1.Using planimeter app for onetime , the shape and dimension of the lawn area (green area) can be known&#xA;Link:&lt;a href=&quot;https://play.google.com/store/apps/details?id=com.vistechprojects.planimeter&amp;amp;hl=en&quot; rel=&quot;nofollow&quot;&gt;https://play.google.com/store/apps/details?id=com.vistechprojects.planimeter&amp;amp;hl=en&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;2.Center of polygon can be found by using the method in the following link&#xA;&lt;a href=&quot;http://en.wikipedia.org/wiki/Centroid#Centroid_of_polygon&quot; rel=&quot;nofollow&quot;&gt;http://en.wikipedia.org/wiki/Centroid#Centroid_of_polygon&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;3.Calculation of area of grey shape in the above figure .&lt;/p&gt;&#xA;&#xA;&lt;p&gt;4 . Grey shape is the least possible area which can be grazed by the ALM . Grey shape is similar to the green area shape and it is formed when Green area is scaled down&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To determine the scale down factor which is a numerical value ‘ n’ (n&amp;lt;1) &#xA;Where Grey area = n * Green area&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Once the Grey area is known , the number of contours or tracks to be grazed by ALM have to be determined manually .&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The width of contour is equal to the distance between the blades on the either end i.e. the width which can be grazed by ALM in a single stroke .&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Green area = Grey area + area of track 1 + area of track 2 + area of track3 + . . . . . . + area of track n&lt;/p&gt;&#xA;&#xA;&lt;p&gt;5.Once the lawn mower is switched on ,it should reach the center of the lawn (red mark showed in the above figure)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;6.Then, ALM should graze the least possible area or grey area .&lt;/p&gt;&#xA;&#xA;&lt;p&gt;7.After that ALM should Switch to contour circumscribing the grey area . It should continue circumscribing in each track till all the tracks are completed( decision has to be made by validating against the calculated and preset value ' No.of tracks' in ALM)   &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In this way entire lawn can be mowed without the need of perimeter wire and also ALM would not mow the neighbor’s lawn &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Challenges :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;a. Enable ALM to reach the center point of the lawn&lt;/p&gt;&#xA;&#xA;&lt;p&gt;a. To make ALM mow the grey area accurately&lt;/p&gt;&#xA;&#xA;&lt;p&gt;b. To make the ALM switch from one track to track .&lt;/p&gt;&#xA;&#xA;&lt;p&gt;c. To bypass the obstacle in track and return to the same track .&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When i mentioned this idea to my colleague ,he mentioned the about possible cumulative addition of error in each iteration resulting in an unpredictable error in the end .&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I intend to minimize the error and fix the boundary as correct as possible. &#xA;In fact this deviation should be predictable before it can be corrected .&lt;/p&gt;&#xA;" OwnerUserId="1394" LastEditorUserId="1394" LastEditDate="2013-06-04T11:14:06.297" LastActivityDate="2013-06-05T14:47:48.850" Title="Working of Autonomous Lawn mower(ALM) in an unbounded area without a perimeter wire" Tags="&lt;motion-planning&gt;" AnswerCount="2" CommentCount="7" />
  <row Id="1350" PostTypeId="1" CreationDate="2013-05-30T07:01:47.417" Score="2" ViewCount="120" Body="&lt;p&gt;Visible worms, pests, and diseased parts of plants emit a unique odor (Volatile Organic compounds with different concentrations). I understand that sensors which can quantitatively detect these compounds development are being developed. My idea is to build a swarm of robots which can spray pesticides by detecting VOCs on three targets present on plants across the fields.&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Target 1: Visible worms, pests, larvae. May these can be mechanically eliminated &lt;/li&gt;&#xA;&lt;li&gt;Target 2: Invisible pathogens on certain areas of a plant &lt;/li&gt;&#xA;&lt;li&gt;Target 3: Areas where pesticides have to be sprayed to prevent disease &lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;For these targets, pesticide has to be administered in the correct concentration &#xA;This idea can optimize the use of pesticides and treat the plant properly &#xA;Questions:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Is swarm robotics still sci-fi or Did any one implement it?&lt;/li&gt;&#xA;&lt;li&gt;Are the  any specific scenarios where implemented swarm robotic systems  are coming to help and establish the ease?   &lt;/li&gt;&#xA;&lt;li&gt;Which is the implemented system or idea in conception that can help in formation of solution for the above problem? &lt;/li&gt;&#xA;&lt;li&gt;How much time is required approximately to realize this idea?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Hope this question does not sound sci-fi and is practical and the intention is to solve a definite problem &#xA;How can i work by following some steps to further  make this idea concrete&lt;/p&gt;&#xA;" OwnerUserId="1394" LastEditorUserId="350" LastEditDate="2013-06-03T16:14:57.257" LastActivityDate="2013-06-03T16:14:57.257" Title="Building a Autonomous pesticide spraying system using swarm robotics based on odor (volatile Organic Compounds) detection" Tags="&lt;sensors&gt;&lt;research&gt;" CommentCount="2" />
  <row Id="1352" PostTypeId="2" ParentId="1348" CreationDate="2013-05-30T22:35:33.007" Score="2" Body="&lt;p&gt;It's hard to say exactly what they were doing, but the terms you may want here are &quot;&lt;a href=&quot;http://en.wikipedia.org/wiki/Optical_flow&quot; rel=&quot;nofollow&quot;&gt;optical flow&lt;/a&gt;&quot; and &quot;&lt;a href=&quot;http://en.wikipedia.org/wiki/Egomotion&quot; rel=&quot;nofollow&quot;&gt;egomotion&lt;/a&gt;&quot;. Sounds like there may have been some feature detection and matching (something like SURF or SIFT) or foreground/background segmentation thrown in as well.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://opencv.org/&quot; rel=&quot;nofollow&quot;&gt;OpenCV&lt;/a&gt; is probably the most widely used codebase for computer vision, they have a lot of &lt;a href=&quot;http://docs.opencv.org/modules/video/doc/motion_analysis_and_object_tracking.html&quot; rel=&quot;nofollow&quot;&gt;functionality for motion analysis&lt;/a&gt;. OpenCV should run on the Raspberry Pi, although your algorithms may be limited by computing power.&lt;/p&gt;&#xA;" OwnerUserId="479" LastActivityDate="2013-05-30T22:35:33.007" />
  <row Id="1353" PostTypeId="2" ParentId="1348" CreationDate="2013-05-30T22:52:21.853" Score="3" Body="&lt;p&gt;Building on &lt;a href=&quot;http://robotics.stackexchange.com/users/479/wildcrustacean&quot;&gt;WildCrustcean&lt;/a&gt;'s response another possiblity would be &lt;a href=&quot;http://en.wikipedia.org/wiki/Computer_stereo_vision&quot; rel=&quot;nofollow&quot;&gt;stereo vision&lt;/a&gt;. While we often think of stereo vision as using two cameras the techniques really only need images displaced in space and a model of the displacement. In other words I can take an image, move, then take another image. So long as I know the transformation between these two images I can then use stereo vision techniques to calculate the distance to a point in the image.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-05-30T22:52:21.853" />
  <row Id="1354" PostTypeId="2" ParentId="1270" CreationDate="2013-05-31T00:53:53.060" Score="1" Body="&lt;p&gt;If you want to detect missed steps, you want an encoder. Luckily, both magnetic and optical encoders exist that easily give you 4096 steps per revolution, so even a micro-stepping stepper motor will be measured with at least one step per step.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note that some CNC mills may not necessarily detect missed steps; it's up to the operator to not program a tool path that's too hard for the spindle and tool, and to hear the problem when it happens. Instead, those CNCs just use end limit switches to find the absolute home, and then work entirely by assuming steps are taken.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Encoders may allow you to experiment with other features, too, like using an assist DC motor for non-engaged moves for really fast rapids :-)&lt;/p&gt;&#xA;" OwnerUserId="88" LastActivityDate="2013-05-31T00:53:53.060" />
  <row Id="1355" PostTypeId="2" ParentId="1277" CreationDate="2013-05-31T01:06:07.433" Score="0" Body="&lt;p&gt;Professional CMYK conversions use algorithms that use blend matrices and even non-linear warping to fit the RGB color space (which color space? sRGB?) onto available printing inks. The best way to do that might be to find a library that does this, and find the specific parameters for the inks you want to use.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You need to design a system that can deliver an increment in coverage based on an input.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, in offset printing and laser printing, the picture is broken up in very small dots (a halftone screen,) and a percentage of dots is covered to achieve a certain degree of saturation. The different colors in 4-color printing are printed using halftone screens at different angles to minimize the case where one colored dot will keep falling right on top of another colored dot and thus &quot;punch out&quot; the covered color.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For an airbrushing robot, perhaps you can measure degree of paint feed (pressure on the lever) and dwell time, and convert that to a measurement of degree of paint coverage. The air brush works a bit like a stochastic paint particle emitter, removing N % of uncovered area within its zone of effect for every millisecond it is &quot;on.&quot; The covered area is also a 2D function that's strongest in the center, and fades out towards the edges.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In my opinion, the most interesting programming challenge in this design is figuring out the optimal path to &quot;sweep&quot; the airbrush to get the right amount of coverage of each kind of paint on each area, while not over/under-covering certain areas and making a mess. Holding the airbrush very close, and painting one &quot;pixel&quot; at a time, would work, but wouldn't be very &quot;artistic.&quot;&lt;/p&gt;&#xA;" OwnerUserId="88" LastActivityDate="2013-05-31T01:06:07.433" />
  <row Id="1356" PostTypeId="1" CreationDate="2013-05-31T16:38:17.993" Score="4" ViewCount="146" Body="&lt;p&gt;I'm trying to use a PID to stabilize a system described from the following difference equation:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$y_{k+1} = a y_k \sqrt{(1-y_k)}~~~ + b y_{k-1} ~+ c u_k$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can I use &lt;a href=&quot;http://en.wikipedia.org/wiki/Ziegler%E2%80%93Nichols_method&quot; rel=&quot;nofollow&quot;&gt;Ziegler-Nichols's rules&lt;/a&gt; to find PID parameters in this situation?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To be more precise. My system is an &lt;a href=&quot;http://en.wikipedia.org/wiki/Apache_HTTP_Server&quot; rel=&quot;nofollow&quot;&gt;Apache Http Server&lt;/a&gt;, in particular I'm trying to model how the CPU load can change in function of &lt;a href=&quot;http://httpd.apache.org/docs/current/mod/core.html#keepalivetimeout&quot; rel=&quot;nofollow&quot;&gt;KeepAlive&lt;/a&gt; parameter. When KeepAlive grows the cpu load should decrease.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$cpu_{k+1} = a \cdot cpu_k \sqrt{(1-cpu_k)}~~~ + b \cdot cpu_{k-1} ~+ c \cdot keepAlive_k$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Obviously the Cpu load is a scalar $\in [0,1]$ , $keepAlive$ is just a time and the $a,b,c$ parameters are known to me through experimental data and multiple regression on them.&lt;/p&gt;&#xA;" OwnerUserId="1408" LastEditorUserId="37" LastEditDate="2013-06-01T22:09:16.833" LastActivityDate="2013-06-01T22:12:47.440" Title="Can I use Ziegler-Nichols's rules to find PID parameters for a non linear system" Tags="&lt;pid&gt;" AnswerCount="1" CommentCount="2" />
  <row Id="1357" PostTypeId="2" ParentId="1356" CreationDate="2013-05-31T19:26:22.700" Score="5" Body="&lt;p&gt;First, you haven't provided enough information.  Your equation is nonlinear, which means that the behavior of the system as described depends not just on the coefficients of the difference equation, but on the range of values that $y$ can take on.  From the looks of things, the closer that $y$ is restricted to 0, the more you can treat the whole thing like a linear system and just apply PID control to it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Second, Ziegler-Nichols just isn't indicated here.  Z-N was invented as an ad-hoc tuning method for industrial plants with unknown characteristics.  It guarantees neither stability nor performance of the result -- and assuming that you know the values of $a$, $b$, and $c$, you have a plant with known characteristics!!!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Even if the plant characteristics are known, Z-N is really only a good way to arrive at a starting point for tuning.  Z-N tends to result in an underdamped system, and as I mentioned, it guarantees neither stability nor performance.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In systems that are amenable, I vastly prefer to do swept-sine measurements (&lt;a href=&quot;http://www.wescottdesign.com/articles/FreqMeas/freq_meas.html&quot; rel=&quot;nofollow&quot;&gt;Measuring Frequency Response&lt;/a&gt;).  If you don't like the buzzing and shrieking noises, and the uninitiated diving for cover behind lab equipment, you can use some sort of a system identification based on a step response instead -- but in my experience with servo systems, a frequency response-based design is superior when you need to go from measured values.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Whatever you do, you want to account for the effect that the variation in the value of $y$ is going to have on your system.  If the derivative &#xA;$$\frac{d}{dy}y\,\sqrt{1-y}$$ varies by more than a few percent, then you need to do your design to accommodate the differing systems characteristics.  If that derivative varies by a factor of two or more, then you need to consider the possibility of some sort of a nonlinear controller, however difficult and perverted your design may end up being, or you need to just pull in your horns and accept that you're going to have a severely detuned system for most ranges of $y$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;See &lt;a href=&quot;http://www.wescottdesign.com/actfes/actfes.html&quot; rel=&quot;nofollow&quot;&gt;Applied Control Theory for Embedded Systems&lt;/a&gt; for more information.&lt;/p&gt;&#xA;" OwnerUserId="1411" LastEditorUserId="37" LastEditDate="2013-06-01T22:12:47.440" LastActivityDate="2013-06-01T22:12:47.440" CommentCount="1" />
  <row Id="1358" PostTypeId="2" ParentId="1033" CreationDate="2013-05-31T19:40:59.703" Score="2" Body="&lt;p&gt;Sorry if this comes late:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are speaking about RC style servos, then the actual drive to the motor is in the form of a pulse width modulated voltage: the servo amplifier just turns the motor on fully in one direction or the other, for a length of time determined by the difference between the measured position and the target position as determined by the width of the incoming pulse.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Life is complicated by the newer &quot;digital&quot; servos -- I can't swear to the internal workings of these, but the drive to the motor is almost certainly PWM of some sort, just at a faster rate than the old-style analog servo amplifiers.  There's no reason that it couldn't be as described below, except that there is precious little room inside of an RC servo, so there's a good chance that no current measurement is done, and hence that the parameter that the microprocessor controls is the PWM duty cycle.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How servo mechanisms in industry are controlled is a much wider answer: basically, it can happen any way that the designer thought was appropriate.  Motor drive can be via a linear amplifier that is configured to drive a current or a voltage, or it can be via a switching amplifier (i.e. PWM).  In the case of a switching amplifier, the amplifier itself can be analog and configured for either constant-current, constant-voltage, or constant duty cycle.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Usually in a &quot;pro&quot; servo mechanism with a brushed or brushless motor there will be an inner loop that servos the motor current (and therefor torque).  This is not so much to provide any big advantage in control as it is because it vastly simplifies current limiting to the motor, which is necessary if you want to keep all that expensive smoke inside the motor where it belongs.  That inner current (and hence torque) loop will often be wrapped by a speed loop that either senses the speed of the motor shaft or that deduces it from the motor's back-EMF (and which provides a convenient means of speed limiting the motor, if that is necessary).  Finally, that speed loop is wrapped by a position loop.&lt;/p&gt;&#xA;" OwnerUserId="1411" LastActivityDate="2013-05-31T19:40:59.703" />
  <row Id="1359" PostTypeId="2" ParentId="1032" CreationDate="2013-05-31T20:50:17.727" Score="2" Body="&lt;p&gt;A PID loop and a so-called PIV loop with equal gains should have the same response to a disturbance, so I'm not sure why the claim that the disturbance response is better or worse.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As mentioned, the derivative &quot;kick&quot; will be less, which can be a good thing if you give the thing sharp inputs.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In addition, there can be some benefits as the thing comes out of integrator saturation, depending on how you implement your anti-windup.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Mostly, the so-called PIV loop is just a way of affecting the zeros of the closed-loop transfer function.  It's a special case of a more general scheme where your controller output is (in Laplace notation) &#xA;$$Y(s)=\frac{k_{fi}U(s) - k_{bi}X(s)}{s} + \left(k_{fp}U(s) - k_{bp}X(s)\right) + \left(k_{fd}U(s) - k_{bd}X(s)\right)s$$ &#xA;where $Y$ is the controller output, $U$ is the system command and $X$ is the controlled variable, while the various $k_{xx}$ are forward and backward integral, derivative, and proportional gains.  In this scheme you tune the various feedback gains ($k_{bx}$) to get the loop (and hence disturbance) response that you want, and you tune the forward gains ($k_{fx}$) to improve the response to a command change, by whatever criteria you have for &quot;better&quot;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Setting all the forward and reverse gains equal gets you a plain ol' PID, while setting $k_{bp}=0$ and  $k_{bd}=0$ gets you the so-called &quot;PIV&quot; controller.&lt;/p&gt;&#xA;" OwnerUserId="1411" LastActivityDate="2013-05-31T20:50:17.727" />
  <row Id="1360" PostTypeId="2" ParentId="1339" CreationDate="2013-05-31T21:12:29.600" Score="4" Body="&lt;p&gt;Disclaimer: &lt;a href=&quot;http://en.wikipedia.org/wiki/IANAL&quot; rel=&quot;nofollow&quot;&gt;IANAL&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For the US law, small UAVs are analogous to RC models and the regulation depends on the use intent.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For non-commercial, recreational use, the law is relatively permissive and mostly relies on the rules of the Academy of Model Aeronautics. You can find their rules here: &lt;a href=&quot;http://www.modelaircraft.org/documents.aspx&quot; rel=&quot;nofollow&quot;&gt;http://www.modelaircraft.org/documents.aspx&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For commercial use, the UAV currently must be certified like a manned aircraft, which is impossible in practice for small UAVs. Until recently, this has rendered the commercial exploitation of UAVs impossible in US. The parliament has been tasked to design laws to permit commercial exploitation of UAVs by 2015 at the latest. At the moment, it's possible for government agencies and university to obtain special permits through Certificates of Authorization. Other ways of demoing/using UAS are also being put in place (testing fields, lightweight certification process, etc.), but it will be difficult to have a clear picture for the next year or two. To complicate the picture, several states are in the process of passing restrictive laws related, e.g., to privacy, so the situation may end up being state dependent.&lt;/p&gt;&#xA;" OwnerUserId="1400" LastEditorUserId="350" LastEditDate="2013-06-21T20:05:32.797" LastActivityDate="2013-06-21T20:05:32.797" />
  <row Id="1363" PostTypeId="2" ParentId="1301" CreationDate="2013-06-01T12:33:10.207" Score="3" Body="&lt;p&gt;There is at least two modalities along which servos (continuous or otherwise) usually fail: gear problems and motor breakdown.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When the gear fails (broken tooth, hard point, etc.), the servo may get stuck, free moving or any combination. When the motor breaks (usually the brushes inside the DC motor are the culprit), the servo stops working altogether (as if it was unplugged) or overheats and burns. In your case, since it's humming and behaves differently when actuated by hand, I'd think your servo has gear problem. Its relatively easy to take a look at the gear box as it is the first apparent area when opening the servo and it can easily be re-assembled afterward (on the contrary, checking the motor's brushes usually means breaking the motor open), so I'd have a look to confirm the diagnostic.&lt;/p&gt;&#xA;" OwnerUserId="1400" LastActivityDate="2013-06-01T12:33:10.207" />
  <row Id="1364" PostTypeId="2" ParentId="1344" CreationDate="2013-06-01T12:42:17.557" Score="1" Body="&lt;p&gt;My choice is Carbon Fiber for sure. It has some advantages and some disadvantages.&#xA;OT: Using carbon fiber your robot will look much more professional and you will feel good looking at it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Advantages:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Much Lighter.&lt;/li&gt;&#xA;&lt;li&gt;Much Stronger&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Disadvantages:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;More expensive&lt;/li&gt;&#xA;&lt;li&gt;Slightly harder to work with (cutting, ...)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="21" LastActivityDate="2013-06-01T12:42:17.557" />
  <row Id="1365" PostTypeId="2" ParentId="1346" CreationDate="2013-06-01T15:33:24.127" Score="7" Body="&lt;p&gt;Keep in mind that &quot;heavier&quot; is not quite the term you're looking for.  You should be trimming your SeaPerch to be neutrally buoyant, so unless the new payload creates significantly more drag than your old one, your existing motors should work fine (just with decreased acceleration in response to the increased mass).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The answer to the question of torque vs RPM really depends on the propeller you use -- they should be evenly matched.  There is a fair amount of theory on this (for example, &lt;a href=&quot;http://web.mit.edu/drela/Public/web/qprop/motorprop.pdf&quot; rel=&quot;nofollow&quot;&gt;Mark Drela's lecture notes from MIT&lt;/a&gt;), but you can also just approach it in a practical way.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The basic idea is to work with the power curves of the propeller and motor (both of which are measurable):&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.tunnel2funnel.com/2013/01/significance-of-propeller-curve.html&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/dFuVS.png&quot; alt=&quot;Engine and propeller power curves&quot;&gt;&lt;/a&gt; (more &lt;a href=&quot;http://www.tunnel2funnel.com/2013/01/significance-of-propeller-curve.html&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Based on this, you should be able to work iteratively with a few propeller designs after you pick your motor.  There are also a lot of guides for this (like &lt;a href=&quot;http://youboat.net/boatPower4.aspx&quot; rel=&quot;nofollow&quot;&gt;this one&lt;/a&gt;, providing the image below) that explain how to choose the propeller based on the power of the motor that you've already selected.  You might not be measuring your engine power in units as large as &lt;a href=&quot;http://en.wikipedia.org/wiki/Horsepower#Brake_horsepower&quot; rel=&quot;nofollow&quot;&gt;BHP&lt;/a&gt;, but the technique is the same.&#xA;&lt;a href=&quot;http://youboat.net/boatPower4.aspx&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/u5r76.png&quot; alt=&quot;Rpm vs propeller size for given HP&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As always, you'll have to run your own thrust-vs-rpm tests on a variety of propellers to verify your calculations.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-06-10T20:28:42.737" LastActivityDate="2013-06-10T20:28:42.737" />
  <row Id="1366" PostTypeId="2" ParentId="1344" CreationDate="2013-06-02T04:27:23.833" Score="6" Body="&lt;p&gt;If your goal is to experiment, then use the cheapest option possible -- it will give you the freedom to make more mistakes.  Carbon fiber would be great if your design is in a fairly final state, but are you 100% assured that you correctly determined all the thicknesses, mounting holes, wiring guides, etc?  Are you good enough working with carbon fiber to successfully build what you designed?  These are serious things to consider if you are on a budget.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Balsa wood is a fairly cheap way to get started, and there are plenty of others (for example, if it's light enough then you may be able to use a sheet of foam).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Will it look pretty?  No.  But that's a prototype for you; if you're too heavily invested in the appearance/workmanship of the first draft, you'll fail to make newer &amp;amp; better drafts.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-06-02T04:27:23.833" />
  <row Id="1367" PostTypeId="1" AcceptedAnswerId="1368" CreationDate="2013-06-02T05:11:59.240" Score="3" ViewCount="136" Body="&lt;p&gt;While looking up information for the right propellers for my quadcopter, I realized that they had different orientations i.e. Clockwise and Counterclockwise. On further research I found that all multi-rotors have different combinations of these orientations. So my question is WHY? How does it matter if the propeller is turning clockwise or anti-clockwise?   &lt;/p&gt;&#xA;" OwnerUserId="1213" LastEditorUserId="1213" LastEditDate="2013-06-02T05:17:43.463" LastActivityDate="2013-06-02T06:35:38.837" Title="Prop Orientation on a Multirotor" Tags="&lt;quadcopter&gt;&lt;multi-rotor&gt;" AnswerCount="1" />
  <row Id="1368" PostTypeId="2" ParentId="1367" CreationDate="2013-06-02T06:35:38.837" Score="4" Body="&lt;p&gt;This has to do with the torque, or moment, the rotors induce on the body of the quadcopter/multirotor. If all of the rotors were to spin the same direction they would all induce a torque in the same direction causing the craft to yaw. Of course this is undesirable for many reasons. By spinning half of the rotors the opposite direction the torques are theoretically canceled preventing the craft from yawing.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-06-02T06:35:38.837" CommentCount="4" />
  <row Id="1369" PostTypeId="1" CreationDate="2013-06-02T19:28:05.727" Score="4" ViewCount="143" Body="&lt;p&gt;I want to find the instantaneous center of rotation of a differential drive robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Assuming I know that the robot will travel with a particular linear and angular velocity $(v,w)$ I can use the equations (given at &lt;a href=&quot;http://rossum.sourceforge.net/papers/CalculationsForRobotics/CirclePath.htm&quot; rel=&quot;nofollow&quot;&gt;A Path Following a Circular Arc To a Point at a Specified Range and Bearing&lt;/a&gt;) which come out to be:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$x_c = x_0 - |\frac{v}{w}| \cdot sin(\theta_0)$$&#xA;$$y_c = y_0 - |\frac{v}{w}| \cdot cos(\theta_0) $$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm using the webots simulator and I dumped gps points for the robot moving in a circle (constant v,w (1,1)) and instead of a single $x_c$ and $y_c$ I get a center point for every point. If I plot it out in matlab it does not look nice:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://docs.google.com/file/d/0BzLnU1-OKHh7dmxvbGU1bDFKcFU/edit?usp=sharing&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/J1r3m.jpg&quot; alt=&quot;circles.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The red points in the image are the perceived centers, they just seem to trace the curve itself. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there some detail I am missing? I'm really really confused as to what's happening. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm trying to figure out the center so I can check whether an obstacle is on this circle or not and whether collision will occur. &lt;/p&gt;&#xA;" OwnerUserId="1419" LastEditorUserId="37" LastEditDate="2013-06-03T16:58:58.107" LastActivityDate="2013-06-04T02:59:23.090" Title="Instantaneous Center of Rotation for a differential Drive Robot" Tags="&lt;mobile-robot&gt;&lt;motion&gt;" AnswerCount="2" CommentCount="1" FavoriteCount="1" />
  <row Id="1370" PostTypeId="1" AcceptedAnswerId="1373" CreationDate="2013-06-02T20:34:24.683" Score="5" ViewCount="464" Body="&lt;p&gt;This question stems from previous &lt;a href=&quot;http://robotics.stackexchange.com/questions/1367/prop-orientation-on-a-multirotor&quot;&gt;question&lt;/a&gt;, where I asked why does the prop orientation matter so much for a multirotor. But on further research&lt;sup&gt;&amp;dagger;&lt;/sup&gt; I found that these reasons need not apply to a tri copter. and then again. Why? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Are these reasons general for all multi rotors with odd number of motors? or even rotors?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&amp;dagger; &lt;a href=&quot;http://www.rcgroups.com/forums/showthread.php?t=1889111&quot; rel=&quot;nofollow&quot;&gt;This forum&lt;/a&gt; talks a lot about tricopters and prop orientations but nothing really answers the question. &lt;/p&gt;&#xA;" OwnerUserId="1213" LastEditorUserId="37" LastEditDate="2013-06-03T08:31:04.710" LastActivityDate="2013-06-03T15:11:46.800" Title="Prop orientation for tricopters" Tags="&lt;multi-rotor&gt;" AnswerCount="1" CommentCount="0" />
  <row Id="1371" PostTypeId="2" ParentId="1266" CreationDate="2013-06-03T02:06:43.127" Score="4" Body="&lt;p&gt;Short answer: the strongest reinforcement effect comes from delivering a valuable reward on an intermittent (random) schedule.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Longer version: One aspect of your question is about &lt;a href=&quot;http://en.wikipedia.org/wiki/Operant_conditioning&quot; rel=&quot;nofollow&quot;&gt;operant conditioning&lt;/a&gt;, at least as it applies to teaching maths to a complex organism. Applying this to machine learning is known as &lt;a href=&quot;http://en.wikipedia.org/wiki/Reinforcement_learning&quot; rel=&quot;nofollow&quot;&gt;reinforcement learning&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Economics (as per &lt;a href=&quot;http://robotics.stackexchange.com/a/1267/37&quot;&gt;jwpat7's answer&lt;/a&gt;) only addresses one part the story of reinforcement. Utility function tells you what reward has the strongest reinforcement effect (biggest impact on behaviour) in a given context. Is it praise? chocolate? cocaine? direct electrical stimulation to certain areas of the brain? Mostly my answer is about effect of context, assuming a given reward utility.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For complex organisms/behaviours, reward scheduling is at least as important as reward utility:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A &quot;fixed-interval reward schedule&quot; is the least effective way to modify behaviour with a given quantity of reward (I'll give you \$10 per week if you keep your bedroom tidy). Think dole bludger.&lt;/li&gt;&#xA;&lt;li&gt;Fixed ratio reward schedules (I'll give you \$10 every seven days you have a tidy bedroom) are more effective than fixed intervals, but they have a kind of effectiveness ceiling (subject will tidy their room seven times when they are hungry for \$10, but not otherwise). Think mercenary.&lt;/li&gt;&#xA;&lt;li&gt;The most influential way to deliver a given reward with a &quot;variable interval reinforcement schedule&quot; (e.g. every day you tidy your bedroom you have a 1/7 chance of getting $10). Think poker machine.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;If you are a learning supervisor with a fixed reward budget, for a given learning situation, there will be an optimum balance of reward size (utility) and frequency. It's probably not a very small slice of reward at a very high frequency, nor a very large chunk of reward delivered very rarely. It might even be a random size reward at a random schedule - the optimum is usually determined experimentally for a particular situation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Finally, the &quot;optimum&quot; schedule (random frequency, random quantity {p(reward),p(value)}) will probably vary at different stages in the learning process. For example, a new pupil might be subject to &quot;primacy&quot; effect (welcome! have a jelly bean) that quickly becomes fixed-interval reward if you repeat it. There might be a &quot;recency&quot; effect that gets more reinforcement value from a reward delivered on the very last trial (&quot;finishing on a high note&quot;). In between, there may be an accumulative &quot;faith effect&quot; where as a learner becomes more experienced, the optimum might shift toward lower probability, higher utility over time. Again, more stuff to determine empirically in your situation.&lt;/p&gt;&#xA;" OwnerUserId="1422" LastEditorUserId="37" LastEditDate="2013-06-03T09:53:43.167" LastActivityDate="2013-06-03T09:53:43.167" CommentCount="2" />
  <row Id="1372" PostTypeId="2" ParentId="1266" CreationDate="2013-06-03T02:49:30.427" Score="1" Body="&lt;p&gt;The optimal reward function depends on the learning objective, i.e. what is to be learned. For simple problems it may be possible to find a closed form representation for the optimal reward function. In fact for really simple problems I'm confident it is possible though I know of no formal methods for doing so (I suspect utility theory would address this question). For more complex problems I would argue that it is not possible to find a closed form solution.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Instead of seeking the optimal function we could look to an expert for a good reward function. One approach to doing so is a technique called Inverse Reinforcement Learning (IRL). It formulates a learning problem as a reinforcement learning problem where the reward function is unknown and the objective of the learning process. The paper Apprenticeship Learning via Inverse Reinforcement Learning by &lt;a href=&quot;http://www.cs.berkeley.edu/~pabbeel/&quot; rel=&quot;nofollow&quot;&gt;Pieter Abbeel&lt;/a&gt; and &lt;a href=&quot;http://ai.stanford.edu/~ang/&quot; rel=&quot;nofollow&quot;&gt;Andrew Ng&lt;/a&gt; is a good place to start learning about IRL.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-06-03T02:49:30.427" />
  <row Id="1373" PostTypeId="2" ParentId="1370" CreationDate="2013-06-03T13:05:43.053" Score="4" Body="&lt;p&gt;For a basic multicopter, in the absence of any other way to control yaw, orientation does matter. A quadrotor needs a balanced set of rotation directions so that it can easily control yaw direction, and at equilibrium, all propellers can rotate at the same speed. This is primarily because all rotors in a quadrotor are fixed (usually). The quadrotor can also control yaw by varying the speed of propellers that rotate in one direction versus another.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Propeller orientation does not matter so much when it has some other method to control yaw. For example, helicopters have a tail rotor, which corrects for any yaw moment caused by the main propeller. Thus, if it was to set to rotate in the opposite direction, the tail rotor can just rotate in the opposite direction to counter this.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The standard tricopter has two front rotors, and a third rear rotor. However, the rear rotor can change its axis. It tilts left or right. When it tilts left or right, a portion of its thrust acts in the yaw direction. Therefore, where front rotors rotate in the same direction, the rear rotor must tilt more the counter the moment from the front rotors. Where the front rotors rotate in opposite directions, the rear rotor tilts less. This is explained in &lt;a href=&quot;http://vimeo.com/22778782&quot; rel=&quot;nofollow&quot;&gt;the video&lt;/a&gt; in &lt;a href=&quot;http://www.rcgroups.com/forums/showpost.php?s=768e670da2be9e8df7c955f722722400&amp;amp;p=24951580&amp;amp;postcount=4&quot; rel=&quot;nofollow&quot;&gt;message #4&lt;/a&gt; of the link you posted.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The reason why the controllers does not even need to know the direction of rotation in the tri-copter is because it is a feedback controller. Thus, when it senses undesired yaw, it simply tilts the rear rotor in the opposite direction to correct the yaw direction.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note that the rear rotor, when tilted in one direction, also causes a lateral force. This is counter-balanced by having the whole tricopter tilt in the opposite direction. Hence, the front rotors are tilted (to a lesser degree), and part of their force is oriented laterally.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Therefore, tricopters are more stable and performs better when the front rotors are counter-rotating, because the rear rotor can tilt less (as well as the whole tricopter tilting less).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In summary, the general rule is that propeller orientation is a consideration &lt;strong&gt;unless&lt;/strong&gt; it has some other mechanism to correct for yaw. With more than 4 rotors (which are unable to tilt), it is not necessary to have rotors in one direction be exactly equal to the number in the other direction, because it can change the speed of the rotors independently to exactly cancel out the moments. However, this may cause uneven utilisation of the rotors - we tend to like symmetry.&lt;/p&gt;&#xA;" OwnerUserId="145" LastEditorUserId="37" LastEditDate="2013-06-03T15:11:46.800" LastActivityDate="2013-06-03T15:11:46.800" />
  <row Id="1374" PostTypeId="2" ParentId="1369" CreationDate="2013-06-03T16:06:37.687" Score="0" Body="&lt;p&gt;It looks like there is some noise in the sensor readings. Make sure your simulator is reporting ground truth, or you have some tolerance to noise.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;See here: &lt;a href=&quot;http://www.cyberbotics.com/dvd/common/doc/webots/guide/section9.2.html&quot; rel=&quot;nofollow&quot;&gt;http://www.cyberbotics.com/dvd/common/doc/webots/guide/section9.2.html&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In particular&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;In Supervisor code:&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;To get the 3D position of any Transform (or derived) node in the&#xA;  Supervisor code: you can use the wb_supervisor_node_get_position()&#xA;  function. Please check this function's description in the Reference&#xA;  Manual.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;To get the 3D position of any Transform (or derived) node placed at&#xA;  the root of the Scene Tree (the nodes visible when the Scene Tree is&#xA;  completely collapsed), you can use the&#xA;  wb_supervisor_field_get_sf_vec3f() function. Here is an example.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;A simulation example that shows both the GPS and the Supervisor&#xA;  techniques is included in the Webots installation, you just need to&#xA;  open this world: $WEBOTS_HOME/projects/samples/devices/worlds/gps.wbt.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;IF in fact noise in the state estimate is the problem (bit IF), then &#xA;the way to compensate for such errors is to use an estimate of your state and error models. It's beyond the scope of the question, unfortunately. If you want to do obstacle avoidance AND you are certain that sensor error is the issue, I suggest you:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;Check for obstacles in a wide band (a fat circle) which could represent your trajectory with a bit of error&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Run a filter to get an estimate of robot position, then find the &quot;likely&quot; collisions&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Only look for obstacles over a small window into the future.  In the short term, your state estimate should be fine.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;However, these are heavy handed fixes for what is likely a small problem.&lt;/em&gt;&lt;/p&gt;&#xA;" OwnerUserId="163" LastEditorUserId="163" LastEditDate="2013-06-04T02:59:23.090" LastActivityDate="2013-06-04T02:59:23.090" CommentCount="5" />
  <row Id="1375" PostTypeId="2" ParentId="1047" CreationDate="2013-06-03T17:01:27.983" Score="1" Body="&lt;p&gt;The two links that I found most useful were &lt;a href=&quot;http://greg.czerniak.info/guides/kalman1/&quot; rel=&quot;nofollow&quot; title=&quot;Kalman Filter for Undergrads1&quot;&gt;Kalman Filter for Undergrads1&lt;/a&gt;&#xA;and &lt;a href=&quot;http://bilgin.esme.org/BitsBytes/KalmanFilterforDummies.aspx&quot; rel=&quot;nofollow&quot;&gt;Kalman Filter for Dummies&lt;/a&gt;. They're not high on the theory though. and &lt;a href=&quot;http://studentdavestutorials.weebly.com/kalman-filter-with-matlab-code.html&quot; rel=&quot;nofollow&quot;&gt;Student Dave's Kalman Filter Tutorial&lt;/a&gt;. The last one has matlab code that you can play with and is easy to follow. &lt;/p&gt;&#xA;" OwnerUserId="1419" LastActivityDate="2013-06-03T17:01:27.983" />
  <row Id="1376" PostTypeId="2" ParentId="1369" CreationDate="2013-06-03T21:19:43.910" Score="1" Body="&lt;p&gt;It's hard to see what's going on exactly, especially without seeing the code or knowing more about the sensor model. That's said, your trajectory is mostly straight and $w$ is thus mostly close to zero. This means that: &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;your center of rotation is far away during most of your experiment -- likely beyond the bounds of your graph;&lt;/li&gt;&#xA;&lt;li&gt;you may have numerical stability issues due to a division by a very small number.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="1400" LastActivityDate="2013-06-03T21:19:43.910" CommentCount="1" />
  <row Id="1378" PostTypeId="1" AcceptedAnswerId="1430" CreationDate="2013-06-04T07:07:59.703" Score="2" ViewCount="126" Body="&lt;p&gt;Using ArduPilot software (fixed wing, ArduPlane), I know that after I boot up I need to keep the system sit still while the gyros initialise.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When I have ground station in the field it's easy to know when it's safe to launch because the telemetry message tells me. But I don't always fly with a ground station. In these situations I currently just sit and wait for a while before arming, then again before launching. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there some reliable rule of thumb? information in the blinking of the arming switch or buzzing that I haven't worked out yet? This UAV has PX4 autopilot hardware (with both Px4FMU and PX4IOBoard), including with buzzer and illuminated arming switch. The LEDs on the board are obscured (but I could make light channels from them if required).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(Note: I'm asking this question here to test the theory that robotics stack exchange night be an appropriate forum for these sorts of questions, which has been suggested a couple of times in response to the Area51 drones proposal.)&lt;/p&gt;&#xA;" OwnerUserId="1422" LastEditorUserId="350" LastEditDate="2013-08-08T13:17:56.823" LastActivityDate="2013-08-08T13:17:56.823" Title="How to tell when an ArduPilot has finished initialising its gyros (without referencing telemetry)?" Tags="&lt;uav&gt;" AnswerCount="2" CommentCount="4" />
  <row Id="1379" PostTypeId="2" ParentId="1349" CreationDate="2013-06-04T07:14:05.407" Score="0" Body="&lt;p&gt;So you want your robot to stay in a fixed area, without giving any sensor feedback? Don't move the robot... &lt;/p&gt;&#xA;&#xA;&lt;p&gt;More seriously, I don't see how you could get away with having no sensor feedback. You tagged your question as motion planning. Yes, you could find a coverage pattern which minimizes your dead reckoning error, e.g. by looking for the least amount of turns or shortest path. But if you want to use the system in the real world I don't see how this would ever result in the robot not going over your boundary. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ah.. wait. Lets say you know your boundary and your starting position, the best I could think of here would be to go straight to your bounds and then move along the bounds at a distance of lets say three sigma of your position uncertainty. You would try to cover your area from the outside to the inside, and always keep a three sigma distance of your position uncertainty to the borders. At some point your uncertainty ellipse will not fit into the area anymore and you will have to stop. With a bit of luck, large parts of your area may have been covered. Not sure if its practical, since I would not expect lawn movers to have very good odometry. &lt;/p&gt;&#xA;" OwnerUserId="127" LastActivityDate="2013-06-04T07:14:05.407" CommentCount="1" />
  <row Id="1380" PostTypeId="2" ParentId="568" CreationDate="2013-06-05T05:39:59.487" Score="3" Body="&lt;p&gt;Yes. If you only run it in feed-forward mode and do your training off-line somewhere else:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I programmed a 3-layer (5-5-2) feedforward ANN on an Arduino UNO.  It ran on a mobile robot.  Whenever the robot would hit something, it would re-train the network.  The feedforward portion of the net ran in real-time; while the back-propagation training took on the order of ~5 to 20 seconds.  I suppose you could trim the size of the network as well as the play with the parameters to make it run a bit faster, but if you plan on doing backpropagation on an Arduino, I think it would be too slow.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some thoughts to speed things up include:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Use fixed vs floating point (for MCU's w/o an FPU)&lt;/li&gt;&#xA;&lt;li&gt;Use an MCU that has a FPU&lt;/li&gt;&#xA;&lt;li&gt;Use a simpler activation function (ie. $\tanh$) instead of Sigmoid&lt;/li&gt;&#xA;&lt;li&gt;Have the training phase occur offline on a PC&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="1428" LastEditorUserId="1428" LastEditDate="2013-06-05T19:25:42.677" LastActivityDate="2013-06-05T19:25:42.677" />
  <row Id="1381" PostTypeId="2" ParentId="568" CreationDate="2013-06-05T06:31:22.010" Score="0" Body="&lt;p&gt;Yes indeed, it's possible to embed neural network in microcontrollers. There are many such examples of this in the scientific literature but I can cite a striking example of what can be done with a very simple MCU if you're smart enough. In &lt;a href=&quot;http://infoscience.epfl.ch/record/63939&quot; rel=&quot;nofollow&quot;&gt;Evolutionary Bits'n'Spikes&lt;/a&gt;, the authors describe the implementation of a real time spiking neural network AND a genetic algorithm to train it, in order to control a differential wheel robot. The whole code runs in a tiny PIC16F628 4MHz MCU embedded on the 1-cubic-inch Alice robot.&lt;/p&gt;&#xA;" OwnerUserId="1400" LastActivityDate="2013-06-05T06:31:22.010" />
  <row Id="1383" PostTypeId="1" CreationDate="2013-06-05T12:48:20.323" Score="3" ViewCount="93" Body="&lt;p&gt;I'm robotic engineer, using OpenSCAD to model robotic components (gears, pulleys, parts, etc). But I need an application to model the physics and interaction of the components (for i.e. how will robot move if I rotate a given gear).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, is there any software I can use for modelling interactions in Linux? Google SketchUp is good, but I can't use it in Linux.&lt;/p&gt;&#xA;" OwnerUserId="415" LastEditorUserId="37" LastEditDate="2013-06-05T13:42:37.877" LastActivityDate="2013-06-07T02:43:46.290" Title="Software for robot parts interaction modeling" Tags="&lt;software&gt;" AnswerCount="1" CommentCount="3" FavoriteCount="1" />
  <row Id="1384" PostTypeId="2" ParentId="1349" CreationDate="2013-06-05T14:47:48.850" Score="2" Body="&lt;p&gt;You have an interesting approach, but I think it's the wrong approach; you've painted yourself into a corner by trying to avoid some technical obstacles (instead of just tackling them).  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Based on the information you've provided, it sounds like the goal is for this robot to successfully mow an irregularly-shaped lawn while staying within an invisible boundary -- defined using GPS.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A positioning system (enabling closed-loop control) is critical to accomplishing this goal.  Going without one is the equivalent of pushing the lawnmower around the yard while blindfolded; not only is it impractical, having a spinning blade on a blindfolded robot borders on unethical.  There are ways to improve the accuracy of GPS, e.g. &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;With an INS (&lt;a href=&quot;http://www.cs.cmu.edu/~pvernaza/papers/gpsBiasEst.pdf&quot; rel=&quot;nofollow&quot;&gt;Robust GPS/INS-aided localization and mapping via GPS bias estimation&lt;/a&gt;)&lt;/li&gt;&#xA;&lt;li&gt;With visual odometry (&lt;a href=&quot;http://www.doc.ic.ac.uk/~sl203/content/IV2011/Lovegrove_etal_iv2011.pdf&quot; rel=&quot;nofollow&quot;&gt;Accurate Visual Odometry from a Rear Parking Camera&lt;/a&gt;)&lt;/li&gt;&#xA;&lt;li&gt;With wheel odometry (&lt;a href=&quot;http://cdn.intechopen.com/pdfs/27718/InTech-Improved_inertial_odometry_gps_positioning_of_wheeled_robots_even_in_gps_denied_environments.pdf&quot; rel=&quot;nofollow&quot;&gt;Improved Inertial/Odometry/GPS&#xA;Positioning of Wheeled Robots Even in&#xA;GPS-Denied Environments&lt;/a&gt;)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Once you have a robot that knows its precise location, you do not need to pick your algorithm based on minimizing error; you need only visit every position in the lawn area.  (Remember, you will have already used a GPS to draw the boundary of the lawn.) I would refer you to other questions on this site that concern coverage, such as:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://robotics.stackexchange.com/q/628/350&quot;&gt;What algorithm should I implement to program a room cleaning robot?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://robotics.stackexchange.com/q/952/350&quot;&gt;What's an efficient way to visit every reachable space on a grid with unknown obstacles?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-06-05T14:47:48.850" CommentCount="2" />
  <row Id="1386" PostTypeId="5" CreationDate="2013-06-05T16:59:58.500" Score="0" ViewCount="3" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2013-06-05T16:59:58.500" LastActivityDate="2013-06-05T16:59:58.500" />
  <row Id="1387" PostTypeId="4" CreationDate="2013-06-05T16:59:58.500" Score="0" Body="[Model Predictive Control](http://en.wikipedia.org/wiki/Model_predictive_control)" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-06-05T18:47:31.513" LastActivityDate="2013-06-05T18:47:31.513" />
  <row Id="1388" PostTypeId="1" CreationDate="2013-06-03T05:00:51.497" Score="1" ViewCount="46" Body="&lt;p&gt;I am trying to write a C code for a pan-tilt unit model ptu-d46 using visual studio 2010 in Windows 7, but I can't find any tutorial or reference on how to do so. All the user's manual mentions is that there is a C programmer's interface (model ptu-cpi) available, but it doesn't say where to find it nor how to use. I looked for it on google but couldn't find anything.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is a command reference manual along with the user's manual, but it only shows the different commands to control the tilt and does not explain how to make a C program that connects to the tilt controller and sends queries to it. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Does anyone please have an idea of where I should look or if there are any open source programs for that. I'm not trying to make a complicated program. I just need it to connect to the tilt controller (the computer is connected via USB cable to the host RS232 of the tilt controller) and makes it nod to say &quot;Yes&quot; and &quot;No&quot; !&lt;/p&gt;&#xA;" OwnerDisplayName="user2446260" LastEditorUserId="350" LastEditDate="2013-06-05T23:33:22.897" LastActivityDate="2013-06-05T23:33:22.897" Title="programming pan-tilt unit with C" Tags="&lt;c&gt;" AnswerCount="2" />
  <row Id="1389" PostTypeId="2" ParentId="1388" CreationDate="2013-06-03T05:23:26.913" Score="1" Body="&lt;p&gt;The command reference manual is &lt;a href=&quot;http://www.dperception.com/pdf/Pan-Tilt-Command-Reference-Manual.pdf&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;. These commands are sent as ASCII text to the serial interface on the controller.  How to send data to a serial port depends on your OS and how the device is attached.  On Linux, you'll probably open a device file like /dev/ttyXXX and write to that.  I don't know about Windows or MacOS.&lt;/p&gt;&#xA;" OwnerDisplayName="Lee Daniel Crocker" LastActivityDate="2013-06-03T05:23:26.913" CommentCount="1" />
  <row Id="1390" PostTypeId="2" ParentId="1388" CreationDate="2013-06-03T05:26:45.940" Score="0" Body="&lt;p&gt;You do not need the PTI-CPU (which is a separate product -- $250) for your application. It's only necessary if you are going to give the PTU instructions more than 10 times per second.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What you just need to do is figure out how to use a serial port in your environment, and send it the commands as described in the manual you already have.&lt;/p&gt;&#xA;" OwnerDisplayName="Gabe" LastActivityDate="2013-06-03T05:26:45.940" CommentCount="1" />
  <row Id="1391" PostTypeId="1" CreationDate="2013-05-07T20:55:32.517" Score="0" ViewCount="4" Body="&lt;p&gt;Does anyone have experience with this &lt;strong&gt;ez-b&lt;/strong&gt;, it is sold by &lt;em&gt;ez-robot.com&lt;/em&gt; and comes with an SDK for Visual Studio&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It has direct scripting in runtime and through usb or bluetooth, wifi, irc, https&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My question is, if I get a regular arduino board, will i be able to do the same?&#xA;from what ive read, arduino needs to hold the instructions on its own memory, but I rather have the brain in the computer, and feed signals back and forth to the microcontroller&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, is &lt;strong&gt;arduino&lt;/strong&gt; alone, a step down as the website niceley puts it&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks for your help in advance&lt;/p&gt;&#xA;" OwnerUserId="1281" OwnerDisplayName="Ess Kay" LastActivityDate="2013-06-05T18:55:20.790" Title="creating a robot from ez-b or regular arduino" Tags="&lt;arduino&gt;&lt;microcontroller&gt;" CommentCount="3" ClosedDate="2013-06-05T19:48:26.987" />
  <row Id="1392" PostTypeId="1" CreationDate="2013-05-02T16:37:54.263" Score="1" ViewCount="119" Body="&lt;p&gt;I am using a LSM303 sensor to compute a heading and I want to turn my robot to a heading.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have the simple code here:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;int mag;&#xA;mag = compass.heading((LSM303::vector){0,-1,0});;   //read the angle of the robot&#xA;&#xA;Serial.println(mag);&#xA;while (mag != angle){   &#xA;    //while it isn't the desired angle turn and continue to update the robot angle      &#xA;    trex.write(0xE9);&#xA;    trex.write(90);&#xA;    trex.write(90);&#xA;    mag = compass.heading((LSM303::vector){0,-1,0});;   //read the angle of the robot&#xA;&#xA;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;In a function called with a speed and angle (heading), the trex part tells the motor controller to turn on a point and the while loop should test for when the desired heading is reached. However, testing using a couple of instances of &lt;code&gt;Serial.println(mag);&lt;/code&gt; I have determined that once inside the while loop, mag never changes which just means the robot turns indefinitely. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have no idea why this would happen. Perhaps someone here does?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks.&lt;/p&gt;&#xA;" OwnerDisplayName="mark mcmurray" LastActivityDate="2013-06-26T22:20:07.560" Title="Why does my LSM303 magnetometer reading not change in a while loop?" Tags="&lt;arduino&gt;" AnswerCount="1" CommentCount="11" />
  <row Id="1393" PostTypeId="1" CreationDate="2013-06-05T19:21:52.773" Score="3" ViewCount="671" Body="&lt;p&gt;I'd like to know if anyone has had success detecting a warm-bodied mammal (ie. Human) using standard off the shelf, inexpensive sensors?  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ideally, I'd like to use an inexpensive sensor or combination of sensors to detect a person within a room and localize that person. I would like the robot to enter a room, detect if a human(s) is/are present and then move to the detected human. The accuracy does not need to be 100%, as cost is more of a factor. I'd like the computational requirements of such a sensor to be such that it can run on an Arduino, although if it's impossible, I'd be willing to utilize something with more horespower, such as a Raspberry Pi or a BeagleBone Black. I have a few thoughts; however, none of them are ideal:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;PIR Sensor&lt;/strong&gt; - Can detect movement within a large field of vision (ie. usually 120 degrees or more).  Might be the closest thing to a &quot;human&quot; detector that I'm aware of; however, it requires movement and localizing/triangulating where a person is would be very difficult (impossible?) with such a large field of vision.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Ultrasound&lt;/strong&gt; - Can detect objects with good precision.  Has a much narrower field of view; however, is unable to differentiate between a static non-living object and a human.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;IR detectors&lt;/strong&gt; - (ie. Sharp range sensors) Can again detect objects with great precision, very narrow field of view; however, it is again unable to differentiate objects.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Webcam + OpenCV&lt;/strong&gt; - Possibly use face detection to detect human(s) in a room.  This may be the best option; however, OpenCV is computationally expensive and would require much more than an arduino to run.  Even on a Raspberry Pi, it can be slow.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Kinect&lt;/strong&gt; - Using the feature detection capabilities of Kinect, it would be relatively easy to identify humans in an area; however, the Kinect is too expensive and I would not consider it a &quot;cheap&quot; solution.  &lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Perhaps someone is aware of a inexpensive &quot;heat-detector&quot; tuned to body heat and/or has had success with some combination of (#1-4) above and would like to share their results?&lt;/p&gt;&#xA;" OwnerUserId="1428" LastEditorUserId="1428" LastEditDate="2013-06-05T21:57:03.077" LastActivityDate="2013-12-12T03:49:52.140" Title="What is the cheapest / easiest way of detecting a person?" Tags="&lt;sensors&gt;&lt;sensor-fusion&gt;" AnswerCount="3" CommentCount="2" FavoriteCount="3" />
  <row Id="1394" PostTypeId="1" CreationDate="2013-05-30T04:32:11.880" Score="0" ViewCount="166" Body="&lt;p&gt;I am working on a robotic application under R.O.S. groovy Galapagos.&#xA;I would like to make a tutorial about how create a template app with catkin_create_qt_pkg.&#xA;I'm unable to call the script &lt;code&gt;catkin_create_qt_pkg&lt;/code&gt; from my catkin workspace.&#xA;I found it at the root : _/opt/ros/groovy/qt_ros/qt_create/script_&#xA;But even if I try to execute it as sudoer I got an error.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;ImportError: No module named qt_create&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;I'm unable to determine what I have to do to make it work.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Why?&lt;/p&gt;&#xA;" OwnerUserId="1647" OwnerDisplayName="Jonny_S" LastEditorUserId="350" LastEditDate="2013-06-05T23:31:30.170" LastActivityDate="2013-07-16T02:18:44.297" Title="qt ros tutorial issue" Tags="&lt;c++&gt;&lt;ros&gt;" AnswerCount="2" CommentCount="1" />
  <row Id="1395" PostTypeId="1" CreationDate="2013-05-28T11:57:44.080" Score="0" ViewCount="59" Body="&lt;p&gt;I try to compile my private project and run&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;`rosmake myproject`&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;under my own workspace $HOME/.../groovy_workspace/sandbox/&lt;/p&gt;&#xA;&#xA;&lt;p&gt;and then there's a error msg like there is a dependancy on a non-existent package 'sensor_msgs'. I think this is a 3 Party Package for ros and find in Internet the following command lines&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;`roslocate info sensor_msgs &amp;gt; sensor_msgs.rosinstall`&#xA;`rosinstall . sensor_msgs.rosinstall`&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I try it under my groovy_workspace directory and try to compile my project again. And this time there's a similar error msg since a need  a nother dependancey PCL. I installed it using the same approach and try to compile my project again. And this time I need another package flann again. What worse is, roslocate can not find the package at all, there's some contacting error:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;`error contacting http://ros.org/doc/api/flann/stack.yaml:`&#xA;`HTTP Error 404: Not Found`&#xA;`error contacting http://ros.org/doc/api/flann/manifest.yaml:`&#xA;`HTTP Error 404: Not Found`&#xA;`cannot locate information about flann`&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I also tried rosdep update / rosdep install flann, but it can't also not find it:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;`ERROR: Rosdep cannot find all required resources to answer your query`&#xA;`Missing resource flann`&#xA;`ROS path [0]=/opt/ros/groovy/share/ros`&#xA;`ROS path [1]=/home/arch/Workspace/groovy_workspace/flann`&#xA;`ROS path [2]=/home/arch/Workspace/groovy_workspace/pcl`&#xA;`ROS path [3]=/home/arch/Workspace/groovy_workspace/sensor_msgs`&#xA;`ROS path [4]=/home/arch/Workspace/groovy_workspace/sandbox`&#xA;`ROS path [5]=/opt/ros/groovy/share`&#xA;`ROS path [6]=/opt/ros/groovy/stacks`&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I think maybe I overlook some basics, since I'm new to ROS. Can someone tell what I've been missing? Or is thers some general approach , to make installation of 3 Party Package easier?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thank you&#xA;Regards&lt;/p&gt;&#xA;" OwnerDisplayName="user2428378" LastActivityDate="2013-06-05T19:37:07.470" Title="ros groovy (arch) 3 party packages installation" Tags="&lt;ros&gt;" CommentCount="1" />
  <row Id="1396" PostTypeId="2" ParentId="578" CreationDate="2013-06-05T20:06:48.530" Score="3" Body="&lt;p&gt;NXT-G is based on LabView. If you don't like LabView, you won't like NXT-G. Good news though. Lego just debuted Mindstorms EV3. It uses a language based on ICON. Something you may be more interested in. It should be available this winter. &lt;a href=&quot;http://mindstorms.lego.com/en-us/News/ReadMore/Default.aspx?id=476243&quot; rel=&quot;nofollow&quot;&gt;http://mindstorms.lego.com/en-us/News/ReadMore/Default.aspx?id=476243&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, while browsing questions on this site, I learned about this: &lt;a href=&quot;http://www.ros.org/wiki/Robots/NXT&quot; rel=&quot;nofollow&quot;&gt;http://www.ros.org/wiki/Robots/NXT&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A group has apparently built bindings that are relatively simple to use for the Robot Operating System and NXT. EV3 is still cooler, but if you simply must use NXT, I would give ROS a try.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;ROS uses &lt;a href=&quot;https://code.google.com/p/nxt-python/&quot; rel=&quot;nofollow&quot;&gt;NXT-python&lt;/a&gt; which you might also give a look as well.&lt;/p&gt;&#xA;" OwnerUserId="1433" LastEditorUserId="1433" LastEditDate="2013-06-06T00:26:23.560" LastActivityDate="2013-06-06T00:26:23.560" />
  <row Id="1397" PostTypeId="2" ParentId="1393" CreationDate="2013-06-05T21:55:21.363" Score="2" Body="&lt;p&gt;A combination of a passive infrared detector (PIR) and sonar range finder (SRF) should do the trick.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What has worked well for me previously (not finding humans but very similar) was to have two PIRs on the left and right sides pointed so they have a little bit of overlap in the middle.&lt;br&gt;&#xA;You can then figure out if the human is to the left, right or in front (when both are on). You basically then stack this on top of the SRF which will tell you range etc. It is a bit dirty and you have to make some assumptions, but it works well for it's simplicity.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The pseudo code for the 2 PIRs could be something as dead simple as:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;amount = 60; //degrees&#xA;while (notCloseEnough)&#xA;{&#xA;  if (bothActive)&#xA;    forward;&#xA;  else &#xA;  {&#xA;    if (leftActive)  &#xA;      turnRightByAmount(amount);&#xA;    else&#xA;      turnLeftByAmount(amount);&#xA;    amount = amount - 5;&#xA;&#xA;    //recalibrate&#xA;    if (amount &amp;lt;= 0)&#xA;      amount = 60;&#xA;  }&#xA;&#xA;  checkIfCloseEnough();&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;The idea is that you turn a lot to one side (60 degrees) if you see something in that area. If they are not in front of you after the turn, turn a little bit less to the side which you are seeing them. Keep repeating and narrowing the amount of turn until they are in front of you, then forward. Remember that you do not turn as much (reset the angle) once they are in front because the will not move 'out of scope' as quick.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I was genuinely amazed by how good this algorithm actually works (we used it for automated chase toys and had to slow/dumb it down because it would beat/catch a human controlled robot too easily).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Both sensors are available from Pololu (no affiliation):&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.pololu.com/catalog/product/1635&quot; rel=&quot;nofollow&quot;&gt;Passive Infrared Detector&lt;/a&gt;&lt;br&gt;&#xA;&lt;a href=&quot;http://www.pololu.com/catalog/product/723&quot; rel=&quot;nofollow&quot;&gt;Sonar Range Finder&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1330" LastEditorUserId="-1" LastEditDate="2013-12-12T03:49:52.140" LastActivityDate="2013-12-12T03:49:52.140" CommentCount="1" />
  <row Id="1398" PostTypeId="2" ParentId="1344" CreationDate="2013-06-05T23:14:28.237" Score="2" Body="&lt;p&gt;Aluminum. Simply because you're going to want to make improvements and design changes. I assume cost is a major consideration else you probably would not ask this question. You're free to get creative, adaptive and constantly make changes if you go with a cheaper material. It would be a shame to inhibit creativity because of budget constraints.&lt;/p&gt;&#xA;" OwnerUserId="1435" LastActivityDate="2013-06-05T23:14:28.237" />
  <row Id="1399" PostTypeId="1" CreationDate="2013-06-06T02:38:59.163" Score="2" ViewCount="80" Body="&lt;p&gt;I've worked with wiimote accelerometer, but I think now I want to move past that. Mostly because I want to have a wider range of available gestures and I think that using only one accelerometer has too many limitations for what I want to do. I'm looking for something compatible with arduino or RPi. Does anyone have recommendations on how I should do this?&lt;/p&gt;&#xA;" OwnerUserId="1433" LastEditorUserId="350" LastEditDate="2013-06-06T21:45:53.507" LastActivityDate="2013-06-17T16:51:42.220" Title="Wearable Accelerometor" Tags="&lt;control&gt;&lt;sensors&gt;&lt;accelerometer&gt;" AnswerCount="2" CommentCount="1" />
  <row Id="1400" PostTypeId="1" CreationDate="2013-06-06T02:46:34.377" Score="2" ViewCount="379" Body="&lt;p&gt;I want to embed environmental data collected from sensors into a live video stream from a camera. Has anyone done this or know how I would go about doing something like this? Is there a library available for the arduino or RPi?&lt;/p&gt;&#xA;" OwnerUserId="1433" LastEditorUserId="350" LastEditDate="2013-10-07T18:47:15.867" LastActivityDate="2013-11-10T23:29:52.210" Title="Stream Real-time Video with Environmental Data Overlaid" Tags="&lt;sensors&gt;&lt;cameras&gt;" AnswerCount="3" CommentCount="1" FavoriteCount="1" />
  <row Id="1401" PostTypeId="2" ParentId="1400" CreationDate="2013-06-06T04:59:47.260" Score="0" Body="&lt;p&gt;There are no ready-made open-source solutions that incorporate both streaming video &amp;amp; sensor data from an Arduino that I am aware of; however, it wouldn't be too hard to build your own.  You would need a webcam + software for live streaming, then you'd need to interface your Rpi with the Arduino in order to access sensors that are connected to the Arduino via Python (or other language).  The easiest way of doing that is through the i2c bus, which will leave both USB ports on the Pi free, so you can connect a webcam, and even a USB wifi stick.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://sourceforge.net/projects/mjpg-streamer/&quot; rel=&quot;nofollow&quot;&gt;&lt;strong&gt;mjpg-streamer&lt;/strong&gt;&lt;/a&gt; - if your webcam supports MJPEG, it is the best and least computationally expensive way of streaming live video from your Raspberry Pi.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://blog.oscarliang.net/raspberry-pi-arduino-connected-i2c/&quot; rel=&quot;nofollow&quot;&gt;&lt;strong&gt;RPi + Arduino via i2c&lt;/strong&gt;&lt;/a&gt; - Tutorial for connecting the Rpi to the Arudino via i2c (uses Python SMBus library).  You will need to modify the Arduino code to send the sensor data you need based upon the byte value sent from the Pi.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;You would then edit the php page hosted by the mjpg daemon to add your sensor data that you would collect via Python and the SMBus library.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can launch mjpg-streamer using the following:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;./mjpg_streamer -i &quot;./input_uvc.so&quot; -o &quot;./output_http.so -w ./www&quot;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;or for webcams w/o MJPEG support:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;./mjpg_streamer -i &quot;./input_uvc.so&quot; -o &quot;./output_http.so -y -w ./www&quot;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;You can then view the livestream at localhost:8080&lt;/p&gt;&#xA;" OwnerUserId="1428" LastEditorUserId="1428" LastEditDate="2013-06-06T05:07:18.660" LastActivityDate="2013-06-06T05:07:18.660" />
  <row Id="1402" PostTypeId="2" ParentId="1399" CreationDate="2013-06-06T06:13:43.043" Score="3" Body="&lt;p&gt;What you want is a three-axis (or sometimes triple-axis, three-axes) accelerometer, which will allow you to detect the magnitude and direction of the acceleration. If you want to detect the acceleration of one part relative to another part, then you need an accelerometer for each part. I2C is a reasonably standard sensor protocol. I2C accelerometers are available off-the-shelf, and Arduino has libraries for I2C communication.&lt;/p&gt;&#xA;" OwnerUserId="1438" LastActivityDate="2013-06-06T06:13:43.043" />
  <row Id="1404" PostTypeId="2" ParentId="1400" CreationDate="2013-06-06T15:28:17.970" Score="0" Body="&lt;p&gt;I have done something similar using the Robot Operating System (ROS). It makes streaming data really easy, although it might be more than you're asking for, and I'm not sure how much support for RPi there is. Basically, after installing ROS, you would just need to download  the mjpeg_server (&lt;a href=&quot;http://ros.org/wiki/mjpeg_server&quot; rel=&quot;nofollow&quot;&gt;http://ros.org/wiki/mjpeg_server&lt;/a&gt;) package for streaming video and rosbridge (&lt;a href=&quot;http://www.ros.org/wiki/rosbridge_suite&quot; rel=&quot;nofollow&quot;&gt;http://www.ros.org/wiki/rosbridge_suite&lt;/a&gt;) for streaming other types of data. ROS probably already has support for your webcam, but you'd probably have to write ROS nodes to collect other sensor data and publish them to topics. With rosbridge, you can easily expose those topics to the web on websockets.&lt;/p&gt;&#xA;" OwnerUserId="181" LastActivityDate="2013-06-06T15:28:17.970" />
  <row Id="1405" PostTypeId="2" ParentId="1348" CreationDate="2013-06-06T15:52:31.753" Score="0" Body="&lt;p&gt;It could have been using Parellel Tracking and Mapping (PTAM: &lt;a href=&quot;http://www.robots.ox.ac.uk/~gk/PTAM/&quot; rel=&quot;nofollow&quot;&gt;http://www.robots.ox.ac.uk/~gk/PTAM/&lt;/a&gt;). PTAM is an implementation of the Simultaneous Localization and Mapping (SLAM) problem that uses a single camera to build a 3D map of the world and localize by tracking visual features.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My team once experimented with using the PTAM package in ROS: &lt;a href=&quot;http://www.ros.org/wiki/ptam&quot; rel=&quot;nofollow&quot;&gt;http://www.ros.org/wiki/ptam&lt;/a&gt;. We were running Ubuntu on an Intel Atom, and as I recall it didn't grain too much of the processor. We didn't end up using though, mainly because we couldn't get it to find enough features in the environment where our robot would be running.&lt;/p&gt;&#xA;" OwnerUserId="181" LastActivityDate="2013-06-06T15:52:31.753" />
  <row Id="1406" PostTypeId="2" ParentId="1336" CreationDate="2013-06-06T19:40:50.397" Score="3" Body="&lt;p&gt;The &lt;a href=&quot;http://en.wikipedia.org/wiki/Hungarian_algorithm&quot; rel=&quot;nofollow&quot;&gt;Hungarian Algorithm&lt;/a&gt; should be suitable for this case. You have already generated the cost matrix that describes the cost of each measurement to each object. The algorithm determines the assignments that yield the minimum total cost. It can handle cases with more measurements that objects (false positives) and more objects than measurements (when an object isn't detected). (These cases have non-square cost matrices.) &lt;/p&gt;&#xA;&#xA;&lt;p&gt;This will assign all measurements if the number of objects if M measurements &amp;lt;= N objects. However, you can then go back and look at the individual costs of the assignments and apply a threshold to weed out matches with low scores.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are many libraries in various programming languages for this algorithm. One I've used and is well documented is the &lt;a href=&quot;https://pypi.python.org/pypi/munkres/&quot; rel=&quot;nofollow&quot;&gt;munkres python library&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="1125" LastActivityDate="2013-06-06T19:40:50.397" />
  <row Id="1407" PostTypeId="2" ParentId="1383" CreationDate="2013-06-07T02:43:46.290" Score="3" Body="&lt;p&gt;Have you considered modeling the robot in a simulator? &lt;a href=&quot;http://www.v-rep.eu/&quot; rel=&quot;nofollow&quot;&gt;V-REP&lt;/a&gt; is new and quite good, having lots of examples robots from other famous projects. &lt;a href=&quot;http://gazebosim.org/&quot; rel=&quot;nofollow&quot;&gt;Gazebo&lt;/a&gt; is another popular one that is usually used with ROS (although V-REP also has ROS support). Both run on linux and are open-source.&lt;/p&gt;&#xA;" OwnerUserId="181" LastActivityDate="2013-06-07T02:43:46.290" CommentCount="3" />
  <row Id="1408" PostTypeId="1" AcceptedAnswerId="1412" CreationDate="2013-06-07T13:41:23.617" Score="3" ViewCount="283" Body="&lt;p&gt;So I want to program something that will simply push a button, but controllable over ethernet.  I'm new to robotics so I don't know where to start.  What's the best way to control an actuator over a network connection?&lt;/p&gt;&#xA;" OwnerUserId="1432" LastEditorUserId="32" LastEditDate="2013-06-07T16:10:33.357" LastActivityDate="2014-01-09T00:24:38.540" Title="Pushing Buttons Remotely over Ethernet" Tags="&lt;arduino&gt;&lt;actuator&gt;" AnswerCount="3" CommentCount="1" FavoriteCount="2" />
  <row Id="1409" PostTypeId="2" ParentId="1408" CreationDate="2013-06-07T15:01:17.560" Score="1" Body="&lt;p&gt;Are you talking about something similar to &lt;a href=&quot;http://www.youtube.com/watch?v=7TcdAJ3LjtM&quot; rel=&quot;nofollow&quot;&gt;this setup&lt;/a&gt;? If so, the code in &lt;a href=&quot;http://forum.arduino.cc/index.php/topic,112311.0.html&quot; rel=&quot;nofollow&quot;&gt;this thread&lt;/a&gt; could be helpful, as well as the video found &lt;a href=&quot;http://bildr.org/2011/06/arduino-ethernet-pin-control/&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What I focused on was first getting Arduino to work as a Web-server (a bit like &lt;a href=&quot;http://www.makeuseof.com/tag/give-your-arduino-project-its-own-mini-webserver-with-an-ethernet-shield/&quot; rel=&quot;nofollow&quot;&gt;this&lt;/a&gt;), then including hyperlinks in the Arduino-generated page that would then allow me to control the actuator.&lt;/p&gt;&#xA;" OwnerUserId="32" LastEditorUserId="32" LastEditDate="2013-06-07T15:06:41.407" LastActivityDate="2013-06-07T15:06:41.407" />
  <row Id="1410" PostTypeId="2" ParentId="1408" CreationDate="2013-06-07T15:04:33.883" Score="3" Body="&lt;p&gt;One approach would be to use and &lt;a href=&quot;https://www.sparkfun.com/categories/103&quot; rel=&quot;nofollow&quot;&gt;Arduino&lt;/a&gt; with an &lt;a href=&quot;https://www.sparkfun.com/products/9026&quot; rel=&quot;nofollow&quot;&gt;ethernet shield&lt;/a&gt;. There are plenty of examples online for both of these devices. From there you would just need to create a GUI and the build your robot to push the button.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-06-07T15:04:33.883" />
  <row Id="1411" PostTypeId="2" ParentId="1339" CreationDate="2013-06-07T17:47:41.113" Score="1" Body="&lt;p&gt;You can fly anything you want in class G airspace. Generally speaking, if you're far from any airport or military training area, you are probably walking around in  class G. To be sure, though, you should consult a &lt;a href=&quot;http://aeronav.faa.gov/index.asp?xml=aeronav/applications/VFR/chartlist_sect&quot; rel=&quot;nofollow&quot;&gt;current FAA sectional chart&lt;/a&gt; for your area.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Class G is considered &quot;uncontrolled&quot; by the FAA. Note however that there are other regulations and agencies that restrict flight activities there. Sadly there is no &quot;easy&quot; answer in U.S. airspace.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In most cases, except for special situations like in the mountains, Class G extends up to 1200 ft above the ground (AGL).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm quite familiar with airspace rules because of my previous job (UAV operator).  I guarantee you can fly anything you want, but see for yourself: &lt;a href=&quot;http://en.wikipedia.org/wiki/Airspace_class_(United_States)#Class_G&quot; rel=&quot;nofollow&quot;&gt;http://en.wikipedia.org/wiki/Airspace_class_(United_States)#Class_G&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1444" LastEditorUserId="1527" LastEditDate="2013-06-21T19:14:18.543" LastActivityDate="2013-06-21T19:14:18.543" />
  <row Id="1412" PostTypeId="2" ParentId="1408" CreationDate="2013-06-07T21:13:26.127" Score="2" Body="&lt;p&gt;First, let's consider what actuator you need to physically push a button. One straight forward solution is to use a RC-Servo motor. An RC-Servo motor is a high torque (DC motor with gearbox) actuator which can be instructed to rotate at a specific angle. It is controlled through a PWM signal. So you need to figure out the duty cycle of the PWM signal to do the desired movement and push the button you want.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Secondly we need a controller that:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;is able to generate a PWM signal&lt;/li&gt;&#xA;&lt;li&gt;communicate through the Internet&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;First thing that comes to my mind is to use a Raspberry Pi. Of course it is a huge overkill to use it just for pushing a button but in the process you will learn a lot of interesting things about setting up Raspberry Pi. You can setup a minimal web-server using python in less that 5 minutes.&#xA;Arduino with an Ethernet shield as DaemonMaker suggested is also a great setup.&lt;/p&gt;&#xA;" OwnerUserId="1445" LastEditorUserId="2447" LastEditDate="2014-01-09T00:24:38.540" LastActivityDate="2014-01-09T00:24:38.540" CommentCount="2" />
  <row Id="1413" PostTypeId="1" AcceptedAnswerId="1415" CreationDate="2013-06-09T21:29:14.680" Score="2" ViewCount="203" Body="&lt;p&gt;In general, is a Raspberry Pi processor powerful enough for a mobile chatbot? I want to make a small mobile robot that is like a chatbot. Is a Raspberry Pi processor powerful enough for any type of AI robotics?&#xA;As far as a mobile robot, I want to make a wheeled robot about one foot in every dimension. The chatbot abilities will be from ProgramPY-SH, a new chatbot program that uses Xaiml databases. The chatbot works by looking through a database for a match of the user's input (vocal or text-based). It then acts according to the instructions given by the XML-like database.&lt;/p&gt;&#xA;" OwnerUserId="1309" LastEditorUserId="1309" LastEditDate="2013-06-09T21:51:36.760" LastActivityDate="2013-06-10T22:00:45.510" Title="Is a Raspberry Pi processor powerful enough for a mobile chatbot?" Tags="&lt;mobile-robot&gt;&lt;raspberry-pi&gt;&lt;artificial-intelligence&gt;" AnswerCount="1" CommentCount="4" />
  <row Id="1414" PostTypeId="1" AcceptedAnswerId="1462" CreationDate="2013-06-10T16:08:43.623" Score="3" ViewCount="91" Body="&lt;p&gt;I am currently working on a legged hexapod which moves around using a tripod gait. I have two sets of code to control the tripod. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Set 1: Time based control&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In this code set, I set the tripod motor set to move at their rated rpm for a required amount of time before shifting to the other tripod motor set.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;PID control would be based on counting the number of transitions using an optical speed encoder, Calculating the error based on difference between actual speed and required speed and then adjusting the error with fixed Kd and Ki values.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Set 2: Transitions based control&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In this code set I count to the number of transitions required to complete one rotation of the leg(tripod motor set) before starting the other leg(tripod motor set).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;PID control would be time based. Calculation of error would be the difference in time taken for individual motors of the motor set.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Query:&#xA;The set 2 shows promising results even without PID control, but the first set does not.Why so? The motors are basically set to move 1 rotation before the other set moves. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Would the speed differences between the motors cause it to destabilize?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How often do I update the PID loop?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My robot seems to drag a little bit. How do I solve this?&lt;/p&gt;&#xA;" OwnerUserId="333" LastEditorUserId="350" LastEditDate="2013-06-22T18:59:32.230" LastActivityDate="2013-06-23T01:34:44.000" Title="PID Conundrums for Legged Robots" Tags="&lt;mobile-robot&gt;&lt;pid&gt;&lt;hexapod&gt;&lt;legged&gt;" AnswerCount="2" CommentCount="4" FavoriteCount="1" />
  <row Id="1415" PostTypeId="2" ParentId="1413" CreationDate="2013-06-10T22:00:45.510" Score="1" Body="&lt;p&gt;Despite its price, the Raspberry Pi is a rather powerful platform that can run most Linux desktop applications but the most CPU/memory hungry. For example, Quake 3 has been shown to &lt;a href=&quot;http://www.youtube.com/watch?v=e_mDuJuvZjI&quot; rel=&quot;nofollow&quot;&gt;run in 1080p&lt;/a&gt; on it.&lt;/p&gt;&#xA;" OwnerUserId="1400" LastActivityDate="2013-06-10T22:00:45.510" />
  <row Id="1416" PostTypeId="1" AcceptedAnswerId="1487" CreationDate="2013-06-11T00:11:39.623" Score="3" ViewCount="139" Body="&lt;p&gt;I'm involved in research on psychologically plausible models of reinforcement learning, and as such I thought it'd be nice to try and see how well some to the models out there perform in the real world (i.e. sensory-motor learning on a mobile robot). This is already been done in some robotics labs, such Sutton's &lt;a href=&quot;http://webdocs.cs.ualberta.ca/~sutton/papers/horde-aamas-11.pdf&quot; rel=&quot;nofollow&quot;&gt;implementation of the Horde Architecture on the &quot;Critterbot&quot;&lt;/a&gt;. However, these implementations involve robots custom-build by robotics experts in order to deal with the trials and tribulations of learning on a long time-scale: &lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;&quot;The robot has been&#xA;  designed to withstand the rigors of reinforcement learning&#xA;  experiments; it can drive into walls for hours without damage or burning out its motors, it can dock autonomously&#xA;  with its charging station, and it can run continuously for&#xA;  twelve hours without recharging.&quot;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Unfortunately I'm no expert when it comes to designing robots, and don't have access to a high quality machine shop even if I did; I'm stuck with whatever I can buy off-the-self or assemble by hand. Are these constraints common enough for amateur robotics suppliers to cater to, or should I expect to have to start from scratch?&lt;/p&gt;&#xA;" OwnerUserId="1460" LastEditorUserId="1460" LastEditDate="2013-06-12T03:44:01.973" LastActivityDate="2013-06-27T04:28:24.337" Title="Building robots with high reliability, durability, and battery life" Tags="&lt;mobile-robot&gt;&lt;batteries&gt;&lt;reinforcement-learning&gt;" AnswerCount="2" CommentCount="12" />
  <row Id="1417" PostTypeId="1" CreationDate="2013-06-11T07:29:41.250" Score="-1" ViewCount="61" Body="&lt;p&gt;How would you go about building a robot that can use a computer? Type on the keyboard, move &amp;amp; click mouse? I am talking about physically manipulating the hardware inputs, and the robot would be able to see the screen. Not connected to anything. It's purely autonomous. My hope is that this will replace human QA testers.&lt;/p&gt;&#xA;" OwnerUserId="1462" LastActivityDate="2013-06-11T10:01:20.850" Title="What is the best way to go about building a robot hand that can type on keyboard, move &amp;click mouse, swipe touchscreens?" Tags="&lt;wheeled-robot&gt;&lt;artificial-intelligence&gt;&lt;robotic-arm&gt;" AnswerCount="1" CommentCount="6" ClosedDate="2013-06-11T11:28:02.617" />
  <row Id="1418" PostTypeId="2" ParentId="1417" CreationDate="2013-06-11T10:01:20.850" Score="2" Body="&lt;p&gt;Your question contains a bunch of questions which i would try to reveal in the first place:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; &lt;em&gt;What kind of drive would i need to solve the task of typing keyboards, clicking a mouse etc.?&lt;/em&gt; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Basically this is answered by your requirements of motion which are force, velocity, range to name the most important. Every type of drive has its own privileges according these requirements, but you totally have an eye on costs and your control as well. For these kind of tasks i would suggest a pneumatic drive for example. But it could be a combination of different types as well, e.g. wrist - electrical drive, finger - pneumatics and so on.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; &lt;em&gt;What kind of control would i need to control these motions?&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; For this you have to consider several aspects such as complexity, your chosen drive, energy consumption (mobile systems!!) and costs as well. Hardware would not be a problem since embedded systems nowadays are quite powerful and performant. But in your case your control would contain closed loops since you need a feedback on force to not destroy your touchpad and keyboard. Which is in general quite complex and difficult to solve in realtime. If we are speaking of recognition by images etc., then hallelujah..&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; &lt;em&gt;Which tools do i need?&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; First of all a your well trained brain :) But in general you would start to desing a simulation for your drives and control to be sure everything COULD work out fine. Then you would need tools for design and layout. These tools are quite expensive as you may have guessed already..&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; &lt;em&gt;Where to start?&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Think in modules. Start with the very basic part and easily spoken integrate all parts to subsystems, all subsystems to a whole system. But don't forget to run tests /  simulations on every level! Every change afterwards will exploder your time (and cost) consumption exponential!&lt;/p&gt;&#xA;" OwnerUserId="1329" LastActivityDate="2013-06-11T10:01:20.850" CommentCount="1" />
  <row Id="1419" PostTypeId="1" CreationDate="2013-06-11T10:07:54.903" Score="6" ViewCount="316" Body="&lt;h1&gt;A little background of my aim&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;I am in the process of building a mobile autonomous robot which must navigate around an unknown area, must avoid obstacles and receive speech input to do various tasks. It also must recognize faces, objects etc. I am using a Kinect Sensor and wheel odometry data as its sensors. I chose C# as my primary language as the official drivers and sdk are readily available. I have completed the Vision and NLP module and am working on the Navigation part. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;My robot currently uses the Arduino as a module for communication and a Intel i7 x64 bit processor on a laptop as a CPU.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is the overview of the robot and its electronics: &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://i.stack.imgur.com/Oo3PD.jpg&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/Oo3PDm.jpg&quot; alt=&quot;overview of the robot&quot;&gt;&lt;/a&gt;&#xA;&lt;a href=&quot;http://i.stack.imgur.com/sYjNL.jpg&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/sYjNLm.jpg&quot; alt=&quot;electronics of the robot&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;h1&gt;The Problem&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;I implemented a simple SLAM algorithm which gets robot position from the encoders and the adds whatever it sees using the kinect (as a 2D slice of the 3D point cloud) to the map.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is what the maps of my room currently look like:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://i.stack.imgur.com/4NzwA.png&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/0jcKv.png&quot; alt=&quot;what a map looks like of my room&quot;&gt;&lt;/a&gt; &lt;a href=&quot;http://i.stack.imgur.com/r81Bd.png&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/r81Bd.png&quot; alt=&quot;Another map my room&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is a rough representation of my actual room:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://i.stack.imgur.com/tsbzE.jpg&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/AnKvn.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As you can see, they are &lt;strong&gt;very&lt;/strong&gt; different and so really bad maps.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Is this expected from using just dead reckoning?&lt;/li&gt;&#xA;&lt;li&gt;I am aware of particle filters that refine it and am ready to implement, but what are the ways in which I can improve this result? &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;h1&gt;Update &lt;br /&gt;&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;I forgot to mention my current approach (which I earlier had to but forgot). My program roughly does this: (I am using a hashtable to store the dynamic map)&#xA;&lt;br /&gt;&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Grab point cloud from Kinect&lt;/li&gt;&#xA;&lt;li&gt;Wait for incoming serial odometry data&lt;/li&gt;&#xA;&lt;li&gt;Synchronize using a time-stamp based method&lt;/li&gt;&#xA;&lt;li&gt;Estimate robot pose (x,y,theta) using equations at &lt;a href=&quot;http://en.wikipedia.org/wiki/Dead_reckoning#Differential_steer_drive_dead_reckoning&quot; rel=&quot;nofollow&quot;&gt;Wikipedia&lt;/a&gt; and encoder data&lt;/li&gt;&#xA;&lt;li&gt;Obtain a &quot;slice&quot; of the point cloud&lt;/li&gt;&#xA;&lt;li&gt;My slice is basically an array of the X and Z parameters&lt;/li&gt;&#xA;&lt;li&gt;Then plot these points based on the robot pose and the X and Z params&lt;/li&gt;&#xA;&lt;li&gt;Repeat&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="1463" LastEditorUserId="350" LastEditDate="2013-06-11T19:33:42.813" LastActivityDate="2013-06-12T08:59:05.333" Title="How can I improve the map in my Mobile Autonomous Robot using KINECT" Tags="&lt;arduino&gt;&lt;slam&gt;&lt;kinect&gt;&lt;odometry&gt;" AnswerCount="3" FavoriteCount="2" />
  <row Id="1420" PostTypeId="2" ParentId="1419" CreationDate="2013-06-11T12:03:33.367" Score="1" Body="&lt;p&gt;Is this what would be expected: in principle yes. Although you may be able to improve your odometry model, in general it is not enough to get a good map. Without a description of your system its difficult to say how to improve it. On most systems translation estimation is better than rotation. You could add a gyro and measure the rotation. This should improve your results significantly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Instead of implementing a particle filter yourself, you could use a SLAM implementation e.g. from &lt;a href=&quot;http://openslam.org/&quot; rel=&quot;nofollow&quot;&gt;openslam&lt;/a&gt;. This should save you a lot of time, and will most likely give better results.&lt;/p&gt;&#xA;" OwnerUserId="127" LastActivityDate="2013-06-11T12:03:33.367" CommentCount="3" />
  <row Id="1421" PostTypeId="2" ParentId="1305" CreationDate="2013-06-11T15:05:56.397" Score="0" Body="&lt;p&gt;Does a simple serial sketch work? If yes, then try using this code:&#xA;What this does is it takes two bytes simultaneously, the  first indicating the pin number and the second the analog value, and then sets the pin mode. I am sure you can modify it for your own needs. This is the code I use for my robot. Hope this helps. (sorry, arduino indentation is weird)&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;int pin = -999;&#xA;int val = -999;&#xA;int count = 0;&#xA;&#xA;void setup()&#xA;{&#xA;    Serial.begin(9600);&#xA;}&#xA;&#xA;void loop()&#xA;{&#xA;&#xA;}&#xA;&#xA;void serialEvent()&#xA;{&#xA;    //As soon as a byte arrives&#xA;    while(Serial.available())&#xA;    {&#xA;        //Read it&#xA;       int data = Serial.read();&#xA;       if (count == 0)&#xA;       {&#xA;           pin = data;&#xA;       }&#xA;       else if(count == 1)&#xA;       {&#xA;           val = data;&#xA;       }&#xA;       count = count + 1;&#xA;&#xA;       if (count == 2)&#xA;       {&#xA;          //Time for reset&#xA;          count = 0;&#xA;&#xA;          //execute&#xA;          analogWrite(pin,val);&#xA;&#xA;       }&#xA;    } &#xA;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="1463" LastActivityDate="2013-06-11T15:05:56.397" />
  <row Id="1422" PostTypeId="2" ParentId="884" CreationDate="2013-06-11T15:08:46.877" Score="1" Body="&lt;p&gt;I have worked with &lt;a href=&quot;http://sicktoolbox.sourceforge.net/&quot; rel=&quot;nofollow&quot;&gt;the Sick LIDAR Matlab/C++ Toolbox&lt;/a&gt;, its pretty easy to use and does the job very well.&lt;/p&gt;&#xA;" OwnerUserId="1463" LastEditorUserId="350" LastEditDate="2013-07-11T17:30:11.980" LastActivityDate="2013-07-11T17:30:11.980" CommentCount="2" />
  <row Id="1423" PostTypeId="2" ParentId="1305" CreationDate="2013-06-11T19:03:22.787" Score="3" Body="&lt;p&gt;I rewrote your program a bit. Not tested since I have no servos.&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#include &amp;lt;Servo.h&amp;gt;&#xA;Servo ULF; // Upper left front servo&#xA;Servo LLF; // Lower left front servo&#xA;byte index = 0;&#xA;int commandnum=1;&#xA;int steps = 0; // position of LLF servo&#xA;int partnum = 0; // unused for now&#xA;String command = &quot;&quot;; // the command we're building&#xA;char in;                // character to read&#xA;int angle;              // desired angle&#xA;&#xA;void setup()&#xA;{&#xA;  LLF.attach(0);&#xA;  ULF.attach(1);&#xA;  Serial.begin(9600);&#xA;}&#xA;&#xA;void loop()&#xA;{&#xA;    // define a protocol for commands, maybe like this:&#xA;    // [XXX&amp;lt;d&amp;gt;] where XXX is command and &amp;lt;d&amp;gt; is the angle,&#xA;    // the brackets [] indicates start and stop of a &quot;packet&quot; ( the command ).&#xA;    // Example: [LLF120], [LLF035], [LLF005]. I am here assuming a 3-digit&#xA;    // value for angle.&#xA;&#xA;    // You also need to reset the variables that holds the command data&#xA;    // when the command has been executed so that they are ready for the next command.&#xA;    // and to use parseInt() you must ensure that the serial buffer has all the &#xA;    // digits that you sent.&#xA;&#xA;  if(Serial.available() &amp;gt; 0) { // if there are more than zero bytes to read&#xA;      in = Serial.read();&#xA;      if(in == '[') // start of packet, now read command&#xA;      {&#xA;        command = &quot;&quot;;&#xA;&#xA;        // get command, 3 chars&#xA;        while(command.length() &amp;lt; 3)&#xA;        {&#xA;            if(Serial.available() &amp;gt; 0)&#xA;                command += Serial.read();&#xA;&#xA;            delay(10);  &#xA;        }&#xA;&#xA;        // get angle    &#xA;        while(Serial.available() &amp;lt; 3) &#xA;        {               &#xA;            delay(10);  &#xA;        }&#xA;&#xA;        angle = Serial.parseInt(); // find the angle we want&#xA;&#xA;        // flush buffer, all info received&#xA;        Serial.flush();&#xA;      }   &#xA;&#xA;      if(command == &quot;LLF&quot;) {&#xA;&#xA;        Serial.println(&quot;Lower Left Foot Selected.&quot;);&#xA;&#xA;        Serial.println(&quot;ANGLE: &quot;+String(angle));&#xA;&#xA;        for(int pos = 0; pos &amp;lt; angle; pos++) // for loop through positions to reach goal&#xA;        {                                  &#xA;           LLF.write(pos); // write servo position&#xA;           delay(15);&#xA;        } &#xA;        for(int pos = angle; pos &amp;gt; 0; pos--) // for loop through positions to reach goal&#xA;        {                                  &#xA;           LLF.write(pos); // write servo position&#xA;           delay(15);&#xA;        } &#xA;      }&#xA;   }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="1380" LastEditorUserId="1380" LastEditDate="2013-06-11T19:15:10.417" LastActivityDate="2013-06-11T19:15:10.417" />
  <row Id="1424" PostTypeId="2" ParentId="1305" CreationDate="2013-06-11T19:30:12.457" Score="3" Body="&lt;p&gt;According to &lt;a href=&quot;http://arduino.cc/en/Reference/ServoAttach&quot; rel=&quot;nofollow&quot;&gt;the Arduino reference for Servo.attach( )&lt;/a&gt;, you should be using pins 9 and 10, not 0 and 1.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Note that in Arduino 0016 and earlier, the Servo library supports only servos on only two pins: 9 and 10.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Verify that you are setting the proper pin number in code.  Specifically, look at these lines in your originally-posted code:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;void setup()&#xA;{&#xA;  LLF.attach(0);&#xA;  ULF.attach(1);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-06-12T19:07:24.833" LastActivityDate="2013-06-12T19:07:24.833" CommentCount="5" />
  <row Id="1425" PostTypeId="2" ParentId="1419" CreationDate="2013-06-12T05:14:48.673" Score="1" Body="&lt;p&gt;Because you are using dead reckoning the errors in estimating the pose of the robot accumulate in time. From my experience, after a while, dead reckoning pose estimation becomes useless. If you use extra sensors,like Gyroscope or Accelerometer the pose estimation will improve but since you have no feedback at some point it will diverge as before. As a result, even if you have good data from the Kinect, building an accurate map is difficult since your pose estimation is not valid.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You need to localize your robot at the same time as your try to build your map (SLAM!). So as the map is being created, the same map is also used to localize the robot. This ensures that your pose estimation will not diverge and your map quality should be better. Therefore I would suggest to study some SLAM algorithms (i.e. FastSLAM) and try to implement your own version.&lt;/p&gt;&#xA;" OwnerUserId="1445" LastEditorUserId="1445" LastEditDate="2013-06-12T08:59:05.333" LastActivityDate="2013-06-12T08:59:05.333" CommentCount="2" />
  <row Id="1426" PostTypeId="2" ParentId="1419" CreationDate="2013-06-12T08:15:28.253" Score="1" Body="&lt;p&gt;I'd suggest that you try particle filters/ EKF.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What you currently do:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;--&gt; Dead Reckoning: You're looking at your current position without any reference.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;--&gt; Continuous Localization: You roughly know where you are in the map.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you don't have a reference and don't know where you are on the map, regardless of what actions you take, you will find it dificult to obtain a perfect map.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example:&#xA;You're in a circular room. You keep moving forward. You know what was your last move. The map which you get will be that of a straight box like structure. This will occur unless and until you have some way to localize or to know where are you precisely on the map, continuously.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Localization can be done via EKF/Particle Filters if you have a starting reference point. However, the starting reference point is a must.&lt;/p&gt;&#xA;" OwnerUserId="333" LastActivityDate="2013-06-12T08:15:28.253" CommentCount="7" />
  <row Id="1427" PostTypeId="1" CreationDate="2013-06-12T10:12:54.573" Score="3" ViewCount="908" Body="&lt;p&gt;I need to control quadrotor from a PC, without using a joystick.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have got a mini-beetle &lt;a href=&quot;http://www.banggood.com/Wholesale-WLtoys-V929-Beetle-4-Axis-Dexterous-Mini-UFO-BNF-p-46046.html&quot; rel=&quot;nofollow&quot;&gt;quad V929 Beetle 4-Axis&lt;/a&gt;  and also have this &lt;a href=&quot;http://www.ebay.in/itm/281061946755?ssPageName=STRK%3aMEWNX%3aIT&amp;amp;_trksid=p3984.m1439.l2648&quot; rel=&quot;nofollow&quot;&gt;NRF24L01+ Wireless Transceiver Module Chip&lt;/a&gt; (2.4ghz transceiver)&#xA;Is it possible to write an arduino program to make them speak to each other?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I did some research and found that the quad v929 model uses flysky protocol and only works with A7105 NRF24L01 2.4ghz transmitter chip not the one which i mentioned above&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Are there any other better ways of controlling the quad from PC or arduino board?&lt;/p&gt;&#xA;" OwnerUserId="1469" LastEditorUserId="350" LastEditDate="2013-06-27T02:04:48.243" LastActivityDate="2013-06-28T20:39:10.260" Title="Controlling a Quadrotor from a PC" Tags="&lt;arduino&gt;&lt;quadcopter&gt;&lt;radio-control&gt;" AnswerCount="2" CommentCount="1" />
  <row Id="1428" PostTypeId="2" ParentId="1394" CreationDate="2013-06-12T18:31:45.447" Score="1" Body="&lt;p&gt;You will get better help for this question by asking on &lt;a href=&quot;http://answers.ros.org&quot; rel=&quot;nofollow&quot;&gt;http://answers.ros.org&lt;/a&gt;, which is a similar, but more specific forum.&lt;/p&gt;&#xA;" OwnerUserId="36" LastActivityDate="2013-06-12T18:31:45.447" />
  <row Id="1429" PostTypeId="1" CreationDate="2013-06-12T20:07:30.473" Score="1" ViewCount="111" Body="&lt;p&gt;Currently, I'm using a &lt;a href=&quot;https://www.sparkfun.com/products/10335&quot; rel=&quot;nofollow&quot;&gt;pan tilt bracket&lt;/a&gt; that works with the servos I have (spark fun product 9065), and are generic to all servos. However, servos aren't accurate enough. I'm looking at other options, but have limited knowledge about them. What would you recommend?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;An important consideration is that I need my motor to tilt in two dimensions, to any random $x, y$ coordinate accurately. To do this, I think I'll need some sort of attachment to the motor shaft, like the pan tilt bracket.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What motor and bracket would you recommend I use to go to any random $(x,y)$ coordinate?&lt;/p&gt;&#xA;" OwnerUserId="1471" LastEditorUserId="1471" LastEditDate="2013-06-13T15:01:51.687" LastActivityDate="2013-06-13T15:01:51.687" Title="Pan and tilt bracket for a stepper motor" Tags="&lt;servos&gt;&lt;stepper-motor&gt;&lt;motion&gt;" CommentCount="3" ClosedDate="2013-06-18T10:45:10.930" />
  <row Id="1430" PostTypeId="2" ParentId="1378" CreationDate="2013-06-12T23:16:23.480" Score="2" Body="&lt;p&gt;This depends on a few things. First of all, are you using ArduPlane or ArduCopter, and what mode are you in? For ArduPlane, your answers are &lt;a href=&quot;http://plane.ardupilot.com/wiki/flying/starting-up-and-calibrating-arduplane/&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;, and for arducopter, &lt;a href=&quot;http://copter.ardupilot.com/wiki/flying-arducopter/&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In both cases, the software has safeguards that will not let you arm or start the motor while it is initializing. In both cases, the LEDs indicate when it is ready to arm or fly. Of course, these behaviours are mostly configurable. For example, you can set the MANUAL_LEVEL parameter in ArduPlane to 1 if you want to skip the accelerometer calibration on each boot.&lt;/p&gt;&#xA;" OwnerUserId="1473" LastActivityDate="2013-06-12T23:16:23.480" CommentCount="2" />
  <row Id="1431" PostTypeId="2" ParentId="1378" CreationDate="2013-06-13T02:57:13.260" Score="2" Body="&lt;p&gt;The LEDs on the board indicate the status of the Ardupilot. See the &lt;a href=&quot;http://code.google.com/p/arducopter/wiki/AC2_LEDs&quot; rel=&quot;nofollow&quot;&gt;LEDs on the boards&lt;/a&gt; on the Arducopter wiki for more detail. Of interest to you are likely the A (red), B (yellow), and C (blue) LEDs. LED A is solid when the motors are armed and blinks otherwise. LED B flashes while the Ardupilot calibrates. Finally LED C indicates the status of the GPS module if there is one.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Edit: I just noticed you are using Arduplane in which case you want to reference the &lt;a href=&quot;http://code.google.com/p/ardupilot-mega/wiki/LED&quot; rel=&quot;nofollow&quot;&gt;LEDs and their meanings&lt;/a&gt; page on the Arduplane wiki. The meanings are basically the same though it appears you do not have the option arm/disarm the motors.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-06-13T02:57:13.260" CommentCount="2" />
  <row Id="1432" PostTypeId="2" ParentId="1393" CreationDate="2013-06-13T08:17:04.370" Score="0" Body="&lt;p&gt;a capacitive sensor could work, it's really cheap to make, just aluminum foil and a few resistors, it can detect flesh but i'm not sure if iy doesn't detect anything but flesh, you can use 3 to triangulate&lt;/p&gt;&#xA;" OwnerUserId="1477" LastActivityDate="2013-06-13T08:17:04.370" />
  <row Id="1433" PostTypeId="2" ParentId="1393" CreationDate="2013-06-13T14:35:33.793" Score="0" Body="&lt;p&gt;I can't say whether this is easiest, but conceivably you could use the &lt;a href=&quot;http://people.csail.mit.edu/mrub/vidmag/&quot; rel=&quot;nofollow&quot;&gt;Eulerian Video Magnification library&lt;/a&gt; to detect the pulse of a person.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In that case, you would be looking for a fluctuation in the video that matched the expected range of human pulses.  You would also need a clear image of a body part that exhibited the visible pulse.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There has also been some work (&lt;a href=&quot;http://www.eecg.toronto.edu/~jayar/pubs/theses/Mccready/RobertMccready.pdf&quot; rel=&quot;nofollow&quot;&gt;example 1&lt;/a&gt;, &lt;a href=&quot;http://www.cse.psu.edu/~cg577/LECTURES/L9-2005.pdf&quot; rel=&quot;nofollow&quot;&gt;example 2&lt;/a&gt;) exploring hardware-based face detection.  Digital cameras from a few years ago had this capability, which was essentially a highly optimized neural network designed to say &quot;does this square contain a face or not&quot;... then you just iterate over a set of predefined squares in the captured image.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-06-13T14:35:33.793" />
  <row Id="1434" PostTypeId="2" ParentId="1025" CreationDate="2013-06-14T19:27:12.030" Score="2" Body="&lt;p&gt;Try &lt;a href=&quot;http://ros.org/wiki/freenect_stack&quot; rel=&quot;nofollow&quot;&gt;freenect&lt;/a&gt;, there are some problems with OpenNI solution.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Firt, install freenect by&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;sudo apt-get install ros-fuerte-freenect-stack&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;After installation, connect your kinect (in USB 2.0 port) and run freenect &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;roslaunch freenect_launch freenect.launch&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Then run Rviz and set Fixed frame to /camera_link, you can now add PointCloud2 window and select the right topic to view the input.&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;rosrun rviz rviz&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Hope you enjoy ROS!&lt;/p&gt;&#xA;" OwnerUserId="405" LastActivityDate="2013-06-14T19:27:12.030" />
  <row Id="1435" PostTypeId="1" AcceptedAnswerId="1436" CreationDate="2013-06-14T22:04:40.517" Score="5" ViewCount="135" Body="&lt;p&gt;I'm looking at laser scanners and I see a huge range of detection distances.  The furthest I've see are 30m if you exclude the very expensive ones that claim up to 150m.  My question is what is the reason for the huge difference in range/price.  I would think that with a laser it wouldn't be that difficult to detect something at distances greater than 30m.  What's the physical limitation that makes it so much more expensive to go above 30m for a laser scanner or is there one?&lt;/p&gt;&#xA;" OwnerUserId="529" LastActivityDate="2013-06-14T23:16:17.137" Title="laser scanner distance" Tags="&lt;localization&gt;" AnswerCount="1" />
  <row Id="1436" PostTypeId="2" ParentId="1435" CreationDate="2013-06-14T23:06:14.220" Score="9" Body="&lt;p&gt;It may be worthwhile to consider how laser scanners work. We know that it is possible to send a beam of light at an object, and detect how long it takes to be reflected back to the sensor to measure its distance.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;First of all, we use lasers because reflection of the light from the object is so important. lasers keep the light concentrated in a narrow beam, with minimal refraction. We'll come back to that later.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are several ways to measure distance. The first is triangulation. This typically depends on good placement of optics, and the CCD sensor the return beam shines onto. You can easily see the problem with a large distance - the angle detected gets increasingly close to $0^\circ$, so that we need sensor components which are very accurate at small scales. We would also like a beam width which is narrow for accurate detection of where the beam is, but there is greater diffraction at narrow beam widths, meaning the return beam of light is not that narrow. Over long distances, the beam gets increasingly wider, because of the small amount of diffraction.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The second way is to measure the round-trip time. Light travels very fast at $3\times 10^8  \textrm{m/s}$. This means that even detecting something at $150 \textrm{m}$ will take $1 \textrm{μs}$. Embedded computers typically have a clock rate of only several megahertz, so even at this large distance, a system would struggle to provide an accuracy of 10%, and that is assuming the data acquisition is as fast - often the peripheral features have a slower clock rate.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The data acquisition is typically much slower, allowing cheaper systems to be built. As to how they can get away with this - an interesting phenomenon is used. If a sinusoidal signal is embedded into the light (via the intensity), the return signal will also be a sinusoidal signal. However, depending on the distance, the signal will have a phase shift. That is, at $0 \textrm m$, there is no phase shift, and if the wavelength is $20 \textrm m$, then an object at $5 \textrm m$ will mean that the light travels $10 \textrm m$, creating a phase shift of $180^\circ$. If the signals are normalized to the same amplitude, taking the difference between the outbound signal, and the return signal, we get another analog sinusoidal signal (note: this is only one method). The amplitude of this depends on the phase shift. At $180^\circ$, we get the maximum amplitude - double of the original outbound signal. We can easily detect the amplitude of this signal even with slow digital circuitry.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The main problem is that the choice of wavelength limits the maximum range. For example, the wavelength of $20 \textrm m$ limits the detection range to only $5\textrm m$. If we simply chose a much longer wavelength, we would get the same percentage accuracy. In many cases, if we want greater absolute accuracy, the system will have a greater cost, since we must more accurately measure amplitude in the face of environmental noise. This may involve a number of changes - for example, a larger laser beam, greater light intensity, and more accurate electronic components, more shielding of noise, and more power to run the system. If any one of these is not good enough, accuracy is affected.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The other problem which affects all methods is the intensity of the return beam. As the distance increases, the intensity decreases. There is not that much scatter of light in air, so attenuation is not so much caused by this. However, even though a laser light is used, there is a very small amount of diffraction. It is not possible to remove this diffraction completely, although it can be decreased with a wider beam width. Diffraction reduces the amount of the returning light beam incident on the sensor. Because the beam width gradually increases, the sensor only receives a small proportion of the returning light. This affects the accuracy of measurements. Using a larger sensor can also increase noise. Therefore, here we also see another limit on the distance. We can increase the distance by increasing light intensity, or increasing beam width. However, increasing light intensity increases power consumption and heat, while increasing beam width requires larger optic lenses, and larger distances between optic components.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Essentially, there is a balance between cost, accuracy, power consumption, and size of the system, and longer distances often requires better components to maintain accuracy.&lt;/p&gt;&#xA;" OwnerUserId="145" LastEditorUserId="145" LastEditDate="2013-06-14T23:16:17.137" LastActivityDate="2013-06-14T23:16:17.137" CommentCount="1" />
  <row Id="1437" PostTypeId="1" CreationDate="2013-06-15T22:30:49.067" Score="2" ViewCount="999" Body="&lt;p&gt;I haven't made or flown any quadcopter, but I am fascinated by them.&#xA;But when looking at the frame of a lot of designs, after whachting &lt;a href=&quot;http://www.youtube.com/watch?v=dAyDi1aa40E&quot; rel=&quot;nofollow&quot;&gt;this video&lt;/a&gt; I wondered why a lot the frames are in an X shape. Since the most efficient shape would according to the video be something like this &gt;-&amp;lt;, where each corner is 120°.&#xA;I also did a quick search on the internet and found &lt;a href=&quot;http://deltaquadlog.blogspot.nl/2013/03/frame-design.html&quot; rel=&quot;nofollow&quot;&gt;this blog&lt;/a&gt; which stated the same (however he did not mention the exact angle) and said: &quot;Even though this is not entirely a new idea, it has not yet been widely accepted by the community.&quot;&lt;/p&gt;&#xA;" OwnerUserId="1487" LastActivityDate="2013-06-16T01:17:21.320" Title="Most material efficient quadcopter frame" Tags="&lt;design&gt;&lt;quadcopter&gt;&lt;quadrotor&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="1438" PostTypeId="2" ParentId="1437" CreationDate="2013-06-16T01:17:21.320" Score="1" Body="&lt;p&gt;If adjacent motors are 1 unit apart, the overall path-length of an X form is 2√2, or about 2.8284, and the overall path-length of a Steiner form is 1+√3, or about 2.732, which is 3.5% less.  It is likely that hub mounting will decrease either or both of the total lengths by a few percent, but I will ignore that factor for the moment and merely say that the length improvement provided by using a Steiner form is quite small.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In addition, the Steiner form will require either two hubs or one rather-long hub, and may require mounting hardware for spokes at six points instead of four.  Because hub weight often is comparable to the weight of one or more spokes, the Steiner form has a weight disadvantage.  (See “&lt;a href=&quot;http://www.rcgroups.com/forums/showthread.php?t=1718951&quot; rel=&quot;nofollow&quot;&gt;Intro to Multirotors, Theory, Build Log and Tips&lt;/a&gt;” for a series of pictures that illustrate relative hub and spoke sizes for a variety of quadcopters.) &lt;/p&gt;&#xA;&#xA;&lt;p&gt;A central point, as available with an X-frame, is a convenient location for a battery and a controller that serves all the motors.  For balance, an extra pad for mounting the battery and controller would be needed on the middle bar of a Steiner frame (unless multiple batteries and controllers are used).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note, the &lt;a href=&quot;http://www.wowhobbies.com/quacopters-drones-quad-flyers.aspx&quot; rel=&quot;nofollow&quot;&gt;quacopters-drones-quad-flyers&lt;/a&gt; page at wowhobbies.com includes a quadcopter, hexacopter and octocopter buying guide, in which several units are characterized by &lt;em&gt;IAS&lt;/em&gt;, meaning there is “Inadequate Structural Support (eg: booms are too long and center frame is too weak to support the size of the quadcopter structure or any substantial payload)”.   As size scales up, the crossbar in the Steiner form needs to scale up more than the rest of the arm structure (which will also overpower that form's 3.5% length advantage) else the frame will become structurally inadequate.&lt;/p&gt;&#xA;" OwnerUserId="478" LastActivityDate="2013-06-16T01:17:21.320" />
  <row Id="1440" PostTypeId="1" CreationDate="2013-06-17T09:16:42.640" Score="0" ViewCount="110" Body="&lt;p&gt;How do you know if a commercial driver is working with trapezoidal or sinusoidal commutation? If you measure the 3-phase voltage applied to the PMSM by means of an oscilloscope, will you see a difference?&lt;/p&gt;&#xA;" OwnerUserId="1494" LastEditorUserId="350" LastEditDate="2013-06-17T17:17:50.590" LastActivityDate="2013-06-17T17:37:31.993" Title="trapezoidal vs sinusoidal commutation" Tags="&lt;brushless-motor&gt;" AnswerCount="1" />
  <row Id="1441" PostTypeId="2" ParentId="1399" CreationDate="2013-06-17T10:46:55.350" Score="2" Body="&lt;p&gt;The Mpu6050, or 9150 is great for gesture sensing. The 6050 has a 3 axis accelerometer and a 3 axis gyro. The 9150 has all that, as well as a 3 axis magnetometer.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Theoretically, you can program gestures into it that trigger an external interrupt when they are activated. Unfortunately, Invensense, the makers of the chip have not been forthcoming with documentation on how to do that.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you want to write the gesture reconization yourself, then there is a library for getting plain data as well as quaternions from the 6050 at &lt;a href=&quot;https://github.com/jrowberg/i2cdevlib&quot; rel=&quot;nofollow&quot;&gt;https://github.com/jrowberg/i2cdevlib&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you go with the 9150, there is a great resource of code at &lt;a href=&quot;https://github.com/Pansenti/MPU9150Lib&quot; rel=&quot;nofollow&quot;&gt;https://github.com/Pansenti/MPU9150Lib&lt;/a&gt;, which includes resources to do some of the higher level processing the 9150 is capable of.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I actually am trying to use the line of mpu's myself, as part of a rocketlogger project. I have some of my code at &lt;a href=&quot;http://waterrocketry.com&quot; rel=&quot;nofollow&quot;&gt;http://waterrocketry.com&lt;/a&gt; It doesn't entirely work yet, but it is still a work in progress, and I hope to have full control of the Data Motion Processing of the 6050 soon.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Good luck with what your building&lt;/p&gt;&#xA;" OwnerUserId="1495" LastEditorUserId="1495" LastEditDate="2013-06-17T16:51:42.220" LastActivityDate="2013-06-17T16:51:42.220" />
  <row Id="1442" PostTypeId="2" ParentId="1440" CreationDate="2013-06-17T17:37:31.993" Score="1" Body="&lt;p&gt;I'm reasonably sure that the sinusoidal wave will look like a sign wave, and that the trapezoidal wave will look more square-ish. The image below explains it better:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/ccHs1.jpg&quot; alt=&quot;Trapezoidal vs Sinusoidal waves&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="1495" LastActivityDate="2013-06-17T17:37:31.993" CommentCount="1" />
  <row Id="1443" PostTypeId="1" CreationDate="2013-06-18T07:33:21.043" Score="0" ViewCount="48" Body="&lt;p&gt;The last robotics project I worked on involved autonomous outdoor navigation, using a microcontroller for lower-level control and a computer for image processing and decision making. I worked more with the higher-level software and another guy on the team did the electrical and embedded systems. I would like to be capable of doing everything, including stuff with embedded, but I'm not sure where to look for information. If I were to have done the project from scratch on my own, I'd need to know:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;What microcontroller to use&lt;/li&gt;&#xA;&lt;li&gt;What motors are required &lt;/li&gt;&#xA;&lt;li&gt;What motor controllers to get, and how to interface with the controllers&lt;/li&gt;&#xA;&lt;li&gt;What encoders to use for motor feedback, and how to write drivers for them&lt;/li&gt;&#xA;&lt;li&gt;What batteries to use and how to safely power everything &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;If I were trying to learn about higher-level software, I'd probably take a few courses on Udacity. Are there any good resources out there like that for this kind of low-level stuff?&lt;/p&gt;&#xA;" OwnerUserId="181" LastActivityDate="2013-06-18T13:15:33.340" Title="Learning about embedded systems" Tags="&lt;microcontroller&gt;&lt;power&gt;&lt;embedded-systems&gt;" AnswerCount="1" CommentCount="5" ClosedDate="2013-06-18T23:21:11.387" />
  <row Id="1444" PostTypeId="2" ParentId="1443" CreationDate="2013-06-18T13:15:33.340" Score="1" Body="&lt;p&gt;While I don't know about any online resources for what you want, I learned my skills by trying and failing, probably the best method to learn this sort of stuff if you have the time to do it. If you don't have much time, your best bet is probably just googling  stuff that you need to know.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A lot of good information can also be found in university thesis or research papers, also a lot of quality parts from reputable manufacturers come with really good documentation on how to use them. The documentation can sometimes be overwhelming, but at least it will point you in the right direction.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And if you did't find anything you need after the steps above, just ask here, that's why this site exists.&lt;/p&gt;&#xA;" OwnerUserId="890" LastActivityDate="2013-06-18T13:15:33.340" />
  <row Id="1445" PostTypeId="1" CreationDate="2013-06-18T13:37:46.553" Score="3" ViewCount="784" Body="&lt;p&gt;I'm doing a project related to telemetry, and I want to make ArduPilot (programmed with ArduPlane 2.73) send through a serial port the sensors informations such as height, GPS position, etc.. I have tried to use ArduStation, but I could not change its firmware to do what I want. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The idea would be to read the Ardupilot's serial port using an Arduino Uno, and then saving it in a SD card in real-time. So ArduPilot needs to send data without any user input or something like that. I've already tried to manipulate ArduPlane source code to do that, but I couldn't either.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Has someone here did something like that before? I need some advice!&lt;/p&gt;&#xA;" OwnerUserId="1502" LastEditorUserId="1473" LastEditDate="2013-08-16T20:06:58.230" LastActivityDate="2013-08-28T21:41:23.587" Title="How to get data from ArduPilot through Serial Port" Tags="&lt;arduino&gt;&lt;ardupilot&gt;" AnswerCount="2" />
  <row Id="1446" PostTypeId="2" ParentId="1445" CreationDate="2013-06-18T15:18:49.450" Score="2" Body="&lt;p&gt;I understand a new Ardupilot was released recently. I am not familiar with it, so if that's the device you have then this answer may not be helpful. With that said I have done something similar to what you are doing with the Ardupilot Mega. Specifically I wrote a node in ROS to control a quadrotor and read its state. The Ardupilot uses a fairly simple protocol called &lt;a href=&quot;http://qgroundcontrol.org/mavlink/start&quot; rel=&quot;nofollow&quot;&gt;Mavlink&lt;/a&gt; to communicate with other systems. You can get the library from the QGroundControl website linked above. From there you will connect the serial port on your Uno to the Xbee port on the APM. There are two caveats however. First, I don't know whether the Mavlink library will fit on the Uno though I believe it will. Second, it does require that your Uno query the APM by sending requests for data but they are simple enough to construct. The purpose for this is to control the flow of information. If I recall correctly you can instruct the device to repeatedly send the data you are interested in but you will have to review the documentation to confirm as much. &lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-06-18T15:18:49.450" CommentCount="2" />
  <row Id="1447" PostTypeId="1" CreationDate="2013-06-18T22:29:13.170" Score="0" ViewCount="21" Body="&lt;p&gt;I am about to enter my junior year of college for my Electrical Engineering/Computer Engineering double major, and it is reaching that point where I need to choose an area to specify in. I find the field of robotics extremely interesting, however I have no experience (other than some basic Arduino programing) or knowledge in robotics. Are there any &quot;blow my mind&quot; articles out there or projects that are being worked on to persuade me that this is the area I want to continue my education in?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, are there any beginner robotics projects that I could work on in my free time to gain a little experience?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks in advance!&lt;/p&gt;&#xA;" OwnerUserId="1505" LastActivityDate="2013-06-18T22:29:13.170" Title="Prospective Robotics Student" Tags="&lt;research&gt;" CommentCount="1" ClosedDate="2013-06-18T23:14:55.960" />
  <row Id="1448" PostTypeId="1" CreationDate="2013-06-18T10:38:45.997" Score="3" ViewCount="517" Body="&lt;p&gt;I am trying to implement a line following robot that can solve mazes similar to the Pololu robots you can watch on youtube. My problem is the maze that I am trying to solve is looped and therefore simple Left/Right hand rule can not solve the maze. I have done some research and think either Flood-Fill or Breadth-First-Search algorithm will be able to solve these looped mazes. Solving the maze is reaching a large black area where all the sensors will read black. When the robot is following the line some of the sensors will read white and the central ones black.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there any other algorithms that can solve looped mazes? I understand how the Flood-Fill algorithm works but am unsure how it could be implemented in this situation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My robot has 3 sensors on the bottom. The one in the centre is expected to always read black (the black line it follows) and the sensors on the right and left are expected to read white (while following a straight line) and then black once a junction or turn is reached. My robot has no problem following the line, turning etc. I need to find an algorithm that can solve looped mazes (that is, find a path from an entrance to an exit).&lt;/p&gt;&#xA;" OwnerUserId="1512" OwnerDisplayName="user2476983" LastEditorUserId="134" LastEditDate="2013-08-20T07:40:58.113" LastActivityDate="2013-08-20T07:40:58.113" Title="Maze Solving Algorithm For Mazes With Loops" Tags="&lt;mobile-robot&gt;&lt;motion-planning&gt;&lt;line-following&gt;&lt;routing&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="1449" PostTypeId="1" AcceptedAnswerId="1459" CreationDate="2013-06-20T07:12:43.997" Score="1" ViewCount="129" Body="&lt;p&gt;I'm trying to understand how noise is represented for accelerometers, gyroscopes, and magnetometers so that I can match the requirements of my project with the standard specs of these sensors. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I want the output of a 3 axis inertial sensor to be values in meters/sec/sec, gauss, and radians/sec for each axis, and noise to be represented by a range around the true value (so X as in +/- X m/s/s, gauss, and radians/sec) for accelerometers, magnetometers, and gyroscopes respectively. Switching out gauss for teslas, meters for feet, radians for degrees, etc. would all be fine.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;After looking at a few datasheets, I'm surprised to find that... &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Accelerometer noise is measured in &quot;LSB rms&quot; and &quot;μg/√Hz&quot;(&lt;a href=&quot;https://www.sparkfun.com/datasheets/Sensors/Accelerometer/ADXL345.pdf&quot; rel=&quot;nofollow&quot;&gt;https://www.sparkfun.com/datasheets/Sensors/Accelerometer/ADXL345.pdf&lt;/a&gt;, &lt;a href=&quot;http://dlnmh9ip6v2uc.cloudfront.net/datasheets/Sensors/Accelerometers/MMA8452Q.pdf&quot; rel=&quot;nofollow&quot;&gt;http://dlnmh9ip6v2uc.cloudfront.net/datasheets/Sensors/Accelerometers/MMA8452Q.pdf&lt;/a&gt;)&lt;/li&gt;&#xA;&lt;li&gt;Gyroscope noise is measured in &quot;º/s-rms&quot; and &quot;º/s/√Hz&quot; (&lt;a href=&quot;https://www.sparkfun.com/datasheets/Sensors/Gyro/PS-ITG-3200-00-01.4.pdf&quot; rel=&quot;nofollow&quot;&gt;https://www.sparkfun.com/datasheets/Sensors/Gyro/PS-ITG-3200-00-01.4.pdf&lt;/a&gt;)&lt;/li&gt;&#xA;&lt;li&gt;Magnetometer noise is measured in &quot;µT rms&quot; and &quot;Gauss/√Hz&quot; (&lt;a href=&quot;http://dlnmh9ip6v2uc.cloudfront.net/datasheets/Sensors/Magneto/MAG3110.pdf&quot; rel=&quot;nofollow&quot;&gt;http://dlnmh9ip6v2uc.cloudfront.net/datasheets/Sensors/Magneto/MAG3110.pdf&lt;/a&gt;, &lt;a href=&quot;http://www.vectornav.com/products/vn200-rug?id=54&quot; rel=&quot;nofollow&quot;&gt;http://www.vectornav.com/products/vn200-rug?id=54&lt;/a&gt;)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;What do these units mean, and how do they (or can they) translate into what I want?&lt;/p&gt;&#xA;" OwnerUserId="181" LastEditorUserId="350" LastEditDate="2013-06-25T16:01:04.643" LastActivityDate="2013-06-25T16:01:04.643" Title="How are units of noise measurement related to units of a sensor's data measurement?" Tags="&lt;imu&gt;&lt;accelerometer&gt;&lt;gyroscope&gt;&lt;noise&gt;&lt;magnetometer&gt;" AnswerCount="1" />
  <row Id="1450" PostTypeId="1" CreationDate="2013-06-20T14:39:21.563" Score="1" ViewCount="20" Body="&lt;p&gt;I want to do a project where I control motors, and the arduino seems ideal for that. However, I'm going to need to do quite a bit of processing on the back end first. Connecting the arduino to a computer isn't an option, because it has to be quite mobile. Does anyone have any experience controlling arduino with raspberry pi?&lt;/p&gt;&#xA;" OwnerUserId="1310" LastActivityDate="2013-06-20T14:39:21.563" Title="How would I go about interfacing the raspberry pi and arduino?" Tags="&lt;arduino&gt;&lt;raspberry-pi&gt;" CommentCount="2" ClosedDate="2013-06-20T15:28:24.073" />
  <row Id="1451" PostTypeId="2" ParentId="150" CreationDate="2013-06-20T16:32:28.930" Score="1" Body="&lt;p&gt;On one of my remotely controlled boats, I used this design...&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/NB48i.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The blue discs are flywheels. They are attached to the green rods which are hooked to both sides of a flexible, waterproof membrane. The membrane is fixed to both sides of the casing so it will transmit the motion, but it will not let water through.&lt;/p&gt;&#xA;" OwnerUserId="1423" LastActivityDate="2013-06-20T16:32:28.930" CommentCount="1" />
  <row Id="1452" PostTypeId="2" ParentId="1344" CreationDate="2013-06-20T21:03:17.630" Score="1" Body="&lt;p&gt;I would say, that it depends on how you fly it, if you think you are going to crash it a lot, and if you make a lot of changes/improvements. Aluminum is pretty damn cheap, and it has, depending on how you fly/crash, one big advantage, it's flexible. Sudden high G-forces don't crack aluminum, carbon fiber on the other hand is very rigid.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So if you are a professional R/C pilot, that build's it right the first time, and doesn't crash a lot, I would say Carbon fiber.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you make a lot of changes, are not a very good pilot, or think you are going to stress it a lot, I would say Aluminum. &lt;/p&gt;&#xA;" OwnerUserId="1520" LastActivityDate="2013-06-20T21:03:17.630" />
  <row Id="1453" PostTypeId="2" ParentId="543" CreationDate="2013-06-21T03:36:13.773" Score="3" Body="&lt;p&gt;The mechanical answers above are correct. The inherent stability problems with single large motors are exchanged for dynamic comtrol over 12 dimensions of acceleration, yaw, pitch, roll which can be partially coupled (the translational amd rotational matrix) where one is presented with a simplified diagonal inertial frame to build a dynamic model with. In this model there is also an inverse relation between the radius of the quad and the translational and rotational agility. It becomes very easy to &quot;dodge bullets&quot; at very very small radii.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To answer the question &lt;em&gt;How do you get pure yaw motion with a quadcoptor?&lt;/em&gt;, in comments to &lt;a href=&quot;http://robotics.stackexchange.com/a/549/37&quot;&gt;this answer&lt;/a&gt;, you get pure yaw in the following way: &lt;/p&gt;&#xA;&#xA;&lt;p&gt;North and South motors rotating the same speed but collectively at a higher (or lower) speed than East and West Motors which are also at the same speed. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;It won't pitch or roll, it will yaw y'all. (Sorry)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Furthermore, in software one can control the copter after breaking off the north and south propellers at the expense of yaw control, the craft will continuously spin and as long as the frequency of software refresh rate is able to handle the speed of yaw rotation the copter remains exactly as stable (sort of) the dimension of acceleration is clipped and response or jerk is also somewhat clipped but it can move pitch and yaw just the same by compensating in software. (Desired yaw state becomes virtually coupled to the physical state)&lt;/p&gt;&#xA;" OwnerUserId="1521" LastEditorUserId="37" LastEditDate="2013-07-09T11:19:12.633" LastActivityDate="2013-07-09T11:19:12.633" CommentCount="1" />
  <row Id="1454" PostTypeId="1" AcceptedAnswerId="1456" CreationDate="2013-06-22T00:59:26.140" Score="5" ViewCount="90" Body="&lt;p&gt;I was wondering if it is possible to plug a motor shield on top of an Ethernet shield, even though the direction pins on the motor shield would be connected to the same pins as the spi bus.  I was thinking that it would work if, in the coding, I disabled both chip selects on the Ethernet shield before I used the motors.&lt;/p&gt;&#xA;" OwnerUserId="1263" LastActivityDate="2013-06-22T12:42:41.000" Title="Motor and Ethernet shields together" Tags="&lt;arduino&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="1455" PostTypeId="1" CreationDate="2013-06-22T01:13:51.013" Score="2" ViewCount="91" Body="&lt;p&gt;&lt;em&gt;&lt;strong&gt;TL;DR:&lt;/em&gt;&lt;/strong&gt;&#xA;Can anyone point me to a good adaptive path fill algorithm?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Hey there, my name is James, and &lt;a href=&quot;http://sylviashow.com&quot; rel=&quot;nofollow&quot;&gt;my daughter&lt;/a&gt; built &lt;a href=&quot;http://watercolorbot.com&quot; rel=&quot;nofollow&quot;&gt;an awesome painting robot&lt;/a&gt; with her friends over at Evil Mad Scientist labs, even brought it to the white house, very fun stuff!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Anyways, I'm a web programmer by day, and though it might be fun to try and write some software to get the robot to do some cool stuff, and for some crazy reason I decided to do this using standard web technologies like SVG and JavaScript, and.. it actually works! [see the project at github.com/techninja/robopaint]&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;But there's a problem:&lt;/strong&gt; to fill in colors for given shapes, it requires some kind of path filling algorithm using a given size shape to cover every part of the shape internally, not to mention it has to take into account overlapping paths and occlusions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have successfully created &quot;&lt;em&gt;fake&lt;/em&gt;&quot; fills, by following known paths like spirals and back and forth hatch lines over paths, while detecting occlusion using browser internal functions for detecting what object lies at a given x/y coordinate, but these fill functions fall incredibly short of doing anything other than simply following paths, and can be incredibly inefficient at filling certain paths (like filling borders, letters, or &lt;strong&gt;U&lt;/strong&gt; shaped areas).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;The question:&lt;/em&gt;&lt;/strong&gt; I need an adaptive path filling algorithm. I know they're currently being used in similar CNC setups for milling, and similar algorithms are used by the Roomba and 3D printers to figure out coverage in the most efficient way possible. The issue comes in that I don't think &lt;strong&gt;&lt;em&gt;any&lt;/em&gt;&lt;/strong&gt; have ever been done in JavaScript, using native SVG paths.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Anyone out there know where I should look? I'm not too afraid to attempt to port something over to JS, or possibly even use it as is for a native Node.JS module. All my work will be sure to go back to the community and become open source as well.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks for the help!&lt;/p&gt;&#xA;" OwnerUserId="1529" LastActivityDate="2013-07-22T18:38:11.587" Title="Help with adaptive fill algorithm for Water Color Painting Robot" Tags="&lt;algorithm&gt;&lt;motion-planning&gt;&lt;motion&gt;&lt;cnc&gt;" AnswerCount="1" />
  <row Id="1456" PostTypeId="2" ParentId="1454" CreationDate="2013-06-22T12:42:41.000" Score="2" Body="&lt;p&gt;The whole point of the chipselect pin is so that multiple devices (in this case, shields) can share the same SPI bus.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As long as no two chipselect pins are the same, you ought to be fine. Make sure only one chip select pin is on at any given time.&lt;/p&gt;&#xA;" OwnerUserId="126" LastActivityDate="2013-06-22T12:42:41.000" />
  <row Id="1457" PostTypeId="1" CreationDate="2013-06-22T13:21:50.047" Score="0" ViewCount="346" Body="&lt;p&gt;3D CAD:&#xA;&lt;img src=&quot;http://i.stack.imgur.com/0heyS.jpg&quot; alt=&quot;quadcopter image&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;After some editing:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm building the frame myself from aluminum and polycarbonate.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;EDIT:&lt;/strong&gt; all frame is polycarbonate except of the arms (and all screws &amp;amp; nuts &amp;amp; washers)), they are form aluminum covered in polycarbonate. the total length (from one motor to another) is exactly &lt;em&gt;60cm&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Approximate Mass: 1.736 kg&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;&lt;strong&gt;What I thought to put in:&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Battery&lt;/strong&gt;: &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/__7634__ZIPPY_Flightmax_4000mAh_3S1P_20C.html&quot; rel=&quot;nofollow&quot;&gt;ZIPPY Flightmax 4000mAh 3S1P 20C&lt;/a&gt; (changed from this 1500mAh &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/uh_viewitem.asp?idproduct=6307&amp;amp;aff=588847&quot; rel=&quot;nofollow&quot;&gt;battery&lt;/a&gt;)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Motors&lt;/strong&gt;: &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/uh_viewitem.asp?idproduct=18151&amp;amp;aff=588847&quot; rel=&quot;nofollow&quot;&gt;Turnigy Aerodrive SK3 - 2822-1090kv&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;PDB&lt;/strong&gt;: &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/uh_viewitem.asp?idproduct=23140&amp;amp;aff=607489&quot; rel=&quot;nofollow&quot;&gt;Hobby King Quadcopter Power Distribution Board&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;ESC&lt;/strong&gt;: &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/__6457__hobbyking_ss_series_18_20a_esc.html&quot; rel=&quot;nofollow&quot;&gt;Hobbyking SS Series 18-20A ESC&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Core&lt;/strong&gt;: &lt;a href=&quot;http://www.ebay.com/itm/Nano-V3-0-ATmega328P-Arduino-Compatible-/170962843198?pt=LH_DefaultDomain_0&amp;amp;hash=item27ce2df63e&quot; rel=&quot;nofollow&quot;&gt;Arduino Nano&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;IMU&lt;/strong&gt;: &lt;a href=&quot;http://cgi.ebay.com/ws/eBayISAPI.dll?ViewItem&amp;amp;item=261231955458&quot; rel=&quot;nofollow&quot;&gt;Invensense MPU-6050&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Propellers&lt;/strong&gt;: &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/uh_viewitem.asp?idproduct=25822&amp;amp;aff=607489&quot; rel=&quot;nofollow&quot;&gt;10x4.5 SF Props 2pc Standa## Heading ##rd Rotation/2 pc RH Rotation&lt;/a&gt; (changed from 8x4.5 ones)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;I'm gonna program it myself (or atleast try to).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;I WANT TO USE IT AS A UAV (self controlled)&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;&lt;strong&gt;Questions:&lt;/strong&gt;&lt;/h2&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;Is this a good setup?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;It costs to much for me, any way to keep the frame and change the&#xA;parts to be cheaper and yet a good quadcopter?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Does the propeller fit the motor?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Any place to buy these for cheaper?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Is it a good frame?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Am I missing some parts?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Thanks alot,&#xA;Dan&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;EDIT:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;I checked it using this &lt;a href=&quot;http://www.ecalc.ch/xcoptercalc.htm?ecalc&amp;amp;lang=en&quot; rel=&quot;nofollow&quot;&gt;site&lt;/a&gt; and it gave no errors (guess its a good sign).&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;The camera on the image is just for the picture (no camera is intended there).&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="1337" LastEditorUserId="1337" LastEditDate="2013-06-23T00:35:28.220" LastActivityDate="2013-12-31T17:39:52.557" Title="Is this a good quadcopter build?" Tags="&lt;arduino&gt;&lt;motor&gt;&lt;quadcopter&gt;" AnswerCount="1" CommentCount="4" ClosedDate="2013-06-23T10:47:25.560" />
  <row Id="1458" PostTypeId="2" ParentId="1455" CreationDate="2013-06-22T17:41:56.890" Score="1" Body="&lt;p&gt;What you're looking for is a &quot;coverage algorithm&quot;.  There are a few relevant questions on this site that address this topic: &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://robotics.stackexchange.com/q/952/350&quot;&gt;What&amp;#39;s an efficient way to visit every reachable space on a grid with unknown obstacles?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://robotics.stackexchange.com/q/628/350&quot;&gt;What algorithm should I implement to program a room cleaning robot?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-06-22T17:41:56.890" CommentCount="2" />
  <row Id="1459" PostTypeId="2" ParentId="1449" CreationDate="2013-06-22T18:15:41.350" Score="3" Body="&lt;p&gt;&quot;&lt;a href=&quot;http://en.wikipedia.org/wiki/Least_significant_bit&quot; rel=&quot;nofollow&quot;&gt;LSB&lt;/a&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Root_mean_square&quot; rel=&quot;nofollow&quot;&gt;RMS&lt;/a&gt;&quot; means the root-mean-squared value of the total noise in least significant bits of the digital channel.  Roughly, that's the standard deviation of the noise times the weight of one step of the digital value.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&quot;$\mu g/\sqrt{Hz}$&quot; means the power spectral density in micro-g's ($1\mu g \simeq 0.0098 m/s$).  If the power spectral density is flat, then you can square this number, multiply it by the bandwidth, take the square root, and get to the noise as LSB RMS.  The power spectral density is useful when you try to figure out the effect of the acceleration on velocity and/or position.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&quot;$^\circ / s$-rms&quot; has a similar meaning to the &quot;LSB RMS&quot;, except the noise is referred to the rate measurement rather than the ADC bits.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&quot;$^\circ /s / \sqrt{Hz}$&quot; is, again, the power spectral density.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It should be obvious at this point what the magnetometer specifications mean.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you haven't got a background in random processes and signal analysis then you're going to have a rough time relating this back to real-world numbers, particularly if you're doing any kind of sensor fusion.  Even the &quot;big boys&quot; in the sensor fusion game can't easily map sensor noise to system behavior without lots of simulation and head-scratching.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Simpler problems will yield to analysis, however.&lt;/p&gt;&#xA;" OwnerUserId="1533" LastEditorUserId="37" LastEditDate="2013-06-25T12:38:22.240" LastActivityDate="2013-06-25T12:38:22.240" />
  <row Id="1460" PostTypeId="2" ParentId="1414" CreationDate="2013-06-22T18:30:37.043" Score="2" Body="&lt;p&gt;I believe that your set #2 works better because you're already applying feedback to it, in the form of counting transitions of your encoder.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My knee-jerk method to do this control would be to first use quadrature encoders on each motor, to make sure that I was capturing any backwards motion that might mess me up.  Then I would store a time vs. position trajectory that I wanted the motor to follow, which would result in my desired velocity trajectory.  Then I would servo the motors to the desired positions using PID control.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The rule of thumb for control loops that generally works is to sample ten times faster than your desired bandwidth.  That works out to a sampling interval that's ten times shorter than the amount of time you want to allow for your system to settle &lt;strong&gt;after&lt;/strong&gt; it is operating in its linear range (which roughly starts at the last instant that any of the variables come out of saturation).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If your encoders are coarse enough that they don't go through many transitions in your desired control loop sampling interval, you may be better off sampling at the encoder transitions.  This will make your life difficult as the speed changes, but perhaps not as difficult as trying to cope with control loop updates with insufficient information.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some of the articles linked to here may help, particularly &quot;PID Without a PhD&quot; and the one on operating motors with friction and backlash:&#xA;&lt;a href=&quot;http://www.wescottdesign.com/articles.html&quot; rel=&quot;nofollow&quot;&gt;http://www.wescottdesign.com/articles.html&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-06-22T18:30:37.043" />
  <row Id="1461" PostTypeId="2" ParentId="1457" CreationDate="2013-06-22T20:52:37.450" Score="1" Body="&lt;p&gt;First of all, don't take it personally.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am not a quad copter builder of some sort myself, but your setup is flawed: &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Battery can deliver 30A constant, maxed out. Your motors take, at full power, 8×4&amp;nbsp;= 32A. You might get away with this battery, but it won't last long because you are pushing it too hard.&lt;/li&gt;&#xA;&lt;li&gt;Big, heavy battery, low power engines/esc/battery. I don't even think your copter is going to lift of with this setup. Engines of&#xA;only 80W on a quad that, taking a look at your picture, is going to&#xA;be relatively heavy, is asking for trouble.&lt;/li&gt;&#xA;&lt;li&gt;PDB is okay with this, and future, more power-hungry (I think), motors. They probably have a safety margin, but don't push it too&#xA;hard, which for now, you are not.&lt;/li&gt;&#xA;&lt;li&gt;Arduino: you are going to &lt;em&gt;try&lt;/em&gt; and program it. Programming a quad isn't an easy task, and unless you are quite a skilled programmer, I&#xA;recommend you to buy a programmed board, something like this: &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/__21977__HobbyKing_Multi_Rotor_Control_Board_V3_0_Atmega328_PA_.html&quot; rel=&quot;nofollow&quot;&gt;Hobby&#xA;king link&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;I don't know a whole lot about copters, I'm more in the plane business, but unless you change motors, these props seem too big.&#xA;Moral of the story: get bigger engines, bigger battery, bigger ESC.&lt;/li&gt;&#xA;&lt;li&gt;I can try to recommend better motors, ESC, etc., but I won't. I don't know enough about quads to be certain it is going to work, and&#xA;I won't recommend you something I don't know for sure, sorry.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;It costs to much for me, any way to keep the frame and change the parts to be cheaper and yet a good quadcopter?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;First make sure that your setup is right, then start asking where you can get it cheaper, that's my advice. &lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Does the propeller fit the motor?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;You are going to need an adaptor, but that is normal, I'd bet there are adaptors that suit your needs.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Any place to buy these for cheaper?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Yes, but you are missing a few (important) parts, the setup you present here isn't a very expensive one, if you can't afford it, I recommend you to save money until you can buy a proper setup, you won't regret having some patience. &lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Is it a good frame?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;I can't judge if a frame is correct by one picture, there are way too many variables (like thickness of the material, where you are using aluminum, and where you are using the plastic, how are your motor mounts, what material, so on...).&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Am I missing some parts?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Yes, since I think you want to control it, you are going to need a controller, add &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/__9042__Hobby_King_2_4Ghz_6Ch_Tx_Rx_V2_Mode_2_.html&quot; rel=&quot;nofollow&quot;&gt;25$&lt;/a&gt;. Materials for the frame, camera, transmitter for the camera, ground station to receive, monitor for the video feed, so on.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I think you are taking this too lightly. You don't just build a quad for the first time, it's going to take a lot, and I mean a lot, of trial and error, and quite a bit of money.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Take your time to find the right parts.&lt;/p&gt;&#xA;" OwnerUserId="1520" LastEditorUserId="1177" LastEditDate="2013-12-31T17:39:52.557" LastActivityDate="2013-12-31T17:39:52.557" CommentCount="2" />
  <row Id="1462" PostTypeId="2" ParentId="1414" CreationDate="2013-06-23T01:34:44.000" Score="2" Body="&lt;p&gt;It sounds like you have 6 legs with some number of PID-controlled joints on each leg.  You would like to move 3 legs at a time, while the other 3 legs stand in a stable tripod configuration.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Instead of figuring out how to move each set of 3 legs as one unit, you should be treating them as individual legs.&lt;/strong&gt;  You will send a leg a set of desired joint positions, and the PID control on each joint motor will effect that change.  By sending a steady stream of desired joint positions, you will be describing a trajectory for the leg to follow.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Coordinating the actions of all 6 legs simply involves a series of checkpoints to make sure that no leg gets too far behind the others.  You need not keep all 6 legs on the same checkpoint; for example, you might keep each set of tripods tightly in sync but only sync the 2 sets at the point in the gait where the weight is shifted.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Another way to imagine the checkpoints is to consider the gait to be a series of repeated movements of each leg, where each leg is slightly phase-shifted.  In that case, the checkpoints would be the &quot;constraints&quot; on the allowed phase differences (e.g. &lt;a href=&quot;http://www.msl.ri.cmu.edu/publications/pdfs/haynes-icra-2006.pdf&quot; rel=&quot;nofollow&quot;&gt;this CMU paper&lt;/a&gt;).&lt;/em&gt;&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-06-23T01:34:44.000" />
  <row Id="1463" PostTypeId="1" CreationDate="2013-06-23T20:01:19.637" Score="1" ViewCount="186" Body="&lt;p&gt;If a motor has more Power (W) from another it means that it is better?&lt;/p&gt;&#xA;" OwnerUserId="1337" LastActivityDate="2013-06-24T02:39:37.067" Title="Does more &quot;Power&quot; (W) means better motor?" Tags="&lt;motor&gt;&lt;quadcopter&gt;&lt;power&gt;" AnswerCount="2" CommentCount="1" />
  <row Id="1464" PostTypeId="2" ParentId="1463" CreationDate="2013-06-24T00:58:34.677" Score="3" Body="&lt;p&gt;The short answer is no.  The longer answer requires more information from you, regarding how the motor is to be used.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Since you have tagged your question with &quot;quadcopter&quot;, I'm going to assume that you plan to put the motor on a UAV, in which case more power definitely does not mean &quot;better&quot;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;More power (W) will draw more current (A) from the battery (meaning a larger battery and higher all-up-weight (AUW) of the craft).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You need to choose the correct motor and prop for your particular quadcopter frame.  There is no one-size-fits-all motor for quadcopters.  In general, you should be looking for a brushless outrunner motor with low kv, and pairing it with a slow-fly prop.&lt;/p&gt;&#xA;" OwnerUserId="1474" LastActivityDate="2013-06-24T00:58:34.677" CommentCount="3" />
  <row Id="1465" PostTypeId="2" ParentId="1463" CreationDate="2013-06-24T02:39:37.067" Score="2" Body="&lt;p&gt;The wattage rating is &lt;em&gt;usually&lt;/em&gt; (read the manufacturer's specs very carefully) the measure of how much power the motor can draw.  It doesn't tell you anything more than that.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Wattage does not tell you whether the motor is &lt;a href=&quot;http://en.wikipedia.org/wiki/Energy_conversion_efficiency&quot; rel=&quot;nofollow&quot;&gt;efficient at converting the input electrical energy into output mechanical energy&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Wattage does not tell you whether the motor's &lt;a href=&quot;http://en.wikipedia.org/wiki/Power-to-weight_ratio&quot; rel=&quot;nofollow&quot;&gt;power-to-weight ratio&lt;/a&gt; is reasonable.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Wattage does not tell you whether the motor's size is reasonable for your application.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Wattage does not tell you whether the &lt;a href=&quot;http://en.wikipedia.org/wiki/Stall_torque&quot; rel=&quot;nofollow&quot;&gt;stall torque&lt;/a&gt; or maximum speed is correct for the load you wish to drive.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Wattage does not tell you whether the motor's &lt;a href=&quot;https://en.wikipedia.org/wiki/Duty_cycle#Electrical_devices&quot; rel=&quot;nofollow&quot;&gt;duty cycle&lt;/a&gt; can support the needs of your application.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are comparing 2 motors that differ &lt;em&gt;only&lt;/em&gt; by their input power rating, and more power is important to you, then yes: the motor with more power will be better for you.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-06-24T02:39:37.067" />
  <row Id="1466" PostTypeId="1" AcceptedAnswerId="1472" CreationDate="2013-06-24T05:26:18.397" Score="4" ViewCount="375" Body="&lt;p&gt;Just out of curiosity, can the concept of a Quadcopter be applied to an ROV? Would it work the same way underwater as it would be in Air? If not what kind of modifications it would take to implement that idea, underwater?&lt;/p&gt;&#xA;" OwnerUserId="1213" LastActivityDate="2013-12-29T21:17:07.600" Title="Quadcopter application underwater" Tags="&lt;quadcopter&gt;" AnswerCount="4" CommentCount="1" />
  <row Id="1467" PostTypeId="2" ParentId="954" CreationDate="2013-06-24T08:38:45.713" Score="0" Body="&lt;p&gt;The problem lies in the Servo.h file in Arduino\libraries\Servo.  The Teensy 3.0 parameters are not defined in this file and therefore it is assumed to have only one timer.  Changing the default action to copy the second last action was sufficient for my purposes, I changed it the file as follows:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#else  // everything else&#xA;#define _useTimer1&#xA;typedef enum { _timer1, _Nbr_16timers } timer16_Sequence_t ;                  &#xA;#endif&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;To:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#else  // everything else&#xA;#define _useTimer3&#xA;#define _useTimer1&#xA;typedef enum { _timer3, _timer1, _Nbr_16timers } timer16_Sequence_t ;&#xA;#endif&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;This only managed to get me 16 servos though.  I also tried adding other timers with no success in increasing the number of available servos.  Hopefully this proves useful to someone.&lt;/p&gt;&#xA;" OwnerUserId="1540" LastActivityDate="2013-06-24T08:38:45.713" />
  <row Id="1468" PostTypeId="2" ParentId="1466" CreationDate="2013-06-24T09:42:45.420" Score="0" Body="&lt;p&gt;First of all, my intuition says it'll work, same logic - props push the water/air makes the quadcopter move.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My guess is that the water resistance to the motors is much higher than the air and therefor the motors should be much stronger.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another thing might be that there is almost no way to fix it if it brakes in the water (it'll probably just drown) so you should probably &quot;extra&quot; protect your props and electronics and actually everything..&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The other thing is quite obvious, you need to protect your electronics from water so that makes the price go up a bit more.&lt;/p&gt;&#xA;" OwnerUserId="1337" LastActivityDate="2013-06-24T09:42:45.420" />
  <row Id="1469" PostTypeId="2" ParentId="954" CreationDate="2013-06-24T09:54:15.750" Score="0" Body="&lt;p&gt;There is another Servo library that can drive as many servo's as you want :&lt;a href=&quot;http://playground.arduino.cc/ComponentLib/servo&quot; rel=&quot;nofollow&quot;&gt;Link to Arduino Software Servo&lt;/a&gt;. Good luck&lt;/p&gt;&#xA;" OwnerUserId="1520" LastActivityDate="2013-06-24T09:54:15.750" />
  <row Id="1470" PostTypeId="2" ParentId="1466" CreationDate="2013-06-24T11:00:28.607" Score="7" Body="&lt;p&gt;I'm guessing that your question is based on whether the mathematical &lt;em&gt;model&lt;/em&gt; of a quadrotor would work in a water environment, and not the hardware. Quite obviously the electronics and mechanical systems would need changing to work in the water: the electronics would short and the rotors would spin too fast.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The rest of my answer is based on the work &lt;a href=&quot;http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5164715&amp;amp;tag=1&quot;&gt;Design and implementation of a structured flight controller for a 6DoF quadrotor using quaternions&lt;/a&gt; by Stingu and Lewis. The free version of that paper can be found at &lt;a href=&quot;http://www.uavdesign.net/adaptive-a-distributed-control/quaternion-based-quadrotor-control/&quot;&gt;Quaternion-Based Quadrotor Control&lt;/a&gt;. Most quadrotor models that I have studied use minor variations on the same equations for the basic flight control.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From that paper we have the following system diagram:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://i.stack.imgur.com/eVHRA.jpg&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/LSpaz.jpg&quot; alt=&quot;System control&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Operating a quadrotor model in a liquid would require one change to the model: if the physical vehicle was neutrally or positively buoyant (ie, it doesn't sink) then the model would be invalidated. In that case the model would have to adjust for flipping the quadrotor upside down to increase the depth.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The rest of the model could be used as is: it's medium independent. In fact, the only portion of the model that touches on the medium is the equations for torque and thrust of the propellers:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$&#xA;K_T = \frac{T}{\rho n^2 D^4}&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$&#xA;K_Q = \frac{Q}{\rho n^2 D^5}&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In these equations, $K_T$ is a thrust constant, $K_Q$ is a torque constant, $T$ is thrust, $\rho$ is free stream density (air or water), $n$ is rotation speed, and $D$ is rotor diameter. To operate the model in water $\rho$ just has to be replaced with the density of water ($1000 kg/m^3$).&lt;/p&gt;&#xA;" OwnerUserId="1524" LastEditorUserId="37" LastEditDate="2013-06-24T17:41:31.707" LastActivityDate="2013-06-24T17:41:31.707" />
  <row Id="1471" PostTypeId="2" ParentId="1448" CreationDate="2013-06-24T12:31:38.037" Score="2" Body="&lt;p&gt;If both entrance and exit of the maze is at the edges of the maze, the left/right hand (wall following) algorithm should work. If you start following a wall that is connected to the exit, you could never get into a loop.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you want the robot to be able to start in the middle of a maze with loops then simple wall following is not enough. I would recommend the &lt;a href=&quot;http://en.wikipedia.org/wiki/Maze_solving_algorithm#Pledge_algorithm&quot; rel=&quot;nofollow&quot;&gt;Pledge algorithm&lt;/a&gt; in that case. The basic idea is that you pick an arbritary direction and follow it until you encounter a wall. Then you follow the wall until you have made as many righ turns as left turns, then continue forward (along the direction you originally picked).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The Pledge algorithm is proven to work in the ideal case with perfect sensors or some kind of error correction. If there could be errors when turning and not all angles are 90° some further measures may be needed (for example a compass). See &lt;a href=&quot;http://academic.research.microsoft.com/Paper/688807.aspx&quot; rel=&quot;nofollow&quot;&gt;this article&lt;/a&gt; for more details (&lt;a href=&quot;http://web.informatik.uni-bonn.de/I/publications/kl-pares-03.pdf&quot; rel=&quot;nofollow&quot;&gt;direct link to the pdf&lt;/a&gt;). In your case the errors should be small enough.&lt;/p&gt;&#xA;" OwnerUserId="1542" LastEditorUserId="1542" LastEditDate="2013-06-26T18:56:17.067" LastActivityDate="2013-06-26T18:56:17.067" CommentCount="2" />
  <row Id="1472" PostTypeId="2" ParentId="1466" CreationDate="2013-06-24T17:01:00.157" Score="11" Body="&lt;p&gt;Is an underwater quadrotor possible?  Absolutely.  Whether it's practical in that configuration is a different matter.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In air, viscosity and buoyancy are negligible; in water, they are not.  An aerial quadrotor will expend energy fighting gravity, while an underwater quadrotor can simply rely on positively bouyant materials to keep it from sinking.  You can experience this yourself &amp;mdash; you can swim in water (or use a small piece of foam for flotation), but not in air.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;An underwater quadrotor will expend energy fighting the water's fluid friction, while an aerial quadrotor will move easily.  You can experience this effect as well &amp;mdash; try throwing a frisbee in air, then see how far you can &quot;throw&quot; it underwater.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you were to actually operate a quadrotor underwater, you would mostly likely fly it with the rotors oriented horizontally &amp;mdash; in the direction of travel, instead of being vertical and just tilting slightly in the direction of travel.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are some AUV designs that use 4 thrusters in a parallel orientation (and no control surfaces &amp;mdash; rudders nor elevators) to maneuver, such as Atlas Maridan's SeaWolf:&lt;br&gt;&#xA;&lt;img src=&quot;http://i.stack.imgur.com/Ddm75.jpg&quot; alt=&quot;Atlas Maridan Seawolf&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;While the torpedo shape is more designed for cruising in a forward direction, there are other vehicles with 4 thrusters (positioned for maneuverability), such as Bluefin's HAUV:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/JlXXy.jpg&quot; alt=&quot;Bluefin HAUV Prototype&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-06-24T17:01:00.157" />
  <row Id="1475" PostTypeId="1" CreationDate="2013-06-26T13:35:50.340" Score="0" ViewCount="31" Body="&lt;p&gt;I am interested in starting a robotics club at my high school next year, since we don't have one, and I want to know what the pros/cons are of common kits. I already have a Vex kit since my uncle is one of the regional suppliers for Indiana, but I'm not sure that Vex is the best choice. What are the pros/cons of the other kits out there?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note: I looked at Lego Mindstorms, and have used them when I was learning robotics, but do not want them for this. Also, i own a Raspberry Pi.&lt;/p&gt;&#xA;" OwnerUserId="1551" LastEditorUserId="1551" LastEditDate="2013-06-26T21:59:34.063" LastActivityDate="2013-06-26T21:59:34.063" Title="Pros/Cons of common robotics &quot;kits&quot; at the high school level" Tags="&lt;raspberry-pi&gt;&lt;mindstorms&gt;&lt;beginner&gt;&lt;children&gt;" CommentCount="7" ClosedDate="2013-06-26T16:48:49.507" />
  <row Id="1477" PostTypeId="5" CreationDate="2013-06-26T14:06:51.673" Score="0" ViewCount="6" Body="&lt;p&gt;From &lt;a href=&quot;http://en.wikipedia.org/wiki/Robotc&quot; rel=&quot;nofollow&quot;&gt;Wikipedia&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;ROBOTC (trademarked as ROBOTC and frequently spelled RobotC) is an Integrated development environment targeted towards students that is used to program and control LEGO NXT, VEX, RCX, and Arduino robots using a programming language based on the C programming language.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="37" LastEditorUserId="37" LastEditDate="2013-06-26T14:06:51.673" LastActivityDate="2013-06-26T14:06:51.673" />
  <row Id="1478" PostTypeId="4" CreationDate="2013-06-26T14:06:51.673" Score="0" Body="ROBOTC (trademarked as ROBOTC and frequently spelled RobotC) is an Integrated development environment targeted towards students that is used to program and control LEGO NXT, VEX, RCX, and Arduino robots using a programming language based on the C programming language. Not to be confused with &quot;Robotic&quot;. Please refrain from using this tag for general robotics questions." OwnerUserId="37" LastEditorUserId="30" LastEditDate="2013-07-31T17:43:45.553" LastActivityDate="2013-07-31T17:43:45.553" />
  <row Id="1481" PostTypeId="2" ParentId="851" CreationDate="2013-06-26T22:13:23.827" Score="1" Body="&lt;p&gt;Without going through all your code (that would be too much like real work), my gut feel is that you have weighted your control effort heavily enough that the least-cost thing to do is to do nothing and live with the error.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Yes, I know -- all your explicit weights are unity.  But still -- try giving the control effort a lower weight, or the position error a higher one.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Again without getting deeply into your code, your ilrq function may not &quot;understand&quot; the nonlinear nature of the thing you're controlling.  As such, it may not see a way to get to the pendulum upright position, and again, it may fail.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The approach that you first tried, to put just the right amount of energy into the pendulum, then regulate optimally once the pendulum is erect, is probably the best way: you know that in the absence of friction, a system with just the perfectly right amount of energy is going to end up standing still on top (however briefly), so that would seem a sensible place to start.&lt;/p&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-06-26T22:13:23.827" CommentCount="1" />
  <row Id="1482" PostTypeId="2" ParentId="1392" CreationDate="2013-06-26T22:20:07.560" Score="1" Body="&lt;p&gt;I don't know Arduino from Aardvark, so this comment is based purely on how a modern C++ compiler would behave:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Were you asking about a plain ol' C++ problem, I would ask you if compass is declared volatile, or if the 'heading' method of compass's class is declared volatile, or if your system is based on cooperative multitasking.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the first two cases (lack of things being tagged as volatile) the compiler will optimize the call to compass.heading to just outside the loop (to save you time -- isn't that nice?).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the third case, whatever the code is that actually acquires the values for the compass structure will never get a chance to run (because your code is stuck in the while loop) and you'll never see results.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I hope this makes sense to the Arduino environment...&lt;/p&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-06-26T22:20:07.560" />
  <row Id="1483" PostTypeId="1" AcceptedAnswerId="1486" CreationDate="2013-06-26T22:51:52.753" Score="3" ViewCount="83" Body="&lt;p&gt;I'm trying to find the optimal-time trajectory for an object (point mass) from point &lt;code&gt;p0&lt;/code&gt; with initial velocity &lt;code&gt;v0&lt;/code&gt; to point &lt;code&gt;p1&lt;/code&gt; with velocity &lt;code&gt;v1&lt;/code&gt;. I'm considering a simple environment without any obstacles to move around. The only constraint is a maximum acceleration in any direction of &lt;code&gt;a_max&lt;/code&gt; and optionally a maximum speed of &lt;code&gt;s_max&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is easy to work out in 1D but I struggle with the solution 2D and 3D. I could apply the 1D solution separately to each dimension, but this would only limit acceleration and speed in a single dimension. The actual acceleration might be larger in multiple dimensions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Are there any textbook, closed-form solutions to this problem? If not, how can I solve this in a discrete-event simulation?&lt;/p&gt;&#xA;" OwnerUserId="1555" LastActivityDate="2013-06-27T14:32:19.673" Title="Optimal-time trajectory in 2D and 3D with simple constraints" Tags="&lt;control&gt;&lt;motion-planning&gt;" AnswerCount="1" FavoriteCount="1" />
  <row Id="1484" PostTypeId="2" ParentId="1416" CreationDate="2013-06-27T01:35:40.590" Score="0" Body="&lt;p&gt;Off-the-shelf robot kits are a good place to start for an amateur. If you're not using system-based kits (i.e. Lego), then they can usually be modified. Mount bumpers around the sides to help it withstand crashes and add a larger battery with a higher milli-amp-hour (mAh) rating for longer battery life. It's tough to provide any more specific solutions than that.&lt;/p&gt;&#xA;" OwnerUserId="1557" LastActivityDate="2013-06-27T01:35:40.590" />
  <row Id="1485" PostTypeId="2" ParentId="1427" CreationDate="2013-06-27T01:40:58.803" Score="1" Body="&lt;p&gt;If you're open to purchasing a new quadrotor, take a look at the Crazyflie from Bitcraze. It operates exactly this way via USB dongle attached to a PC.&lt;/p&gt;&#xA;" OwnerUserId="1557" LastActivityDate="2013-06-27T01:40:58.803" />
  <row Id="1486" PostTypeId="2" ParentId="1483" CreationDate="2013-06-27T04:06:00.853" Score="3" Body="&lt;p&gt;In case you're not already aware, the problem you are asking about is generally referred to as the &lt;a href=&quot;https://en.wikipedia.org/wiki/Boundary_value_problem&quot; rel=&quot;nofollow&quot;&gt;two-point boundary value problem&lt;/a&gt;. For some systems, a closed form solution may be extremely difficult to calculate and may not even exist. As such it would help to know more about your dynamics.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Your description would seem to imply that you are working with a double integrator system. If that's accurate then you could use a fixed-final-state-free-final-time controller. Because the dynamics matrix is nilpotent you can find a closed form solution in terms of time, then minimize the function to find the optimal arrival time. From there you can use your favorite numerical integration method to verify that the accelerations are within the desired bound. This approach will actually work for any linear system with a nilpotent dynamics matrix. For additional details please see section IV, Optimally Connecting a Pair of States, of my paper &lt;a href=&quot;http://arl.cs.utah.edu/pubs/ICRA2013-1.pdf&quot; rel=&quot;nofollow&quot;&gt;Kinodynamic RRT$^*$: Asymptotically Optimal Motion Planning for Robots with Linear Dynamics&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="177" LastEditorUserId="350" LastEditDate="2013-06-27T14:32:19.673" LastActivityDate="2013-06-27T14:32:19.673" CommentCount="2" />
  <row Id="1487" PostTypeId="2" ParentId="1416" CreationDate="2013-06-27T04:28:24.337" Score="2" Body="&lt;p&gt;In short, yes, there are a number of robotics companies catering to just your needs. Specifically which apply to you depends on what type of robot you desire. Naturally cost varies with the complexity and durability. For example if you would be satisfied with a differential drive robot for indoor use then the &lt;a href=&quot;http://www.irobot.com/us/learn/Educators/Create.aspx&quot; rel=&quot;nofollow&quot;&gt;iRobot Create&lt;/a&gt; may suit your needs. If you need something for outside use then you could look at &lt;a href=&quot;http://www.clearpathrobotics.com/&quot; rel=&quot;nofollow&quot;&gt;Clearpath Robotics&lt;/a&gt; products. For a full humanoid robot the &lt;a href=&quot;http://www.aldebaran-robotics.com/en/&quot; rel=&quot;nofollow&quot;&gt;Aldeberan Nao&lt;/a&gt; is a good choice. For quadrotors check out the &lt;a href=&quot;http://ardrone2.parrot.com/&quot; rel=&quot;nofollow&quot;&gt;AR.Drone Parrot&lt;/a&gt;. And I understand &lt;a href=&quot;http://liquidr.com/technology/wave-glider.html&quot; rel=&quot;nofollow&quot;&gt;Liquid Robotics&lt;/a&gt; offers a good selection of water based robots. &lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-06-27T04:28:24.337" CommentCount="2" />
  <row Id="1488" PostTypeId="2" ParentId="851" CreationDate="2013-06-27T04:46:14.530" Score="1" Body="&lt;p&gt;iLQR is an iterative method but you do not in fact appear to be iterating. Todorov supplies a &lt;a href=&quot;http://homes.cs.washington.edu/~todorov/software/test_ilqg_det.m&quot; rel=&quot;nofollow&quot;&gt;test script&lt;/a&gt; that should elucidate the approach though it may need to be customized for your system.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-06-27T04:46:14.530" CommentCount="3" />
  <row Id="1489" PostTypeId="1" CreationDate="2013-06-27T10:05:35.743" Score="-1" ViewCount="74" Body="&lt;p&gt;I'm endeavoring to prototype a challenging sorting mechanism inside a fridge and would appreciate any constructive tips on how to get from the specs to a plausible design.&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Problem&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;The aim of the game is to identify and sort food items in the limited space of a fridge&#xA;-   such that a user would push their unsorted shopping into a chamber at the top of the enclosure&#xA;-   and the machine inside would then try to identify the contents with help of bar-codes (first big problem)&#xA;-   and then sort and move the items according to their identities into different chambers below (second big problem). &lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Solution?&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Are there any existing devices that already serve such functions (automatic bar-coding and sorting), the designs of which could perhaps inform the mechanics of the device I'm planning to construct?&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I'm thinking maybe manufacturing plants&lt;/li&gt;&#xA;&lt;li&gt;or packing factories with conveyor belts etc may use systems that already solve such problems? &lt;/li&gt;&#xA;&lt;li&gt;Or filtering mechanisms in candy dispensers,&lt;/li&gt;&#xA;&lt;li&gt;mechanized lifting forks? &lt;/li&gt;&#xA;&lt;li&gt;Textbook engineering mechanisms?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="1489" LastActivityDate="2013-06-27T19:02:03.810" Title="automatic sorting with barcode identification inside a refrigerator" Tags="&lt;arduino&gt;&lt;motor&gt;&lt;sensors&gt;&lt;cameras&gt;" AnswerCount="1" CommentCount="8" ClosedDate="2013-06-27T20:51:21.113" />
  <row Id="1491" PostTypeId="2" ParentId="1489" CreationDate="2013-06-27T19:02:03.810" Score="1" Body="&lt;p&gt;Moving it around requires, apart the mechanics, always a free and therefore unused space. Wouldn't you rather like to know, &lt;em&gt;what&lt;/em&gt; is in &lt;em&gt;which&lt;/em&gt; position? And for the barcode: it can become unreadable by ice. I'm thinking of using RFID for a similar project for about 10 fridges with each 30 boxes in it.&lt;/p&gt;&#xA;" OwnerUserId="1251" LastActivityDate="2013-06-27T19:02:03.810" CommentCount="3" />
  <row Id="1492" PostTypeId="1" CreationDate="2013-06-27T21:10:37.393" Score="4" ViewCount="67" Body="&lt;p&gt;It seems popular to build robotic systems with separate supplies for the electronics and motors/servos, but what would be involved in a circuit that powers both from one source?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If it helps, here is my particular situation. I want to use a single 7.4V Li-Po pack to power an embedded system (2.5-6V operating voltage input, max 1A current draw) and up to 18 standard-sized servos (HS-645, 4.8-6V operating voltage). This would be a hexapod, so it is unlikely that all servos would be stalling at once with normal gait patterns.&lt;/p&gt;&#xA;" OwnerUserId="1557" LastActivityDate="2013-07-03T22:55:51.753" Title="Single power source for electronics and actuators" Tags="&lt;electronics&gt;&lt;servos&gt;&lt;power&gt;&lt;legged&gt;" AnswerCount="3" />
  <row Id="1493" PostTypeId="2" ParentId="1492" CreationDate="2013-06-27T21:32:52.673" Score="6" Body="&lt;p&gt;There are a variety of reasons to separate the motor power from the &quot;hotel load&quot;, including:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Reducing the number of wires running between high-power and low-power electronics&lt;/li&gt;&#xA;&lt;li&gt;Redundancy (your homing beacon shouldn't run out of power when the rest of the system does)&lt;/li&gt;&#xA;&lt;li&gt;Preventing heavy current loads from browning out the control system&lt;/li&gt;&#xA;&lt;li&gt;Making the system more modular&lt;/li&gt;&#xA;&lt;li&gt;Being able to have an emergency kill switch for the actuator power that won't hard-shutdown your onboard PC (risking data loss in the filesystem).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;However, there's nothing fancy about doing it all from one battery: use a DC-DC converter to get the voltage you need for your electronics, and watch out for ground faults.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-06-27T21:32:52.673" />
  <row Id="1494" PostTypeId="1" CreationDate="2013-06-28T10:59:20.897" Score="0" ViewCount="470" Body="&lt;p&gt;My team developed a filling machine for liquids which uses a piston to measure and deliver volumes 0.1 to 1 liters into bottles. It is built mostly with mechanical parts and we'd like to replace most of them with electronic ones.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How do I build a machine to pull liquid from a reservoir and fills a bottle using a piston, with electronic parts such as stepper motor, linear actuators and sensors?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I understand this is somewhat vague. Any aligned response is appreciated.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Update:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This machine should, at its max speed, fill a 1 litter bottle with water in 2 seconds (to deliver 30 bottles per minute). Higher viscosity liquids may take longer.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It should not spill so liquid needs some filling acceleration control.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You may assume two operation modes: with bubbles and without bubbles. The first is a plus.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'd like to be able to change the volume electronically (via a LCD menu).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I thought of a single main valve that switches between the reservoir and the bottle. That should be controlled electronically too. I could use two valves too.&lt;/p&gt;&#xA;" OwnerUserId="1556" LastEditorUserId="1556" LastEditDate="2013-06-29T10:23:25.790" LastActivityDate="2013-06-29T10:23:25.790" Title="How to build a liquid filling machine using piston?" Tags="&lt;sensors&gt;&lt;stepper-motor&gt;&lt;mechanism&gt;" AnswerCount="2" CommentCount="1" FavoriteCount="1" ClosedDate="2013-07-01T15:23:54.943" />
  <row Id="1495" PostTypeId="2" ParentId="1494" CreationDate="2013-06-28T14:40:49.420" Score="1" Body="&lt;p&gt;Off the top of my head, the first thing I would try:&#xA;Attach a &lt;a href=&quot;http://reprap.org/wiki/stepper_motor&quot; rel=&quot;nofollow&quot;&gt;stepper motor&lt;/a&gt; to a &lt;a href=&quot;http://en.wikipedia.org/wiki/Pump#Positive_displacement_pump&quot; rel=&quot;nofollow&quot;&gt;positive-displacement pump&lt;/a&gt;.&#xA;(Gearing it down is often necessary).&#xA;Then hook the wires from the stepper motor one of the many off-the-shelf stepper motor drivers, perhaps &lt;a href=&quot;http://reprap.org/wiki/Pololu_Electronics&quot; rel=&quot;nofollow&quot;&gt;Pololu stepper drivers&lt;/a&gt; or the many &lt;a href=&quot;http://reprap.org/wiki/Alternative_electronics&quot; rel=&quot;nofollow&quot;&gt;alternatives&lt;/a&gt;.&#xA;Then figure out how much volume came out for every revolution of the stepper motor.&#xA;Then program the Arduino (or one of many alternatives) to somehow detect when there is a bottle in position and how much volume it needs, pump the appropriate volume into the bottle, and stop.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A note near the bottom of&#xA;&lt;a href=&quot;http://www.stpats.com/FillingMachines.htm&quot; rel=&quot;nofollow&quot;&gt;one filling machine vendor&lt;/a&gt;&#xA;points out that sometimes constant-volume filling doesn't work --&#xA;sometimes it's better to start filling when the bottle is in position,&#xA;then turn off the pump&#xA;when the liquid has reached the fill line.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My understanding is that a visible-light laser and a photo-sensor&#xA;is the easiest way to manually line up a non-contact sensor to the appropriate fill line.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Have you searched Google for &quot;bottle filling&quot; to see if maybe there's an off-the-shelf system that already does most of what you need to do?&lt;/p&gt;&#xA;" OwnerUserId="187" LastActivityDate="2013-06-28T14:40:49.420" CommentCount="2" />
  <row Id="1496" PostTypeId="1" CreationDate="2013-06-28T15:32:27.220" Score="1" ViewCount="103" Body="&lt;p&gt;I'm looking for an electrical explanation of the statement &lt;a href=&quot;http://copter.ardupilot.com/wiki/camera-mount/&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Warning: Do not connect power (red + &amp;amp; black -) from the RC10 (A10) &amp;amp;&#xA;  RC11 (A11) connectors to the servos, just use the signal lines. Power&#xA;  the servos via the PWM Outputs connectors. These solutions will avoid&#xA;  the scenario that can possibly happen when the Pan/Tilt servo draw too&#xA;  much current and cause the APM to brownout (reset)&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;I examined the APM2.5 board drawing and schematic &lt;a href=&quot;http://stuff.storediydrones.com/APM_v252_RELEASE.zip&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt; and the grounding is a little unclear. On the schematic, they all just go to GND, but on the board drawing some of the ground pins appear unconnected to traces. I checked for continuity, and there is no continuity between the PWM grounds and the A10/A11 ground pins. By the way, my power setup is that I have J1 enabled and I am using an ESC to power the board.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can anyone figure out, electrically, what is between these two sets of ground pins?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ground pins appear unconnected to the traces:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://i.stack.imgur.com/hLO2r.jpg&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/hLO2rm.jpg&quot; alt=&quot;Ground pins appear unconnected to the traces&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;PWM ground just connected to GND:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://i.stack.imgur.com/Fyzmo.png&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/Fyzmom.png&quot; alt=&quot;PWM ground just connected to GND&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;analog output ground also connected to GND:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://i.stack.imgur.com/arrQR.png&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/arrQRm.png&quot; alt=&quot;analog output ground also connected to GND&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1473" LastEditorUserId="1473" LastEditDate="2013-07-02T18:22:40.370" LastActivityDate="2013-07-02T18:22:40.370" Title="On the ardupilot board, what is the difference between A10 / A11 ground pins and the PWM ground pins?" Tags="&lt;power&gt;&lt;ardupilot&gt;" AnswerCount="1" CommentCount="3" />
  <row Id="1497" PostTypeId="2" ParentId="1494" CreationDate="2013-06-28T16:51:14.833" Score="3" Body="&lt;p&gt;Yes, general question.  Here's some general bits-o-answer: some assembly is required.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;First, I would leave the decision about stepper vs. some other kind of motor until later -- it should be a tactical, not a strategic, decision.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Second, assuming that the positive displacement idea works at all, I would assume that at the core of your machine you still need that piston that you mention.  I would achieve controlled displacement of the piston by using some sort of linear actuator that has lots of available force and considerable mechanical stiffness, coupled with a good distance measurement on the piston.  I'd close my outer loop around the distance that the piston has traveled.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What springs to mind for a linear actuator is either a stepper motor (probably geared down) driving a jack screw, or a small DC gear motor, with an encoder on the motor and speed control, driving a jack screw.  I am personally biased against steppers, so if I were King on this project it would almost certainly be the DC gear motor -- but if you were paying me to implement it with a stepper, I'd say &quot;sure!&quot; and make sure that you selected one that had more than sufficient torque to get the job done.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The field is pretty open as far as the piston position sensor.  I don't know how clean your environment is, but assuming reasonable cleanliness I'd probably choose an optical linear encoder with a good fine line -- but I know there's other technologies out there that would work as well.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For control I'd close the piston, fill the piston by some extra amount to account for bubbles or whatever, switch the flow over to the bottle, then push the piston in by the correct distance to get the amount of fill desired.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Or, I'd find a way to weigh the bottles as I was filling them, and do the job by weight.&lt;/p&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-06-28T16:51:14.833" CommentCount="1" />
  <row Id="1498" PostTypeId="2" ParentId="1492" CreationDate="2013-06-28T19:52:24.480" Score="3" Body="&lt;p&gt;You can also add between the controller power an electrolytic capacitor of about 500 or even 1000 microfarads x 12 volts and a diode in series with it, so when the trigger pull much current source with a corresponding drop in voltage will be avoided that Power down controller please and even free you from unwanted noise (about 10 turns of cable around a ferrite core also help eliminate noise).![enter image description here][1]&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;+__________mmm___________K|_______________ + controller&#xA;Fonte                          ___|___&#xA;                             |_________|&#xA;                                  |&#xA;                                 ground                                      &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="1563" LastEditorUserId="350" LastEditDate="2013-06-28T20:40:46.523" LastActivityDate="2013-06-28T20:40:46.523" CommentCount="1" />
  <row Id="1499" PostTypeId="2" ParentId="1427" CreationDate="2013-06-28T20:34:03.613" Score="0" Body="&lt;p&gt;It's a non-starter to try and send flysky data from a computer, since it is a closed-source protocol designed to be sent from r/c transmitters.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You really want a separate data radio with a serial-type connection, using wifi, xbee, or similar.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would recommend using &lt;a href=&quot;http://qgroundcontrol.org/mavlink/start#autopilots_using_mavlink&quot; rel=&quot;nofollow&quot;&gt;one of the many quadcopter flight controllers&lt;/a&gt; that speaks the standard &lt;a href=&quot;http://qgroundcontrol.org/mavlink&quot; rel=&quot;nofollow&quot;&gt;MAVlink&lt;/a&gt; protocol. Then you can use many programs, such as qgroundcontrol, andropilot, or APM planner to control your quad. You can also use pymavlink to control your quad from python, and you have complete flexibility to set it up with any sort of interface you like with a little programming.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you're looking for a pre-made micro quad, you may be able to use the new walkera qr-w100, which has wifi. So far they have only created an iphone app, but I hope someone will reverse engineer their wifi command protocol so that we can use a computer or android phone.&lt;/p&gt;&#xA;" OwnerUserId="1473" LastEditorUserId="1473" LastEditDate="2013-06-28T20:39:10.260" LastActivityDate="2013-06-28T20:39:10.260" />
  <row Id="1500" PostTypeId="1" AcceptedAnswerId="1502" CreationDate="2013-06-29T00:30:43.873" Score="1" ViewCount="82" Body="&lt;p&gt;I am building a robot where power density is critical, and looking into using lithium thionyl chloride (SOCl2) batteries. I will be drawing around 20A constantly and need between 12 and 17V. The batteries I have found so far are AA-sized and designed to deliver 100mA, 3.6v, 2.4Ah, and weigh 19g each. I could picture a pack with 4 blocks of these batteries in series, where each block has 20 batteries in parallel. That would mean 48Ah, which is way more than the ~10Ah that I need, and 1.52kg, which is more than I would like the robot be carrying.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, the question is, is there a way to achieve 10Ah at 20A and 14.4V (i.e. for 5 hours) using SOCl2, carrying much less weight than 1.52kg?&lt;/p&gt;&#xA;" OwnerUserId="1473" LastEditorUserId="1473" LastEditDate="2013-06-29T13:02:58.040" LastActivityDate="2013-06-29T20:29:40.677" Title="lithium thionyl chloride batteries to generate 20A @ 14.4V" Tags="&lt;power&gt;" AnswerCount="1" CommentCount="4" FavoriteCount="0" />
  <row Id="1501" PostTypeId="2" ParentId="1496" CreationDate="2013-06-29T16:09:14.850" Score="1" Body="&lt;p&gt;I found a possible answer for you &lt;a href=&quot;https://groups.google.com/forum/#!topic/drones-discuss/baFSnoCtKJ0&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;A10 &amp;amp; A11 are connected to the input rail because historically those were inputs and the Vcc rail was used to power the sensors.  When you attempt to power servos from the input rail, the extra current draw causes an additional voltage drop across the input diode and fuse and Vcc drops to brownout levels regardless if you are using a BEC or the Power Module.  If you are going to connect servos to A10 &amp;amp; A11 you must provide an alternate source of power not Vcc from the input rail.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="1565" LastActivityDate="2013-06-29T16:09:14.850" />
  <row Id="1502" PostTypeId="2" ParentId="1500" CreationDate="2013-06-29T20:29:40.677" Score="2" Body="&lt;p&gt;Lithium thionyl chloride / SOCl2 batteries have excellent &lt;a href=&quot;http://www.allaboutbatteries.com/Battery-Energy.html&quot; rel=&quot;nofollow&quot;&gt;energy density&lt;/a&gt; but are not aimed at high-current applications and are not rechargeable, so it seems likely that you can save weight and cost by using some other kind of batteries.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Quadcopter batteries (typically &lt;a href=&quot;http://en.wikipedia.org/wiki/Lithium_polymer_battery&quot; rel=&quot;nofollow&quot;&gt;lithium ion polymer&lt;/a&gt; technology, rated for 5C to 15C discharge rates and rechargeable hundreds of times) might be a better choice.  You could use half-a-dozen 2200 mAh packs, or a couple of 5500 mAh packs.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Previous question &lt;a href=&quot;http://robotics.stackexchange.com/q/554&quot;&gt;Quadcopter liPo battery weight/capacity trade off&lt;/a&gt; includes some charts comparing energy densities, etc., for several battery technologies.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note, if your application is controlling several motors, with several motor controllers, you may be able to use higher voltages to the controllers, which use PWM to deliver desired amounts of energy to the motors.  This technique is usable when you have a high-voltage, low-current power source.  However (see below) that doesn't help in the present case.  Likewise, a DC/DC buck converter (that converts high voltages to lower voltages, at ~ 95% efficiency) doesn't help.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The 20A, 10Ah parameters of your SOCl2 example imply 30 minutes of operation.  The 20A, 14.4V parameters imply energy rate is 288 W.  The current drain per cell in the example is 1A (which exceeds the rating of a typical AA  SOCl2 cell).  If we limit per-cell current to 1A, we get 3.6 W per cell.  Then the number of cells required is 288/3.6 = 80 cells, regardless of the cells' series or parallel configuration, which is why a higher voltage to the motor controller, or to a buck converter, doesn't help.&lt;/p&gt;&#xA;" OwnerUserId="478" LastActivityDate="2013-06-29T20:29:40.677" CommentCount="1" />
  <row Id="1503" PostTypeId="1" AcceptedAnswerId="1521" CreationDate="2013-06-29T22:41:17.110" Score="1" ViewCount="47" Body="&lt;p&gt;Are there any Python3 modules used to program robotic movement by declaring a device or component and then providing the instructions? I am not looking for modules that test the components.&lt;/p&gt;&#xA;" OwnerUserId="1309" LastEditorUserId="1309" LastEditDate="2013-07-01T18:15:20.870" LastActivityDate="2013-07-01T19:15:10.237" Title="Python3 Modules for motor movement" Tags="&lt;python&gt;" AnswerCount="1" CommentCount="2" />
  <row Id="1504" PostTypeId="5" CreationDate="2013-06-29T22:41:53.250" Score="0" ViewCount="2" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2013-06-29T22:41:53.250" LastActivityDate="2013-06-29T22:41:53.250" />
  <row Id="1505" PostTypeId="4" CreationDate="2013-06-29T22:41:53.250" Score="0" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2013-06-29T22:41:53.250" LastActivityDate="2013-06-29T22:41:53.250" />
  <row Id="1506" PostTypeId="5" CreationDate="2013-06-29T22:43:44.257" Score="0" ViewCount="3" Body="&lt;p&gt;3D-printing is the process of making virtual objects into real objects by using a device that 'prints' material (often plastic) layer by layer.&lt;/p&gt;&#xA;" OwnerUserId="1309" LastEditorUserId="37" LastEditDate="2013-06-30T00:35:59.487" LastActivityDate="2013-06-30T00:35:59.487" />
  <row Id="1507" PostTypeId="4" CreationDate="2013-06-29T22:43:44.257" Score="0" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2013-06-29T22:43:44.257" LastActivityDate="2013-06-29T22:43:44.257" />
  <row Id="1508" PostTypeId="5" CreationDate="2013-06-29T22:45:13.623" Score="0" ViewCount="6" Body="&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Artificial_intelligence&quot; rel=&quot;nofollow&quot;&gt;Wikipedia&lt;/a&gt;: Artificial intelligence (AI) is a branch of computer science that studies and develops systems that can perceive their environment and take actions that maximize the chances of success.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Currently popular approaches include statistical methods, computational intelligence and traditional symbolic AI. There are an enormous number of tools used in AI, including versions of search and mathematical optimization, logic, methods based on probability and economics, and many others.&lt;/p&gt;&#xA;" OwnerUserId="1449" LastEditorUserId="350" LastEditDate="2013-08-04T16:29:26.033" LastActivityDate="2013-08-04T16:29:26.033" />
  <row Id="1509" PostTypeId="4" CreationDate="2013-06-29T22:45:13.623" Score="0" Body="The central problems (or goals) of Artificial Intelligence research include reasoning, knowledge, planning, learning, communication, and perception." OwnerUserId="-1" LastEditorUserId="350" LastEditDate="2013-08-04T16:29:26.033" LastActivityDate="2013-08-04T16:29:26.033" />
  <row Id="1510" PostTypeId="5" CreationDate="2013-06-29T22:45:47.110" Score="0" ViewCount="2" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2013-06-29T22:45:47.110" LastActivityDate="2013-06-29T22:45:47.110" />
  <row Id="1511" PostTypeId="4" CreationDate="2013-06-29T22:45:47.110" Score="0" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2013-06-29T22:45:47.110" LastActivityDate="2013-06-29T22:45:47.110" />
  <row Id="1512" PostTypeId="5" CreationDate="2013-06-29T22:46:30.517" Score="0" ViewCount="2" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2013-06-29T22:46:30.517" LastActivityDate="2013-06-29T22:46:30.517" />
  <row Id="1513" PostTypeId="4" CreationDate="2013-06-29T22:46:30.517" Score="0" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2013-06-29T22:46:30.517" LastActivityDate="2013-06-29T22:46:30.517" />
  <row Id="1514" PostTypeId="1" AcceptedAnswerId="1522" CreationDate="2013-06-30T18:23:12.643" Score="5" ViewCount="182" Body="&lt;p&gt;So I built three little bots so far. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;One with a raspberry-pi, (6V motors), one with an arduino (12V motors), and another with an arduino but a hacked remote car (7ish, volt motors):&lt;br&gt;&#xA;&lt;a href=&quot;http://i.stack.imgur.com/AJ45l.jpg&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/AJ45ls.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt;&#xA;&lt;a href=&quot;http://i.stack.imgur.com/f6NUt.jpg&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/f6NUts.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt;&#xA;&lt;a href=&quot;http://i.stack.imgur.com/Rr5fH.jpg&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/Rr5fHs.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The problem I have with all these is that the motors spin so fast the car just bumps into something in a few seconds. (I have a small house)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I tried to use PWM to control the speed, but at a little less than full throttle (255) they jam up and they can't take the weight I put on them.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Should I buy one of these chassis that slow the motor down and give it torque with a gearbox, or is there anything else I can do?&lt;/p&gt;&#xA;" OwnerUserId="1522" LastEditorUserId="350" LastEditDate="2013-07-01T15:57:43.283" LastActivityDate="2013-08-16T13:38:23.540" Title="Reducing motor speed without jamming up" Tags="&lt;motor&gt;&lt;pwm&gt;" AnswerCount="3" />
  <row Id="1515" PostTypeId="1" CreationDate="2013-07-01T10:44:57.507" Score="3" ViewCount="172" Body="&lt;p&gt;I'm looking for a way to create a non-rotating persistence of vision device. I have all the electronics set up but I'm stumped with the mechanical design.&#xA;I tried these two designs:&lt;img src=&quot;http://i.stack.imgur.com/Xvb5l.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;br&gt;&#xA;But these didn't work so well. Everything shakes violently and it doesn't go nearly as fast as I need (about 20 swipes per second)&#xA;Any ideas on how I can build this?&lt;/p&gt;&#xA;" OwnerUserId="1571" LastActivityDate="2013-09-01T20:55:32.027" Title="Building a non rotating persistence of vision device" Tags="&lt;motor&gt;&lt;mechanism&gt;" AnswerCount="2" CommentCount="7" />
  <row Id="1517" PostTypeId="1" CreationDate="2013-07-01T15:07:47.273" Score="2" ViewCount="39" Body="&lt;p&gt;I have two Kinects (each on its own USB card) whose cameras I'm watching in RVIZ through OpenNI, and the structured light pattern of one is flashing intermittently - it's only there for a short flash every two seconds. Obviously, the structured light depth calculations only work if the pattern is always projected when the camera is looking at it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What causes this, and how do I fix it?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT: I was also having this issue with a single Kinect, for which I discovered the issue, as detailed in my own answer. However, the problem persists when two Kinects are plugged in, with one Kinect flashing and the other functioning normally.&lt;/p&gt;&#xA;" OwnerUserId="31" LastEditorUserId="31" LastEditDate="2013-07-01T18:03:27.633" LastActivityDate="2013-07-01T18:03:27.633" Title="Light pattern is flashing intermittently using RVIZ/OpenNI with two Kinects" Tags="&lt;ros&gt;&lt;kinect&gt;&lt;openni&gt;" AnswerCount="1" />
  <row Id="1518" PostTypeId="1" AcceptedAnswerId="1529" CreationDate="2013-07-01T16:27:51.393" Score="1" ViewCount="56" Body="&lt;p&gt;If a street is extremely crowded to an extent that the terrain is not visible from the point of view of the LIDAR (e.g. in google's self driving car), can it still manage to localize itself and continue to operate? I recall Sebastian Thrun saying that Google's car cannot navigate through snow filled roads since the onboard LIDAR cannot map the terrain beneath the snow (&lt;a href=&quot;http://www.economist.com/node/21560989&quot; rel=&quot;nofollow&quot;&gt;e.g. here&lt;/a&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;[Edit : Based on the comments] Clarifying the context, here &quot;not visible&quot; means there is an obstacle between the LIDAR and the terrain&lt;/p&gt;&#xA;" OwnerUserId="105" LastEditorUserId="350" LastEditDate="2013-07-02T15:03:01.770" LastActivityDate="2013-07-02T16:53:43.190" Title="How do visual obstructions impact the ability to localize using LIDAR?" Tags="&lt;ugv&gt;&lt;lidar&gt;" AnswerCount="1" CommentCount="4" />
  <row Id="1519" PostTypeId="1" CreationDate="2013-07-01T17:39:34.627" Score="1" ViewCount="35" Body="&lt;p&gt;Does anyone here know PX4 software? I'm using Eclipse to program it and I want to Open a new UART door and write on this, I'm doing the following commands...&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;static int uart2=open(&quot;/dev/ttyS1&quot;, O_RDWR | O_NONBLOCK | O_NOCTTY);&#xA;write(uart2,&quot;Hi&quot;,3);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;But this is not working! Anyone have any idea why?&lt;/p&gt;&#xA;" OwnerUserId="1502" LastEditorUserId="350" LastEditDate="2013-07-02T01:47:38.387" LastActivityDate="2013-07-02T01:47:38.387" Title="PX4 Communication" Tags="&lt;microcontroller&gt;&lt;communication&gt;" CommentCount="4" FavoriteCount="1" />
  <row Id="1520" PostTypeId="2" ParentId="1517" CreationDate="2013-07-01T17:40:43.393" Score="1" Body="&lt;p&gt;Apparent partial issue was a conflict with the VM running Windows (on my Linux box) attempting to grab the XnSensorServer resource. Running the VM and then the setup specified in the question produced the observed Kinect disfunctionality, whereas running the setup and then opening the VM crashed the XnSensorServer, freezing the Kinect altogether.&lt;/p&gt;&#xA;" OwnerUserId="31" LastEditorUserId="31" LastEditDate="2013-07-01T18:00:26.697" LastActivityDate="2013-07-01T18:00:26.697" />
  <row Id="1521" PostTypeId="2" ParentId="1503" CreationDate="2013-07-01T19:15:10.237" Score="1" Body="&lt;p&gt;This is an extremely general question. What code you will use will depend on the type of &quot;robotic movement&quot; you are attempting to achieve, and what platform you are running the code on.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Let's say you want to control a stepper motor from python running on a Raspberry Pi. Stephen Phillips has written &lt;a href=&quot;http://blog.scphillips.com/2012/12/a-python-class-to-move-the-stepper-motor/&quot; rel=&quot;nofollow&quot;&gt;a nice python class&lt;/a&gt; for this purpose. The code was for Python 2.x, but the only changes you need to make to port it to python 3 are to add parenthesis to the print statements and change the backticks to repr() because python 3 has cleaned up the print syntax. See the output of python's 2to3 command below:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;@@ -41,10 +41,10 @@&#xA;         steps = (steps % self.steps_per_rev)&#xA;         if steps &amp;gt; self.steps_per_rev / 2:&#xA;             steps -= self.steps_per_rev&#xA;-            print &quot;moving &quot; + `steps` + &quot; steps&quot;&#xA;+            print(&quot;moving &quot; + repr(steps) + &quot; steps&quot;)&#xA;             self._move_acw(-steps / 8)&#xA;         else:&#xA;-            print &quot;moving &quot; + `steps` + &quot; steps&quot;&#xA;+            print(&quot;moving &quot; + repr(steps) + &quot; steps&quot;)&#xA;             self._move_cw(steps / 8)&#xA;         self.step_angle = target_step_angle&#xA;&#xA;@@ -98,7 +98,7 @@&#xA;     GPIO.setmode(GPIO.BOARD)&#xA;     m = Motor([18,22,24,26])&#xA;     m.rpm = 5&#xA;-    print &quot;Pause in seconds: &quot; + `m._T`&#xA;+    print(&quot;Pause in seconds: &quot; + repr(m._T))&#xA;     m.move_to(90)&#xA;     sleep(1)&#xA;     m.move_to(0)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="1473" LastActivityDate="2013-07-01T19:15:10.237" />
  <row Id="1522" PostTypeId="2" ParentId="1514" CreationDate="2013-07-01T22:49:21.473" Score="8" Body="&lt;ol&gt;&#xA;&lt;li&gt;Gearboxes are probably your best bet if you never want to go fast.&lt;/li&gt;&#xA;&lt;li&gt;You may be able to make it work better if you give it pulsed power (PWM in a way, but pulsed at a speed low enough that the motor actually gets going and then slows down each time.  See &lt;a href=&quot;http://wescottdesign.com/articles/Friction/friction.pdf&quot;&gt;Controlling Motors in the Presence of Friction and Backlash&lt;/a&gt; for details on the technique.&lt;/li&gt;&#xA;&lt;li&gt;You can almost certainly make it better if you put some sort of closed-loop speed control on the motors.  Encoders are best, but you can do amazing things using back-EMF speed sensing.  Either of these techniques require you to work with a closed-loop system which isn't trivial, and neither of them will overcome all the problems unless you use a gearbox (but, with closed-loop speed control you can have a much higher ratio of top to bottom speed while keeping things smooth).&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-07-01T22:49:21.473" CommentCount="3" />
  <row Id="1524" PostTypeId="1" AcceptedAnswerId="1527" CreationDate="2013-07-02T12:06:21.443" Score="2" ViewCount="686" Body="&lt;p&gt;I'm working on building a line follower robot and want to optimize its performance. It was suggested that I use a PID algorithm. I read a lot about PID but am confused a bit regarding following:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've calculated the error_value using $k_p * proportional + ...$&#xA;But regarding the change in the motor speed I'm confused as to what to use during comparison the difference (i.e. currentposition - setpoint) or the errorvalue. That is should I use &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;if (difference &amp;gt; 0)&#xA;{ //code for changing appropriate motor's speed using error_value }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;or &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;if (error_value &amp;gt; 0)&#xA;{ //code for changing appropriate motor's speed using error_value }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Also is there any specified range for the values of the constants $k_p$, $k_i$ and $k_d$?&#xA;I'm using a &lt;a href=&quot;https://en.wikipedia.org/wiki/Differential_wheeled_robot&quot; rel=&quot;nofollow&quot;&gt;differential wheeled robot&lt;/a&gt; for my line follower.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also I would be happy if someone suggests me any other advanced optimization algorithm for improving the line follower robot.&lt;/p&gt;&#xA;" OwnerUserId="1359" LastEditorUserId="134" LastEditDate="2013-08-20T07:39:16.417" LastActivityDate="2013-08-20T07:39:16.417" Title="Line Follower optimization" Tags="&lt;arduino&gt;&lt;pid&gt;&lt;line-following&gt;" AnswerCount="2" CommentCount="1" />
  <row Id="1525" PostTypeId="1" CreationDate="2013-07-02T13:03:24.603" Score="0" ViewCount="47" Body="&lt;p&gt;I have built a &lt;a href=&quot;http://sourceforge.net/projects/r-localization/&quot; rel=&quot;nofollow&quot;&gt;Particles Filter simulator&lt;/a&gt; and I wanted to add the following functionalities.&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Limited Range Vision (Robot can see up to 50 meters)&lt;/li&gt;&#xA;&lt;li&gt;Limited Angle Vision (Robot can see within a certain angle w.r.t its current orientation.  &lt;em&gt;e.g.&lt;/em&gt; If the current orientation is 30 degree then it can see in the range from 0 to 60 degree.)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;I have managed to add the Limited Range Vision functionality but unable to add Limited Angle Vision.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Method to Sense the landmarks distance within the range&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;public double[] sense(boolean addNoise) {&#xA;    double[] z = new double[World.getLandmark().getLandmarks().size()];&#xA;    for (int i = 0; i &amp;lt; z.length; i++) {&#xA;        Point lm = World.getLandmark().getLandmarks().get(i);&#xA;        double dx = x - lm.getX();&#xA;        double dy = y - lm.getY();&#xA;        double dist = Math.sqrt(Math.pow(dx, 2) + Math.pow(dy, 2));&#xA;        if (addNoise) {&#xA;            dist += Util.nextGaussian(0, sense_noise);&#xA;        }&#xA;        if (isBoundedVision()) {&#xA;            // TODO Limited angle vision&#xA;            // if robot can see within 60 degree angle w.r.t its orientation&#xA;            if (dist &amp;lt;= laserRange) {&#xA;                z[i] = dist;&#xA;            }&#xA;        } else {&#xA;            z[i] = dist;&#xA;        }&#xA;    }&#xA;    return z;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Method to calculate the probability of this particle&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;@Override&#xA;public double measurement_prob(double[] measurements) {&#xA;    double prob = 1.0;&#xA;    int c = 0;&#xA;    double[] myMeasurements = sense(false);&#xA;    for (int j = 0; j &amp;lt; measurements.length; j++) {&#xA;        if (measurements[j] != 0) {&#xA;            prob *= Util.gaussian(myMeasurements[j], sense_noise, measurements[j]);&#xA;            c++;&#xA;        }&#xA;    }&#xA;    if (isBoundedVision()) {&#xA;        if (c &amp;gt; 0) {&#xA;            // increase the probability if this particle can see more landmarks&#xA;            prob = Math.pow(prob, 1.0 / c);&#xA;        } else {&#xA;            prob = 0.0;&#xA;        }&#xA;    }&#xA;    return prob;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="1573" LastEditorUserId="350" LastEditDate="2013-07-02T13:27:58.677" LastActivityDate="2013-07-02T13:47:48.950" Title="How to implement Bounded Angle Vision in Particle Filter?" Tags="&lt;localization&gt;&lt;particle-filter&gt;&lt;visualization&gt;" AnswerCount="1" CommentCount="3" FavoriteCount="1" />
  <row Id="1526" PostTypeId="2" ParentId="1525" CreationDate="2013-07-02T13:47:48.950" Score="1" Body="&lt;p&gt;It looks like you're missing the angle that the robot is currently looking, e.g. &lt;code&gt;robot_angle_radians&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Once you know where the robot is looking, you just use the &lt;a href=&quot;http://docs.oracle.com/javase/6/docs/api/java/lang/Math.html#atan2&amp;#40;double,&amp;#32;double&amp;#41;&quot; rel=&quot;nofollow&quot;&gt;atan2 function&lt;/a&gt; (see also: &lt;a href=&quot;http://www.tutorialspoint.com/java/lang/math_atan2.htm&quot; rel=&quot;nofollow&quot;&gt;example usage&lt;/a&gt;) on each point:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;point_angle = Math.atan2(dy, dx); // in radians&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Then you want to check whether the angle is &lt;a href=&quot;http://docs.oracle.com/javase/6/docs/api/java/lang/Math.html#abs&amp;#40;double&amp;#41;&quot; rel=&quot;nofollow&quot;&gt;not more than&lt;/a&gt; 30&amp;deg; off of the robot's angle:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;offset = Math.abs(robot_angle_radians - point_angle) % (2 * Math.PI); &#xA;if (Math.toRadians(30) &amp;lt; offset) // then it's out of +/- 30 degree range&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Make sure you are consistent between &lt;a href=&quot;http://nautilus.baruch.sc.edu/CSV/explain_coord_sys_diagram.pdf&quot; rel=&quot;nofollow&quot;&gt;a polar coordinate system and a compass rose coordinate system&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-07-02T13:47:48.950" CommentCount="3" />
  <row Id="1527" PostTypeId="2" ParentId="1524" CreationDate="2013-07-02T13:52:05.687" Score="2" Body="&lt;p&gt;When using a PID loop to steer using line following, then your set point will always be the same. You will always want the line to be in the same position with respect to the robot, for instance in the centre of your sensor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So if your line sensor outputs a value from -1 to 1 with 0 being the centre of the sensor, then you will want your set point to be zero (and sensor read back and difference will be the same). If your line sensor outputs a value of 0 to 10, then you will want your set point to be 5 (and your sensor read back and difference will be different).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Since you are steering by setting the wheels to turn at different speeds, then to smoothly follow a line at a constant velocity, you will probably want to adjust the speeds for both wheels based on the error. For example, if you need to turn left to stay on the line, you will slow down the left wheel and speed up the right wheel. The more you need to turn, the more you will need to slow down the inside wheel and the more you will need to speed up the outside wheel.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Consider the situation where you need to turn $\theta$ radians to the left to correct for error $e$ and your current speed is $S_0$:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/File%3aDifferentialSteering.svg&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/TVXKL.png&quot; alt=&quot;Differential Steering&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So your left wheel needs to travel at $S_L = r\theta$ and your right wheel needs to travel at $S_R = (r+b)\theta$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To maintain the same overall speed $S_0$, you need $S_0 = (r+b/2)\theta$, &#xA;so the left wheel will need to travel at $S_L = S_0 - (b/2)\theta$&#xA;while the right wheel will need to travel at $S_R = S_0 + (b/2)\theta$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As your error tends towards zero, the speeds of each motor will also tend towards each other. As the error grows, the speed differentials will grow too.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You may even need your inside wheel to rotate backwards if your sensor is telling you that the line is curving more tightly than the distance between your wheels. These are complications which you can work through step by step as your control gets more sophisticated though.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, since your error will have both positive and negative values (to represent the continuum from &lt;em&gt;off the scale left ... too far left ... on the line ... too far right ... off the scale right&lt;/em&gt; then you should never need to ask &lt;code&gt;if&lt;/code&gt; the error is positive or negative, you should just calculate new values based on the error value, since a positive value and a negative value should have opposite and symmetric effects on the motors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note that for line following, you may be able to get away with just the proportional gain term (i.e. leaving the other terms at zero). Implementing a Derivative term may well allow you to push up the proportional gain term higher to get a more responsive system, but an integral term is unlikely to help. The fact that if you robot goes in the wrong direction the error will get larger means that your robots physical movements will act like an integral term anyway.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The specific values of P, D and I will be determined by the responsiveness of your system. For general advice about tuning PID parameters, see &lt;a href=&quot;http://robotics.stackexchange.com/a/174/37&quot;&gt;my answer&lt;/a&gt; and others on &lt;a href=&quot;http://robotics.stackexchange.com/q/167/37&quot;&gt;What are good strategies for tuning PID loops?&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="37" LastEditorUserId="37" LastEditDate="2013-07-04T10:09:02.967" LastActivityDate="2013-07-04T10:09:02.967" CommentCount="6" />
  <row Id="1528" PostTypeId="2" ParentId="1524" CreationDate="2013-07-02T14:00:42.113" Score="2" Body="&lt;p&gt;You may want to check out &lt;a href=&quot;http://robotics.stackexchange.com/questions/167/what-are-good-strategies-for-tuning-pid-loops&quot;&gt;this question on how to tune PIDs&lt;/a&gt;.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;It sounds like you're confusing the role of &lt;code&gt;error&lt;/code&gt; in this calculation.  The PID equation takes the error measurement (actual position - desired position) and determines how much &quot;response&quot; should be commanded in the controller (e.g. how much force).  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So instead of saying &lt;code&gt;if (error_value &amp;gt; 0) { }&lt;/code&gt;, you should be saying something like &lt;code&gt;response = get_PID_calculation(error_value)&lt;/code&gt;.  Depending on the construction of your specific vehicle, that response would be sent to the drive motor as the throttle amount, the steering as desired angle, or some other control input.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-07-02T14:00:42.113" CommentCount="2" />
  <row Id="1529" PostTypeId="2" ParentId="1518" CreationDate="2013-07-02T16:53:43.190" Score="0" Body="&lt;p&gt;The snow problem you're referring to seems to that the car can no longer tell where the edge of the road is.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Even in heavy traffic, a good driver still maintains enough space from the car in front that plenty of road is visible, and the side of the road identifiable from LiDAR. This is not common practice, but I imagine autonomous cars would be programmed to do so. In that case, plenty of road is always visible for the car.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Google's car seems to have &lt;a href=&quot;http://www.youtube.com/watch?v=BrmorE5W1tM&quot; rel=&quot;nofollow&quot;&gt;no problems in heavy traffic&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="1473" LastActivityDate="2013-07-02T16:53:43.190" CommentCount="4" />
  <row Id="1530" PostTypeId="1" CreationDate="2013-07-02T21:37:23.510" Score="0" ViewCount="118" Body="&lt;p&gt;I was considering using a Raspberry Pi controlling a USB Relay to dim 12V LED lights, but I'm having trouble finding a solution that isn't a simple ON/OFF.  What type of device would I need for dimming?&lt;/p&gt;&#xA;" OwnerUserId="1432" LastActivityDate="2013-07-03T18:09:21.187" Title="How do you dim 12 volt LEDs?" Tags="&lt;raspberry-pi&gt;" AnswerCount="1" ClosedDate="2013-07-03T12:42:06.150" />
  <row Id="1531" PostTypeId="2" ParentId="1530" CreationDate="2013-07-03T02:25:56.093" Score="2" Body="&lt;p&gt;You probably want a PWM (pulse width modulation) solution. Essentially this means flashing the led on and off faster than you can see. To make it brighter, you increase the amount of on time versus off time.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You could use an external PWM LED driver, or possibly you can produce &lt;a href=&quot;https://sites.google.com/site/semilleroadt/raspberry-pi-tutorials/gpio&quot; rel=&quot;nofollow&quot;&gt;PWM from the GPIO ports&lt;/a&gt; on the Pi and step it up using a transistor and / or relay.&lt;/p&gt;&#xA;" OwnerUserId="1473" LastEditorUserId="1473" LastEditDate="2013-07-03T18:09:21.187" LastActivityDate="2013-07-03T18:09:21.187" CommentCount="2" />
  <row Id="1533" PostTypeId="2" ParentId="167" CreationDate="2013-07-03T21:52:50.190" Score="2" Body="&lt;p&gt;Embedded.com has moved my article yet again, but here is where it is now.  This shows you both how to write a PID loop (figuring out how to do it in something other than floating point is left as an exercise to the reader) and how to tune it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.embedded.com/design/prototyping-and-development/4211211/PID-without-a-PhD&quot; rel=&quot;nofollow&quot;&gt;PID Without a PhD&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The &lt;em&gt;best way&lt;/em&gt; depends a lot on your abilities.  The way to get the &lt;em&gt;best tuning&lt;/em&gt;, assuming you're an experienced control system hand, is usally to measure the response of the plant (&quot;plant&quot; == &quot;the thing you're controlling&quot;), then depending on how you did the measurements extract a model of the plant and design to that, or just design directly to the measurements.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For certain difficult plants you'll find that you can't ever make satisfactory measurements, in which case you have to go by models alone.  Those are rare, but satisfying when you get them working.&lt;/p&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-07-03T21:52:50.190" />
  <row Id="1534" PostTypeId="2" ParentId="1492" CreationDate="2013-07-03T22:55:51.753" Score="0" Body="&lt;p&gt;Both your computer and your servos need supplies at a lower voltage than your battery supplies.  So you need some sort of voltage regulation between battery and &quot;the rest&quot;.  Just make sure that the servo side is current limited.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Better, make sure that the one to the servos is current limited, and that it indicates to the processor that it's in current limit.  That way if it goes into current limit for more than a moment you can shut the whole thing off.&lt;/p&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-07-03T22:55:51.753" />
  <row Id="1536" PostTypeId="2" ParentId="1229" CreationDate="2013-07-04T16:41:59.377" Score="2" Body="&lt;p&gt;When I'm processing quadrature encoder input in an &lt;a href=&quot;http://en.wikipedia.org/wiki/Interrupt_handler&quot; rel=&quot;nofollow&quot;&gt;ISR&lt;/a&gt;, I prefer to have a simple ISR running on a timer that's guaranteed to run fast enough to catch every state (not state change) of the encoder.  Interrupting on every pin transition invites a situation where the processor gets bogged down if a pin starts bouncing.  Interrupting at a fixed rate may use up processor resources all the time, but it always uses the same amount of resources, so it doesn't catch you by surprise when you least want it to happen.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For your 48 transitions/rotation, 400RPM motor, that works out to 320 transitions per second: I would set my ISR to interrupt at least twice that fast.  It should do nothing but check the current state of the two pins against the previous one, and then increment or decrement the wheel's counter as appropriate based on what it sees.  At 640Hz, such an ISR should load the processor very lightly, even if you're doing updates for multiple wheels.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've built quite a few successful control systems that use this method, so it can't be all bad.&lt;/p&gt;&#xA;" OwnerUserId="1533" LastEditorUserId="1533" LastEditDate="2013-07-08T05:03:09.690" LastActivityDate="2013-07-08T05:03:09.690" CommentCount="0" />
  <row Id="1537" PostTypeId="2" ParentId="1514" CreationDate="2013-07-05T00:26:38.530" Score="5" Body="&lt;p&gt;When you PWM the voltage to the motor you are effectively controlling the current to the motor which is related to torque (acceleration).  The &quot;jamming up&quot; that you notice is basically the inability of the motor to overcome friction.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Think about the PWM as the gas pedal in your car, to get to a constant speed you may push all the way down, gradually back off as you reach your target speed and then modulate it to maintain that speed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A DC motor driven at a fixed voltage loses torque as it goes faster and faster.  That's why it doesn't speed up to infinity.  Gearing it down effectively limits the top speed you'll see at the output.  It gives you more torque at the output but you're trading off speed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As Tim notes what you need is a closed speed control loop running over that such that you set a speed set-point and the loop, very quickly, ramps the PWM up and down to maintain the speed.  To do that you need some way of measuring the speed.  Once you have that you may be able to get by with a relatively simple PI controller.&lt;/p&gt;&#xA;" OwnerUserId="1584" LastEditorUserId="1584" LastEditDate="2013-07-05T20:11:19.647" LastActivityDate="2013-07-05T20:11:19.647" CommentCount="4" />
  <row Id="1538" PostTypeId="1" AcceptedAnswerId="1543" CreationDate="2013-07-05T03:47:23.300" Score="4" ViewCount="1412" Body="&lt;p&gt;I am interested in using this miniature motor (&lt;a href=&quot;http://www.newscaletech.com/technology/squiggle-motors.php&quot; rel=&quot;nofollow&quot;&gt;Squiggle Micro Motor&lt;/a&gt;) to create very tiny &lt;strong&gt;horizontal&lt;/strong&gt; movements. However, due to very limited space, I can only place it &lt;strong&gt;vertically&lt;/strong&gt; within my project.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Assuming this motor is placed as follows, how can one adapt it to simultaneous movement at a right angle? (Ideally with the X-axis movement matched to the Y-axis movement as well as possible.)&#xA;&lt;img src=&quot;http://i.stack.imgur.com/sdyln.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="1588" LastEditorUserId="1588" LastEditDate="2013-07-05T03:53:52.017" LastActivityDate="2013-08-15T11:45:16.637" Title="How to convert vertical motion to horizontal" Tags="&lt;motor&gt;&lt;motion&gt;&lt;movement&gt;&lt;driver&gt;&lt;linear-bearing&gt;" AnswerCount="3" CommentCount="5" />
  <row Id="1541" PostTypeId="2" ParentId="167" CreationDate="2013-07-05T19:52:50.117" Score="1" Body="&lt;p&gt;I'll try to expand a little from my experience for those who may be interested.  I think the problem is we have a lot of control theory that is somewhat inaccessible (and sometimes not useful) and then we have rules of thumb that make assumptions about systems that are often inaccurate.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Stability&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Let's talk first about why control loops become unstable.  For this discussion I'll assume a linear system.  Informally this means that if your control signal is a sine wave at a given frequency then your observed output is at the same frequency and if you change the amplitude of your control system your output responds at the same ratio.  This assumption is a good approximation for many real world systems and lets us look at different frequencies in isolation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you look at the control path you have a set-point, your PID controller, your system (aka &quot;Plant&quot;), and then your sensor.  Imagine a fixed set-point and a sine wave from your sensor (this is equal to a real world disturbance at the sensor, fed back).  In an unstable system your feedback causes the control loop to amplify the error rather than reducing it such that as time increases your amplitude increases.  The reason this happens is due do a delay, or for this particular frequency a phase shift between the input and output.  For a given frequency we can look at that open loop (i.e. no feedback) shift and amplitude of the output and when we draw all those on a graph we get something like a &lt;a href=&quot;http://en.wikipedia.org/wiki/Bode_plot&quot; rel=&quot;nofollow&quot;&gt;Bode Plot&lt;/a&gt;.  If we have a situation in this open loop graph where the error keeps getting amplified then we have an unstable system.  If the delay is less than 1/2 the wavelength or the gain is less than x1 the system will be &lt;a href=&quot;http://en.wikipedia.org/wiki/Barkhausen_stability_criterion&quot; rel=&quot;nofollow&quot;&gt;stable&lt;/a&gt;.  In practice we want some margin from that point (gain margin and phase margin) which is why you'll see this &quot;backing off&quot; in many of the manual/heuristic methods.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The main problem with those manual methods is that you're flying blind and you're pretty much guaranteed to get a poor control system.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also keep in mind that the meaning P, I and D is related to what your sensor is measuring and what control you're applying.  A common mistake in home built controllers is for people to think they're applying P when they're actually not.  Motor controllers often have a position loop, running over a velocity loop running over a torque loop. (A &lt;a href=&quot;http://www.controldesign.com/Media/0704/article_061_fig2-2.jpg&quot; rel=&quot;nofollow&quot;&gt;cascade&lt;/a&gt;)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;OK but how does this help us?&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The first point I'd like to make is that if you're building your own PID controller you should also build a way of measuring the open loop response.  Do a frequency sweep at the input to your controller and measure the sensor's output with the feedback disconnected.  Then you can draw the open loop Bode plot and &lt;em&gt;see&lt;/em&gt; why your system is stable and be able to trade off the various controls.  It's also useful to measure the closed loop response and you can do that with any system by doing a frequency sweep of your set-point while the loop is closed.  Both these aren't that hard and don't require a lot of theoretical knowledge.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you're simply tweaking controls without any understanding of what's going on under the hood you won't be able to optimize your system.  Building some intuition about these systems isn't that hard.  E.g. the proportional gain has no effect on phase but simply increases the open loop gain across all frequencies.  So what you're doing when you're increasing the proportional gain in all those manual tuning methods is finding the frequency where the phase goes to -180.  See &lt;a href=&quot;http://en.wikibooks.org/wiki/Control_Systems/Bode_Plots#Examples&quot; rel=&quot;nofollow&quot;&gt;this&lt;/a&gt; to get some more idea about the impact of the various controls on your frequency response.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Quite often getting best closed loop performance involves tweaking the system and not just the controller gains.  What you want is to make the system as &quot;stiff&quot; as possible.  That will let you ramp up the control parameters and get the best open and closed loop bandwidth.  In my experience in motor control applications the proportional gain is the one that should be doing most of the &quot;work&quot; and the integrator the &quot;rest&quot;.  I don't think you need a D term at all.  Having a low pass filter and a notch filter helps a lot in situations where you may have some mechanical resonance but setting them without a Bode Plot is very difficult (the oscillation frequency you observe under closed loop may be different than the open loop one).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If safety is a concern (very powerful motors or a system that could be destroyed by the motor going out of control) you need to put in some limits before you start tuning (e.g. current limit, maximum position error) to protect the system.  Then you need to get some sort of feel for the range of the parameters.  If your feedback has 40 counts per rotation or 4000 counts per rotation your parameters will be a factor of 100 for a given system.  My approach would be to first find a range where you have some poor controllability and then ramp up from there starting with P and then I (though again you're flying blind).  Backing off creates this stability margin.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Beyond closed loop&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Closed loop attempts to take out the error from the system.  It's always going to have a somewhat limited performance.  What you want to do is minimize the error your closed loop controller sees and one way to do that is through a technique called &lt;a href=&quot;http://en.wikipedia.org/wiki/Feed_forward_%28control%29&quot; rel=&quot;nofollow&quot;&gt;feed forward&lt;/a&gt;.  In feed-forward you go around the controller and drive a command directly to the system.  An example of that would be acceleration feed-forward.  If you know you're motor's torque constant and you know the load you can pretty much tell how much current you need to drive to get a certain acceleration of the load.  You simply take the command input acceleration, multiply it by a constant and add that to the controller's drive command.  You're basically doing what it would take to drive the system if there was no controller and the closer you can get the less error your loop has to take out and the better your system will perform.  It makes a huge difference in practice.&lt;/p&gt;&#xA;" OwnerUserId="1584" LastActivityDate="2013-07-05T19:52:50.117" CommentCount="3" />
  <row Id="1542" PostTypeId="2" ParentId="143" CreationDate="2013-07-05T21:12:53.183" Score="1" Body="&lt;p&gt;When the string isn't under tension you have a non-linear system (i.e. you're pushing on a rope) which may also make this harder to control.  The stiffness of your string is going to limit your bandwidth. (The string acts as a low-pass filter, at least when it's under tension).  I've actually worked a little on a similar setup and it was really hard to control.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Since you're sampling the &lt;a href=&quot;http://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem&quot; rel=&quot;nofollow&quot;&gt;sampling theorem&lt;/a&gt; absolutely applies and you must sample at least x2 the highest frequency in your input (either by increasing the sample rate or filtering the input before sampling or both) otherwise you'll get aliasing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As Kyle points out the other factor is your desired control bandwidth.  I concur with the rule of thumb that the loop should run at least ~x10 that frequency.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Both these conditions need to be met.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There's a pretty good discussion of this in &lt;a href=&quot;http://dissertations.ub.rug.nl/FILES/faculties/science/1995/m.d.van.der.laan/c6.pdf&quot; rel=&quot;nofollow&quot;&gt;Chapter 6: Sampling in closed loop control systems&lt;/a&gt; of Marten Derk van der Laan's (1995) dissertation &lt;a href=&quot;http://irs.ub.rug.nl/ppn/138454876&quot; rel=&quot;nofollow&quot;&gt;Signal sampling techniques for data acquisition in process control&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Selection of sampling rates is an important issue. For economical&#xA;  reasons, sampling rates are kept as low as possible: A lower rate&#xA;  means that there is more time available for control algorithm&#xA;  execution, which can thereby be carried out on slower computers.&#xA;  Digitizing well behaved analog control systems can heavily affect&#xA;  system response. If sampling frequencies is too low, the systems may&#xA;  even become unstable. According to the Nyquist criterion, the sampling&#xA;  frequency should at least be twice as high as the bandwidth of the&#xA;  error signal. This bandwidth is bounded by the system bandwidth, hence&#xA;  ws  2wB. However, in order to guarantee satisfactory response, a&#xA;  factor of 10 to 20 may be required&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="1584" LastEditorUserId="37" LastEditDate="2013-07-06T00:49:22.970" LastActivityDate="2013-07-06T00:49:22.970" CommentCount="2" />
  <row Id="1543" PostTypeId="2" ParentId="1538" CreationDate="2013-07-05T21:33:05.743" Score="2" Body="&lt;p&gt;If this is true linear motion (non-rotational) then you will need some sort of a pivoting linkage in between the two units to transfer one motion to the other. Something like this would probably work:&#xA;&lt;img src=&quot;http://i.stack.imgur.com/rGdKH.jpg&quot; alt=&quot;Pivoting Linkage&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As the lower link moves vertically, it rotates the red gear which in turn pushes the second link horizontally.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, given that your image shows more of a screw type link, I feel like the lower link will be rotating (correct me if I'm wrong here). In that case, then a different approach would need to be taken - at least, a rotational ball joint would need to be used to attached the rotating unit to any linkage.&lt;/p&gt;&#xA;" OwnerUserId="1197" LastActivityDate="2013-07-05T21:33:05.743" CommentCount="2" />
  <row Id="1544" PostTypeId="1" AcceptedAnswerId="1546" CreationDate="2013-07-06T13:25:20.640" Score="0" ViewCount="734" Body="&lt;p&gt;I have no problem in reading circuit schemes, connecting wires, resistors etc. (basing on for example instructables.com), but I've only tried to learn Java (a while ago) and it's difficult to me to find out what's going on with all this C-code-stuff.&#xA;Are there any tutorials that are focused on the programming part?&#xA;thanks&lt;/p&gt;&#xA;" OwnerUserId="1593" LastActivityDate="2013-07-06T17:12:16.290" Title="Arduino C/C++ progamming tutorials" Tags="&lt;arduino&gt;" AnswerCount="2" CommentCount="5" FavoriteCount="1" ClosedDate="2013-07-09T11:00:37.730" />
  <row Id="1545" PostTypeId="2" ParentId="1544" CreationDate="2013-07-06T16:09:31.183" Score="1" Body="&lt;p&gt;Yes, under the &lt;a href=&quot;http://arduino.cc/en/Tutorial/HomePage&quot; rel=&quot;nofollow&quot;&gt;learning&lt;/a&gt; section of the &lt;a href=&quot;http://arduino.cc&quot; rel=&quot;nofollow&quot;&gt;Arduino website&lt;/a&gt; there are a number of coding tutorials. They begin with explaining the &lt;a href=&quot;http://arduino.cc/en/Tutorial/BareMinimum&quot; rel=&quot;nofollow&quot;&gt;minimum code necessary&lt;/a&gt; to how to use many of the peripherals. These tutorials explain fairly well what each line of the programs do.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-07-06T16:09:31.183" />
  <row Id="1546" PostTypeId="2" ParentId="1544" CreationDate="2013-07-06T17:12:16.290" Score="3" Body="&lt;pre&gt;&lt;code&gt; A great way to learn C/C++ for arduino is by going to the website: ardx.org/CIRC01&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;This website is completely and gives great mini projects that involve electronics and then gives an example code and a great explanation of how the code works. This site consists of 11 projects and explains the basics of C/C++ for arduino, it also teaches you how to read schematics and data sheets. After you are done with project #1 change the CIRC01 at the end of url to CIRC02, and each time you complete a project continue to go to the next one by changing the # on the end of the CIRC to a higher # until you get to 11. By the time you get to project #11 you should have a good understanding of programming for arduino and a better understanding of electronics as well. Another way that I learned C++ is by reading the book &quot;C++ for Dummies by Stephen R. Davis&quot;. This book teaches C++ in a simple yet affective fashion, however it is quite tedious to completely read this book, if it were me I would start by using the projects on ardx.org and then once I have finished all the projects and if I wanted even more knowledge on programming c/C++ then read the book. Good luck!&lt;/p&gt;&#xA;" OwnerUserId="1596" LastActivityDate="2013-07-06T17:12:16.290" CommentCount="2" />
  <row Id="1547" PostTypeId="1" CreationDate="2013-07-06T20:56:49.207" Score="3" ViewCount="57" Body="&lt;p&gt;Many robot applications (actually - the most practical and appealing ones) include the robot's reaction to (and impact on) the evironment, e.g. due to stochastic nature of the environment (e.g. when robot should handle non-rigid objects like clothes) or due to the variability of environment (e.g. harvesting robots should be prepared to pick fruits of different sizes and shapes).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The question is - is there a robotics simulator that can simulate not only robot but also the environment as well? E.g. that can simulate the response of robots action on cloth folding or fruit picking and so on. I guess that such simulator is really non-trivial but maybe there is some ongoing project for it?&lt;/p&gt;&#xA;" OwnerUserId="809" LastEditorUserId="350" LastEditDate="2013-07-07T17:55:22.947" LastActivityDate="2013-07-09T23:51:41.807" Title="How can I simulate a changing environment with non-rigid objects?" Tags="&lt;simulator&gt;&lt;industrial-robot&gt;" AnswerCount="2" CommentCount="1" FavoriteCount="1" />
  <row Id="1548" PostTypeId="2" ParentId="1538" CreationDate="2013-07-07T01:07:38.390" Score="2" Body="&lt;p&gt;The mechanism suggested in the previous answer is a form of&#xA;&lt;em&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Four-bar_linkage&quot; rel=&quot;nofollow&quot;&gt;four-bar linkage&lt;/a&gt;&lt;/em&gt;.  A &lt;em&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Bell_crank&quot; rel=&quot;nofollow&quot;&gt;bell crank&lt;/a&gt;&lt;/em&gt; is a slightly simpler form of basically the same thing.  You could push on one side of a &lt;a href=&quot;https://www.google.com/search?hl=en&amp;amp;site=imghp&amp;amp;tbm=isch&amp;amp;source=hp&amp;amp;biw=1052&amp;amp;bih=570&amp;amp;q=bell+crank&amp;amp;oq=bell+crank&amp;amp;gs_l=img.3..0l5j0i10j0l4.1311.1311.0.1675.1.1.0.0.0.0.170.170.0j1.1.0....0...1ac..19.img.32OY_EL0zEI&quot; rel=&quot;nofollow&quot;&gt;bell crank&lt;/a&gt; with the end of the motor shaft, and use a spring return for the other direction if it is difficult to attach to the shaft.  (The shaft apparently rotates, but the &lt;a href=&quot;http://www.newscaletech.com/technology/squiggle-motors.php&quot; rel=&quot;nofollow&quot;&gt;Squiggle motors&lt;/a&gt; site doesn't say if it does or doesn't, and the pictures, videos, and technical drawing PDF files are not clear on this point.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also consider using a flexible-wire push-pull control cable, or a push cable with  spring return; or push a wedge up to produce &lt;a href=&quot;http://en.wikipedia.org/wiki/Cam&quot; rel=&quot;nofollow&quot;&gt;cam&lt;/a&gt; action.&lt;/p&gt;&#xA;" OwnerUserId="478" LastActivityDate="2013-07-07T01:07:38.390" CommentCount="2" />
  <row Id="1550" PostTypeId="2" ParentId="1547" CreationDate="2013-07-07T21:30:55.837" Score="1" Body="&lt;p&gt;Gazebo, the most popular open-source robotics simulator at the moment, is adding support for the Bullet physics library and that should eventually add simulation of contact with deformable objects. Check out this question: &lt;a href=&quot;http://answers.ros.org/question/57900/deformation-on-gazebo-and-ros-possible/&quot; rel=&quot;nofollow&quot;&gt;http://answers.ros.org/question/57900/deformation-on-gazebo-and-ros-possible/&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, &lt;a href=&quot;http://opengrasp.sourceforge.net&quot; rel=&quot;nofollow&quot;&gt;OpenGRASP&lt;/a&gt;, built on top of &lt;a href=&quot;http://openrave.org&quot; rel=&quot;nofollow&quot;&gt;OpenRAVE&lt;/a&gt;, includes soft contact simulation.&lt;/p&gt;&#xA;" OwnerUserId="1473" LastEditorUserId="1473" LastEditDate="2013-07-07T21:42:24.240" LastActivityDate="2013-07-07T21:42:24.240" />
  <row Id="1552" PostTypeId="1" AcceptedAnswerId="1553" CreationDate="2013-07-08T00:46:21.340" Score="1" ViewCount="408" Body="&lt;p&gt;Hy, I just found useful to post my idea here. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've seen videos about automated quadcopters: &lt;a href=&quot;http://www.ted.com/talks/raffaello_d_andrea_the_astounding_athletic_power_of_quadcopters.html&quot; rel=&quot;nofollow&quot;&gt;http://www.ted.com/talks/raffaello_d_andrea_the_astounding_athletic_power_of_quadcopters.html&lt;/a&gt; and &lt;a href=&quot;http://www.ted.com/talks/vijay_kumar_robots_that_fly_and_cooperate.html&quot; rel=&quot;nofollow&quot;&gt;http://www.ted.com/talks/vijay_kumar_robots_that_fly_and_cooperate.html&lt;/a&gt;. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I surfed pages from the companies presenting this research and other information on the internet, but I haven't found why they use quadcopters specifically. &#xA;I understand, how accelerating, rotating and rolling works in those quadcopters - it's simple, but they claim that quadcopters have minimum number of working parts to fulfill their needs, which I don't agree and I think that tricopters are better in this (duocopters can't rotate horizontally, but tricopters can by inclining and then powering the remaining left or right propeller). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I rode forums, calculated and draw drafts of both tri and quad and found, that tri is much more efficient just in everything than quad with same props and battery when taken in account that best properties has the smallest copter with the largest props so: &#xA;3:4 moving parts (no vectored yaw in tri), 9.5:16 size, building Y instead of X construction take far less material 1.5:2.82, lesser maximum power input 3:4, better power efficiency makes longer flight time and tricopters have also improved agility over quadcopters. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The only disadvantage I see is a bit complicated horizontal rotating in tricopter without vectored yaw, which can be problem in man controlled machines but easily solved by simple algorithms in automated machines -&gt; it's not a real disadvantage, just a small work to be done. I was thinking about doing that in my bachelor thesis, but for now I am looking for your opinions, thanks!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT: Maybe the torque is the problem, because on tricopters you can can have all 3 props in 1 direction or 2 in 1 direction and 1 in the opposite and it's symmetrical in neither way, but I'm not sure if this is the main problem...&lt;/p&gt;&#xA;" OwnerUserId="1602" LastEditorUserId="1602" LastEditDate="2013-07-08T03:22:54.580" LastActivityDate="2013-07-08T04:43:04.390" Title="Use of automated tricopters instead of quadcopters?" Tags="&lt;quadcopter&gt;&lt;multi-rotor&gt;" AnswerCount="1" CommentCount="4" ClosedDate="2013-07-09T10:50:46.017" />
  <row Id="1553" PostTypeId="2" ParentId="1552" CreationDate="2013-07-08T04:43:04.390" Score="1" Body="&lt;p&gt;If you want to maximise efficiency, you go with two rotors: a main rotor, and a tail rotor. I.e. a traditional helicopter. With the common CCPM setup (Cyclic Collective Pitch Mixing), you have three servos controlling the main rotor. Together they can tilt it any direction and control the pitch on the blades. As you can imagine, this is mechanically complicated.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The advantage of a quadcopter is that it's very simple; you have no servos. Adjacent arms are counter-rotating to control yaw.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Tricopters have a yaw imbalance that is corrected by dynamically tilting one of the motors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, with a tricopter you lose the &quot;no servo&quot; advantage that made people switch from traditional 2-rotor helis to quads.&lt;/p&gt;&#xA;" OwnerUserId="1473" LastActivityDate="2013-07-08T04:43:04.390" />
  <row Id="1554" PostTypeId="1" AcceptedAnswerId="1559" CreationDate="2013-07-08T06:46:38.617" Score="3" ViewCount="1189" Body="&lt;p&gt;If this has already been answered, by all means please point me to it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am in the process of building a quadcopter which I eventually plan to run autonomously by allowing it to track an object and take a video feed of it moving.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;GPS is one of the options I've considered, basically:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;GPS antena on moving object (person, car, bike, surfer)&lt;/li&gt;&#xA;&lt;li&gt;GPS antena on quadcopter&lt;/li&gt;&#xA;&lt;li&gt;Radio to transmit coordinates from moving object to quad copter&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Some of the challenges I can foresee are&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Line of sight for camera. How does the camera know exactly where to point?&lt;/li&gt;&#xA;&lt;li&gt;Angle, how can I pre-program the quad to always record, say... 10m to the right of the moving object, or even better, program a set of angles to record from whilst keeping up with the object&lt;/li&gt;&#xA;&lt;li&gt;GPS accuracy, what happens if the GPS lock is weak?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;What are some of my other options? I saw this &lt;a href=&quot;http://www.youtube.com/watch?v=w2itwFJCgFQ&quot; rel=&quot;nofollow&quot;&gt;TED Talk&lt;/a&gt; where the quads are following a ball shaped sensor? I believe it uses Kinect cameras and lots of them which is not really an option for this challenge.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So I'm open to hearing some ideas before I start research and development of these features.&lt;/p&gt;&#xA;" OwnerUserId="825" LastActivityDate="2014-01-07T20:18:09.773" Title="Track a moving object" Tags="&lt;arduino&gt;&lt;quadcopter&gt;&lt;gps&gt;" AnswerCount="5" />
  <row Id="1558" PostTypeId="2" ParentId="1554" CreationDate="2013-07-08T16:12:51.137" Score="1" Body="&lt;p&gt;Research the accuracy of your proposed GPS receivers.  You may be disappointed.  You can augment GPS accuracy by fusing the GPS receiver output with data from an inertial sensor, but as far as I know you can't get a hobbyist-price system where that's already done, and the problem isn't at all trivial to solve.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For pointing, consider a compass on your quad copter.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It's going to be a pretty rough problem to solve, particularly if you want the quad copter to be small and not tied to a ground station (there's lots you could do if you had video processing capabilities, and the time to get them working, but that's not something that'll readily fit on a small copter).&lt;/p&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-07-08T16:12:51.137" CommentCount="1" />
  <row Id="1559" PostTypeId="2" ParentId="1554" CreationDate="2013-07-08T16:13:01.717" Score="3" Body="&lt;p&gt;A &lt;a href=&quot;http://www.vicon.com/&quot; rel=&quot;nofollow&quot;&gt;Vicon&lt;/a&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Motion_capture&quot; rel=&quot;nofollow&quot;&gt;motion capture system&lt;/a&gt; system is used in the TED Talk that you referenced. It is similar to a Kinect in that gives the 3D coordinates of any object being tracked within its field of view. Like the Kinect it uses IR, but uses IR reflective balls attached to the quadrotor and the presenters pointer to identify and track objects. Not to mention it is a considerably more expensive system.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Systems like Vicon and the Kinect do not work outdoors because they use IR and the sun blinds them. The GPS solution you propose is a common approach to this problem for outdoor venues. Another approach might be to use &lt;a href=&quot;http://quuppa.com/&quot; rel=&quot;nofollow&quot;&gt;Quuppa&lt;/a&gt;, an RF based motion capture system.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Regardless of which tracking method you use, once you know the position of the robot and the target the problem of calculating the direction to the target, or ahead of it, is a basic geometric problem. Subtracting the robot position from the target position will give you the direction to point the camera. To track a few feet ahead of the target you would first add vector to the target position representing the direction of travel and lead distance (10m in your example).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you don't actually need to know the location of the robot, only its relative position to the target, then you could use computer vision techniques to track the target and move with it. Of course you will need to avoid obstacles in the process. Also the obstacles themselves could occlude your view in which case you would need some way to predict the targets movement. This could be particularly difficult to come up with if your tracking humans outdoors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The reality is that the problem you are addressing is a highly active area of research. I know of several research groups, both in academia and industry, that are trying to address this problem. I have only scratched the surface here.&lt;/p&gt;&#xA;" OwnerUserId="177" LastEditorUserId="2447" LastEditDate="2014-01-07T20:02:21.813" LastActivityDate="2014-01-07T20:02:21.813" CommentCount="1" />
  <row Id="1560" PostTypeId="2" ParentId="1554" CreationDate="2013-07-08T19:21:05.057" Score="1" Body="&lt;p&gt;Your proposed GPS solution is the best option by a significant margin, as long as you are in an environment where GPS is available (aka you are always outdoors).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Vision-based solutions might seem tempting, but they are really not appropriate in this situation.  Not only are you limited in terms of camera quality and processing power, but object tracking in arbitrary locations outdoors is a horrendously difficult problem, especially once you start have partial/complete occlusions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You also have a very nice advantage because the vast majority of GPS errors will affect both receivers simultaneously. Their &quot;global&quot; position might be off by dozens of meters, but their relative locations are likely to be much, much closer. (This is essentially &lt;a href=&quot;http://en.wikipedia.org/wiki/Differential_GPS&quot; rel=&quot;nofollow&quot;&gt;DGPS&lt;/a&gt;.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As soon as you know the location of your quadrotor relative to the location of the target the problem reduces down to high-school trig or basic linear algebra. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note that as soon as you start talking about obstacle avoidance, or robustness when sensors drop out things become genuinely complicated again.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Frankly, a reliable solution to this problem that does not involve placing a beacon on the target would be at the minimum worthy of a PhD thesis, and probably worth a lot more.&lt;/p&gt;&#xA;" OwnerUserId="65" LastEditorUserId="1177" LastEditDate="2013-12-31T16:58:12.753" LastActivityDate="2013-12-31T16:58:12.753" />
  <row Id="1561" PostTypeId="2" ParentId="1554" CreationDate="2013-07-08T19:33:38.937" Score="1" Body="&lt;p&gt;In this case, your absolute-positioning technology is a red herring.  If you are trying to track an object, all that matters is your relative position.  We did such vision-based navigation (relative to an underwater structure) with an underwater vehicle -- unable to receive GPS signals while submerged.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Assuming that you've established the ability to locate an object in a video frame (and deduce your range and bearing relative to it), all that remains is to calculate your desired position and feed that into your X/Y PID control.  The only difficult part is getting the object into the frame initially.  (Presumably, your coarse GPS control will get you in the right ballpark.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I can think of 3 fairly simple ways that you might get your range and bearing from an input video stream.  The best way would be to have native 3D support in the camera (such as in a Kinect).  Failing that, if you know your target's size (and how to detect it in the frame) then you should be able to calculate the range based on how many pixels it occupies.  Worst case, just use an &lt;a href=&quot;http://www.aforgenet.com/articles/glyph_recognition/&quot; rel=&quot;nofollow&quot;&gt;augmented reality glyph&lt;/a&gt; on your target -- they are fairly easy for computer vision to detect.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-07-08T19:33:38.937" CommentCount="2" />
  <row Id="1562" PostTypeId="1" AcceptedAnswerId="1563" CreationDate="2013-07-09T11:15:30.823" Score="2" ViewCount="154" Body="&lt;p&gt;&lt;a href=&quot;http://robotics.stackexchange.com/a/549/37&quot;&gt;An answer&lt;/a&gt; to the question &lt;a href=&quot;http://robotics.stackexchange.com/q/543/37&quot;&gt;Why do quadcopters have four propellers? (Besides the name)&lt;/a&gt;  said:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;You need 4 degrees of freedom to control yaw, pitch, roll and thrust.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Four props is therefore the minimum number of actuators required. Tricoptors require a servo to tilt one or more rotors which is more mechanically complicated.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;In a comment, I asked:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;How do you get pure yaw motion with a quadcoptor and if that's possible why won't this work with a tricoptor? I don't understand how can you get yaw motion with any system where all rotors are in a plane without first tilting and moving. I would have thought that the main difference between quadcopters and tricoptors would be the kinematic calculations would be more complex.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://robotics.stackexchange.com/a/1453/37&quot;&gt;Another answer&lt;/a&gt; explained:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;you get pure yaw in the following way:&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;North and South motors rotating the same speed but collectively at a higher (or lower) speed than East and West Motors which are also at the same speed. &lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;This explains why it works with a quadcopter, but doesn't explain why it won't work with a tricopter.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is it simply the fact that the asymmetry means that you can't imbalance the &lt;a href=&quot;http://en.wikipedia.org/wiki/Torque_effect&quot; rel=&quot;nofollow&quot;&gt;torque effects&lt;/a&gt; to provide yaw movement while still keeping the thrusts balanced to keep pitch and roll constant?&lt;/p&gt;&#xA;" OwnerUserId="37" LastEditorUserId="350" LastEditDate="2013-07-09T19:00:23.583" LastActivityDate="2013-07-09T19:00:23.583" Title="If you can create pure yaw motion with a quadcoptor then why won't this work with a tricoptor?" Tags="&lt;design&gt;&lt;quadcopter&gt;&lt;uav&gt;&lt;tricopter&gt;" AnswerCount="1" CommentCount="1" FavoriteCount="2" />
  <row Id="1563" PostTypeId="2" ParentId="1562" CreationDate="2013-07-09T12:20:25.863" Score="5" Body="&lt;p&gt;Let's look at how a quadrotor flies, then apply that to a trirotor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Let's assume that we want to remain in a stationary hover position. To do that, you need to balance all the forces: thrust from the propellers vs. gravity, and the torques of each motor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Each motor produces both thrust and torque according to the equations:&#xA;$$&#xA;T = K_T\rho n^2 D^4&#xA;$$&#xA;$$&#xA;Q = K_Q\rho n^2 D^5&#xA;$$&#xA;Where $T$ is thrust, $Q$ is torque, $K_T$ and $K_Q$ are system dependent constants, $\rho$ is the air density, $n$ is rotor speed, and $D$ is rotor diameter.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you increase thrust then you increase torque, and vice versa. A quadrotor remains stationary by balancing all the forces. This is possible because the quadrotor is symmetrical: two motors spin clockwise, and two motors spin anti clockwise. If all the motors rotate at the same speed then the torques balance, and the thrust balances. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The only question then is what speed? The four rotors need to spin fast enough to collectively generate enough lift to remain in a stationary hover.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What about a trirotor?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Intuitively, the easy base case is when the arms holding the motors are all the same length (such that you can ignore the effects of the motor's displacement from the center of mass). In this case you must set the force of each motor to be equal (to hover without falling) then the torques will be unbalanced (2 in one direction, 1 in the other). The result is a spinning trirotor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The slightly more difficult case is when the rotor arms are not the same length. To solve that, let's solve the general case. The equation for torque is:&#xA;$$&#xA;\tau = rFsin(\theta)&#xA;$$&#xA;$sin(\theta)$ is 1 (at a right angle), so we can ignore it and rearrange our torque equation as follows:&#xA;$$&#xA;F = \frac{\tau}{r}&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Let's make a trirotor and label it as follows:&#xA;&lt;img src=&quot;http://i.stack.imgur.com/bfK3P.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then, we can balance all the torques:&#xA;$$&#xA;\frac{\tau_A}{r_A} + \frac{\tau_B}{r_B} + \frac{\tau_C}{r_C} = 0&#xA;$$&#xA;Substitute in the motor equation for torque from above:&#xA;$$&#xA;\frac{ K_Q\rho n_A^2 D^5}{r_A} + \frac{K_Q\rho n_B^2 D^5}{r_B} + \frac{K_Q\rho n_C^2 D^5}{r_C} = 0&#xA;$$&#xA;And get rid of the common constants:&#xA;$$&#xA;\frac{n_A^2}{r_A} + \frac{n_B^2}{r_B} + \frac{n_C^2}{r_C} = 0&#xA;$$&#xA;To solve this equation, we need to make a system of equations with the thrust for each motor:&#xA;$$&#xA;T_A + T_B + T_C = mg&#xA;$$&#xA;$$&#xA;K_T\rho n_A^2 D^4 + K_T\rho n_B^2 D^4 + K_T\rho n_C^2 D^4 = mg&#xA;$$&#xA;$$&#xA;n_A^2 + n_B^2 + n_C^2  = \frac{mg}{K_T\rho D^4} = C&#xA;$$&#xA;Where C is some constant. We don't really care what it is as long as it's non-zero (if it's zero then we don't need the motors to do anything).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now, make our system of equations and solve them:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$&#xA;\frac{n_A^2}{r_A} + \frac{n_B^2}{r_B} + \frac{n_C^2}{r_C} = 0&#xA;$$&#xA;$$&#xA;n_A^2 + n_B^2 + n_C^2  =  C&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Right away we see that there is no solution except when $C=0$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thus, a trirotor needs the servo to rotate at least one motor in order to generate more torque without generating more thrust (in the z direction).&lt;/p&gt;&#xA;" OwnerUserId="1524" LastActivityDate="2013-07-09T12:20:25.863" CommentCount="1" />
  <row Id="1564" PostTypeId="1" CreationDate="2013-07-09T12:57:07.513" Score="1" ViewCount="29" Body="&lt;p&gt;I am trying to launch a file from remote computer but I could not success. Actually I can connect to remote computer but I think the problem is with including a file from remote computer. In other words, I am looking for a machine tag for include. Here is the my code:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;launch&amp;gt;  &#xA;&#xA;    &amp;lt;group &amp;gt;&#xA;      &amp;lt;machine name=&quot;marvin-1&quot; address=&quot;tek-marvin-1&quot; user=&quot;blabla&quot; password=&quot;blabla&quot; env-loader=&quot;/home/blabla/.rosLaunchScript.sh&quot;/&amp;gt;  &#xA;&#xA;      &amp;lt;include file=&quot;$(find openni_launch_marvin)/launch/kinect_left.launch&quot;/&amp;gt;&#xA;    &amp;lt;/group&amp;gt;     &#xA;&#xA;&amp;lt;/launch&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="1611" LastActivityDate="2013-07-09T12:57:07.513" Title="Roslaunch include file remotely" Tags="&lt;ros&gt;" CommentCount="1" />
  <row Id="1565" PostTypeId="5" CreationDate="2013-07-09T13:02:35.087" Score="0" ViewCount="5" Body="&lt;p&gt;A sensor (also called detector) is a converter that measures a physical quantity and converts it into a signal which can be read by an observer or by an (today mostly electronic) instrument. For example, a mercury-in-glass thermometer converts the measured temperature into expansion and contraction of a liquid which can be read on a calibrated glass tube. A thermocouple converts temperature to an output voltage which can be read by a voltmeter. For accuracy, most sensors are calibrated against known standards.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Sensors are used in everyday objects such as touch-sensitive elevator buttons (tactile sensor) and lamps which dim or brighten by touching the base. There are also innumerable applications for sensors of which most people are never aware. Applications include cars, machines, aerospace, medicine, manufacturing and robotics.&lt;/p&gt;&#xA;" OwnerUserId="1449" LastEditorUserId="1449" LastEditDate="2013-08-02T18:58:59.417" LastActivityDate="2013-08-02T18:58:59.417" />
  <row Id="1566" PostTypeId="4" CreationDate="2013-07-09T13:02:35.087" Score="0" Body="A sensor (also called detector) is a converter that measures a physical quantity and converts it into a signal which can be read by an observer or by an (today mostly electronic) instrument." OwnerUserId="1449" LastEditorUserId="1449" LastEditDate="2013-08-02T18:59:03.247" LastActivityDate="2013-08-02T18:59:03.247" />
  <row Id="1567" PostTypeId="1" CreationDate="2013-07-09T18:13:57.490" Score="4" ViewCount="187" Body="&lt;p&gt;For a DC motor with a stall current of 950 mA, what should the H-bridge's current rating be?  What will happen if we use our H-bridge L293D whose max. output current is 600 mA?&lt;/p&gt;&#xA;" OwnerUserId="1613" LastEditorUserId="350" LastEditDate="2013-07-09T18:57:44.237" LastActivityDate="2013-07-11T00:07:16.307" Title="H-bridges and stall current" Tags="&lt;motor&gt;&lt;electronics&gt;&lt;h-bridge&gt;" AnswerCount="2" />
  <row Id="1568" PostTypeId="2" ParentId="1547" CreationDate="2013-07-09T23:51:41.807" Score="1" Body="&lt;p&gt;I think &lt;a href=&quot;http://www.gazebosim.org/&quot; rel=&quot;nofollow&quot;&gt;Gazebo&lt;/a&gt; is the most popular, but &lt;a href=&quot;http://www.openrobots.org/wiki/morse/&quot; rel=&quot;nofollow&quot;&gt;Morse&lt;/a&gt; is also worth checking.&lt;/p&gt;&#xA;" OwnerUserId="484" LastActivityDate="2013-07-09T23:51:41.807" CommentCount="1" />
  <row Id="1569" PostTypeId="2" ParentId="1567" CreationDate="2013-07-09T23:57:08.023" Score="2" Body="&lt;p&gt;First a bit about motors. Stall current is the current drawn by the motor when the recommended voltage is applied and the motor is not turning due to a load. Alternatively, the no load speed is the speed the motor will spin at under no load. In this state it will draw a minimum current.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here is an example torque/speed current for a DC motor:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/dsC0E.jpg&quot; alt=&quot;Torque / Speed Curve for DC motor&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Source: &lt;a href=&quot;http://www.societyofrobots.com/robotforum/index.php?topic=4324.0&quot; rel=&quot;nofollow&quot;&gt;societyofrobots.com&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So whether or not you can use your H-Bridge depends on how you are using the motor. If you are using the motor at a high speed and thus low torque state, you will not approach the stall current and may stay within the spec for the motor driver.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Furthermore, torque/speed curve is voltage dependent. If you operate at a lower voltage, you will draw less current and could possibly stay within spec for the H-bridge. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you exceed the recommended current draw for the H-Bridge, it will heat up and possibly burn out or in the worst case start a fire. The L293D has overtemp protection so it may just stop functioning.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are ways to increase the max current capacity of the H-bridge by introducing cooling in the form of a heat sink or fan or liquid cooling, etc. The current through the H-bridge is causing resistive heating of the chip. The heating raises the temperature of the chip eventually causing damage. If you increase the flow of heat out of the chip, you will be able to heat it more (more current) without raising the temperature too high.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another option is use two L293D chips in parallel (H-bridge piggybacking). Adafruit suggests this with their motor arduino shield which uses L293D chips. They state this will double the current capacity. &lt;a href=&quot;http://learn.adafruit.com/adafruit-motor-shield/power-requirements&quot; rel=&quot;nofollow&quot;&gt;http://learn.adafruit.com/adafruit-motor-shield/power-requirements&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Other H-bridges you could checkout are the L298 and DRV8801.&lt;/p&gt;&#xA;" OwnerUserId="1125" LastEditorUserId="350" LastEditDate="2013-07-10T04:10:29.557" LastActivityDate="2013-07-10T04:10:29.557" CommentCount="1" />
  <row Id="1570" PostTypeId="1" AcceptedAnswerId="1573" CreationDate="2013-07-10T11:07:19.197" Score="1" ViewCount="109" Body="&lt;p&gt;I found &lt;a href=&quot;http://www.kionix.com/sites/default/files/AN012%20Accelerometer%20Errors.pdf&quot; rel=&quot;nofollow&quot;&gt;a good explanation&lt;/a&gt; on how to remove accelerometer bias (when on flat table only one axis should show values, the other two should be 0). I've calculated S and B factors (page 3):&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Record $B_x^{0g}$, $B_y^{0g}$, $B_z^{0g}$, $S_{xx}$, $S_{yy}$, and $S_{zz}$ in EEPROM or flash memory&#xA;  and use these values in all subsequent calculations of acceleration to&#xA;  get the corrected outputs.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;I don't know how to incorporate these into the final calculation of accelerations. I guess the bias should be substracted from my sensor reading. What about sensitivities (S)?&lt;/p&gt;&#xA;" OwnerUserId="584" LastEditorUserId="350" LastEditDate="2013-07-10T14:56:33.010" LastActivityDate="2013-07-10T16:07:57.553" Title="Accelerometer bias removal" Tags="&lt;accelerometer&gt;&lt;calibration&gt;&lt;errors&gt;" AnswerCount="2" />
  <row Id="1571" PostTypeId="1" AcceptedAnswerId="1576" CreationDate="2013-07-10T14:31:23.340" Score="3" ViewCount="177" Body="&lt;p&gt;For Halloween, I'd like to build a spider that drops from the ceiling when it detects motion, and then rewinds itself back up to scare the next kids. I already have a lightweight foamish spider from Hobby Lobby that I'd like to use, but I need help adding the smarts to it to scare the kids.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ideally it'd be able to detect how tall/far away the kid is to drop to a custom height each time, but I'd settle for a standard dropping height if that's too much. I even had an idea of having a motion sensor and having it shoot Silly String webs in front of people. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have a very technical background, but I'm a total n00b when it comes to robotics, so ideas as to what components and considerations I'd need would be greatly appreciated!&lt;/p&gt;&#xA;" OwnerUserId="1624" LastActivityDate="2013-07-10T22:43:45.287" Title="How to raise/drop a spider" Tags="&lt;motor&gt;&lt;rcservo&gt;" AnswerCount="4" />
  <row Id="1572" PostTypeId="2" ParentId="1571" CreationDate="2013-07-10T14:50:17.530" Score="1" Body="&lt;p&gt;It sounds like you want some sort of winch that moves faster in one direction (for the release) than the other.  There are heavy-duty winches that accomplish this by having a clutch in addition to the winch motor, so that when the clutch is disengaged the cable can unspool freely.  &lt;strong&gt;EDIT:&lt;/strong&gt; Fishing reels are a more appropriate example (+1 &lt;a href=&quot;http://robotics.stackexchange.com/a/1576/350&quot;&gt;JoeFromOzarks&lt;/a&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To achieve custom drop distance with such a setup, you'd have to rely on disengaging the clutch for a very specific interval -- you should be able to find the relationship between drop time and drop distance (considering gravity, spool momentum, and string friction).  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;When rewinding, you'd need a sensor to detect when the string is all the way back in.  There are several ways you might do this, from electrical measurement of the motor load to physical measurements on the string/spider position.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You may want to check out this other question for a list of ways to detect motion: &lt;a href=&quot;http://robotics.stackexchange.com/q/1393/350&quot;&gt;What is the cheapest / easiest way of detecting a person?&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-07-10T18:14:04.890" LastActivityDate="2013-07-10T18:14:04.890" />
  <row Id="1573" PostTypeId="2" ParentId="1570" CreationDate="2013-07-10T15:12:01.310" Score="2" Body="&lt;p&gt;As noted at the top of the second page:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;$B_z^{0g} = a_{z1}-S_{zz}*1g$&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;The &quot;ground truth&quot; z-axis acceleration (of an accelerometer sitting flat on the table) is $1g$, which is affected by the sensitivity of the accelerometer along that axis.  You could rewrite it as follows:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$Bias = a_{measured} - Sensitivity * a_{actual}$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Since you want to calculate the actual acceleration from the measured acceleration, you'd rewrite it like this:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$a_{actual}=\frac{a_{measured}-Bias}{Sensitivity}$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Or in terms of the original variables,&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$a_{z1}^{corrected}=\frac{a_{z1}-B_z^{0g}}{S_{zz}}$$&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-07-10T15:23:09.263" LastActivityDate="2013-07-10T15:23:09.263" CommentCount="1" />
  <row Id="1574" PostTypeId="2" ParentId="1570" CreationDate="2013-07-10T16:07:57.553" Score="2" Body="&lt;p&gt;Ian's answer is mathematically correct.  However, on most processors division takes longer than multiplication.  So if you're at all pressed for processor resources you would want to precalculate a gain and offset for each channel, and apply it:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$k_{zz} = \frac{1}{S_{zz}}$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$b_{zz} = -\frac{B_z^{0g}}{S_{zz}}$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$a_{z1}^{corrected} = k_{zz} a_{z1} + b_{zz}$&lt;/p&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-07-10T16:07:57.553" CommentCount="1" />
  <row Id="1575" PostTypeId="2" ParentId="1567" CreationDate="2013-07-10T16:22:48.997" Score="1" Body="&lt;p&gt;What Brendan said.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, there is an out if you want to reach for it: once you have determined the actual stall current for your situation, from the motor armature resistance, supply voltage, and the whopping 1.4V drop in the L293, if you pulse the drive to the motor such that the &lt;em&gt;average&lt;/em&gt; current through the L293 is the rated 600mA or less, then it shouldn't burn up.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You'll need to pay attention to switching speed, and where the current goes on the back side of the PWM, and all those other pesky details, and if your PWM generator stalls at the wrong portion of the cycle things will get toasty, but that doesn't mean there isn't a path to success with that part.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(Personally, I'd figure out how to deal with surface-mount parts and put in the DRV8801 -- it looks far superior.  Or, if I never needed to generate top torque at top speed, and if efficiency wasn't a concern, I'd just put a resistor in series with the motor).&lt;/p&gt;&#xA;" OwnerUserId="1533" LastEditorUserId="1533" LastEditDate="2013-07-11T00:07:16.307" LastActivityDate="2013-07-11T00:07:16.307" CommentCount="2" />
  <row Id="1576" PostTypeId="2" ParentId="1571" CreationDate="2013-07-10T16:59:58.937" Score="6" Body="&lt;p&gt;Take a look at a kids &quot;spincast&quot; fishing reel and rod.&lt;br&gt;&#xA;&lt;a href=&quot;http://i.stack.imgur.com/XYdwV.jpg&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/XYdwVm.jpg&quot; alt=&quot;Spincast reel&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We built one in 2008 (still works, rain, snow and all!) using a automobile door lock solenoid to operate the &quot;thumb release&quot; and an automobile power window motor (PWM &amp;amp; MOSFET) via rubber hose driveline to operate the retract.  Choice of MCU is yours, but we've since added spooky lights, MP3 with speaker, &quot;beam break&quot; and IR detectors just to &quot;juice it up.&quot;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.flickr.com/photos/joefromozarks/9257124436/sizes/o/in/photostream/&quot;&gt;&lt;img src=&quot;http://farm6.staticflickr.com/5521/9257124436_7ef2c04e3b_z.jpg&quot; alt=&quot;diagram&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1625" LastEditorUserId="350" LastEditDate="2013-07-10T18:02:13.573" LastActivityDate="2013-07-10T18:02:13.573" CommentCount="11" />
  <row Id="1577" PostTypeId="2" ParentId="1571" CreationDate="2013-07-10T17:13:46.590" Score="3" Body="&lt;p&gt;If you want to detect how tall your target is &lt;em&gt;and&lt;/em&gt; tailor the drop height to suit, then you are going to need more precise &lt;em&gt;sensors&lt;/em&gt; and &lt;em&gt;control&lt;/em&gt; than the other (excellent) answers here.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One option might be to use a &lt;a href=&quot;http://www.pololu.com/catalog/product/723&quot; rel=&quot;nofollow&quot;&gt;Sonar Range Finder&lt;/a&gt; as suggested in &lt;a href=&quot;http://robotics.stackexchange.com/a/1397/37&quot;&gt;this answer&lt;/a&gt; to &lt;a href=&quot;http://robotics.stackexchange.com/q/1393/350&quot;&gt;What is the cheapest / easiest way of detecting a person?&lt;/a&gt; &lt;sup&gt;(Thanks &lt;a href=&quot;http://robotics.stackexchange.com/a/1572/37&quot;&gt;Ian&lt;/a&gt;)&lt;/sup&gt;&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Basic idea&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;While the &lt;em&gt;SRF&lt;/em&gt; is detecting a distance of more than your maximum drop distance, the 'spider' would lie in wait. If the &lt;em&gt;SRF&lt;/em&gt; detects anything closer, you immediately start the motor unspooling the cord and the spider will start dropping.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As the spider is dropping you continue monitoring the &lt;em&gt;SRF&lt;/em&gt; and stop unspooling when the length of cord you've unspooled is approximately the same as the &lt;em&gt;minimum&lt;/em&gt; distance measured by the &lt;em&gt;SRF&lt;/em&gt; since it started dropping. This should place the spider right at eye level of the tallest person there, for maximum effect.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Finally, after a short delay, start the motor slowly returning to it's rest position by spooling the cord back in and resetting for the next &lt;em&gt;attack&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Complications&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;You will need to be careful about the weight of the spider. It needs to be heavy enough that &lt;a href=&quot;https://en.wikipedia.org/wiki/Drag_%28physics%29&quot; rel=&quot;nofollow&quot;&gt;drag (air resistance)&lt;/a&gt; does not significantly impede it's acceleration due to gravity, but not so heavy that it could harm anyone or overload your motor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Even if your spider isn't &lt;em&gt;too&lt;/em&gt; heavy, you will want to make sure that there is &lt;a href=&quot;http://www.wikihow.com/Make-Larp-Arrows&quot; rel=&quot;nofollow&quot;&gt;1.5 to 2&quot; of foam&lt;/a&gt; between the heavy centre and anything that might touch anyone. You will also need to make sure that there are no stiffening wires or springs which can end up protruding out of the spider as it wears. All basic health and safety stuff really.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If the spider is dropping into the SRF sensor beam area, then obviously you will not be able to improve your initial estimate of drop distance, and will just have to drop to that first range measured. This might mean that you end up dropping to teh height of someone's hand rather than to the level of their head though.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you want to be clever, you can arrange your drop trajectory to be controlled so that you never have too much loose cord, this will minimise the risk of the cord getting tangled and snagging on anything. In this case you will want to ramp up the speed of the motor such that the cord is being spooled out at the same rate as the acceleration of the spider due to gravity, i.e. $9.8 ms^{-2}$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You may or may not also want to control the deceleration rate as you approach the desired drop length. The faster you stop it, the more dramatically the spider will bounce and jump around, but the more stress you will put your system under.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Finally, you will want to size your motor such that it can move relatively quickly under light load (when dropping) but still have the torque to stop the spider at the end of travel (and winch the spider back up).&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Some calculations&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;The formulae for &lt;a href=&quot;http://en.wikipedia.org/wiki/Acceleration#Uniform_acceleration&quot; rel=&quot;nofollow&quot;&gt;uniform acceleration&lt;/a&gt; is $s=ut+\frac{1}{2}at^2$ where $s$ is displacement, $u$ is initial velocity (zero in our case), $a$ is uniform acceleration and $t$ is time.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Assuming that you have a spool of 10cm in circumference, and want to drop the spider at most 2m then $s=2$, $u=0$, $a=9.8$ and $t$ is unknown: $t=\sqrt{\frac{2}{\frac{9.8}{2}}}=0.638$. To spool 2m in that time seconds would require the spool to turn at almost 2000 rpm on average ($200/10/0.638*60=1881$).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This seems a little unreasonable, so doubling the spool to 20cm circumference would drop the motor speed to under 1000rpm on average, but we are now looking at quite a bulky bit of mechanics.&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Conclusion&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;If you get the design right, you might even be able to fit all of the components needed (spider, spool, motor, drive electronics, control electronics, sensor and power supply) into something which you can screw into a light fitting and thus hide in a (large) lamp shade.&lt;/p&gt;&#xA;" OwnerUserId="37" LastEditorUserId="37" LastEditDate="2013-07-10T22:43:45.287" LastActivityDate="2013-07-10T22:43:45.287" CommentCount="1" />
  <row Id="1578" PostTypeId="2" ParentId="1571" CreationDate="2013-07-10T18:16:20.393" Score="1" Body="&lt;p&gt;I did this exact same project 6 years back. I used two servos. The first was a continuous rotation servo with a spool the pull the spider up. The spool did not have an end on it so that when the spool turned parallel to the string it all came loose and the spider fell. It was simple and effective, although the CR servo that I used was under powered.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have a write up in &lt;a href=&quot;http://forums.parallax.com/showthread.php/107352-Oldbit-s-Unofficial-Propeller-Halloween-Contest-%28Over-300-value-in-cash-amp-priz?p=760287&amp;amp;viewfull=1#post760287&quot; rel=&quot;nofollow&quot;&gt;this thread&lt;/a&gt; on the Parallax forums.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/LSHzj.jpg&quot; alt=&quot;hardware picture&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="1524" LastActivityDate="2013-07-10T18:16:20.393" CommentCount="2" />
  <row Id="1579" PostTypeId="1" CreationDate="2013-07-10T20:44:48.130" Score="3" ViewCount="129" Body="&lt;p&gt;I've already &lt;a href=&quot;http://robotics.stackexchange.com/questions/1570/accelerometer-bias-removal&quot;&gt;asked a related question (accelerometer bias removal)&lt;/a&gt; here on robotics and got a bit better results on corrected accelerometer output. To get even better results I found the &lt;a href=&quot;http://www.vectornav.com/support/library?id=86&quot; rel=&quot;nofollow&quot;&gt;calibration equations (7th &amp;amp; 8th paragraph)&lt;/a&gt; from Vectornav which are just a bit enhanced than the solution in the linked question:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/ZlbWs.png&quot; alt=&quot;enter image description here&quot;&gt; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, six more variables are needed:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Sensitivity of sensor X-axis to Y-axis inputs ($M_{xy}$)&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Sensitivity of sensor X-axis to Z-axis inputs ($M_{xz}$)&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Sensitivity of sensor Y-axis to X-axis inputs ($M_{yx}$)&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Sensitivity of sensor Y-axis to Z-axis inputs ($M_{yz}$)&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Sensitivity of sensor Z-axis to X-axis inputs ($M_{zx}$)&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Sensitivity of sensor Z-axis to Y-axis inputs ($M_{zy}$)&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Below it is also stated:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;IEEE-STD-1293-1998 [...] provides a detailed test procedure for&#xA;  determining each of these calibration parameters&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;However, after searching through the &lt;a href=&quot;https://docs.google.com/file/d/0B8zqB-WeBKRBTUN4OU0weEV0eVE/edit&quot; rel=&quot;nofollow&quot;&gt;1293-1998 standard&lt;/a&gt; (especially page 201 in Google Docs) I didn't find any clue on how to calculate the $M$ values. Also, $B_{d}$ and $V_x$ values from Vectornav equations is not explained anywhere. Can someone point me further?&lt;/p&gt;&#xA;" OwnerUserId="584" LastEditorUserId="584" LastEditDate="2013-07-11T19:39:48.763" LastActivityDate="2013-07-11T23:16:47.153" Title="Accelerometer calibration - how to get cross-axis sensitivities" Tags="&lt;sensors&gt;&lt;accelerometer&gt;&lt;calibration&gt;&lt;errors&gt;" AnswerCount="1" CommentCount="2" FavoriteCount="2" />
  <row Id="1580" PostTypeId="2" ParentId="1579" CreationDate="2013-07-11T00:05:28.110" Score="1" Body="&lt;p&gt;OK.  I'm too lazy to read the document, but in general you can model the sensor response as&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$\alpha_m = S \alpha + b$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;where $\alpha$ is the actual acceleration in three dimensions with respect to the accelerometer body (including the acceleration due to gravity), $\alpha_m$ is the measured acceleration from the accelerometer, $b$ is an offset, and $S$ is a $3\times3$ sensitivity matrix.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$S$ and $b$ can be derived from the equations you give in your question above: $S$ is the product of your two $3\times3$ matrices, while $b$ is the product of $S$ and their $B$ and $V$ vectors.  We're all saying the same thing; I'm just compressing the math a bit.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you know $S$, $b$, and $\alpha_m$ then you can solve the above equation for $\alpha$ to get&#xA;$$\hat{\alpha}=S^{-1}\left(\alpha_m - b \right)$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So if you don't assume that $S$ is symmetrical (I don't think it needs to be) then you have 12 unknowns (nine in $S$ and three in $b$).  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you mount your accelerometer into a cube whose sides are more accurate than the calibration you're trying to make, and you set it on a table that is as accurate as the cube, and measure the acceleration at each of the six faces of the cube, then you'll get 18 equations, three for the three axes, times the six faces of the cube.  There should be sufficient information there to extract your 12 unknowns by linear algebra.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Serious aerospace companies do this job with rotary tables, but that gets kinda spendy.&lt;/p&gt;&#xA;" OwnerUserId="1533" LastEditorUserId="1533" LastEditDate="2013-07-11T23:16:47.153" LastActivityDate="2013-07-11T23:16:47.153" CommentCount="3" />
  <row Id="1581" PostTypeId="1" AcceptedAnswerId="1585" CreationDate="2013-07-11T15:19:47.430" Score="2" ViewCount="97" Body="&lt;p&gt;I have a project which requires a robot to move around a room with a flat surface (concrete floor).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The robot must carry a laptop. I estimated that the total weight would be 6-7kg (including motors, battery, laptop, motor controller board and other mics items). I would like it to move at about the same speed as a Roomba moves. The robot will have two motors and a castor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have tried doing the calculation to determine the type of motor to use, but I'm very confused.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can someone advise me on the type of motor and type of battery (Lipo/SLA) to use?&lt;/p&gt;&#xA;" OwnerUserId="1629" LastEditorUserId="177" LastEditDate="2013-07-11T16:09:04.977" LastActivityDate="2013-07-11T23:11:43.363" Title="Choosing motor and battery for a robot" Tags="&lt;motor&gt;&lt;wheeled-robot&gt;&lt;battery&gt;" AnswerCount="1" CommentCount="2" />
  <row Id="1582" PostTypeId="1" AcceptedAnswerId="1588" CreationDate="2013-07-11T18:31:18.143" Score="3" ViewCount="302" Body="&lt;p&gt;I'm starting to attempt to fly FPV on my quadrotor. I am using a FrSky D8R-II 2.4 GHz frequency hopping diversity receiver (two antennas) for control and recently added a &lt;a href=&quot;http://www.readymaderc.com/store/index.php?main_page=product_info&amp;amp;cPath=11_30_31&amp;amp;products_id=348&quot; rel=&quot;nofollow&quot;&gt;no-name 910 MHz 1.5 watt analog video transmitter&lt;/a&gt; for FPV flying:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/UFrHc.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When the video transmitter is powered up, my control range drops from about 1.5km to under 50m. I'm surprised that the 910 MHz video channel affects my 2.4 GHz control channel this way.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is this sort of interference expected? Is it because my transmitter is low quality? What changes are recommended&amp;nbsp;— should I switch to a UHF control radio? Or a different frequency (eg 5.8 GHz?) for the video radio? Or just try moving it a few more inches (they are already about 5in apart)?&lt;/p&gt;&#xA;" OwnerUserId="1473" LastEditorUserId="478" LastEditDate="2014-01-01T14:11:37.897" LastActivityDate="2014-01-01T14:11:37.897" Title="Interference between 900 MHz video transmitter and 2.4 GHz control radio" Tags="&lt;multi-rotor&gt;&lt;fpv&gt;&lt;interference&gt;" AnswerCount="2" CommentCount="5" FavoriteCount="1" />
  <row Id="1584" PostTypeId="1" AcceptedAnswerId="1586" CreationDate="2013-07-11T22:16:02.167" Score="6" ViewCount="168" Body="&lt;p&gt;Our robot has a circular array of 12 sonar sensors that looks like this:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/Q5dBX.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/__31136__ultrasonic_module_hc_sr04_arduino.html&quot;&gt;sonar sensors themselves&lt;/a&gt; are pretty good. We use a low-pass filter to deal with noise, and the readings seem pretty accurate. However, when the robot comes across a flat surface like a wall, something weird happens. The sonars don't show readings that would indicate a wall, instead, it appears like a curved surface. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The plot below was made when the robot was facing a wall. See the curve in the blue lines, as compared to the straight red line. The red line was produced by using a camera to detect the wall, where the blue lines show filtered sonar readings. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/B4KWm.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We believe this error is due to crosstalk, where one sonar sensor's pulse bounces off the wall at an angle and is received by another sensor. This is a systematic error, so we can't really deal with it like we would with noise. Are there any solutions out there to correct for it?&lt;/p&gt;&#xA;" OwnerUserId="181" LastActivityDate="2013-12-31T03:22:58.930" Title="How to deal with sonar crosstalk" Tags="&lt;sonar&gt;&lt;sensor-error&gt;" AnswerCount="3" CommentCount="2" FavoriteCount="1" />
  <row Id="1585" PostTypeId="2" ParentId="1581" CreationDate="2013-07-11T23:11:43.363" Score="1" Body="&lt;p&gt;Roombas move slowly, below a walking pace, right?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If that's so, then you probably want a geared DC motor.  I'm guessing that on concrete you can get away with a motor that's 100W or less, particularly if it's geared down a whole bunch.  You might want to figure out the highest incline or steepest step that you want to negotiate, figure out what force you need to surmount that obstacle, multiply by two, and go from there.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To figure out the gear ratio (or to buy a gearbox-motor combination), decide on a wheel diameter and a top speed.  Then figure out the wheel speed that gets you that top speed.  Then go buy a pair of gear motor that are rated for that RPM as a unit, or select a motor with a known RPM and a gearbox with the right ratio to bring the RPM down.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As far as batteries -- SLA will be way cheaper, LiPo will be more expensive for both batteries and support equipment, but will hold more charge for the weight.  You makes your choice and you pays your money...&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If this is a one-off then just buy a pair of wheel units made for robots.  Whatever you get you're just about guaranteed to be wrong somehow, so the most important thing to do is to start making the mistakes that you'll correct in Robot, Mark II.&lt;/p&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-07-11T23:11:43.363" />
  <row Id="1586" PostTypeId="2" ParentId="1584" CreationDate="2013-07-12T03:06:14.600" Score="8" Body="&lt;p&gt;This is a common problem, and one of a great many.  Acoustic sensing is a complicated field of study, a significant part of which is spent guessing what path a sound wave took between sending it and receiving it.  As you've noticed, assuming that it went straight out and came straight back will produce odd results in practice.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To really solve it, you'll need to use a system that places a unique frequency and/or tone length on each sensor.  This can be taken to significant extremes, &lt;em&gt;e.g.&lt;/em&gt; &lt;a href=&quot;http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&amp;amp;arnumber=4058758&quot;&gt;Frequency-Hopping Pseudo-Random Pulse Width Modulation to Eliminate Crosstalk of Sonar Sensors in Mobile Robots&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is also a low-tech solution, which is fairly straightforward in concept.  If you wanted to simply detect the crosstalk, it would be a matter of firing a single sensor's pulse in between the firing of all sensors' pulses.  If you detect the return pulse with any other sensor, you know that you are in a crosstalk situation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In practice, this is fairly wasteful: notice that this effectively halves the number of samples you can take.  So you can improve on the implementation by dividing the sensors into groups where each member of the group is far enough from the others that it will not receive crosstalk.  The most robust version of this approach is to &lt;a href=&quot;http://www-personal.umich.edu/~johannb/Papers/paper32.pdf&quot;&gt;make the groups themselves be pseudorandom&lt;/a&gt; which not only allows the errors to average out over time but aids the detection of crosstalk on an individual sensor basis.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In your particular case, you have the added benefit of a camera sensor that you've shown is returning a more correct value for the ranges.  Strategies to combine separate (and possibly conflicting) measurements into a single more accurate estimate is its own very broad topic (called &lt;em&gt;fusion&lt;/em&gt;, &lt;a href=&quot;http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;amp;arnumber=363924&quot;&gt;example 1&lt;/a&gt;, &lt;a href=&quot;http://eia.udg.es/~qsalvi/papers/2009-MARTECH.pdf&quot;&gt;example 2&lt;/a&gt;), but a very relevant one to what you're doing here.  &lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-07-12T03:06:14.600" />
  <row Id="1587" PostTypeId="2" ParentId="1584" CreationDate="2013-07-12T17:25:56.687" Score="4" Body="&lt;p&gt;Some sensors, such as the Maxbotix MB1200 XL-MaxSonar-EZ0, have a daisy chaining system built in where one sensor triggers the next sensor once it has finished its measurement. This way you can have N sensors and ensure that only one is firing at once but that there the next sensor fires as soon as the first has collected its return. This solution is simple but obviously greatly reduces the amount of data you get per unit time. Ian's solutions are far closer to optimal.&lt;/p&gt;&#xA;" OwnerUserId="1473" LastActivityDate="2013-07-12T17:25:56.687" />
  <row Id="1588" PostTypeId="2" ParentId="1582" CreationDate="2013-07-12T23:34:04.733" Score="1" Body="&lt;p&gt;There's a lot of things that this could be.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The transmitter could be faulty, and transmitting considerable power close enough to 2.4GHz to be directly interfering with the receiver.  Yes, the receiver is spread-spectrum, but interference to such a receiver will generally raise its noise floor, which will reduce its range.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The receiver could be faulty; it's front end could be getting swamped by the 910MHz.  This would reduce the effective gain of the receiver front end, which would also result in low range.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There's even a slight chance that the problem is neither one, but some other bit of electronics: the 910MHz signal could be getting rectified by some component in a servo or other bit of electronics.  This would generate signal at 1.82GHz, 2.73GHz and more -- that 2.73GHz signal, if it's strong enough, could cause issues with your 2.4GHz receiver.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A rough test of which is which would be to unhook one or the other from the quadcopter, then increase the separation between them while you see how the signal strength, or range, looks on the 2.4GHz receiver.  If the range of the 2.4GHz receiver rises rapidly with separation, or shows some threshold effect where it is low, low, low, HIGH, then there's a good chance that the problem is that the 2.4GHz receiver is allowing itself to be stomped on by the out-of-band energy from the transmitter.  If the range of the 2.4GHz receiver rises gradually and smoothly as you back away from the video transmitter, then the problem could be in either radio but is most likely in the transmitter.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In an ideal world both the receiver and the video transmitters would be inside of metal boxes, with bandpass filters right at the point of entry or exit for the RF signal that only let the correct frequencies through.  Those metal boxes would weigh nothing, of course.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Alas, this is the real world.  I'm not sure if it'd be worthwhile to try the metal box idea -- the required filters are hard to debug without a spectrum analyzer; you can put one together and see if it works, but if it doesn't you still won't know for sure if a filter isn't the answer, or if that particular filter didn't do the job for you.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The (US) Amateur Radio Relay League has a book called the &quot;Radio Interference Handbook&quot;.  The book is aimed at amateur radio operators who are having problems with their neighbors -- but much of what it'll have to say should be pertinent to your case.&lt;/p&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-07-12T23:34:04.733" />
  <row Id="1589" PostTypeId="1" CreationDate="2013-07-13T00:34:59.227" Score="0" ViewCount="49" Body="&lt;p&gt;I want to compute an existence probability of an object in a sensor fusion on the high level (having from each sensor list of objects already filtered with e.g. Kalman Filter).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are these formulae:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$LR(G)_{old} = \frac{p(Ex_{out})_{old}}{1 - p(Ex_{out})_{old}}$$&#xA;$$\alpha = \frac{p(Ex_{in})_{old}}{p(Ex_{in})_{old}*(1 - p(Ex_{in})_{new})}$$&#xA;$$LR(G)_{new} = LR(G)_{old} * \alpha$$&#xA;$$p(Ex_{out})_{new} = \frac{LR(G)_{new}}{1 + LR(G)_{new}}$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Where $p(Ex)$ is the probability of existence and $LR$ is the Likelihood Ratio.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The idea is that $p(Ex)_{in}$ is some probability existence of local object, which was fused into the global $p(Ex_{out})$, and its probability influences that global one.  $old$ would mean values from previous cycle. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;How do you condition that computation to avoid situations of dividing by zero, obtaining &lt;code&gt;NaN&lt;/code&gt;, or &lt;code&gt;Inf&lt;/code&gt;? Also, if $p(Ex_{in})_{new}$ is almost 1, then $\alpha$ will be huge, increasing output, and increasing it enormously in each later cycle, so that the object will live forever. How to prevent it?&lt;/p&gt;&#xA;" OwnerUserId="1633" LastEditorUserId="350" LastEditDate="2013-07-14T00:11:31.880" LastActivityDate="2013-08-13T22:05:15.823" Title="existence probability of an object in fusion" Tags="&lt;sensors&gt;&lt;sensor-fusion&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="1590" PostTypeId="1" CreationDate="2013-07-13T05:14:28.927" Score="2" ViewCount="133" Body="&lt;p&gt;What is the name for the transfer function, GH, in a simple feedback control system like&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$y=\frac{G}{1+GH}u$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What do you call G? What about (G/(1+GH))?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am confused by the fact that that  &quot;open-loop transfer function&quot; and &quot;Loop transfer function&quot; are used to mean GH by different people. Which is academically correct or widely accepted?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are several terms: &quot;closed-loop transfer function&quot;&#xA;&quot;open-loop transfer function&quot;&#xA;&quot;overall transfer function&quot;&#xA;&quot;Loop transfer function&quot;&#xA;&quot;loop gain&quot;&#xA;&quot;loop ratio&quot;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks&lt;/p&gt;&#xA;" OwnerUserId="1634" LastEditorUserId="350" LastEditDate="2013-07-13T19:57:33.583" LastActivityDate="2013-07-16T04:47:00.057" Title="What is the name for the transfer function, GH" Tags="&lt;control&gt;&lt;classical-control&gt;&lt;linear-time-invariant&gt;" AnswerCount="3" CommentCount="1" />
  <row Id="1591" PostTypeId="2" ParentId="1590" CreationDate="2013-07-13T06:21:39.540" Score="2" Body="&lt;p&gt;$GH$ has no special name in and of itself, it is merely a part of the transfer function.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$G$ is the plant/system. It is a mode of the system you want to control.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$y = Gu$ is the open-loop transfer function. It describes how the output of the system changes given a conrol signal $u$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$y = \frac{G}{1+GH}u$ is the closed loop transfer function. It describes how the output of the system changes given a control signal $u$ and some observation model $H$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The phrase &quot;Loop transfer function&quot; is used in contexts where the type of controller (open vs. closed) is not relevant.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A good introductory text to these ideas is the sixth edition of &lt;a href=&quot;http://books.google.com/books?id=gxOLZwEACAAJ&amp;amp;dq=feedback+control+of+dynamic+systems&amp;amp;hl=en&amp;amp;sa=X&amp;amp;ei=gnbjUZXmMsbBigLZ1oEY&amp;amp;ved=0CDUQ6AEwAA&quot; rel=&quot;nofollow&quot;&gt;Feedback Control of Dynamic Systems by Franklin, Powell, and Emami-naeini&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="177" LastEditorUserId="177" LastEditDate="2013-07-15T04:13:38.100" LastActivityDate="2013-07-15T04:13:38.100" CommentCount="7" />
  <row Id="1592" PostTypeId="2" ParentId="1582" CreationDate="2013-07-14T00:57:05.353" Score="1" Body="&lt;p&gt;I hesitated to provide this answer, because I can't find directly relevant articles to back it up.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;It's possible that the video transmitter (even though it's on a separate frequency) is saturating the receiver for the controls.  If this is the case, you'll have to find some way to reduce this.  There are a few possibilites:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Increase the distance between the antennas.  On a quadrotor, this can only be taken so far.&lt;/li&gt;&#xA;&lt;li&gt;Change the distance between the antennas to a 1/2 or 1/4 wavelength of the interfering signal.&lt;/li&gt;&#xA;&lt;li&gt;Change the orientation of the antennas to interfere less &amp;mdash; use a 90&amp;deg; offset.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;In any of these cases, you'll be better off if you can directly measure the interference signal instead of relying on the audible beeps to gauge the signal level.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-07-14T00:57:05.353" CommentCount="2" />
  <row Id="1593" PostTypeId="2" ParentId="1590" CreationDate="2013-07-14T21:08:34.987" Score="0" Body="&lt;p&gt;Both &quot;loop transfer function&quot; and &quot;open loop transfer function&quot; are acceptable terms for $GH$, as are &quot;loop gain&quot; and &quot;loop ratio&quot;.  They all mean much the same thing.  We're humans, we can't always stick to a 1:1 correspondence between the thing and it's name.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Are you sure that you meant $\frac{G}{1+GH}$, or did you mean $\frac{GH}{1+GH}$?  The former is useful in its way, but the latter is so common that I saw what you wrote and mistook it for the common form.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is a complicated subject.  You need a book.  Being naturally modest and retiring, I suggest this one: &lt;a href=&quot;http://www.wescottdesign.com/actfes/actfes.html&quot; rel=&quot;nofollow&quot;&gt;http://www.wescottdesign.com/actfes/actfes.html&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="1533" LastEditorUserId="1533" LastEditDate="2013-07-16T04:47:00.057" LastActivityDate="2013-07-16T04:47:00.057" CommentCount="1" />
  <row Id="1594" PostTypeId="2" ParentId="1589" CreationDate="2013-07-14T21:16:48.477" Score="1" Body="&lt;p&gt;There's not enough information there for me to comment on the validity of your formula.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, if you substitute the first three equations into the last on, you will find two things.&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;the expression will be very messy, and&lt;/li&gt;&#xA;&lt;li&gt;the factors $1 - p\left(Ex_{out}\right)_{old}$ and $1 - p\left(Ex_{in}\right)_{new}$ occur in both the numerator and denominator, and can be canceled out, making the expression more opaque, but numerically more tractable.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-07-14T21:16:48.477" />
  <row Id="1595" PostTypeId="1" CreationDate="2013-07-15T02:13:57.117" Score="3" ViewCount="65" Body="&lt;p&gt;I'm quite new to mechanical engineering and not familiar with gears and motors. A few days ago, I bought a second-hand GWS servo motor for my project, and it didn't include gears.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can someone help me understand the correct measurement of my motor so I can buy the correct &lt;strong&gt;gear&lt;/strong&gt; to fit on my servo motor. Specifically, the measurement of the &lt;strong&gt;gear hole&lt;/strong&gt;:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://oi43.tinypic.com/2ekktw7.jpg&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/fK4KE.jpg&quot; alt=&quot;GWS S35 Continuous rotation servo&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1641" LastEditorUserId="37" LastEditDate="2013-07-15T08:41:36.550" LastActivityDate="2013-07-16T17:36:59.453" Title="measuring gears for servo motors" Tags="&lt;rcservo&gt;" AnswerCount="2" CommentCount="1" />
  <row Id="1596" PostTypeId="2" ParentId="1595" CreationDate="2013-07-15T02:17:38.247" Score="1" Body="&lt;p&gt;That servo already has a gear train inside of it.  It's designed to have an arm attached to that output shaft.  The splines on the shaft need to be matched specifically to the servo arm.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You need to find arms that are meant to fit that servo.  If you can't find them at hobby shops, then try eBay or similar.&lt;/p&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-07-15T02:17:38.247" CommentCount="1" />
  <row Id="1597" PostTypeId="2" ParentId="1590" CreationDate="2013-07-15T04:18:42.193" Score="0" Body="&lt;p&gt;G is the open loop transfer function&lt;/p&gt;&#xA;&#xA;&lt;p&gt;G*H is the loop transfer function. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The closed loop transfer function is the (open loop) / (1 + loop)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Closed-loop_transfer_function&quot; rel=&quot;nofollow&quot;&gt;http://en.wikipedia.org/wiki/Closed-loop_transfer_function&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1642" LastActivityDate="2013-07-15T04:18:42.193" CommentCount="1" />
  <row Id="1598" PostTypeId="1" CreationDate="2013-07-15T14:54:59.060" Score="2" ViewCount="90" Body="&lt;p&gt;I am software engineering student and don't know much about hardware.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I recently have started a project in my AI course. The project is &lt;strong&gt;playing a 3x3 &lt;a href=&quot;http://en.wikipedia.org/wiki/Tic-tac-toe&quot; rel=&quot;nofollow&quot;&gt;tic-tac-toe&lt;/a&gt; game between computer and a human&lt;/strong&gt;. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In a tic-tac-toe board, suppose you play first and you put a cross mark in a certain place.(in &lt;a href=&quot;https://dl.dropboxusercontent.com/u/80047546/tic.png&quot; rel=&quot;nofollow&quot;&gt;tic-tac-toe board&lt;/a&gt; your position is (3,1)).&#xA; Now my computer will take a picture with webcam and analyse this picture with help of Opencv(It is a open source c++ library for image processing. for details opencv.org). After finding the position of your cross mark it will find the optimal position with the help of my algorithm at which it will put a circle. For output it will just speak out the position.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now, I want to make a robotic hand that can draw this circle as output. Would anybody please help me to find the hardware and other materials that needed to make that robotic hand? It will be very helpful if anybody suggest me some tutorials.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I Googled and found many many suggestions, but I am confused about what to choose. &lt;/p&gt;&#xA;" OwnerUserId="1644" LastEditorUserId="1309" LastEditDate="2013-07-17T15:39:36.293" LastActivityDate="2013-07-17T15:39:36.293" Title="Making a robotic arm that can draw a circle" Tags="&lt;robotic-arm&gt;" CommentCount="5" ClosedDate="2013-07-15T19:54:21.310" />
  <row Id="1599" PostTypeId="2" ParentId="1394" CreationDate="2013-07-16T02:18:44.297" Score="0" Body="&lt;p&gt;Hi sorry for being so late.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My OS is Linux Ubuntu 13.04.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I already fix that issue.&#xA;It was weird I just reuse an ROS exemple, readapt it exactly as I did when post that message, and everything worked ...&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thank you for your help&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Jonny&lt;/p&gt;&#xA;" OwnerUserId="1647" LastActivityDate="2013-07-16T02:18:44.297" />
  <row Id="1600" PostTypeId="2" ParentId="873" CreationDate="2013-07-16T07:22:03.817" Score="1" Body="&lt;p&gt;In answer to your q1 Kinect mapping quadcopter has been done:&#xA;&lt;a href=&quot;http://www.engadget.com/2010/12/06/kinect-used-as-a-quadrocopter-radar-video/&quot; rel=&quot;nofollow&quot;&gt;http://www.engadget.com/2010/12/06/kinect-used-as-a-quadrocopter-radar-video/&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In answer to your q2 you can read from some of the online analyses of the project (&lt;a href=&quot;http://aeroquad.com/archive/index.php/t-1503.html?s=eb7c86f8f916e82c4d8bb7476a68f608&quot; rel=&quot;nofollow&quot;&gt;http://aeroquad.com/archive/index.php/t-1503.html?s=eb7c86f8f916e82c4d8bb7476a68f608&lt;/a&gt;) the onboard computer was a 1.6GHz Intel Atom CPU, which is significantly more powerful than arduino.&lt;/p&gt;&#xA;" OwnerUserId="1648" LastActivityDate="2013-07-16T07:22:03.817" />
  <row Id="1601" PostTypeId="1" CreationDate="2013-07-16T11:22:44.243" Score="0" ViewCount="14" Body="&lt;p&gt;I want to give my robot a differential mechanism for the system of turning and steering. Considering the case of turning a right-angled corner, the robot will achieve this by following a gradual circular arc through the intersection while maintaining a steady speed. To accomplish this end, we increase the speed of the outer wheel while slowing that of the inner.&#xA;But supposing i want the turn to be within a definite radius, how do i calculate what ratio the 2 speeds have to be in? Can someone give me an insight into this? Also Im only in the 10th and just doing this as a hobby- so I dont have any knowledge of calculus. Is there an easy way to calculate this? Thanks.&lt;/p&gt;&#xA;" OwnerUserId="1650" LastActivityDate="2013-07-16T11:22:44.243" Title="How to design a differential steering mechanism?" Tags="&lt;mobile-robot&gt;" CommentCount="0" ClosedDate="2013-07-16T13:26:40.570" />
  <row Id="1602" PostTypeId="1" AcceptedAnswerId="1605" CreationDate="2013-07-16T11:26:28.637" Score="1" ViewCount="312" Body="&lt;p&gt;I want to give my robot a differential mechanism for the system of turning and steering. Considering the case of turning a right-angled corner, the robot will achieve this by following a gradual circular arc through the intersection while maintaining a steady speed. To accomplish this end, we increase the speed of the outer wheel while slowing that of the inner. But supposing i want the turn to be within a definite radius, how do i calculate what ratio the 2 speeds have to be in? Can someone give me an insight into this? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What Ive done is this, although I have my doubts.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If the speed of the right wheel is $V_r$ and the speed of the left wheel is $V_l$, then the ratio of their speeds while turning will be equal to the ratio of the circumferences of their corresponding quadrants.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Therefore&lt;/strong&gt;&#xA;$$V_r :V_l =\frac{r+A}{r}$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is this right? I have a sinister feeling Im missing something out..&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/FjWpW.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="1650" OwnerDisplayName="Ghost" LastEditorUserId="350" LastEditDate="2013-07-16T17:43:37.460" LastActivityDate="2013-07-16T18:02:14.867" Title="How to design a differential steering mechanism?" Tags="&lt;kinematics&gt;" AnswerCount="1" CommentCount="1" FavoriteCount="1" />
  <row Id="1603" PostTypeId="1" CreationDate="2013-07-16T13:40:38.343" Score="2" ViewCount="182" Body="&lt;p&gt;I am thinking of creating a robot that can navigate using a map. It is controlled from a PC. An 8-bit controller performs low level tasks and the PC is doing the image processing. I plan to implement it in a single room where the robot is placed and the robot and environment are tracked by a camera from a height or from the ceiling of the room. First, the robot needs to be mapped, like this &lt;a href=&quot;http://www.societyofrobots.com/programming_wavefront.shtml&quot; rel=&quot;nofollow&quot;&gt;http://www.societyofrobots.com/programming_wavefront.shtml&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To do:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Track the robot from some height  using camera Following the&#xA;wavefont algorithim to locate robot and obstacles.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Procedure:&lt;/strong&gt;(just my idea)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The camera will give image of the robot surrounded by obstacles in the random places.&#xA; using some opencv technique draw some grind over the image. &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Locating the  grid which contain  robot(by having some colored&#xA;symbol over the robot) and locating the grids containing the &#xA;obstacle.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Now the grids with obstacle is thought as wall and the remaining is&#xA;the free space for the robot to navigate.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;robot is going to get  the goal place which should be reached is&#xA;given from the pc(may be like point the place to reach in the image&#xA;by mouse click).&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Unknowns&lt;/strong&gt; :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Mapping the room and locating the robot&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;How  to do that? The robot should know where it is in the map or the image. We cannot believe only the camera is enough to locate the robot. So I thought of adding &lt;strong&gt;&lt;em&gt;triangulation&lt;/em&gt;&lt;/strong&gt; mapping like placing two IRs in the room and a receiver in the robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The doubt I have in this is how an IR receiver can know from which direction it is receiving the IR signal (from left or right ). I think it knows only that it receives IR not the direction. Then how is the triangulation going to happen if I don't know the angle and direction?&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;coming to the image processing, how can I implement the Wavefront&#xA;   algorithm(that is capture the live vedio and draw grids over it to&#xA;   find robot and the obstacles)?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;I have HC-05 Bluetooth module, Arduino, Bluetooth dongle, chassis with dc motors and driver, and a dc supply.&lt;/p&gt;&#xA;" OwnerUserId="1622" LastEditorUserId="1309" LastEditDate="2013-07-17T15:34:08.740" LastActivityDate="2013-12-22T19:18:12.373" Title="How to implement the Wavefront algorithm" Tags="&lt;algorithm&gt;&lt;mapping&gt;" AnswerCount="2" CommentCount="3" />
  <row Id="1604" PostTypeId="2" ParentId="1595" CreationDate="2013-07-16T17:36:59.453" Score="1" Body="&lt;p&gt;The output spline is generally proprietary, and will vary by manufacturer.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Measuring the diameter is generally not useful, although counting the teeth can help.  Really all you need to do is type the servo model number into google and see what arms match.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I did the legwork and the S35 uses the futuba spline, so any arm designed for a futuba servo in that size range will fit.&lt;/p&gt;&#xA;" OwnerUserId="65" LastActivityDate="2013-07-16T17:36:59.453" />
  <row Id="1605" PostTypeId="2" ParentId="1602" CreationDate="2013-07-16T18:02:14.867" Score="1" Body="&lt;p&gt;Your intuition is correct.  We can look at the difference in arc length that each wheel will roll for a given &lt;a href=&quot;http://en.wikipedia.org/wiki/Circular_sector&quot; rel=&quot;nofollow&quot;&gt;sector&lt;/a&gt; (specified by $\theta$ in degrees).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$d_l = \frac{\theta*2\pi{r}}{360}$$&#xA;$$d_r = \frac{\theta*2\pi(r+A)}{360}$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This simplifies to:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$ \frac{d_r}{d_l} = \frac{\frac{\theta*2\pi(r+A)}{360}}{\frac{\theta*2\pi{r}}{360}} = \frac{r+A}{r}$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Speed is just distance over time:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$ \frac{V_r}{V_l} = \frac{d_r/t}{d_l/t} = \frac{r+A}{r}$$&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-07-16T18:02:14.867" />
  <row Id="1606" PostTypeId="2" ParentId="1257" CreationDate="2013-07-16T23:51:39.800" Score="1" Body="&lt;p&gt;If someone gets an error relating to missing GLUT_Xmu_LIBRARY stuff after running &quot;cmake ..&quot; using Tom Bamber's instructions just install &quot;sudo apt-get install libxmu-dev libxi-dev&quot; and then cmake should work now.&lt;/p&gt;&#xA;" OwnerUserId="1655" LastActivityDate="2013-07-16T23:51:39.800" />
  <row Id="1607" PostTypeId="1" AcceptedAnswerId="1608" CreationDate="2013-07-16T17:57:51.097" Score="3" ViewCount="99" Body="&lt;p&gt;I'm moving from controlling a robot arm with basic time based motors controlled using a raspberry pi and python to a more advanced robotic arm that has servos (e.g &lt;a href=&quot;http://dlnmh9ip6v2uc.cloudfront.net/datasheets/Robotics/Hitec-HS-425BB-Servo-Specsheet.pdf&quot; rel=&quot;nofollow&quot;&gt;HS-425BB&lt;/a&gt;). With the time based motors I must constantly keep track of the arms position (guess work) and make sure it doesn't over turn.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Do servos automatically stop if you give them a position that is outside of their boundaries rather than grinding the gears?&lt;/p&gt;&#xA;" OwnerUserId="1682" OwnerDisplayName="GreenGiant" LastEditorUserId="187" LastEditDate="2014-01-03T04:15:23.060" LastActivityDate="2014-01-08T13:28:27.563" Title="Do servos stop at their limits automatically?" Tags="&lt;rcservo&gt;" AnswerCount="3" />
  <row Id="1608" PostTypeId="2" ParentId="1607" CreationDate="2013-07-16T18:02:14.317" Score="2" Body="&lt;p&gt;Most PWM servos (including the one you indicated, the HS-425BB) do stop at their limits automatically. This can be useful for initial calibration as it allows you to move the servo to a known point.&lt;/p&gt;&#xA;" OwnerDisplayName="quinxorin" LastActivityDate="2013-07-16T18:02:14.317" CommentCount="1" />
  <row Id="1609" PostTypeId="2" ParentId="1607" CreationDate="2013-07-16T18:07:13.490" Score="1" Body="&lt;p&gt;In general, servos don't stop unless you command them to (remove power). I'm not familiar with this model and the spec sheet is not clear.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;hope you get a better answer soon.&lt;/p&gt;&#xA;" OwnerDisplayName="edprochak" LastActivityDate="2013-07-16T18:07:13.490" />
  <row Id="1610" PostTypeId="1" CreationDate="2013-07-17T00:50:36.413" Score="1" ViewCount="122" Body="&lt;p&gt;I'm a newbie to Electronics/ Robotics, but I love to do it as a hobby. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So I want to build a circuit (a really small in size would be much better) with a motion sensor that can communicate data (Basically when it sense a motion send a signal) to my computer over Wifi. Is this something possible? &#xA;If so how do I do it, may be a schematics diagram, or someway to start the project would be a grate help.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thank you!!  &lt;/p&gt;&#xA;" OwnerUserId="1616" LastEditorUserId="1616" LastEditDate="2013-07-17T00:58:24.587" LastActivityDate="2013-07-17T00:58:24.587" Title="How to make a motion sensor circuit, that can communicate with my LAN?" Tags="&lt;sensors&gt;&lt;wifi&gt;&lt;communication&gt;&lt;circuit&gt;" CommentCount="8" ClosedDate="2013-07-22T10:57:48.053" />
  <row Id="1611" PostTypeId="5" CreationDate="2013-07-17T12:53:16.637" Score="0" ViewCount="2" Body="&lt;p&gt;Any device with electrical circuits.&lt;/p&gt;&#xA;" OwnerUserId="1309" LastEditorUserId="1309" LastEditDate="2013-07-17T15:38:46.337" LastActivityDate="2013-07-17T15:38:46.337" />
  <row Id="1612" PostTypeId="4" CreationDate="2013-07-17T12:53:16.637" Score="0" Body="Any device with electrical circuits." OwnerUserId="1309" LastEditorUserId="1309" LastEditDate="2013-07-17T15:39:04.243" LastActivityDate="2013-07-17T15:39:04.243" />
  <row Id="1613" PostTypeId="1" CreationDate="2013-07-17T15:23:10.513" Score="1" ViewCount="109" Body="&lt;p&gt;I am building a 2 wheel robot to carry 7KG of load. I used this &lt;a href=&quot;http://www.robotshop.com/dc-motor-selection.html?lang=en-us&quot; rel=&quot;nofollow&quot;&gt;link&lt;/a&gt; to get the torque required for each motor which is &lt;strong&gt;11Kg-cm&lt;/strong&gt;. So I choose 2 of these &lt;a href=&quot;http://www.robot-r-us.com/motor-brushed/planetary-gearhead-motor-12v-13.71-with-encoder.html&quot; rel=&quot;nofollow&quot;&gt;motor&lt;/a&gt; which has &lt;strong&gt;36Kg-cm&lt;/strong&gt;(2x more) torque. I noticed that the stall current is 14A. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can I use Adafruit Motor Shield for Arduino which is rated 3A peak current capability?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If not what current rating driver should look into?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks!!&lt;/p&gt;&#xA;" OwnerUserId="1662" LastActivityDate="2013-08-27T18:50:40.910" Title="Motor driver selection" Tags="&lt;motor&gt;&lt;driver&gt;&lt;current&gt;" AnswerCount="2" CommentCount="4" />
  <row Id="1614" PostTypeId="1" AcceptedAnswerId="1691" CreationDate="2013-07-17T16:50:15.297" Score="2" ViewCount="243" Body="&lt;p&gt;We are using &lt;a href=&quot;http://code.google.com/p/ardu-imu/&quot; rel=&quot;nofollow&quot;&gt;ArduIMU (V3)&lt;/a&gt; as our Quadrotor's inertial measurement unit. (we have a separate board to control all motors, not with ArduIMU itself). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now we have a problem with ArduIMU's sensors output. When we put our quadrotor steady on the ground with motors on, instead of getting 0 degree in roll and pitch we have a noisy output something like the image below( -6 to 6 degree error ):&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/cd62D.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;delta_t = 0.2s&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We are sure that this isn't a mechanical problem, because we checked the mechanical joints and everything.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I should mention that with motors off everything is going well. Also we checked that if we vibrate the device slowly on yaw axis or any other axis, it still shows the noisy output.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We are using DCM filter inside ArduIMU, also we tested with Kalman filter but no difference.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We also tested FRI low-pass filter, results is good but there is about 3 seconds delay in the output.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We also checked that if we separate the ArduImu's power from our circuit, it still no difference.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What's the problem with ArduIMU and how we can get rid off this noisy output ?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; &#xA;We think that the problem with our PID controller is because of these noises ... Is this a true assumption ? We can't tune our PID parameters ( using Ziegler–Nichols method ) when we have noisy data. We tested Ziegler–Nichols method when we have low rate noises and we successfully tuned our PID but when noise appears we are unable to tune PIDs. Is there anyway for us for tuning our PID in such situation ? Is this problem is because of the noises or the PID itself can get rid of them ?&lt;/p&gt;&#xA;" OwnerUserId="1137" LastEditorUserId="1137" LastEditDate="2013-07-19T06:10:48.373" LastActivityDate="2013-08-01T16:18:15.533" Title="ArduIMU noisy output in Quadrotor" Tags="&lt;arduino&gt;&lt;quadcopter&gt;&lt;quadrotor&gt;&lt;noise&gt;&lt;ardupilot&gt;" AnswerCount="2" CommentCount="18" />
  <row Id="1615" PostTypeId="1" CreationDate="2013-07-17T18:15:40.580" Score="5" ViewCount="110" Body="&lt;p&gt;I was at a Robotics conference earlier today and one of the speakers mentioned robots not being able to function as well in a crowd because they can't single out audio like a person can.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Why can people single out audio so well?  And what would it take for a robot to do the same?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm aware of Active Noise Reduction (ANR) like on Bose Aviation headset, but that is not what I'm talking about.  I am thinking about the ability to take everything in but process only what you feel is important. &lt;/p&gt;&#xA;" OwnerUserId="1663" LastActivityDate="2013-07-22T19:39:31.133" Title="Why can Humans single out audio in a crowd? What would it take for a robot to do the same?" Tags="&lt;artificial-intelligence&gt;" AnswerCount="2" />
  <row Id="1616" PostTypeId="2" ParentId="1615" CreationDate="2013-07-17T19:55:10.570" Score="2" Body="&lt;p&gt;I think there are at least three things going on:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Filtering that is dependant on the location the sound is coming from.  Our stereo hearing combined with certain attributes of how our ears are built helps us isolate sound coming from a particular location/direction.&lt;/li&gt;&#xA;&lt;li&gt;Filtering that is dependant on the frequency/amplitude of the audio.&lt;/li&gt;&#xA;&lt;li&gt;The redundancy in the audio allows us to reconstruct the input.  If multiple people are speaking over each other (or generally in the presence of noise) we only need to catch a fraction of what's being said (or sometimes even observe visually) to know what is being said.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;I would think that a robot can outperform humans on #1 and #2.  With a microphone array one would think you could effectively focus on a single point in space and eliminate all other interference.  That may be made more complicated by reflections and various other disturbances.  #3 is probably something that is harder for computers to do.&lt;/p&gt;&#xA;" OwnerUserId="1584" LastActivityDate="2013-07-17T19:55:10.570" CommentCount="1" />
  <row Id="1617" PostTypeId="2" ParentId="1613" CreationDate="2013-07-17T20:41:19.767" Score="1" Body="&lt;p&gt;The Adafruit Motor Shield for Arduino should work, if two conditions are satisfied:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;the Adafruit Motor Shield for Arduino can limit its own current, or there's enough data available so that you can.&lt;/li&gt;&#xA;&lt;li&gt;the motor you want to use can generate sufficient torque on 3 amps&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;The answer to (1) should come from the data for the Adafruit Motor Shield for Arduino.  The answer to (2) should come from the motor data (look for the motor torque constant.  It should be in (torque units)/(amp).  Given what the motor uses for torque units, it'll probably be in kg-cm/amp, however improper those units may be as a measure of torque.  Multiply that torque constant by 3A, and you have your answer for the motor.&lt;/p&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-07-17T20:41:19.767" CommentCount="1" />
  <row Id="1618" PostTypeId="1" AcceptedAnswerId="1621" CreationDate="2013-07-18T02:34:04.530" Score="2" ViewCount="243" Body="&lt;p&gt;What is the minimum amount of power that a beaglebone needs to start up? This would be with no   peripherals attached besides host usb. The getting started guide claims that it can run off of a computer's usb power, but makes no mention of how many amps are actually needed. I saw a mention of older kernels limiting current draw to .5 amps when working off of usb, although that was all I could find. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Could one start a BeagleBone Black off of .3 amps? If not, how many?&lt;/p&gt;&#xA;" OwnerUserId="1667" LastActivityDate="2013-07-18T11:05:11.023" Title="Beaglebone Black power draw" Tags="&lt;microcontroller&gt;" AnswerCount="1" ClosedDate="2013-07-18T12:47:07.873" />
  <row Id="1619" PostTypeId="2" ParentId="1607" CreationDate="2013-07-18T04:42:58.463" Score="4" Body="&lt;p&gt;I have worked with quite a few servos (Industrial and RC) and from my experience they don't come with a limit switch that actually takes the current off the motor when they hit a limit. They are however limited in rotation by the PWM signal you send them and are as such limited to a rotation safe area. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;It does become a bit more complicated when you link several servos into a robot arm as there is a chance that individual arm segments might hit each other or the ground or... . &lt;/p&gt;&#xA;&#xA;&lt;p&gt;For a reference feedback i recommend measuring the internal voltage over the servo reference potentiometer as outlined in the following link:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://forums.trossenrobotics.com/tutorials/how-to-diy-128/get-position-feedback-from-a-standard-hobby-servo-3279/&quot; rel=&quot;nofollow&quot;&gt;http://forums.trossenrobotics.com/tutorials/how-to-diy-128/get-position-feedback-from-a-standard-hobby-servo-3279/&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This analog voltage gives you an indication of the actual servo position. This voltage can be sampled from eg. an Arduino board or any other board with an analog/digital converter.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have done something similar with a hexapod robot, and it worked perfectly.&lt;/p&gt;&#xA;" OwnerUserId="1670" LastEditorUserId="2447" LastEditDate="2014-01-08T13:28:27.563" LastActivityDate="2014-01-08T13:28:27.563" CommentCount="1" />
  <row Id="1620" PostTypeId="2" ParentId="1613" CreationDate="2013-07-18T10:58:05.790" Score="0" Body="&lt;p&gt;You could use it, but that would mean you will have to limit your power supply &lt;strong&gt;&lt;em&gt;a lot&lt;/em&gt;&lt;/strong&gt;. When your robot starts up, it will need a serious amount of power for the time it takes to accelerate, if you have a power supply of 12V, you will probably immediately burn out the motor driver you mentioned.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A motor driver that would work (from Sparkfun, I couldn't find a high power motor driver at Adafruit) is &lt;a href=&quot;https://www.sparkfun.com/products/10182&quot; rel=&quot;nofollow&quot;&gt;this shield&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;That said, you could use these motors, with the shield you mentioned, but you will have to limit your power supply, and that is going to cost you: speed, acceleration, torque and a big headache. You are way better off getting a higher power shield.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am in no way affiliated with Sparkfun, I just knew they had a shield that will suit your needs.&lt;/p&gt;&#xA;" OwnerUserId="1520" LastEditorUserId="350" LastEditDate="2013-08-27T18:50:40.910" LastActivityDate="2013-08-27T18:50:40.910" />
  <row Id="1621" PostTypeId="2" ParentId="1618" CreationDate="2013-07-18T11:05:11.023" Score="0" Body="&lt;p&gt;If the getting started guide claims you can run it of a computers USB port, it will work at about .5 amps. A normal computer power supply limits the current to a USB port to .5 amps. Doing some research on the Beaglebone Black's site &lt;a href=&quot;http://beagleboard.org/Support/FAQ&quot; rel=&quot;nofollow&quot;&gt;http://beagleboard.org/Support/FAQ&lt;/a&gt;, I found this:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;When powered up over USB, the regulators are somewhat limited in what they can supply the system. Power over USB is sufficient as long as the software and system running perform some management to keep it under the USB current limit threshold.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;and&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;The recommended supply current is at least 1.2A (or 6W), but at least 2A (or 10W) is recommended if you are going to connect up anything over the USB. The actual power consumption will vary greatly with changes on the USB load.&lt;/em&gt; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So it seems like the .5 amps from the computers USB port, is about as low as it gets.  &lt;/p&gt;&#xA;" OwnerUserId="1520" LastActivityDate="2013-07-18T11:05:11.023" CommentCount="1" />
  <row Id="1622" PostTypeId="1" AcceptedAnswerId="1624" CreationDate="2013-07-18T02:20:07.367" Score="5" ViewCount="216" Body="&lt;p&gt;How would you motorize the joints in an Iron Man suit? You need something fairly shallow, I would think, probably dual servos sitting on either side of an elbow or knee joint or either side of your hips, but how do you get motorized action there without dramatically adding to the thickness of the joint? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Bicycle-style chain drives wouldn't work, I would think, since the length of the chain would need to vary depending on what position you're in for at least a lot of joints.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How would you motorize the joints?&lt;/p&gt;&#xA;" OwnerUserId="1676" OwnerDisplayName="Erik  Reppen" LastEditorUserId="350" LastEditDate="2013-07-18T18:10:51.003" LastActivityDate="2013-07-19T07:29:46.483" Title="How do I motorize the elbow socket and other joints in a powered exo-skeleton?" Tags="&lt;design&gt;&lt;mechanism&gt;" AnswerCount="2" CommentCount="13" />
  <row Id="1623" PostTypeId="2" ParentId="1622" CreationDate="2013-07-18T03:32:12.027" Score="3" Body="&lt;p&gt;Erik, your wish is my command:   &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&quot;High torque pancake stepper motor&quot; comes to mind. Can you develop one, and a couple of extra's? :)  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Seriously, you're looking at a combination of technologies and disciplines.  Precision positioning of a &quot;High torque pancake stepper motor&quot; might be an acceptable direction, but it'll probably end up simply being the driver behind Nick Alexeev's (Terminator) hydraulics, after all, the back-hoe surely has its place in &quot;motive amplification,&quot; if I may use the term sloppily. :) &lt;/p&gt;&#xA;" OwnerUserId="1625" OwnerDisplayName="JoeFromOzarks" LastActivityDate="2013-07-18T03:32:12.027" CommentCount="2" />
  <row Id="1624" PostTypeId="2" ParentId="1622" CreationDate="2013-07-18T06:47:17.703" Score="7" Body="&lt;p&gt;Addressing the &lt;strong&gt;shoulder joint&lt;/strong&gt;, which is rather more complicated than elbows and knees... After this one, the other joints become far simpler to visualize or engineer.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Here is how the ball and socket shoulder joint could work:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/EDy5z.jpg&quot; alt=&quot;Shoulder Joint&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Freedom of movement: Approximately 60 degrees end to end, all around. Less than for humans, but it can be tweaked to around 80 degrees without difficulty just by making the half-torus narrower.&lt;/li&gt;&#xA;&lt;li&gt;The static half-torus (shown in shiny steel here) is for strength, and would be joined to the torso exoskeleton by a rigid set of struts. Half torus = torus with an inner coaxial cylinder excised, tentative diameter of cylindrical hole 145 mm.&lt;/li&gt;&#xA;&lt;li&gt;The inner blued-steel hollow sphere is where the arm goes through, just beyond the actual shoulder. Tentative diameter of sphere 138mm, diameter of inner cylindrical hole 100 mm.&lt;/li&gt;&#xA;&lt;li&gt;Rings of little stepper motors on both front and hidden edges of half-torus, gripping inner hollow sphere. &lt;/li&gt;&#xA;&lt;li&gt;Stepper motors have outer ring rotor, inner stator, and rubberized omniwheel &quot;teeth&quot; to move the inner sphere.&lt;/li&gt;&#xA;&lt;li&gt;Inner sphere will of course be attached to a rigid exoskeleton matching the upper arm dimensions, up to the elbow joint. &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;This is how the motors act upon the inner sphere, close up:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/qKl4e.jpg&quot; alt=&quot;Close-up of joint&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is how each omniwheel stepper motor will work:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/JI2KQ.jpg&quot; alt=&quot;Omniwheel Stepper&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The omniwheel design is required for the teeth to allow frictionless motion axial to the rotation direction.&lt;/p&gt;&#xA;" OwnerUserId="109" OwnerDisplayName="Anindo Ghosh" LastEditorUserId="109" LastEditDate="2013-07-19T07:29:46.483" LastActivityDate="2013-07-19T07:29:46.483" CommentCount="7" />
  <row Id="1625" PostTypeId="2" ParentId="1615" CreationDate="2013-07-18T18:26:20.893" Score="7" Body="&lt;p&gt;What the speaker said at the conference was not accurate.  Perhaps they meant &quot;&lt;em&gt;our robot&lt;/em&gt; can't single out audio like a person can&quot;, but the statement &quot;[robots] can't single out audio like a person can&quot; is false.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here is a partial list of systems that can determine the source of an audio signal, and track it:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Conference phones (and many cell phones), with technique(s) described in papers &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.43.139&quot; rel=&quot;nofollow&quot;&gt;this one&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Gunfire_locator&quot; rel=&quot;nofollow&quot;&gt;Gunfire locators&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Underwater robots with towed microphone arrays, e.g. &lt;a href=&quot;http://acoustics.mit.edu/faculty/henrik/LAMSS/Pubs/poulsen_eickstedt_oceans06.pdf&quot; rel=&quot;nofollow&quot;&gt;the AUV described in this paper&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.fer.unizg.hr/_download/repository/kvalifikacijski_IvanMarkovic.pdf&quot; rel=&quot;nofollow&quot;&gt;Mobile land-based robots&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The term you're looking for is a &quot;phased array&quot; of microphones (see also: &lt;a href=&quot;http://www.mathworks.com/products/phased-array/examples.html?file=%2Fproducts%2Fdemos%2Fshipping%2Fphased%2Fmicrophonebeamformerdemo.html&quot; rel=&quot;nofollow&quot;&gt;Matlab phased array toolbox&lt;/a&gt;).  NASA uses phased arrays to &lt;a href=&quot;http://www.grc.nasa.gov/WWW/Acoustics/testing/instrumentation/arraymic.htm&quot; rel=&quot;nofollow&quot;&gt;localize the noise coming from spinning rotor fan blades&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-07-22T19:39:31.133" LastActivityDate="2013-07-22T19:39:31.133" CommentCount="5" />
  <row Id="1626" PostTypeId="2" ParentId="1614" CreationDate="2013-07-18T20:06:47.443" Score="3" Body="&lt;p&gt;&lt;strong&gt;This answer is incorrect (TaW)&lt;/strong&gt; It is based on IMU noise that's about 1000 times faster than it really is, based on a typo in the discussion following the original question.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm not a big fan of the Ziegler-Nichols method.  It's an ad-hoc method that is not only not guaranteed to stabilize all plants, it comes with a guarantee that there will be some plants that it cannot stabilize.  Furthermore, it has a history of coughing up an underdamped system.  Its only advantage seems to be that it comes up often in web searches.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would suspend the copter on one of the horizontal axes, parallel to the IMU, and I would tune the PID controller using the usual seat of the pants method (derivative, then proportional, then integral).  Then I'd go back and measure the frequency response of the thing (still tethered), and tune the PID properly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then I would repeat for the vertical axis.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Only then would I cross my fingers, hold my breath, and go fly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For some reason, I seem to think that this is a good description of the seat of the pants PID tuning method:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.embedded.com/design/prototyping-and-development/4211211/PID-without-a-PhD&quot; rel=&quot;nofollow&quot;&gt;http://www.embedded.com/design/prototyping-and-development/4211211/PID-without-a-PhD&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;With that much noise in the IMU output would bandlimit my differentiator.  That'll limit the bandwidth of your control loop, but if you don't do it then your differentiator will swamp out any other control signals.&lt;/p&gt;&#xA;" OwnerUserId="1533" LastEditorUserId="1533" LastEditDate="2013-07-20T05:02:15.110" LastActivityDate="2013-07-20T05:02:15.110" CommentCount="1" />
  <row Id="1627" PostTypeId="1" AcceptedAnswerId="1629" CreationDate="2013-07-18T21:37:55.480" Score="4" ViewCount="814" Body="&lt;p&gt;I've been thinking about starting a quadcopter project, maybe building it from scratch. One of the main barriers-to-entry for me is the motors: it seems like most quadcopters use brushless motors. I have some experience with DC motors and using PWM signals to regulate speed, but no experience with brushless motors. As I understand it, brushless motors are more expensive than the typical DC motor I would use on a land robot, and they also require electronic speed controllers (ESCs), which seem to make them (from my perspective) even more expensive and more complicated to use.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, my question: what is it about brushless motors that make them useful in a quadcopter? Is it more torque, less weight, something to do with efficiency? And would it be significantly harder (or even possible) to achieve lift using DC motors instead? &lt;/p&gt;&#xA;" OwnerUserId="181" LastActivityDate="2013-07-19T11:26:56.230" Title="Why do quadcopters use brushless motors" Tags="&lt;quadcopter&gt;&lt;brushless-motor&gt;" AnswerCount="2" FavoriteCount="1" />
  <row Id="1628" PostTypeId="2" ParentId="1627" CreationDate="2013-07-18T22:13:09.930" Score="3" Body="&lt;p&gt;The brushless motors are way more powerful for their weight than available brushed motors, and they last longer.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Power to weight ratio is king, in an aircraft.&lt;/p&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-07-18T22:13:09.930" />
  <row Id="1629" PostTypeId="2" ParentId="1627" CreationDate="2013-07-19T11:26:56.230" Score="6" Body="&lt;p&gt;Most motors on quadcopters are outrunners. In outrunner motors, the rotating part is on the outside, and not the inside (as opposed to the inrunner motors). Because of this layout this type of motors can generate much more torque. High torque is required for quadcopters, since you balance by changing the revolutions of the motor. The higher your torque the faster you can change the speed of your propellers. High torque also means you don't need a gearbox, and save a lot of mass. Outrunners are not very practical for brushed commutation, as it would require lots of wires and additional contacts. Hence most of the outrunners are brushless.&lt;/p&gt;&#xA;" OwnerUserId="127" LastActivityDate="2013-07-19T11:26:56.230" />
  <row Id="1630" PostTypeId="1" AcceptedAnswerId="1632" CreationDate="2013-07-19T19:14:17.173" Score="2" ViewCount="137" Body="&lt;p&gt;I have some crude time based motors taken from a robot arm that we upgraded to proper servos. I want to be able to power a conveyor belt with one of them and I was wondering how I would go about the following setup:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A ball drops through a hole onto the conveyer belt hitting a lever switch on its way through. This switch triggers the motor to start. When the ball gets to the top of the belt and falls off it hits another lever switch that turns the motor off.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I could handle this logic by hooking it up to my raspberry pi and using python to start and stop the motor depending on which GPIO pin received input (top or bottom lever). Or I could use a single lever and set a constant time interval to stop the motor. I would prefer to use both to handle any change in scale/construction.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I was wondering however if this could be done with the breadboard alone, using logic gates or similar?&lt;/p&gt;&#xA;" OwnerUserId="1682" LastEditorUserId="1429" LastEditDate="2013-09-15T10:28:45.957" LastActivityDate="2013-09-15T10:28:45.957" Title="Controlling a conveyor belt with a time based motor" Tags="&lt;motor&gt;&lt;raspberry-pi&gt;" AnswerCount="1" />
  <row Id="1631" PostTypeId="2" ParentId="1025" CreationDate="2013-07-19T19:48:25.337" Score="1" Body="&lt;p&gt;First of all, I know this is not an answer, however since I am a new user I cannot comment on Preetham's question.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have a very similar problem, however, when I first run roswtf, I get no errors but when I wait a bit after using rviz or trying to record a bagfile, the openni.launch terminal itself gives me this error:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;terminate called after throwing an instance of 'openni_wrapper::OpenNIException'&#xA;  what():  virtual void openni_wrapper::OpenNIDevice::startImageStream() @ /tmp/buildd/ros-groovy-openni-camera-1.8.8-0precise-20130418-2203/src/openni_device.cpp @ 224 : starting image stream failed. Reason: Xiron OS got an event timeout!&#xA;[camera_nodelet_manager-2] process has died [pid 3788, exit code -6, cmd /opt/ros/groovy/lib/nodelet/nodelet manager __name:=camera_nodelet_manager __log:=/home/rosbotics/.ros/log/16b63744-e043-11e2-ac16-080027486aa8/camera_nodelet_manager-2.log].&#xA;log file: /home/rosbotics/.ros/log/16b63744-e043-11e2-ac16-080027486aa8/camera_nodelet_manager-2*.log&lt;/p&gt;&#xA;&#xA;&lt;p&gt;and roswtf  displays:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;unknown network error contacting node: timed out&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Warning These nodes have died:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;camera_nodelet_manager-2&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;found 2 errors&lt;/p&gt;&#xA;&#xA;&lt;p&gt;ERROR The following nodes should be connected but aren't:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;/camera_base_link1-&gt;/camera_nodelet_manager (/tf)&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;/camera_base_link-&gt;/camera_nodelet_manager (/tf)&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;/camera_base_link3-&gt;/camera_nodelet_manager (/tf)&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;/camera_base_link2-&gt;/camera_nodelet_manager (/tf)&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;ERROR Errors connecting to the following services: (then it displays a lot of services)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;At first After looking around a bit I thought it was a problem with openni and tried using freenect instead, however that too gave a black screen. Then I tried using something completely unrelated to ros, freenect-glview, however that too gave me a black screen.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;lsusb shows that all 3 parts of the kinect are connected and I've been able to control the kinect's motor through ubuntu so I know that there is at least a connection established between both.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am using ubuntu 12.04 and ROS-Groovy.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would appreciate anyone's help on the matter.&lt;/p&gt;&#xA;" OwnerUserId="1681" LastActivityDate="2013-07-19T19:48:25.337" CommentCount="1" />
  <row Id="1632" PostTypeId="2" ParentId="1630" CreationDate="2013-07-19T21:14:34.010" Score="0" Body="&lt;p&gt;To control the motor with logic gates, you could make a circuit with a monostable multivibrator (or  “one-shot”), an R-S flipflop (or R-S latch), and an AND gate or an OR gate to combine the one-shot and latch outputs.  You would use an AND if you want the motor to run when both the latch and the one-shot are active, &lt;em&gt;vs&lt;/em&gt; an OR to make the motor run when either of them is active.  Whether to use AND or OR depends on what error conditions you want to detect or handle.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;An &lt;a href=&quot;http://en.wikibooks.org/wiki/Electronics/Flip_Flops#RS_Flip_Flop&quot; rel=&quot;nofollow&quot;&gt;R-S flipflop&lt;/a&gt; is easily made using two NAND gates, &lt;em&gt;ie&lt;/em&gt; half of the gates in the quad NAND 74LS00.  A one-shot also can be made &lt;a href=&quot;http://www.electronics-tutorials.ws/sequential/seq_3.html&quot; rel=&quot;nofollow&quot;&gt;using  two NANDs&lt;/a&gt; (see “Simple NAND Gate Monostable Circuit” at about 1/3 thru page), or you can use a 74121, 74221, etc.  The 555 also is often used as a &lt;a href=&quot;http://www.circuitstoday.com/555-timer-as-monostable-multivibrator&quot; rel=&quot;nofollow&quot;&gt;monostable multivibrator&lt;/a&gt;, and can also be &lt;a href=&quot;http://www.edaboard.com/thread142724.html&quot; rel=&quot;nofollow&quot;&gt;used as an R-S flipflop&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, you could use two 7400 packages for the circuit, or could use one 7400 and one 556 (which is a dual 555).  Circuits with NAND gates can be simulated by hand or in &lt;a href=&quot;http://www.neuroproductions.be/logic-lab/&quot; rel=&quot;nofollow&quot;&gt;online simulators&lt;/a&gt;. &lt;a href=&quot;https://www.circuitlab.com/circuit/e38756/555-timer-as-astable-multivibrator-oscillator/&quot; rel=&quot;nofollow&quot;&gt;Some simulators&lt;/a&gt; also simulate 555's.&lt;/p&gt;&#xA;" OwnerUserId="478" LastActivityDate="2013-07-19T21:14:34.010" CommentCount="1" />
  <row Id="1633" PostTypeId="1" AcceptedAnswerId="1643" CreationDate="2013-07-19T22:01:54.720" Score="4" ViewCount="195" Body="&lt;p&gt;Whenever I try using &lt;code&gt;openni_launch&lt;/code&gt;, it works normally, however, when I try viewing an image using the kinect's rgb or depth camera, or even recording a simple &lt;code&gt;bagfile&lt;/code&gt; with data from the kinect, I am unable to see any picture and &lt;code&gt;rosbag&lt;/code&gt; does not record any data, and after a few seconds of running &lt;code&gt;image_view&lt;/code&gt; or &lt;code&gt;rosbag record&lt;/code&gt;, I got this error:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;terminate called after throwing an instance of 'openni_wrapper::OpenNIException'&#xA;  what():  virtual void openni_wrapper::OpenNIDevice::startImageStream() @ /tmp/buildd/ros-groovy-openni-camera-1.8.8-0precise-20130418-2203/src/openni_device.cpp @ 224 : starting image stream failed. Reason: Xiron OS got an event timeout!&#xA;[camera_nodelet_manager-2] process has died [pid 3788, exit code -6, cmd /opt/ros/groovy/lib/nodelet/nodelet manager __name:=camera_nodelet_manager __log:=/home/rosbotics/.ros/log/16b63744-e043-11e2-ac16-080027486aa8/camera_nodelet_manager-2.log].&#xA;log file: /home/rosbotics/.ros/log/16b63744-e043-11e2-ac16-080027486aa8/camera_nodelet_manager-2*.log&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;After searching around and trying various fixes, I figured it might be a problem with openni and started using freenect, however I encountered the same problems, I could not record any data using bagfiles or see any images from the kinect (using &lt;code&gt;rviz&lt;/code&gt; or &lt;code&gt;image_view&lt;/code&gt;)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then someone asked me to use something completely unrelated, &lt;code&gt;freenect-glview&lt;/code&gt;, however that too gave me a black screen.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;lsusb&lt;/code&gt; shows that all 3 parts of the kinect are connected and I've been able to control the kinect's motor through ubuntu so I know that there is at least a connection established between both.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Additional Info:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;I run ROS on Ubuntu using VirtualBox V.4.2.14 and Windows 7 with USB 2 ports&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;I am using ubuntu 12.04 and ROS-Groovy (all up to date)&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;I've had the exact same errors on my Mac OSX Lion&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;When I try using Rviz with the kinect, VirtualBox crashes all together&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;I would appreciate anyone's help on the matter.&lt;/p&gt;&#xA;" OwnerUserId="1681" LastEditorUserId="37" LastEditDate="2013-07-20T18:49:13.420" LastActivityDate="2013-07-22T22:10:46.177" Title="How can I get data from my kinect?" Tags="&lt;ros&gt;&lt;kinect&gt;" AnswerCount="1" />
  <row Id="1634" PostTypeId="1" CreationDate="2013-07-20T15:49:55.773" Score="1" ViewCount="68" Body="&lt;p&gt;Im designing a differential steering mechanism for my robot. Supposing my robot is going in a straight line and I want it to change it direction by a certain angle( $θ$ in the diagram). What should the velocity ratio be of the 2 wheels so that it gradually turns and starts moving along a line that is $θ$ degrees to the initial line of movement?&#xA;If there's any ambiguity in the question please take a look at my earlier question which is similar. &lt;a href=&quot;http://robotics.stackexchange.com/questions/1602/how-to-design-a-differential-steering-mechanism&quot;&gt;How to design a differential steering mechanism?&lt;/a&gt;&#xA;&lt;img src=&quot;http://i.stack.imgur.com/a0vKQ.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="1650" LastActivityDate="2013-07-20T20:59:55.350" Title="How to control velocity ratio when turning angle is θ?" Tags="&lt;kinematics&gt;" AnswerCount="1" CommentCount="7" />
  <row Id="1635" PostTypeId="2" ParentId="1634" CreationDate="2013-07-20T20:59:55.350" Score="1" Body="&lt;p&gt;In your &lt;a href=&quot;http://robotics.stackexchange.com/q/1602/350&quot;&gt;previous question&lt;/a&gt;, we calculated the &lt;s&gt;velocity&lt;/s&gt; speed ratio that would be required to make a turn of a given radius.  I'm going to reuse those formulas with &lt;em&gt;inner&lt;/em&gt; and &lt;em&gt;outer&lt;/em&gt; replacing &lt;em&gt;left&lt;/em&gt; and &lt;em&gt;right&lt;/em&gt;, and $d_{axle}$ replacing $A$.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In those terms, the ratio of the outer wheel's speed to the inner wheel's speed is still what it was before:&#xA;$$\frac{v_{outer}}{v_{inner}} = \frac{r+d_{axle}}{r}$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, in this question, you're trying to determine how much time should pass with the wheels turning at those speeds (in other words, following a circular path of a given $r$) before you come to a desired turning angle of $\theta$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here is the distance equation from before:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$d_{inner} = \frac{\theta*2\pi{r}}{360}$$&#xA;$$v_{inner} = \frac{d_{inner}}{t} = \frac{\theta*2\pi{r}}{360*t}$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, solving for $t$:&#xA;$$ t = \frac{\theta*2\pi{r}}{360*v_{inner}}$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is essentially saying &quot;how long will it take me to travel along a circular arc defined by $r$ and $\theta$ if I move at the given speed $v_{inner}$&quot;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now for the bad news: &lt;strong&gt;achieving this is impossible in practice&lt;/strong&gt;.  The equations above are assuming that your acceleration is infinite, meaning that you would change your speed from $0$ to $v_{inner}$ instantly.  This has never happened.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you need to be sure that you've reached a desired heading, you'll need to start working with sensors.  A GPS, a compass, or even wheel odometry would be good places to start.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-07-20T20:59:55.350" />
  <row Id="1636" PostTypeId="2" ParentId="1584" CreationDate="2013-07-21T04:45:31.300" Score="3" Body="&lt;p&gt;Is it possible to use multiple ultrasonic sensors on a single robot? Yes: &lt;a href=&quot;http://www.societyofrobots.com/sensors_sonar.shtml&quot; rel=&quot;nofollow&quot;&gt;&quot;Using Multiple Sonar Sensors&quot;&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As you have already figured out, one sensor often receives echoes of pings sent by another sensor.&#xA;There are several ways to deal with cross-sensitivity, roughly in order of simplest first:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Ping only one transducer at a time, ignoring all the other transducers while waiting for the &quot;ghost echoes&quot; from the current transducer to die down before pinging the next transducer. This is much faster than mechanically rotating a single transducer. Perhaps this will be fast enough, unless your robot is ramming into things at nearly the speed of sound.&lt;/li&gt;&#xA;&lt;li&gt;Use relatively narrow beam angle transmitters or receivers (or both) per sensor, and increase the angle from one sensor to the next so one sensor can't hear the echo from another (unless the stuff in front of the transducer causes some weird lateral reflections)&amp;nbsp;— sensors angled apart roughly the same as the beam angle. Alas, this leaves &quot;blind spots&quot; between transducers where objects can't be seen by any transducer.&lt;/li&gt;&#xA;&lt;li&gt;Some combination — for example, increase the angle from one sensor to another so one sensor only hears echoes from its 2 neighbors (about half the beam angle); then alternate between pinging the even transducers (ignoring the odd transducers) and pinging the odd transducers (ignoring the even transducers).&lt;/li&gt;&#xA;&lt;li&gt;Each transducer operating at a different frequency. Alas, all the low-cost ultrasonic transducers, with &lt;a href=&quot;http://www.newark.com/multicomp/mcpct-g5120-4140/ultrasonic-transducer/dp/25R0960?in_merch=Popular%20Products&quot; rel=&quot;nofollow&quot;&gt;few exceptions&lt;/a&gt;, are tuned to resonate at 40 kHz. When listening to a variety of signals, these transducers can only &quot;hear&quot; signals that are within a few kHz of 40 kHz. You'll have to balance (a) The further away from 40 kHz you use on a transducer designed for 40 kHz, the less sensitive it is, so you want a frequency &quot;relatively close&quot; to 40 kHz; and (a) The closer all the frequencies are together, the more difficult it is to discriminate between them, so you want a set of frequencies that are spread &quot;relatively far apart&quot;. I don't know if there is a good compromise or not&amp;nbsp;— if not, you're stuck with (c) use more expensive sensors tuned to other frequencies, or more expensive &lt;a href=&quot;http://search.digikey.com/us/en/products/SPM0404UD5/423-1086-1-ND/1587388&quot; rel=&quot;nofollow&quot;&gt;&quot;wide-bandwidth&quot; sensors&lt;/a&gt; not tuned to any particular frequency.&lt;/li&gt;&#xA;&lt;li&gt;Use various transmit timings to rule out ghost echoes. Say you transmit from the left, delay 2 ms (not nearly enough to let the echoes die down), then transmit from the right,... after the echoes die down, then transmit from the left, delay 3 ms, then transmit from the right. If the right receiver gets an echo back 5 ms later both times, then you can be pretty sure it's a real echo; if the right receiver gets an echo back 5 ms later the first time, 6 ms later the second time, it's probably a ghost from the left receiver. (There are much more sophisticated &quot;spread spectrum&quot; techniques for separating out many transmitters all using the same frequency at the same time.)&lt;/li&gt;&#xA;&lt;li&gt;Combine the signals from all the receivers. If you have one central transmitter that pings in all directions (or equivalently you have transmitters pointed in every direction, and you ping them all at the same instant), and the first echo you get back hits the left receiver first (then later the right receiver hears an echo), you know that the nearest obstacle is closer to the left side than the right side. (There are more sophisticated &quot;phased array&quot; techniques that combine signals from all the receivers, and even more sophisticated &quot;beamforming&quot; techniques for slightly adjusting the transmit times of all the transmitters.)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;P.S.: Have you seen &lt;a href=&quot;http://www.societyofrobots.com/member_tutorials/node/71&quot; rel=&quot;nofollow&quot;&gt;&quot;Infrared vs. Ultrasonic — What You Should Know&quot;&lt;/a&gt; ?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(Yes, I've said this all before, at &lt;a href=&quot;http://electronics.stackexchange.com/questions/24835/multiple-ultrasonic-rangefinder-question&quot;&gt;&quot;Multiple Ultrasonic Rangefinder Question&quot;&lt;/a&gt;.)&lt;/p&gt;&#xA;" OwnerUserId="187" LastEditorUserId="1177" LastEditDate="2013-12-31T03:22:58.930" LastActivityDate="2013-12-31T03:22:58.930" />
  <row Id="1637" PostTypeId="1" AcceptedAnswerId="1640" CreationDate="2013-07-21T17:33:49.660" Score="-1" ViewCount="83" Body="&lt;p&gt;I am a graduate student trying to make my own Line follower Robot for my minor assessment, I've all &lt;strong&gt;hardware&lt;/strong&gt; parts and all &lt;strong&gt;data-sheets&lt;/strong&gt; with me, I've attended a workshops of Robotics and studied a lot on &lt;strong&gt;Line follower robot&lt;/strong&gt;. I have a good knowledge of C Programming and Embedded systems, but the problem is I've a very &lt;strong&gt;limited amount&lt;/strong&gt; of time(2 days).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Please help me to suggest a good paper work about my Project - Line follower robot, where should I start from ? I am getting myself confused should I start from &lt;strong&gt;Programming&lt;/strong&gt; or should I first do circuit &lt;strong&gt;simulations&lt;/strong&gt; as I know It is not a better approach to use directly hardware. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Please suggest me a fine &lt;strong&gt;Paper work&lt;/strong&gt; or some links/videos so that I can make my Robotics projects fast. Any help would be really appreciated, Thanks.&lt;/p&gt;&#xA;" OwnerUserId="1558" LastActivityDate="2013-07-21T21:36:16.453" Title="Paper work before I do make my own Line follower Robot" Tags="&lt;mobile-robot&gt;" AnswerCount="1" CommentCount="2" ClosedDate="2013-07-22T10:55:51.467" />
  <row Id="1638" PostTypeId="1" AcceptedAnswerId="1639" CreationDate="2013-07-21T18:33:28.620" Score="4" ViewCount="104" Body="&lt;p&gt;I have been looking online for a while, and I cannot seem to find any steppers without any torque ratings. (&lt;strong&gt;Operating torque, not holding torque.&lt;/strong&gt;) I even looked on hobby sites that usually have all the ratings, including Adafruit and Sparkfun. I only have found one ever that said the operating torque, however, it didn't seem that reputable and it didn't have holding torque, so it might be likely that it's a mistake. I might contact them and ask.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Am I missing something? Can I calculate what it will run at with certain factors? (How long in between each step, etc.)&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The reason that I say that is I found a tutorial saying how much &lt;em&gt;torque&lt;/em&gt; (didn't specify which kind, but I kinda assume it isn't holding) you need for a CNC machine (what I'm building).&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Equation (From &lt;a href=&quot;http://buildyourcnc.com/torquemotion.aspx&quot; rel=&quot;nofollow&quot;&gt;this&lt;/a&gt; site):&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;Torque = ((weight)(inches/revolution))/2(pi)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Also on the page:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;By the way, we are talking about torque during a continual turning motion, not at a holding position.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;That seems like operating torque, but what makes it the most confusing is they sell steppers and they only list the holding.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What am I missing?&lt;/strong&gt;&lt;/p&gt;&#xA;" OwnerUserId="824" LastActivityDate="2013-07-27T04:53:20.023" Title="WHY are there no operating torque specifications on steppers?" Tags="&lt;stepper-motor&gt;&lt;cnc&gt;" AnswerCount="3" CommentCount="4" />
  <row Id="1639" PostTypeId="2" ParentId="1638" CreationDate="2013-07-21T21:32:06.780" Score="2" Body="&lt;p&gt;Stepper motors are nasty little beasts and I don't like them.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Actually, stepper motors are perfectly good as far as they go, but there are subtleties involved in selecting them and running them -- and I've had a couple of projects where the incorrect motor was chosen, then the problem of driving it was dumped unceremoniously in my lap.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Given a stepper motor without feedback, if you ask for too much torque from the motor then it will slip, and you won't have any clue where your mechanism is until you home it again.  Given a stepper motor &lt;em&gt;with&lt;/em&gt; feedback, you have all the pieces you need to use a DC motor, perhaps with a gearbox, in a smaller package that won't get as hot.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;You want to design your mechanism with lots of torque overhead.  The article that ott references says you got a guideline to overdesign by a factor of 2 -- that's probably wise, unless you really flog the numbers, test the snot out of things, and are ready to fail anyway.&lt;/li&gt;&#xA;&lt;li&gt;With constant-voltage drive, torque drops with speed.  I believe that this is mostly due to the inductance of the motor, which is listed in the good data sheets.  Fancy stepper drives are current-controlled, to try to drive the current to the data sheet value quickly, in spite of the stepper's inductance (and maybe back-EMF).  They do this by driving higher voltage into the stepper than its continuous-duty rating.&lt;/li&gt;&#xA;&lt;li&gt;More subtly, accelerating a mechanism requires torque, and decelerating it requires torque in the other direction.  If you're trying for speedy transitions this can make a stepper slip.  You need to calculate the acceleration that you can achieve, and stay below it both coming and going.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-07-21T21:32:06.780" CommentCount="8" />
  <row Id="1640" PostTypeId="2" ParentId="1637" CreationDate="2013-07-21T21:36:16.453" Score="1" Body="&lt;p&gt;Two days?  Eeek!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I wouldn't try to simulate the thing at a circuit level.  If you're an EE and you're familiar with circuit simulation packages then using SPICE (or whatever) to simulate the &lt;em&gt;system&lt;/em&gt; may let you slide by with an acceptable performance.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Personally, if I were designing one of these for money, I'd probably simulate it in Scilab, possibly using Xcos -- but that's because I'm familiar with that tool.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Given your limited time I wouldn't try to do more than make something that follows straight lines and gentle curves at some fixed speed.&lt;/p&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-07-21T21:36:16.453" CommentCount="1" />
  <row Id="1641" PostTypeId="2" ParentId="235" CreationDate="2013-07-22T14:55:05.883" Score="2" Body="&lt;p&gt;Definitely rigidly mounted to make use of the batteries mass for vibration damping but where?&#xA;Depends if you want an agile acrobatic machine or a stable camera platform. Spread the mass out if you want to reduce the wobbles in turbulence.&lt;/p&gt;&#xA;" OwnerUserId="1693" LastActivityDate="2013-07-22T14:55:05.883" CommentCount="1" />
  <row Id="1642" PostTypeId="1" CreationDate="2013-07-22T16:25:55.013" Score="4" ViewCount="147" Body="&lt;p&gt;I need  my robotic arm to ring a desk bell. &lt;a href=&quot;http://www.maplin.co.uk/robotic-arm-kit-with-usb-pc-interface-266257&quot; rel=&quot;nofollow&quot;&gt;I one on the maplins site  usb robotic arm.&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It does seem very slow.  What can I hack on it to boost the downwards and upwards speed. I need it hit the bell tip/platform quickly once or twice.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/9tJZC.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;This is purely a LOL project for work. Ever time we get an order we want the arm to ring the bell. :)&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/X3imO.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;-EDIT&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is the gearbox assembly - And it much much to slow - What can i change in here to speed up one gearbox by at least 4 times?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The grabber gearbox is different though. The gear marker P7 is white and seems to move the grabbers at a faster speed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/4pUS5.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="233" LastEditorUserId="233" LastEditDate="2013-07-30T08:38:10.607" LastActivityDate="2013-07-30T08:38:10.607" Title="How to speed up robotic arm?" Tags="&lt;robotic-arm&gt;" AnswerCount="2" CommentCount="3" />
  <row Id="1643" PostTypeId="2" ParentId="1633" CreationDate="2013-07-22T22:10:46.177" Score="0" Body="&lt;p&gt;It turns out VirtualBox was causing everything to not work properly for some reason. Now I'm using VMware and everything's running fine. What confused me was that I was getting errors that I found online and that even after trying every fix I could find some would still be there. Next step is getting XYZ coordinates of a moving robot, I'll start looking for tutorials right away (I'm still new to ros).&lt;/p&gt;&#xA;" OwnerUserId="1681" LastActivityDate="2013-07-22T22:10:46.177" CommentCount="2" />
  <row Id="1644" PostTypeId="1" CreationDate="2013-07-22T22:20:23.120" Score="1" ViewCount="11" Body="&lt;p&gt;On my stepper's &lt;a href=&quot;http://download.lulzbot.com/AO-100/hardware/electronics/spec_sheets/SY42STH47-1504A_stepperMotors.pdf&quot; rel=&quot;nofollow&quot;&gt;datasheet&lt;/a&gt;, it has the category &quot;rotor torque&quot; (labeled in N-CM). &lt;strong&gt;What does that mean? Is this the torque it has can supply when turning? (Hopefully)&lt;/strong&gt;&lt;/p&gt;&#xA;" OwnerUserId="824" LastActivityDate="2013-07-22T22:20:23.120" Title="What is rotor torque?" Tags="&lt;torque&gt;&lt;stepper-motor&gt;" CommentCount="0" ClosedDate="2013-07-24T07:49:35.130" />
  <row Id="1645" PostTypeId="2" ParentId="1642" CreationDate="2013-07-22T23:03:15.253" Score="1" Body="&lt;p&gt;Since the website for the arm doesn't provide useful technical specs. you will have to do some investigating yourself to figure out how to boost the speed. Some knowledge of electronics knowledge is required and it may not be a simple change.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The first thing to do would be to find out what is currently bottle-necking the speed. &#xA;It could be due to&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;the motors themselves (underated for the performance that you want)&lt;/li&gt;&#xA;&lt;li&gt;current limiting circuitry on the control board (eg. low current voltage regulators)&lt;/li&gt;&#xA;&lt;li&gt;current limiting power supply (eg. low current wall adapter)&lt;/li&gt;&#xA;&lt;li&gt;The software that controls the arm&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;You can investigate by using a digital multimeter to measure the current at different parts of the control board to see where the bottleneck is. Doing a google search for the part(s) where the bottleneck occurs can get you more information so that you could buy a higher power version that will perform the same tasks. For example, swapping out a 5V 1A DC voltage regulator for a 5V 10A regulator. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If the motors are the bottleneck then you can just try and replace them with higher rated motors.&lt;/p&gt;&#xA;" OwnerUserId="983" LastEditorUserId="983" LastEditDate="2013-07-24T17:51:02.883" LastActivityDate="2013-07-24T17:51:02.883" CommentCount="6" />
  <row Id="1646" PostTypeId="2" ParentId="1642" CreationDate="2013-07-23T02:29:07.403" Score="2" Body="&lt;p&gt;You might be able to speed up the arm's movement in a purely mechanical way -- non-invasively.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, you could extend the arm and use the rotation of the base to ring the bell.  Or, you could coordinate the movements of all the joints to make the gripper pass the bell at a maximum speed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another way to do it could be to have the gripper pick up a long rod and use that to ring the bell.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-07-23T14:45:06.283" LastActivityDate="2013-07-23T14:45:06.283" CommentCount="2" />
  <row Id="1648" PostTypeId="2" ParentId="1638" CreationDate="2013-07-23T18:31:54.420" Score="2" Body="&lt;p&gt;I have never seen a stepper motor manufacturer &lt;strong&gt;not&lt;/strong&gt; specify the torque vs. speed.  I'm not sure where you've looked but a lot of people re-sell various random equipment to hobbyists without providing the same level of information.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;These graphs look like this one (&lt;a href=&quot;http://www.orientalmotor.com/products/pdfs/2012-2013/A/usa_st_overview.pdf&quot; rel=&quot;nofollow&quot;&gt;source&lt;/a&gt;)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/XijM8.png&quot; alt=&quot;Stepper torque vs. speed&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The way you drive steppers has a large influence on their performance.  The DC bus voltage you use, whether or not it's a constant current driver and whether or not you're micro-stepping all have an influence.  The vendor will state the conditions under which this curve was measured.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you're using a stepper in open loop (stepper motors can be used in closed loop servo just like their brushless DC cousins) you want to have adequate torque margin to ensure you never lose a step.  A rule of thumb is x2.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Examples of some vendors are: &lt;a href=&quot;http://www.orientalmotor.com/index.html&quot; rel=&quot;nofollow&quot;&gt;Oriental Motor&lt;/a&gt;, &lt;a href=&quot;http://www.electrocraft.com/&quot; rel=&quot;nofollow&quot;&gt;ElectroCraft&lt;/a&gt; (formerly Eastern Air Devices).&lt;/p&gt;&#xA;" OwnerUserId="1584" LastActivityDate="2013-07-23T18:31:54.420" />
  <row Id="1649" PostTypeId="1" CreationDate="2013-07-24T00:08:28.877" Score="4" ViewCount="160" Body="&lt;p&gt;I have a APM 3DR Quad with a 3DR radio telemetry kit.  I would like to send real-time sonar data to my laptop (running Windows 7) in order to manipulate it in an additional Arduino Sketch.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The sonar sensor is connected to an Analog In channel on my Arduino. That data is processed for altitude calculations, and I would like to send this altitude data to some sort of ground station on my computer through the use of a telemetry kit (2 3DR Radios: 1 on the quadcopter and 1 on my computer).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am not quite sure how to go about this task.  Is there a way that I can modify the source code (GCS.h or GCS_Mavlink.pde) in conjunction with Mission Planner Mav 1.0 ground station to do this?  Or would I need to write a python module to accomplish this?  &lt;/p&gt;&#xA;" OwnerUserId="1702" LastEditorUserId="37" LastEditDate="2013-07-24T08:36:54.643" LastActivityDate="2013-07-24T08:36:54.643" Title="How can I manipulate real-time sonar data from my Arducopter in Arduino?" Tags="&lt;quadcopter&gt;&lt;python&gt;&lt;sonar&gt;" CommentCount="5" FavoriteCount="2" />
  <row Id="1650" PostTypeId="2" ParentId="758" CreationDate="2013-07-24T10:31:20.937" Score="1" Body="&lt;p&gt;Actually at the University of Pisa, Centro Piaggio, Italy, we discovered this years ago while working with a human-like robot and presented it at the conference for Autism in Catania, Sicily in 2010.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.ilc.cnr.it/~ferro/publications/Roboethics__Human_Robot_Interaction_in_Autism.pdf&quot; rel=&quot;nofollow&quot;&gt;Human-Robot Interaction in Autism&lt;/a&gt; (PDF)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="1705" LastEditorUserId="350" LastEditDate="2013-09-13T15:17:24.780" LastActivityDate="2013-09-13T15:17:24.780" CommentCount="2" />
  <row Id="1653" PostTypeId="1" AcceptedAnswerId="1679" CreationDate="2013-07-25T07:54:49.897" Score="2" ViewCount="604" Body="&lt;p&gt;&lt;strong&gt;How do you calculate or update the position of a differential drive robot with incremental sensors?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is one incremental sensor attatched to each of the two differential wheels. Both sensors determine the distance $\Delta left$ resp. $\Delta right$ their wheel has rolled during a known time $\Delta t$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;First, let's assume the center between both wheels marks the position of the robot. In this case, one could calculate the position as:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$&#xA;x = \frac{x_{left}+x_{right}}{2} \\&#xA;y = \frac{y_{left}+y_{right}}{2}&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&quot;Deriving&quot; those equations under the assumption that both wheels rolled in a straight line (which should be approximately correct for small distances) I get:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$&#xA;\frac{\Delta x}{\Delta t} = \frac{1}{2}\left( \frac{\Delta left}{\Delta t} + \frac{\Delta right}{\Delta t}\right)cos(\theta) \\&#xA;\frac{\Delta y}{\Delta t} = \frac{1}{2}\left( \frac{\Delta left}{\Delta t} + \frac{\Delta right}{\Delta t}\right)sin(\theta)&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Where $\theta$ is the angle of orientation of the robot. For the change of this angle I found the equation&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$&#xA;\frac{\Delta \theta}{\Delta t} = \frac{1}{w} \left( \frac{\Delta left}{\Delta t} - \frac{\Delta right}{\Delta t}\right)&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Where $w$ is the distance between both wheels.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Because $\Delta x$ and $\Delta y$ depend on $\theta$, I wonder whether I should first calculate the new $\theta$ by adding $\Delta \theta$ or if I should rather use the &quot;old&quot; $\theta$ ? &lt;strong&gt;Is there any reason to use one over the other?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then, let's now assume the center between both wheels does &lt;em&gt;not&lt;/em&gt; mark the position of the robot. Instead I want to use a point which marks the geometric center of the robot's bounding box. Then $x$ and $y$ change to:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$&#xA;x = \frac{x_{left}+x_{right}}{2} + l\, cos(\theta)\\&#xA;y = \frac{y_{left}+y_{right}}{2} + l\, sin(\theta)&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&quot;Deriving&quot; the first gives:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$&#xA;\frac{\Delta x}{\Delta t} = \frac{1}{2}\left( \frac{\Delta left}{\Delta t} + \frac{\Delta right}{\Delta t}\right)cos(\theta) - l\,sin(\theta)\,\frac{\Delta \theta}{\Delta t}&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now there is a dependance on $\Delta \theta$. &lt;strong&gt;Is this a reason to use the &quot;new&quot; $\theta$ ?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Is there any better method to do simulatenous update of position and orientation?&lt;/strong&gt; May be using complex numbers (same approach as with quaternions in 3D?) or homogeneous coordinates?&lt;/p&gt;&#xA;" OwnerUserId="720" LastActivityDate="2013-08-01T03:21:40.660" Title="Calculate position of differential drive robot" Tags="&lt;mobile-robot&gt;&lt;kinematics&gt;&lt;motion&gt;&lt;two-wheeled&gt;&lt;forward-kinematics&gt;" AnswerCount="2" />
  <row Id="1654" PostTypeId="1" AcceptedAnswerId="1657" CreationDate="2013-07-25T16:30:23.483" Score="7" ViewCount="487" Body="&lt;p&gt;What is the difference between a Robot and a Machine? At what point does a machine begin to be called a robot?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is it at a certain level of complexity? Is it when it has software etc?.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For instance: A desktop printer has mechanics, electronics and firmware but it is not considered a robot (or is it). A Roomba has the same stuff but we call it a robot. So what is the difference.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have always believed that a robot is a robot when it takes input from it's environment and uses it to make decisions on how to affect it's environment; i.e. a robot has a feedback loop.&lt;/p&gt;&#xA;" OwnerDisplayName="user797" LastEditorUserId="37" LastEditDate="2013-07-29T14:33:08.380" LastActivityDate="2013-08-31T23:04:55.403" Title="What is the difference between a Robot and a Machine?" Tags="&lt;industrial-robot&gt;" AnswerCount="5" CommentCount="6" FavoriteCount="1" />
  <row Id="1655" PostTypeId="2" ParentId="1653" CreationDate="2013-07-25T18:27:02.080" Score="1" Body="&lt;p&gt;For a repeated calculation, it doesn't matter whether you find $\Delta\theta$ before or after you apply $\theta$ to the $\Delta{x}, \Delta{y}$ calculation.  You will always be alternating between a position and an orientation calculation.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In a practical sense, it might be better to calculate $\Delta\theta$ after you calculate $\Delta{x}, \Delta{y}$, since your first iteration through the loop requires an initial value of $\theta$.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Remember that this is an error-prone measurement method anyway -- it's a pair of 1D measurements feeding a 2D approximation of a 3D world.  Even if you are able to get a $\Delta{t}$ very close to $0$, it still won't account for wheel slippage and uneven terrain.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-07-26T15:00:43.490" LastActivityDate="2013-07-26T15:00:43.490" CommentCount="1" />
  <row Id="1656" PostTypeId="2" ParentId="1654" CreationDate="2013-07-25T18:53:53.307" Score="3" Body="&lt;p&gt;As @Shahbaz points out this is a highly philosophical question though it does get to the core of the field of robotics. &lt;a href=&quot;http://www.cs.utah.edu/~jmh/&quot; rel=&quot;nofollow&quot;&gt;Dr. John Hollerbach&lt;/a&gt; begins his &lt;a href=&quot;http://www.eng.utah.edu/~cs5310/chapters.html&quot; rel=&quot;nofollow&quot;&gt;Intro to Robotics notes&lt;/a&gt; as follows:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;What is a robot? In 1980, the Robot Institute of America (RIA), an industrial trade group, came up with the following definition:&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&quot;A robot is a reprogrammable multifunctional manipulator designed to move material, parts, tools, or specialized devices through variable programmed motions for the performance of a variety of tasks.&quot;&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;These days, this definition would be considered too restrictive, as it reflects the concentration of the RIA on robot manipulators on an assembly line. Robotics has broadened over the years in many ways: to include mobility platforms, to address the service sector as well as the manufacturing sector, and to incorporate man-machine interactions, not just autonomy, in telerobotic and virtual reality systems.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Ultimately he does not offer an alternative definition outright, that I recall. Instead he discusses the elements of a robot system which he lists as:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Mechanical Structure&lt;/li&gt;&#xA;&lt;li&gt;Actuators&lt;/li&gt;&#xA;&lt;li&gt;Sensors&lt;/li&gt;&#xA;&lt;li&gt;Computer Controller&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;It is arguable whether the computer controller is even necessary because mechanisms can be built that respond to environmental stimuli without the explicit aid of a computer (see &lt;a href=&quot;http://blog.ted.com/2007/11/27/robert_full/&quot; rel=&quot;nofollow&quot;&gt;Dr. Robert Full&lt;/a&gt;'s work). In AI we call such things reflex agents.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If we accept the first three elements (or all four) then our world is overrun by robots. This is a bit unsatisfying for many because we often envision the robots from SciFi. If we don't then the definition becomes arbitrary as @Ian points out because we cannot draw a distinction between two devices with the same components wherein we call one a robot (e.g. 3D printer) and another we don't (e.g. microwave) as you implicitly observe.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Regardless it is generally accepted that these are the elements of a robot. This of course gives rise to the question, did we have robots before we had the term &quot;robot?&quot; The answer to this question is yes (see &lt;a href=&quot;http://robotics.stackexchange.com/questions/533/what-was-the-earliest-concept-of-a-robot/547#547&quot;&gt;What is the earliest concept of a robot?&lt;/a&gt;). However you shouldn't let this bother you, it is not uncommon for a field of research to come after the technology and/or ideas that define it.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-07-25T18:53:53.307" CommentCount="2" />
  <row Id="1657" PostTypeId="2" ParentId="1654" CreationDate="2013-07-26T03:00:17.627" Score="3" Body="&lt;p&gt;You asked two (root) questions:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Question: What is the difference between a Robot and a Machine?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;and&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Question: At what point does a machine begin to be called a robot?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If I may, allow me to present the following text to address the first question:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org:/wiki/Simple_machine&quot; rel=&quot;nofollow&quot;&gt;six classical simple machines&lt;/a&gt; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Reference: &lt;a href=&quot;https://en.wikipedia.org/wiki/Simple_machine&quot; rel=&quot;nofollow&quot;&gt;https://en.wikipedia.org/wiki/Simple_machine&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Lever&lt;/li&gt;&#xA;&lt;li&gt;Wheel and axle&lt;/li&gt;&#xA;&lt;li&gt;Pulley&lt;/li&gt;&#xA;&lt;li&gt;Inclined plane&lt;/li&gt;&#xA;&lt;li&gt;Wedge&lt;/li&gt;&#xA;&lt;li&gt;Screw&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Any one of these “machines” is a long way from (but may contribute to the construction of) a robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Addressing your second question and although fiction, Isaac Asimov presented &lt;a href=&quot;http://en.wikipedia.org/wiki/Three_Laws_of_Robotics&quot; rel=&quot;nofollow&quot;&gt;a line of thought&lt;/a&gt; (reference: &lt;a href=&quot;http://en.wikipedia.org/wiki/Three_Laws_of_Robotics&quot; rel=&quot;nofollow&quot;&gt;http://en.wikipedia.org/wiki/Three_Laws_of_Robotics&lt;/a&gt;) still discussed today:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The Three Laws of Robotics (often shortened to The Three Laws or Three Laws) are a set of rules devised by the science fiction author Isaac Asimov. The rules were introduced in his 1942 short story &quot;Runaround&quot;, although they had been foreshadowed in a few earlier stories. The Three Laws are:&lt;/p&gt;&#xA;  &#xA;  &lt;ol&gt;&#xA;  &lt;li&gt;A robot may not injure a human being or, through inaction, allow a human being to come to harm.&lt;/li&gt;&#xA;  &lt;li&gt;A robot must obey the orders given to it by human beings, except where such orders would conflict with the First Law.&lt;/li&gt;&#xA;  &lt;li&gt;A robot must protect its own existence as long as such protection does not conflict with the First or Second Law.&lt;/li&gt;&#xA;  &lt;/ol&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Since I’m referencing Wikipedia verses presenting any original thought, I might as well &lt;a href=&quot;http://en.wikipedia.org/wiki/Robot&quot; rel=&quot;nofollow&quot;&gt;continue&lt;/a&gt;: (reference: &lt;a href=&quot;http://en.wikipedia.org/wiki/Robot&quot; rel=&quot;nofollow&quot;&gt;http://en.wikipedia.org/wiki/Robot&lt;/a&gt;)&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;A robot is a mechanical or virtual agent, usually an electro-mechanical machine that is guided by a computer program or electronic circuitry. ... Robotics is the branch of technology that deals with the design, construction, operation, and application of robots, as well as computer systems for their control, sensory feedback, and information processing.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;In summary, a machine can be a robot, a robot can be a machine, a robot can be virtual.   I agree with the poster who said it would be several doctoral programs defining the difference.   :)&lt;/p&gt;&#xA;" OwnerUserId="1625" LastEditorUserId="1625" LastEditDate="2013-08-04T19:20:43.603" LastActivityDate="2013-08-04T19:20:43.603" CommentCount="4" />
  <row Id="1658" PostTypeId="1" CreationDate="2013-07-26T09:19:46.223" Score="3" ViewCount="56" Body="&lt;p&gt;I would like to know if there are any other solutions to implement slip compensation into a Half-Size Micromouse other than the conventional method. I have spoken to a few Japanese competitors, and they told me that the only solution they have to such a problem is creating a table of predetermined values and using these values to increase or decrease the before turn/after turn distances. The values used are determined by the Mouse's intelligence. Due to the fact that this method has too many limitations, I would like to hear more suggestions from people who are familiar with this matter.&lt;/p&gt;&#xA;" OwnerDisplayName="Lai Feng" LastEditorUserId="158" LastEditDate="2014-01-10T10:52:16.793" LastActivityDate="2014-01-10T10:52:16.793" Title="Implementing Slip Compensation into a Half-Size Micromouse" Tags="&lt;micromouse&gt;&lt;slip-compensation&gt;" CommentCount="2" />
  <row Id="1660" PostTypeId="1" AcceptedAnswerId="1664" CreationDate="2013-07-26T18:41:28.633" Score="2" ViewCount="199" Body="&lt;p&gt;I am working on a homemade vending machine project that serves milk and cookies, using arduino and some basic servos and stuff.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The problem is: I really have no clue on how to protect the milk to last long, or how to even know if the milk is still ok to drink.. All I really know is that air is bad for the milk (and the cookies), so here is what I came up with:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/mGUMy.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Two solenoids that activates at the same time, to allow air in, and milk out. All of this should be inside a &quot;slightly&quot; colder place.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm sure this design might sound stupid to some of you, but this is where I need your help please, do you think this design can work ? (Would that solenoid on top make any difference to protect milk?) How to improve it to make the milk last as long as possible ?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'v heard about the big guys making machines that keep milk fresh for weeks even months, while i'm probably sure my milk won't stand a couple of hours..&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any idea or any information, link, or clue would be greatly appreciated. Thank you.&lt;/p&gt;&#xA;" OwnerUserId="1717" LastActivityDate="2013-07-27T01:01:50.680" Title="How to protect the milk in a homemade vending machine?" Tags="&lt;arduino&gt;" AnswerCount="2" CommentCount="3" />
  <row Id="1661" PostTypeId="2" ParentId="1660" CreationDate="2013-07-26T19:11:31.307" Score="6" Body="&lt;p&gt;Milk is readily available in plastic bags inside cardboard boxes, as illustrated in the picture below of part of a cafeteria-style milk dispenser.  Flow of milk is controlled by pinching off the white plastic tube that comes out of the bottom front edge of the box.  To resupply the machine, you get a new box of milk from a larger refrigerator, rip open a tab and pull out the white tube, put the box into the dispenser, thread the tube through the pinch-off, then cut off the seal at the bottom end of the tube.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Using a readily available commercial product like this probably would be a better approach than having to clean and refill a tank like that shown in your picture.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Picture source: &lt;a href=&quot;http://www.hurstgreenplastics.com/products-page/&quot;&gt;hurstgreenplastics.com&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/XGun5.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="478" LastActivityDate="2013-07-26T19:11:31.307" />
  <row Id="1664" PostTypeId="2" ParentId="1660" CreationDate="2013-07-27T01:01:50.680" Score="1" Body="&lt;p&gt;If you are concerned about the milk coming in contact with the air. I'd suggest using a plastic bag which the air from the first solenoid pours into. On expansion, the plastic bag(filled with air) will force the milk in the container to push out through the second solenoid. This way doesn't come in contact with milk. The only problem I see, which would compromise the milk, is any leaks in the bag itself. And another problem would that you'll have to find a way to drain that air in the plastic bag once all the milk is out.&lt;/p&gt;&#xA;" OwnerUserId="1213" LastActivityDate="2013-07-27T01:01:50.680" CommentCount="1" />
  <row Id="1665" PostTypeId="2" ParentId="1638" CreationDate="2013-07-27T04:53:20.023" Score="1" Body="&lt;p&gt;I'm pretty sure that people at the place that manufactured your stepper motors did, in fact, write up a datasheet including operating torque specifications and lots of other information.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It is unfortunate that all too often a person ends up with some electrical part in his hand, and somehow the datasheet was lost along the way.&#xA;I've discovered that it's well worth the money to buy stuff from people who actually do supply good datasheets, rather than try to save a few nickles buying allegedly &quot;the same&quot; part from other people who can't be bothered to forward the datasheets they got from the manufacturer.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A few links to datasheets that list operating torque:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.kelinginc.net/KL23H251-24-8BT.pdf&quot; rel=&quot;nofollow&quot;&gt;Torque curve for the KL23H251-24-8B&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.shinano.com/motors/docs/SKC_stepper_operation.pdf&quot; rel=&quot;nofollow&quot;&gt;&quot;Stepper Motor Operation and Theory&quot;: &quot;Fig. 7-1 Speed - Torque Curve&quot;&lt;/a&gt; gives a brief explanation of the speed-torque curve.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.linengineering.com/line/contents/stepmotors/pdf/LinEngineering_Catalog_2011-2012_HR.pdf&quot; rel=&quot;nofollow&quot;&gt;&quot;Lin Engineering Catalog&quot;: &quot;Reading a speed and torque curve&quot;&lt;/a&gt; on p. 11 gives  a brief explanation of the speed-torque curve. The rest of the catalog has many speed-torque curves for particular motors.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.alltronics.com/mas_assets/acrobat/28M016.pdf&quot; rel=&quot;nofollow&quot;&gt;torque curves&lt;/a&gt; for several Lin Engineering steppers&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.alephobjects.com/hardware/motors/SY42STH47-1504A_060047067.pdf&quot; rel=&quot;nofollow&quot;&gt;Pull out torque curve for the SY42STH47-1504A&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.trinamic.com/tmc/media/Downloads/QMot_motors/QSH4218/QSH4218_manual.pdf&quot; rel=&quot;nofollow&quot;&gt;Torque figures for Trinamic QSH4218 series&lt;/a&gt;(p. 7-8)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.wantmotor.com/ProductsView.asp?id=155&amp;amp;pid=75&amp;amp;sid=80&quot; rel=&quot;nofollow&quot;&gt;Pulse-torque characteristics of the 42BYGHW&lt;/a&gt; (several graphs of speed vs. torque, each one of the &lt;em&gt;same&lt;/em&gt; motor connected to a different kind of motor driver).&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://catalog.orientalmotor.com/plp/itemdetail.aspx?cid=1002&amp;amp;categoryname=all-categories&amp;amp;productname=pk-series-stepping-motors&amp;amp;itemname=pke245da-l&amp;amp;cid=1002&amp;amp;plpver=11&amp;amp;categid=100&amp;amp;prodid=3001048&amp;amp;itemid=49362&amp;amp;origin=groupdetail&amp;amp;by=prod&amp;amp;filter=0&amp;amp;grpid=25391&amp;amp;backtoname=Compatible%20Motors%20%28sold%20separately%29&amp;amp;isUOM=1#&quot; rel=&quot;nofollow&quot;&gt;Speed-Torque Characteristics of the Oriental Motor PKE245DA-L&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;As you can see from the above graphs, the torque at the maximum-mechanical-power part of the torque curve is very roughly half the &quot;holding torque&quot; (the torque when moving very slowly).&lt;/p&gt;&#xA;" OwnerUserId="187" LastActivityDate="2013-07-27T04:53:20.023" />
  <row Id="1666" PostTypeId="1" CreationDate="2013-07-27T11:45:45.427" Score="4" ViewCount="67" Body="&lt;p&gt;I have a box (cuboid) lying on floor or table. So there are 6 surfaces of the box and 1 surface of the floor. If I take each pair of surface such that the surfaces are &quot;adjacent&quot; to each other, I get two kind of pairings:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;1) two surfaces of the box: the surface normals of the surfaces diverge from each other.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;2) 1 surface of the box + surface of the floor : the surface normals converge and intersect at an angle of 90 degrees. ( 8o to 100 degrees, if we want to add some tolerance).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I want to distinguish these two cases by representing through a function? What function can distinguish between these two situations?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In both cases, the the normalized dot product of the surface normals is 0, since the angle b/w them is 90 degrees. So this is not the right solution...&lt;/p&gt;&#xA;" OwnerUserId="658" LastEditorUserId="350" LastEditDate="2013-08-02T15:03:46.100" LastActivityDate="2013-08-15T21:44:27.363" Title="classify if two adjacent surfaces belong to same object" Tags="&lt;kinect&gt;&lt;computer-vision&gt;&lt;machine-learning&gt;" AnswerCount="1" CommentCount="2" />
  <row Id="1668" PostTypeId="2" ParentId="287" CreationDate="2013-07-28T03:46:32.167" Score="0" Body="&lt;p&gt;There is also a project called &lt;a href=&quot;http://www.espruino.com/&quot; rel=&quot;nofollow&quot;&gt;Espruino&lt;/a&gt;, which is a JavaScript interpreter for low power ARM microcontrollers. It is a rewrite of the &lt;a href=&quot;https://code.google.com/p/tiny-js/&quot; rel=&quot;nofollow&quot;&gt;tiny-js&lt;/a&gt; project, a small C++ interpreter for Javascript.&lt;/p&gt;&#xA;" OwnerUserId="181" LastActivityDate="2013-07-28T03:46:32.167" />
  <row Id="1670" PostTypeId="1" AcceptedAnswerId="1671" CreationDate="2013-07-28T15:19:02.270" Score="5" ViewCount="89" Body="&lt;p&gt;I’m trying to inject some kind of rubber around an aluminum strut to form “feet” for a robot. I’ve already milled the mold, but I’m having trouble finding an inexpensive and readily available rubber compound that will cure without exposure to air. Ideally it should cure to about the consistency of a silicone O-ring. I’ve tried silicone gasket-maker (the automotive stuff), however a week later it hasn’t cured in the mold, as there is no exposure to the air.  Is there anything out there with a similar consistency to silicone, but doesn’t require air to cure?  Or is there a way to get what I’m currently using to set up without waiting a millennium?  There aren’t any real mechanical requirements, I’m just trying to clean up the look of the robot and prevent its legs from scratching my table. &lt;/p&gt;&#xA;" OwnerUserId="176" LastEditorUserId="478" LastEditDate="2013-07-29T02:56:36.433" LastActivityDate="2013-08-15T16:22:27.460" Title="Moldable rubber for &quot;feet&quot;" Tags="&lt;cnc&gt;&lt;feet&gt;&lt;legs&gt;&lt;rubber&gt;&lt;mold&gt;" AnswerCount="3" CommentCount="3" />
  <row Id="1671" PostTypeId="2" ParentId="1670" CreationDate="2013-07-28T23:54:51.457" Score="6" Body="&lt;p&gt;You need a two-part resin of some sort.  Search on &quot;room-temperature vulcanized&quot; rubber, or &quot;RTV rubber&quot;.  There may also be epoxies that are designed to dry rubbery.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You want stuff that comes with an activator -- if it's single-part RTV it depends on drying or on oxygen in the air to kick off, and you're back to never curing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Your challenge will be to find something that is available in small quantities to the hobbyist.  I can't help you with that, alas -- I just have the name floating around in my head from some prior research, and new what search terms to type in.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here's an example, but I couldn't even say if they'd sell to you: &lt;a href=&quot;http://www.contenti.com/products/casting/179-050.html&quot;&gt;http://www.contenti.com/products/casting/179-050.html&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-07-28T23:54:51.457" CommentCount="1" />
  <row Id="1672" PostTypeId="2" ParentId="1515" CreationDate="2013-07-29T00:22:02.817" Score="3" Body="&lt;p&gt;&lt;em&gt;I'm looking for a way to create a non-rotating persistence of vision device.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It seems to me that the two designs that you propose yourself, at least rely on rotation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would suggest getting rid of rotation entirely. In particular since you say you have problems swinging these arms around.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One way to go about this, is by using magnets, springs and electro magnets. Actually, instead of me explaining this, go look at a loud speaker unit, and apply that same principle to your challenge. You want it to move further though, so use some soft springs to suspend your moving  component between, so you can get some good range on it.&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;          &amp;lt;fixed electro magnet&amp;gt;               L&#xA;&amp;lt;spring&amp;gt;--&amp;lt;free moving magnet&amp;gt;--&amp;lt;electronics&amp;gt;--E--&amp;lt;spring&amp;gt;&#xA;          &amp;lt;fixed electro magnet&amp;gt;               D&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;The middle line can move from side to side, the electromagnet is curled around the sliding assembly&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You would likely need to drive the electro magnet in both directions (reversing the poles) to get some good speed too.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The benefit of this, is that the suspended electronics, can be really light, so you dont need some really heavy weights to keep the vibrations down. And the two springs of either end, could carry the power to the moving electronics.&lt;/p&gt;&#xA;" OwnerUserId="1724" LastActivityDate="2013-07-29T00:22:02.817" />
  <row Id="1674" PostTypeId="2" ParentId="1670" CreationDate="2013-07-29T03:09:17.173" Score="5" Body="&lt;p&gt;Instead of trying to mold a liquid, you could try to form a viscoelastic solid.  That way, the uncured material would keep its shape without an airtight mold.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;There's a product called &lt;a href=&quot;https://sugru.com/about&quot;&gt;Sugru&lt;/a&gt; that you might try; it's hand-moldable silicone rubber that dries in air.  (I am not affiliated with their company.)  &lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-07-29T03:09:17.173" />
  <row Id="1675" PostTypeId="2" ParentId="1072" CreationDate="2013-07-29T11:19:44.063" Score="1" Body="&lt;p&gt;I am working on an open source project to make a platform to make diy automated kite steering unit. I sent a reply as well on electronics.stackexchange.com&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am using SimpleCV which is a python binding to OpenCV to get the position and orientation of the kite relative to the camera of my mobile phone. I use the acceleration and magnetometer of my mobile phone to get the orientation of the camera. I then send the data to my computer over wifi and process them into python.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The project is still in development, but everybody's welcome to help. The source code and documentation is available here &lt;a href=&quot;http://code.google.com/p/robokite/&quot; rel=&quot;nofollow&quot;&gt;http://code.google.com/p/robokite/&lt;/a&gt; I have a blog but it is in french, soon in English?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can also have a look at zenith wind power. It's a student project. The code was on google code as well, but can't be seen anymore for unknown reason. However, you can still get it with svn checkout &lt;a href=&quot;http://zenith-wind-power.googlecode.com/svn/trunk&quot; rel=&quot;nofollow&quot;&gt;http://zenith-wind-power.googlecode.com/svn/trunk&lt;/a&gt; I was not able to compile it, but they made a great job. Adrien should start working again on the project in September.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You have as well academics project (mainly TU Delft).&#xA;And you have the &quot;proprietary&quot; solution lie Makani power, sky sails, kite gen.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Hope it helps!&#xA;Baptiste LABAT&lt;/p&gt;&#xA;" OwnerUserId="1726" LastActivityDate="2013-07-29T11:19:44.063" />
  <row Id="1676" PostTypeId="1" CreationDate="2013-07-30T13:27:09.137" Score="2" ViewCount="71" Body="&lt;p&gt;I'm trying to control the speed of this &lt;a href=&quot;http://www.pololu.com/catalog/product/1117&quot; rel=&quot;nofollow&quot;&gt;motor&lt;/a&gt;, with this &lt;a href=&quot;http://www.pololu.com/catalog/product/2130&quot; rel=&quot;nofollow&quot;&gt;motor driver&lt;/a&gt; and pic16f690. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;pwm in my program&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;5 kHz frequency (0.2 ms period)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Starting with 50% duty cycle the motor doesn't run.&#xA;But moving from say, 80% to 50% (i.e. program my PIC with 80% duty cycle, and then re-program it with 50%), the motor will run at 50% (of course at a lower speed). I consider this funny. Anyone to explain this?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;my motor powered by 5V.&lt;/p&gt;&#xA;" OwnerUserId="1733" LastActivityDate="2013-07-30T22:29:06.617" Title="funny behaviour or what - dc motor control" Tags="&lt;motor&gt;" AnswerCount="1" />
  <row Id="1677" PostTypeId="2" ParentId="1676" CreationDate="2013-07-30T22:29:06.617" Score="4" Body="&lt;p&gt;If you're saying that it always starts with 80% PWM, but never with 50%, but it runs with 50% after starting, then you're just starting to learn the joys of working with a system that has significant stiction (AKA starting friction).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Somewhere buried in this document is a description, along with some prescriptions of how to deal with it in a closed-loop control system: &#xA;&lt;a href=&quot;http://wescottdesign.com/articles/Friction/friction.pdf&quot; rel=&quot;nofollow&quot;&gt;http://wescottdesign.com/articles/Friction/friction.pdf&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-07-30T22:29:06.617" CommentCount="1" />
  <row Id="1678" PostTypeId="1" AcceptedAnswerId="1681" CreationDate="2013-07-31T00:04:17.147" Score="3" ViewCount="225" Body="&lt;p&gt;I made a small crawler robot a little while ago that had two legs with two degrees of freedom each, so 4 RC servos total. While I was programming the movement of the legs I noticed that they moved rather stiffly. It makes sense that the RC servo's internal controller would have a very quick response to position commands, but I wanted my crawler to move in a way that seems a little more smooth and life-like.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My solution was create a cubic function of time that describes the path of the servos, and then set their position in small time increments, resulting in more smooth motion. Essentially what I did was solve for the $a_i$ coefficients in a cubic equation using the time interval, starting and ending position of the servo, and starting and ending rates the servo should move (which is just the derivative of the position):&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Solve for $a_0$, $a_1$, $a_2$, and $a_3$:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$ position(t) = a_0 + a_1t + a_2t^2 + a_3t^3 $$&#xA;$$ rate(t) = position'(t) = a_1 + 2a_2t + 3a_3t^2 $$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Given: $position(0)$, $position(t_f)$, $rate(0)$, $rate(t_f)$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I set the rate of the servo between a pair of movements to be zero if the movements were in opposite directions, and positive or negative if the movements were both in the positive or negative direction, respectively. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;This worked pretty well, but this solution is limited in a few ways. For one, it's difficult to decide what exactly the rates between movements that go in the same direction should be. I used the average of the slopes ahead and behind of a particular position between movements, but it isn't clear to me that is optimal. Second of all, cubic curves could take the servo to a position outside of the range of the positions at the beginning and end of a movement, which may be undesirable. For example, at some point during the time interval, the curve could cause the servo to go beyond the second position, or below the first position. Thirdly, curve generation here does not consider the maximum rate that the servo can turn, so a curve may have the servo move at a speed that is unrealistic. With that, a minor concern is that the maximum turning rate depends on the response of servo's internal controller, and may change depending on the size of the position interval. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Neglecting that last concern, these issues may be solved by increasing the degree of the polynomial and adding constraints to solve for the coefficients, but I'm now starting to wonder...&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there a better way than this to make servo movement smooth and seem more life-like?&lt;/p&gt;&#xA;" OwnerUserId="181" LastEditorUserId="350" LastEditDate="2013-08-05T12:57:41.913" LastActivityDate="2013-08-05T12:57:41.913" Title="Smooth servo movement for a crawling robot" Tags="&lt;servos&gt;&lt;kinematics&gt;&lt;crawler&gt;" AnswerCount="2" CommentCount="17" FavoriteCount="2" />
  <row Id="1679" PostTypeId="2" ParentId="1653" CreationDate="2013-07-31T09:52:19.097" Score="0" Body="&lt;p&gt;To answer your first question: if you really want to find the true kinematic equations for differential drive, I wouldn't start approximating by assuming that each wheel has moved in a straight line. Instead, find the turning radius, calculate the center point of the arc, and then calculate the robot's next point. The turning radius would be infinite if the robot is moving straight, but in the straight case the math is simple. Here's some sample code:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;// leftDelta and rightDelta = distance that the left and right wheel have moved along&#xA;//  the ground&#xA;&#xA;if (fabs(leftDelta - rightDelta) &amp;lt; 1.0e-6) { // basically going straight&#xA;    new_x = x + leftDelta * cos(heading);&#xA;    new_y = y + rightDelta * sin(heading);&#xA;    new_heading = heading;&#xA;} else {&#xA;    float R = unitsAxisWidth * (leftDelta + rightDelta) / (2 * (rightDelta - leftDelta)),&#xA;          wd = (rightDelta - leftDelta) / unitsAxisWidth;&#xA;&#xA;    new_x = x + R * sin(wd + heading) - R * sin(heading);&#xA;    new_y = y - R * cos(wd + heading) + R * cos(heading);&#xA;    new_heading = boundAngle(heading + wd);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I used similar math in a simulator to demonstrate different ways of steering: &lt;a href=&quot;http://www.cs.utexas.edu/~rjnevels/RobotSimulator4/demos/SteeringDemo/&quot; rel=&quot;nofollow&quot;&gt;http://www.cs.utexas.edu/~rjnevels/RobotSimulator4/demos/SteeringDemo/&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="181" LastEditorUserId="181" LastEditDate="2013-08-01T03:21:40.660" LastActivityDate="2013-08-01T03:21:40.660" />
  <row Id="1680" PostTypeId="1" CreationDate="2013-07-31T13:09:43.993" Score="1" ViewCount="54" Body="&lt;p&gt;I am working on a robotics project with C++ (drawing signs on board), on CRS CataLyst5 arm.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have faced a problem:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have many methods move in different directions, goToLocalizations, etc, but the problem is that when I run many of them in main without Sleep() function between each function they does not run properly. I think that the first one needs time (the time of robot movement) but when I put Sleep(10000) between them (I guessed that 10 seconds are enough for the movement) all is ok. This is very ineffective and slow solution. Would you like to give me some solutions to avoid the use of Sleep ?&lt;/p&gt;&#xA;" OwnerUserId="1743" LastEditorUserId="158" LastEditDate="2013-07-31T15:56:55.207" LastActivityDate="2013-07-31T22:58:00.367" Title="Management of asynchronous commands" Tags="&lt;crs&gt;&lt;activerobot&gt;" AnswerCount="1" CommentCount="0" />
  <row Id="1681" PostTypeId="2" ParentId="1678" CreationDate="2013-07-31T17:33:30.940" Score="3" Body="&lt;p&gt;&lt;strong&gt;Motion Profile Generation&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the past, I've used a motion profile generator to solve this problem. To use it you would need the desired target position (set point), maximum velocity, and acceleration values that are associated with your motors. It works by integrating a trapezoidal velocity curve in order to get a smooth position profile. An S-curve can be used if the motion has to be even smoother.&#xA;&lt;a href=&quot;http://www.pmdcorp.com/news/articles/html/Mathematics_of_Motion_Control_Profiles.cfm&quot; rel=&quot;nofollow&quot;&gt;Reference to article explaining Motion profiling&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Set Point Pre-filtering&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Aside from the motion profiling route, you can try simply low pass filtering the command to the servos. This type of setpoint filtering will slow your response down but it will also smooth it out and it's easy to implement. The cut-off frequency will have to be chosen so that it supports the bandwidth of your system (so it does not filter out desired motion). &#xA;&lt;a href=&quot;https://ccrma.stanford.edu/~jos/filters/Definition_Simplest_Low_Pass.html&quot; rel=&quot;nofollow&quot;&gt;Simple Low-pass filter implementation in C&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="983" LastActivityDate="2013-07-31T17:33:30.940" CommentCount="1" />
  <row Id="1682" PostTypeId="1" AcceptedAnswerId="1683" CreationDate="2013-07-31T17:41:12.177" Score="2" ViewCount="96" Body="&lt;p&gt;I am in the concept phase of a driving robot. The two wheels on the front axle will be powered, while the rear will be dragged along. The rear is also responsible for steering but this has noting to do with my question.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Since the robot is required to make relatively sharp turns at high speed. Therefore I have two options to compensate the different speeds on both sides. On the one hand, a differential gear in the front axle could be used. It would be powered by one motor then. On the other hand, I could simply use two motors directly powering each a front wheel. This way I could simulate the differentiation in software.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'd like to go for the first approach, using the hardware differential. But I have the one concern with it. Would a robot vehicle with differential gear still move straight, without explicit steering applied?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My imagination is that, with those wheels not being solidly connected, the robot would move in random curves which I'd have to compensate with a lot of steering then. I know that for real cars, differential gears are standard and do their work, but now I am talking about a small robot measuring about 6 inches.&lt;/p&gt;&#xA;" OwnerUserId="1054" LastActivityDate="2013-07-31T18:15:45.133" Title="Does a vehicle with defferential gear still move straight?" Tags="&lt;motor&gt;&lt;wheeled-robot&gt;&lt;motion&gt;&lt;wheel&gt;" AnswerCount="1" CommentCount="2" />
  <row Id="1683" PostTypeId="2" ParentId="1682" CreationDate="2013-07-31T18:07:41.043" Score="3" Body="&lt;p&gt;If I understand your question, you are asking whether a vehicle balancing on two wheels (or two wheels and one &lt;a href=&quot;http://en.wikipedia.org/wiki/Caster&quot; rel=&quot;nofollow&quot;&gt;caster&lt;/a&gt;) will be able to move straight, or at least predictably, if both wheels were driven from the same motor and used a differential.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The answer is yes, but only if you have a way to equalize the forces of friction affecting each wheel.  For example, by applying a brake individually to each wheel, you could alter the balance of force between the left and right.  It would be crude, but certainly possible to control the steering in this way.  In fact, many &lt;a href=&quot;http://en.wikipedia.org/wiki/Tractor#Pedals&quot; rel=&quot;nofollow&quot;&gt;tractors use independent left and right brake pedals&lt;/a&gt; to accomplish this.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Without actively braking (or some other method), your intuition is correct: the amount of rotation of each wheel would depend on an unpredictable set of forces, and the robot would make seemingly random turns.  &lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-07-31T18:15:45.133" LastActivityDate="2013-07-31T18:15:45.133" CommentCount="7" />
  <row Id="1684" PostTypeId="1" CreationDate="2013-07-31T22:23:52.237" Score="3" ViewCount="56" Body="&lt;p&gt;I've got an arm attached to a shaft. The arms dimensions are 40x5 inches the arm weights about 10 lbs.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If I have a wind acting on the side of the arm, how would I translate the wind force into torque on the shaft?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To give some more information, I'm rotating the arm using a stepper motor, and I would like to know how to size the motor depending environmental conditions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What should my formula look like in order to arrive a required oz-in of torque given my requirements being:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I need to be able to accelerate the arm from 0 to 12 rpm in 1.5 seconds&lt;/li&gt;&#xA;&lt;li&gt;The wind speed can be as high as 30 mph&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Using the formula &lt;strong&gt;P = .00256 x 30^2&lt;/strong&gt; i find the wind pressure per square foot being &lt;strong&gt;2.304&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Using the formula &lt;strong&gt;F = A x P x Cd&lt;/strong&gt; for calculating force, I get &lt;strong&gt;1.389 x 2.304 x 2 = 6.4&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So I know that the wind force on my arm is &lt;strong&gt;6.4 lbs&lt;/strong&gt;. But now how do I translate this to torque on my arm? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/awzfj.png&quot; alt=&quot;mechanical arm&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Source: &lt;a href=&quot;http://k7nv.com/notebook/topics/windload.html&quot; rel=&quot;nofollow&quot;&gt;http://k7nv.com/notebook/topics/windload.html&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1749" LastActivityDate="2013-07-31T22:32:13.760" Title="Wind force impact on torque mechanical arm" Tags="&lt;force&gt;&lt;torque&gt;" AnswerCount="1" />
  <row Id="1685" PostTypeId="2" ParentId="1684" CreationDate="2013-07-31T22:32:13.760" Score="3" Body="&lt;p&gt;If you assume that the wind force you calculated is distributed evenly about the arm (reasonable assumption) then the torque about the shaft is the distance to the center of the arm (20 in) multiplied by the force in oz.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Torque = Force in ounces * Distance = (6.4 lb) * (16 oz / 1 lb) * (20 in) =  2048 oz. in.&lt;/strong&gt;&lt;/p&gt;&#xA;" OwnerUserId="983" LastActivityDate="2013-07-31T22:32:13.760" />
  <row Id="1686" PostTypeId="2" ParentId="1680" CreationDate="2013-07-31T22:58:00.367" Score="1" Body="&lt;p&gt;Since you mention that you are using a &lt;a href=&quot;http://en.wikipedia.org/wiki/CRS_Robotics&quot; rel=&quot;nofollow&quot;&gt;CRS Catalyst 5&lt;/a&gt; arm, I assume that you are using the &lt;a href=&quot;http://www.thermoscientific.fr/com/cda/product/detail/0,1055,21981,00.html&quot; rel=&quot;nofollow&quot;&gt;CRS ActiveRobot&lt;/a&gt; ActiveX control.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A quick look through &lt;a href=&quot;http://www.scribd.com/doc/44659351/Tutorial-Active-Robot&quot; rel=&quot;nofollow&quot;&gt;this ActiveRobot Tutorial&lt;/a&gt; suggests that &lt;a href=&quot;http://en.wikipedia.org/wiki/Asynchronous_method_invocation&quot; rel=&quot;nofollow&quot;&gt;all robot commands are asynchronous&lt;/a&gt;, so when you command the gripper to open (using &lt;code&gt;Robot.GripperOpen&lt;/code&gt; in VB) you then have to wait for the move to finish (using &lt;code&gt;Robot.GripperFinish&lt;/code&gt; in VB).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Similarly it looks like you need to wait for a &lt;code&gt;Robot.MoveStraight&lt;/code&gt; to complete with a &lt;code&gt;Robot.Finish&lt;/code&gt; etc.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Replace all of your sleep calls with the relevant wait commands and you will get rid of all of the unwanted &lt;a href=&quot;https://en.wikipedia.org/wiki/Dead_time&quot; rel=&quot;nofollow&quot;&gt;dead time&lt;/a&gt;. Similarly if you wait for one move to finish before starting a subsequent move, you may prevent moves conflicting with eact other, confusing the control system.&lt;/p&gt;&#xA;" OwnerUserId="37" LastActivityDate="2013-07-31T22:58:00.367" />
  <row Id="1687" PostTypeId="1" AcceptedAnswerId="1688" CreationDate="2013-08-01T02:26:37.093" Score="2" ViewCount="107" Body="&lt;p&gt;I'm going to be embarking on an autonomous robot project and I was going to be using GPS to navigate to waypoints (I'm aware of the margin of error when it comes to localization with GPD but I live in a lovely area with many open fields). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I was going to use Adafruit's Ultimate GPS Breakout board with my RaspberryPi, and I was wondering how I should protect or mount the GPS to protect it from the elements. Do all GPS units need to be face up and unobstructed (ex. wood or plastic) in order to work? If so, how can I still protect a GPS unit from the outdoors?&lt;/p&gt;&#xA;" OwnerUserId="1740" LastActivityDate="2013-08-02T13:51:38.660" Title="Can GPS modules work inside plastic enclosures?" Tags="&lt;gps&gt;&lt;protection&gt;&lt;coverage&gt;" AnswerCount="2" CommentCount="1" />
  <row Id="1688" PostTypeId="2" ParentId="1687" CreationDate="2013-08-01T03:27:05.733" Score="2" Body="&lt;p&gt;Yes, it works fine in a plastic (or wood) case. I've used the PA6H GPS from Adafruit in a &lt;a href=&quot;http://www.mouser.com/Search/ProductDetail.aspx?R=1553BRDBKvirtualkey54600000virtualkey546-1553BRDBK&quot; rel=&quot;nofollow&quot;&gt;Hammond 1553B&lt;/a&gt; plastic case with no issues.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/j4Edm.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Mostly what you want to avoid is any sort of conductor that might block a signal. This includes copper and iron.&lt;/p&gt;&#xA;" OwnerUserId="1524" LastActivityDate="2013-08-01T03:27:05.733" CommentCount="1" />
  <row Id="1689" PostTypeId="2" ParentId="150" CreationDate="2013-08-01T07:40:44.277" Score="0" Body="&lt;p&gt;Simple DC motors installed in my Underwater Robot are still running (with a little more noise), from an year, without ANY seal.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The voltage of 12V is not so much, so even if the power terminals are dipped in water,  water will not conduct much current through itself, unless it is salty.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As the current flows through the path of least possible resistance, most of the current will still be going through the motor windings, however presence of water causes Rusting which will damage the brushes of the motor and hence more noise and friction.&lt;/p&gt;&#xA;" OwnerUserId="1753" LastActivityDate="2013-08-01T07:40:44.277" CommentCount="0" />
  <row Id="1690" PostTypeId="2" ParentId="287" CreationDate="2013-08-01T08:05:02.233" Score="1" Body="&lt;p&gt;Programming the &lt;a href=&quot;http://en.wikipedia.org/wiki/Parrot_AR.Drone&quot; rel=&quot;nofollow&quot;&gt;AR.Drone 2.0&lt;/a&gt; with Javascript is super fun. Here's an example that makes a drone take off, move around, do a flip, then land, all using the &lt;a href=&quot;https://github.com/felixge/node-ar-drone&quot; rel=&quot;nofollow&quot;&gt;node-ar-drone&lt;/a&gt; library:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;var arDrone = require('ar-drone');&#xA;var client = arDrone.createClient();&#xA;&#xA;client.takeoff();&#xA;&#xA;client&#xA;  .after(5000, function() {&#xA;    this.clockwise(0.5);&#xA;  })&#xA;  .after(3000, function() {&#xA;    this.animate('flipLeft', 15);&#xA;  })&#xA;  .after(1000, function() {&#xA;    this.stop();&#xA;    this.land();&#xA;  });&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;The blog post &lt;a href=&quot;http://voodootikigod.com/nodebots-the-rise-of-js-robotics/&quot; rel=&quot;nofollow&quot;&gt;NodeBots - the Rise of JS Robotics&lt;/a&gt; talks about advantages javascript has for robotics, specifically the natural way that real world objects and actions can be modeled as chainable, evented processes.  The example code above to animate a drone looks very similar to using jQuery to animate an HTML element:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;$(&quot;#foo&quot;)&#xA;  .slideUp(300)&#xA;  .delay(800)&#xA;  .fadeIn(400);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="1488" LastEditorUserId="1488" LastEditDate="2013-08-21T19:02:07.687" LastActivityDate="2013-08-21T19:02:07.687" CommentCount="2" />
  <row Id="1691" PostTypeId="2" ParentId="1614" CreationDate="2013-08-01T16:18:15.533" Score="0" Body="&lt;p&gt;We build a new version and its now available for download:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://code.google.com/p/ardu-imu/downloads/detail?name=arduimu_vD&quot; rel=&quot;nofollow&quot;&gt;http://code.google.com/p/ardu-imu/downloads/detail?name=arduimu_vD&lt;/a&gt;....&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The problem completely gone in this version. Read comments in arduimu_vd.ino for more info.&lt;/p&gt;&#xA;" OwnerUserId="1137" LastActivityDate="2013-08-01T16:18:15.533" />
  <row Id="1692" PostTypeId="2" ParentId="1666" CreationDate="2013-08-01T18:48:33.903" Score="3" Body="&lt;p&gt;It actually makes sense that the dot product in both cases is the same (zero) because the dot product of two vectors does not consider the vectors' origins.  Or in other words the math for the dot product places the two vectors at the same origin. In this sense there is no way to distinguish converging or diverging vectors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I think what you need to do is to consider a midpoint for your surfaces as well as their normals and then you should have a convergence or a divergence. Or try taking a dot product of one surface's normal with the other surface's position or vice versa. You will probably find that positive vs negative numbers in this regard will get the answer you seek. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Or maybe you can use the delta position from one to the other against a normal. See the following sketch.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/3IqXt.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;By delta position I mean P1-P2. I hope the diagram helps to clarify. I've drawn two cases: case #1 on the left and case #2 on the right. Calculate the dot product of the two blue vectors or the two red vectors. So, for example:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;answer = dot( N[blue], P[red]-P[blue] )&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;These vectors won't be perpendicular, but the answer will tell you if the one surface is in front of the other or behind it. For case #1 the dot products will be positive. For case #2 the dot products will be negative.  In fact, this method will tell you if any two arbitrarily positioned surfaces that meet at a common edge are convex or concave (divergent or convergent). They don't have to be perpendicular.&lt;/p&gt;&#xA;" OwnerUserId="1075" LastEditorUserId="1075" LastEditDate="2013-08-15T21:44:27.363" LastActivityDate="2013-08-15T21:44:27.363" CommentCount="3" />
  <row Id="1693" PostTypeId="1" AcceptedAnswerId="1694" CreationDate="2013-08-01T22:08:53.750" Score="5" ViewCount="126" Body="&lt;p&gt;For the Dagu Wild Thumper 6 Wheeled platform, or any multiple motor system, do I really need 1 battery for each motor? Or should I just buy 2 for either side of the platform. In addition, for larger motors like the ones on this platform, how do I deal with the power generated from a coasting motor?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I want to jump into the deep end with robotics, as I already hold all the programming skills, and I realize a platform of this magnitude may be a difficult endeavor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Recommended motor voltage is 2 – 7.5 Volts, so should one use two 22 Volt batteries for the left and right side, or six 7.5 volt batteries?&lt;/p&gt;&#xA;" OwnerUserId="1740" LastEditorUserId="350" LastEditDate="2013-08-02T15:03:04.893" LastActivityDate="2013-08-02T15:03:04.893" Title="Do 6 motors require 6 individually-assigned batteries?" Tags="&lt;motor&gt;&lt;batteries&gt;&lt;battery&gt;" AnswerCount="1" />
  <row Id="1694" PostTypeId="2" ParentId="1693" CreationDate="2013-08-01T23:35:52.627" Score="6" Body="&lt;p&gt;I'm not familiar with that platform.  But in general, no, you do not need separate batteries for each motor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also in general, if you need 2-7.5V for each motor, then you probably want one honkin' big battery that puts out 7.5V or slightly more.  You could use a 12V battery and take care with your drive commands to never give the motors over 7.5V.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Only if you need to do something odd like connecting the motors in series would you need more voltage.&lt;/p&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-08-01T23:35:52.627" />
  <row Id="1695" PostTypeId="1" CreationDate="2013-08-02T05:22:18.607" Score="1" ViewCount="788" Body="&lt;p&gt;I'm in the process of writing my own simple quadcopter controller for experimental use, and I'm having trouble getting my head around how to convert from the degrees which my PID controller demands to an appropriate 1k-2k range for PWM output. For example, take the roll axis on a '+' configured 'copter (pseudo-code):&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;setpoint = scaleToRange(receiver.rollValue, -30, 30); //scale the command (1000-2000) to between -30 and 30 degrees, as that's the maximum roll permitted.&#xA;demandedRoll = rollPID.calculate(setpoint, imu.currentRoll, PID_params);&#xA;&#xA;/// the part I'm having trouble with&#xA;&#xA;motorLeft_command = receiver.throttle - rollPWM;&#xA;motorRight_command = receiver.throttle + rollPWM;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;How do I take the roll demanded by my PID controller and convert it to a value useful to the motors, that is to say, where does &lt;code&gt;rollPWM&lt;/code&gt; come from? My first instinct is to use a simple linear relationship, i.e.:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;rollPWM = scaleToRange(demandedRoll, MinValue=receiver.throttle/2, MaxValue=2000-receiver.throttle);&#xA;//don't let it go beyond 50% of throttle on low end, and the ESC's max on the high end. &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;However this seems far too simplistic to work.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Or should I be doing more calculations before everything goes through PID control? Any help would be great. &lt;/p&gt;&#xA;" OwnerUserId="176" LastActivityDate="2013-08-02T19:00:41.753" Title="Help with PID &quot;units&quot; in a quadcopter control system" Tags="&lt;pid&gt;&lt;motion&gt;&lt;multi-rotor&gt;" AnswerCount="2" CommentCount="2" FavoriteCount="1" />
  <row Id="1696" PostTypeId="2" ParentId="1687" CreationDate="2013-08-02T13:51:38.660" Score="0" Body="&lt;p&gt;There are a variety of GPS units available that use plastic cases to protect against the elements, and they are all plastic.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, &lt;a href=&quot;https://www.google.com/search?q=garmin+puck&amp;amp;tbm=isch&quot; rel=&quot;nofollow&quot;&gt;these Garmin units&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It sounds like you're really asking about what enclosure materials will keep the weather out but let the signal in.  For this, you just need to make sure that you aren't using a conductive shield:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;&lt;a href=&quot;http://electronics.stackexchange.com/a/2370&quot;&gt;the conductor used as a shield has to be thicker than the &quot;skin depth&quot; of the metal at the frequencies you're trying to block out. [...] 1 micron is enough in practice.&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;This &lt;a href=&quot;https://en.wikipedia.org/wiki/Electromagnetic_shielding&quot; rel=&quot;nofollow&quot;&gt;shielding&lt;/a&gt; could be in the form of a metal, a paint, or even a fabric.  So, your enclosure can be anything that does not have a lining made with one of these materials.  Unpainted plastic is a good option.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-08-02T13:51:38.660" />
  <row Id="1697" PostTypeId="1" AcceptedAnswerId="1704" CreationDate="2013-08-02T15:36:39.800" Score="0" ViewCount="318" Body="&lt;p&gt;I bought this MPU-6050: &lt;a href=&quot;http://www.ebay.com/itm/MPU-6050-6DOF-3-Axis-Gyroscope-Accelerometer-Module-for-Arduino-DIY-/261231955458&quot; rel=&quot;nofollow&quot;&gt;link&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;According to the manufacture site, the sensor logic level is 3.3V (though the &lt;em&gt;ebay&lt;/em&gt; page says &lt;code&gt;Power supply :3-5v&lt;/code&gt;)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Should I use a 4 channel Bi-Directional Logic Level Converter (&lt;a href=&quot;http://www.dash.co.il/image/cache/data/AD-757/ID757_LRG-500x500.jpg&quot; rel=&quot;nofollow&quot;&gt;like this one&lt;/a&gt;) for the &lt;code&gt;SDA, SCL, INT&lt;/code&gt; channels? or can I connect it directly to my arduino nano?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I saw some places that says I should use it with a logic level converter and some who say it's ok without it. (I guess it depends on the sensor board, so please take a look, link above)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Current Setup:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;SDA &amp;lt;-&amp;gt; LLC &amp;lt;-&amp;gt; A4&#xA;SCL &amp;lt;-&amp;gt; LLC &amp;lt;-&amp;gt; A5&#xA;INT &amp;lt;-&amp;gt; LLC &amp;lt;-&amp;gt; D2&#xA;VCC &amp;lt;- LLC &amp;lt;- 5V (arduino)&#xA;GND &amp;lt;- LLC &amp;lt;- GND (arduino)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;I still don't have the parts so I can't test it, and I'm probably going to use &lt;a href=&quot;http://www.i2cdevlib.com/devices/mpu6050&quot; rel=&quot;nofollow&quot;&gt;Jeff Rowberg library&lt;/a&gt;&lt;/em&gt; to communicate with the sensor (I&lt;sup&gt;2&lt;/sup&gt;C)&lt;/p&gt;&#xA;" OwnerUserId="1337" LastActivityDate="2013-08-02T19:41:48.770" Title="MPU-6050 + Arduino nano - Logic converter or not?" Tags="&lt;arduino&gt;&lt;sensors&gt;&lt;quadcopter&gt;&lt;logic-control&gt;" AnswerCount="1" CommentCount="2" FavoriteCount="1" ClosedDate="2013-08-02T22:09:30.283" />
  <row Id="1698" PostTypeId="2" ParentId="1695" CreationDate="2013-08-02T18:12:57.027" Score="2" Body="&lt;p&gt;Wrapping your head around unit conversions in controllers is a pretty common problem, so don't think you're alone.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you're implementing your PID controller using floating point math, then you really don't have to worry: the gains that you assign for the proportional, integral, and derivative action will take care of the differing ranges for the inputs and outputs.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you're implementing your PID controller using integer math or fixed-point math, then you don't have to worry for the reasons you're worrying.  Instead, you have to worry about keeping the calculations in the right range so that you neither lose precision nor overflow any calculations.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As an example for a floating-point calculation, a plausible proportional gain would be 500 output counts per degree of input error.  In floating point, you'd just assign 500.0 to the proportional gain.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So have fun.  Don't forget the integrator anti-windup.&lt;/p&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-08-02T18:12:57.027" CommentCount="2" />
  <row Id="1699" PostTypeId="5" CreationDate="2013-08-02T18:45:12.290" Score="0" ViewCount="4" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2013-08-02T18:45:12.290" LastActivityDate="2013-08-02T18:45:12.290" />
  <row Id="1700" PostTypeId="4" CreationDate="2013-08-02T18:45:12.290" Score="0" Body="Machine learning is a branch of Artificial Intelligence concerned with the development of algorithms that adapt their behavior based on past observations. Examples of such algorithms include Artificial Neural Networks, Genetic Algorithms, Expectation-Maximization, and Support Vector Machines. Such algorithms are used for classifying previously unseen data and predicting future values of some unknown process." OwnerUserId="1449" LastEditorUserId="177" LastEditDate="2013-08-05T08:06:22.420" LastActivityDate="2013-08-05T08:06:22.420" />
  <row Id="1701" PostTypeId="5" CreationDate="2013-08-02T18:47:24.190" Score="0" ViewCount="2" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2013-08-02T18:47:24.190" LastActivityDate="2013-08-02T18:47:24.190" />
  <row Id="1702" PostTypeId="4" CreationDate="2013-08-02T18:47:24.190" Score="0" Body="A distributed system consists of a collection of autonomous computers, connected through a network and distribution middleware, which enables computers to coordinate their activities and to share the resources of the system, so that users perceive the system as a single, integrated computing facility." OwnerUserId="1449" LastEditorUserId="1449" LastEditDate="2013-08-02T18:59:11.777" LastActivityDate="2013-08-02T18:59:11.777" />
  <row Id="1703" PostTypeId="2" ParentId="1695" CreationDate="2013-08-02T19:00:41.753" Score="2" Body="&lt;p&gt;Tim Wescot is one of the most experienced experts ever in this forum especially in the PID controllers field.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I recommend you to read his brilliant article &lt;a href=&quot;http://www.embedded.com/design/prototyping-and-development/4211211/PID-without-a-PhD&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We used discrete PID for our quadrotor control system. We are building a quadrotor right now and tested both continuous PID controller(What you are usually find in wikipedia or web searches) and discrete PID controller, and for quadrotor systems which has a digitized system, we find discrete PID far better than continuous one.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In this method, you should use 2 separate PID for each motor, but PID gains is equal except Kp of one of them should be -Kp of another one. Here is the sample code( in C# ):&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;    class PIDController&#xA;    {&#xA;        float[] _u = new float[3];&#xA;        float[] _e = new float[3];&#xA;        float[] _ef = new float[3];&#xA;        float _Tf;&#xA;&#xA;        float _Kp;&#xA;        float _Ti;&#xA;        float _Td;&#xA;        float _h; //delta_t&#xA;        float MaxValue; // min value for motors output&#xA;        float MinValue; // max value for motors output       &#xA;        float _Alfa; //mostly 0.1&#xA;        public PIDController(float SamplingPeriod,float Alfa)&#xA;        {&#xA;            _Alfa = Alfa;&#xA;            _h = SamplingPeriod;&#xA;            MinValue = 0;&#xA;            MaxValue = 100;&#xA;&#xA;        }&#xA;        public void SetCoefficient(float Kp,float Ti,float Td)&#xA;        {&#xA;            _Kp = Kp;&#xA;            _Ti = Ti;&#xA;            _Td = Td;&#xA;        }&#xA;        public void SetRenge(float Min,float Max)&#xA;        {&#xA;            MinValue = Min;&#xA;            MaxValue = Max;&#xA;        }&#xA;&#xA;&#xA;        public float GetOutputSignal(float y, float r)&#xA;        {&#xA;&#xA;            _Tf = _Alfa * _Td;&#xA;            float a = _h / (_Tf + _h);&#xA;            _u[1] = _u[0];&#xA;            _ef[2] = _ef[1];&#xA;            _ef[1] = _ef[0];&#xA;            _e[2] = _e[1];&#xA;            _e[1] = _e[0];&#xA;            _e[0] = r - y;&#xA;            _ef[0] = (1 - a) * _ef[1] + a * _e[0];&#xA;            if ((_Ti != 0) &amp;amp;&amp;amp; (_h &amp;gt; 0))&#xA;                _u[0] = _u[1] + _Kp * (_e[0] - _e[1]) + (_Kp * _h / _Ti) * _e[0] + ((_Kp * _Td) / _h) * (_ef[0] - 2 * _ef[1] + _ef[2]);&#xA;            else&#xA;                _u[0] = 0;&#xA;            //System.Diagnostics.Debug.WriteLine(string.Format(&quot;y = {0} , r = {1} , e = {2} u={3}&quot;,y,r,_e[0],_u[0]));&#xA;            //System.Diagnostics.Debug.WriteLine(string.Format(&quot;Ti = {0} , Td = {1} , Kp = {2}&quot;, _Ti, _Td, _Kp));&#xA;            //System.Diagnostics.Debug.WriteLine(&quot;&quot;);&#xA;            if ((_u[0] &amp;gt; MaxValue) || (_u[0] &amp;lt; MinValue))&#xA;            {&#xA;                if (_u[0] &amp;gt; MaxValue) { _u[0] = MaxValue; };&#xA;                if (_u[0] &amp;lt; MinValue) { _u[0] = MinValue; };&#xA;            }            &#xA;&#xA;            return _u[0];&#xA;        }&#xA;&#xA;    }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Test it, you will find this solution far better than continious one. We also used genetic algorithm for auto-tuning this PID. I should mention this type of PID controller won't work without an integral gain. I also should mention that, we didn't currently fully tune our quadrotor, but we got far far better results than continuous one.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.4shared.com/office/F4_cfogP/tidsdiskret_pid_reg.html&quot; rel=&quot;nofollow&quot;&gt;Here&lt;/a&gt; is the mathematical explanation of this method for more info.&lt;/p&gt;&#xA;" OwnerUserId="1137" LastActivityDate="2013-08-02T19:00:41.753" CommentCount="2" />
  <row Id="1704" PostTypeId="2" ParentId="1697" CreationDate="2013-08-02T19:41:48.770" Score="2" Body="&lt;p&gt;According to the link you provided, you can use 5V or 3.3V directly on the sensor (it already have a voltage regulator). Since the arduino is able to send 3.3V or 5V you can use both of them directly without any level converter.&#xA;You can see on the video &lt;a href=&quot;http://lukagabric.com/arduino-mpu6050/&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt; that you don't need anything &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I got a GY-80 with the same kind of features and I use it directly on my arduino nano without any level converter.&#xA;Their is also a whole arduino playground on how to use this sensor.&lt;/p&gt;&#xA;" OwnerUserId="1615" LastActivityDate="2013-08-02T19:41:48.770" CommentCount="4" />
  <row Id="1705" PostTypeId="2" ParentId="1678" CreationDate="2013-08-02T21:53:18.877" Score="1" Body="&lt;p&gt;I think the question refers to this sort of device: &lt;a href=&quot;http://en.wikipedia.org/wiki/Servo_%28radio_control%29&quot; rel=&quot;nofollow&quot;&gt;RC servo&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Those usually aren't very high performance so they're not going to be able to track a generated motion profile very well.  Most commercial motor control systems use an S curve for a point to point move (see @ddevaz's answer) which do a piece-wise profile where each segment uses a different equation.  Your problem is going to be that in order for your motor to track the generated profile you're probably going to have a very &quot;slow&quot; profile.  Otherwise the profile you try and command the device to follow is going to have a large position error vs. the actual position of the device.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ideally you'll want some sort of feedback you can look at while you are executing the motion so you can see how well the device is tracking the command.  From a more practical perspective, if you want significantly better motion you may need different motors and different motor control.&lt;/p&gt;&#xA;" OwnerUserId="1584" LastActivityDate="2013-08-02T21:53:18.877" />
  <row Id="1707" PostTypeId="1" CreationDate="2013-08-04T15:49:24.350" Score="0" ViewCount="381" Body="&lt;p&gt;I have a USB webcam and a WiFi module which it can convert Serial data to WiFi and vice versa.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The question is can I simply convert the data coming from the webcam to serial with a USB to Serial IC (like FT232R ) and then hand it over to my WiFi Module?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The WiFi module DataSheet is &lt;a href=&quot;http://www.uplooder.net/cgi-bin/dl.cgi?key=1bbc1bb2c5731ba520a0a206664ba57b&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1481" LastEditorUserId="1481" LastEditDate="2013-08-04T16:27:57.183" LastActivityDate="2013-08-04T16:54:52.517" Title="Build an WiFi IP camera with webcam" Tags="&lt;cameras&gt;&lt;wifi&gt;&lt;usb&gt;" AnswerCount="1" CommentCount="3" ClosedDate="2013-08-05T13:04:39.737" />
  <row Id="1708" PostTypeId="2" ParentId="1707" CreationDate="2013-08-04T16:54:52.517" Score="1" Body="&lt;p&gt;I think you're asking whether you can use a USB-to-serial adapter to enable you to connect a USB webcam to a serial-to-wifi converter.  The answer to that is no, unfortunately.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;USB defines a hardware interface and a communications protocol.  Your webcam driver communicates with the physical webcam by sending image data over USB, and your USB-to-serial adapter sends RS232 data over USB.  The video stream and the RS232 stream are not compatible.  (And even if your webcam somehow sent data over RS232, USB devices communicate with the operating system, not each other.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What you are looking for is a bridge -- a way to send USB data over wifi.  There are other consumer products which perform this function, &lt;em&gt;e.g.&lt;/em&gt; &lt;a href=&quot;http://www.gizmag.com/iogear-wireless-4-port-usb-sharing-station/19471/&quot; rel=&quot;nofollow&quot;&gt;this one&lt;/a&gt; or &lt;a href=&quot;http://www.icron.com/products/icron-brand/legacy/usb-wi-ranger/&quot; rel=&quot;nofollow&quot;&gt;this one&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-08-04T16:54:52.517" CommentCount="2" />
  <row Id="1710" PostTypeId="2" ParentId="1654" CreationDate="2013-08-05T20:02:09.420" Score="3" Body="&lt;p&gt;In the industrial world, robots have a clear definition to differentiate them from other industrial machines:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Industrial robot as defined by ISO 8373:&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;An automatically controlled, reprogrammable, multipurpose manipulator programmable in three or more axes, which may be either fixed in place or mobile for use in industrial automation applications.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Reprogrammable: whose programmed motions or auxiliary functions may be changed without physical alterations;&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Multipurpose: capable of being adapted to a different application with physical alterations;&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Physical alterations: alteration of the mechanical structure or control system except for changes of programming cassettes, ROMs, etc.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Axis: direction used to specify the robot motion in a linear or rotary mode &lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;The important words in this definition are &quot;reprogrammable&quot; and &quot;multipurpose.&quot;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, let's think about a welding operation that takes place in a car factory.  This operation could be done with a custom machine that lowers welding elements into place at the appropriate place on the car.  Or we could install a robot arm, put a welder on the end of the arm, and teach (program) it where to weld.  When a new model of car comes along, we can teach it the new weld points.  If we no longer need the welding operation, we can move the robot somewhere else, put a new tool on the end of the arm, and teach it to paint or to screw in a bolt.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In a larger context, people have different ideas about what is a robot and what is not.  But &quot;multipurpose&quot; and &quot;reprogrammable&quot; are still key ideas.  If you can't easily re-purpose your machine to do something completely different by reprogramming (and perhaps making minimal hardware &quot;tool&quot; changes), it's not a robot.&lt;/p&gt;&#xA;" OwnerUserId="1748" LastActivityDate="2013-08-05T20:02:09.420" />
  <row Id="1711" PostTypeId="1" AcceptedAnswerId="1714" CreationDate="2013-08-05T21:23:04.340" Score="4" ViewCount="379" Body="&lt;p&gt;Consider a differential drive robot that has two motorized wheels with an encoder attached to each for feedback. Supposed there is a function for each DC motor that takes a float from -1 to 1 and sets the PWM signals to provide a proportional amount of power to that motor. Unfortunately, not all motors are created equal, so sending each motor the same PWM signal makes the robot veer left or right. I'm trying to think about how to drive the robot straight using the encoders attached to each motor as input to a PID loop.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here's how I would do it: I would take the difference between the left and right encoders, bound the error between some range, normalize it to be from [-1, 1], and then map it to the motor powers 0 to 1. So if I and D were zero, and we get an error of 1 (so the left motor has turned much more than the right motor), then left motor would be set to 0, and the right motor set to 1 (causing a hard left). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Are there any issues with this? What is a better approach?&lt;/p&gt;&#xA;" OwnerUserId="181" LastEditorUserId="181" LastEditDate="2013-08-07T15:52:59.587" LastActivityDate="2013-08-16T03:29:34.177" Title="Approach to using PID to get a differential robot driving straight" Tags="&lt;pid&gt;&lt;differential-drive&gt;" AnswerCount="2" FavoriteCount="2" />
  <row Id="1712" PostTypeId="1" AcceptedAnswerId="1715" CreationDate="2013-08-06T09:26:02.310" Score="5" ViewCount="542" Body="&lt;p&gt;I am working on a robot with focus on speed. At the moment I am looking for a suitable motor but it world help if I understood the difference between the various options.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To provide some background, I have not worked with RC model components before, but I think this is the only place for me to find the components needed for my robot, such as the motor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have already figured out how much power the motor needs to accelerate my robot as desired, taking energy conversion efficiency and tractional resistance into account. It's about 170 watts, depending on the final weight.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To limit my search further, I need to decide on either using a RC car motor or a RC helicopter motor now, but I don't understand the difference between these options.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Focussing on brushless motors (if that matters), what are the differences between RC car and RC helicopter motors which might need to be taken into account when choosing between them?&lt;/p&gt;&#xA;" OwnerUserId="1054" LastEditorUserId="37" LastEditDate="2013-08-06T14:28:47.760" LastActivityDate="2014-01-16T22:23:22.123" Title="What is the difference between RC motors for cars and helicopters?" Tags="&lt;motor&gt;&lt;brushless-motor&gt;" AnswerCount="3" CommentCount="1" />
  <row Id="1714" PostTypeId="2" ParentId="1711" CreationDate="2013-08-06T15:23:20.257" Score="3" Body="&lt;blockquote&gt;&#xA;  &lt;p&gt;Are there any issues with this?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;The main issue with this is that while your proposed solution will instantaneously correct for a mismatch between the performance of the motors, it will not correct for accumulated error, let alone more complex errors in position such as &lt;a href=&quot;http://en.wikipedia.org/wiki/Abbe_error&quot; rel=&quot;nofollow&quot;&gt;Abbe error&lt;/a&gt; (see later).&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;What is a better approach?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;There are several things you can do, depending on what your tolerance for errors are and how much effort you want to put into correcting them.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The first step would be to set up a pair of PID loops, one for each wheel, giving them both the same demand position. As I suggested in &lt;a href=&quot;http://robotics.stackexchange.com/a/1234/37&quot;&gt;my answer to a similar question&lt;/a&gt;, if you keep both wheels within a very tight error bound of where you ask them to be, then it will take some time to accumulate enough of an error to cause noticeable veer.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It will also be much easier to tune two nominally independent Motor level PID loops than to tune a single complex, interdependent combined system. To stand any change of the higher level control working you really need each motor to behave as similarly as possible to the other motor for as much of the time as possible, and that really requires separate servo loops.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are a number of further complications however, and it depends what accuracy you need and how much effort you are prepared to go to to correct for them as to which solution you go for. It may be that &lt;a href=&quot;http://en.wikipedia.org/wiki/Dead_reckoning&quot; rel=&quot;nofollow&quot;&gt;Dead Reckoning&lt;/a&gt; is sufficient, or you may need to add Relative or Absolute position determination to your robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One problem is that even if your left and right wheels both move 1000 encoder counts, you &lt;em&gt;may&lt;/em&gt; still end up in a different position on two different runs.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, say you have a maximum following error of 10 encoder counts, and your motors are running at a speed of say 10 encoder counts per PID loop iteration. Your left motor might move 5,10,10,10...10,5 while your right motor might have a profile of 4,11,10,10...10,5 and even that slight difference in acceleration at the start of the move could cause the robot to set off in slightly the wrong direction. Not only that but the further you move in that direction, the greater the error will become in absolute terms. This is what we are talking about when we talk of &lt;a href=&quot;http://en.wikipedia.org/wiki/Abbe_error&quot; rel=&quot;nofollow&quot;&gt;Abbe error&lt;/a&gt;, and without a complex kinematic model or some sort of external reference, you are never going to be able to correct for it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For more information, see &lt;a href=&quot;http://robotics.stackexchange.com/a/1234/37&quot;&gt;my answer&lt;/a&gt; to a similar but not quite duplicate question: &lt;a href=&quot;http://robotics.stackexchange.com/q/1232/37&quot;&gt;How can I use the Arduino PID library to drive a robot in a straight line?&lt;/a&gt; &#xA;and &lt;a href=&quot;http://robotics.stackexchange.com/a/1527/37&quot;&gt;my answer&lt;/a&gt; to the also related &lt;a href=&quot;http://robotics.stackexchange.com/q/1524/37&quot;&gt;Line Follower optimization&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="37" LastEditorUserId="37" LastEditDate="2013-08-07T16:42:16.877" LastActivityDate="2013-08-07T16:42:16.877" CommentCount="5" />
  <row Id="1715" PostTypeId="2" ParentId="1712" CreationDate="2013-08-06T16:28:04.127" Score="6" Body="&lt;p&gt;I think the term you're looking for is &lt;a href=&quot;http://en.wikipedia.org/wiki/Outrunner&quot; rel=&quot;nofollow&quot;&gt;outrunner&lt;/a&gt; (vs &lt;a href=&quot;http://en.wikipedia.org/wiki/Inrunner&quot; rel=&quot;nofollow&quot;&gt;inrunner&lt;/a&gt;):&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;This type of motor spins its outer shell around its windings&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;[...]&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Outrunners spin much slower than their inrunner counterparts with their more traditional layout (though still considerably faster than ferrite motors) while producing far more torque. This makes an outrunner an excellent choice for directly driving electric aircraft propellers since they eliminate the extra weight, complexity, inefficiency and noise of a gearbox.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Inrunners (which are what most people think of when they think of a &lt;a href=&quot;http://en.wikipedia.org/wiki/DC_motor&quot; rel=&quot;nofollow&quot;&gt;DC motor&lt;/a&gt;) are high-RPM motors with low torque, which usually require some kind of mechanical transmission to be practical.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Quadcopters and other aerial vehicles tend to use outrunners, while R/C cars tend to use inrunners.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-08-08T13:12:28.800" LastActivityDate="2013-08-08T13:12:28.800" CommentCount="6" />
  <row Id="1717" PostTypeId="1" CreationDate="2013-08-07T06:08:26.700" Score="3" ViewCount="425" Body="&lt;p&gt;I know that the Complementary Filter has the functions of both LPF and HPF. But I think my understanding on the principal behind it is still unclear.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am quite new on digital signal processing, and maybe some very fundamental explanations will help a lot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Say I have a Complementary Filter as follows:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$y =a\cdot y+(1-a)\cdot x$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then my parameter $a$ may be calculated by $$a=\frac{\text{time constant}}{\text{time constant}+\text{sample period}}$$&#xA;where the $\text{sample period}$ is simply the reciprocal of the $\text{sampling frequency}$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The $\text{time constant}$ seems to be at my own choice.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;My Questions:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;What is the theory behind this calculation?&lt;/li&gt;&#xA;&lt;li&gt;How do we choose the $\text{time constant}$ properly?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;&lt;sub&gt;&lt;strong&gt;Note:&lt;/strong&gt; I also &lt;a href=&quot;http://stackoverflow.com/q/18095785&quot;&gt;posted this question on Stack Overflow&lt;/a&gt;, as the answers there are likely to be slightly different in emphasis.&lt;/sub&gt;&lt;/p&gt;&#xA;" OwnerUserId="1770" LastEditorUserId="37" LastEditDate="2013-08-08T11:41:25.443" LastActivityDate="2013-08-08T11:41:25.443" Title="How to determine the parameter of a Complementary Filter?" Tags="&lt;gyroscope&gt;&lt;magnetometer&gt;" AnswerCount="1" CommentCount="6" FavoriteCount="1" />
  <row Id="1719" PostTypeId="2" ParentId="807" CreationDate="2013-08-07T13:36:08.673" Score="3" Body="&lt;p&gt;I would say any application where a large number of communications nodes are required (sensors or actuators) would benefit from being implemented as a system bus (in contrast to point to point links such as UART or Ethernet), due to wiring complexity, determinism and modularity.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any control system requires a high degree of determinism, which high bandwidth channels (such as Ethernet) are usually poor at (especially when used with a general purpose OS which introduces large amounts of scheduling jitter, see &lt;a href=&quot;http://elinux.org/images/4/4e/Real-Time-Preemption-Patchset.pdf&quot; rel=&quot;nofollow&quot;&gt;the following link for a discussion on scheduling determinism&lt;/a&gt;). Application processors (such as the ARM11 of the Raspberry Pi) is also probably a poor fit for real-time systems (due to effects such as interrupt latency, and instruction pipe-lining). &lt;a href=&quot;http://www.digikey.com/us/en/techzone/microcontroller/resources/articles/real-time-notes-on-microcontroller-interrupt-latency.html&quot; rel=&quot;nofollow&quot;&gt;See the following digikey discussion comparing real-time behavior of a ARM application core vs a microcontroller&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It's a shame the availability of integrated CAN isn't as widespread as UART (RS-485) or I2C (yet), because I think it really simplifies the problem of distributed sensing and actuation. And while the usual 1 Mbps may seem slow, it's usually more than enough after refresh rates of all bus members are calculated (and the transmission rate can always be increased, depending on bus length, impedance and whether your transceivers will allow it). There's also brilliant simulation software available, that basically guarantees worst case response times (for instance RealTime-at-work has a free CAN bus analyser called RTaW-Sim). And finally, it would seem the availability of MEMS sensors with integrated CAN is rather poor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another example where actuators are configured as a bus (or ring), is Dynamixels AX and MX series, where each motor is daisy chained to the next via a UART link. This greatly simplifies system design if you have a large amount of actuators.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But, to get back to the actual question, I think if you describe your system as real-time set points, instead of commands (eg rather continuously broadcast a motor angle than instructing a command such as goto angle), it simplifies the coupling between the 200 Hz and 30 Hz loop.&lt;/p&gt;&#xA;" OwnerUserId="1775" LastActivityDate="2013-08-07T13:36:08.673" />
  <row Id="1720" PostTypeId="2" ParentId="1712" CreationDate="2013-08-07T16:54:53.193" Score="2" Body="&lt;p&gt;Ian is absolutely right.  I've been in the RC hobby for years.  Your drivetrain/gearing is going to be your biggest factor into deciding inrunner vs. outrunner.  You must also consider your power source and figure out it's voltage and max current output and be sure it has enough capacity (typically measured in milliamp/hours).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To make things easier, I'd recommend buying a brushless SYSTEM so you don't have to worry when buying a separate ESC (electronic speed controller) and having it not be a good match for your motor choice.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Brushless motors are faster than you might think.  They can easily make RC cars go 50+ MPH.  You don't want to have something so fast you can't control it.  All said, I'd go with a properly powered and geared inrunner because I believe the large RPM range will allow greater control.  I've NEVER seen a radio controlled land vehicle use an outrunner brushless setup in all my years.  Good luck!&lt;/p&gt;&#xA;" OwnerUserId="1779" LastActivityDate="2013-08-07T16:54:53.193" CommentCount="1" />
  <row Id="1721" PostTypeId="2" ParentId="1717" CreationDate="2013-08-07T19:55:21.663" Score="2" Body="&lt;p&gt;The complementary filter you mentioned comprises of both a low-pass filter (which filters out, or attenuates, short term accelerometer fluctuations), as well as a high pass filter (which tries to negate the effect of drift on the gyroscope).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/GTkB0.jpg&quot; alt=&quot;Image copied from [http://www.chrismarion.net/index.php?option=com_content&amp;amp;view=article&amp;amp;id=122:the-segway-theory&amp;amp;catid=44:robotics](Chris Marion  - The Segway: Theory (Jan 2011))&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A time constant $\tau$ with respect to first order filters describes at what point (the cut-off frequency $f_{c}$) information should start being rejected (LPF) or stop being rejected (HPF). With respect to a complementary filter the time-constant used is the same for both the LPF as well as the HPF. The time constant can be thought of as boundary between trusting the gyroscope, and trusting the accelerometer.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The value of $a$, or the time constant, should be a function of your gyroscope's drift and accelerometer noise. You can optimize to filter out gyroscopic drift (HPF with slow cut-off), but then your accelerometer will allow too much accelerometer noise (LPF with slow cut-off).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As with all filter design, calculate the filter coefficients, test it to confirm it doesn't work, and randomly tweak it till it does.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Refer to the following links for more in depth discussion:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.chrismarion.net/index.php?option=com_content&amp;amp;view=article&amp;amp;id=122%3athe-segway-theory&amp;amp;catid=44%3arobotics&quot; rel=&quot;nofollow&quot;&gt;Marion, C. The Segway: Theory (Jan 2011)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://web.mit.edu/scolton/www/filter.pdf&quot; rel=&quot;nofollow&quot;&gt;Colton, S. A Simple Solution for Integrating Accelerometer and&#xA;Gyroscope Measurements for a Balancing Platform (June 2007)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="1775" LastEditorUserId="1775" LastEditDate="2013-08-07T20:11:06.873" LastActivityDate="2013-08-07T20:11:06.873" CommentCount="5" />
  <row Id="1724" PostTypeId="1" CreationDate="2013-08-08T03:40:20.787" Score="4" ViewCount="120" Body="&lt;p&gt;Need a way to dispense micro liter amounts of water (lets say 1-10ul). Only thing I've found is piezoelectric dispensers and they are &gt;$100. Any suggestions? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I can build, but preferably would be an off-the-shelf component.&lt;/p&gt;&#xA;" OwnerUserId="1782" LastActivityDate="2013-08-16T21:37:30.907" Title="Off-the-shelf micro fluid dispenser" Tags="&lt;electronics&gt;" AnswerCount="4" CommentCount="3" />
  <row Id="1727" PostTypeId="2" ParentId="1654" CreationDate="2013-08-08T07:18:59.660" Score="0" Body="&lt;p&gt;There are quite some definitions (see other questions) and even robot ontologies. I am with &lt;a href=&quot;http://en.wikipedia.org/wiki/Joseph_Engelberger&quot; rel=&quot;nofollow&quot;&gt;Joseph Engelberger&lt;/a&gt; (inventor of the first industrial robot &lt;a href=&quot;http://en.wikipedia.org/wiki/Unimate&quot; rel=&quot;nofollow&quot;&gt;Unimate&lt;/a&gt;):&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;I can't define a robot, but I know one when I see one.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Works quite well.&lt;/p&gt;&#xA;" OwnerUserId="157" LastEditorUserId="134" LastEditDate="2013-08-18T06:48:42.477" LastActivityDate="2013-08-18T06:48:42.477" />
  <row Id="1728" PostTypeId="1" AcceptedAnswerId="1971" CreationDate="2013-08-08T11:47:18.693" Score="2" ViewCount="163" Body="&lt;p&gt;I'm working on a robotics project, and I am using grayscale sensors to automatically follow a black line: turning 90 degrees, going round in a circle, and passing through gaps in the lines etc.  I was wondering what is an effective way to detect the colours and move it through the lines, with five or six grayscale sensors.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thank you very much.&lt;/p&gt;&#xA;" OwnerUserId="1783" LastEditorUserId="134" LastEditDate="2013-08-20T07:41:29.770" LastActivityDate="2013-11-12T10:11:08.047" Title="What is an effective distribution of grayscale sensors on robot" Tags="&lt;mobile-robot&gt;&lt;sensors&gt;&lt;automatic&gt;&lt;line-following&gt;" AnswerCount="2" CommentCount="3" />
  <row Id="1729" PostTypeId="1" CreationDate="2013-08-09T16:15:58.987" Score="8" ViewCount="110" Body="&lt;p&gt;I'm doing some groundwork for a project, and I have a question about the current state of SLAM techniques.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When a SLAM-equipped device detects an object, that object's position is stored. If you look at the point cloud the device is generating, you'll see points for this object, and models generated from it will include geometry here.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If an object is placed in a previously-empty space, it is detected, and points are added. Subsequent models will feature geometry describing this new object.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How does the device react if that object is removed? As far as I've seen, SLAM systems will tend to leave the points in place, resulting in &quot;ghost&quot; geometry. There are algorithms that will disregard lone points caused by transient contacts, but objects that remained long enough to build up a solid model will remain in the device's memory. Are there any systems that are capable of detecting that previously-occupied space is now empty?&lt;/p&gt;&#xA;" OwnerUserId="873" LastEditorUserId="134" LastEditDate="2013-08-12T18:52:25.430" LastActivityDate="2013-08-12T18:52:25.430" Title="How do SLAM algorithms handle a changing environment?" Tags="&lt;slam&gt;" AnswerCount="1" CommentCount="2" FavoriteCount="2" />
  <row Id="1730" PostTypeId="1" CreationDate="2013-08-10T08:47:59.637" Score="2" ViewCount="179" Body="&lt;p&gt;I'm trying to put together a simple simulation for a delta robot and I'd like to use forward kinematics (direct kinematics) to compute the end effector's position in space by passing 3 angles.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've started with the &lt;a href=&quot;http://forums.trossenrobotics.com/tutorials/introduction-129/delta-robot-kinematics-3276/&quot; rel=&quot;nofollow&quot;&gt;Trossen Robotics Forum Delta Robot Tutorial&lt;/a&gt; and I can understand most of the math, but not all. I'm lost at the last part in forward kinematics, when trying to compute the point where the 3 sphere's intersect. I've looked at spherical coordinates in general but couldn't work out the two angles used to find to rotate towards (to E(x,y,z)).&#xA;I see they're solving the equation of a sphere, but that's where I get lost. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can someone please 'dumb it down' for me ?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, I've used the example code to do a quick visualization using &lt;a href=&quot;http://processing.org/&quot; rel=&quot;nofollow&quot;&gt;Processing&lt;/a&gt;,&#xA;but the last part seems wrong. The lower leg changes length and it shouldn't:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;//Rhino measurements in cm&#xA;final float e = 21;//end effector side&#xA;final float f = 60.33;//base side&#xA;final float rf = 67.5;//upper leg length - radius of upper sphere&#xA;final float re = 95;//lower leg length - redius of lower sphere (with offset will join in E(x,y,z))&#xA;&#xA;final float sqrt3 = sqrt(3.0);&#xA;final float sin120 = sqrt3/2.0;   &#xA;final float cos120 = -0.5;        &#xA;final float tan60 = sqrt3;&#xA;final float sin30 = 0.5;&#xA;final float tan30 = 1/sqrt3;&#xA;final float a120 = TWO_PI/3;&#xA;final float a60 = TWO_PI/6;&#xA;&#xA;//bounds&#xA;final float minX = -200;&#xA;final float maxX = 200;&#xA;final float minY = -200;&#xA;final float maxY = 200;&#xA;final float minZ = -200;&#xA;final float maxZ = -10;&#xA;final float maxT = 54;&#xA;final float minT = -21;&#xA;&#xA;float xp = 0;&#xA;float yp = 0;&#xA;float zp =-45;&#xA;float t1 = 0;//theta&#xA;float t2 = 0;&#xA;float t3 = 0;&#xA;&#xA;float prevX;&#xA;float prevY;&#xA;float prevZ;&#xA;float prevT1;&#xA;float prevT2;&#xA;float prevT3;&#xA;&#xA;boolean validPosition;&#xA;//cheap arcball&#xA;PVector offset,cameraRotation = new PVector(),cameraTargetRotation = new PVector();&#xA;&#xA;void setup() {&#xA;  size(900,600,P3D);&#xA;}&#xA;&#xA;void draw() {&#xA;  background(192);&#xA;  pushMatrix();&#xA;  translate(width * .5,height * .5,300);&#xA;  //rotateY(map(mouseX,0,width,-PI,PI));&#xA;&#xA;  if (mousePressed &amp;amp;&amp;amp; (mouseX &amp;gt; 300)){&#xA;    cameraTargetRotation.x += -float(mouseY-pmouseY);&#xA;    cameraTargetRotation.y +=  float(mouseX-pmouseX);&#xA;  }&#xA;  rotateX(radians(cameraRotation.x -= (cameraRotation.x - cameraTargetRotation.x) * .35));&#xA;  rotateY(radians(cameraRotation.y -= (cameraRotation.y - cameraTargetRotation.y) * .35));&#xA;&#xA;  stroke(0);&#xA;  et(f,color(255));&#xA;  drawPoint(new PVector(),2,color(255,0,255));&#xA;  float[] t = new float[]{t1,t2,t3};&#xA;  for(int i = 0 ; i &amp;lt; 3; i++){&#xA;    float a = HALF_PI+(radians(120)*i);&#xA;    float r1 = f / 1.25 * tan(radians(30));&#xA;    float r2 = e / 1.25 * tan(radians(30));&#xA;    PVector F = new PVector(cos(a) * r1,sin(a) * r1,0);&#xA;    PVector E = new PVector(cos(a) * r2,sin(a) * r2,0);&#xA;    E.add(xp,yp,zp);&#xA;    //J = F * rxMat&#xA;    PMatrix3D m = new PMatrix3D();&#xA;    m.translate(F.x,F.y,F.z);&#xA;    m.rotateZ(a);&#xA;    m.rotateY(radians(t[i]));&#xA;    m.translate(rf,0,0);&#xA;&#xA;    PVector J = new PVector();&#xA;    m.mult(new PVector(),J);&#xA;    line(F.x,F.y,F.z,J.x,J.y,J.z);&#xA;    line(E.x,E.y,E.z,J.x,J.y,J.z);&#xA;    drawPoint(F,2,color(255,0,0));&#xA;    drawPoint(J,2,color(255,255,0));&#xA;    drawPoint(E,2,color(0,255,0));&#xA;    //println(dist(F.x,F.y,F.z,J.x,J.y,J.z)+&quot;\t&quot;+rf);&#xA;    println(dist(E.x,E.y,E.z,J.x,J.y,J.z)+&quot;\t&quot;+re);//length should not change&#xA;  }&#xA;  pushMatrix();&#xA;    translate(xp,yp,zp);&#xA;    drawPoint(new PVector(),2,color(0,255,255));&#xA;    et(e,color(255));&#xA;    popMatrix();&#xA;  popMatrix(); &#xA;}&#xA;void drawPoint(PVector p,float s,color c){&#xA;  pushMatrix();&#xA;    translate(p.x,p.y,p.z);&#xA;    fill(c);&#xA;    box(s);&#xA;  popMatrix();&#xA;}&#xA;void et(float r,color c){//draw equilateral triangle, r is radius ( median), c is colour&#xA;  pushMatrix();&#xA;  rotateZ(-HALF_PI);&#xA;  fill(c);&#xA;  beginShape();&#xA;  for(int i = 0 ; i &amp;lt; 3; i++)&#xA;    vertex(cos(a120*i) * r,sin(a120*i) * r,0);&#xA;  endShape(CLOSE);&#xA;  popMatrix();&#xA;}&#xA;void keyPressed(){&#xA;  float amt = 3;&#xA;  if(key == 'q') t1 -= amt;&#xA;  if(key == 'Q') t1 += amt;&#xA;  if(key == 'w') t2 -= amt;&#xA;  if(key == 'W') t2 += amt;&#xA;  if(key == 'e') t3 -= amt;&#xA;  if(key == 'E') t3 += amt;&#xA;  t1 = constrain(t1,minT,maxT);&#xA;  t2 = constrain(t2,minT,maxT);&#xA;  t3 = constrain(t3,minT,maxT);&#xA;  dk();&#xA;}&#xA;&#xA;void ik() {&#xA;  if (xp &amp;lt; minX) { xp = minX; }&#xA;  if (xp &amp;gt; maxX) { xp = maxX; }&#xA;  if (yp &amp;lt; minX) { yp = minX; }&#xA;  if (yp &amp;gt; maxX) { yp = maxX; }&#xA;  if (zp &amp;lt; minZ) { zp = minZ; }&#xA;  if (zp &amp;gt; maxZ) { zp = maxZ; }&#xA;&#xA;  validPosition = true;&#xA;  //set the first angle&#xA;  float theta1 = rotateYZ(xp, yp, zp);&#xA;  if (theta1 != 999) {&#xA;    float theta2 = rotateYZ(xp*cos120 + yp*sin120, yp*cos120-xp*sin120, zp);  // rotate coords to +120 deg&#xA;    if (theta2 != 999) {&#xA;      float theta3 = rotateYZ(xp*cos120 - yp*sin120, yp*cos120+xp*sin120, zp);  // rotate coords to -120 deg&#xA;      if (theta3 != 999) {&#xA;        //we succeeded - point exists&#xA;        if (theta1 &amp;lt;= maxT &amp;amp;&amp;amp; theta2 &amp;lt;= maxT &amp;amp;&amp;amp; theta3 &amp;lt;= maxT &amp;amp;&amp;amp; theta1 &amp;gt;= minT &amp;amp;&amp;amp; theta2 &amp;gt;= minT &amp;amp;&amp;amp; theta3 &amp;gt;= minT ) { //bounds check&#xA;          t1 = theta1;&#xA;          t2 = theta2;&#xA;          t3 = theta3;&#xA;        } else {&#xA;          validPosition = false;&#xA;        }&#xA;&#xA;      } else {&#xA;        validPosition = false;&#xA;      }&#xA;    } else {&#xA;      validPosition = false;&#xA;    }&#xA;  } else {&#xA;    validPosition = false;&#xA;  }&#xA;&#xA;  //uh oh, we failed, revert to our last known good positions&#xA;  if ( !validPosition ) {&#xA;    xp = prevX;&#xA;    yp = prevY;&#xA;    zp = prevZ;&#xA;  }&#xA;&#xA;}&#xA;&#xA;void dk() {&#xA;  validPosition = true;&#xA;&#xA;  float t = (f-e)*tan30/2;&#xA;  float dtr = PI/(float)180.0;&#xA;&#xA;  float theta1 = dtr*t1;&#xA;  float theta2 = dtr*t2;&#xA;  float theta3 = dtr*t3;&#xA;&#xA;  float y1 = -(t + rf*cos(theta1));&#xA;  float z1 = -rf*sin(theta1);&#xA;&#xA;  float y2 = (t + rf*cos(theta2))*sin30;&#xA;  float x2 = y2*tan60;&#xA;  float z2 = -rf*sin(theta2);&#xA;&#xA;  float y3 = (t + rf*cos(theta3))*sin30;&#xA;  float x3 = -y3*tan60;&#xA;  float z3 = -rf*sin(theta3);&#xA;&#xA;  float dnm = (y2-y1)*x3-(y3-y1)*x2;&#xA;&#xA;  float w1 = y1*y1 + z1*z1;&#xA;  float w2 = x2*x2 + y2*y2 + z2*z2;&#xA;  float w3 = x3*x3 + y3*y3 + z3*z3;&#xA;&#xA;  // x = (a1*z + b1)/dnm&#xA;  float a1 = (z2-z1)*(y3-y1)-(z3-z1)*(y2-y1);&#xA;  float b1 = -((w2-w1)*(y3-y1)-(w3-w1)*(y2-y1))/2.0;&#xA;&#xA;  // y = (a2*z + b2)/dnm;&#xA;  float a2 = -(z2-z1)*x3+(z3-z1)*x2;&#xA;  float b2 = ((w2-w1)*x3 - (w3-w1)*x2)/2.0;&#xA;&#xA;  // a*z^2 + b*z + c = 0&#xA;  float a = a1*a1 + a2*a2 + dnm*dnm;&#xA;  float b = 2*(a1*b1 + a2*(b2-y1*dnm) - z1*dnm*dnm);&#xA;  float c = (b2-y1*dnm)*(b2-y1*dnm) + b1*b1 + dnm*dnm*(z1*z1 - re*re);&#xA;&#xA;  // discriminant&#xA;  float d = b*b - (float)4.0*a*c;&#xA;  if (d &amp;lt; 0) { validPosition = false; }&#xA;&#xA;  zp = -(float)0.5*(b+sqrt(d))/a;&#xA;  xp = (a1*zp + b1)/dnm;&#xA;  yp = (a2*zp + b2)/dnm;&#xA;&#xA;  if (xp &amp;gt;= minX &amp;amp;&amp;amp; xp &amp;lt;= maxX&amp;amp;&amp;amp; yp &amp;gt;= minX &amp;amp;&amp;amp; yp &amp;lt;= maxX &amp;amp;&amp;amp; zp &amp;gt;= minZ &amp;amp; zp &amp;lt;= maxZ) {  //bounds check&#xA;  } else {&#xA;    validPosition = false;&#xA;  }&#xA;&#xA;  if ( !validPosition ) {    &#xA;    xp = prevX;&#xA;    yp = prevY;&#xA;    zp = prevZ;&#xA;    t1 = prevT1;&#xA;    t2 = prevT2;&#xA;    t3 = prevT3;  &#xA;  }&#xA;&#xA;}&#xA;&#xA;void  storePrev() {&#xA;  prevX = xp;&#xA;  prevY = yp;&#xA;  prevZ = zp;&#xA;  prevT1 = t1;&#xA;  prevT2 = t2;&#xA;  prevT3 = t3;&#xA;}&#xA;&#xA;float rotateYZ(float x0, float y0, float z0) {&#xA;  float y1 = -0.5 * 0.57735 * f; // f/2 * tg 30&#xA;  y0 -= 0.5 * 0.57735    * e;    // shift center to edge&#xA;  // z = a + b*y&#xA;  float a = (x0*x0 + y0*y0 + z0*z0 +rf*rf - re*re - y1*y1)/(2*z0);&#xA;  float b = (y1-y0)/z0;&#xA;  // discriminant&#xA;  float d = -(a+b*y1)*(a+b*y1)+rf*(b*b*rf+rf); &#xA;  if (d &amp;lt; 0) return 999; // non-existing point&#xA;  float yj = (y1 - a*b - sqrt(d))/(b*b + 1); // choosing outer point&#xA;  float zj = a + b*yj;&#xA;  return 180.0*atan(-zj/(y1 - yj))/PI + ((yj&amp;gt;y1)?180.0:0.0);&#xA;} &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="269" LastActivityDate="2013-08-10T08:47:59.637" Title="How to correctly compute direct kinematics for a delta robot?" Tags="&lt;kinematics&gt;&lt;forward-kinematics&gt;" CommentCount="6" />
  <row Id="1732" PostTypeId="2" ParentId="1724" CreationDate="2013-08-10T17:04:12.840" Score="4" Body="&lt;p&gt;It may be practical to adapt some ink-jet printer heads to dispense water.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;An ink-jet printer head projects a stream of droplets.  Droplet volume varies widely among printers; typically, it's smaller in newer printers.  Eg, a fairly-comprehensive 1998 &lt;a href=&quot;http://www.imaging.org/ist/resources/tutorials/inkjet.cfm&quot; rel=&quot;nofollow&quot;&gt;inkjet tutorial&lt;/a&gt; at imaging.org says early HP 800-series ink-jets produced 6000 drops per second with 32 pL per drop, which works out to about 5.2 seconds to deliver 1 µL of ink.  (I don't know if the DPS is per nozzle or per head.) The later 890C with a 192-nozzle head produced 12000 drops per second with 10 pL per drop, or about 8.3 s to deliver 1 µL of ink.  As noted in a 2010 &lt;a href=&quot;http://blogs.computerworld.com/16162/hp_explains_why_printer_ink_is_so_expensive&quot; rel=&quot;nofollow&quot;&gt;computerworld.com blog&lt;/a&gt;, the “Photosmart 8250 uses 3,900 nozzles to deliver 122 million drops per second onto the paper.”&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(Note, with a &lt;a href=&quot;http://en.wikipedia.org/wiki/Inkjet_printing#Drop-on-demand&quot; rel=&quot;nofollow&quot;&gt;drop-on-demand&lt;/a&gt; printhead, you could count drops – that is, control the number of pulses –  vs turning the head on for a timed interval.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;An article called &lt;a href=&quot;http://www.labautopedia.org/mw/index.php/Non-Contact_Liquid_Handling%3a_Basics_and_Technologies&quot; rel=&quot;nofollow&quot;&gt;Non-Contact Liquid Handling: Basics and Technologies&lt;/a&gt; at labautopedia.org gives a good introduction to several techniques now in use for delivering small amounts of liquid.  Among other topics it covers physics of &#xA;droplet formation and illustrates several valving techniques.  Another useful survey, “Dispensing systems for miniaturized diagnostics”, is at &lt;a href=&quot;http://www.ivdtechnology.com/article/dispensing-systems-miniaturized-diagnostics&quot; rel=&quot;nofollow&quot;&gt;ivdtechnology.com&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The &lt;a href=&quot;http://en.wikipedia.org/wiki/Inkjet_printing&quot; rel=&quot;nofollow&quot;&gt;wikipedia inkjet article&lt;/a&gt; referenced earlier and a &lt;a href=&quot;http://en.wikipedia.org/wiki/Microdispensing&quot; rel=&quot;nofollow&quot;&gt;wikipedia microdispensing article&lt;/a&gt; are helpful but seem superficial compared to the imaging.org and labautopedia.org articles.  Also see an &lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pubmed/17588671&quot; rel=&quot;nofollow&quot;&gt;nlm.nih.gov article&lt;/a&gt; about dispensing an enzyme-conjugated solution into an ELISA plate by adapting ink-jet printers, by Lonini et al.&lt;/p&gt;&#xA;" OwnerUserId="478" LastEditorUserId="478" LastEditDate="2013-08-10T17:12:24.183" LastActivityDate="2013-08-10T17:12:24.183" />
  <row Id="1735" PostTypeId="2" ParentId="1729" CreationDate="2013-08-12T14:08:07.957" Score="4" Body="&lt;p&gt;That very much depends. Since SLAM is a problem (or at least a technique), not a solution, there is no definitive SLAM algorithm.  Semantically, you have to decide what goes on a &quot;map&quot; of the environment, and that determines how your algorithm should handle transient (aka moving) signals. But that's a digression.&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Permanent maps:&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Permanent maps should contain enough information to localize yourself with respect to known geometry. Typically used in buildings. Typically human-readable. See Willow-Garage's work. or anything by Thrun in his quite famous textbook. If you lose this map, you have to build it up over time again. &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;Removing objects. Yes, the object will appear in a static map for a time. If no measures are taken to remove previously-detected objects, then it will persist. A typical 2D grid-based representation will use each grid cell to represent the probability of an object, so after time the object will &quot;fade&quot;.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Adding objects. Same as above.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;h3&gt;Local maps:&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;In reality, SLAM is usually used to localize a robot as it moves, and the map is not kept permanently (or, it is kept permanently, but only the closest Y features are used). Local maps are whatever the robot needs to know to determine how it moved in the last X minutes, where X depends on the application. If you lose the map, you can still fly just fine by using whatever features are in sight right now. &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;Batch methods such as Bundle Adjustment using visual features is a very common technique in this direction. Features may be kept over time, and even revisited, but a moving feature is just an unreliable feature, and it will be ignored when trying to figure out where the robot is.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Visual SLAM is exactly this. It is a delta-P (change in pose) estimator, not a map-based localization algorithm. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;In short, as long as most things are &lt;em&gt;not currently&lt;/em&gt; moving, it doesn't matter if you remove an object when the robot isn't &quot;looking&quot; at it.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;h3&gt;Example&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;So do this. When you read a SLAM paper, decide the following:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;Are they really building a map?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Are they just keeping a list of features and locations?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;If so, what &quot;features&quot; go in the map? Lines, points, visual features?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Are these features likely to move? &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;If so, how can they handle that?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Finally, sensor noise often &quot;looks&quot; like moving features. How do they handle sensor noise? Because this will often determine what happens to moving features.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;You'll get a different answer for each paper / author / book / application. In short, they are typically omitted since they don't help the robot localize much, and can be avoided by simply having a few low-level path planner that only uses local information. &lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Good luck, slam is a huge topic.&lt;/h3&gt;&#xA;" OwnerUserId="163" LastEditorUserId="163" LastEditDate="2013-08-12T14:13:50.577" LastActivityDate="2013-08-12T14:13:50.577" CommentCount="8" />
  <row Id="1736" PostTypeId="2" ParentId="1724" CreationDate="2013-08-12T15:06:00.130" Score="0" Body="&lt;p&gt;Just how precise do you need to be? We build medical instruments and a $100 pump would be considered pretty damn cheap around here. The most common technology is a syringe pump controlled by a stepper motor, but for precise, very repeatable dispense, fluid dynamic effects have to be considered. e.g., wicking off the droplet at the probe tip can have a dramatic impact on accuracy.&lt;/p&gt;&#xA;" OwnerUserId="794" LastActivityDate="2013-08-12T15:06:00.130" />
  <row Id="1737" PostTypeId="1" CreationDate="2013-08-12T18:00:51.573" Score="0" ViewCount="191" Body="&lt;p&gt;I want to use my atmega8 uC as a &lt;a href=&quot;/questions/tagged/h-bridge&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged 'h-bridge'&quot; rel=&quot;tag&quot;&gt;h-bridge&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can anybody give me the source code using C, so that the microcontroller acts as an H-Bridge.&lt;/p&gt;&#xA;" OwnerUserId="1799" LastEditorUserId="134" LastEditDate="2013-08-12T18:47:34.567" LastActivityDate="2013-08-13T23:44:35.437" Title="H-Bridge using atmega8 microcontroller" Tags="&lt;microcontroller&gt;&lt;c&gt;&lt;atmega&gt;&lt;h-bridge&gt;" AnswerCount="2" CommentCount="3" />
  <row Id="1738" PostTypeId="2" ParentId="1737" CreationDate="2013-08-12T21:56:39.593" Score="0" Body="&lt;p&gt;I'm not really familiar with Atmel microcontrollers, but I'm assuming you're using some Arduino variant. &lt;a href=&quot;http://itp.nyu.edu/physcomp/Labs/DCMotorControl&quot; rel=&quot;nofollow&quot;&gt;Here's a pretty thorough tutorial about using an Arduino with a SN754410 h-bridge&lt;/a&gt; (found it via the SN754410 Sparkfun entry). It seems the only thing the tutorial lacks is controlling the motors via PWM, which of course means you will only be able to control the motors direction, and whether the motor is on or off. Just google Arduino PWM, I'm sure there's loads of code examples. [Update] &lt;a href=&quot;http://learn.adafruit.com/adafruit-arduino-lesson-15-dc-motor-reversing?view=all&quot; rel=&quot;nofollow&quot;&gt;See also Adafruit Arduino tutorials&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One thing to keep in mind is to never enable both directional signals at the same time (which obviously causes a straight short across your motor rail). One way of ensuring this never happens is by using only one micro-controller output (eg &lt;code&gt;MOTOR_DIR_FORWARD&lt;/code&gt;), and then feeding that into a not-gate, and then into your other directional signal (in other words, instead of having a motor enable ouput, and two directional outputs, you'll only have a motor enable output, and a single directional output).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also remember that if your motors and micro are running off the same supply that insufficient decoupling may cause your micro to reset.&lt;/p&gt;&#xA;" OwnerUserId="1775" LastEditorUserId="1775" LastEditDate="2013-08-12T22:12:18.823" LastActivityDate="2013-08-12T22:12:18.823" />
  <row Id="1740" PostTypeId="2" ParentId="1724" CreationDate="2013-08-13T18:24:50.087" Score="1" Body="&lt;p&gt;If your goal is to dispense a single reagent (water), then you are best off using a microdispensing valve based solution. I do not know that you will find something for less than $100, but if you went that route, you would be looking for parts like &lt;a href=&quot;http://www.theleecoefs.com/EFSWEB2.NSF/MDG!OpenView&quot; rel=&quot;nofollow&quot;&gt;this&lt;/a&gt;. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are other technologies out there (syringe based, capillary action based, pipette based), but none are suited as well as a microdispensing valve for bulk reagent dispensing in the 1-10uL volume range. You can find more technical information about microdispensing &lt;a href=&quot;http://www.theleecoefs.com/PDF.nsf/bdb21d9b7952d46a85256a400071dc4c/e9c48210dfa8354f85256cc4004de470/%24FILE/VHS-STARTER%20KIT%20MANUAL-B2.pdf&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="1800" LastActivityDate="2013-08-13T18:24:50.087" />
  <row Id="1741" PostTypeId="2" ParentId="1132" CreationDate="2013-08-13T23:08:24.927" Score="2" Body="&lt;p&gt;It really depends what you want to learn and how you learn. Robotics is a pretty wide field. Do you want to learn machine vision? Control systems? Kinematics? Starting with (insert microcontroller here) as others have recommended may be fine, but it may also be too open ended for some folks. Ok, so you have an Arduino and some components, now what? Do you add a motor? Sensors? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;My personal experience in teaching robotics to others would be to pick a specific robotics project that you find interesting and determine what tools you need to implement that specific project. That's not to say the project will not change once you start, but at least you have a goal to guide you instead of randomly assembling parts. Note that many of the good kits out there now already include curriculum based around building a specific project or robot, so you do not have to come up with the project yourself. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ok, so now you have a project and the question becomes how do you find the tools? Here are the specifics that I look for when sourcing something like this:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Availability of technical documentation (product manuals, examples, source code, curriculum). Are the parts coming with sufficient documentation to get you started and give you an idea of what to do with them? Something like the LEGO Mindstorms has a book with a number of distinct projects to choose from. If the company has their act together, you can check this out before purchasing a single thing by downloading the documentation directly from their website (this is also a great test of their support system!)&lt;/li&gt;&#xA;&lt;li&gt;Does the product have an active user community? User communities can be great resources for troubleshooting, getting ideas, etc. Companies like LEGO and Parallax host discussion forums right on their website.&lt;/li&gt;&#xA;&lt;li&gt;Has the product been iterated upon? Most of the successful kits have been revised over time (see LEGO Mindstorms), this is usually a good sign. &lt;/li&gt;&#xA;&lt;li&gt;Is the software that goes with the product maintained and kept up to date? Go to the support section of the company website and navigate to the software downloads section. If the last software update for the product is many years old, look elsewhere. &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="1800" LastEditorUserId="1800" LastEditDate="2013-08-13T23:13:38.810" LastActivityDate="2013-08-13T23:13:38.810" />
  <row Id="1742" PostTypeId="2" ParentId="1737" CreationDate="2013-08-13T23:44:35.437" Score="1" Body="&lt;p&gt;It is not possible to use the micro-controller directly as an H-Bridge. A micro-controller is a micro-controller and an H-bridge is an H-bridge. You need both of them to control a motor (or something equivalent).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I will suppose that you are using motors and not servo. Let's say you want to use your micro-controller as an H-bridge. You have two cables from the motor. One for the ground and the other one for the current. When both of them are plugged, how are you going to wired it to the micro-controller to control the motor ? Or are you going to wire directly the current supply wire to the micro-controller ?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The thing is you will not be able to input enough current to move the motor with just the pin of a micro-controller. You will need another source of current and thus, something to control it, if you want to control the direction and speed of your motor. That's where the H-bridge is used.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You should read some documentation about &lt;a href=&quot;http://en.wikipedia.org/wiki/H_bridge&quot; rel=&quot;nofollow&quot;&gt;H-Bridge&lt;/a&gt;, it's not that complicated to understand.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And if you really want not to use H-Bridge, you can create one with &lt;a href=&quot;http://www.instructables.com/id/H-Bridge-on-a-Breadboard/&quot; rel=&quot;nofollow&quot;&gt;transistors&lt;/a&gt; on the bread-board. That tutorial is pretty good for that.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If in the end you want to use H-Bridge, the &lt;a href=&quot;http://itp.nyu.edu/physcomp/Labs/DCMotorControl&quot; rel=&quot;nofollow&quot;&gt;tutorial&lt;/a&gt; that EDDY74 gave you is perfect for that. Really simple and easy to understand. To, then, control the motor via a PWM is fairly easy since you just have to modulate the enable pin or the motor logic pins (I guess it depend on the H-bridge you are using).&#xA;There a &lt;a href=&quot;http://forum.arduino.cc/index.php/topic,9522.0.html&quot; rel=&quot;nofollow&quot;&gt;discussion&lt;/a&gt; about speed control on the Arduino forum.&lt;/p&gt;&#xA;" OwnerUserId="1615" LastActivityDate="2013-08-13T23:44:35.437" />
  <row Id="1743" PostTypeId="1" AcceptedAnswerId="1744" CreationDate="2013-08-14T08:20:38.523" Score="1" ViewCount="503" Body="&lt;p&gt;I am using SIM900A for some purpose and want to know the number of the sender from where a message comes. I am unable to find the specific AT command related to receiving message which give me number from where latest message comes.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I had used AT+CNMI (it corresponds to notification regarding latest received message), but am unable to find sender number.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I had seen AT+CMGL=&amp;lt;stat&amp;gt;[,&amp;lt;mode&amp;gt;] will give you a string which will have oa i.e. originating address and once that is stored in a string I can easily parse it out, but when I had data format of that string. Need help or any suggestion if somebody can help me out with any other possible solution.&lt;/p&gt;&#xA;" OwnerUserId="1322" LastEditorUserId="1177" LastEditDate="2013-12-31T16:58:03.877" LastActivityDate="2013-12-31T16:58:03.877" Title="AT command in SIM900A GSM/GPRS module to find out originating address of an SMS" Tags="&lt;arduino&gt;&lt;microcontroller&gt;" AnswerCount="1" />
  <row Id="1744" PostTypeId="2" ParentId="1743" CreationDate="2013-08-14T09:26:57.180" Score="1" Body="&lt;h3&gt;Text mode vs PDU mode&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;The SIM900 module supports both text and PDU mode. Please note that some AT commands have different syntax depending on which mode is currently active. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;To check which mode is currently active (0: PDU mode, 1: Text mode):&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt; AT+CMGF?&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h3&gt;Retrieving SMS's&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;You can use the CMGL command to retrieve unread, read, stored unsent, stored sent, or all messages.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If text mode is currently selected:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt; AT+CMGL=STAT,MODE&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Parameters:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;STAT:&#xA;   &quot;REC UNREAD&quot;  Received unread messages&#xA;   &quot;REC READ&quot;    Received read messages&#xA;   &quot;STO UNSENT&quot;  Stored unsent messages&#xA;   &quot;STO SENT&quot;    Stored sent messages&#xA;   &quot;ALL&quot;         All messages&#xA;MODE: (OPTIONAL)&#xA;   0 Normal&#xA;   1 Not change status of the specified SMS record&#xA;&#xA;In other words, the following command should print all SMS messages:&#xA;&#xA;   AT+CMGL=&quot;ALL&quot;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;If PDU mode is currently selected:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt; AT+CMGL=STAT,MODE&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Parameters:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;STAT:&#xA;   0  Received unread messages&#xA;   1  Received read messages&#xA;   2  Stored unsent messages&#xA;   3  Stored sent messages&#xA;   4  All messages&#xA;MODE: (OPTIONAL)&#xA;   0 Normal&#xA;   1 Not change status of the specified SMS record&#xA;&#xA;In other words, the following command should print all SMS messages:&#xA;&#xA;   AT+CMGL=4&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h3&gt;Example&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;If text mode is currently selected, and a CMGL command is issued, the following is an example of what could be expected (note there's a line break before the actual message starts).&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;AT+CMGL=&quot;ALL&quot;&#xA;+CMGL: 1,&quot;REC READ&quot;,&quot;+85291234567&quot;,,&quot;07/05/01,08:00:15+32&quot;,145,37&#xA;It is easy to list SMS text messages.&#xA;&#xA;     1                      : Message index&#xA;     &quot;REC READ&quot;             : Message status (it's been read before)&#xA;     &quot;+85291234567&quot;         : Source number (ie the person that sent you the sms)&#xA;     &quot;07/05/01,08:00:15+32&quot; : Service center timestamp&#xA;     145                    : Character set&#xA;     37                     : Length of message&#xA;&#xA;Refer to Section 4.2.3, page 99, of the SIM900 AT command set for more information.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h3&gt;External links&lt;/h3&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.cooking-hacks.com/skin/frontend/default/cooking/pdf/SIM900_AT_Command_Manual.pdf&quot; rel=&quot;nofollow&quot;&gt;SIM900A AT Command set (V1.05: 2011-10-24)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.developershome.com/sms/checkCommandSupport.asp&quot; rel=&quot;nofollow&quot;&gt;Developers home — Tutorials regarding AT commands&lt;/a&gt; (I'd strongly recommend you take some time and go through the tutorials — especially sections 18 to 26)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="1775" LastEditorUserId="1177" LastEditDate="2013-12-31T16:57:56.517" LastActivityDate="2013-12-31T16:57:56.517" />
  <row Id="1745" PostTypeId="1" AcceptedAnswerId="1747" CreationDate="2013-08-14T11:48:18.233" Score="0" ViewCount="59" Body="&lt;p&gt;I am planning to build a robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;1) What free or low cost robot modelling tools exist.&lt;/p&gt;&#xA;" OwnerUserId="1813" LastActivityDate="2013-08-16T17:26:03.963" Title="What modelling tools are available to design a robot" Tags="&lt;design&gt;" AnswerCount="1" FavoriteCount="2" ClosedDate="2013-08-16T13:37:46.303" />
  <row Id="1746" PostTypeId="2" ParentId="1538" CreationDate="2013-08-14T12:20:45.840" Score="3" Body="&lt;p&gt;I think a more compact and reliable solution would be to use a third shaft that is perpendicular to the other two (on the Z-axis)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Given the shaft moving up/down is moving on the Y-axis and the shaft moving left/right is moving on the X-axis.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This crude diagram should explain things better.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As the motor turns Shaft A upwards it then turns Shaft C. Shaft C then moves Shaft B left and right  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The addition of Shaft C would make this vertical to horizontal conversion precise and compact.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note that the only rotating parts are Shafts A and C. Shaft B would only move left and right.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And unlike Kurts answer there's no need for messy joints at the end of each shaft.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/8Z17O.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="1610" LastEditorUserId="1610" LastEditDate="2013-08-15T11:45:16.637" LastActivityDate="2013-08-15T11:45:16.637" />
  <row Id="1747" PostTypeId="2" ParentId="1745" CreationDate="2013-08-14T16:36:17.253" Score="1" Body="&lt;p&gt;Here are some that I know of:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Solidworks student edition: &#xA;&lt;a href=&quot;http://www.solidworks.com/sw/education/cad-faq-students.htm&quot; rel=&quot;nofollow&quot;&gt;http://www.solidworks.com/sw/education/cad-faq-students.htm&lt;/a&gt;&#xA;(Free for students who use a school's privately assigned password, otherwise $149)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;AutoCAD Student version: &lt;a href=&quot;http://students.autodesk.com/&quot; rel=&quot;nofollow&quot;&gt;http://students.autodesk.com/&lt;/a&gt; (Free for students)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Google Sketchup: &lt;a href=&quot;http://www.sketchup.com/products/sketchup-make&quot; rel=&quot;nofollow&quot;&gt;http://www.sketchup.com/products/sketchup-make&lt;/a&gt; (Free)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;FreeCAD: &lt;a href=&quot;http://www.freecadweb.org/&quot; rel=&quot;nofollow&quot;&gt;http://www.freecadweb.org/&lt;/a&gt; (Free)&lt;/p&gt;&#xA;" OwnerUserId="983" LastEditorUserId="983" LastEditDate="2013-08-16T17:26:03.963" LastActivityDate="2013-08-16T17:26:03.963" />
  <row Id="1748" PostTypeId="2" ParentId="1514" CreationDate="2013-08-15T11:58:22.200" Score="0" Body="&lt;p&gt;You need to use a PID algorithm to control the speed of the motors, that way you'll be able to make them spin as slow as you need while still getting torque. The PID algorithm needs to measure the speed of your motor somehow, the typical way is to place some optical encoders in the wheels, this is a must for any rover and besides giving you the speed will give you a very good estimate of the position, which helps navigate and make turns.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can steal the optical encodes from an old mouse, those with a ball. &lt;/p&gt;&#xA;" OwnerUserId="1816" LastEditorUserId="134" LastEditDate="2013-08-16T13:38:23.540" LastActivityDate="2013-08-16T13:38:23.540" CommentCount="1" />
  <row Id="1749" PostTypeId="2" ParentId="1670" CreationDate="2013-08-15T16:22:27.460" Score="0" Body="&lt;p&gt;Sugru is great for this kind of thing, but it can be a little pricey. An alternative is &lt;a href=&quot;http://www.instructables.com/id/How-To-Make-Your-Own-Sugru-Substitute/&quot; rel=&quot;nofollow&quot;&gt;Oogoo&lt;/a&gt;, a DIY mixture of silicone caulk, cornstarch, and (optional) pigment.&lt;/p&gt;&#xA;" OwnerUserId="1174" LastActivityDate="2013-08-15T16:22:27.460" />
  <row Id="1750" PostTypeId="1" CreationDate="2013-08-16T03:29:25.240" Score="3" ViewCount="219" Body="&lt;p&gt;I have been studying about building a tricopter.  But I couldn't find the design calculations or mathematical modeling of the tricopter any where over the internet. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What are the mathematical relationships or equations of motion and forces in tricopter?  How do I calculate the requirements of the structural design and the energy requirements of the motors?&lt;/p&gt;&#xA;" OwnerUserId="1820" LastEditorUserId="350" LastEditDate="2013-08-27T18:49:15.090" LastActivityDate="2013-08-31T17:43:20.310" Title="Design Calculations &amp; Mathematical Modeling of Tricopters" Tags="&lt;design&gt;" AnswerCount="1" CommentCount="0" FavoriteCount="1" />
  <row Id="1751" PostTypeId="2" ParentId="1711" CreationDate="2013-08-16T03:29:34.177" Score="2" Body="&lt;p&gt;I have a bot with 2 independently driven wheels. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I chose to use a gyro to keep it heading in the desired direction, bumps slippage and even picking it up and turning it around are of little consequence to it as it will just correct it's heading.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I use a single PID, which adds/subtracts a correction to the desired current speed for each of the 2 motors in accordance with the error in the current heading (direction) as determined by the gyro.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example I set the speed to 50% and the heading to 20degrees. this would normally drive both motors at 50% power. but as the heading wanders off, the PID will make adjustments adding some power to one motor and removing some power from the other, so you might end up with a 45%/55% power split between the motors as the pid corrects the heading.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Gyros have their problems though, even with some time spent calibrating I'm still finding my gryo has about 1 degree per minute drift.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As previously stated encoders on the wheels are a great idea for actually knowing how far you have traveled.&lt;/p&gt;&#xA;" OwnerUserId="1819" LastActivityDate="2013-08-16T03:29:34.177" />
  <row Id="1752" PostTypeId="2" ParentId="1750" CreationDate="2013-08-16T08:20:31.670" Score="1" Body="&lt;p&gt;I found the following paper, &lt;a href=&quot;http://liu.diva-portal.org/smash/get/diva2:538067/FULLTEXT01.pdf&quot; rel=&quot;nofollow&quot;&gt;Model Predictive Control of a Tricopter (Barsk, J. 2012)&lt;/a&gt; quite helpful.&lt;/p&gt;&#xA;" OwnerUserId="1775" LastEditorUserId="37" LastEditDate="2013-08-31T17:43:20.310" LastActivityDate="2013-08-31T17:43:20.310" CommentCount="2" />
  <row Id="1753" PostTypeId="1" AcceptedAnswerId="1805" CreationDate="2013-08-16T08:40:44.710" Score="2" ViewCount="171" Body="&lt;p&gt;This might be a out of league question and may seems to be very odd.I am using multiple Arduino UNO boards over network and want to assign a GUID and Serial number to each board so that when ever they send any data to a central server, server is able to find which Device it is if we have assign name for each device.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;first way to do this is to assign GUID and serial number of device before each message that is send to central server manually while programming and then burn that hex to arduino.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Now is there any way out that we can burn a program that always give a output as a string (GUID+Serial number of device) like we program EEPROM for this and then burn our main code in Arduino which pick the GUID+Serial ID combo from EEPROM and write it before every message which arduino is pushing to central server.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Or my another way of asking is can we program EEPROM with a different program and our Arduino separately like 2 files running in parallel or is it not possible?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there any other way of doing this?&lt;/p&gt;&#xA;" OwnerUserId="1322" LastActivityDate="2013-09-03T12:50:26.717" Title="Assigning Serial number and GUID to a microcontroller" Tags="&lt;arduino&gt;&lt;microcontroller&gt;&lt;communication&gt;" AnswerCount="2" CommentCount="2" />
  <row Id="1754" PostTypeId="2" ParentId="1753" CreationDate="2013-08-16T15:31:04.327" Score="3" Body="&lt;p&gt;The answer to this question depends entirely on the type of connection you are using to build your network.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Assuming that when you say you have arduinos &quot;on a network&quot; you are using ethernet shields or similar to put them on an ethernet network, one way to accomplish your goal would be to take advantage of the MAC address on the ethernet shield as this is a pre-existing globally-unique identifier. The MAC address is appended to every ethernet &lt;em&gt;frame&lt;/em&gt;. Now, you only have access to that data at Level 2 (the &quot;link layer&quot;) of ethernet and you are not going through a switch / hub which will modify the frames which you almost certainly are.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So instead, you could have your hub or switch assign IP addresses through DHCP based on the MAC address of the ethernet shield. This is sometimes referred to as &quot;link layer filtering.&quot; Then when you get packets with data from the Arduino, you know which one it comes from by the source IP address on the &lt;em&gt;packet&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You suggested you might be using cellular data, IP addresses are probably dynamic and the problem becomes more difficult. You would need to talk to your provider and see if you can get static IP addresses.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are using SMS, then simply identify by phone number.&lt;/p&gt;&#xA;" OwnerUserId="1473" LastEditorUserId="1473" LastEditDate="2013-08-31T17:37:27.023" LastActivityDate="2013-08-31T17:37:27.023" CommentCount="11" />
  <row Id="1755" PostTypeId="1" AcceptedAnswerId="1760" CreationDate="2013-08-16T15:48:38.817" Score="4" ViewCount="75" Body="&lt;p&gt;I have several &lt;a href=&quot;http://store.3drobotics.com/products/apm-2-5-kit&quot; rel=&quot;nofollow&quot;&gt;APM 2.5 boards&lt;/a&gt; and need to identify them based on some globally unique hardware signature that does not change with programming.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Arduinos and atmel AVR chips in general &lt;a href=&quot;http://forum.arduino.cc/index.php?topic=45104.0&quot; rel=&quot;nofollow&quot;&gt;do not have&lt;/a&gt; (also &lt;a href=&quot;http://forum.arduino.cc/index.php?topic=45060.0&quot; rel=&quot;nofollow&quot;&gt;this thread&lt;/a&gt;) an accessible serial number.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, it seems that the Ardupilot has so many integrated sensors and other ICs that one of them must have something unique I can use ( &lt;a href=&quot;http://stuff.storediydrones.com/APM_v252_RELEASE.zip&quot; rel=&quot;nofollow&quot;&gt;see schematic&lt;/a&gt; )!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I will be checking datasheets for MPU-6000, HMC5883L-TR and MS5611, but in the meantime, if someone has already figured this one out, please answer.&lt;/p&gt;&#xA;" OwnerUserId="1473" LastActivityDate="2013-08-18T19:56:03.627" Title="Any globally unique signature in Ardupilot hardware, or Arduino in general?" Tags="&lt;arduino&gt;&lt;ardupilot&gt;" AnswerCount="1" />
  <row Id="1756" PostTypeId="2" ParentId="1724" CreationDate="2013-08-16T21:37:30.907" Score="1" Body="&lt;p&gt;I have used small solenoid valves with a fixed displacement to dispense small droplets. For example, the valve I used consistently pumped 0.5 uL from one orifice to the other every time it was switched. That particular valve was not intended to be used as a pump, but there was no reason it couldn't be. There are other solenoids which are intended to be used that way.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The valve I used costs less than $100. Unfortunately I can't share the specific part number, but you should be able to find some help from &lt;a href=&quot;http://www.theleeco.com/products.cfm&quot; rel=&quot;nofollow&quot;&gt;The Lee Company&lt;/a&gt;, or &lt;a href=&quot;http://www.smcusa.com/smc.aspx&quot; rel=&quot;nofollow&quot;&gt;SMC&lt;/a&gt;, who sell these types of valves. Lee will definitely sell small quantities. I don't know about SMC. Either one should be able to provide you with samples. &lt;/p&gt;&#xA;" OwnerUserId="1827" LastActivityDate="2013-08-16T21:37:30.907" />
  <row Id="1757" PostTypeId="1" CreationDate="2013-08-17T17:39:02.537" Score="1" ViewCount="87" Body="&lt;p&gt;I'm looking for a laser / photosensor pair (or product of similar function) for detecting when a beam is interrupted (no more than 3ft apart, probably more like 1ft).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'd like these to run off of 5V, since I'm using an Arduino. My main requirement, however, is that these parts have nice housings, ideally with some mounting screw holes or something along those lines. This is going into a project where sturdiness and durability are important.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I don't know how to search for parts like what I am looking for. Could you please point me either to some good product sources, give me some better keywords for searching, or link me directly to potentially useful products?&lt;/p&gt;&#xA;" OwnerUserId="1828" LastEditorUserId="37" LastEditDate="2013-08-31T17:34:36.997" LastActivityDate="2013-08-31T17:34:36.997" Title="Laser / photosensor pair or similar" Tags="&lt;arduino&gt;&lt;sensors&gt;" CommentCount="6" ClosedDate="2013-08-31T17:37:15.383" />
  <row Id="1758" PostTypeId="1" CreationDate="2013-08-18T17:41:02.557" Score="5" ViewCount="197" Body="&lt;p&gt;We hope to build a simple line follower robot and we got a problem when we were discussing about PIC programming.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We planed to write a endless loop, check the sensor panel reading and do the relevant stuff for that reading.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But one of our friends told us to use a timer interrupt to generate interrupts in definite time periods and in each interrupt check the sensor panel reading and do the relevant stuff for that reading.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But we can't figure out which is best: the endless loop in main method OR timer interrupt method.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What is the best way, and why?&lt;/p&gt;&#xA;" OwnerUserId="1829" LastEditorUserId="1600" LastEditDate="2013-08-22T02:12:10.917" LastActivityDate="2013-08-22T02:12:10.917" Title="Polling or Timer interrupt?" Tags="&lt;sensors&gt;&lt;microcontroller&gt;&lt;interrupts&gt;" AnswerCount="4" CommentCount="1" />
  <row Id="1759" PostTypeId="2" ParentId="1758" CreationDate="2013-08-18T18:47:35.870" Score="6" Body="&lt;p&gt;The processor has to execute something.  You will always have an &quot;endless&quot; loop even if you're doing some work in an interrupt handler.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The best solution depends on exactly what you're trying to do.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The main advantage of using interrupts is they allow you to service events in real-time while your main program is doing something else.  Timer interrupts specifically allow you to perform some periodic activity on a fairly accurate time-base while doing some other processing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For most control algorithms it is useful to have some sort of a time-base (or fixed frequency).  If that's all your CPU is doing you can easily do that without interrupts by either controlling the number of cycles/instructions in your control loop or polling the timer.  Both methods would be simpler and more efficient than using interrupts.  Interrupts are more useful in more complex systems doing many things concurrently (I/O, time keeping, scheduling etc.).  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you go with the endless loop without polling the timer or calibrating the time it takes to run one iteration of the loop you will have to be careful of situations where adding more code in your loop changes the timing and the behavior of your control system.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you implement your control algorithm in a timer interrupt you will have to be careful you're not trying to perform more work than the CPU can handle in one time &quot;slot&quot; or that will again impact the behavior of your control system.&lt;/p&gt;&#xA;" OwnerUserId="1584" LastEditorUserId="1584" LastEditDate="2013-08-21T05:06:26.437" LastActivityDate="2013-08-21T05:06:26.437" />
  <row Id="1760" PostTypeId="2" ParentId="1755" CreationDate="2013-08-18T19:56:03.627" Score="1" Body="&lt;p&gt;Well, I'll be darned. A serial number shows up in dmesg when you plug the thing in. I checked two boards that the number was different, so hopefully these are globally unique.&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;me@mycompy:~/arducopter/MissionPlanner$ dmesg|tail                                                                                                                                                   &#xA;[26581.627967] iwlwifi 0000:03:00.0: fail to flush all tx fifo queues&#xA;[26583.020822] usb 1-1.2: new full-speed USB device number 27 using ehci-pci&#xA;[26583.115672] usb 1-1.2: New USB device found, idVendor=2341, idProduct=0010&#xA;[26583.115682] usb 1-1.2: New USB device strings: Mfr=1, Product=2, SerialNumber=220&#xA;[26583.115689] usb 1-1.2: Product: Arduino Mega 2560&#xA;[26583.115696] usb 1-1.2: Manufacturer: Arduino (www.arduino.cc)&#xA;[26583.115702] usb 1-1.2: SerialNumber: 64033353830351A0B122&#xA;[26583.116485] cdc_acm 1-1.2:1.0: ttyACM0: USB ACM device&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="1473" LastActivityDate="2013-08-18T19:56:03.627" />
  <row Id="1761" PostTypeId="2" ParentId="1758" CreationDate="2013-08-19T05:42:25.293" Score="3" Body="&lt;p&gt;Further to Guy's answer, using a timer interrupt to generate accurate intervals adds determinacy.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, at any given time, you know exactly what the processor is doing, and all activities are performed at specified rates.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You also should schedule at determined rates as otherwise you have no basis for time constants and such like, which will be essential in your filtering.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And finally, this means that if you add additional tasks, then the existing tasks are not slowed down.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Simple polling is OK if that is all your system has to do - but while time slot scheduling is a minor overhead in a trivial system, adding it from the start allows growth and expansion without having to restructure everything later.&lt;/p&gt;&#xA;" OwnerUserId="134" LastActivityDate="2013-08-19T05:42:25.293" CommentCount="1" />
  <row Id="1762" PostTypeId="2" ParentId="1728" CreationDate="2013-08-19T14:16:22.903" Score="0" Body="&lt;p&gt;Use dynamic threshold to counter variation of ambient light condition, though the color green may still be hard to distinguish from white and black (dependent on the reflective index of the green material, which you might have to experiment with). This is a serious problem if you are using photo reflectors as grayscale sensors. The distribution of grayscale sensors depends on the size of your robot and your expected speed. If your robot aims at 1.0m/s, I would say six sensors are enough, placed at the front of your robot with a distance of roughly 1cm or 2cm. If you want to achieve higher speed (i.e., 3.0m/s) you might need as many as twelve to sixteen sensors. But these numbers are very inconclusive since you are giving out too limited information about your project. As someone who has done this before, I would recommend using the TSL1401 linear sensor array, which is equivalent to 128 grayscale sensors, yet is still quite cheap. &lt;/p&gt;&#xA;" OwnerUserId="1833" LastActivityDate="2013-08-19T14:16:22.903" />
  <row Id="1763" PostTypeId="2" ParentId="1758" CreationDate="2013-08-19T16:26:40.307" Score="3" Body="&lt;p&gt;I would just like to add few points to other posts. My personal opinion is that endless while loop has no sense in systems which read from snsors or write to actuators as both has some physical constrains, eg. There is no point in reading from sensors at 1Mhz if the sensor has stability cycle before meassurent is accurate at 100Hz. Same goes to motor drivers. You can send 1mil instructiins to move motor but it can only witstand its physical limitations in respect of inertia.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What i do in my designs is following. I create timer interrupt which triggers every 1ms or so, and then i decrement some global variables in that interrupt routine. In main while loop i check if variable is 0 and execute command that is defined by that variable. In that case i can drive motor at 125Hz, read sensor at 20Hz, and output leds at 0.5Hz. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I hope you got the point.&lt;/p&gt;&#xA;" OwnerUserId="973" LastActivityDate="2013-08-19T16:26:40.307" />
  <row Id="1764" PostTypeId="2" ParentId="1758" CreationDate="2013-08-19T20:53:13.160" Score="2" Body="&lt;p&gt;I'd also like to stress that the comparison between polling (i.e. checking if a interrupt flag has been set) and interrupt vectors (i.e. an ISR, or function that's loaded when a interrupt has occurred) should be more than just evaluating the efficiency/simplicity of executing a block of reactionary code. The interrupt controllers of most modern micros are capable of so much more, especially when considering inter-peripheral signalling (ie, DMA).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, a Texas Instruments TMS320F28335 microcontroller &lt;a href=&quot;http://www.ti.com/lit/ug/sprug04a/sprug04a.pdf&quot; rel=&quot;nofollow&quot; title=&quot;Please refer to Figure 42 on page 64&quot;&gt;allows you to trigger your ADC's start of conversion pulse directly from a PWM's rising or falling edge&lt;/a&gt;. In addition to this, the micro also has a six channel DMA controller, which for instance can also be programmed to trigger off the same PWM signal (this could allow you to &lt;a href=&quot;http://www.ti.com/lit/ug/sprufb8d/sprufb8d.pdf&quot; rel=&quot;nofollow&quot; title=&quot;Please refer to Section 1 on page 8&quot;&gt;start a memory read via the devices' parallel bus&lt;/a&gt;, that's for instance connected to a high speed delta sigma converter). The same DMA controller can then be used to buffer the values read from the ADC and external delta sigma to internal RAM. The DMA controller can then be configured to only trigger a normal interrupt service routine after sampling a total of lets say 128 ADC and delta sigma readings. All this would happen without any CPU intervention (freeing you up to do other things).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This type of behind-the-scenes triggering allows you to get a lot more work done compared to when you would have had an ISR controlling all the enable flags or memory reads (due to the overhead associated with &lt;a href=&quot;http://en.wikipedia.org/wiki/Interrupt_latency&quot; rel=&quot;nofollow&quot;&gt;interrupt latency&lt;/a&gt;). The vector chained approach would allow you to sample at (let's say) 50 KHz, where an ISR driven approach would only allow you to sample at (let's say) 5 KHz.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also as Andrew stated, using interrupt vectors are much more deterministic, or repeatable, than polling a status register.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'd also highly recommend subscribing to &lt;a href=&quot;http://betterembsw.blogspot.com/&quot; rel=&quot;nofollow&quot;&gt;Phil Koopman's blog&lt;/a&gt;, or at least reading the following posts:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://betterembsw.blogspot.com/2013/03/rules-for-using-interrupts.html&quot; rel=&quot;nofollow&quot;&gt;Rules for using interrupts&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://betterembsw.blogspot.com/2013/04/why-short-interrupt-service-routines.html&quot; rel=&quot;nofollow&quot;&gt;Why Short Interrupt Service Routines Matter&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://betterembsw.blogspot.com/2013/07/making-main-loop-scheduling-timing-more.html&quot; rel=&quot;nofollow&quot;&gt;Making Main Loop Scheduling Timing More Deterministic&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://betterembsw.blogspot.com/2012/12/software-timing-loops.html&quot; rel=&quot;nofollow&quot;&gt;Software Timing Loops&lt;/a&gt; (and why you should rather use a hardware timer)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="1775" LastEditorUserId="1775" LastEditDate="2013-08-19T21:06:58.273" LastActivityDate="2013-08-19T21:06:58.273" />
  <row Id="1765" PostTypeId="1" CreationDate="2013-08-20T05:29:43.533" Score="5" ViewCount="116" Body="&lt;p&gt;I used to think that the higher GPS antenna position the better until I read the following on &lt;a href=&quot;http://gpsd.berlios.de/faq.html#accuracy&quot; rel=&quot;nofollow&quot;&gt;GPSd FAQ&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;One &lt;strong&gt;common error is to place the GPS or antenna as high as possible&lt;/strong&gt;.&#xA;  This will increase multipath effects due to signal bounce from the&#xA;  ground or water, which can cause the GPS to mistake its position and&#xA;  the time signal. The &lt;strong&gt;correct location for a boat GPS antenna&lt;/strong&gt; is on the&#xA;  gunwale rail or pushpit rail, &lt;strong&gt;close to the water&lt;/strong&gt; and as far from the&#xA;  mast as possible (to reduce signal bounce from the mast). If you're&#xA;  outside or in a fixed location, put the GPS antenna as far from&#xA;  buildings as possible, and on the ground.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;If you're &lt;strong&gt;in a car&lt;/strong&gt;, &lt;strong&gt;don't&#xA;  put the GPS antenna on the roof, put it on the towbar&lt;/strong&gt; or some similar&#xA;  location. If you're driving in a heavily built up area, you're going&#xA;  to get signal bounce off buildings and reduced accuracy. That's just&#xA;  how the physics works. Note, however, that as your velocity goes up it&#xA;  becomes easier for the convergence filters in your GPS to spot and&#xA;  discard delayed signal, so multipath effects are proportionally less&#xA;  important in fast-moving vehicles.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Does anyone has experience placing GPS antenna on a towbar of the car as suggested? Does it give reasonable effect?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My concern is that placing antenna there will not reduce an error that much, but will expose the device (antenna) to possible mechanical damage.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, are there any better positions apart from roof and towbar?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks&lt;/p&gt;&#xA;" OwnerUserId="1836" LastEditorUserId="350" LastEditDate="2013-08-27T18:42:21.197" LastActivityDate="2013-12-10T19:15:46.160" Title="Place for GPS antenna on autonomous vehicle" Tags="&lt;gps&gt;&lt;ugv&gt;" AnswerCount="2" CommentCount="7" FavoriteCount="3" />
  <row Id="1766" PostTypeId="1" CreationDate="2013-08-20T13:59:45.130" Score="3" ViewCount="139" Body="&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am implementing a simple Kalman Filter that estimates the heading direction of a robot. The robot is equipped with a compass and a gyroscope.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;My Understanding:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am thinking about representing my state as a 2D vector $(x, \dot{x})$, where $x$ is the current heading direction and  $\dot{x}$ is the rotation rate reported by the gyroscope.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Questions:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;If my understanding is correct, there will be no control term, $u$ in my filter. Is it true? What if I take the state as a 1D vector $(x)$? Then does my $\dot{x}$becomes the control term $u$? Will these two methods yield different results?&lt;/li&gt;&#xA;&lt;li&gt;As we know, the main noise source comes from the compass when the compass is in a distorted magnetic field. Here, I suppose the Gaussian noise is less significant. But the magnetic distortion is totally unpredictable. How do we model it in the Kalman Filter?&lt;/li&gt;&#xA;&lt;li&gt;In Kalman Filter, is the assumption that &quot;all the noises are white&quot; necessary? Say, if my noise distribution is actually a Laplacian distribution, can I still use a Kalman Filter? Or I have to switch to another filter, like Extended Kalman Filter?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="1770" LastEditorUserId="1770" LastEditDate="2013-08-20T14:29:23.123" LastActivityDate="2013-08-21T15:53:09.533" Title="How to model unpredictable noise in Kalman Filter?" Tags="&lt;localization&gt;&lt;kalman-filter&gt;&lt;gyroscope&gt;&lt;compass&gt;" AnswerCount="2" FavoriteCount="1" />
  <row Id="1767" PostTypeId="1" CreationDate="2013-08-20T14:38:10.740" Score="4" ViewCount="87" Body="&lt;p&gt;I am implementing a simple Kalman Filter that estimates the heading direction of a robot. The robot is equipped with a compass and a gyroscope.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Say at time $t-dt$, the compass reports a reading $\theta_{t-dt}$, and the gyroscope reports a reading $\omega_{t-dt}$. Then I assume from time $t-dt$ to $t$, the rotation rate can be regarded as a constant. Thus, my current heading direction is $$\theta_{t}=\theta_{t-dt}+\omega_{t-dt}\cdot dt$$&#xA;As can be seen, the $\theta$ can be easily time-updated.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But what about my $\omega$? The robot is not at my control. So its rotation rate at next moment is &lt;strong&gt;unpredictable&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;How should I do the time update in this case?&lt;/strong&gt;&lt;/p&gt;&#xA;" OwnerUserId="1770" LastActivityDate="2013-08-20T16:06:16.933" Title="What to do when the control input of the Kalman filter is unknown?" Tags="&lt;kalman-filter&gt;&lt;gyroscope&gt;&lt;compass&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="1768" PostTypeId="5" CreationDate="2013-08-20T16:04:54.510" Score="0" ViewCount="3" Body="&lt;p&gt;A line-following robot is typically a wheeled robot with light sensor(s) beneath it. These sensors are used to determine whether the robot is on the line, outside the line or in transition between the two states. Accordingly, the robot chooses the appropriate control action to move back in the line if not on it already and go along the line otherwise.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Line-following robots are often didactic.&lt;/p&gt;&#xA;" OwnerUserId="158" LastEditorUserId="158" LastEditDate="2013-08-20T16:14:41.177" LastActivityDate="2013-08-20T16:14:41.177" />
  <row Id="1769" PostTypeId="4" CreationDate="2013-08-20T16:04:54.510" Score="0" Body="A line-following robot is typically a wheeled robot with light sensor(s) beneath it. The goal of the robot is to follow along a line with a distinct color or intensity, e.g. black on white background." OwnerUserId="158" LastEditorUserId="158" LastEditDate="2013-08-20T16:14:27.300" LastActivityDate="2013-08-20T16:14:27.300" />
  <row Id="1770" PostTypeId="2" ParentId="1767" CreationDate="2013-08-20T16:06:16.933" Score="2" Body="&lt;p&gt;For both states, you are using sensors to give you the required information. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;One way to make this work properly: Use the gyroscope reading for your ω and your previous state estimate for your θ (or initial state estimate if its the first iteration). This is the &lt;strong&gt;predict&lt;/strong&gt; step of the filter. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then for the &lt;strong&gt;update&lt;/strong&gt; step you can use your compass measurement (this will correct the gyro drift).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For both states, you are relying on sensors to provide information about heading, not the control inputs of the robot itself. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;This method is common in attitude heading and reference systems. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;For your application a &lt;a href=&quot;http://www.pieter-jan.com/node/11&quot; rel=&quot;nofollow&quot;&gt;complementary filter&lt;/a&gt; may be better suited since its easily implemented and is easy to tune and can have comparable performance to a Kalman filter in many situations.&lt;/p&gt;&#xA;" OwnerUserId="983" LastActivityDate="2013-08-20T16:06:16.933" />
  <row Id="1771" PostTypeId="2" ParentId="1766" CreationDate="2013-08-20T16:24:40.783" Score="2" Body="&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;There will be no control input term. You should take (x, xdot) as your state vector to formulate the Kalman filter properly.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;The primary sources of noise are the compass &lt;strong&gt;and the gyroscope&lt;/strong&gt;. The gyroscope noise and drift are significant. It is pretty challenging to overcome magnetic distortion in general but there are &lt;a href=&quot;http://www.sensorsmag.com/sensors/motion-velocity-displacement/compensating-tilt-hard-iron-and-soft-iron-effects-6475&quot; rel=&quot;nofollow&quot;&gt;compensation techniques&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;The assumption of &lt;strong&gt;zero mean multivariate normal &#xA;distribution&lt;/strong&gt; noise is necessary however white noise is only a special case of this. For the extended Kalman filter, this assumption still needs to be true. You can look into other types of filters (&lt;a href=&quot;http://www.cim.mcgill.ca/~yiannis/particletutorial.pdf&quot; rel=&quot;nofollow&quot;&gt;particle filter&lt;/a&gt;, &lt;a href=&quot;http://en.wikipedia.org/wiki/Kalman_filter#Unscented_Kalman_filter&quot; rel=&quot;nofollow&quot;&gt;unscented kalman filter&lt;/a&gt;).&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Kalman Filter Design/Implementation Paper: &lt;a href=&quot;http://franciscoraulortega.com/pubs/Algo3DFusionsMems.pdf&quot; rel=&quot;nofollow&quot;&gt;http://franciscoraulortega.com/pubs/Algo3DFusionsMems.pdf&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="983" LastEditorUserId="983" LastEditDate="2013-08-21T15:53:09.533" LastActivityDate="2013-08-21T15:53:09.533" CommentCount="2" />
  <row Id="1772" PostTypeId="2" ParentId="1766" CreationDate="2013-08-20T18:06:24.757" Score="5" Body="&lt;ol&gt;&#xA;&lt;li&gt;I would model this as a one-state system (x), with the gyro as the control input.  The gyro noise becomes state input noise, the compass noise becomes measurement noise.  So your system model becomes $$\hat{\dot \theta} = \omega_{gyro} + w$$ $$\hat y = \hat x$$ where $\hat y$ is the filter's estimate of direction, which you compare to the compass direction to get your Kalman update.&lt;/li&gt;&#xA;&lt;li&gt;The magnetic distortion is going to be difficult, because if you sit in any one place it will appear as a constant offset term -- the Kalman filter won't deal with this well.  I'm pretty sure you'll either need to map the distortion, get some second absolute direction reference, or just accept the distortion.&lt;/li&gt;&#xA;&lt;li&gt;You are confusing spectral content with probability distribution.  If the noise is white, then each sample in perfectly independent of any other sample.  If the noise is Laplacian, each sample obeys the Laplace distribution.  Kalman filters don't like colored noise (but you can deal with that by adding states).  A Kalman filter is only the overall optimal filter when the noise is of Gaussian distribution and the cost function is sum-of-squares.  For any other noise and cost function, the optimal filter is probably nonlinear.  But for any zero-mean, white noise and sum-of-squares cost function, the Kalman filter is the best linear filter to be found.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;(Note that the system model I gave ends up with a pretty trivial Kalman filter -- you may be better off, if you can't find some other means of estimating compass offset, using a complimentary filter to combine these two sensor inputs.  Doing all the Kalman computations will just end up coughing up a complimentary filter anyway, and chances are that you'll have enough guesses for your constants that you may as well just guess at the crossover point in a complimentary filter and be done with it).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(Note, too, that if you have some absolute &lt;em&gt;position&lt;/em&gt; reference, and some means estimating speed, and a vehicle that always goes in the direction you point it, that you can use an extended Kalman filter very profitably to correct the compass distortion by using the direction it actually moves to correct for the compass direction).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&quot;Optimal State Estimation&quot; by Dan Simon, Wiley 2006, is -- in my opinion -- a very rich and clear treatment of the subject of Kalman filtering and its more sophisticated brethren (H-infinity, extended Kalman, unscented Kalman, and even a bit on Baysian and particle filtering).  It won't tell you how to apply that to navigation problems like this, but where would be the fun in life if all the problems were solved?.  If you can't follow the math in Simon's book, then you should probably be asking yourself if you're going to be able to apply a Kalman filter in any sort of intelligent way.&lt;/p&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-08-20T18:06:24.757" CommentCount="3" />
  <row Id="1774" PostTypeId="1" AcceptedAnswerId="1890" CreationDate="2013-08-21T07:02:49.803" Score="3" ViewCount="97" Body="&lt;p&gt;In this &lt;a href=&quot;http://www.mdpi.com/1424-8220/12/1/429&quot; rel=&quot;nofollow&quot;&gt;paper&lt;/a&gt;, the author says that during SLAM process, pseudo segments that appear from any momentary pause of dynamic objects in laser data would make the map unsatisfied.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How is this caused?  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If the dynamic object moved, won't laser data update and eliminate the segment of dynamic objects?&lt;/p&gt;&#xA;" OwnerUserId="405" LastEditorUserId="350" LastEditDate="2013-08-27T18:18:53.953" LastActivityDate="2013-09-26T21:45:44.243" Title="In SLAM, how does a laser range finder produce pseudo-segments from dynamic objects?" Tags="&lt;sensors&gt;&lt;slam&gt;" AnswerCount="1" />
  <row Id="1775" PostTypeId="1" CreationDate="2013-08-21T20:42:06.220" Score="0" ViewCount="230" Body="&lt;p&gt;How can I control the position of a &lt;strong&gt;pneumatic&lt;/strong&gt; piston?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The only way I know about is using a magnetic reed switch (magnetic sensor) with a matching piston and use some type of control algorithm, like PID for instance, to keep the piston where the sensor is.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The problem with that is that it gives you only limited control of the position, it just adds another &quot;state&quot; (open, closed, sensor position) and not full control. for example I want it to be 43% once and 70% the other time, but without using a sensor for each position because I would like all the &quot;options&quot; to be available (I mean that the percentages aren't pre-defined)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is an example of the pistons I use:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/Lm29K.jpg&quot; alt=&quot;piston&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is a good example of what I want: &lt;a href=&quot;http://www.youtube.com/watch?v=A8LZ15uiuXU&quot; rel=&quot;nofollow&quot;&gt;http://www.youtube.com/watch?v=A8LZ15uiuXU&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1337" LastEditorUserId="1337" LastEditDate="2013-08-22T16:36:10.627" LastActivityDate="2013-08-27T18:09:22.890" Title="How to control the position of a pneumatic piston?" Tags="&lt;sensors&gt;&lt;control&gt;&lt;pid&gt;&lt;movement&gt;" AnswerCount="2" CommentCount="5" />
  <row Id="1776" PostTypeId="1" CreationDate="2013-08-21T22:34:52.203" Score="1" ViewCount="38" Body="&lt;p&gt;Where can I find a good documentation about the UWSim in ROS. Actually having the source files is not enough and it is actually hard to follow all the functions. for example, how can I use these command correctly :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&amp;amp; rosrun UWSim gotoAbsolutePosition   0 0 0 0 0 0&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I know that there is a node 'gotoAbsolutePosition' in the Package 'UWSim' and I knwo the variables, but I cannot set the two topics properly.&lt;/p&gt;&#xA;" OwnerUserId="1850" LastActivityDate="2013-08-21T22:34:52.203" Title="running UWSim commands in ROS" Tags="&lt;ros&gt;" CommentCount="2" />
  <row Id="1777" PostTypeId="1" CreationDate="2013-08-23T12:19:47.470" Score="2" ViewCount="558" Body="&lt;p&gt;I'm building quadcopter and most of the control systems use one accelerometer and gyro. I've read few papers and usually accelerometer is used as reference to the ground because gyro slowly drifts away in time. But if quadcopter does some crazy maneuvering when force direction from accelerometer does not have to point to the ground than accelerometer data is useless. As well there is problem with centripetal force if the accelerometer is not directly in the centor of mass.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I was thinking about using multiple accelerometers. To fully determine position and motion of quadcopter one would need three accelerometers(If I have done the math right). This would kind of solve the problem with centripetal force&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So I would like to know if anyone tried to use multiple accelerometers for better orientation estimation. &lt;/p&gt;&#xA;" OwnerUserId="1861" LastActivityDate="2013-08-26T15:56:39.410" Title="Tracking with accelerometer and gyro versus multiple accelerometers" Tags="&lt;quadcopter&gt;&lt;imu&gt;&lt;accelerometer&gt;&lt;gyroscope&gt;" AnswerCount="2" />
  <row Id="1778" PostTypeId="2" ParentId="1777" CreationDate="2013-08-23T14:06:46.640" Score="2" Body="&lt;p&gt;You definitely mean the orientation and not position. Any yes, people have used multiple accelerometers to determine the orientation, for example Wii's &quot;nunchuck&quot; is an attachment to the Wiimote that has an additional accelerometer, so that the orientation of the stick can be calculated&lt;/p&gt;&#xA;" OwnerUserId="1289" LastActivityDate="2013-08-23T14:06:46.640" />
  <row Id="1779" PostTypeId="2" ParentId="1775" CreationDate="2013-08-23T14:17:33.113" Score="2" Body="&lt;p&gt;You probably could attach an optical encoder strip to the piston, maybe even paint the piston rod with some reflecting / non reflecting paint.&#xA;Or you could attach a modified digital caliper to it, using something similar to this: &lt;a href=&quot;http://hackaday.com/2013/06/20/giving-digital-calipers-bluetooth/&quot; rel=&quot;nofollow&quot;&gt;http://hackaday.com/2013/06/20/giving-digital-calipers-bluetooth/&lt;/a&gt; .&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have never done anything like this, so I don't really know if it would work in reality :-)&lt;/p&gt;&#xA;" OwnerUserId="482" LastActivityDate="2013-08-23T14:17:33.113" CommentCount="3" />
  <row Id="1780" PostTypeId="2" ParentId="1777" CreationDate="2013-08-25T01:21:23.313" Score="2" Body="&lt;p&gt;You won't be able to determine the &lt;strong&gt;position&lt;/strong&gt; of the quadcopter with accelerometers or gyros or a combination of both. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can use either accelerometers or a combination of accelerometers and gyros to determine the &lt;strong&gt;orientation&lt;/strong&gt; (eg. roll, pitch, yaw) of the quadcopter. The gyro will allow for a more nimble quadcopter because it provides additional information at a faster rate. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can think of it like this: The accelerometers are useful for determining your orientation when moving slow (stable response, no drift, low bandwidth). The gyros are useful for determining your orientation when your moving fast (provide high bandwidth updates but have significant drift over longer time periods). The combination of the two using something like a &lt;a href=&quot;http://www.pieter-jan.com/node/11&quot; rel=&quot;nofollow&quot;&gt;complementary filter&lt;/a&gt; will provide the best of both worlds however you will need 6 axes of measurement (3-axis gyro, 3-axis accelerometer). Also, since gravity is symmetric about the vertical axis you would need a magnetometer or compass sensor to zero the gyro drift about that axis and provide reliable heading control. There are several off-shelf &lt;a href=&quot;https://www.sparkfun.com/products/10736&quot; rel=&quot;nofollow&quot;&gt;Intertial Measurement Units (IMU)&lt;/a&gt; that can be purchased and interfaced to your main controller.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you use only accelerometers your quadcopter won't be as agile as if you used a combination of gyros and accelerometers since the bandwidth of accelerometers are generally lower than that of gyros. Most ready-to-fly quads use accelerometers, gyros, and magnetometers.&lt;/p&gt;&#xA;" OwnerUserId="983" LastEditorUserId="983" LastEditDate="2013-08-26T15:56:39.410" LastActivityDate="2013-08-26T15:56:39.410" />
  <row Id="1781" PostTypeId="2" ParentId="1314" CreationDate="2013-08-25T20:13:00.247" Score="0" Body="&lt;p&gt;A very informative way to visualize the effect of measurements (for me) is to plot the state of the robot (mean, with covariance ellipse) before and after each measurement. Then, take the individual &lt;em&gt;components&lt;/em&gt; of the measurement (bearing, range for AR markers), and apply them separately to get a feel for it.&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;To do this:&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;I use one or more of &lt;a href=&quot;https://en.wikipedia.org/wiki/Ellipse#Equations&quot; rel=&quot;nofollow&quot;&gt;these functions&lt;/a&gt; to plot the ellipse. To find the constants $a,b$, note that they are the square roots of the eigenvalues of the covariance matrix.  Then sample the angle $\alpha$ over $0, 2*\pi$ and find the range from the hypothesis. using the linked equation. I especially recommend using &lt;a href=&quot;https://en.wikipedia.org/wiki/Ellipse#Polar_form_relative_to_center&quot; rel=&quot;nofollow&quot;&gt;this equation&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$ &#xA;r(\theta) = \frac{ab}{\sqrt{b\cos^2\theta + a\sin^2\theta} }&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Tracking the covariance of the prior hypothesis, measured state, and posterior hypothesis is usually sufficient to find if the equations of an EKF are being applied correctly. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Good luck, and don't update your question too frequently. Instead, come back with new questions.&lt;/p&gt;&#xA;" OwnerUserId="163" LastEditorUserId="350" LastEditDate="2013-08-27T17:52:06.240" LastActivityDate="2013-08-27T17:52:06.240" />
  <row Id="1782" PostTypeId="1" AcceptedAnswerId="1783" CreationDate="2013-08-26T12:47:32.267" Score="4" ViewCount="68" Body="&lt;p&gt;So i got this idea waay back when i was in highschool as a kind of electromagnetic analogue to a biological muscle. it is basically a long stack of thin electromagnets connected in parallel. &#xA;&lt;img src=&quot;https://lh5.googleusercontent.com/-DUdbOfkO9bI/UhtIXyefiII/AAAAAAAAB0c/vmkKU3K6rF0/w2350-h1762-no/IMG_20130826_152132.jpg&quot; alt=&quot;(the picture)&quot;&gt;. &#xA;when current is applied gaps between electromagnets shrink thus providing contraction of the whole chain. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am pretty sure it can work. It can't offer great contraction range (up to 50% i would guess) but it has potential to provide good speed and be compact so that multiple chains can be combined to form stong and fast linear actuators. The thing is, i never heard of this type of actuator being used. so what is the catch? is there a better alternative? is there a design flaw? too much heat generated making them unpractical?&lt;/p&gt;&#xA;" OwnerUserId="1870" LastEditorUserId="350" LastEditDate="2013-08-27T17:48:27.923" LastActivityDate="2013-08-30T08:20:47.370" Title="Actuator design. plausible?" Tags="&lt;actuator&gt;" AnswerCount="1" />
  <row Id="1783" PostTypeId="2" ParentId="1782" CreationDate="2013-08-27T14:36:40.607" Score="3" Body="&lt;p&gt;This design is definitely plausible, but there are some problems I can see.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The maximum length is defined by the force the magnets can lift, since the ones lowest in the stack won't push the other ones up after some amount of them.&lt;/li&gt;&#xA;&lt;li&gt;The magnets will want to get as far from the force as possible, so they will most definitely not go straight up. This calls for a use of something like a flexible tube. This may mean the design won't be as space-efficient as it seems (if it is even possible).&lt;/li&gt;&#xA;&lt;li&gt;The stack won't keep it's shape if the magnets are not energized all the time, so the current consumption may be bigger than readily-available parts.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;It is an interesting concept, but I can't see using it to lift any significant load to a reasonable distance.&lt;/p&gt;&#xA;" OwnerUserId="890" LastEditorUserId="890" LastEditDate="2013-08-30T08:20:47.370" LastActivityDate="2013-08-30T08:20:47.370" CommentCount="1" />
  <row Id="1784" PostTypeId="2" ParentId="1775" CreationDate="2013-08-27T18:09:22.890" Score="0" Body="&lt;p&gt;To control the position of a piston, you need -- at the very least -- a position sensor and an actuated valve.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In reality, you will encounter a few other effects that will complicate the simple PID algorithm you're attempting.  &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;Depending on how many pistons you're driving, or how much airflow your piston takes, you may find that the available air pressure fluctuates.  If your valve can achieve a range of positions (not just open or closed), this changes the relationship between valve position and the resulting pneumatic force.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;The system may exhibit negative damping for a variety of reasons.  For a good explanation, see &lt;a href=&quot;http://projecthexapod.com/blog/battling-subtle-negative-damping/&quot; rel=&quot;nofollow&quot;&gt;this page about a robot experiencing negative damping, and how to fix it&lt;/a&gt;.  (This might also be a solution to your problem of the actuator moving too fast.)&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;There is no simple answer; these systems are complicated and require testing every step of the way.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-08-27T18:09:22.890" />
  <row Id="1787" PostTypeId="1" AcceptedAnswerId="2150" CreationDate="2013-08-28T19:13:55.500" Score="1" ViewCount="166" Body="&lt;p&gt;I'm trying to get the &quot;Torobot&quot; USB servo controller to work with Angstrom Linux on a Beagle Board XM.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The servo controller registers as a USB device. The device just takes simple text commands, but there is no TTY associated with it. So I'm not sure how to send commands to it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can I just send data like this (assuming that 002/005 is the device):&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;$ cat file.txt &amp;gt;&amp;gt; /dev/bus/usb/002/005&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Or do I need to associate it with the generic USB device? If so, how do I do that?&lt;/p&gt;&#xA;" OwnerUserId="947" LastActivityDate="2013-12-15T09:23:21.943" Title="How do I send text to a Torobot USB device?" Tags="&lt;control&gt;&lt;microcontroller&gt;&lt;rcservo&gt;&lt;usb&gt;&lt;embedded-systems&gt;" AnswerCount="2" />
  <row Id="1788" PostTypeId="2" ParentId="1445" CreationDate="2013-08-28T20:02:49.340" Score="0" Body="&lt;p&gt;If you just want to write data to the UART, you can use &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;cliSerial-&amp;gt;printf(&quot;my output&quot;);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;cliSerial is an alias for hal.console .&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is a good example &lt;a href=&quot;https://github.com/diydrones/ardupilot/blob/master/libraries/AP_HAL/examples/AnalogIn/AnalogIn.pde&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;UART 2 is unused on the APM so I think you can examine how hal.console is set up and set up your own equivalent that uses UART 2. Looks like you would start with&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;hal.uartB-&amp;gt;begin(115200);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Using the mavlink protocol is also an option but you probably want your own simpler protocol. If you want to use mavlink you can use the gcs_send_text_fmt() function. For example, it is used inside verify_nav_wp() of commands_logic.pde .&lt;/p&gt;&#xA;" OwnerUserId="1473" LastEditorUserId="1473" LastEditDate="2013-08-28T21:41:23.587" LastActivityDate="2013-08-28T21:41:23.587" />
  <row Id="1789" PostTypeId="2" ParentId="1787" CreationDate="2013-08-28T21:38:27.713" Score="1" Body="&lt;p&gt;you can pyusb for send data &lt;a href=&quot;http://pyusb.sourceforge.net/docs/1.0/tutorial.html&quot; rel=&quot;nofollow&quot;&gt;http://pyusb.sourceforge.net/docs/1.0/tutorial.html&lt;/a&gt;&#xA;and your data information is here &lt;a href=&quot;http://www.torobot.com/down/usc_en.pdf&quot; rel=&quot;nofollow&quot;&gt;http://www.torobot.com/down/usc_en.pdf&lt;/a&gt;&#xA;i think you python code like this&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;    import usb.core&#xA;import usb.util&#xA;&#xA;# find our device&#xA;dev = usb.core.find(idVendor=0xfffe, idProduct=0x0001)&#xA;&#xA;# was it found?&#xA;if dev is None:&#xA;    raise ValueError('Device not found')&#xA;&#xA;# set the active configuration. With no arguments, the first&#xA;# configuration will be the active one&#xA;dev.set_configuration()&#xA;&#xA;# get an endpoint instance&#xA;cfg = dev.get_active_configuration()&#xA;interface_number = cfg[(0,0)].bInterfaceNumber&#xA;alternate_settting = usb.control.get_interface(interface_number)&#xA;intf = usb.util.find_descriptor(&#xA;    cfg, bInterfaceNumber = interface_number,&#xA;    bAlternateSetting = alternate_setting&#xA;)&#xA;&#xA;ep = usb.util.find_descriptor(&#xA;    intf,&#xA;    # match the first OUT endpoint&#xA;    custom_match = \&#xA;    lambda e: \&#xA;        usb.util.endpoint_direction(e.bEndpointAddress) == \&#xA;        usb.util.ENDPOINT_OUT&#xA;)&#xA;&#xA;assert ep is not None&#xA;&#xA;# write the data&#xA;ep.write('#1P1500T100\r\n')&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="1882" LastActivityDate="2013-08-28T21:38:27.713" CommentCount="3" />
  <row Id="1790" PostTypeId="1" CreationDate="2013-08-29T06:39:51.187" Score="1" ViewCount="96" Body="&lt;p&gt;I am a Robotics enthusiast and planning to make a small and simple four wheel car whose motors are supposed to be controlled by an Android device housed inside the car by means of the micro USB port of the device. The car has to move forward or backward only as directed by the signals from the Android device.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So my assumption is that there should be a circuit board which accepts the signals from the microUSB/USB of the Android device and controls the power to the electric DC motor. Also the power for the motor will be supplied from a battery pack inside the car.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Could anyone suggest me a cheap motor driver circuit which supports micro USB or USB? And where can I get the parts for this online? I did a lot research but very confused with the technical terms which I am not familiar with.&lt;/p&gt;&#xA;" OwnerUserId="1478" LastEditorUserId="1478" LastEditDate="2013-08-29T07:03:14.273" LastActivityDate="2013-08-29T07:03:14.273" Title="Motor Controller with micro USB interface" Tags="&lt;mobile-robot&gt;&lt;motor&gt;&lt;wheeled-robot&gt;" CommentCount="2" FavoriteCount="2" ClosedDate="2013-08-29T23:14:19.827" />
  <row Id="1791" PostTypeId="1" AcceptedAnswerId="1792" CreationDate="2013-08-29T19:25:26.487" Score="2" ViewCount="202" Body="&lt;p&gt;I consider using a brushless outrunner motor, designed for helicopters, in my driving roboter. How can I control such a brushless motor with my micro controller? Of course I'll have a separate power source.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The roboter should be able to move forwards and backwards, so I need to control the motor in a way to determine direction of rotation, too. I think this isn't related to the question, but I need to ensure high acceleration.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Specially, I am talking about &lt;a href=&quot;http://www.modellhobby.de/Motoren/E-Motoren/DYMOND-Brushless-Antriebe/Aussenlaeufer/DYMOND-MASTER-HQ-2838.htm?shop=k_staufenb&amp;amp;SessionId=&amp;amp;a=article&amp;amp;ProdNr=03121706&amp;amp;t=11&amp;amp;c=3258&amp;amp;p=3258&quot; rel=&quot;nofollow&quot;&gt;this motor&lt;/a&gt; which is listed in a German shop.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/Q3ih6.jpg&quot; alt=&quot;DYMOND MASTER HQ motor&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="1054" LastEditorUserId="40" LastEditDate="2013-08-31T21:38:01.547" LastActivityDate="2013-08-31T21:38:01.547" Title="How to control a brushless motor?" Tags="&lt;motor&gt;&lt;control&gt;&lt;microcontroller&gt;&lt;power&gt;&lt;brushless-motor&gt;" AnswerCount="1" />
  <row Id="1792" PostTypeId="2" ParentId="1791" CreationDate="2013-08-29T20:26:08.440" Score="3" Body="&lt;p&gt;You can control brushless motors 2 ways&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;control with a hall effect sensor &lt;a href=&quot;http://scholar.lib.vt.edu/theses/available/etd-09152003-171904/unrestricted/T.pdf&quot; rel=&quot;nofollow&quot;&gt;http://scholar.lib.vt.edu/theses/available/etd-09152003-171904/unrestricted/T.pdf&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;sensorless(back emf) control &lt;a href=&quot;http://www.pmdcorp.com/downloads/app_notes/BrushlessSensorConfig.pdf&quot; rel=&quot;nofollow&quot;&gt;http://www.pmdcorp.com/downloads/app_notes/BrushlessSensorConfig.pdf&lt;/a&gt;&#xA;or you can buy an esc (elcetronic speed control) My advice If you are not knowledgeable about electronic you can buy esc&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="1882" LastActivityDate="2013-08-29T20:26:08.440" CommentCount="8" />
  <row Id="1795" PostTypeId="1" AcceptedAnswerId="1804" CreationDate="2013-08-31T21:49:19.597" Score="2" ViewCount="154" Body="&lt;p&gt;I have a 300cm x 300cm room with a 25cm high ceiling (yes twenty five centimeters). It contains 50 small wheeled robots (about 20cm x 20cm). A central computer will orchestrate the movements of the robots, using a wireless network to send position commands to them. The robots will perform their own closed loop position control to save wireless bandwidth. The robots have 32-bit ARM microcontrollers. They have wheel position sensors, and the ability to do accurate wheel control. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Problem: The robots can't actually do this yet because they have no way to measure their position in the room.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Question: How can the robots be given the ability measure their position and orientation to an accuracy of better than ±5mm? I am looking for an accurate and robust solution, which is not affected by occlusions, and doesn't require a high power PC on each robot. Whatever sensors are necessary for localisation can easily be added to the robots. The microcontrollers can easily be changed for more powerful ones if the localisation solution demands it.&lt;/p&gt;&#xA;" OwnerUserId="40" LastEditorUserId="40" LastEditDate="2013-08-31T23:19:43.003" LastActivityDate="2013-09-03T18:33:28.443" Title="Localizing a swarm of robots" Tags="&lt;localization&gt;&lt;wireless&gt;&lt;swarm&gt;" AnswerCount="4" CommentCount="5" />
  <row Id="1796" PostTypeId="2" ParentId="1654" CreationDate="2013-08-31T23:04:55.403" Score="0" Body="&lt;p&gt;When I was contributing to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Robot&quot; rel=&quot;nofollow&quot;&gt;Robot Wikipedia article&lt;/a&gt;, this was a question I spent a long time struggling with. What could you possibly write in the first sentence to basically define 'robot'. I spent days searching for people's personal definitions of robot, and reading forum discussions, until I found the 'agent' definition, and I realised this was the closest I was going to get to a definition.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;A robot is a mechanical or virtual artificial agent&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;The sense of agency seems to be key whether or not people generally call a machine a robot. A machine must give a sense that it has its own agency:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;it's active in the environment&lt;/li&gt;&#xA;&lt;li&gt;it can take in data&lt;/li&gt;&#xA;&lt;li&gt;it can affect the environment&lt;/li&gt;&#xA;&lt;li&gt;it has its own internal state&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;This is why software agents get called robots too, even though they have no body. Software agents are active in the environment inside computers.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A long time ago, the Wikipedia article went into much more depth describing how, for example, Kitt would be considered a robot, while a radio controlled humanoid would generally not be. See the Robot page from &lt;a href=&quot;https://en.wikipedia.org/w/index.php?title=Robot&amp;amp;oldid=300662394&quot; rel=&quot;nofollow&quot;&gt;July 2009&lt;/a&gt;. (Sadly, since then it has rotted quite a lot.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I think that the reason the 'agency' definition works well is that it replaces the poorly defined and poorly understood concept of 'robot' and replaces it with the equally poorly defined, but much better understood concept of 'agency'. Even if we don't explicitly think of animals and robots as agents, we are wired to recognise agents, and categorise objects into things that are and aren't agents. We can easily tell the difference between animals and plants (well, for the types of animals and plants we usually encounter).&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Animal -&gt; Robot&lt;/li&gt;&#xA;&lt;li&gt;Plant -&gt; Machine&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="40" LastActivityDate="2013-08-31T23:04:55.403" />
  <row Id="1797" PostTypeId="1" AcceptedAnswerId="1798" CreationDate="2013-09-01T03:20:07.567" Score="2" ViewCount="85" Body="&lt;p&gt;&lt;em&gt;Outline:&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm trying to work with an Arduino and Analog thumb stick to get values for a simple differential drive robot I'm working on. The &lt;a href=&quot;http://www.plexishop.it/en/modulo-joystick-keyes-sjoys.html&quot; rel=&quot;nofollow&quot;&gt;Keyes_Sjoys Arduino Joystick Module&lt;/a&gt; I have in my possession is giving me some strange numbers. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Following axises Data I have:&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;X-axis range of 0 to a shaky 470-520 with a center value of 40.&lt;/li&gt;&#xA;&lt;li&gt;Y-axis range of a solid 4 to solid 1023 with a center value of 605.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Problem&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I haven't used analog sensors before but it seems pretty obvious that my X-axis ranges should feel somewhat similar to the Y-axis but they don't. In addition, the X-axis hits zero way way before even coming close to the edge for its operating range.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is my sensor broken (it's new), or is there some way I can recalibrate the potentiometer?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;sub&gt;Note, I also asked this over on &lt;a href=&quot;http://electronics.stackexchange.com/q/80870&quot;&gt;Electrical Engineering Stack Exchange&lt;/a&gt;.&lt;/sub&gt;&lt;/p&gt;&#xA;" OwnerUserId="1740" LastEditorUserId="1740" LastEditDate="2013-12-17T00:57:55.970" LastActivityDate="2013-12-17T00:57:55.970" Title="How do I Calibrate Analog Thumb stick?" Tags="&lt;microcontroller&gt;" AnswerCount="1" CommentCount="0" ClosedDate="2013-09-04T22:44:01.437" />
  <row Id="1798" PostTypeId="2" ParentId="1797" CreationDate="2013-09-01T09:07:37.277" Score="3" Body="&lt;p&gt;It certainly sounds like the joystick is broken, but in Robotics, nothing is certain. Some things to try:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Swap over the X and Y wires going to the Arduino. Which axis exhibits the problem now?&lt;/li&gt;&#xA;&lt;li&gt;Disconnect the joystick from the Arduino, and power it up on its own. Using a multimeter, measure the voltage on the X axis wire as you move the joystick. Does this make more sense? If so, then there's something wrong with the way it's connected to the Arduino, or something wrong in software.&lt;/li&gt;&#xA;&lt;li&gt;Disconnect the joystick completely from its power, and use the multimeter to measure the resistance between the X axis signal wire and the GND wire. If this doesn't make sense, then there's likely a fault in the joystick. Possibly a failed solder joint. This could be fixed by simply re-heating the solder joints on that pot.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="40" LastActivityDate="2013-09-01T09:07:37.277" CommentCount="1" />
  <row Id="1799" PostTypeId="2" ParentId="1795" CreationDate="2013-09-01T15:21:19.253" Score="1" Body="&lt;p&gt;If a &lt;a href=&quot;http://www.vicon.com/&quot; rel=&quot;nofollow&quot;&gt;vicon system&lt;/a&gt; is out of the question, then you can use a system of calibrated cameras to read markers placed on top of the robots. &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Place the best cameras you can get around the environment. I use $20 web cams from amazon.com&lt;/li&gt;&#xA;&lt;li&gt;Use OpenCV's calibration tools to calibrate the cameras.&lt;/li&gt;&#xA;&lt;li&gt;Place markers on top of the robots&lt;/li&gt;&#xA;&lt;li&gt;The cameras know their relative positions in the environment, so by triangulating the marker positions, they can accurately output the position and orientation of the markers.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Sort of like what &lt;a href=&quot;http://mars.cs.umn.edu&quot; rel=&quot;nofollow&quot;&gt;these researchers&lt;/a&gt; did in &lt;a href=&quot;http://www-users.cs.umn.edu/~stergios/papers/TRO-Optimal-Motions-Distance-Bearing-2010.pdf&quot; rel=&quot;nofollow&quot;&gt;this paper&lt;/a&gt; (see page 16)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, as others have noted, if the ceiling is very low, you won't have a good line of sight to the top of the robots, and you'll have a difficult time using this method.&lt;/p&gt;&#xA;" OwnerUserId="163" LastActivityDate="2013-09-01T15:21:19.253" CommentCount="1" />
  <row Id="1800" PostTypeId="2" ParentId="1795" CreationDate="2013-09-01T16:14:37.607" Score="2" Body="&lt;p&gt;If the ceiling is a flat surface that is visible from the tops of the robots, you could place marker stripes (or some other known fiducial pattern) on the ceiling at regular intervals.   The stripes might be white or black lines or narrow reflective tape, detected using photosensors on top of robots.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If wheel position sensors and accurate wheel control are good enough to maintain desired location data accuracy when a robot has moved no further than distance &lt;em&gt;d&lt;/em&gt; from an accurately known position, the stripes (which might be white stripes, black stripes, or narrow reflective tape) might need to be placed no further than about &lt;em&gt;d&lt;/em&gt;/√2 apart.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The motion-planning software probably would need to adapt. If a robot's position is consistently wrong when it crosses a stripe, adjust its ratio of wheel encoder counts to distance traveled; or if a stripe would be seen if a travel leg were just slightly longer, extend the leg to cross the stripe; or move to calibrate against several stripes just before any position-sensitive operations; or perform position-sensitive operations at a stripes crossing-point.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is quite a variety of fiducial patterns possible.  Orthogonal stripes laid out parallel to x and y axes are probably simplest to create and work with.  But bulls-eyes, cross-hairs, wedges,  bar codes, and other patterns as well are worth considering.&lt;/p&gt;&#xA;" OwnerUserId="478" LastEditorUserId="478" LastEditDate="2013-09-03T03:21:41.797" LastActivityDate="2013-09-03T03:21:41.797" CommentCount="2" />
  <row Id="1801" PostTypeId="2" ParentId="1515" CreationDate="2013-09-01T20:55:32.027" Score="1" Body="&lt;p&gt;I think Zuu's answer was very good, but I'd like to add some more detail to it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/YAjtC.png&quot; alt=&quot;Persistence of Vision oscillator&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The idea of using a spring is very good. From the start this creates the oscillating movement you want. I would suggest using a steel leaf spring. This is good for two reasons:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It restricts the movement to just left-right.&lt;/li&gt;&#xA;&lt;li&gt;It allows you to add solenoids to drive the movement.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Firstly, set up your spring system. The PCB with LEDs is mounted somehow on the end of the leaf spring. As well as the LEDs, the PCB should also have an accelerometer to measure the movement of the PCB.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pull back the PCB with LEDs and let it oscillate. Look at the output of the accelerometer to measure the frequency of oscillation. Adjust the length of the spring until the oscillation frequency is about 20 swipes per second. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;You're almost there. Now you need to drive the oscillation using the solenoids. Use the accelerometer to synchronise energising the solenoids. &lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2013-09-01T20:55:32.027" />
  <row Id="1802" PostTypeId="5" CreationDate="2013-09-01T22:36:24.477" Score="0" ViewCount="1" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2013-09-01T22:36:24.477" LastActivityDate="2013-09-01T22:36:24.477" />
  <row Id="1803" PostTypeId="4" CreationDate="2013-09-01T22:36:24.477" Score="0" Body="A step-by-step procedure for calculations. Algorithms are used for calculation, data processing, and automated reasoning." OwnerUserId="40" LastEditorUserId="40" LastEditDate="2013-09-02T04:38:04.090" LastActivityDate="2013-09-02T04:38:04.090" />
  <row Id="1804" PostTypeId="2" ParentId="1795" CreationDate="2013-09-02T04:08:31.023" Score="2" Body="&lt;p&gt;Some ideas off the top of my head...  Generally you can either have each robot sense it's own position or have some sort of system find the robots and send them information about their position (or a combination).  Possibly using other robot positions to locate yourself is another option if they can communicate.  You could also combine sensor information from the robots and other sources.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Optical&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can encode either absolute position or relative position on the floor or ceiling.  A sensor on the robot can look at those.  A sensor like the one in your optical mouse can get relative motion off most surfaces even without any pattern.  There were older style mice that used a patterned grid.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You could have two (or more) cameras on every robot looking at different directions, if the walls of the room have the right kind of pattern you could determine your location based on the images.  A spinning camera is another option.  Obstruction of the camera by other robots may be a concern.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A sensor array or camera in the floor or ceiling could locate the robots and then you can send the robots their location.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some sort of spinning optical sensor that can locate the direction of an optical beacon (e.g. a LED).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Sound&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You could have a few beacons around emitting ultrasound chirps.  If they are all synchronized (e.g. fixed delay between them) then given their location you could use a time of flight calculation to determine the position of the robot.  Many years ago I've worked with an ultrasound digitizer that was accurate to about a mm over a distance of about a meter so it seems in the ballpark.  Depending on the shape of your robot and the configuration of the swarm reflections and obstructions may or may not be a problem.  You would need to experiment but my gut feeling is that with enough beacons you could good performance.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ultrasound range finders on every robot.  (spinning?)  Could map the distance to other robots or the walls.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If any of these sound interesting I can try develop those ideas a little further.&lt;/p&gt;&#xA;" OwnerUserId="1584" LastActivityDate="2013-09-02T04:08:31.023" CommentCount="2" />
  <row Id="1805" PostTypeId="2" ParentId="1753" CreationDate="2013-09-03T12:50:26.717" Score="2" Body="&lt;p&gt;I would create a small sketch that allows you to communicate over serial port that will let you create a GUID on the desktop computer and write it to the EEPROM of your uno to a known location.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then later on in your networked arduino code you can use that saved value.  I've done this before and it's pretty simple to implement.  You can even copy / paste guid values from the web like this &lt;a href=&quot;http://www.famkruithof.net/uuid/uuidgen&quot; rel=&quot;nofollow&quot;&gt;Online GUID Generator&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;See this for simple usage.  &lt;a href=&quot;http://arduino.cc/en/Tutorial/EEPROMWrite&quot; rel=&quot;nofollow&quot;&gt;Arduino EEPROMWrite Command&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another option if you have networking already active is to setup a server on your network and have the machines request a GUID from a network server if they don't have one already present on the device, then write that to the EEPROM.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Either way it should be a small step you perform when first programming your devices.&lt;/p&gt;&#xA;" OwnerUserId="208" LastActivityDate="2013-09-03T12:50:26.717" />
  <row Id="1806" PostTypeId="1" CreationDate="2013-09-03T12:54:04.527" Score="3" ViewCount="112" Body="&lt;p&gt;I'm trying to make differential in Google SketchUp using this tutorial &lt;a href=&quot;http://support.ponoko.com/entries/21249896-Gears-and-Joints-with-SketchUp-Sketchy-Physics&quot; rel=&quot;nofollow&quot;&gt;http://support.ponoko.com/entries/21249896-Gears-and-Joints-with-SketchUp-Sketchy-Physics&lt;/a&gt; for gears modeling.&#xA;But I have problem: gears don't collide with any objects (and other gears). What's wrong? How to fix this?&#xA;How to make a bevel gear placed at 90 degrees relative to each other and conical cylindrical gears joints?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;P.S. Is there something like SketchUp and SketchyPhisics in Linux?&lt;/p&gt;&#xA;" OwnerUserId="415" LastActivityDate="2013-09-03T21:32:54.510" Title="Gears modeling in Google SketchUp and SketchyPhisics" Tags="&lt;design&gt;&lt;mechanism&gt;&lt;3d-printing&gt;" AnswerCount="0" />
  <row Id="1807" PostTypeId="2" ParentId="1795" CreationDate="2013-09-03T18:33:28.443" Score="2" Body="&lt;p&gt;The low distance between the top of the robot and the ceiling really restricts your options. It seems pretty much impossible to get a centralised overview of the whole room and work from there.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm not sure what kind of 'room' you are talking about and how much you can instrument it, but it might be an option to place markers on the ceiling rather than the robots. Given the short distance, you'd have to pretty much completely fill the ceiling with tiny markers that can be completely observed by an upwards pointing camera on every single robot, though you might be able to position this camera lower on the robot, say between the front and back wheels on either side, to give you a wider viewing angle. But the biggest challenge would be to print enough distinct markers to instrument the whole ceiling.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Alternatively, it might be conceivable to instrument the floor with lots of RFID tags, provided you can find readers that have a small enough range (AFAIK, RFID readers will only tell you that a certain tag is in range, not where it is). The &lt;a href=&quot;http://www.phidgets.com/products.php?category=14&amp;amp;product_id=1024_0&quot; rel=&quot;nofollow&quot;&gt;Phidgets RFID reader&lt;/a&gt; already has a range of approx. 3 inches, so unless you localise by seeing which group of tags you can observe (if it's possible to observe multiple tags at the same time - can you tell I have no actual working experience with RFID?), you'd have to experiment with getting smaller tags and 'shielding' them to a degree from the reader, so that they can't be read other than at very close range.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;All in all it seems a tough but very interesting challenge. If it's for work, I assume you can't tell us the purpose of the project, but it sure sounds intriguing :)&lt;/p&gt;&#xA;" OwnerUserId="131" LastActivityDate="2013-09-03T18:33:28.443" CommentCount="1" />
  <row Id="1808" PostTypeId="1" AcceptedAnswerId="1810" CreationDate="2013-09-03T19:23:28.217" Score="2" ViewCount="92" Body="&lt;p&gt;I need to assemble a small (about 8cm x 5cm x 5cm maximum), actuator with as much torque as I can get at that size. It will be driving a small reel and pulley (reel is ~1.25cm^3, 5mm center diameter), and needs to respond to load (eg. stop if the load increases beyond a certain threshold). Power to the actuator will be provided via a common bus line, so the space limit isn't further limited by the size of the battery.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My thought is to use a worm drive for this (for torque) and watch for change in current/voltage (for load), but I'm not sure if that is mechanically sound. It seems like the mechanical advantage provided by the worm would make it hard to detect a change in load.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Plan B&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I could add another sensor that would gauge the force being exerted. I'd prefer to avoid adding too many points of failure to the system, but if I did what sort of sensor would I use?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How should I approach this?&lt;/p&gt;&#xA;" OwnerUserId="1316" LastEditorUserId="1316" LastEditDate="2013-09-03T20:48:52.473" LastActivityDate="2013-09-03T21:38:45.603" Title="Tiny high torque actuator/sensor design" Tags="&lt;sensors&gt;&lt;control&gt;&lt;actuator&gt;" AnswerCount="1" CommentCount="3" />
  <row Id="1810" PostTypeId="2" ParentId="1808" CreationDate="2013-09-03T21:38:45.603" Score="5" Body="&lt;p&gt;With a series of planetary gear sets aligned axially, one can gear down by high ratios.  For example, the picture below (a &lt;a href=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Rearview_Mirror_Epicyclic_Gears.jpg/640px-Rearview_Mirror_Epicyclic_Gears.jpg&quot;&gt;wikipedia commons&lt;/a&gt; image used in the &lt;a href=&quot;https://en.wikipedia.org/wiki/Planetary_gear#Gallery&quot;&gt;planetary gear&lt;/a&gt; article) shows a 2.5-cm gearset with ratio -5/352, about 1:70.  Stacking three of these would give a ratio of about 1:343000.  Some torque and power would be lost to friction, and plastic gears would not be strong enough to deliver all of the torque possible at the output, but the concept should be clear.  If multiplying motor torque by 1/3 of a million isn't enough, add a fourth gearset, giving a torque multiplication from motor to output of about 24 million.  Note that rotation speed would be correspondingly divided (by about 24 million) and only about 1/2 to 3/4 of the motor power would arrive at the output, due to friction losses.&lt;img src=&quot;http://i.stack.imgur.com/VZIUx.jpg&quot; alt=&quot;mirror gearset&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To stop turning the pulley if load gets too high, you could use a &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Clutch#Torque_limiter&quot;&gt;torque-limiter&lt;/a&gt;&lt;/em&gt; (or, &lt;em&gt;safety clutch&lt;/em&gt; or  &lt;em&gt;slip clutch&lt;/em&gt;) at the output. &lt;/p&gt;&#xA;" OwnerUserId="478" LastActivityDate="2013-09-03T21:38:45.603" />
  <row Id="1811" PostTypeId="1" CreationDate="2013-09-04T12:03:26.460" Score="1" ViewCount="59" Body="&lt;p&gt;This question is further to &lt;a href=&quot;http://robotics.stackexchange.com/questions/1795/localizing-a-swarm-of-robots&quot;&gt;Localizing a swarm of robots&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In summary: I want to create a swarm of robots which can each measure their own position in a 3x2m room with a 25cm high ceiling, to an accuracy of ±5mm. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;There were some good answers, but most of them were optical methods. I would be interested to hear some non-optical localisation ideas, so I will impose the following further constraints:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Localisation method cannot use optical means, either visible or invisible.&lt;/li&gt;&#xA;&lt;li&gt;Nothing can be added to the floor or ceiling.&lt;/li&gt;&#xA;&lt;li&gt;There's no appreciable gap between the top of the robots and the ceiling.&lt;/li&gt;&#xA;&lt;li&gt;There are no walls, and equipment can be added around the perimeter of the room.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;I look forward to hearing some creative ideas.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2013-09-04T14:04:32.823" Title="Localising a robot swarm non-optically" Tags="&lt;wireless&gt;&lt;swarm&gt;&lt;localisation&gt;" AnswerCount="1" />
  <row Id="1812" PostTypeId="2" ParentId="1811" CreationDate="2013-09-04T13:42:36.020" Score="2" Body="&lt;p&gt;I guess after optic (direct-line of sight) solutions, &lt;a href=&quot;http://electronics.stackexchange.com/questions/8690/signal-triangulation&quot;&gt;triangulation via sonic/radio frequency seems to be a possible solution&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A factor that needs to be decided is how the triangulation will be achieved. Will your transmitters be stationary, or will your receivers be stationary. In other words, will you synchronize your transmitters or your receivers.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Stationary transmitters&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;In other words, your robots will have receivers, while your room has 2 or more stationary transmitters (each synchronized). Each transmitter will continuously broadcast a unique identifier (for instance, each transmitting on their own frequency). The mobile receiver (robot), will then measure the phase shift between each transmission and triangulate.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Stationary Receivers&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;In other words, your robots will have speakers, while your room has 2 or more microphones (each synchronized). Each mobile transmitter (ie, each robot), will have an unique id (again for example their own frequency), while the stationary receivers (synchronized) will listen for broadcasts. The only problem of course is the stationary receivers will need to communicate the triangulated position back to the robot via a parallel channel (eg Bluetooth).&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Implementation&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Since trying to sample time-of-flight for RF waves isn't exactly cheap/easy (299 792 458 m / s at 5 mm : 16.7 ps ~ sampling rate in excess of 50 GHz), I'd recommend going for sonic.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The only problem of course is the desired resolution. Given the speed of sound at sea level 340.29 m/s, a signal pulse will take 14.7 us to travel 5 mm. And since we'd like to take a sample at least twice per our base period, we need to sample at a rate of at least 1/7.35 us = 136 kHz.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;While you do get system's that can sample the audible range at that rate (professional audio recording equipment usually goes up to 192 kHz and above), easily accessible recording equipment usually samples at 48 kHz (PC sound cards).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ultimately I think I'd try and go for stationary (expensive) recorders, and cheap speakers on the robots.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;External links&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://instruct1.cit.cornell.edu/Courses/ee476/FinalProjects/s2007/ai45_hkc2_sbs43/ai45_hkc2_sbs43/index.html#hardware&quot; rel=&quot;nofollow&quot;&gt;Cornell University - PeanutBot, The Audio Homing Robot&lt;/a&gt; (uses a single stationary speaker, with three microphones on the robot itself).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="1775" LastEditorUserId="1775" LastEditDate="2013-09-04T14:04:32.823" LastActivityDate="2013-09-04T14:04:32.823" />
  <row Id="1813" PostTypeId="1" AcceptedAnswerId="1818" CreationDate="2013-09-04T21:51:27.273" Score="2" ViewCount="100" Body="&lt;p&gt;Which software can be used to prototype/design robot parts (mechanical parts, body, gears, etc)&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have some crazy idea I would like to try (quadripedal walking robot, animal-like), but I'd like to design the mechanism and test (to some degree) the mechanism in some kind of simulator before I start wasting money on parts/materials. What tool could I use for that? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm only interested in mechanical design (chassis + servo/motor placement + cogs/gears), not in electronic design. I'm not interesting in robot &lt;em&gt;control&lt;/em&gt; software, because I'll be probably able to slap something like arduino onto it and program behavior I want (experienced programmer)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Details (what I'd like to see)&lt;/strong&gt;:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Should work in 3d. I.e. finished system should be viewable in 3d.&lt;/li&gt;&#xA;&lt;li&gt;I should be able to cut materials like plywood/metal, drill holes, place gears on it, etc.&lt;/li&gt;&#xA;&lt;li&gt;It would be nice if it had some kind of part catalog so to place a gear/cog I wouldn't need to design it from scratch.&lt;/li&gt;&#xA;&lt;li&gt;It would be nice I could test if parts can actually move. I don't need full-blown simulation, just to see if gears can turn or if they'll get stuck.&lt;/li&gt;&#xA;&lt;li&gt;Not interested in electronic circuitry, just need mechanical parts, but should be able to place servos.&lt;/li&gt;&#xA;&lt;li&gt;It would be nice if it could produce blueprints.&lt;/li&gt;&#xA;&lt;li&gt;cheap/inexpensive, if possible.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Basically, I should be able to construct robot mechanism in it (by placing/connecting parts like gears,cogs, motors, springs), or some kind of clock, and test (to some degree) if it actually works.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I know that I could use blender3d for that, but it wasn't exactly designed for this purpose.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I also heard that solidworks could be used for designing mechanical parts, but it is too expensive, especially for one-time-project. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any recommendations?&lt;/p&gt;&#xA;" OwnerUserId="1910" LastEditorUserId="1910" LastEditDate="2013-09-04T21:59:49.670" LastActivityDate="2013-09-05T16:29:04.220" Title="Software for designing mechanical systems/robotic parts" Tags="&lt;software&gt;" AnswerCount="1" ClosedDate="2013-09-06T06:22:49.273" />
  <row Id="1815" PostTypeId="1" AcceptedAnswerId="1833" CreationDate="2013-09-05T12:40:22.553" Score="5" ViewCount="170" Body="&lt;p&gt;I need an equation or a some hints to solve the following problem.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Imagine a &lt;a href=&quot;http://en.wikipedia.org/wiki/Roller_screw&quot; rel=&quot;nofollow&quot;&gt;roller screw&lt;/a&gt; drive. I apply a torque of &lt;code&gt;T&lt;/code&gt; to translative move my load mass &lt;code&gt;M&lt;/code&gt;. I assume my screw has an efficiency of 90%. Now an additional axial force affects my mass in the opposite moving direction. Is this force completely transformed into torque (of course considering the efficiency) or is it possible, that my whole roller screw is moving, because it is not fixed? I just found papers/books/articles for movable slides/loads, but fixed shafts. But in my case motor and shaft are part of an osciallation system.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm not a mechanical engineer, so I'm sorry if the answer may is trivial.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I made a little sketch now &lt;img src=&quot;http://i.stack.imgur.com/70UmY.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The process force &lt;code&gt;Fp&lt;/code&gt; is pushing my mass, most of the force is transformed into a load torque &lt;code&gt;Tp&lt;/code&gt; which acts against my drive torque &lt;code&gt;TD&lt;/code&gt;. Some of the energy is lost by friction. The question is, if there is also a partial force &lt;code&gt;Tp?&lt;/code&gt; which is affecting the bearing and therefore exciting my chassis.&lt;/p&gt;&#xA;" OwnerUserId="1913" LastEditorUserId="-1" LastEditDate="2013-09-08T16:16:12.500" LastActivityDate="2013-09-12T16:56:46.577" Title="Roller Screw drive - axial movement instead of friction" Tags="&lt;movement&gt;&lt;torque&gt;&lt;differential-drive&gt;" AnswerCount="1" CommentCount="10" />
  <row Id="1816" PostTypeId="2" ParentId="815" CreationDate="2013-09-05T14:44:32.470" Score="0" Body="&lt;p&gt;Are you worried that the Arduino may not have enough pins to control 4 different motors plus the stuff on that other shield?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It is possible to control any number of motors using 4 digital pins from the Arduino.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The STMicroelectronics L6470 stepper motor driver chip is designed to be daisy-chained so 4 digital pins from the Arduino can control any number of motors.&#xA;(If you know of any other motor driver that can be daisy-chained to control any number of motors using less than 10 pins from the Arduino, please comment and mention its name).&#xA;I built a prototype using the Sparkfun &lt;a href=&quot;https://www.sparkfun.com/products/10859&quot; rel=&quot;nofollow&quot;&gt;L6470 breakout board&lt;/a&gt;.&#xA;Apparently several people have made other &lt;a href=&quot;http://reprap.org/wiki/Stepper_motor_driver#Stepper_driver_chips&quot; rel=&quot;nofollow&quot;&gt;open-source hardware boards for the L6470&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="187" LastActivityDate="2013-09-05T14:44:32.470" />
  <row Id="1817" PostTypeId="2" ParentId="815" CreationDate="2013-09-05T16:10:39.327" Score="0" Body="&lt;p&gt;Is the problem that the off-the-shelf motor shields all look like they mechanically interfere with the other shield you want to use?&#xA;Perhap you're seeing the &quot;both shields want to be the top shield, so they can't stack&quot; problem?&#xA;It's pretty simple to control servo motors with simple wire connections.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Standard off-the-shelf servo motors have a 3-wire cable for &lt;a href=&quot;https://en.wikipedia.org/wiki/servo_control&quot; rel=&quot;nofollow&quot;&gt;servo control&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Many shields -- in addition to their &quot;main&quot; circuit -- throw in a &quot;power connection&quot; and a few servo connections.&lt;a href=&quot;http://www.scienceprog.com/testing-arduino-motor-shield-with-servo-motor/&quot; rel=&quot;nofollow&quot;&gt;(a)&lt;/a&gt;, &lt;a href=&quot;http://arduino-info.wikispaces.com/SensorShield&quot; rel=&quot;nofollow&quot;&gt;(b)&lt;/a&gt;, &lt;a href=&quot;http://www.robotshop.com/dual-stepper-motor-driver-shield-arduino.html&quot; rel=&quot;nofollow&quot;&gt;(c)&lt;/a&gt;, etc.&#xA;They connect the 3 servo wires connected -- the GND (G) and Power (+) wires connected to the appropriate power supply, and the Arduino GND and the power supply GND connected.&#xA;Typically the signal wire (S) is connected to one of the six special &lt;a href=&quot;http://arduino-info.wikispaces.com/Arduino-PWM-Frequency&quot; rel=&quot;nofollow&quot;&gt;Arduino PWM pins&lt;/a&gt;.&#xA;(This method can drive a maximum of 6 motors -- or less if that other shield needs some of these pins).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you make the same connections between the Arduino and the servo with simple wire connections, it works just as well.&#xA;&lt;a href=&quot;http://www.adafruit.com/blog/2012/12/18/tutorial-arduino-lesson-14-servo-motors/&quot; rel=&quot;nofollow&quot;&gt;(a)&lt;/a&gt;, &lt;a href=&quot;http://forum.arduino.cc/index.php?topic=111690.msg838987#msg838987&quot; rel=&quot;nofollow&quot;&gt;(b)&lt;/a&gt;, &lt;a href=&quot;http://www.instructables.com/id/Controlling-an-RC-Servo-motor-with-an-Arduino-and-/&quot; rel=&quot;nofollow&quot;&gt;(c)&lt;/a&gt;, etc.&lt;/p&gt;&#xA;" OwnerUserId="187" LastActivityDate="2013-09-05T16:10:39.327" />
  <row Id="1818" PostTypeId="2" ParentId="1813" CreationDate="2013-09-05T16:29:04.220" Score="1" Body="&lt;p&gt;You can use &lt;a href=&quot;http://www.sketchup.com/&quot; rel=&quot;nofollow&quot;&gt;google sketchup&lt;/a&gt;. It's free and should be allow you to do most of what you want. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Solidworks would most likely fully match your requirements above. Since it is a one-time project, you could consider evaluating Solidworks by requesting a &lt;a href=&quot;http://www.solidworks.com/sw/purchase/solidworks-trial.htm&quot; rel=&quot;nofollow&quot;&gt;free trial&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Good luck.&lt;/p&gt;&#xA;" OwnerUserId="983" LastActivityDate="2013-09-05T16:29:04.220" />
  <row Id="1819" PostTypeId="2" ParentId="1066" CreationDate="2013-09-06T09:29:25.550" Score="3" Body="&lt;p&gt;As you correctly say, if you want to compute the transform from link $(n+1)$ to link $n$, you should simply invert the matrix $G$. The inverse of a homogenous transformation matrix&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$G = \left[\begin{matrix}&#xA;  R &amp;amp; p \\&#xA;  0 &amp;amp; 1&#xA;\end{matrix}\right]$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;is&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$G^{-1} = \left[\begin{matrix}&#xA;  R^T &amp;amp; -R^T p \\&#xA;  0 &amp;amp; 1&#xA;\end{matrix}\right]$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If $G$ is already available, this is probably the fastest way of computing $G^{-1}$. Otherwise, if only the DH parameters are known, you can insert the expression for $G$ to find this simplified expression for the translation of $G^{-1}$:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$-R^T p = \left[\begin{matrix}&#xA;-a\\&#xA;-d \sin(\alpha)\\&#xA;-d \cos(\alpha)&#xA;\end{matrix}\right]$&lt;/p&gt;&#xA;" OwnerUserId="1917" LastActivityDate="2013-09-06T09:29:25.550" CommentCount="1" />
  <row Id="1820" PostTypeId="2" ParentId="521" CreationDate="2013-09-06T12:08:15.040" Score="1" Body="&lt;p&gt;Your formula for a 6 &lt;em&gt;dof&lt;/em&gt; joint assumes that all 6 joints have the axis $(0, 0, 1)$ in the world frame and that all joints are revolute. Since the 6 joints are thus identical, their columns in the Jacobian are also identical.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Starting over, suppose a joint has an axis $a$ going through a point $r$. Let $e$ be the position of the end-effector. The coordinates of $a$, $r$, and $e$ are all given in the world frame and are being updated as the robot is being moved. The axis $a$ has length $1$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If the joint is revolute, the column of the Jacobian for the joint is&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$J_{\theta}(a, r) = \left[\begin{matrix}&#xA; a \times (e - r) \\&#xA; a&#xA;\end{matrix}\right]$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If the joint is prismatic, the column is&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$J_{p}(a) = \left[\begin{matrix}&#xA; a \\&#xA; 0&#xA;\end{matrix}\right]$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Suppose we have a 6 &lt;em&gt;dof&lt;/em&gt; joint which is not only spherical but can translate in space too. Suppose the axes of the joint are $a_x$, $a_y$, and $a_z$ and that each revolute and prismatic joint shares an axis, so that the Jacobian for the joint becomes&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$J = \left[\begin{matrix}&#xA;  J_p(a_x) &amp;amp; J_p(a_y) &amp;amp; J_p(a_z) &amp;amp; J_{\theta}(a_x, r) &amp;amp; J_{\theta}(a_y, r) &amp;amp; J_{\theta}(a_z, r)&#xA;\end{matrix}\right]$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The axes $a_x$, $a_y$, and $a_z$ depend on the forward kinematics of the robot. To illustrate, let the transformation of the $k$th joint in the world frame be given by&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$F_k = \prod_{i=1}^{k} L_i T_i$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;where the transformations $L_i$ are constants, and the transformations $T_i$ depend on the joint variables. Let $R_c(q)$ and $P_c(q)$ be the transformations that rotate and translate by $q$ about the coordinate axis named $c$ (either $x$, $y$, or $z$).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Let $\Delta q = (\Delta p_x, \Delta p_y, \Delta p_z, \Delta \theta_x, \Delta \theta_y, \Delta \theta_z)$ be a displacement, computed by help of the Jacobian, for the $i$th joint. Let $\Delta T = P_x(\Delta p_x) P_y(\Delta p_y) P_z(\Delta p_z) R_x(\Delta \theta_x) R_y(\Delta \theta_y) R_z(\Delta \theta_z)$ and update the local transformation of the joint by:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$T_i \leftarrow T_i \, \Delta T$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In this formulation of the forward kinematics, the axes $a_x$, $a_y$, and $a_z$ of joint $i$ are exactly the columns of the rotation matrix of $F_i$. Also the position $r$ is the translation vector of $F_i$.&lt;/p&gt;&#xA;" OwnerUserId="1917" LastActivityDate="2013-09-06T12:08:15.040" />
  <row Id="1825" PostTypeId="2" ParentId="344" CreationDate="2013-09-06T14:31:25.567" Score="2" Body="&lt;p&gt;Since the question is about an industrial robot, we probably don't have a model of the dynamics of the robot, so I am assuming we are looking for solutions that optimize a kinematic criterion only.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The robot has a closed-form solution for its inverse kinematics, but unluckily the end-effector has an extra rotational degree of freedom, which means that the robot has essentially 7 degrees of freedom. But because this is just one more &lt;em&gt;dof&lt;/em&gt;, it is not as much of an issue as one might think.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A common trick for such &lt;em&gt;almost&lt;/em&gt; non-redundant robots is to lock the extra degrees of freedom and solve for the remaining joint values analytically. Let's say we write a closed-form IK solver for the 6 &lt;em&gt;dof&lt;/em&gt; robot that returns solutions in $0.05$ ms on average. By iterating from $1$ to $360$ you can therefore find the optimal solution for a discretization of the pen angle of $1^\circ$ in about $18$ ms, which given the application is probably more than adequate.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If most of the time the pen is only moving a little (e.g. when drawing a line), another trick to speed up the search is to make use of numerical IK, for example the pseudoinverse method:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Let $q_1$ be the current configuration of the robot, let $J$ be its Jacobian, and let $\Delta x$ be the displacement of the target relative to the current end-effector transformation. Solve $\Delta x = J \, \Delta q$ for $\Delta q$ and compute a new configuration $q_2 = q_1 + \Delta q$. I am skipping details here, but the solution $\Delta q$ should minimize $\|\Delta q\|$ for a properly chosen metric.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is done for the 7 &lt;em&gt;dof&lt;/em&gt; robot and again should take only fractions of a millisecond. Although $q_2$ might not be a valid configuration (the joint values can be out of bounds) and might not be an accurate IK solution (you can take more pseudoinverse steps, though), most of the time it will be a good starting point for a search using the closed-form solver.&lt;/p&gt;&#xA;" OwnerUserId="1917" LastActivityDate="2013-09-06T14:31:25.567" />
  <row Id="1826" PostTypeId="1" CreationDate="2013-09-07T18:05:23.013" Score="-1" ViewCount="116" Body="&lt;p&gt;Today I was going to buy a motor online, and saw that 10 rpm and 1000 rpm DC motors cost the same. How is it possible to change the rpm without requiring any additional parts cost?&lt;/p&gt;&#xA;" OwnerUserId="1924" LastEditorUserId="350" LastEditDate="2013-09-07T20:06:02.977" LastActivityDate="2013-09-07T20:21:07.433" Title="Why do 1000 rpm and 10 rpm DC motors cost the same?" Tags="&lt;motor&gt;" AnswerCount="2" CommentCount="1" ClosedDate="2013-09-08T06:04:33.527" />
  <row Id="1827" PostTypeId="2" ParentId="1826" CreationDate="2013-09-07T19:10:49.490" Score="1" Body="&lt;p&gt;Revolutions per minute (RPM) is merely one of the parameters of a DC motor. Another important criterion is torque, which may be understood as the power output capability of the motor. Perhaps the 10 RPM motor is capable of driving a heavier load, and the 1000-RPM motor simply cannot reach its nominal revolutions per minute with even a very light load. &lt;/p&gt;&#xA;" OwnerUserId="1833" LastActivityDate="2013-09-07T19:10:49.490" />
  <row Id="1828" PostTypeId="2" ParentId="1826" CreationDate="2013-09-07T20:21:07.433" Score="1" Body="&lt;p&gt;Most likely, the difference between the two motors will be the number of times the wire is wrapped around the &lt;a href=&quot;http://en.wikipedia.org/wiki/Commutator_%28electric%29&quot; rel=&quot;nofollow&quot;&gt;commutator&lt;/a&gt;.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is a &lt;a href=&quot;http://lancet.mit.edu/motors/motors3.html#tscurve&quot; rel=&quot;nofollow&quot;&gt;tradeoff between RPM and torque in DC motors&lt;/a&gt;, where more windings mean more torque (but a lower maximum RPM).  Depending on the characteristics of the motor, some manufacturers use a thicker wire when building motors with fewer windings -- allowing more current to flow.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, it's possible that the same amount of copper wire is being used for both motors, or that it's near enough not to bother with pricing the different motor types differently.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-09-07T20:21:07.433" />
  <row Id="1831" PostTypeId="1" CreationDate="2013-09-09T18:06:08.263" Score="2" ViewCount="447" Body="&lt;p&gt;I want to make a mathematical model of quadcopter in simulink. I have studied quadcopter, although I am new and not build any flying robot before. I studied so far that I have to use four brushless DC motors PID speed control, two motors will rotate clock wise and two anti clock wise. I want to make very simple mathematical model. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The input of the model will be the xyz locations on 3d space, copter will always fly from 0,0,0 path. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So far I decided that I will increment the coordinates step by step for example if I want the next location of the to be x=10, y=10, z=10; then I will increment in these locations and input to a flight control block. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;My question is how can I decide the speed of motors according to x,y,z next location and how to convert that speed into Yaw Pitch and Roll and finnally convert the Yaw, Pitch and Roll into X,Y,Z coordinates. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I need the convertion formulas that can be easily implemented into simulink. &#xA;Please provide help thanks &lt;/p&gt;&#xA;" OwnerUserId="1015" LastActivityDate="2013-10-09T19:55:31.960" Title="quadcopter parameters calculations for simulink model" Tags="&lt;quadcopter&gt;&lt;simulator&gt;" AnswerCount="1" FavoriteCount="0" />
  <row Id="1832" PostTypeId="2" ParentId="1831" CreationDate="2013-09-09T19:18:26.980" Score="1" Body="&lt;p&gt;A linearized quadrotor model can be found in the results section of my paper &lt;a href=&quot;http://arl.cs.utah.edu/pubs/ICRA2013-1.pdf&quot; rel=&quot;nofollow&quot;&gt;Kinodynamic RRT*: Asymptotically Optimal Motion Planning&#xA;for Robots with Linear Dynamics&lt;/a&gt;. This is a state space model that includes the 3D position, 3D velocity, 2D angular position, and 2D angular velocity. The angular position and angular velocity are 2D because it restricts the quadrotor from yawing. If you want to model yaw then you need to add a couple of equations to describe how the yaw at its associated angular velocity changes.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-09-09T19:18:26.980" />
  <row Id="1833" PostTypeId="2" ParentId="1815" CreationDate="2013-09-09T21:13:24.670" Score="3" Body="&lt;p&gt;OK.  &lt;strong&gt;as drawn&lt;/strong&gt;, ignoring mass and accelerations, the force $F_p$ will appear as a torque on your ball screw.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;However&lt;/strong&gt;, the total force on the ball screw, and hence the torque, depends on the mass of the thing you're moving with the ball screw interacting with gravity (if it's being moved in anything other than a horizontal plane), and on whether or not the whole assembly -- frame and load -- is moving at anything other than a steady velocity.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On a bad day, your mass-spring-damper system will have an overall resonance that interacts with your control system, making oscillations happen where you never expected them.&lt;/p&gt;&#xA;" OwnerUserId="1533" LastEditorUserId="350" LastEditDate="2013-09-12T16:56:46.577" LastActivityDate="2013-09-12T16:56:46.577" CommentCount="5" />
  <row Id="1835" PostTypeId="1" CreationDate="2013-09-10T18:51:58.993" Score="2" ViewCount="273" Body="&lt;p&gt;I am trying to build an arm that will have about 5 by 5 by maybe 7 or so centimeters of room for a rotary motor capable of lifting it. The joint will basically allow the arm to rotate in a single degree of freedom in a circle that is perpendicular to the ground.The rest of the arm will probably be around 64 centimeters long and weigh around a minimum of 9 kilograms before it lifts anything. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What kind of motor type would give it the best chance of lifting the arm quickly&lt;sup&gt;&amp;dagger;&lt;/sup&gt; and reasonably accurately&lt;sup&gt;&amp;ddagger;&lt;/sup&gt;? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;sup&gt;&amp;dagger; Raising from straight down to out 90 degrees in around 1 to .5 seconds maximum.&lt;/sup&gt;&lt;br&gt;&#xA;&lt;sup&gt;&amp;ddagger; At least a centimeter at the end of the arm which means probably at the very least 300 positions for the motor.&lt;/sup&gt;&lt;/p&gt;&#xA;" OwnerUserId="1936" LastEditorUserId="37" LastEditDate="2013-09-20T14:56:57.090" LastActivityDate="2013-09-20T14:56:57.090" Title="Effective motor type for robotic arm?" Tags="&lt;motor&gt;&lt;robotic-arm&gt;" AnswerCount="1" CommentCount="7" FavoriteCount="1" />
  <row Id="1837" PostTypeId="1" CreationDate="2013-09-11T12:21:35.940" Score="0" ViewCount="64" Body="&lt;p&gt;I'd like to start with robotics, but unfortunately I know very little about HW engineering. Moreover I used to use such languages as Python, C# and Java, and do not have much experience in C. Still I want very much to be able to program a robot, and I have very big interest in Computer Vision and AI. Are there any platforms/kits that you can buy, and with little time spent you already can program them, preferably in high-order languages?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'd prefer something wheeled (something flying would also be nice, but it may be too hard to be the case for a first robot), with a camera and some additional sensors. Would be also nice to have there something, that could help to avoid obstacles, like laser distance sensor or ultra-sonic sensor. Ideally I would like to build a robot that can navigate in the room without the help of operator. I'd like to look at SLAM some time in future, but for now I just need something to get familiar with the robotics.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also it should probably be not very expensive, at least not before I will be very sure that I am ready to go deeper into robotics. Something for 300-500$ would be awesome.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can somebody suggest kits/platforms/tutorials/any other info?&lt;/p&gt;&#xA;" OwnerUserId="1918" LastActivityDate="2013-09-11T18:57:42.827" Title="Choosing a platform to start" Tags="&lt;beginner&gt;" AnswerCount="1" CommentCount="6" ClosedDate="2013-09-11T22:30:40.490" />
  <row Id="1838" PostTypeId="1" CreationDate="2013-09-11T12:35:16.233" Score="0" ViewCount="783" Body="&lt;p&gt;I am doing simulation of Quadcopter in simulink. I want to know how Yaw, Pitch and Roll effect the flight of Quadcopter? and How these are different from a single rotor helicopter? &#xA;Mainly how to change the RPM to change the x,y,z coordinates of the Quadcopter? &#xA;Is there any Differential Equation that can convert the rpm to yaw pitch and roll? Please help.&lt;/p&gt;&#xA;" OwnerUserId="1015" LastActivityDate="2013-09-11T18:51:37.317" Title="How Yaw, Pitch and Roll effect the flight of Quadcopter?" Tags="&lt;quadcopter&gt;" AnswerCount="1" CommentCount="0" ClosedDate="2013-09-12T05:42:39.237" />
  <row Id="1839" PostTypeId="1" CreationDate="2013-09-11T15:51:34.930" Score="4" ViewCount="70" Body="&lt;p&gt;I'm new to the whole visual servoing area.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm now reading the tutorial &lt;a href=&quot;http://www.irisa.fr/lagadic/pdf/2006_ieee_ram_chaumette.pdf&quot; rel=&quot;nofollow&quot;&gt;Visual Servo Control &#xA;Part I: Basic Approaches&quot;&lt;/a&gt; and I don't understand something fundamental - what information is available to the robot?&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Is the 3D location of the tracked features in the current frame known?&lt;/li&gt;&#xA;&lt;li&gt;Is it known for the desired frame?&lt;/li&gt;&#xA;&lt;li&gt;Is it known for both?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;If it's known for both - then what would be the best thing to do? &#xA;Would it be to compute the current and desired 3D location and orientation of the robot, and plan an optimal path accordingly, essentially knowing everything in advance?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, in what sense could a control law (i.e translation + rotation path) be optimal for a visual servo?&lt;/p&gt;&#xA;" OwnerUserId="1940" LastEditorUserId="350" LastEditDate="2013-09-13T03:22:34.940" LastActivityDate="2013-09-13T03:22:34.940" Title="What frame of reference is used during Visual Servoing?" Tags="&lt;localization&gt;&lt;research&gt;&lt;visual-servoing&gt;" AnswerCount="1" />
  <row Id="1841" PostTypeId="2" ParentId="1838" CreationDate="2013-09-11T18:51:37.317" Score="2" Body="&lt;p&gt;In a &lt;strong&gt;helicopter&lt;/strong&gt; (which has 2 rotors, one main rotor and one tail rotor) the angle of attack of the main rotor controls the altitude, pitch, and roll. The yaw is controlled by the counter-torque rotor (tail rotor) which counter acts the reaction torque exerted by the rotation of main rotor which acts on the body of the helicopter. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Cyclic Control for Pitch and Roll&lt;/strong&gt; &#xA;The blades of the main rotor are pitched up or down cyclically, that is, the pitch depends on the blades current position in the rotation cycle. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Collective Control for Altitude&lt;/strong&gt;&#xA;The blades are pitched up or down &quot;collectively&quot;, that is, at the same time. This produces a balanced lift force that can move the helicopter up or down. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Throttle control&lt;/strong&gt;&#xA;The throttle controls the speed of rotation of the blades. Through mechanical or electro-mechanical control systems this is often automatically controlled to maintain constant power while altering the other two control mechanisms.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;More information here: &#xA;&lt;a href=&quot;http://en.wikipedia.org/wiki/Helicopter_flight_controls&quot; rel=&quot;nofollow&quot;&gt;http://en.wikipedia.org/wiki/Helicopter_flight_controls&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In a &lt;strong&gt;quadcopter&lt;/strong&gt;, the pitch of the blades doesn't change. Instead, the rotation speed of the rotors change to control the flight dynamics.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In a plus configuration&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Pitch&lt;/strong&gt;&#xA;Pitch is controlled by increasing and decreasing the rpms of the front and back rotors causing a moment which causes the copter to pitch up or down. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Roll&lt;/strong&gt;&#xA;Same mechanism as pitch but using left and right rotors instead of front and rear.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Yaw&lt;/strong&gt;&#xA;In a quadcopter the rotors are counter rotating. Two of the rotors rotate in one direction and two rotate in the other. If the rpms of all rotors are the same then no moment about he yaw axis is created. By altering the rpms of the sets of counter rotating rotors, a moment will be created and the copter will yaw.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here is a paper that models and simulates the dynamics of a quadcopter:&#xA;&lt;a href=&quot;http://andrew.gibiansky.com/downloads/pdf/Quadcopter%20Dynamics,%20Simulation,%20and%20Control.pdf&quot; rel=&quot;nofollow&quot;&gt;http://andrew.gibiansky.com/downloads/pdf/Quadcopter%20Dynamics,%20Simulation,%20and%20Control.pdf&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="983" LastActivityDate="2013-09-11T18:51:37.317" />
  <row Id="1842" PostTypeId="2" ParentId="1837" CreationDate="2013-09-11T18:57:42.827" Score="1" Body="&lt;p&gt;I would suggest trying &lt;a href=&quot;http://mindstorms.lego.com/%E2%80%8E&quot; rel=&quot;nofollow&quot;&gt;lego mindstorms&lt;/a&gt;. It removes a lot of the electronics, and mechanical barriers when starting to learn about robotics.&lt;/p&gt;&#xA;" OwnerUserId="983" LastActivityDate="2013-09-11T18:57:42.827" CommentCount="1" />
  <row Id="1844" PostTypeId="1" AcceptedAnswerId="1849" CreationDate="2013-09-12T15:15:05.590" Score="3" ViewCount="470" Body="&lt;p&gt;My quad copter can balance itself in the air using data collected from mpu6050. With the sonar sensor, it can hover at a specific height, but it  moves on the horizontal plane in a random direction.  If i put an object below it, it will ascend to keep the distance between the sonar senor and the object.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now i want to make it have the ability to hover stably. Is it possible to add a downward-facing camera to calculate the speed of optical flow in order to keep it hovering on the same point in the horizontal plane?  Could I use a forward-facing camera to stabilize its vertical speed?&lt;/p&gt;&#xA;" OwnerUserId="1948" LastEditorUserId="350" LastEditDate="2013-09-13T03:21:34.610" LastActivityDate="2014-01-16T08:46:34.223" Title="Stabilizing a quadcopter with optical flow" Tags="&lt;sensors&gt;&lt;quadcopter&gt;&lt;cameras&gt;&lt;visual-servoing&gt;" AnswerCount="4" CommentCount="2" FavoriteCount="2" />
  <row Id="1845" PostTypeId="2" ParentId="1839" CreationDate="2013-09-12T16:52:52.043" Score="1" Body="&lt;p&gt;Generally, visual servoing is a way to measure your position &lt;em&gt;relative&lt;/em&gt; to features that are seen on the camera, without having to know your absolute position.  In other words, registering those features with those in a global frame would be a separate process.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Remember that visual servoing is not limited to simply providing more data about your static environment -- it's entirely appropriate to use visual servoing to maintain a position relative to something else in the environment that might move.  &lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-09-12T16:52:52.043" />
  <row Id="1846" PostTypeId="2" ParentId="1844" CreationDate="2013-09-13T03:21:19.577" Score="0" Body="&lt;p&gt;It sounds like you want to control the position of your quadcopter, and although it's possible to do with a camera I don't think optical flow is the right way to approach the problem.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Rather than measure the motion of the quadcopter, you should measure the position.  For that, you'll want to use the camera to identify features in its field of vision, then attempt to keep them in the same place relative to the vehicle.  This is called &lt;a href=&quot;http://en.wikipedia.org/wiki/Visual_Servoing&quot; rel=&quot;nofollow&quot;&gt;Visual Servoing&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-09-13T03:21:19.577" />
  <row Id="1847" PostTypeId="2" ParentId="1844" CreationDate="2013-09-13T09:54:47.517" Score="1" Body="&lt;p&gt;You can definitely use Visual Servoing for pose maintenance in the X-Y plane. You need to have sufficient distinct features on the ground to get a good estimate of drift/spin etc. For example, on an uniform and large ground/field, lack of features might become a problem. But things will be more in your control and you can add visual cues into the scene to assist the image processing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The forward facing camera is quite different. If your quadcopter flies high enough and is staring right into the horizon, precise pose maintenance will be very difficult (roll/pitch stabilisation might become easy in that case). But stabilising the vertical speed based on solely its front facing camera may not be a very good idea. &lt;/p&gt;&#xA;" OwnerUserId="1949" LastActivityDate="2013-09-13T09:54:47.517" />
  <row Id="1848" PostTypeId="2" ParentId="758" CreationDate="2013-09-13T12:19:30.160" Score="-1" Body="&lt;p&gt;The thing is that it's an opinion. Everyone sees things differently and while this may affect it I think it has more to do with each individual.&lt;/p&gt;&#xA;" OwnerUserId="1950" LastActivityDate="2013-09-13T12:19:30.160" CommentCount="1" />
  <row Id="1849" PostTypeId="2" ParentId="1844" CreationDate="2013-09-13T20:52:55.443" Score="6" Body="&lt;p&gt;The following diagram (&lt;a href=&quot;http://www.thedambusters.org.uk/height.html&quot;&gt;1&lt;/a&gt;) illustrates a method by which a Lancaster navigator determined airplane height above the water of a lake. Such a method is useful if the ground lacks features needed for other forms of Visual Servoing.  A program I saw about mission &lt;a href=&quot;https://en.wikipedia.org/wiki/Operation_Chastise&quot;&gt;Chastise&lt;/a&gt; showed one spotlight shining green and the other red, to avoid confusion about which way to go to get to correct altitude.  Note, the bomb aiming &lt;a href=&quot;http://www.thedambusters.org.uk/sight.html&quot;&gt;rangefinder&lt;/a&gt; used similar geometric principles.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/gz4i3.jpg&quot; alt=&quot;2-spotlight height-method&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;With a quadcopter, you could use red and green lasers, eg from a red laser pointer and a green laser pointer.  You could also add servos to rotate one or both of the lasers to adjust the altitude setpoint.  A camera or a line sensor would detect the relative positions where the lights hit the ground.&lt;/p&gt;&#xA;" OwnerUserId="478" LastActivityDate="2013-09-13T20:52:55.443" CommentCount="4" />
  <row Id="1853" PostTypeId="1" CreationDate="2013-09-15T20:45:39.083" Score="3" ViewCount="86" Body="&lt;p&gt;i need your advice if someone experienced something similar. I try using digital servo but when i tried to connect it to board by this tutorial &lt;a href=&quot;https://blogs.oracle.com/hinkmond/entry/connect_robot_servo_to_rpi3&quot; rel=&quot;nofollow&quot;&gt;https://blogs.oracle.com/hinkmond/entry/connect_robot_servo_to_rpi3&lt;/a&gt;&lt;br&gt;&#xA;servo motor only shakes for first ten cycles but after that turns normally. I have no idea why is that but in every article i read that controlling digital servo is same as analog with no need to program them after unboxing.&#xA;Thanks for any idea&lt;/p&gt;&#xA;" OwnerUserId="1955" LastActivityDate="2013-09-16T22:08:02.160" Title="Digital servo shaking" Tags="&lt;raspberry-pi&gt;&lt;servos&gt;" AnswerCount="1" />
  <row Id="1854" PostTypeId="2" ParentId="1853" CreationDate="2013-09-16T00:28:24.200" Score="1" Body="&lt;p&gt;The tutorial is using software pwm from java code. If the PI is otherwise busy or the jvm pauses for garbage collection, the pwm signals to the servo will be erratic. Which could be causing your problems.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have to admit to only looking at the first page of the tutorial.... The other problem I encountered which was very confusing was erratic behaviour caused by the servo drawing more powerr than the PI can supply... Yes I was powering my servo from the pi's 5 volt rail.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;By far the most likely answer is that java does lots of small garbage collections for a while until it adjusts its settings and settles into a much longer garbage collection cycle causing your program to pause repeatedly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When java does a garbage collection your code stops, therefore so does the pwm and this would cause the strange behavior your are describing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For my servos I'm using the adafruit 16 Channel pwm board, it has it's own clock, you talk to it via i2c and it leaves your code free to do other stuff.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You should probably do some reading about java garbage collection, java and real-time processing don't go together so well. As long as you understand that you can only get near to real-time processing out of java, all is good.&lt;/p&gt;&#xA;" OwnerUserId="1819" LastEditorUserId="1819" LastEditDate="2013-09-16T22:08:02.160" LastActivityDate="2013-09-16T22:08:02.160" CommentCount="2" />
  <row Id="1856" PostTypeId="1" CreationDate="2013-09-16T17:33:16.537" Score="0" ViewCount="148" Body="&lt;p&gt;I am tasked with creating a system that will recognize fish pulled out of a lake. The system should be able to identify the type of species of fish. Typically, I turn to Arduino for projects like this. However, based on what I've read about image processing, it's sounding like Arduino doesn't have the processing power. Does anyone have any suggestions for development boards and cameras that can easily interface with the board?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've look at this option, &lt;a href=&quot;http://www.finboard.org/videos/introducing-finboard?utm_campaign=Embedded%20Processing%20and%20DSP%20Newsletter%2013-Q3%20NA&amp;amp;utm_medium=email&amp;amp;utm_source=Eloqua&quot; rel=&quot;nofollow&quot;&gt;http://www.finboard.org/videos/introducing-finboard?utm_campaign=Embedded%20Processing%20and%20DSP%20Newsletter%2013-Q3%20NA&amp;amp;utm_medium=email&amp;amp;utm_source=Eloqua&lt;/a&gt;. It seems like it would be a nice all in one type of thing. Has anyone used anything like this?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks!&lt;/p&gt;&#xA;" OwnerUserId="1958" LastActivityDate="2013-10-18T23:26:32.243" Title="Need suggestions for object recognition" Tags="&lt;arduino&gt;&lt;microcontroller&gt;&lt;raspberry-pi&gt;&lt;cameras&gt;" AnswerCount="2" CommentCount="1" FavoriteCount="0" />
  <row Id="1857" PostTypeId="1" AcceptedAnswerId="1859" CreationDate="2013-09-16T17:59:59.720" Score="2" ViewCount="58" Body="&lt;p&gt;I'm kicking around the idea of building a small passive sonar for an autonomous submarine. I've looked through the net for parts and finding a good transducer for converting the sound underwater into an electrical impulse. After looking at parts I got into the piezoelectric materials used for doing this such as barium titanate or Lead zirconate titanate. From what I've read on the web, some of these materials are toxic. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;My question is, are there piezoelectric materials that one could to build a sensor from scratch that does not possess the toxic qualities? Something that could preferably thrown in a pool w/ my kids and not give them or me any defects.&lt;/p&gt;&#xA;" OwnerUserId="1957" LastEditorUserId="350" LastEditDate="2013-09-16T18:24:42.563" LastActivityDate="2013-09-16T18:46:59.793" Title="Transducer for underwater applications (passive sonar)" Tags="&lt;sensors&gt;" AnswerCount="1" />
  <row Id="1858" PostTypeId="1" CreationDate="2013-09-16T18:18:13.083" Score="4" ViewCount="104" Body="&lt;p&gt;Careful inspection of page 35 (figure 58) of the ADXL345 datasheet (rev. D) shows that under gravitational loading only, the chip uses a left-handed coordinate system.  My own experiments with this chip confirm this.  What's the deal?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I typically only use the chip to indicate the gravity vector.  So when using this chip, I simply negate the values to get a right handed coordinate system.  Does anyone else do this? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/bItD6.png&quot; alt=&quot;Image from ADXL345 Datasheet&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="110" LastEditorUserId="983" LastEditDate="2013-09-16T22:48:50.347" LastActivityDate="2013-09-17T18:38:32.547" Title="Why do 3-axis accelerometers seemingly have a left-handed coordinate system?" Tags="&lt;sensors&gt;&lt;imu&gt;&lt;accelerometer&gt;&lt;calibration&gt;" AnswerCount="1" CommentCount="1" FavoriteCount="1" />
  <row Id="1859" PostTypeId="2" ParentId="1857" CreationDate="2013-09-16T18:46:59.793" Score="3" Body="&lt;p&gt;In general, the microphone should be covered in some sort of waterproofing material (called &quot;potting&quot;) that would prevent its materials from ever coming in contact with the pool water.  So unless you are concerned that the microphone will be smashed to pieces while in your pool, it shouldn't be a problem&lt;/p&gt;&#xA;&#xA;&lt;p&gt;That said, there are some other transducer technologies besides piezo.  Ribbon microphones won't suffice, mostly because of their fragility.  Dynamic microphones might also a bad idea, because they are generally larger and require more motion than the others.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'd recommend trying a cheap electrostatic (also called electret) microphone.  You should be able to cover it in silicone RTV or &quot;plumbing goop&quot; and still get a signal out of it.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-09-16T18:46:59.793" />
  <row Id="1860" PostTypeId="2" ParentId="1856" CreationDate="2013-09-16T19:48:36.240" Score="1" Body="&lt;p&gt;I don't think it would be powerful enough, but you could look into the raspberry pi.  It has an HDMI port and ethernet port, and it allows you to run Linux. The Beaglebone is similar but more powerful. At work when I built an image processing platform for an autonomous ATV we used a miniITX motherboard with an i5 processor and a separate firewire card plugged into the PCIE port (this was for the stereo camera). Computer vision can involve some very intense computation, so I'd probably recommend a similar setup. However, the perception system I built was constantly running in a loop, whereas yours only needs to process one image and it's probably fine if it takes 10+ seconds to operate. When driving an autonomous vehicle, you don't have that kind of time XD. For those reasons, you might be able to get away with the previously mentioned boards.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here's a video of someone using a webcam to capture video and images (and look at that he's looking at FISH!) with a Beaglebone. He's also using the openCV library, which is something you'd probably want to use as well: &lt;a href=&quot;http://www.youtube.com/watch?v=8QouvYMfmQo&quot; rel=&quot;nofollow&quot;&gt;http://www.youtube.com/watch?v=8QouvYMfmQo&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1960" LastEditorUserId="1960" LastEditDate="2013-09-16T21:50:47.313" LastActivityDate="2013-09-16T21:50:47.313" />
  <row Id="1861" PostTypeId="1" CreationDate="2013-09-17T13:25:28.787" Score="3" ViewCount="182" Body="&lt;p&gt;I have a question about car-like robot localization using only dead-reckoning. Given: &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;robot position (at current time step) in the form $\begin{bmatrix}x &amp;amp; y &amp;amp; \theta\end{bmatrix}$ (theta is the heading)&lt;/li&gt;&#xA;&lt;li&gt;steering angle &lt;/li&gt;&#xA;&lt;li&gt;distance traveled between two time steps&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;How can I estimate the position of the robot at the next time step?&lt;/p&gt;&#xA;" OwnerUserId="1965" LastEditorUserId="350" LastEditDate="2013-09-17T15:30:53.477" LastActivityDate="2013-09-23T17:02:24.017" Title="question about car-like robot localization based on dead-reckoning" Tags="&lt;mobile-robot&gt;&lt;localization&gt;" AnswerCount="3" CommentCount="4" FavoriteCount="1" />
  <row Id="1862" PostTypeId="2" ParentId="1858" CreationDate="2013-09-17T18:38:32.547" Score="1" Body="&lt;p&gt;At the end of the day, you can use a matrix to transform whatever coordinate system was used to your own system. This is typically the case when you have to place parts in a certain direction because of routing difficulties. Using a simple 3x3 matrix you can transform X,Y,Z readings so that they all align on multiple sensors. The matrix will have 0, 1 and -1 values accordingly depending on how the transformation is to be done.&lt;/p&gt;&#xA;" OwnerUserId="804" LastActivityDate="2013-09-17T18:38:32.547" />
  <row Id="1863" PostTypeId="1" CreationDate="2013-09-17T19:16:32.240" Score="1" ViewCount="33" Body="&lt;p&gt;I want to build some simple application. I need a 5 or 6 degrees of freedom robotic arm. The arm must have feedback, so that I can control it preciously. The arm must be able to handle at least 5 lbs. And the arm would be able to work 10 hours a day.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My budget is USD$300 . Any suggestion?&lt;/p&gt;&#xA;" OwnerUserId="1967" LastActivityDate="2013-09-17T19:16:32.240" Title="May I have some suggestion on inexpensive robotic arm?" Tags="&lt;robotic-arm&gt;" CommentCount="4" ClosedDate="2013-09-17T22:13:13.650" />
  <row Id="1864" PostTypeId="1" AcceptedAnswerId="1921" CreationDate="2013-09-18T00:50:06.823" Score="2" ViewCount="312" Body="&lt;p&gt;I was looking into the  Razor IMU from Sparkfun, and realized that the only example code on sparkfun's website was for it was meant for hooking it up to a computer (the AHRS head tracker used a serial to usb chip). I looked on google and saw nothing but stories about how it did not work. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there any good way to hook up the  Razor IMU to an arduino uno (or any arduino without hardware support for more than one serial port), and if so does example code exist?&lt;/p&gt;&#xA;" OwnerUserId="1667" LastActivityDate="2013-10-02T12:59:05.517" Title="Razor IMU Arduino interfacing" Tags="&lt;arduino&gt;&lt;imu&gt;" AnswerCount="2" FavoriteCount="0" />
  <row Id="1866" PostTypeId="2" ParentId="1132" CreationDate="2013-09-18T09:20:47.267" Score="0" Body="&lt;p&gt;On the market are available a wide range of robotics kits C compatible. As a start I recommend you to use Arduino board, which can be programmed using C and then jump into an &lt;a href=&quot;http://www.intorobotics.com/robotic-kits-for-developing-new-and-exciting-diy-projects/&quot; rel=&quot;nofollow&quot;&gt;advanced robotics kit&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1970" LastActivityDate="2013-09-18T09:20:47.267" CommentCount="1" />
  <row Id="1867" PostTypeId="2" ParentId="1861" CreationDate="2013-09-18T23:54:17.453" Score="0" Body="&lt;p&gt;I'm reasonably sure the answer to your original question using the steering angle, will involve some hefty calculus. Although I'd like to be proven wrong.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'd suggest putting encoders on the non steering pair of wheels so you can tell how far each wheel has traveled. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;As the non steering wheels are always pointing the same direction you can use the information about how far each wheel has traveled in the same way that you would for a differential drive robot. This does of course assume that the to wheels can rotate independently of each other, as is traditional with cars having a differential to allow for the vehicle turning.&lt;/p&gt;&#xA;" OwnerUserId="1819" LastEditorUserId="1819" LastEditDate="2013-09-19T11:23:05.167" LastActivityDate="2013-09-19T11:23:05.167" CommentCount="2" />
  <row Id="1868" PostTypeId="2" ParentId="554" CreationDate="2013-09-19T03:48:00.900" Score="0" Body="&lt;p&gt;have you seen these new zinc air 8cell 10,000mAh 12V drone batteries? &#xA;&lt;a href=&quot;http://www.tradekorea.com/product-detail/P00265914/drone_battery_10000mAh.html#.UjpxM2QpY2K&quot; rel=&quot;nofollow&quot;&gt;http://www.tradekorea.com/product-detail/P00265914/drone_battery_10000mAh.html#.UjpxM2QpY2K&lt;/a&gt;&#xA;saw the chart on different power to weight ratios on the above discussion comparing efficiency to fuel cells (which are still too heavy 1.2kg + fuel^800g+)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;was toying round with the idea of a quad fitted with a zinc air 10,000mAh battery, 4xGenesys alternators and 2x super capacitors&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Barry Densley&lt;/p&gt;&#xA;" OwnerUserId="1973" LastActivityDate="2013-09-19T03:48:00.900" />
  <row Id="1869" PostTypeId="2" ParentId="1864" CreationDate="2013-09-19T04:11:57.403" Score="0" Body="&lt;p&gt;The Razor IMU has an ATmega328 microcontroller on board that can be programmed with the Arduino IDE according to &lt;a href=&quot;https://www.sparkfun.com/products/10736&quot; rel=&quot;nofollow&quot;&gt;sparkfun's product page&lt;/a&gt;. You could use the tx/rx pins (serial communication) to connect to your other Arduino's rx/tx pins (tx to rx, tx to rx) and program a communication protocol to pass data from the Razor IMU to the Arduino Uno. The Razor IMU probably already has code on board to do this. It's a matter of writing the Uno's code to request and receive the data. The Razor IMU uses 3.3V logic so make sure you use an arduino variant that uses 3.3V or use a level shifter.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another option is to &lt;a href=&quot;http://trandi.wordpress.com/2011/01/03/razor-9dof-imu-i2c-to-arduino/&quot; rel=&quot;nofollow&quot;&gt;hack an I2C connection&lt;/a&gt;. This involves soldering to a pin ATmega328 and modifying some of its code.&lt;/p&gt;&#xA;" OwnerUserId="1125" LastActivityDate="2013-09-19T04:11:57.403" />
  <row Id="1870" PostTypeId="2" ParentId="1861" CreationDate="2013-09-19T17:25:07.807" Score="1" Body="&lt;p&gt;Assuming that this doesn't count as a duplicate of the math that &lt;a href=&quot;http://robotics.stackexchange.com/users/720/daniel-oertwig&quot;&gt;Daniel Oertwig&lt;/a&gt; provided in his question &quot;&lt;a href=&quot;http://robotics.stackexchange.com/q/1653/350&quot;&gt;Calculate position of differential drive robot&lt;/a&gt;&quot;, the calculations are as follows (for each time step):&lt;/p&gt;&#xA;&#xA;&lt;p&gt;First, calculate the distance travelled.&#xA;$$&#xA;\Delta d = \frac{\Delta L + \Delta R}{2} = \Delta t * s&#xA;$$&#xA;Where $L$ is the left wheel odometry, $R$ is the right wheel odometry, and s is the vehicle speed.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Next, calculate the change in $x, y$ position.&#xA;$$&#xA;\Delta x = \Delta d \cdot cos(\theta) \\&#xA;\Delta y = \Delta d \cdot sin(\theta)&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Where $\theta$ is the orientation angle (in radians) of the robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Next, calculate the change in the heading.&#xA;$$&#xA;\Delta \theta = \frac{\Delta R - \Delta L}{w}&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Where $w$ is the distance betweeen the two wheels.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The accuracy of this technique is inversely proportional to the size of the time steps ($\Delta{t}$), and will accumulate error over time.  You can improve estimation if you have a compass, as you can detect some slippage of the wheels by comparing the actual vs expected orientation.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-09-23T17:02:24.017" LastActivityDate="2013-09-23T17:02:24.017" />
  <row Id="1871" PostTypeId="2" ParentId="1835" CreationDate="2013-09-19T18:49:09.810" Score="3" Body="&lt;p&gt;So you want to lift 9kg of mass, which means a force of around 90N, that's on an arm that's 64cm long, in one second.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$\frac{\left(90N\right)\left(0.64m\right)}{1s}\simeq58W$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, that's probably doable.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You don't say anything at all about gearing -- how do you propose to take the high-speed, low-torque power that comes from most motors and turn it into the low-speed, high-torque (or high-force) power that you need for the arm?  Do you have space allocated for that, or were you planning on attaching your motor output directly to the arm?&lt;/p&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-09-19T18:49:09.810" CommentCount="2" />
  <row Id="1873" PostTypeId="2" ParentId="1861" CreationDate="2013-09-20T11:37:54.800" Score="1" Body="&lt;p&gt;With a vehicle with steered wheels the simple approach is to calculate the centre of rotation for the vehicle and then, given the speed of the vehicle, the distance travelled around the arc can be calculated. This results in a change in position and heading. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The centre of rotation can be determined by projecting lines along the axles of the four wheels and finding where they intersect. Normally the rear wheels are non steering so they project a line along the rear axle line. If the steering geometry is 100% Ackermann, the lines projected from the front axles will intersect at the same point on the rear axle line, giving the centre of rotation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The 'AckerMann Steering Geometry' and 'Slip Angle' entries on Wikipedia cover this quite nicely without getting bogged down in the maths.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note that this is a simple model which ignores wheel slip, static toe etc&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A slightly more complex approach is to calculate the angle of the wheels relative to the motion of the vehicle (aka the slip angle) and then determine the force vector generated by each wheel. &#xA;Each wheel has a longitudinal force (rolling resistance and driving/braking torque) and a lateral force (generated by the slip) which combine to give the force vector.&#xA;Each of these forces act upon the vehicle to give a net acceleration (both linear and rotational)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This approach requires knowledge of the wheel loads and, at the least, an estimation of the tyre slip-force curves, although you could assume the force is linearly dependent on slip angle for low speed modelling.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you want to really simplify matters you can treat the vehicle as a bicycle model i.e. two wheels on the centreline, one steering.&#xA;The position calculation can then be approximated by using the steering angle to generate a rotation around the centre of gravity (the steering angle is roughly proportional to a force which acts along the axle line of the wheel) and then travel in a straight line using the vehicle velocity over the sampling interval. In some regards this is similar to the calculations required for a tracked vehicle.&lt;/p&gt;&#xA;" OwnerUserId="1978" LastEditorUserId="1978" LastEditDate="2013-09-20T11:58:15.750" LastActivityDate="2013-09-20T11:58:15.750" />
  <row Id="1874" PostTypeId="1" CreationDate="2013-09-21T07:16:58.173" Score="-1" ViewCount="115" Body="&lt;p&gt;I am a programmer by profession and new to Robotics. I have studied ECE, so know electronics, but not very familiar with mechanical aspects of robotics. I am working on a learning project with Dagu Rover 5 platform.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am trying to control the 4 DC motors with PWM and want to use the optical encoders for feedback. I am looking for some algorithms, example code in C to effectively control the rover. I know how to control the GPIO, PWM and interrupts from the processor. I am more interested in learning the algorithm that controls the motors based on this. For now, i am working on a manual robot, controlled with up/down/left/right keys. In future, I would like to add sensors, camera etc and work on autonomous aspects. Any pointers would be helpful.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For reference, I am working on the Raspberry Pi platform to control the rover.&lt;/p&gt;&#xA;" OwnerUserId="1144" LastActivityDate="2013-10-27T05:02:11.357" Title="Where I can learn algorithms or and find examples of code for controlling a rover?" Tags="&lt;mobile-robot&gt;&lt;algorithm&gt;&lt;pwm&gt;&lt;c&gt;" AnswerCount="1" CommentCount="2" />
  <row Id="1876" PostTypeId="1" CreationDate="2013-09-22T09:47:40.777" Score="1" ViewCount="95" Body="&lt;p&gt;Is it possible to get two images from the Raspberry Pi camera mounted on a remote controlled bot and have them sent to a computer through Wi-Fi and process the images in the computer to generate a depth map?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;All this is to be done in a very short time so that the robot can be helped with its locomotion without making it completely autonomous.&lt;/p&gt;&#xA;" OwnerUserId="1989" LastEditorUserId="1906" LastEditDate="2013-09-26T22:36:01.543" LastActivityDate="2013-09-26T22:36:01.543" Title="Depth map with Raspberry Pi" Tags="&lt;raspberry-pi&gt;" AnswerCount="1" />
  <row Id="1877" PostTypeId="1" CreationDate="2013-09-22T11:15:25.803" Score="1" ViewCount="121" Body="&lt;p&gt;I am going to start a project on controlling robots using hand gestures.&#xA;Though I have used MATLAB for this purpose earlier, I realized it is extremely slow for any practical real-time system.&#xA;I am currently planning to use OpenCV for this purpose.&#xA;I want suggestions on, if OpenCV is the best alternative, are there any other alternatives and if I use OpenCV, which language should I go for, C, C++ or Python?&lt;/p&gt;&#xA;" OwnerUserId="1954" LastActivityDate="2013-11-14T10:48:34.290" Title="Controlling bot using video and image processing" Tags="&lt;real-time&gt;" AnswerCount="2" CommentCount="3" FavoriteCount="1" />
  <row Id="1878" PostTypeId="2" ParentId="1876" CreationDate="2013-09-22T16:36:01.873" Score="2" Body="&lt;p&gt;Yes, it is possible. This is a form of &lt;a href=&quot;http://en.wikipedia.org/wiki/Computer_stereo_vision&quot; rel=&quot;nofollow&quot;&gt;stereo vision&lt;/a&gt;. You will need an accurate model of how the robot moved between frames. Then you can use stereo vision techniques to calculate the disparity.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-09-22T16:36:01.873" />
  <row Id="1879" PostTypeId="5" CreationDate="2013-09-24T08:25:52.737" Score="0" ViewCount="4" Body="&lt;p&gt;Real-time software is one with tasks that have critical timing requirements. Failure in delivering results within the required deadlines results in catastrophe at worst and uselessness of the results at best.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Real-time software is executed on an &lt;a href=&quot;http://en.wikipedia.org/wiki/Real-time_operating_system&quot; rel=&quot;nofollow&quot;&gt;RTOS&lt;/a&gt; capable of guaranteeing that those deadlines are meant, as far as the task scheduling is concerned. The task itself must be as deterministic as possible to guarantee production of its results within the allocated time slice.&lt;/p&gt;&#xA;" OwnerUserId="158" LastEditorUserId="158" LastEditDate="2013-09-24T17:57:12.077" LastActivityDate="2013-09-24T17:57:12.077" />
  <row Id="1880" PostTypeId="4" CreationDate="2013-09-24T08:25:52.737" Score="0" Body="Real-time software is one with tasks that have critical timing requirements. Failure in delivering results within the timing requirement results in catastrophe at worst and uselessness of the results at best." OwnerUserId="158" LastEditorUserId="158" LastEditDate="2013-09-24T17:57:42.313" LastActivityDate="2013-09-24T17:57:42.313" />
  <row Id="1881" PostTypeId="1" AcceptedAnswerId="1882" CreationDate="2013-09-24T15:50:54.913" Score="0" ViewCount="263" Body="&lt;p&gt;I ask this since assembly language is really close to the micro-controller hardware, and what micro-controller would you reccomend.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The bot has to search for object that I show it before and then I 'lose' the object. Note, I do not know anything about micro-controllers.&lt;/p&gt;&#xA;" OwnerUserId="1888" LastEditorUserId="1888" LastEditDate="2013-09-24T16:37:48.200" LastActivityDate="2013-09-28T15:10:48.357" Title="Should you learn assembly language for robotics?" Tags="&lt;microcontroller&gt;&lt;software&gt;&lt;programming-languages&gt;" AnswerCount="6" CommentCount="2" />
  <row Id="1882" PostTypeId="2" ParentId="1881" CreationDate="2013-09-24T16:11:31.637" Score="5" Body="&lt;p&gt;This is one of those &quot;open-ended&quot; questions that the moderator doesn't like.  So I'm going to leave you with some short, general answers.  These are based on over 20 years in industry designing various bits of hardware and software for embedded systems:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Learning enough about microprocessors so that assembly language programming comes naturally will be a big plus, but is not necessary.  Just knowing assembly language programming for some processor or another because you've memorized it isn't going to be very useful.&lt;/li&gt;&#xA;&lt;li&gt;There is no one microcontroller to recommend.  There is such a huge number of factors that come into play that the correct processor for your project could be anything from a slow 8051 clone to a super-fast bazzilion-core desktop processor with liquid cooling.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-09-24T16:11:31.637" CommentCount="2" />
  <row Id="1883" PostTypeId="2" ParentId="1881" CreationDate="2013-09-24T16:12:39.400" Score="6" Body="&lt;p&gt;In general you don't need to learn assembly to be able to program a microcontroller. As long as you know C, it's enough for you.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Knowledge of assembly of course would help. Specifically, it would help in writing optimized code (or rather, not writing stupid code) as well as having a good estimate of how fast or slow a piece of code could be. Sometimes in very performance critical sections manipulating the assembly may also be needed, but again, in general you wouldn't be needing any of this.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Specially if you are a beginner.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Regarding microcontrollers, there is a wide variety of them, almost all of which are good and useful. Choosing a microcontroller really depends on what you want to attach to it and how complicated its software is going to be. With similar microcontrollers among different brands, I would personally pay attention to how well the microcontroller is documented and how good its compiler/IDE is. Little-explained data-sheet is a headache and a bad IDE an annoyance you don't want to deal with.&lt;/p&gt;&#xA;" OwnerUserId="158" LastActivityDate="2013-09-24T16:12:39.400" CommentCount="2" />
  <row Id="1884" PostTypeId="1" CreationDate="2013-09-24T19:51:57.107" Score="4" ViewCount="168" Body="&lt;p&gt;I'm interested in simulating Quadcopter control and Swarm co-ordinations. Was wondering if Blender or specifically &lt;a href=&quot;http://www.openrobots.org/wiki/morse/&quot; rel=&quot;nofollow&quot;&gt;MORSE&lt;/a&gt; was going to be good enough? According to the &lt;a href=&quot;http://www.openrobots.org/morse/doc/latest/what_is_morse.html#but-even-morse-has-its-limitations&quot; rel=&quot;nofollow&quot;&gt;limitations of MORSE&lt;/a&gt;, it states:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;ul&gt;&#xA;  &lt;li&gt;&lt;p&gt;MORSE was never meant to be a physically accurate simulator: while we rely on a state-of-the-art physics engine (Bullet), do not expect to accurately simulate robot arm dynamics or fine grasping. Other projects are doing that much better (like OpenGrasp for grasping).&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;While on-going efforts try to tackle this issue, we do not consider MORSE to have a good enough temporal accuracy and time synchronization capabilities for application like hybrid simulation (where some robots are simulated while others are physically operated).&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Was wondering if anyone has experience in using blender for these types of applications.&lt;/p&gt;&#xA;" OwnerUserId="1999" LastActivityDate="2013-11-24T17:31:45.983" Title="Blender a good robotic simulator for quadcopters / swarm simulations?" Tags="&lt;simulator&gt;" AnswerCount="1" CommentCount="1" FavoriteCount="1" />
  <row Id="1885" PostTypeId="1" CreationDate="2013-09-25T06:02:54.413" Score="0" ViewCount="190" Body="&lt;p&gt;Original text:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Soy nuevo en este sistema de arduino y programación, quisiera ayuda en&#xA;  el aspecto de saber como programar los códigos del skeleto del kinect&#xA;  y que los reproduzca el arduino uno con los servos por medio del&#xA;  programa de VB. O si me pueden corregir, por que no sé si esta bien le&#xA;  modo en que lo pienso, tal vez pude haber una forma más fácil de que&#xA;  el arduino uno realice los movimientos que le envía el Skeleto del&#xA;  kinect.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Google Translate translation with some manual fixes:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am new to arduino and programming. I need help with programming using the &quot;Skeleto&quot; of kinect and reproducing them with servos on arduino Uno using VB. Or if it's possible, because I don't know if what I have in mind is okay, maybe there's an easier way to realize movements with arduino Uno given the Skeleto of kinect?&lt;/p&gt;&#xA;" OwnerUserId="2001" LastEditorUserId="158" LastEditDate="2013-12-18T14:05:07.007" LastActivityDate="2014-01-17T14:15:23.573" Title="Using Kinect with Arduino. (was Uso del Skeleto de kinect con arduino uno con servos. Utilizando VB)" Tags="&lt;arduino&gt;&lt;kinect&gt;&lt;servos&gt;" AnswerCount="1" CommentCount="5" />
  <row Id="1886" PostTypeId="2" ParentId="1884" CreationDate="2013-09-25T16:47:14.383" Score="2" Body="&lt;p&gt;You might look at &lt;a href=&quot;http://www.coppeliarobotics.com/&quot; rel=&quot;nofollow&quot;&gt;v-rep&lt;/a&gt;. They say that the program is specifically designed to simulate any robot and support dynamic particles allowing for the creation of engines and propellors. The program even comes with a pre-made quadcopter model.&lt;/p&gt;&#xA;" OwnerUserId="1708" LastActivityDate="2013-09-25T16:47:14.383" />
  <row Id="1887" PostTypeId="2" ParentId="1881" CreationDate="2013-09-25T20:37:44.017" Score="3" Body="&lt;p&gt;The major disadvantage of assembly language is that it is different for each processor that you use.  Therefore there is a big learning curve whenever you change processor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Clearly, if you only ever plan on using a single processor (or family of processors) then this is less of an issue; however, life is rarely that simple.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Equally, assembler allows you to really get things wrong, unless you are very careful. I speak as someone with lots of years commercial experience writing flight-critical assembly code!!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On the other hand, pretty much every processor comes with a suitable C compiler (as @Shahbaz suggests) and porting C from one processor to another is a lot more straightforward than porting assembler.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Unless you already have good assembler experience, I'd be minded to learn C, and leave assembly language for those (very rare) occurrences when C just isn't up for it.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;As for which processor... how long is your piece of string?&lt;/p&gt;&#xA;" OwnerUserId="134" LastActivityDate="2013-09-25T20:37:44.017" CommentCount="2" />
  <row Id="1888" PostTypeId="2" ParentId="1881" CreationDate="2013-09-25T21:15:19.287" Score="0" Body="&lt;p&gt;I think the answer here is &quot;that's the wrong question&quot;.  (It's a bit like asking &quot;what spoken language should I learn if I want to write detective novels?&quot;)  But it does have an answer: &lt;strong&gt;it depends&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I can't speak for everyone, but when I was just starting out in programming it seemed to me that learning assembly language would help my programs run faster.  This is not necessarily true, because it was based on a faulty assumption: that my writing assembly code (at a beginner level) would produce more efficient code than today's sophisticated compilers.  Furthermore, I assumed that I could pull off complicated algorithms in assembly in the first place -- look at how a simple algorithm like &lt;a href=&quot;http://en.wikipedia.org/wiki/Bubble_sort#Pseudocode_implementation&quot; rel=&quot;nofollow&quot;&gt;bubble sort&lt;/a&gt; becomes &lt;a href=&quot;http://www.dailyfreecode.com/Code/performs-bubble-sort-497.aspx&quot; rel=&quot;nofollow&quot;&gt;very intimidating in assembly&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You should have a good command of the algorithms themselves that are required for robotics.  With that knowledge, the specific language is irrelevant; you will use the language most appropriate to the platform, even if you have to learn a new language to do so.    In some cases this will be assembly, in other cases it will be a variant of C/C++ (like in Arduino), and in still other cases it could be a high-level language.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But learn the theory first, before you get bogged down in the implementation.  In other words, before you choose a language you should think about what you're going to say.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-09-25T21:15:19.287" CommentCount="2" />
  <row Id="1890" PostTypeId="2" ParentId="1774" CreationDate="2013-09-26T21:45:44.243" Score="2" Body="&lt;p&gt;I think you're misunderstanding the following two sentences from the abstract: &lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;(i) the first one is a fusion module which synthesizes line segments obtained from laser rangefinder and line features extracted from monocular camera. This policy eliminates any pseudo segments that appear from any momentary pause of dynamic objects in laser data.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;It looks like they're first extracting lines from the point cloud generated from the laser range finder. They then cross-reference these lines with lines extracted via computer vision on the monocular image. If a line extracted from the point cloud doesn't exist in the image, then it is NOT a valid line. Therefore, you are correct, &quot;If the dynamic object moved, [the] laser data [WILL] update and eliminate the segment&quot; caused by dynamic objects. However, they're trying to correctly identify segments specifically when the dynamic object is briefly static.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can see a specific example on page 441 where a person standing still caused a segment to be extracted from the point cloud. Fortunately, this segment does not exist in the monocular image, and so it was deemed an INVALID segment. There's also a brief description of this process in section 4 on page 437.&lt;/p&gt;&#xA;" OwnerUserId="1960" LastActivityDate="2013-09-26T21:45:44.243" />
  <row Id="1891" PostTypeId="2" ParentId="1874" CreationDate="2013-09-27T04:30:10.100" Score="0" Body="&lt;p&gt;Specifically about control of motors by PWM, you should learn about the &lt;a href=&quot;http://en.wikipedia.org/wiki/PID_controller&quot; rel=&quot;nofollow&quot;&gt;PID controller&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The sky's the limit for what you want to learn about.  Find a robotics simulator to start playing around with algorithms -- otherwise you will find that you will spend all year building the robot instead.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For a mobile robot, motion planning or mapping algorithms would be a good start.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Real sensors are noisy and ambiguous, so machine learning (i.e. statistical, fuzzy learning) is a whole field you can look at if you're interested, with applications in control, motion planning, and vision processing.  How much time do you have?&lt;/p&gt;&#xA;" OwnerUserId="2005" LastActivityDate="2013-09-27T04:30:10.100" CommentCount="1" />
  <row Id="1892" PostTypeId="2" ParentId="1881" CreationDate="2013-09-27T04:37:08.787" Score="0" Body="&lt;p&gt;What kind of problems are you interested in?  Mechanical design?  Electronics?  Low-level control and algorithms?  High-level planning and state estimation?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pick your battles.  Assembly is good to know for some projects, but use bigger/easier building blocks depending on what your interest is.&lt;/p&gt;&#xA;" OwnerUserId="2005" LastActivityDate="2013-09-27T04:37:08.787" CommentCount="4" />
  <row Id="1895" PostTypeId="1" AcceptedAnswerId="1900" CreationDate="2013-09-27T06:27:53.983" Score="1" ViewCount="99" Body="&lt;p&gt;First, I'm a beginner in MCU/Robotic world (been working with ATMega+CVavr, but that's all). so please bear with me.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm making a prototype data glove (Like &lt;a href=&quot;http://keyglove.com&quot; rel=&quot;nofollow&quot;&gt;KeyGlove&lt;/a&gt;, but much more simpler), it consist of:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;IMU sensors (MPU 9150 9DOF, all reading is fused with built in DMP) -&gt;&#xA;Reads hand position and orientations&lt;/li&gt;&#xA;&lt;li&gt;Minimum of 2 flex sensors -&gt; Reads Figer flexion&lt;/li&gt;&#xA;&lt;li&gt;MCU (well, Arduino to be specific)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;The sensors are plugged in to the Arduino and the reading will be filtered (e.g Low pass, Kalmann) in the Arduino before being transferred over serial to PC. The PC will then translates the data into virtual gripper to move an object (VR)  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Initially I planned to use UNO +  Pansenti’s MPU9150 Library in my code, then I realised the flash memory size left would be so tiny (i.e MPU9150 lib code size is ~29k, Uno has 32k).&#xA;My project is still in very early stage, so a lot things are expected to be changed and added, with so little flash memory left. I can only do so much.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I immediately looking for Mega as replacement (256k flash) but I realised there is also newer Due with faster processor. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;They cost effectively the same as for now.&#xA;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My main concern here is the robustness and compatibility when:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Designing  the HW interface to Arduino (making circuits, addding&#xA;shield)&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Code development (available library)&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Streaming and filtering the sensor readings &lt;strong&gt;(would 32 bit MCus helps, or it's overkill?)&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;I know this question might sound as too localized, but I believe a lot of projects that utilize multiple sensor reading + filtering similarly will also benefits from this discussion&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'll revise the question if it's needed. The main question is probably&#xA;&lt;strong&gt;Would 32 bit MCUs perform &lt;em&gt;significantly&lt;/em&gt; better in multiple sensor reading and signal filtering compared to 8 bit MCUs?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Or in my case.. should I go with Mega or Due?&lt;/p&gt;&#xA;" OwnerUserId="1865" LastActivityDate="2013-09-27T22:34:18.560" Title="Arduino for simple Data-Glove. Should I go with Mega or Due?" Tags="&lt;arduino&gt;&lt;imu&gt;" AnswerCount="1" />
  <row Id="1897" PostTypeId="1" CreationDate="2013-09-27T20:06:01.870" Score="1" ViewCount="66" Body="&lt;p&gt;I'm looking to make an automatically shifting bicycle for my senior design project (along with some additional features TBD). However, I come from an electrical/software background; not a mechanical one. So I need to figure out a decent way to shift gears. I was thinking of leaving the gear system in place as is and using some sort of motor (servo or stepper motor with worm gears) to pull and release the wire cable as needed. However, I have some concerns with this; namely the amount of torque needed to pull the wire and finding something with enough holding torque. Perhaps my best option is to use the trigger shifters on as well and perhaps use a solenoid. My other concern (namely with the worm gear) is that it'll be too slow. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So I would like to pick your brains here for a moment. Thanks&lt;/p&gt;&#xA;" OwnerUserId="2013" LastActivityDate="2013-09-28T02:14:01.013" Title="Mechanism for changing gears on a bicycle" Tags="&lt;motor&gt;&lt;automatic&gt;" AnswerCount="2" CommentCount="2" />
  <row Id="1898" PostTypeId="2" ParentId="1897" CreationDate="2013-09-27T21:16:33.770" Score="2" Body="&lt;p&gt;Depending on your budget, for the mechanical part you could use one of the electronic derailleurs on the market and simply add send it signals from your microcontroller. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;One of the fancier ones I've seen is the Shimano Di2 Dura Ace 7970 It's not cheap though, it's about &lt;a href=&quot;http://www.performancebike.com/bikes/Product_10052_10551_1147610_-1_400608__400608&quot; rel=&quot;nofollow&quot;&gt;\$2200&lt;/a&gt; for the set or \$500 for the rear derailleur alone, \$690 for the shifters, plus another \$85 for the battery.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you're looking for something cheaper, you might want to check out a project from some Carnegie Mellon students. &lt;a href=&quot;http://build18.ece.cmu.edu/wiki/index.php/Automatic_Bicycle_Transmission&quot; rel=&quot;nofollow&quot;&gt;Their wiki&lt;/a&gt; goes into more detail. It looks like they used an Arduino controller, hall effect sensors and four servos to control the shifting based on rider cadence.&lt;/p&gt;&#xA;" OwnerUserId="2014" LastActivityDate="2013-09-27T21:16:33.770" CommentCount="2" />
  <row Id="1899" PostTypeId="1" CreationDate="2013-09-27T22:16:16.680" Score="1" ViewCount="106" Body="&lt;p&gt;I'd like to assemble a prototype of brushless servo system using a RC brushless motor (heavily geared down), a sensored Electronic Speed Controller for RC motors, and a microcontroller to do the PID control.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/anmOB.png&quot; alt=&quot;Brushless motor and sensored ESC&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'd add three Hall sensors around the motor, and feed those signals into the ESC and the microcontroller. The MCU will run a PID controller, and output an RC servo compatible PWM signal to the ESC.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Question: Is this likely to work, or will I find that the ESC is trying to be clever? I have one RC car which only switches into reverse if you double pulse the reverse signal.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(Note, the reason I'm trying to get this working using an off-the-shelf ESC, rather than designing my own proper one is that development time is &lt;em&gt;much&lt;/em&gt; more expensive than parts cost at the moment).&lt;/p&gt;&#xA;" OwnerUserId="40" LastEditorUserId="350" LastEditDate="2013-09-28T18:40:30.630" LastActivityDate="2013-09-28T18:40:30.630" Title="Making a brushless servo using Hall sensors" Tags="&lt;servos&gt;&lt;brushless-motor&gt;&lt;esc&gt;" CommentCount="8" FavoriteCount="1" />
  <row Id="1900" PostTypeId="2" ParentId="1895" CreationDate="2013-09-27T22:34:18.560" Score="1" Body="&lt;p&gt;The number of bits in the instruction set for the MCU will directly affect the precision of the math operations on that given MCU. If you're going to be doing a lot of 16/32 bit math operations, then yes, a 32 bit MCU will perform significantly better compared to an 8 bit MCU.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This article may help you understand the difference: &lt;a href=&quot;http://www.embedded.com/electronics-blogs/industry-comment/4027627/The-8-bit-MCUs-won-t-be-going-away-anytime-soon&quot; rel=&quot;nofollow&quot;&gt;http://www.embedded.com/electronics-blogs/industry-comment/4027627/The-8-bit-MCUs-won-t-be-going-away-anytime-soon&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The Due has an 84MHz CPU vs the Mega's 16MHz...this isn't even taking into account that a 32-bit core allows the Due to perform operations on 4 byte wide data within a single CPU clock cycle, whereas the Mega will need a clock cycle for each byte at least.&lt;/p&gt;&#xA;" OwnerUserId="1960" LastActivityDate="2013-09-27T22:34:18.560" CommentCount="3" />
  <row Id="1901" PostTypeId="1" AcceptedAnswerId="1907" CreationDate="2013-09-28T01:43:26.767" Score="2" ViewCount="73" Body="&lt;p&gt;So I'm doing some reading on Monte Carlo Localization, and it sounds like the approach is based on using a predefined map, but I just need to make sure (because I haven't read anywhere that it absolutely needs a predefined map). I just want to make 100% sure that my understanding is correct:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Does it absolutely need a predefined map?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;[maybe I need to add the below stuff as another question, but here goes nothing]&#xA;And what other localization approaches are there that don't need a predefined map? So far I've only read about SLAM (which sounds to me like a general approach instead of a specific implementation).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks in advance!&lt;/p&gt;&#xA;" OwnerUserId="1887" LastActivityDate="2013-09-28T18:26:41.263" Title="Does Monte Carlo Localization need a predefined map?" Tags="&lt;localization&gt;&lt;slam&gt;&lt;mapping&gt;" AnswerCount="1" FavoriteCount="1" />
  <row Id="1902" PostTypeId="2" ParentId="1897" CreationDate="2013-09-28T02:14:01.013" Score="0" Body="&lt;p&gt;This might be a stupid idea, but wouldn't using a CVT (continuously variable transmission) be easier to control using an electronic system (both from a mechanical and control points of view)?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm just not sure how easy it is to build one. I hope this helps! Good luck! :D&lt;/p&gt;&#xA;" OwnerUserId="1887" LastActivityDate="2013-09-28T02:14:01.013" />
  <row Id="1903" PostTypeId="1" AcceptedAnswerId="1908" CreationDate="2013-09-28T06:56:12.847" Score="3" ViewCount="91" Body="&lt;p&gt;I'm working on a robot with a team, and we're building our robot out of acetal &lt;a href=&quot;http://en.wikipedia.org/wiki/Polyoxymethylene&quot; rel=&quot;nofollow&quot;&gt;polyoxymethylene (POM)&lt;/a&gt; (specifically, delrin) plastic. However, we'd like to prototype the robot before we build it out of POM, as POM is somewhat expensive.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are several critical areas that plywood would be used in place of POM:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Over sliding surfaces&lt;/li&gt;&#xA;&lt;li&gt;Around gearboxes &lt;/li&gt;&#xA;&lt;li&gt;Under weight stress&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;We'd like to take into account the friction coefficients, smoothness, and rigidity of the materials in deciding whether plywood is a valid prototype substitute. The material will be 1/4&quot; thick.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What differentiates plywood from acetal POM with respect to the relevant points?&lt;/p&gt;&#xA;" OwnerUserId="2015" LastEditorUserId="37" LastEditDate="2013-09-30T23:47:56.717" LastActivityDate="2013-09-30T23:47:56.717" Title="Is finished plywood a comparable prototyping substitute for polyoxymethylene?" Tags="&lt;design&gt;" AnswerCount="1" CommentCount="5" />
  <row Id="1904" PostTypeId="1" CreationDate="2013-09-28T11:03:58.123" Score="4" ViewCount="67" Body="&lt;p&gt;I am part of my college robotics team. We are participating in Robocon 2014 and are thinking about using mecanum wheels. We have done our research but one thing id like to clarify is: Does the number of rollers in the mecanum wheel effect its strafing? if yes then how?&lt;/p&gt;&#xA;" OwnerUserId="2016" LastActivityDate="2013-09-28T17:06:17.237" Title="Strafing of Mecanum wheels" Tags="&lt;wheeled-robot&gt;" AnswerCount="1" />
  <row Id="1905" PostTypeId="2" ParentId="1881" CreationDate="2013-09-28T15:10:48.357" Score="0" Body="&lt;p&gt;It's nice, but for the most part, unnecessary if you're just dealing with robotics. Maybe if you need some high-end optimization, it may be helpful. But most compilers can optimize better than average humans these days anyway. Unless you really know what you're doing and understand the architecture enough to optimize further, I'd say it's not necessary. Plus, different manufactures have their own instruction sets, many of which behave differently on different MCU's. Another thing to cosider is that syntax varies between different MCU's. For instance, AVR MCU's have a different syntax than MIPS architectures and TI DSP's. It all depends on what you're doing.&lt;/p&gt;&#xA;" OwnerUserId="2013" LastActivityDate="2013-09-28T15:10:48.357" />
  <row Id="1906" PostTypeId="2" ParentId="1904" CreationDate="2013-09-28T17:06:17.237" Score="4" Body="&lt;p&gt;No, the number of wheels does not affect its strafing. Strafing is affected only by the angle of the rollers relative to the wheels, and you shouldn't need to worry about that for standard mecanums. The reason for this is that as your robot moves (let's assume constant velocity), the wheels spin; as they spin, the same velocity is on a different part of the wheel, which continues to spin freely. No net effect, besides a minor bump, will occur from rolling a wheel forward. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Of course, everything with a limit. The number of rollers will affect the &lt;em&gt;bumpiness&lt;/em&gt; of the movements. The more rollers, the less vibration your frame will undergo. Obviously, for instance, four rollers won't work. However, again, most commercial mecanums have at least enough for decent smoothness. &lt;/p&gt;&#xA;" OwnerUserId="2015" LastActivityDate="2013-09-28T17:06:17.237" />
  <row Id="1907" PostTypeId="2" ParentId="1901" CreationDate="2013-09-28T18:26:41.263" Score="3" Body="&lt;p&gt;Yes, as defined in literature, all &lt;em&gt;localization&lt;/em&gt; requires a prior map.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is because the goal of localization is to &lt;em&gt;localize&lt;/em&gt; a robot with respect to some feature. If you don't know where the feature is, you can't know where the robot is.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are &lt;em&gt;uncertain&lt;/em&gt; about the features, then you are doing &lt;em&gt;Simultaneous Localization and Mapping&lt;/em&gt; (SLAM).&lt;/p&gt;&#xA;" OwnerUserId="163" LastActivityDate="2013-09-28T18:26:41.263" CommentCount="1" />
  <row Id="1908" PostTypeId="2" ParentId="1903" CreationDate="2013-09-28T23:37:36.670" Score="3" Body="&lt;p&gt;Plywood is available in various grades (A, B, C),  sanded and unsanded, veneer core or MDF core, and with surfaces of various kinds of woods.  I'm not aware of any plywood that will emulate the friction coefficient of &lt;a href=&quot;http://en.wikipedia.org/wiki/Delrin&quot; rel=&quot;nofollow&quot;&gt;Delrin&lt;/a&gt; (polyoxymethylene).  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;With some hard, tightly grained, or oily woods (eg ironwood, ebony, teak) or Baltic Birch plywood, it might be possible to polish the wood to a point that its smoothness approaches that of  polyoxymethylene.  Note that those woods might cost more than polyoxymethylene does.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For other woods, it might be possible to use a filler and an epoxy finish to emulate some properties of Delrin, but if your project is about building your robot and not about accurately emulating properties of polyoxymethylene, I don't recommend the approach of experimenting with different finishes on plywood.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Instead, it may be best to purchase several &lt;a href=&quot;http://en.wikipedia.org/wiki/Polyethylene&quot; rel=&quot;nofollow&quot;&gt;polyethylene&lt;/a&gt; cutting boards and cut them up for use as polyoxymethylene testing standins.  Large cutting boards often are available cheap on Ebay, and small cutting boards can be found at thrift stores.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note that polyoxymethylene is significantly stronger, harder, and more wear-resistant than the polyethylene in cutting boards, but polyethylene's properties are so much closer to polyoxymethylene's than plywood's are, that the prototyping fit should be much closer.  For a still-closer fit, you can buy  “drops” (small cutoffs) of  UHMWPE (&lt;a href=&quot;http://en.wikipedia.org/wiki/Ultra-high-molecular-weight_polyethylene&quot; rel=&quot;nofollow&quot;&gt;ultra high molecular weight polyethylene&lt;/a&gt;) that in some applications will work as a Delrin replacement.&lt;/p&gt;&#xA;" OwnerUserId="478" LastActivityDate="2013-09-28T23:37:36.670" CommentCount="1" />
  <row Id="1909" PostTypeId="1" CreationDate="2013-09-29T21:12:03.760" Score="1" ViewCount="32" Body="&lt;p&gt;In earlier versions of the Arduino IDE there was a option to burn a the bootloader using an Arduino as the programmer. As of current there is only a burn bootloader option. Was the burn using a Arduino as a isp integrated into the still existing one, or did it disappear?&lt;/p&gt;&#xA;" OwnerUserId="1667" LastActivityDate="2013-09-29T21:12:03.760" Title="Arduino isp bootloader burning" Tags="&lt;arduino&gt;" CommentCount="1" ClosedDate="2013-09-29T22:48:14.667" />
  <row Id="1910" PostTypeId="1" CreationDate="2013-09-29T22:05:57.563" Score="3" ViewCount="119" Body="&lt;p&gt;Would like a product that enables me to use my computer to throw an small DC ON / OFF switch. Seems like a stupidly simple thing to do, but for the life of me I can't seem to find such a device when I search online.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there a device floating around out there that I can order? Or is there some kind of term I should be searching for?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks so much!&lt;/p&gt;&#xA;" OwnerUserId="1857" LastActivityDate="2013-09-30T06:15:15.170" Title="Use computer to throw a small switch" Tags="&lt;control&gt;" AnswerCount="1" CommentCount="10" />
  <row Id="1911" PostTypeId="1" AcceptedAnswerId="1917" CreationDate="2013-09-30T03:23:16.163" Score="1" ViewCount="97" Body="&lt;p&gt;I just got my rover 5 chassis with 4 motors and 4 &lt;a href=&quot;http://en.wikipedia.org/wiki/Rotary_encoder#Incremental_rotary_encoder&quot; rel=&quot;nofollow&quot;&gt;quadrature encoders&lt;/a&gt; and I am trying to utilize the optical encoders. I know the encoders generate pulse signals which can be used to measure speed and direction of the motor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I want to know how 4 separate optical encoders add value for the controller of rover 5 like platform. The controller normally uses PWM to control the speed of the motor. If two motors are running at same speed then the encoder output will be same. So, why should the controller monitor all 4 encoders?&lt;/p&gt;&#xA;" OwnerUserId="1144" LastEditorUserId="37" LastEditDate="2013-09-30T23:55:27.920" LastActivityDate="2013-09-30T23:55:27.920" Title="How are the optical encoders used in platforms like Rover 5?" Tags="&lt;mobile-robot&gt;&lt;motor&gt;&lt;control&gt;" AnswerCount="3" CommentCount="1" />
  <row Id="1912" PostTypeId="2" ParentId="1910" CreationDate="2013-09-30T06:15:15.170" Score="2" Body="&lt;p&gt;There are two easy ways:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Use a relay&lt;/li&gt;&#xA;&lt;li&gt;Use a transistor&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;In both cases, you can use the processor as the switch input...&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/khRpY.png&quot; alt=&quot;Example MOSFET switch&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="134" LastActivityDate="2013-09-30T06:15:15.170" CommentCount="7" />
  <row Id="1913" PostTypeId="2" ParentId="1911" CreationDate="2013-09-30T12:49:24.887" Score="0" Body="&lt;p&gt;There are two use cases i can think of, which benefits of individual motor feedback. &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;If you are moving in strait line, you need to have both sides synced. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;You can have motor that will degrade over the time and will not stay in sync with the other one at the same side (in case you control them by only one encoder), which will fail rolling the caterpillar band.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="973" LastActivityDate="2013-09-30T12:49:24.887" />
  <row Id="1914" PostTypeId="2" ParentId="1911" CreationDate="2013-09-30T12:56:42.810" Score="0" Body="&lt;p&gt;If you are running the Rover 5 in a tracked configuration then, as you rightly point out, the two wheels on each side should rotate at equal speeds meaning that half of the sensors are redundant.&#xA;If you swap the tracks out for the mecanum wheels then the four encoders have more of a benefit.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It probably also makes sense from a manufacturing point of view to keep all the motor/encoder units the same. The increased cost of manufacture may be offset by the reduced complexity.&lt;/p&gt;&#xA;" OwnerUserId="1978" LastActivityDate="2013-09-30T12:56:42.810" CommentCount="1" />
  <row Id="1917" PostTypeId="2" ParentId="1911" CreationDate="2013-09-30T22:37:27.103" Score="2" Body="&lt;p&gt;No two motors will ever turn with the same angular velocity given the same voltage. If you power each of your Rover 5 motors with 12V (I don't know what they're rated for), you'll see that each motor will spin at slightly different speeds. If you want to guarantee you're traveling in a straight line, you need to implement velocity control on both wheels. One method of doing this is implementing a PID controller on the drive wheels to ensure their velocity is the same, based on encoder ticks per unit time. Otherwise (let's assume you have two wheels that are driving the vehicle) one wheel will turn faster than the other, and you'll slowly drift in one direction.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, you may want to turn a vehicle with no steering control! That means you want to turn your drive wheels at different velocities (albeit this will cause your wheels to slip horizontally and thus cause you to lose some traction/power), and so you need two different encoders that will be the input to two different velocity controllers. For a tank like system, if the front left wheel encoder is ticking and the rear left wheel encoder is NOT ticking, then maybe your tread has fallen off! It's really very useful to create a robust system.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Edit: Man I keep editing and adding more stuff...having multiple encoders will also allow you to identify failures. If you see that one wheel has stopped moving, it could be stuck on something and/or broken! This could allow you to halt the system and tell the operator that a mechanical failure has occurred with, for example, the front left wheel. This can only be done if you have more than one encoder.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As a side note, it's always good to have a redundant system in case one breaks!&lt;/p&gt;&#xA;" OwnerUserId="1960" LastEditorUserId="1960" LastEditDate="2013-09-30T22:43:41.037" LastActivityDate="2013-09-30T22:43:41.037" CommentCount="1" />
  <row Id="1918" PostTypeId="1" AcceptedAnswerId="1932" CreationDate="2013-10-01T14:28:08.767" Score="0" ViewCount="151" Body="&lt;p&gt;I've been having trouble installing MORSE.&#xA;I am trying to install it on Ubuntu 12.04 and on a VirtualBox with Ubuntu 13.04 (I don't need it on a VirtualBox, I'm just trying to make &lt;em&gt;something&lt;/em&gt; work). &#xA;On Ubuntu 12.04 I get the following errors at the cmake stage:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;$ cmake -DCMAKE_INSTALL_PREFIX=/home/oferb/opt/morse_build ..&#xA;-- will install python files in /home/oferb/opt/morse_build/lib/python3/dist-packages&#xA;CMake Error: The following variables are used in this project, but they are set to NOTFOUND.&#xA;Please set them or make sure they are set and tested correctly in the CMake files:&#xA;PYTHON_INCLUDE_DIR (ADVANCED)&#xA;   used as include directory in directory /home/oferb/mnt/svr_home/opt/morse&#xA;   used as include directory in directory /home/oferb/mnt/svr_home/opt/morse/src&#xA;   used as include directory in directory /home/oferb/mnt/svr_home/opt/morse/src/morse&#xA;   used as include directory in directory /home/oferb/mnt/svr_home/opt/morse/src/morse/builder&#xA;   used as include directory in directory /home/oferb/mnt/svr_home/opt/morse/src/morse/modifiers&#xA;   used as include directory in directory /home/oferb/mnt/svr_home/opt/morse/src/morse/sensors&#xA;   used as include directory in directory /home/oferb/mnt/svr_home/opt/morse/src/morse/multinode&#xA;   used as include directory in directory /home/oferb/mnt/svr_home/opt/morse/src/morse/middleware&#xA;   used as include directory in directory /home/oferb/mnt/svr_home/opt/morse/bindings&#xA;   used as include directory in directory /home/oferb/mnt/svr_home/opt/morse/testing&#xA;   used as include directory in directory /home/oferb/mnt/svr_home/opt/morse/testing/base&#xA;   used as include directory in directory /home/oferb/mnt/svr_home/opt/morse/testing/failures&#xA;   used as include directory in directory /home/oferb/mnt/svr_home/opt/morse/testing/robots/human&#xA;   used as include directory in directory /home/oferb/mnt/svr_home/opt/morse/testing/robots/segway&#xA;   used as include directory in directory /home/oferb/mnt/svr_home/opt/morse/testing/robots/pr2&#xA;   used as include directory in directory /home/oferb/mnt/svr_home/opt/morse/testing/robots/pionner3dx&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;On a fresh VMBox with Ubuntu 13.04, after 'morse check' succeeds, I try &quot;morse create mysim&quot; and get:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;adminuser@adminuser-VirtualBox:~$ morse create mysim&#xA;usage: morse [-h] [-b BASE] [--name NAME] [-c] [--reverse-color] [-g GEOM]&#xA;         [-v]&#xA;         {check,edit,run} [scene] ...&#xA;morse: error: argument mode: invalid choice: 'create' (choose from 'check', 'edit', 'run')&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Any suggestions?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;UPDATE:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've managed to install MORSE on Ubuntu 12.04. Make sure your Blender was compiled with the same version of python (i.e python 3.2.2) that MORSE was compiled in. I used this Blender: &#xA;&lt;a href=&quot;http://download.blender.org/release/Blender2.62&quot; rel=&quot;nofollow&quot;&gt;http://download.blender.org/release/Blender2.62&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1940" LastEditorUserId="1940" LastEditDate="2013-10-07T12:35:31.570" LastActivityDate="2013-10-08T08:10:03.647" Title="Installing MORSE simulator on Ubuntu 12.04" Tags="&lt;simulator&gt;" AnswerCount="1" CommentCount="7" />
  <row Id="1919" PostTypeId="1" AcceptedAnswerId="1922" CreationDate="2013-10-01T21:49:15.783" Score="3" ViewCount="134" Body="&lt;p&gt;I need to actuate 3 or 4 Cnc-like Nema 23 (~1N.m torque) stepper motors, I would like some cable solution to connect easily the motor to the motor driver. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have not yet bought anything, I have searched various robotic stores and ebay, but did not yet found a triple (motor, cables, driver) which would be &quot;plug and play&quot;. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;As stepper motors usually have 4 to 6 cables, and there are multiple motors, manual soldering everything would be too time consuming, error prone and messy.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there a standard way to deal with cables for stepper motors ?&lt;/p&gt;&#xA;" OwnerUserId="2033" LastEditorUserId="187" LastEditDate="2013-10-06T15:11:51.517" LastActivityDate="2013-11-10T01:47:43.657" Title="How can we manage stepper motor cables?" Tags="&lt;stepper-motor&gt;&lt;wiring&gt;" AnswerCount="3" />
  <row Id="1920" PostTypeId="2" ParentId="1919" CreationDate="2013-10-02T00:20:14.670" Score="1" Body="&lt;p&gt;Stepper motors usually have 4 to 6 &lt;em&gt;wires&lt;/em&gt;, often bundled up into one &lt;em&gt;cable&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There might be some pro industrial solution out there that's 100% plug and play, but I would consider myself lucky if I found connectorized motors and drivers for which I could make up cables.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Making up cables is not rocket science.  Find the matching connectors for the motors and drivers (this is much less trivial than you would either think or like), make up your cables (by soldering, most likely -- someone has to do it), and have fun.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Be sure to make the cables long enough.  I'm always too stingy the first time around and have everything stretched way too much.&lt;/p&gt;&#xA;" OwnerUserId="1533" LastActivityDate="2013-10-02T00:20:14.670" />
  <row Id="1921" PostTypeId="2" ParentId="1864" CreationDate="2013-10-02T10:11:56.170" Score="2" Body="&lt;p&gt;by searching for a different topic I found your post and I work with the Sparkfun Razor 9DOF IMU too. Actually it was a pain in the ass to get it all work.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;First of all you have to do the tutorial &lt;a href=&quot;https://github.com/ptrbrtz/razor-9dof-ahrs/wiki/Tutorial&quot; rel=&quot;nofollow&quot;&gt;razor-9dof-ahrs&lt;/a&gt; form ptrbrtz. When this is working you can do the next steps. Btw.: read it carefully and you should be able to do it on your own!!!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;First I tried to get it work with an Arduino Uno and a SoftwareSerial. Sadly I wasn’t able to get it work with a SoftwareSerial, I received with Text and Binary output only rubbish data. I worked a whole day on this topic and I wasn’t able to do it and I could say I have a lot experience with Arduino programming. If you are able to get it work with a SoftwareSerial please post an answear.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;With the Uno I was only able to receive data with this configuration: &lt;a href=&quot;http://blog.mobileapes.com/2010/09/read-data-from-9dof-razor-imu-via.html&quot; rel=&quot;nofollow&quot;&gt;http://blog.mobileapes.com/2010/09/read-data-from-9dof-razor-imu-via.html&lt;/a&gt;&#xA;But be aware the TX should go to RX and the RX to TX!!! The description in the picture (Rx to Rx and Tx to Tx) is false.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are able to use an Arduino MEGA, which has at least 4 UARTs, you could use the code I developed. Once I get it work on an Uno but I searched for the Code and I didn’t found it anymore, with a little try and fail you should be able to do it. But be aware, if you are sending data to the PC and receiving data from to IMU on only one UART, you could probably negatively influence the serial communication.&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;/**************************** INFO ********************************/&#xA;&#xA;// This code expects a message in the format: H 12.00,-345.00,678.00&#xA;&#xA;/******************************************************************/&#xA;&#xA;#include &amp;lt;TextFinder.h&amp;gt;&#xA;&#xA;/*** Defines the frequency at which the data is requested ***/&#xA;/*** frequency f=1/T, T=period; ie. 100ms --&amp;gt; f=10Hz, 200ms --&amp;gt; f=5Hz ***/&#xA;#define PERIOD      100 // [ms]&#xA;&#xA;/*** Vars for IMU ***/&#xA;TextFinder  finder(Serial3);  &#xA;const int NUMBER_OF_FIELDS = 3; // how many comma seperated fields we expect                                           &#xA;float rpy[NUMBER_OF_FIELDS];    // array holding values for all the fields&#xA;&#xA;/************************************************************/&#xA;/*** Setup&#xA;/************************************************************/&#xA;void setup()&#xA;{&#xA;  Serial.begin(57600);  // init the Serial port to print the data to PC&#xA;  Serial3.begin(57600); // init the Serial3 port to get data from the IMU&#xA;&#xA;  delay(500);&#xA;&#xA;  initIMU();&#xA;}&#xA;&#xA;/************************************************************/&#xA;/*** Loop&#xA;/************************************************************/&#xA;void loop()&#xA;{&#xA;  // print manager timer&#xA;  static unsigned long timer = 0;&#xA;  static unsigned long currentTime = 0;&#xA;&#xA;  /************************************************************/&#xA;  /*** Request after a specific period for the data&#xA;  /************************************************************/&#xA;  currentTime = millis();&#xA;  if(currentTime - timer &amp;gt;= PERIOD)&#xA;  {&#xA;    // Request one output frame from the IMU&#xA;    // #f only requests one reply, replies are still bound to the internal 20ms (50Hz) time raster.&#xA;    // So worst case delay that #f can add is 19.99ms.&#xA;    Serial3.write(&quot;#f&quot;);&#xA;&#xA;    /************************************************************/&#xA;    /*** Get the IMU values&#xA;    /************************************************************/&#xA;&#xA;    // the current field being received&#xA;    int fieldIndex = 0;            &#xA;&#xA;    // search the Serial Buffer as long as the header character is found&#xA;    boolean found_HeaderChar = finder.find(&quot;H&quot;);&#xA;&#xA;    if (found_HeaderChar)&#xA;    {&#xA;      // Get all 3 values (yaw, pitch, roll) from the Serial Buffer&#xA;      while(fieldIndex &amp;lt; NUMBER_OF_FIELDS)&#xA;      {&#xA;        rpy[fieldIndex++] = finder.getFloat();&#xA;      }&#xA;    }&#xA;&#xA;    /************************************************************/&#xA;    /*** Print out the values&#xA;    /*** Format: yaw, pitch, roll, left_Encoder, right_Encoder&#xA;    /************************************************************/&#xA;    if (found_HeaderChar)&#xA;    {&#xA;      // print Interval&#xA;      Serial.print(currentTime - timer);&#xA;      Serial.print(&quot;,&quot;);&#xA;&#xA;      // print IMU values&#xA;      for(fieldIndex=0; fieldIndex &amp;lt; NUMBER_OF_FIELDS; fieldIndex++)&#xA;      {&#xA;        Serial.print(rpy[fieldIndex]);&#xA;        Serial.print(&quot;,&quot;);&#xA;      }&#xA;      Serial.println(&quot;&quot;);&#xA;    }&#xA;&#xA;    timer = millis();&#xA;  }&#xA;}&#xA;&#xA;/********************************/&#xA;/*** Initialize Functions&#xA;/********************************/&#xA;&#xA;void initIMU()&#xA;{&#xA;  // Output angles in TEXT format &amp;amp; Turn off continuous streaming output &amp;amp; Disable error message output&#xA;  Serial3.write(&quot;#ot#o0#oe0&quot;);&#xA;  Serial3.flush();&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Edit: Oh I forgot to say that you must edit the Output.ino from the Razor AHRS Firmware. search for the function &quot;output_angles()&quot; and change it to:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;// Output angles: yaw, pitch, roll&#xA;void output_angles()&#xA;{&#xA;  if (output_format == OUTPUT__FORMAT_BINARY)&#xA;  {&#xA;    float ypr[3];  &#xA;    ypr[0] = TO_DEG(yaw);&#xA;    ypr[1] = TO_DEG(pitch);&#xA;    ypr[2] = TO_DEG(roll);&#xA;&#xA;    Serial.write((byte*) ypr, 12);  // No new-line&#xA;  }&#xA;  else if (output_format == OUTPUT__FORMAT_TEXT)&#xA;  {&#xA;    Serial.print(&quot;H &quot;);&#xA;    Serial.print(TO_DEG(yaw)); Serial.print(&quot;,&quot;);&#xA;    Serial.print(TO_DEG(pitch)); Serial.print(&quot;,&quot;);&#xA;    Serial.print(TO_DEG(roll)); Serial.println();&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="2035" LastEditorUserId="2035" LastEditDate="2013-10-02T12:59:05.517" LastActivityDate="2013-10-02T12:59:05.517" CommentCount="1" />
  <row Id="1922" PostTypeId="2" ParentId="1919" CreationDate="2013-10-02T20:00:31.350" Score="3" Body="&lt;p&gt;Don't worry about the cables; plan to make them yourself.  I recommend using one of the wide variety of crimp-on connectors available to you, depending on what you can find for your ESC and steppers connections.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here are a handful of connectors representing part of what we stock in our lab:&#xA;&lt;img src=&quot;http://i.stack.imgur.com/EvFlc.jpg&quot; alt=&quot;Molex minifit and microfit&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The white connector is the Molex Minifit, the black one to its right is the Molex Microfit, and the 1/8&quot; miniplug is for scale.  Using these connectors can involve either soldering them to a board, or using a crimp tool and crimp-on terminations which are then snapped into the plug body.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This allows the cables to be run much more precisely than they would be if you just made solder connections in the middle of the cable length.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-10-02T20:00:31.350" CommentCount="1" />
  <row Id="1923" PostTypeId="2" ParentId="150" CreationDate="2013-10-04T07:47:02.593" Score="1" Body="&lt;p&gt;I have come across all the suggestions in the other posts. I don't understand why people are suggesting complex and expensive solutions which are also not feasible.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A &lt;strong&gt;mechanical seal&lt;/strong&gt; is the simplest answer for sealing the motor or making it of IP 68. We can use this motor to a depth of 20 m in sea water. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The construction is like a WET pit.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Such types of motor are used in sewage submersible pumps which work to the depth of 20 m in water.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The cost of such a seal is also very low.&lt;/p&gt;&#xA;" OwnerUserId="2044" LastEditorUserId="131" LastEditDate="2013-10-06T16:24:37.993" LastActivityDate="2013-10-06T16:24:37.993" CommentCount="1" />
  <row Id="1924" PostTypeId="1" CreationDate="2013-10-05T00:19:15.813" Score="1" ViewCount="64" Body="&lt;p&gt;I am in the FLL (First Lego League), and while we are waiting for the competitions, we want to work on a robot. Anyone have any ideas?&lt;/p&gt;&#xA;" OwnerUserId="2047" LastActivityDate="2013-10-05T06:23:44.090" Title="Any ideas for a robot?" Tags="&lt;sensors&gt;" AnswerCount="1" CommentCount="2" FavoriteCount="1" ClosedDate="2013-10-05T07:29:50.677" />
  <row Id="1925" PostTypeId="1" AcceptedAnswerId="1929" CreationDate="2013-10-05T00:39:23.150" Score="3" ViewCount="108" Body="&lt;p&gt;I could use some guidance regarding a coordinate system transform problem. My situation is this: my system begins at some unknown location, which I initialize the location (x y) and orientation (roll, pitch, and yaw) all to zero. I establish a frame of reference at this point, which I call the &quot;local&quot; coordinate frame. It is fixed in the world and does not move. At system startup, the body frame is perfectly aligned with the local frame, where body +x points forward, +y to the right and +z down. The body frame is fixed to my system, and travels with the system as it moves.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have an estimation routine that provides me with the x and y position, as well as the roll, pitch, and yaw of the system. Yaw is rotation about the z axis of the local frame. Pitch and roll are with respect to the body frame (I.e.,if the robot pitches up, I always get a positive value. If it rolls right, I get a positive value.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How can I take the known roll and pitch values and transform them to be with respect to the local (fixed) frame?&lt;/p&gt;&#xA;" OwnerUserId="2048" LastActivityDate="2013-10-07T14:52:39.570" Title="Performing the proper coordinate system transformation" Tags="&lt;mobile-robot&gt;&lt;kinematics&gt;" AnswerCount="1" />
  <row Id="1926" PostTypeId="2" ParentId="1924" CreationDate="2013-10-05T06:23:44.090" Score="2" Body="&lt;p&gt;I have worked as a robot design judge at my local qualifiers and regional events for 3 years now. There are several major areas where successful teams tend to excel. Following are a few in no particular order:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Sensors: Learning to use sensors is simultaneously the hardest and best thing you can do to improve performance. Using sensors well can increase reliability and repeatability when performing tasks. In other words it can improve the performance of the robot by making it more accurate. Start with something simple like learning how to use bump sensors. Then try something a little more complicated like learning how to use color sensors considering how their output changes given different lighting conditions. If you are really up for a challenge then you can learn how to do &lt;a href=&quot;http://www.nxtprograms.com/line_follower/index.html&quot; rel=&quot;nofollow&quot;&gt;line following&lt;/a&gt;. The most successful teams I have seen make line following a core component.&lt;/li&gt;&#xA;&lt;li&gt;Programming: Many tasks require the same functionality. For instance, you can use line following to get from home base to the various challenges. You can either put this functionality into each of your programs directly or you can use &lt;em&gt;&lt;a href=&quot;http://www.nxtprograms.com/help/MyBlocks/tutorial.html&quot; rel=&quot;nofollow&quot;&gt;My Blocks&lt;/a&gt;&lt;/em&gt; to build the functionality once and use it over and over in your programs. Doing so has the added benefit of making your code more reliable because once it has been written and tested you know it works. It has the added benefit of making your programs smaller allowing you to fit more programs. This can be great for testing. But be careful, too many programs can make switching programs during a challenge time consuming.&lt;/li&gt;&#xA;&lt;li&gt;Attachments: Changing attachments during the competition is a major time sink. Learning to design attachments that can be used to perform multiple tasks saves time and helps score many points. Try making different types of attachments and focus on learning how to make them rigid and strong.&lt;/li&gt;&#xA;&lt;li&gt;Stability: Tipping over during a challenge can cost you points as a result of touching the robot while it's away from home base. Practice building chassis that avoiding tipping when the robot turns and interacts with objects in the environment.&lt;/li&gt;&#xA;&lt;li&gt;Team: FLL emphasizes team building for a reason. A good team can divide the numerous tasks necessary to be successful and can help each other when challenges arise. Learn how to communicate with your team members especially when you disagree. This will show through when you are in the various judging rooms which can earn you a prize in-and-of-itself.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-10-05T06:23:44.090" />
  <row Id="1927" PostTypeId="1" CreationDate="2013-10-05T14:56:03.603" Score="1" ViewCount="144" Body="&lt;p&gt;I found many tutorials and online calculators for the selection of dc motor to drive wheel, I understood how the torque affect the driving of wheel.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But what happen when I change the orientation of motor and load? What is the main criteria for a dc motor to work when I want to rotate a plate which is vertically mounted on motor's shaft, when the motor is placed vertically also (as shown in the picture)?&#xA;&lt;img src=&quot;http://i.stack.imgur.com/aSlKL.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am not an engineering student so please provide me an answer as simple as possible.&lt;/p&gt;&#xA;" OwnerUserId="2049" LastEditorUserId="2447" LastEditDate="2014-01-14T19:51:41.910" LastActivityDate="2014-01-15T05:37:23.203" Title="DC motor direct loading" Tags="&lt;motor&gt;&lt;torque&gt;" AnswerCount="2" CommentCount="5" />
  <row Id="1929" PostTypeId="2" ParentId="1925" CreationDate="2013-10-07T00:04:46.260" Score="1" Body="&lt;p&gt;I introduced a different frame of reference, which I called $\mathbf{R}_p$, or position of the robot on the ground plane, instead of the &quot;body&quot; frame that I asked about.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$\mathbf{R}_p$ moves with the robot, but only in yaw and X and Y position. The pitch and roll (provided by the estimator) are relative to this frame, so the roll ($\phi$) and pitch ($\theta$) are relative to the frame $\mathbf{R}_p$. To transform a point from $\mathbf{R}_p$, to the local frame $\mathbf{L}$, we just rotate $\psi$, (yaw) about the Z axis of $\mathbf{R}_p$ of e.g.: &lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$&#xA;\mathbf{T}_R^L = \begin{vmatrix} cos(\psi) &amp;amp; -sin(\psi) &amp;amp; 0 &amp;amp; 0 \\ sin(\psi) &amp;amp; cos(\psi) &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \end{vmatrix}&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$&#xA;P_L = \mathbf{T}_R^L * \begin{vmatrix} \phi \\ \theta \\ 0 \\ 0 \end{vmatrix}&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This gives me the attitude with respect to the local frame that I established when I initialized my system.&lt;/p&gt;&#xA;" OwnerUserId="2048" LastEditorUserId="2048" LastEditDate="2013-10-07T14:52:39.570" LastActivityDate="2013-10-07T14:52:39.570" />
  <row Id="1930" PostTypeId="1" CreationDate="2013-10-07T12:48:30.307" Score="0" ViewCount="69" Body="&lt;p&gt;I've been trying to add a second camera to a MORSE qudrotor robot, to simulate the ground facing camera of the ARDrone. The problem is that I haven't found where/how the camera of the Quadrotor robot was defined. I've searched the files for the text 'Quad' and came up with these files:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;.../morse/lib/python3.2/site-packages/morse/actuators/stabilized_quadrotor.py&#xA;.../morse/lib/python3.2/site-packages/morse/robots/quadrotor_dynamic.py&#xA;.../morse/lib/python3.2/site-packages/morse/robots/quadrotor.py&#xA;.../morse/lib/python3.2/site-packages/morse/builder/data.py&#xA;.../morse/lib/python3.2/site-packages/morse/builder/actuators.py&#xA;.../morse/lib/python3.2/site-packages/morse/builder/robots/morserobots.py&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;None of them seems to have the definition of the camera.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;tl;dr: How do I add another camera to a robot?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any suggestions are welcome.&lt;/p&gt;&#xA;" OwnerUserId="1940" LastActivityDate="2013-10-07T12:48:30.307" Title="Adding a second camera to a MORSE quadcopter" Tags="&lt;quadcopter&gt;&lt;simulator&gt;" CommentCount="0" />
  <row Id="1931" PostTypeId="1" CreationDate="2013-10-08T01:27:47.520" Score="3" ViewCount="119" Body="&lt;p&gt;I'm trying to learn about a very basic motor, the servo motor.  Can these be found a thrift stores like Goodwill in old toys?  Are these &quot;robotic&quot; quality?  What toys or other kinds of things would I scavenge?  All I want to do is get a motor.  After that I want an Arduino and make it &quot;work.&quot;  Nothing complex.&lt;/p&gt;&#xA;" OwnerUserId="2058" LastEditorUserId="350" LastEditDate="2013-10-09T17:24:22.690" LastActivityDate="2013-10-12T11:01:30.320" Title="Is a thrift store a good place to get a servo motor?" Tags="&lt;servomotor&gt;" AnswerCount="3" CommentCount="1" />
  <row Id="1932" PostTypeId="2" ParentId="1918" CreationDate="2013-10-08T08:10:03.647" Score="1" Body="&lt;p&gt;&lt;strong&gt;Tips for MORSE on Ubuntu 12.04&lt;/strong&gt;:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you're having trouble compiling MORSE, perhaps these can help:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Install python3-dev or python-dev or both (not sure which was needed)&lt;/li&gt;&#xA;&lt;li&gt;Check which version python3 directs to. If it's the wrong one, you can specify the python version explicitly in cmake. The cmake I used is: &quot;cmake -DCMAKE_INSTALL_PREFIX=/home/oferb/opt/morse -DPYTHON_EXECUTABLE=/usr/local/bin/python3.3 ..&quot;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;If you've already managed to compile MORSE, then make sure your Blender was compiled with the same version of python (i.e python 3.2.2) that MORSE was compiled in. I used this Blender: &lt;a href=&quot;http://download.blender.org/release/Blender2.62&quot; rel=&quot;nofollow&quot;&gt;http://download.blender.org/release/Blender2.62&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Tips for MORSE on Ubuntu 13.04&lt;/strong&gt;:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note that &quot;sudo apt-get install morse-simulator&quot; gives you morse 1.0, but according to morse support, &quot;morse create&quot;, which shows up in the tutorials, is something new in morse-1.1. You might want to search for an older tutorial, or install a more recent version of MORSE.&lt;/p&gt;&#xA;" OwnerUserId="1940" LastActivityDate="2013-10-08T08:10:03.647" />
  <row Id="1933" PostTypeId="2" ParentId="1931" CreationDate="2013-10-08T12:38:45.047" Score="1" Body="&lt;p&gt;While some people scavenge even for cheap parts, I do not do that, simply because it will cost you more than just ordering the exact thing you need and knowing it is working. Don't forget that you probably have some specific requirements, i.e. the servo must be of some size, have some torque and so on...&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Majority of toys (if not all of them) you will find at Goodwill will have just a basic DC motor with minimal feedback and won't probably as a 3-pin plug&amp;amp;play servo. These are not even required to be the same in identical toys, simply because manufacturer will use the one that is cheaper. This means the properties of the motors may be different and to tune your control loop to get two motors running at the same speed will cost you the same as just buying a working part with known characteristics.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT: Since it seems like you are contradicting yourself in the question I would like to make it clear that a servo motor is not the easiest to use, since besides power it also needs a signal that determines where it will turn. A typical servo motor you will find looks something like &lt;a href=&quot;https://lh3.ggpht.com/-d377i5B68IU/Tgha_la8CWI/AAAAAAAAACY/_b0CCHvi3i0/s1600/servo.gif&quot; rel=&quot;nofollow&quot;&gt;this&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On the other hand, the easiest motor to use is just a plain DC motor. They look something like &lt;a href=&quot;http://images.wisegeek.com/dc-motor.jpg&quot; rel=&quot;nofollow&quot;&gt;this&lt;/a&gt;, although there are many models of them that may even look different. To turn this motor you just need to supply power to it. The polarity of the wires determines the direction in which it will turn and the voltage determines the speed.&lt;/p&gt;&#xA;" OwnerUserId="890" LastEditorUserId="890" LastEditDate="2013-10-09T18:25:41.973" LastActivityDate="2013-10-09T18:25:41.973" CommentCount="5" />
  <row Id="1934" PostTypeId="1" CreationDate="2013-10-08T14:18:53.537" Score="5" ViewCount="70" Body="&lt;p&gt;If I was controlling a normal brushed motor as a servo, I would measure the motor's position, and adjust the PWM signal to control the voltage. This way I could achieve a precise velocity/position profile if my control was good enough.&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;pwm_duty = CalcPID(motor_position - target_position);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;When doing Field Oriented Control (FOC) of a brushless motor, there are two parameters I can control: The voltage angle, and the voltage magnitude. There are three things I can measure, the current angle and magnitude, and the rotor position.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I want to achieve a precise velocity/position profile including good control down to zero speed and reverse.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Question: how can I calculate the correct voltage field angle (or phase lead) and magnitude?  Do I need two PID algorithms?&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;phase_lead  = CalcPID_1( ... );&#xA;voltage_mag = CalcPID_2( ... );&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Assume I can take any reasonable measurements of the motor state, including rotor position and winding current.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2013-10-10T20:07:49.967" Title="Field oriented control of brushless motors" Tags="&lt;servos&gt;&lt;pid&gt;&lt;brushless-motor&gt;" AnswerCount="1" FavoriteCount="1" />
  <row Id="1935" PostTypeId="1" CreationDate="2013-10-08T15:18:31.727" Score="7" ViewCount="158" Body="&lt;p&gt;I live in an apartment that has sliding windows in it. The apartment is naturally warm because we live above a mechanical room, such that we either opened the windows or ran the air conditioning through the winter. I want to create a device than can open and close the windows in the apartment depending on temperature. The software and electronics are already figured out, I just need to figure out how to move the windows.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/ffas3.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is a sample of the window. It takes about 4 lbs of force to pull it open, and they only open 6 inches(since I'm 16 stories high).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ultimately, I want to make this cheap enough that I could replicate it on 6 windows.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My first thought was a linear actuator, but most of the ones I have seen are designed for moving 100+lbs and cost several hundred dollars. Pneumatic actuators are cheaper, but I'd have to run a network of air lines and solenoids, and would have a compressor that would randomly kick in. A double winch system would be very complicated to set up and prone to failure. Lastly, I was thinking of a cheap metal gear servo(dealextreme has 15kg/cm servos for under $15.00), but it would be somewhat difficult to use a series of turnbuckles and arms to translate into 6 inches of linear movement.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any help would be appreciated.&lt;/p&gt;&#xA;" OwnerUserId="2065" LastActivityDate="2013-11-03T14:04:53.690" Title="How to open a sliding window?" Tags="&lt;design&gt;&lt;actuator&gt;" AnswerCount="3" CommentCount="2" FavoriteCount="2" />
  <row Id="1938" PostTypeId="2" ParentId="1934" CreationDate="2013-10-09T20:56:39.617" Score="3" Body="&lt;p&gt;I believe the most efficient thing to do is to maintain a 90 degree phase lead, and adjust your voltage magnitude for control.  You'll probably want to have an inner current loop, wrapped by the actual position loop.&lt;/p&gt;&#xA;" OwnerUserId="1533" LastEditorUserId="37" LastEditDate="2013-10-10T20:07:49.967" LastActivityDate="2013-10-10T20:07:49.967" CommentCount="0" />
  <row Id="1939" PostTypeId="2" ParentId="1935" CreationDate="2013-10-09T22:37:59.277" Score="7" Body="&lt;p&gt;As others have said in comments, a screw is probably your best bet. It's mechanically pretty simple to set up, and could be made to look fairly tidy, which is always nice in a home.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But the main problem, as always is going to be doing this on the cheap. The cost of the parts soon adds up. Even if your motors are only $15, you still need to buy the lead screw and nuts. These can be shockingly expensive if you buy nice ones for CNC machines, but you can probably get away with a simple length of threaded rod attached to a motor mounted on the wall, and a nut attached to the window. Since this thing isn't going to be moving very often, it should last a reasonably long time. And when the components wear out, they'll be cheap to replace.&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2013-10-09T22:37:59.277" />
  <row Id="1940" PostTypeId="2" ParentId="1765" CreationDate="2013-10-10T16:42:19.353" Score="1" Body="&lt;p&gt;I work on  race cars which occasionally race in built up areas such as street circuits. &#xA;As part of the mandatory electronic systems we fit a GPS antenna to the car to allow vehicle tracking.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some of the guidance we have for the installation is &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Fit the antenna to the upper surface of the car &lt;/li&gt;&#xA;&lt;li&gt;Keep the antenna within 5 degrees of horizontal&lt;/li&gt;&#xA;&lt;li&gt;Do not place metal objects above the antenna&lt;/li&gt;&#xA;&lt;li&gt;Guarantee the direct visibility of the sky from the antenna, with a minimum of 170º cone unimpeded&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;So I would have expected that mounting a GPS antenna on a towbar where, potentially, half of the visibility would be obstructed by the metal structures at the rear of the vehicle would not be a good idea and would almost certainly be worse than fitting it to the roof&lt;/p&gt;&#xA;" OwnerUserId="1978" LastActivityDate="2013-10-10T16:42:19.353" />
  <row Id="1942" PostTypeId="2" ParentId="1931" CreationDate="2013-10-10T23:29:23.830" Score="1" Body="&lt;p&gt;A servo is not a basic motor - it's a motor plus some means to control its position. If you want DC motors. A small servo costs around £1.75/$2 new for 1-10 quantities.  Servos have three wires going to them - ground, power, and a pulse width modulation signal to control them, which is fairly easy to generate with a microcontroller. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Plain DC motors are electrically simpler - you provide power as DC and they move one way or another depending on polarity - but require more driving electronics as a microcontroller cannot provide enough current. So you would need either an H-bridge to drive it both ways, or a power transistor to drive it one direction only. A small low-quality DC motor costs about a pound, a higher quality motor (such as you'd get in a model railway locomotive) ten or a few tens of pounds. An H-bridge to drive it, such as L298 costs a couple of pounds, so if you want bidirectional drive it's probably worth buying a better motor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The prices above are for hobby kit; industrial robotics motors are typically ten times more expensive, so if you mean industrial by 'robotic quality' then it's unlikely you'll find something in a second hand store.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Buying scrap equipment and salvaging the motors from goodwill is unlikely to give you better quality or consistency than buying cheap motors new. You may get lucky and be able to buy a toy with a few hobby quality servos in it for less than $$2 per servo, or you may have a project in mind which needs a higher power motor and so buy something like a sewing machine for less than the cost of an equivalent motor (~$20), but unless you're lucky it's probably not worth the candle. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So be lucky!&lt;/p&gt;&#xA;" OwnerUserId="1321" LastActivityDate="2013-10-10T23:29:23.830" />
  <row Id="1943" PostTypeId="2" ParentId="1931" CreationDate="2013-10-12T11:01:30.320" Score="1" Body="&lt;p&gt;Not servos explicitly, but I've obtained low end nema 17 stepper motors on occasion from electronic typewriters at goodwill. The typewriters I've seen there usually have 1 such motor in them (in addition to some other neat pin mount components) and fetch for $1 each. In my case the only other source for parts is radio shack and online outlets, so for me it's a viable option if I don't want sit around waiting for orders. This is however not a reliable method at all, especially if you want parts in large numbers or with certain specifications.&lt;/p&gt;&#xA;" OwnerUserId="1845" LastActivityDate="2013-10-12T11:01:30.320" />
  <row Id="1944" PostTypeId="1" AcceptedAnswerId="1945" CreationDate="2013-10-12T19:30:42.633" Score="1" ViewCount="215" Body="&lt;p&gt;Has anybody experimented with &lt;a href=&quot;http://en.wikipedia.org/wiki/Gas_metal_arc_welding&quot; rel=&quot;nofollow&quot;&gt;GMAW&lt;/a&gt; for additive manufacturing? The thing is, welding wire is so much cheaper than ABS or PLA filaments and, well, it is steel you are printing in, not some flimsy plastic! I imagine the arc deposition printhead would be constructed similarly to one used in plastic filament printers, except there is no need for the heating element (so, even simpler). Welding often requires fast Z speed (to finely control the arc) so i think Delta (&lt;a href=&quot;http://www.wired.com/design/2013/02/deltamaker-3d-printer/&quot; rel=&quot;nofollow&quot;&gt;DeltaMaker&lt;/a&gt;) chassis would work best. GMAW calls for some sort of inert gas to insulate heated metal from oxygen. It would make sense to seal off most of the interior of the printer and fill it with heavier than air inert gas during printing. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would highly appreciate any pointers on existing 3d printer designs employing this deposition method as well as flaws in design i outlined here.&lt;/p&gt;&#xA;" OwnerUserId="1870" LastActivityDate="2013-10-22T12:20:43.627" Title="Arc welder for 3d printing" Tags="&lt;3d-printing&gt;" AnswerCount="2" />
  <row Id="1945" PostTypeId="2" ParentId="1944" CreationDate="2013-10-13T13:10:53.077" Score="2" Body="&lt;p&gt;I believe this is in very active development.  Here's an article with a few videos on that subject:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.extremetech.com/extreme/143552-3d-printing-with-metal-the-final-frontier-of-additive-manufacturing&quot; rel=&quot;nofollow&quot;&gt;3D printing with metal: The final frontier of additive manufacturing&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The real breakthrough that has enabled 3D printing for the masses has been the laser. Spray welding is a technique that has been used for decades to build up worn motor shafts, but it is far too crude for controlled additive printing. Spray welding uses a gravity-fed powdered metal dispenser integrated into a special oxygen-acetylene torch head which melts the powder as it is dispensed. Swapping the torch for a laser gave us the powerful construction tool we have today. A powdered metal feedstream, confined and protected against oxidation with a surrounding jet of inert shielding gas, fused by a laser piped through a central bore in the head is now the state of the art technology. &lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;There is also a room-temperature extrusion method that seems to work, using gallium:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://hackaday.com/2013/07/09/3d-printing-with-liquid-metals/&quot; rel=&quot;nofollow&quot;&gt;3D printing with liquid metals&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The medium the team is using for their metallic 3D prints is an alloy of 75% gallium and 25% indium. This alloy is liquid at room temperatures, but when exposed to an oxygen atmosphere, a very thin layer of oxide forms on a small metal bead squeezed out of a syringe. Tiny metal sphere by tiny metal sphere, the team can build up metallic objects out of this alloy, stacking the beads into just about any shape imaginable.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-10-13T13:10:53.077" />
  <row Id="1946" PostTypeId="1" CreationDate="2013-10-13T14:07:39.250" Score="2" ViewCount="96" Body="&lt;p&gt;I have been researching on SLAM. I came across EKF SLAM which uses odometry to measure the robot's initial position in the map and as well as landmarks which helps the robot's position to be more accurate. Based on the SLAM for dummies, it has a problem of loop closure. In another journal, it was compared to fastSLAM and EKF has a big-O function of $O(K^2)$ where $K$ is the number of landmarks while fastSLAM has $O(M\log(K))$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It was also said that the most promising SLAM algorithm from the journal &lt;a href=&quot;http://www.vision.caltech.edu/mariomu/research/papers/vSLAM-krs.pdf&quot; rel=&quot;nofollow&quot;&gt;&quot;The vSLAM Algorithm for Navigation in Natural Environments&quot;&lt;/a&gt;&#xA; is FastSLAM &#xA;However, the vSLAM used by an experiment done by the University of Pennsylvania is the occupancy grid SLAM.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I want to ask what would be the most approriate SLAM algorithm for vSLAM given an unmanned aerial vehicle like the quadrotor and RGB-D camera + IMU? Also are there any algorithm that can be extended to support co-operation?&lt;/p&gt;&#xA;" OwnerUserId="2089" LastEditorUserId="350" LastEditDate="2013-10-14T02:05:47.280" LastActivityDate="2013-10-14T02:05:47.280" Title="What is the most appropriate SLAM algorithm for quadrotors with RGB-D camera?" Tags="&lt;quadcopter&gt;&lt;localization&gt;&lt;slam&gt;&lt;quadrotor&gt;&lt;mapping&gt;" />
  <row Id="1947" PostTypeId="1" AcceptedAnswerId="1951" CreationDate="2013-10-14T06:21:05.723" Score="1" ViewCount="218" Body="&lt;p&gt;I have this project I'm working on where I'll need the speed of the stepper motor to change set speed at a certain distance, I just can't figure out a way to do it. I'm using arduino and a stepper motor, this is the current code.&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#include &amp;lt;AccelStepper.h&amp;gt;&#xA;&#xA;AccelStepper stepper1(AccelStepper::FULL4WIRE, 0, 1, 2, 3);&#xA;&#xA;void setup()&#xA;{  &#xA;    stepper1.setMaxSpeed(200.0);&#xA;    stepper1.setAcceleration(400.0);&#xA;    stepper1.moveTo(5000);&#xA;&#xA;}&#xA;&#xA;void loop()&#xA;{&#xA;    // Change direction at the limits&#xA;    if (stepper1.distanceToGo() == 0)&#xA;    stepper1.moveTo(-stepper1.currentPosition());&#xA;    stepper1.run();&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;What I want it to do basically is to first &lt;code&gt;moveTo(2500)&lt;/code&gt;  at the current speed 200 then after 2500 I want it to increase speed to 400. After it has moved 5000 it turns and moves back to position but that's implemented already.&lt;/p&gt;&#xA;" OwnerUserId="2091" LastEditorUserId="350" LastEditDate="2013-10-14T17:56:29.170" LastActivityDate="2014-01-15T05:28:52.263" Title="I want my stepper motor to switch speed while traveling (not acceleration wise)" Tags="&lt;arduino&gt;&lt;control&gt;&lt;stepper-motor&gt;" AnswerCount="2" CommentCount="4" />
  <row Id="1949" PostTypeId="1" CreationDate="2013-10-14T09:22:32.657" Score="3" ViewCount="98" Body="&lt;p&gt;In the book of SLAM for dummies, why do we even need the odometry when the robot would use the data retrieved from the laser scanner which is more accurate than odometry? Why not just rerly on the laser scanner and do away from the odometry? Is there any contribution by the odometry that the laser scanner does not have? Also, are all SLAM algorithms feature-based?&lt;/p&gt;&#xA;" OwnerUserId="2089" LastActivityDate="2013-10-15T18:18:01.540" Title="In EKF-SLAM, why do we even need odometry when there is a more reliable sensor?Also, are all SLAM algorithms feature-based?" Tags="&lt;localization&gt;&lt;slam&gt;&lt;mapping&gt;" AnswerCount="2" CommentCount="1" />
  <row Id="1950" PostTypeId="2" ParentId="1949" CreationDate="2013-10-14T23:16:04.297" Score="1" Body="&lt;p&gt;If you read about the principles of sensor fusion, you will always get a better estimate when you combine data in the right way. For example, if you are measuring temperature in a room with 3 different temperature sensors, it is not ideal to only use the best sensor. The ideal case would be to create a weighted combination of each sensor, where the sensor's weight is proportional to one over that sensor's variance. Not to mention, odometry data is VERY good. It's the extraction of landmarks that is noisy and will most likely have a higher variance.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you think about it from a high level perspective it's also required that you have a motion update based on odometry. If you only used landmarks, then you would have ambiguous cases. Take for example, the case where you only identify one landmark. You'd have a distance z from your robot to the landmark, but this would map to an infinite number of points in a circle around the landmark. If you identify zero landmarks, then you can't do anything! By including odometry, we no longer have an ambiguity. Assuming we're localizing in a 2D plane (x,y), then you would have to guarantee you have readings for at least 3 landmarks to triangulate your position without odometry, and you cannot make that guarantee in normal environments.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Finally, an encoder can be sample on the order of 50Hz, whereas a LIDAR can only be sampled at around 6-7Hz (don't quote me on those frequencies). This means that you can update your current position much more frequently via odometry than you can from sensor readings. This isn't even taking into account how long it takes you to process your sensor reading to identify landmarks!&lt;/p&gt;&#xA;" OwnerUserId="1960" LastActivityDate="2013-10-14T23:16:04.297" />
  <row Id="1951" PostTypeId="2" ParentId="1947" CreationDate="2013-10-15T11:50:51.697" Score="2" Body="&lt;p&gt;For this task; increase speed when a certain distance is reached.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would use encoders on the wheels which will workout the distance travelled and when the target distance is reached then increase speed.  &lt;/p&gt;&#xA;" OwnerUserId="2099" LastActivityDate="2013-10-15T11:50:51.697" />
  <row Id="1952" PostTypeId="2" ParentId="1927" CreationDate="2013-10-15T12:12:25.137" Score="0" Body="&lt;p&gt;I would say that the main criteria for a motor mounted in this way would be to ensure that's it's balanced, equal to it's middle position and well supported and secured to it's base. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;You will have centrifugal force wanting to pull the centre shaft outwards. This force will increase the faster you spin the plate. The torque calculation should be the same but you might need to take into account the weight (if any) acting down on the motor's shaft. Also make the plate as light as possible as this will reduce load bearing on the shaft and reduce the centrifugal force.  &lt;/p&gt;&#xA;" OwnerUserId="2099" LastActivityDate="2013-10-15T12:12:25.137" />
  <row Id="1953" PostTypeId="2" ParentId="1949" CreationDate="2013-10-15T13:05:52.967" Score="2" Body="&lt;p&gt;You are reading it too narrowly. &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;You don't &quot;need&quot; odometery. SLAM is simply a way to fuse any sensor estimates into a consistent estimate of the robot's state.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&quot;Feature-based&quot; doesn't necessarily mean you need to have identifiable features everywhere in the environment. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;First principal of sensor fusion: Two estimates are better than one! &lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h3&gt;Example&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;I haven't read the book &quot;for dummies&quot; but if they don't do the following numeric example, I'd set the book on fire and get a better one. And if they &lt;strong&gt;do&lt;/strong&gt; have this example, then I wonder why you didn't mention it!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;( you can follow along in the math &lt;a href=&quot;http://en.wikipedia.org/wiki/Kalman_filter&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt; )&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A robot is at position $x=0$, and is moving to the right (increasing $x$). In this perfect world, the dynamics and sensor modes are linear. (otherwise use EKF, PF, or some variant).&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;There's a wall at &lt;em&gt;exactly&lt;/em&gt; $x=10$ which the robot can measure distance to.&lt;/li&gt;&#xA;&lt;li&gt;The robot has a laser scanner to get distance with sensor variance $\sigma_l^2=.1$&lt;/li&gt;&#xA;&lt;li&gt;The robot can measure it's distance travelled with odometers using sensor variance $\sigma_o^2 = .5$. Clearly the laser is more accurate than the odos.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Here's how the robot handles SLAM in this simple environment. (note this is actually localization since we aren't updating the position of the wall).&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The robot tries to move one unit to the right.&lt;/li&gt;&#xA;&lt;li&gt;Odometry measures $x=.9$&lt;/li&gt;&#xA;&lt;li&gt;Laser scanner says you are $8.8$ units from the wall. (implying you are at 1.2)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Question&lt;/em&gt;: Where are you? &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Do you choose the best sensor? In this case, the laser is the best right? So obviously I'm at $x=1.2$.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Do you choose the one &quot;closest&quot; to what you expect? Well in this case I think we should use odometry, since $.9$ is closer to what I intended, (moving one unit).&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Maybe you could average the two? Well, that's better, but it is susceptible to outliers.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;The shiny principals of sensor fusion tell you how to answer the question as follows:&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Your minimum mean-squared estimate of the robot position is given by:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$x_{mmse}=\frac{\sigma_l^2}{\sigma_o^2+\sigma_l^2}(.9) + \frac{\sigma_o^2}{\sigma_o^2+\sigma_l^2}(1.2)$$&#xA;$$x_{mmse}=\frac{.1}{.6}(.9) + \frac{.5}{.6}(1.2)$$&#xA;$$x_{mmse}=1.15$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;... unless I screwed up the algebra somewhere. People localize airplanes using math not much more complicated than that.&lt;/p&gt;&#xA;" OwnerUserId="163" LastEditorUserId="163" LastEditDate="2013-10-15T18:18:01.540" LastActivityDate="2013-10-15T18:18:01.540" />
  <row Id="1954" PostTypeId="1" AcceptedAnswerId="1957" CreationDate="2013-10-16T06:09:58.530" Score="2" ViewCount="186" Body="&lt;p&gt;The HC-SR04 is directly connected to an Arduino board with the receiver end(echo) connected to analog pin 2 and the transmitter (trigger) connected to digital pin 4.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am wondering if I can use the sensor to sense the change in saturation from when object block its path. The receiver and transmitter will be positioned like this &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/phIBB.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The line in the middle is supposed to be a paper. I'll be using it to see the difference between one paper and two paper when they travel trough the two. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now I'm not sure if this is possible but the way I see it working is kind of similar to an IR LED Arduino program connected to an LED, where when one paper passes trough the light gets a little bit weaker and with two it takes a heavier hit.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is this possible?&lt;/p&gt;&#xA;" OwnerUserId="2091" LastEditorUserId="1177" LastEditDate="2013-12-30T19:50:07.077" LastActivityDate="2013-12-30T19:50:07.077" Title="Is it possible to use HC-SR04 ultrasonic range sensor to indicate thickness of a material" Tags="&lt;arduino&gt;&lt;sensors&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="1955" PostTypeId="1" CreationDate="2013-10-16T14:36:36.653" Score="3" ViewCount="240" Body="&lt;p&gt;I am working on a 2D space where my robot needs to follow a trajectory while avoiding some obstacles.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've read recently about methods for path planning as &quot;Vector Field Histogram&quot; and the &quot;Dynamic window approach&quot;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is it worth to use these kind of algorithms for a 2D space or should I go with something as Potential Fields or Rapidly-Exploring Random Trees?&lt;/p&gt;&#xA;" OwnerUserId="2102" LastActivityDate="2014-01-02T11:56:18.640" Title="Choosing path planning and obstacle avoidance algorithm for 2D space" Tags="&lt;mobile-robot&gt;&lt;motion-planning&gt;" AnswerCount="2" CommentCount="3" />
  <row Id="1956" PostTypeId="2" ParentId="1955" CreationDate="2013-10-16T17:06:16.720" Score="1" Body="&lt;p&gt;In a 2D space, you could probably get away with something much simpler to begin with like Breadth-first search, Dijkstra's or A-Star. Combine it with an occupancy grid as a map based on LIDAR data and you'd be good to go. RRT's work well and I've used them in the past, but for much higher dimensional search spaces. In general I would recommend starting out with the simplest solution. If it turns out it doesn't perform fast/well enough, then you upgrade to something more complicated. There's no need to build a formula-1 car to drive to the grocery store XD.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It really depends on your application, and since I know nothing about it, it's hard to give you the best answer.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Edit: RRT* (read: RRT star) is also very nice.&lt;/p&gt;&#xA;" OwnerUserId="1960" LastEditorUserId="1960" LastEditDate="2013-10-16T17:13:19.770" LastActivityDate="2013-10-16T17:13:19.770" />
  <row Id="1957" PostTypeId="2" ParentId="1954" CreationDate="2013-10-17T18:22:57.347" Score="4" Body="&lt;p&gt;The short answer is &quot;no, a sonic range sensor can't do it&quot;.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;It might &quot;work&quot; under very controlled conditions, but relying on only the attenuation of the returned signal to determine thickness may leave you open to incorrect results due to &lt;a href=&quot;http://en.wikipedia.org/wiki/Multipath_propagation&quot; rel=&quot;nofollow&quot;&gt;multipath propagation&lt;/a&gt; effects.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The more traditional way to measure thickness with sound is called profiling.  The following is excerpted from &lt;a href=&quot;http://woodshole.er.usgs.gov/operations/sfmapping/seismic.htm&quot; rel=&quot;nofollow&quot;&gt;a USGS Woods Hole Science Center page on Seismic Profiling systems&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;reflection profiling is accomplished by [emitting] acoustic energy in timed intervals [...]. The transmitted acoustic energy is reflected from boundaries between various layers with different acoustic impedances [i.e. the air and the paper]. Acoustic impedance is defined by the bulk density of the medium times the velocity of the sound within that medium. The reflected acoustic signal is received [by one or more microphones]. The receiver converts the reflected signal to an analog signal [which is digitized and heavily processed to determine the makeup of the materials].  &lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/wwlhm.png&quot; alt=&quot;Seismic Profiling System&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Rather than just measuring the time of the incoming pulse, you'd need to analyze both the time and frequency domain of the recovered signal to solve for the acoustic properties necessary to transform your transmitted pulse into the received pulse.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So the long answer is that it can be done sonically, although a sonic range sensor is generally insufficient for this purpose.  &lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-10-17T18:22:57.347" CommentCount="1" />
  <row Id="1959" PostTypeId="1" CreationDate="2013-10-18T22:40:17.927" Score="2" ViewCount="51" Body="&lt;p&gt;I have read that you can wire a unipolar stepper to a bipolar driver, which I have, by ignoring the two extra wires. One concern I have is whether connecting a unipolar stepper to a bipolar driver will cause it to lose torque (holding or operating)? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Will it be the same? Increase? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've read that bipolars are more bang for your buck energy-wise, and since you can &quot;transform&quot; a unipolar stepper to a bipolar good enough that the driver will still work right, I would think that it might run more efficiently. Is this true?&lt;/p&gt;&#xA;" OwnerUserId="824" LastEditorUserId="350" LastEditDate="2013-10-22T16:26:23.777" LastActivityDate="2014-01-06T19:03:19.243" Title="Will wiring a unipolar stepper to a bipolar stepper driver decrease the holding torque?" Tags="&lt;torque&gt;&lt;stepper-driver&gt;&lt;stepper-motor&gt;" AnswerCount="1" />
  <row Id="1960" PostTypeId="2" ParentId="1856" CreationDate="2013-10-18T23:26:32.243" Score="2" Body="&lt;p&gt;The arduino is a pretty versatile piece of kit that can work alongside pretty much anything. I'd look at the fish identification process and work back to the appropriate hardware.&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;How many possible species of fish are there in the lake? (The more fish, the more memory you'll need, and the more complex your software will be)&lt;/li&gt;&#xA;&lt;li&gt;Can these species clearly be told apart by size/weight? (If so, you may not necessarily need computer vision at all)&lt;/li&gt;&#xA;&lt;li&gt;Can the species be told apart simply by colour? (colour averaging will be significantly easier to process than differentiating finer details, less processing power required)&lt;/li&gt;&#xA;&lt;li&gt;How fast does this recognition need to occur? (imaging processing can be intensive, pick an appropriately fast system)&lt;/li&gt;&#xA;&lt;li&gt;Does the system need to be entirely self-contained / on-site? (If not, you could save time by sending the image to a remote computer over wireless/3G for processing)&lt;/li&gt;&#xA;&lt;li&gt;How small are the distinguishing features? (This will determine what camera resolution / number of cameras / lens you will need)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;...etc&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In terms of computer vision software, &lt;a href=&quot;http://opencv.org&quot; rel=&quot;nofollow&quot;&gt;OpenCV&lt;/a&gt; should be high on your list.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you have a good understanding of mobile app development, a smart phone could be appropriate (combined camera &amp;amp; computer, cheap, portable, relatively fast), combined with Google's ADK and you could pass resulting commands to actuators.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The list of hardware capable of running image processing software is rather large. Arduinos, Beaglebone/boards, mbeds, FPGAs, RaspberryPi, fitPC, NUCs, full-sized computers (ATX motherboards etc) and beyond. Up to you what works for your application and budget.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Have a look at some of the HD logitech web cams, for the price and resolution they deliver high frame rates and have support across a good few operating systems.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Good luck!&lt;/p&gt;&#xA;" OwnerUserId="2113" LastActivityDate="2013-10-18T23:26:32.243" />
  <row Id="1961" PostTypeId="2" ParentId="1885" CreationDate="2013-10-19T00:25:08.443" Score="0" Body="&lt;p&gt;I understand you're interested in skeletal tracking using the Kinect (programming the software in Visual Basic), and replicating the skeletal motion with servos controlled by an Arduino.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;'&lt;a href=&quot;http://www.openni.org&quot; rel=&quot;nofollow&quot;&gt;OpenNI&lt;/a&gt;' would be my first point of call for skeletal tracking, and 'Kinect for Windows SDK'.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As for hardware, it depends how many servos you're using and how powerful they are (i.e. how big your robot is). &lt;a href=&quot;http://bildr.org/2012/03/servos-tlc5940-arduino/&quot; rel=&quot;nofollow&quot;&gt;I'd recommend looking at the TLC5940&lt;/a&gt; driver for smaller servos.&lt;/p&gt;&#xA;" OwnerUserId="2113" LastActivityDate="2013-10-19T00:25:08.443" />
  <row Id="1962" PostTypeId="2" ParentId="1944" CreationDate="2013-10-19T01:03:29.443" Score="2" Body="&lt;p&gt;Look at Electron Beam welding technology.  Businesses like &lt;a href=&quot;http://www.sciaky.com/products_EB.html&quot; rel=&quot;nofollow&quot;&gt;Sciaky's Additive Manufacturing&lt;/a&gt; have found a niche market by using 3D printing techniques in metal applications.  They have a 2 min video on &lt;a href=&quot;https://www.youtube.com/watch?v=A10XEZvkgbY&quot; rel=&quot;nofollow&quot;&gt;Youtube&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Specifically with GMAW you will want to use a wire with very little manganese and other &quot;cleaner&quot; elements.  This wire will cause the formation of a silica slag (glass) on the top of the weld.  This slag will act as an insulator and prevent the next successive arc on that spot from establishing.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Read the literature that comes with the wire you select.  Often straight CO2 gas will work more economically that an Argon gas mix.  Also factor in temperature / gas expansion when you design your enclosure or consider pre and post flow gas timing when considering your output speed.&lt;/p&gt;&#xA;" OwnerUserId="2114" LastEditorUserId="131" LastEditDate="2013-10-22T12:20:43.627" LastActivityDate="2013-10-22T12:20:43.627" />
  <row Id="1963" PostTypeId="5" CreationDate="2013-10-19T03:12:49.613" Score="0" ViewCount="3" Body="&lt;p&gt;Brushless DC motor or BLDC motor is a type of synchronous electric motor powered by direct current. BLDC motor does not operate on brushes, rather than it operates on controller via electronic commutation.&lt;/p&gt;&#xA;" OwnerUserId="1336" LastEditorUserId="1336" LastEditDate="2013-10-19T11:10:52.087" LastActivityDate="2013-10-19T11:10:52.087" />
  <row Id="1964" PostTypeId="4" CreationDate="2013-10-19T03:12:49.613" Score="0" Body="Brushless motor is kind of DC motor. It is also called BLDC Motors (Brush-Less Direct Current Motors)." OwnerUserId="1336" LastEditorUserId="1336" LastEditDate="2013-10-19T11:11:08.133" LastActivityDate="2013-10-19T11:11:08.133" />
  <row Id="1965" PostTypeId="1" AcceptedAnswerId="1967" CreationDate="2013-10-21T11:11:13.247" Score="3" ViewCount="74" Body="&lt;p&gt;I'm pretty new to the world of UAS after a ten year holiday from RC flying.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm looking at Ardupilot and am wondering what purpose telemetry serves? Is it just to get in flight data back to a ground station or can it also be used to program the system in flight? Are there other capabilities that I am missing?&lt;/p&gt;&#xA;" OwnerUserId="2127" LastEditorUserId="2127" LastEditDate="2013-10-21T11:43:08.917" LastActivityDate="2013-10-22T18:52:50.630" Title="What is telemetry used for?" Tags="&lt;uav&gt;&lt;ardupilot&gt;" AnswerCount="1" />
  <row Id="1966" PostTypeId="1" CreationDate="2013-10-21T11:39:01.407" Score="4" ViewCount="59" Body="&lt;p&gt;This question is to anyone familiar with object (specifically vehicle) detection research.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm new to computer vision and am confused about training object detection classifiers. Specifically, the objective is vehicle detection. I've been reading through vehicle detection literature for weeks now, but I'm still a bit confused.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What I'm confused about is evaluation. For the evaluation of a system, the research community usually has a benchmarked dataset which can be used for testing data. But the performance of a system also depends very much on the data that was used to train it, no? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So aren't there any &lt;em&gt;training datasets&lt;/em&gt; out there, too? That would make for far more uniform method comparisons. I seem to keep finding papers using benchmarked datasets for evaluation, but making no mention of where they got their training data from.&lt;/p&gt;&#xA;" OwnerUserId="2128" LastActivityDate="2013-10-22T21:05:57.047" Title="Public training data for vehicle detectors in computer vision?" Tags="&lt;computer-vision&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="1967" PostTypeId="2" ParentId="1965" CreationDate="2013-10-22T18:52:50.630" Score="2" Body="&lt;p&gt;Telemetry is used to get in-flight data back to a ground station. For example, attitude (roll, pitch, yaw), altitude, GPS position, speed, battery voltages. It just gives you more feedback.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It can also be used to alert you when battery levels are too low or when a fault occurs.&lt;/p&gt;&#xA;" OwnerUserId="983" LastActivityDate="2013-10-22T18:52:50.630" CommentCount="1" />
  <row Id="1968" PostTypeId="2" ParentId="1966" CreationDate="2013-10-22T21:05:57.047" Score="1" Body="&lt;p&gt;You typically use the same data set (or, rather, parts of it) for training and testing. I. e. you split the data set into a training set and a test set. A common technique for evaluating classifiers in general is called 10-fold cross validation. You split your data set 10 different ways such that 90% of the data is used for training and 10% of the data is used for testing. This way you get 10 different accuracy results, which you can then use to do statistical significance testing to show that your classifier is better than somebody else's.&lt;/p&gt;&#xA;" OwnerUserId="1115" LastActivityDate="2013-10-22T21:05:57.047" />
  <row Id="1971" PostTypeId="2" ParentId="1728" CreationDate="2013-10-23T16:53:20.703" Score="2" Body="&lt;p&gt;I recommend arranging your sensors like the following:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;         Thickness of Line&#xA;            &amp;lt;--------&amp;gt;             /\&#xA;            |        |            /  \&#xA;            | *    * |             ||&#xA;            |        |             || moving&#xA;         *  |        |  *          || direction&#xA;            |        |             ||&#xA;            | *    * |             ||&#xA;            |        |             ||&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;This allows you to detect many conditions.  Let's say the sensors receives 1 if on black area and 0 if on white. Let's look at some of the configurations that may happen and their interpretations. I will use &lt;code&gt;|&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt;, &lt;code&gt;/&lt;/code&gt; and &lt;code&gt;\&lt;/code&gt; to indicate the borders of the actual line:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;You are completely lost:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;          0    0  &#xA;&#xA;     0              0&#xA;&#xA;          0    0  &#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;moving on straight line:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;        |        |&#xA;        | 1    1 |&#xA;        |        |&#xA;     0  |        |  0&#xA;        |        |&#xA;        | 1    1 |&#xA;        |        |&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;The line turns right:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;          0    0 &#xA;        ------------------&#xA;     0  |           1&#xA;        |         &#xA;        | 1    1 |--------&#xA;        |        |&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;The line turns left:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;          0    0 &#xA;------------------&#xA;     1           |  0&#xA;                 |&#xA;--------| 1    1 |&#xA;        |        |&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Gap ahead:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;        |________|&#xA;          0    0  &#xA;         ________ &#xA;     0  |        |  0&#xA;        |        |&#xA;        | 1    1 |&#xA;        |        |&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Gap behind:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;        |        |&#xA;        | 1    1 |&#xA;        |        |&#xA;     0  |________|  0&#xA;&#xA;          0    0  &#xA;         ________ &#xA;        |        |&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;leaning out of the line from the left:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;            |        |&#xA;          0/   1    /&#xA;          |         |&#xA;     0   /         /0 or 1&#xA;         |        |&#xA;        / 1    1 /&#xA;        |        |&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;you are being teased:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;          1    1  &#xA;&#xA;     1              1&#xA;&#xA;          1    1  &#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;There are many other variations you can think of. As one of the examples shows, this also gives you the ability to detect when you are leaning out of the line so you can come back smoothly (without having to turn back on the line sharply). Given this, following the circle shouldn't be a problem at all regardless of whether it's green or black.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Detecting color with grey-scale sensors is possible, but probably not what you are looking for. In your specific case, a value that is far from both 0 and 1 (say from 0.2 to 0.8 or something like that) would depict your color, which is only one. You should still pay attention that if only one of the sensors is showing such a value, for example 0.5, it is likely that you are just going out of the line and it's measuring a half white/half black location.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you really want to detect the actual color you have to do the following:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Use three grey-scale sensors instead of one at each location.&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;On each of the three, mount a color filter; one green, one blue and one red. Color filters are as simple as colored transparent pieces of plastic:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/dqfTd.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Read the three RGB values and convert them to &lt;a href=&quot;https://en.wikipedia.org/wiki/HSL_color_space&quot; rel=&quot;nofollow&quot;&gt;HSL (Hue-Saturation-Lightness)&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;Base your decisions on the calculated hue. I say only on the hue because the environment lighting very easily changes your observed saturation and lightness so they are not very reliable.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="158" LastEditorUserId="158" LastEditDate="2013-11-12T10:11:08.047" LastActivityDate="2013-11-12T10:11:08.047" />
  <row Id="1972" PostTypeId="2" ParentId="18" CreationDate="2013-10-24T10:01:13.187" Score="1" Body="&lt;p&gt;In the field of machine learning, we look at a Kalman filter as an inference algorithm on a latent variable model. The measurements are visible, but the true state is hidden. You now want to infer the true states.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As usual, this method relies on a set of parameters and -- in principle -- the way to obtain the best point-estimate for the parameters is to look at the likelihood for the data (given the parameters) and optimising your parameters to obtain the maximum value. This gives you the maximum likelihood estimate.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Unfortunately, in the case of the Kalman filter, this approach is not so easy and intractable to do in closed form. This is because we do not observe the hidden states. Therefore, one has to apply some tricks. One of them is to use the Expecation Maximisation (EM) Algorithm, which is an iterative approach: In the first step, you calculate the most likely value for your hidden states (the expected value) under your current parameters. In the second step, you keep the hidden states fixed and optimise the parameters to obtain the solution with highest likelihood. These steps are repeated until convergence.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can read up on the general concept of EM in a whole bunch of text books on machine learning (only one example: &lt;a href=&quot;http://web4.cs.ucl.ac.uk/staff/D.Barber/pmwiki/pmwiki.php?n=Brml.HomePage&quot; rel=&quot;nofollow&quot;&gt;&quot;Bayesian Reasoning and Machine Learning&quot;&lt;/a&gt; by David Barber). The process of inferring the parameters for linear dynamical systems (which gives you the Kalman filter type of model) is well described in a &lt;a href=&quot;http://www.gatsby.ucl.ac.uk/~zoubin/papers/tr-96-2.pdf&quot; rel=&quot;nofollow&quot;&gt;tech report by Zoubin Ghahramani and Geoffrey Hinton&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="2143" LastActivityDate="2013-10-24T10:01:13.187" />
  <row Id="1974" PostTypeId="1" AcceptedAnswerId="1977" CreationDate="2013-10-24T21:20:04.303" Score="2" ViewCount="179" Body="&lt;p&gt;I want to steer a RC car in a straight line.The car has 4 sharp IR sensors on each corner of the car to help it steer the corridor.The corridor is irregular and looks something similar to the picture below.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The car needs to be stay exactly at the middle(shown by lighter line) and take help of the IR sensors to correct its path.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The car has a servo on the front wheel to steer and another that controls the speed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I tried running it using a algorithm where it summed the values on each side of the car and took the difference.THe difference was then fed to a pid control the output of which went to steer the car.The greater the value from the pid (on either sides), the greater the value of the steering angle till it reaches the middle.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It works for the part where the walls are at similar distance from the center and even then it oscillates a lot around the center and fails miserably around the bumps in the corridor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I need to make changes to the algorithm and need some help in steering me  in the right direction.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The IR sensors are too finicky and is there a way to filter out the noise and make the readings more stable?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any help regarding the changes that needs to be implemented is much appreciated.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Currently the car only uses 4 IR sensors to guide.I can also use 2 ultrasonic sensors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/sXdUT.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="1139" LastEditorUserId="1139" LastEditDate="2013-10-24T23:03:00.993" LastActivityDate="2013-10-30T08:41:31.120" Title="Autonomous car steering using IR sensors" Tags="&lt;mobile-robot&gt;&lt;sensors&gt;" AnswerCount="3" CommentCount="3" />
  <row Id="1975" PostTypeId="2" ParentId="1167" CreationDate="2013-10-25T04:29:01.403" Score="2" Body="&lt;p&gt;I will try to answer 2 and 3.&lt;/p&gt;&#xA;&#xA;&lt;h1&gt;2&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;I am pretty sure the cheap ones won't and I doubt expensive ones would.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In addition, The viscosity isn't the only thing you have to take into account when it comes to accuracy. Distance, height, wear of the tubes, wear of the motor, liquids that can potentially accumulate in the tube, etc, etc. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Having that said, I wouldn't design the solution expecting constant rate. I would rather provide an easy interface to calibrate the pumps to a particular situation. Also, I would recommend the user to check calibration in a regular basis (something like 6 months, by experience).&lt;/p&gt;&#xA;&#xA;&lt;h1&gt;3&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;It doesn't really matter, you can use a simple relay, a solid state relay or a mosfet. &#xA;A professional level custom circuit would use a mosfets, as it is silent, small and fits better in a PCB. &#xA;Personally, I would rather use a relay board for DIY stuff, which is surprisingly cheaper and easier to find in single units these days. Also, it requires no soldering and doesn't require you to learn how to use the mosfet.&lt;/p&gt;&#xA;" OwnerUserId="2145" LastActivityDate="2013-10-25T04:29:01.403" />
  <row Id="1976" PostTypeId="1" AcceptedAnswerId="1982" CreationDate="2013-10-25T05:58:53.117" Score="2" ViewCount="45" Body="&lt;p&gt;I belong to an AUV team at my university. We are planning to have a Multibeam 2D Imaging Sonar (the Blueview P900) for our AUV to detect obstacles underwater.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have the following questions to ask on the feasibility of testing/implementing such sonars on AUVs.&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;As we know that these multibeam sonars have multiple reflections arriving at different times from various surfaces while testing in a pool, is there any recommended way to filter these noises in the image obtained from the sonar pings?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Are such sonars in use/test by any other team/organization anywhere else who do pool testing other than a ocean/reservoir testing where multiple reflections are almost zero except the reflections from the obstacle(s)?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Also i would like to know the recommended image processing algorithms that can be implemented/used to detect obstacles from the sonar images.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="2146" LastEditorUserId="350" LastEditDate="2013-10-25T19:53:07.923" LastActivityDate="2013-11-02T10:15:11.100" Title="Usage of Multibeam 2D Imaging Sonar for AUVs, testing them in the pool environment" Tags="&lt;sonar&gt;" AnswerCount="2" />
  <row Id="1977" PostTypeId="2" ParentId="1974" CreationDate="2013-10-25T15:30:02.703" Score="2" Body="&lt;p&gt;If you have a map, then you can use a Kalman filter with a motion update based on odometry and a sensor update based on the actual IR sensor readings and the expected sensor readings given your current position and the map. The PID control you implemented will only be able to make the vehicle drive in the actual center of the hallway, which would be a curved path based on the bumps in the hallway.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;HOWEVER, the simplest things you should try are as follows: 1) Implement an averaging filter on the IR sensor readings...aka take the average of n IR readings as the input to your control algorithm. This simulates a low pass filter and can eliminate high frequency noise. 2) Implement a threshold filter on the IR sensors...if the readings are greater than some range value, then DON'T use that sensor in your control loop. Combined, an averaging filter and threshold filter should mean that your PID loop is only controlling to the center of the walls that you want. In the image below, the algorithm would only control based off readings from the red walls, ignoring any readings from the black walls. If you don't find any walls within your range threshold (i.e. the hallway is open on both sides, you can try just maintaining your current heading). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/j336U.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="1960" LastActivityDate="2013-10-25T15:30:02.703" CommentCount="1" />
  <row Id="1978" PostTypeId="1" CreationDate="2013-10-25T16:25:45.717" Score="2" ViewCount="48" Body="&lt;p&gt;Recently I am working with two accelerometers: BMA020 and BMA180. I will try to explain my problem using BMA020 as example because it is less accurate therefore problem is more visible. When I hold my Acc in neutral position I get correct average result: -1G. Now I turn my Acc upside down but this time my average result is +0,91G. The same problem occurs for other axis. For BMA180 problem is less visible (-1G in normal position and +0.98G upside down). Do you know why accelerometer behaves like this ?&lt;/p&gt;&#xA;" OwnerUserId="2147" LastActivityDate="2013-11-02T22:30:28.927" Title="Accelerometers error (BMA020 and BMA180)" Tags="&lt;accelerometer&gt;" AnswerCount="2" />
  <row Id="1979" PostTypeId="1" CreationDate="2013-10-25T16:39:24.323" Score="1" ViewCount="46" Body="&lt;p&gt;I've been able to use &lt;a href=&quot;https://github.com/mavlink/pymavlink/blob/master/mavutil.py&quot; rel=&quot;nofollow&quot;&gt;pymavlink.mavutil&lt;/a&gt; to read telemetry from a .tlog created by &lt;a href=&quot;https://github.com/diydrones/MissionPlanner&quot; rel=&quot;nofollow&quot;&gt;MissionPlanner&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To do this, I create a &lt;code&gt;mavlogfile&lt;/code&gt; like this:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;mlog = mavutil.mavlink_connection('mylogfile.tlog')&lt;/code&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now I want to read the flight parameters (settings) from the .tlog . The method mavlogfile.param_fetch_all() appears to be designed only to work with a live telemetry link rather than a log. It sends a parameter request command, which obviously has no result when you are linked to a log rather than an actual aircraft.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I know the parameters are in the .tlog... how do I get them out?&lt;/p&gt;&#xA;" OwnerUserId="1473" LastActivityDate="2013-10-25T17:26:42.957" Title="How to retrieve parameters from mavlink .tlog using pymavlink?" Tags="&lt;python&gt;&lt;ardupilot&gt;&lt;mavlink&gt;" AnswerCount="1" />
  <row Id="1980" PostTypeId="2" ParentId="1979" CreationDate="2013-10-25T17:26:42.957" Score="2" Body="&lt;p&gt;Turns out it's implemented in &lt;a href=&quot;https://github.com/mavlink/mavlink/blob/master/pymavlink/tools/mavparms.py&quot; rel=&quot;nofollow&quot;&gt;https://github.com/mavlink/mavlink/blob/master/pymavlink/tools/mavparms.py&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;and the relevant code is:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;m = mlog.recv_match(type='PARAM_VALUE')&lt;/code&gt;&lt;/p&gt;&#xA;" OwnerUserId="1473" LastActivityDate="2013-10-25T17:26:42.957" />
  <row Id="1981" PostTypeId="1" CreationDate="2013-10-25T18:45:18.497" Score="1" ViewCount="135" Body="&lt;p&gt;I need to track a point in space. The point is less than 2&amp;nbsp;m away, it has to be passive, no batteries, and no charging.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I don't always have a line of sight. I need to pinpoint it to about a centimeter. I need to sample it at a frequency of 10&amp;nbsp;Hz or more.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can it be done at all? Does such a solution exist?&lt;/p&gt;&#xA;" OwnerUserId="2149" LastEditorUserId="1906" LastEditDate="2013-11-22T15:48:01.507" LastActivityDate="2013-11-22T15:48:01.507" Title="1 cm accuracy radio rangefinder?" Tags="&lt;sensors&gt;" AnswerCount="0" CommentCount="4" />
  <row Id="1982" PostTypeId="2" ParentId="1976" CreationDate="2013-10-25T20:32:31.400" Score="3" Body="&lt;p&gt;As you've noted, a pool is one of the worst environments in which to test acoustic sensors; there is nothing to dampen the echoes, and the multipath is quite extreme.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Generally, one of 3 things is done to help mitigate these effects -- the goal being an &lt;a href=&quot;http://en.wikipedia.org/wiki/Anechoic_chamber&quot; rel=&quot;nofollow&quot;&gt;anechoic test chamber&lt;/a&gt;.  &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;Make the shape of your test tank such that all echoes are reflected into a trap.  The &lt;a href=&quot;http://wikimapia.org/1362997/TRANSDEC-Anechoic-Pool&quot; rel=&quot;nofollow&quot;&gt;TRANSDEC anechoic pool&lt;/a&gt; accomplishes this with its eliptical shape; sounds that hit the bottom are directed toward the edge, which has a &quot;trap&quot; around its perimeter. (I can no longer find the cut-away diagram for that... sorry).&lt;br&gt;&#xA;&lt;img src=&quot;http://i.stack.imgur.com/FMyNb.jpg&quot; alt=&quot;TRANSDEC anechoic pool&quot;&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Put foam wedges along the outside of the tank to absorb acoustic energy, similar to the way that recording-studio anechoic chambers are designed. &#xA;&lt;a href=&quot;http://www.floridamemory.com/items/show/75485&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/YBKiQ.png&quot; alt=&quot;Vincent Benedetti placing a submarine model inside the large anechoic tank at the Naval Research Laboratory - Orlando, Florida.&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Aerate the water to scatter the echoes, a technique described in &lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1692822/pdf/11079420.pdf&quot; rel=&quot;nofollow&quot;&gt;this paper&lt;/a&gt;.  The use of microbubbles is apparently able to prevent most of the multipath effects.&#xA;&lt;a href=&quot;http://i.stack.imgur.com/5vrov.png&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/5vrovm.png&quot; alt=&quot;Diagrammatic representation of the anechoic aquarium, (a) cross-section and (b) top view.&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-10-25T20:32:31.400" />
  <row Id="1983" PostTypeId="1" CreationDate="2013-10-26T22:41:29.173" Score="4" ViewCount="218" Body="&lt;p&gt;I'm a first year electronics engineering student. I love almost all the aspects of robotics - the electronics, algorithms, control theory etc. I can't stand the mechanical aspect of robotics though.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can I have a fulfilling career in Robotics if I hate mechanics but love all other parts of robotics? I'm ready to learn mechanics if I absolutely have to, but would strongly prefer not to learn anymore than the absolute basics.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks.&lt;/p&gt;&#xA;" OwnerUserId="2154" LastActivityDate="2013-10-31T19:27:03.100" Title="Can you have a career in robotics if you hate mechanics?" Tags="&lt;software&gt;&lt;electronics&gt;&lt;mechanism&gt;" AnswerCount="4" CommentCount="3" FavoriteCount="1" />
  <row Id="1984" PostTypeId="2" ParentId="1983" CreationDate="2013-10-27T00:53:26.100" Score="7" Body="&lt;p&gt;The answer is 'yes'.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A more detailed answer likely depends on how you define &quot;robotics&quot;.  But generally, robotics applications are considered to require a very broad spectrum of knowledge.  So while most robotics includes some form of mechanical function, you could easily specialize in artificial intelligence, microcontroller design,  or any number of specialties without ever having to learn advanced mechanical theory and application. I would even say you are at advantage; I would guess, but do not know for certain, that most people are the other way. They enjoy the mechanical real-world aspects of robotics, not so much the abstract topics.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Given what you say you enjoy though, I would have to wonder if &quot;robotics&quot; should be your focus vs. a more general computer engineering or science focus.&lt;/p&gt;&#xA;" OwnerUserId="167" LastActivityDate="2013-10-27T00:53:26.100" />
  <row Id="1985" PostTypeId="1" CreationDate="2013-10-27T08:13:45.520" Score="4" ViewCount="126" Body="&lt;p&gt;First, is it possible to build map without landmarks for a robot in 2D? Let's say we have an aisle surrounded  by two walls. The robot moves in this environment. Now is it feasible to build such a SLAM problem? Or landmarks must be available to do so?&lt;/p&gt;&#xA;" OwnerUserId="2155" LastActivityDate="2013-10-30T09:42:28.047" Title="SLAM without landmarks?" Tags="&lt;mobile-robot&gt;&lt;slam&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="1986" PostTypeId="2" ParentId="1985" CreationDate="2013-10-27T17:21:05.450" Score="4" Body="&lt;p&gt;I think you misunderstand what a landmark is. It is a generic, catch-all term for anything that a robot can recognize and use as part of a map. In particular, &quot;landmarks&quot; are important for feature-based SLAM algorithms, such as EKF-based slam. What you use for &quot;landmarks&quot; depends on what sensors are available to the robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In your case, since you haven't specified any sensing, then we'll assume the robot knows when it hits an object. Then any &quot;landmark&quot; is simply any time the robot bumps into something. If you do this with pen and paper, you'd just wander around and put an X any time you hit something, then turn and keep wandering. As time goes to infinity, you'd have a reasonable map of where object boundaries are, and what the object shapes are, as long as everything is static.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In this case, the &quot;map&quot; can just be a bitmap, where each pixel is 0 or 1, depending on if it has an object in that space or not. Scaling is up to the application.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I suggest doing a bit more research on these topics:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Occupancy Grid representation&lt;/li&gt;&#xA;&lt;li&gt;Feature-based mapping&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="163" LastActivityDate="2013-10-27T17:21:05.450" CommentCount="1" />
  <row Id="1987" PostTypeId="2" ParentId="1983" CreationDate="2013-10-27T18:02:49.873" Score="4" Body="&lt;p&gt;Working in robotics doesn't mean that you must understand (or enjoy) all the relevant disciplines.  It simply means that you must understand that you are one part of a team that produces a robotic system.  On the other hand, what skills you have will determine which teams will find you valuable as a member -- smaller teams require everyone to bring multiple skills to the table, but in larger teams you can get extreme specialization.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;At a minimum, you need only understand that the mechanical system will constrain what can be with the other systems (e.g. you may have a hard maximum or minimum acceleration, finite range of motion, limit on total battery current, etc).  You will work within those constraints.  &lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-10-27T18:02:49.873" />
  <row Id="1988" PostTypeId="2" ParentId="1974" CreationDate="2013-10-28T09:31:49.100" Score="1" Body="&lt;p&gt;You could have it keep track of the last distance read from the IR sensors and if it changes more than a certain amount (2%? not sure what would work for you) calculate the difference between the measured distance and the expected distance. Save that difference as an offset, which you apply to the reading from that IR sensor until it returns to normal. If the sensor reads 'infinity' you could ignore the actual reading entirely and just give the PID loop the &quot;expected&quot; value. This is entirely untested.&lt;/p&gt;&#xA;" OwnerUserId="2160" LastActivityDate="2013-10-28T09:31:49.100" />
  <row Id="1989" PostTypeId="2" ParentId="1983" CreationDate="2013-10-28T16:21:37.197" Score="1" Body="&lt;p&gt;Robotics is by definition a subject rooted in mechanics and if you &quot;hate&quot; this subject then surely there will always be an large part of this industry that you &quot;hate&quot;.  So I would suggest you review either:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;a.  What you mean by &quot;I hate mechanics&quot; or &quot;the mechanical side&quot;&#xA;b.  Understand what you like about Robotics because in the end all of the work is translated into the mechanical side (electronics, algorithms, control theory etc.).  That is this work has to be implemented in the real world.  And this is where the real rewards, off seeing the results of your work, will come from.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note:  My experience is that if you work hard at the mechanics side then ultimately you will learn to like it as your work translates into real things.&lt;/p&gt;&#xA;" OwnerUserId="2166" LastActivityDate="2013-10-28T16:21:37.197" />
  <row Id="1991" PostTypeId="1" AcceptedAnswerId="2060" CreationDate="2013-10-29T09:01:10.230" Score="5" ViewCount="108" Body="&lt;p&gt;I'm looking to build an outdoor robot and I need to know if &lt;a href=&quot;http://en.wikipedia.org/wiki/Time-of-flight_camera&quot; rel=&quot;nofollow&quot;&gt;time-of-flight cameras&lt;/a&gt; like the &lt;a href=&quot;http://www.mesa-imaging.ch/swissranger4500.php&quot; rel=&quot;nofollow&quot;&gt;SwissRanger™ SR4500&lt;/a&gt; work in fog, does anybody have some experiences on that?&lt;/p&gt;&#xA;" OwnerUserId="1777" LastEditorUserId="37" LastEditDate="2013-10-31T22:10:07.890" LastActivityDate="2013-11-13T15:01:20.960" Title="Are time-of-flight cameras like the swissranger affected by outdoor fog?" Tags="&lt;mobile-robot&gt;&lt;cameras&gt;" AnswerCount="1" FavoriteCount="1" />
  <row Id="1992" PostTypeId="1" CreationDate="2013-10-30T04:59:42.603" Score="2" ViewCount="90" Body="&lt;p&gt;The state vector is &#xA;$$ \textbf{X} = \begin{bmatrix} x \\ y \\ v_{x} \\ v_{y} \end{bmatrix}$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;transition function is &#xA;$$&#xA;\textbf{X}_{k} = f(\textbf{X}_{k-1}, \Delta t) =&#xA;\begin{cases} &#xA;x_{k-1} + v_{xk} \Delta t \\&#xA;y_{k-1} + v_{yk} \Delta t &#xA; \end{cases} &#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$z_{b} = atan2(y, x)$ and&#xA;$z_{r} = \sqrt{ x^{2} + y^{2}}$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;the Jacobian of the observation model:&#xA;$$&#xA;\frac{\partial h}{\partial x} =&#xA; \begin{bmatrix} \frac{-y}{x^{2}+y^{2}} &amp;amp; \frac{1}{x(1+(\frac{y}{x})^{2})} &amp;amp; 0 &amp;amp; 0 \\&#xA;                 \frac{x}{\sqrt{ x^{2} + y^{2}}} &amp;amp; \frac{y}{\sqrt{ x^{2} + y^{2}}} &amp;amp; 0 &amp;amp; 0 &#xA; \end{bmatrix}&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My question is how  the Jacobian of the observation model has been obtained? and why it is 2X4?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;the model from &lt;a href=&quot;http://www.mrpt.org/Kalman_Filters&quot; rel=&quot;nofollow&quot;&gt;Kalman filter&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="2155" LastEditorUserId="2155" LastEditDate="2013-10-31T04:18:41.040" LastActivityDate="2013-11-01T15:08:00.910" Title="Jacobian of the observation model?" Tags="&lt;kalman-filter&gt;" AnswerCount="2" CommentCount="2" ClosedDate="2013-10-31T18:58:49.853" />
  <row Id="1993" PostTypeId="2" ParentId="1974" CreationDate="2013-10-30T08:41:31.120" Score="0" Body="&lt;p&gt;I had problems with servo jitter and power surges when the motors where running which reset the Arduino I was uisng.&#xA;I sorted the problem by using capacitors on my servo &amp;amp; main power rails. My thinking is that you have the same type of noise affecting the IR sensors.&#xA;Take a look at these posts on Let's Make Robots which should help you track down the source of the noise. &lt;br&gt;&#xA;&lt;a href=&quot;http://letsmakerobots.com/node/23297&quot; rel=&quot;nofollow&quot;&gt;http://letsmakerobots.com/node/23297&lt;/a&gt; &lt;br&gt;&#xA;&lt;a href=&quot;http://letsmakerobots.com/node/5549&quot; rel=&quot;nofollow&quot;&gt;http://letsmakerobots.com/node/5549&lt;/a&gt;  &lt;br&gt;&#xA;&lt;a href=&quot;http://letsmakerobots.com/node/3880&quot; rel=&quot;nofollow&quot;&gt;http://letsmakerobots.com/node/3880&lt;/a&gt;  &lt;br&gt;&lt;br&gt;&#xA;If you use the ultrasonic sensors there is a good library for the Arduino called NewPing which has good function within as it can be set a maximum distance to scan for. So if you know the width of the corridor you could half it then set a flag when reading within or outside that range       &lt;/p&gt;&#xA;" OwnerUserId="2099" LastActivityDate="2013-10-30T08:41:31.120" />
  <row Id="1994" PostTypeId="2" ParentId="1935" CreationDate="2013-10-30T09:03:46.500" Score="1" Body="&lt;p&gt;You could try this:&#xA;Using wire cable; mount pulleys at each corner of window; then get a suitable motor for your pull requirement (4lbs). wind the cable around the motor shatft then power forward/backward to Maybe use a block and tackle arrangement for increased torque. Don't forget the need for limit stop switches.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This could be cheaper than screw method but might not have same look and feel     &lt;/p&gt;&#xA;" OwnerUserId="2099" LastActivityDate="2013-10-30T09:03:46.500" />
  <row Id="1995" PostTypeId="1" CreationDate="2013-10-30T09:12:57.947" Score="2" ViewCount="205" Body="&lt;p&gt;I lead a university robotics team that needs PID controllers for four drive motors and two additional motors that are used in a secondary system. I would strongly prefer to buy pre-built PID controllers that provide just about any reasonable interface for setting PID constants, motor velocity and direction, as the controllers are not remotely central to the difficult, interesting problems we're trying to solve. To my astonishment, the Internet doesn't seem to be saturated with such controllers (talk about reinventing the wheel - hundreds of tutorials but almost no pre-built solutions! Did Willow Garage build their own PID controller for the PR2?!). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Does anyone have recommendations/experience, preferably pointers to such controllers? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've Googled around quite a bit, and so far &lt;a href=&quot;https://github.com/Exadler/DualMotorControlCape&quot; rel=&quot;nofollow&quot;&gt;this&lt;/a&gt; is the best option I've found. It's a cape for a BeagleBone Black (which is the board we're using). The problem is that the Python library is not finished - it resets PID constants at every call, it doesn't support changing the direction of the motor, and it seems to only support setting motor power, not velocity, which gives me the impression that it's not actually using the PID controller at all.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Additional details:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The stall current of our &lt;a href=&quot;http://www.pololu.com/catalog/product/2271&quot; rel=&quot;nofollow&quot;&gt;drive motors&lt;/a&gt; is 6A. They are brushless DC motors with quadrature encoders. The secondary motors are much smaller, and we're building our own encoders for them.&lt;/li&gt;&#xA;&lt;li&gt;Our code base is in Python, and we're running on a BeagleBone Black using the latest Debian image from Robert Nelson (that guy's awesome!). Our batteries provide 14.8V, and we already have 3.3V and 5V rails.&lt;/li&gt;&#xA;&lt;li&gt;Our robot is fairly small, about 1x1x2 feet, and weighs about 9 pounds. This info is meant to give perspective with regard to scale.&lt;/li&gt;&#xA;&lt;li&gt;$350 or so is the comfortable top range of what we could spend to get all 6 motors PID-controlled.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Any help would be greatly appreciated!&lt;/p&gt;&#xA;" OwnerUserId="2173" LastEditorUserId="2173" LastEditDate="2013-10-31T07:22:18.790" LastActivityDate="2013-12-30T12:41:55.830" Title="Pre-built PID motor controller" Tags="&lt;motor&gt;&lt;pid&gt;&lt;brushless-motor&gt;" AnswerCount="3" CommentCount="8" />
  <row Id="1997" PostTypeId="1" AcceptedAnswerId="2006" CreationDate="2013-10-30T16:31:17.353" Score="3" ViewCount="67" Body="&lt;p&gt;For a 6DoF robot with all revolute joints the Jacobian is given by:&#xA;$$&#xA;\mathbf{J} = &#xA;\begin{bmatrix}&#xA;\hat{z_0} \times (\vec{o_6}-\vec{o_0}) &amp;amp; \ldots &amp;amp; \hat{z_5} \times (\vec{o_6}-\vec{o_5})\\&#xA;\hat{z_0} &amp;amp; \ldots &amp;amp; \hat{z_5}&#xA;\end{bmatrix}&#xA;$$&#xA;where $z_i$ is the unit z axis of joint $i+1$(using DH params), $o_i$ is the origin of the coordinate frame connected to joint $i+1$, and $o_6$ is the origin of the end effector.  The jacobian matrix is the relationship between the Cartesian velocity vector and the joint velocity vector:&#xA;$$&#xA;\dot{\mathbf{X}}=&#xA;\begin{bmatrix}&#xA;\dot{x}\\&#xA;\dot{y}\\&#xA;\dot{z}\\&#xA;\dot{r_x}\\&#xA;\dot{r_y}\\&#xA;\dot{r_z}&#xA;\end{bmatrix}&#xA;=&#xA;\mathbf{J}&#xA;\begin{bmatrix}&#xA;\dot{\theta_1}\\&#xA;\dot{\theta_2}\\&#xA;\dot{\theta_3}\\&#xA;\dot{\theta_4}\\&#xA;\dot{\theta_5}\\&#xA;\dot{\theta_6}\\&#xA;\end{bmatrix}&#xA;=&#xA;\mathbf{J}\dot{\mathbf{\Theta}}&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here is a singularity position of a Staubli TX90XL 6DoF robot:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/Ikjas0J.png&quot; alt=&quot;robot with joint 4 and joint 6 aligned pointed down&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$&#xA;\mathbf{J} = &#xA;\begin{bmatrix}&#xA;          -50     &amp;amp;    -425     &amp;amp;    -750      &amp;amp;      0     &amp;amp;    -100      &amp;amp;      0\\&#xA;       612.92     &amp;amp;       0     &amp;amp;       0      &amp;amp;      0     &amp;amp;       0      &amp;amp;      0\\&#xA;            0     &amp;amp; -562.92     &amp;amp;       0      &amp;amp;      0     &amp;amp;       0      &amp;amp;      0\\&#xA;            0     &amp;amp;       0     &amp;amp;       0      &amp;amp;      0     &amp;amp;       0      &amp;amp;      0\\&#xA;            0     &amp;amp;       1     &amp;amp;       1      &amp;amp;      0     &amp;amp;       1      &amp;amp;      0\\&#xA;            1     &amp;amp;       0     &amp;amp;       0      &amp;amp;     -1     &amp;amp;       0      &amp;amp;     -1&#xA;\end{bmatrix}&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can easily see that the 4th row corresponding to $\dot{r_x}$ is all zeros, which is exactly the lost degree of freedom in this position.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, other cases are not so straightforward.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/cAUoVq3.png&quot; alt=&quot;robot with joint 4 and joint 6 aligned pointed at an angle&quot;&gt;&#xA;$$&#xA;\mathbf{J} = &#xA;\begin{bmatrix}&#xA;          -50   &amp;amp;   -324.52  &amp;amp;    -649.52   &amp;amp;         0   &amp;amp;   -86.603   &amp;amp;         0\\&#xA;       987.92   &amp;amp;         0  &amp;amp;          0   &amp;amp;         0   &amp;amp;         0   &amp;amp;         0\\&#xA;            0   &amp;amp;   -937.92  &amp;amp;       -375   &amp;amp;         0   &amp;amp;       -50   &amp;amp;         0\\&#xA;            0   &amp;amp;         0  &amp;amp;          0   &amp;amp;       0.5   &amp;amp;         0   &amp;amp;       0.5\\&#xA;            0   &amp;amp;         1  &amp;amp;          1   &amp;amp;         0   &amp;amp;         1   &amp;amp;         0\\&#xA;            1   &amp;amp;         0  &amp;amp;          0   &amp;amp;    -0.866   &amp;amp;         0   &amp;amp;    -0.866&#xA;\end{bmatrix}&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here you can clearly see that joint 4 and joint 6 are aligned because the 4th and 6th columns are the same.  But it's not clear which Cartesian degree of freedom is lost (it should be a rotation about the end effector's x axis in red).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Even less straightforward are singularities at workspace limits.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/ykxmMUH.png&quot; alt=&quot;robot at workspace limit with no aligned joint axes&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$&#xA;\mathbf{J} = &#xA;\begin{bmatrix}&#xA;          -50     &amp;amp;     650   &amp;amp;       325  &amp;amp;          0    &amp;amp;        0     &amp;amp;       0\\&#xA;       1275.8     &amp;amp;       0   &amp;amp;         0  &amp;amp;         50    &amp;amp;        0     &amp;amp;       0\\&#xA;            0     &amp;amp; -1225.8   &amp;amp;   -662.92  &amp;amp;          0    &amp;amp;     -100     &amp;amp;       0\\&#xA;            0     &amp;amp;       0   &amp;amp;         0  &amp;amp;    0.86603    &amp;amp;        0     &amp;amp;       1\\&#xA;            0     &amp;amp;       1   &amp;amp;         1  &amp;amp;          0    &amp;amp;        1     &amp;amp;       0\\&#xA;            1     &amp;amp;       0   &amp;amp;         0  &amp;amp;        0.5    &amp;amp;        0     &amp;amp;       0&#xA;\end{bmatrix}&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In this case, the robot is able to rotate $\dot{-r_y}$ but not $\dot{+r_y}$.  There are no rows full of zeros, or equal columns, or any clear linearly dependent columns/rows.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there a way to determine which degrees of freedom are lost by looking at the jacobian?&lt;/p&gt;&#xA;" OwnerUserId="2175" LastActivityDate="2013-10-31T17:28:18.563" Title="Is there a way to determine which degrees of freedom are lost in a robot at a singularity position by looking at the jacobian?" Tags="&lt;robotic-arm&gt;&lt;inverse-kinematics&gt;&lt;industrial-robot&gt;" AnswerCount="1" />
  <row Id="1998" PostTypeId="2" ParentId="1995" CreationDate="2013-10-30T17:30:56.493" Score="0" Body="&lt;p&gt;Should be able to find something either &lt;a href=&quot;http://www.kbelectronics.com/Variable_Speed_DC_Drives.html&quot; rel=&quot;nofollow&quot;&gt;here at Kb Drives&lt;/a&gt; or &lt;a href=&quot;http://www.geckodrive.com/g320x.html&quot; rel=&quot;nofollow&quot;&gt;at GeckoDrive&lt;/a&gt;&#xA;I think the &quot;problem&quot; is that very few hobbyists actually use servo drives for projects since steppers are simpler. As a result, most of the prebuilt stuff you will find is for industry, with prices to match. Geckodrive has a good reputation (never used them) and their prices are quite reasonable.&lt;/p&gt;&#xA;" OwnerUserId="794" LastActivityDate="2013-10-30T17:30:56.493" CommentCount="3" />
  <row Id="1999" PostTypeId="2" ParentId="1995" CreationDate="2013-10-30T18:24:46.943" Score="0" Body="&lt;p&gt;These should work well: &lt;a href=&quot;http://www.jrkerr.com/&quot; rel=&quot;nofollow&quot;&gt;http://www.jrkerr.com/&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Control via serial w/ tunable PID gains for position, velocity and acceleration. They also require a quadrature encoder signal, so you're good to go in that regard.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My boss has used these in previous robotics projects and vouches for them.&lt;/p&gt;&#xA;" OwnerUserId="1960" LastActivityDate="2013-10-30T18:24:46.943" CommentCount="1" />
  <row Id="2000" PostTypeId="1" AcceptedAnswerId="2004" CreationDate="2013-10-30T18:46:37.280" Score="2" ViewCount="79" Body="&lt;p&gt;I have an unscented Kalman filter (UKF) that tracks the state of a robot. The state vector has 12 variables. Each time I carry out a prediction step, my transfer function (naturally) acts on the entire state. However, my sensors provide measurements of different parts of the robot's state, so I may get roll, pitch, yaw and their respective velocities in one measurement, and then linear velocity in another.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My approach to handling this so far has been to simply create sub-matrices for the covariance, carry out my standard UKF update equations, and then stick the resulting values back into the full covariance matrix. However, after a few updates, the UKF yells at me for trying to pass a matrix that isn't positive-definite into a Cholesky Decomposition function. Clearly the covariance is losing its positive-definite properties, and I'm guessing it has to do with my attempts to update subsets of the full covariance matrix. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;As an example taken from an actual log file, the following matrix (after the UKF prediction step) is positive-definite:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;   1.1969            0            0            0            0            0      0.11567            0            0            0            0            0&#xA;        0       1.9682            0            0            0            0            0      0.98395            0            0            0            0&#xA;        0            0       1.9682            0            0            0            0            0      0.98395            0            0            0&#xA;        0            0            0       1.9682            0            0            0            0            0      0.98395            0            0&#xA;        0            0            0            0       1.9682            0            0            0            0            0      0.98395            0&#xA;        0            0            0            0            0       1.9682            0            0            0            0            0      0.98395&#xA;  0.11567            0            0            0            0            0      0.01468            0            0            0            0            0&#xA;        0      0.98395            0            0            0            0            0            1            0            0            0            0&#xA;        0            0      0.98395            0            0            0            0            0            1            0            0            0&#xA;        0            0            0      0.98395            0            0            0            0            0            1            0            0&#xA;        0            0            0            0      0.98395            0            0            0            0            0            1            0&#xA;        0            0            0            0            0      0.98395            0            0            0            0            0            1&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;However, after processing the correction for one variable (in this case, linear X velocity), the matrix becomes:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;   1.1969            0            0            0            0            0      0.11567            0            0            0            0            0&#xA;        0       1.9682            0            0            0            0            0      0.98395            0            0            0            0&#xA;        0            0       1.9682            0            0            0            0            0      0.98395            0            0            0&#xA;        0            0            0       1.9682            0            0            0            0            0      0.98395            0            0&#xA;        0            0            0            0       1.9682            0            0            0            0            0      0.98395            0&#xA;        0            0            0            0            0       1.9682            0            0            0            0            0      0.98395&#xA;  0.11567            0            0            0            0            0         0.01            0            0            0            0            0&#xA;        0      0.98395            0            0            0            0            0            1            0            0            0            0&#xA;        0            0      0.98395            0            0            0            0            0            1            0            0            0&#xA;        0            0            0      0.98395            0            0            0            0            0            1            0            0&#xA;        0            0            0            0      0.98395            0            0            0            0            0            1            0&#xA;        0            0            0            0            0      0.98395            0            0            0            0            0            1&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;The difference between the two matrices above is &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;        0            0            0            0            0            0            0            0            0            0            0            0&#xA;        0            0            0            0            0            0            0            0            0            0            0            0&#xA;        0            0            0            0            0            0            0            0            0            0            0            0&#xA;        0            0            0            0            0            0            0            0            0            0            0            0&#xA;        0            0            0            0            0            0            0            0            0            0            0            0&#xA;        0            0            0            0            0            0            0            0            0            0            0            0&#xA;        0            0            0            0            0            0     -0.00468            0            0            0            0            0&#xA;        0            0            0            0            0            0            0            0            0            0            0            0&#xA;        0            0            0            0            0            0            0            0            0            0            0            0&#xA;        0            0            0            0            0            0            0            0            0            0            0            0&#xA;        0            0            0            0            0            0            0            0            0            0            0            0&#xA;        0            0            0            0            0            0            0            0            0            0            0            0&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;As you can see, the only difference between the two is the value in the location of the variance of linear X velocity, which is the measurement I just processed. This difference is enough to &quot;break&quot; my covariance matrix.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have two questions:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;Updating a subset of the filter doesn't appear to be the right way to go about things. Is there a better solution?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Alternatively, am I missing a step that would keep my covariance matrix as positive-definite?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Thanks!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It looks like I'm not properly placing the values back into the original covariance matrix. Simply copying the values back isn't sufficient. I need to track the correlation coefficients for the covariance matrix, and make sure that when I update a variance value, I update all the values in its row/column to maintain the correlation coefficient value. I have to do some more testing to verify that this is my issue, but some initial analysis in Matlab suggests that it is. If I'm correct, I'll answer my own question.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT 2:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Given the response below and after trying it, I can see that my original edit idea won't fly. However, I have one more question:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As this is a UKF, I don't actually have Jacobian matrices. I think I see how I would make it work within the UKF update equations, but even in an EKF - and I ask because I have one of those as well - my state-to-measurement function $h$ is going to end up being the identity matrix, as I am directly measuring my state variables. In the case, I take it my &quot;Jacobian&quot; would just be an $m \times n$ matrix with ones in the $(i, i)$ location, where $i$ is the index of the measured values in the measurement vector?&lt;/p&gt;&#xA;" OwnerUserId="2176" LastEditorUserId="2176" LastEditDate="2013-11-01T13:31:19.383" LastActivityDate="2013-11-01T13:31:19.383" Title="Maintaining positive-definite property for covariance in an unscented Kalman filter update" Tags="&lt;kalman-filter&gt;" AnswerCount="1" />
  <row Id="2001" PostTypeId="2" ParentId="1992" CreationDate="2013-10-31T04:19:18.603" Score="1" Body="&lt;p&gt;I've solved the problem by applying&#xA;$$  \frac{\partial h}{\partial x} = &#xA;\begin{bmatrix}&#xA;\frac{\partial z_{b}}{\partial x} &amp;amp; \frac{\partial z_{b}}{\partial y} &amp;amp;&#xA;\frac{\partial z_{b}}{\partial v_{x}} &amp;amp; \frac{\partial z_{b}}{\partial v_{y}} \\&#xA;\frac{\partial z_{r}}{\partial x} &amp;amp; \frac{\partial z_{r}}{\partial y} &amp;amp;&#xA;\frac{\partial z_{r}}{\partial v_{x}} &amp;amp; \frac{\partial z_{r}}{\partial v_{y}}&#xA;\end{bmatrix}  =&#xA;	\begin{bmatrix}  \frac{-y}{x^{2}+y^{2}} &amp;amp; \frac{1}{x(1+(\frac{y}{x})^{2})} &amp;amp; 0 &amp;amp; 0 \\&#xA;					 \frac{x}{\sqrt{x^{2}+y^{2}}} &amp;amp; \frac{y}{\sqrt{x^{2}+y^{2}}} &amp;amp; 0 &amp;amp; 0 \\ &#xA;	\end{bmatrix}&#xA;$$&lt;/p&gt;&#xA;" OwnerUserId="2155" LastEditorUserId="2155" LastEditDate="2013-11-01T15:08:00.910" LastActivityDate="2013-11-01T15:08:00.910" CommentCount="5" />
  <row Id="2002" PostTypeId="2" ParentId="1995" CreationDate="2013-10-31T06:47:50.713" Score="0" Body="&lt;p&gt;Check &lt;a href=&quot;http://www.pololu.com&quot; rel=&quot;nofollow&quot;&gt;http://www.pololu.com&lt;/a&gt; , they have few cheap options. If you want more reliable, more expensive solutions, then check &lt;a href=&quot;http://www.copleycontrols.com&quot; rel=&quot;nofollow&quot;&gt;http://www.copleycontrols.com&lt;/a&gt; . Both have solutions that meet your requirements, just find something that suits your budget. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is another option that is used mainly for robotic drive, quite easy to setup, but it also allows you to drive motors individually, worth while looking at : www.robot-electronics.co.uk/htm/md49tech.htm&lt;/p&gt;&#xA;" OwnerUserId="642" LastEditorUserId="642" LastEditDate="2013-10-31T06:59:03.813" LastActivityDate="2013-10-31T06:59:03.813" CommentCount="3" />
  <row Id="2003" PostTypeId="2" ParentId="736" CreationDate="2013-10-31T09:51:04.067" Score="0" Body="&lt;p&gt;I know I'm digging up an old thread and this is sort of off topic, but I don't think you can just get hold of ET1200 chips from Beckhoff. I emailed them a little while back and was advised that I need to join the Ethercat group. To do this I had to demonstrate that I was going to contribute back to the group - ie, by building and selling devices that used the Ethercat stuff. At that (and this) point in time, I am still prototyping my device (a brushless motor controller for robot applications - currently using CAN) so I could not offer anything (I cannot give a solid time for completion - Im still working on my undergrad). I expressed to them my disappointment. They said not to be disappointed!! Pretty funny stuff! &#xA;I would &lt;em&gt;really&lt;/em&gt; like to get into Ethercat, but the ASICs seem to be untouchable to hobbyists or those without a company.&#xA;Also, this is my first post, so apologies if I have angered the gods by digging up an old post!&lt;/p&gt;&#xA;" OwnerUserId="2178" LastActivityDate="2013-10-31T09:51:04.067" CommentCount="3" />
  <row Id="2004" PostTypeId="2" ParentId="2000" CreationDate="2013-10-31T17:03:43.553" Score="0" Body="&lt;p&gt;A few notes first,&lt;/p&gt;&#xA;&#xA;&lt;p&gt;First, as you mentioned, you can't just pull out a submatrix and do an &lt;em&gt;update&lt;/em&gt; on it. You &lt;em&gt;can&lt;/em&gt; do a propogation step on a submatrix, however. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is because of the cross-covariance terms (which &quot;spread&quot; information across different parts of the state). This is why having a more accurate estimate of your heading will lead to more accurate position estimates, for example. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, following your edit, simply updating the cross-correlation (covariance) terms won't do it either, you need to update the whole matrix (unless you know &lt;em&gt;for sure&lt;/em&gt; that some elements are independent, conditioned on the state estimate.  &lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Here you go:&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;To do this, form the Jacobian matrices as before, but note that there should be zeros in all off-diagonal elements when no part of that state is being measured. Then the magic of matrix inversion will spread the innovation corrections to the correct parts of the state. The Jacobian matrix &lt;em&gt;must&lt;/em&gt; be of size $n\times m$ for $m$ measured values and $n$ state variables (or $m\times n$ depending on your definition of Jacobian). None of this &quot;update part of the covariance junk&quot; unless you know &lt;em&gt;for sure&lt;/em&gt; that the Jacobian elements are equivalent to identity. The safest way is to use the full Jacobian.&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Other hacks (once everything is theoretically correct)&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;However, this &lt;em&gt;still&lt;/em&gt; won't ensure PD covariance matrices.&#xA;I strongly &lt;em&gt;strongly&lt;/em&gt; recommend you don't do the following hacks until you fix all the other mistakes. But in the end, for a field-deploy-able system that operates for non-trivial amounts of time, I've found it is almost always necessary to do the following things:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;After all updates, Let covariance $P$ be $P\gets \frac{1}{2}P + \frac{1}{2}P^{T}$, just to &quot;even out&quot; the off-diagonal terms -- for symmetry&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Let $P\gets P + \epsilon I_{n\times n}$, where $\epsilon$ is a small scalar to ensure you don't underflow (and wreck the &lt;a href=&quot;https://en.wikipedia.org/wiki/Condition_number&quot; rel=&quot;nofollow&quot;&gt;condition number&lt;/a&gt; of your matrix)&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="163" LastActivityDate="2013-10-31T17:03:43.553" CommentCount="1" />
  <row Id="2005" PostTypeId="2" ParentId="1992" CreationDate="2013-10-31T17:14:51.900" Score="2" Body="&lt;p&gt;The Jacobian is of size $2\times 4$ because you have four state elements and two measurement equations.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant&quot; rel=&quot;nofollow&quot;&gt;Jacobian&lt;/a&gt; of the measurement model is the matrix where each $i,j$ element corresponds to the partial derivative of the $i$th measurement equation with respect to the $j$th state element.&lt;/p&gt;&#xA;" OwnerUserId="163" LastActivityDate="2013-10-31T17:14:51.900" CommentCount="1" />
  <row Id="2006" PostTypeId="2" ParentId="1997" CreationDate="2013-10-31T17:28:18.563" Score="1" Body="&lt;p&gt;You need to find the null space, not just look for zero rows or full columns. And I don't mean the null space of &lt;em&gt;any particular&lt;/em&gt; jacobian, I mean the analytic space of all singular configurations, given the closed-form Jacobian. Usually this occurs because of a &lt;a href=&quot;https://en.wikipedia.org/wiki/Gimbal_lock&quot; rel=&quot;nofollow&quot;&gt;gimbal lock&lt;/a&gt; (as opposed to just an unreachable state space)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Doing this in closed form is very, very hard.   But sometimes you can reduce the space a little.&lt;/p&gt;&#xA;" OwnerUserId="163" LastActivityDate="2013-10-31T17:28:18.563" />
  <row Id="2007" PostTypeId="2" ParentId="1983" CreationDate="2013-10-31T19:21:48.197" Score="1" Body="&lt;p&gt;I have been working with Numerical Control for more than 30 years. This is a arm of the robotics genera which doesn't appear to be touched upon. What I do is programming, not mechanics. There are several types of jobs available in NC without getting your hands dirty.&#xA;Most of the people I interface with are mechanical and manufacturing engineers. &lt;/p&gt;&#xA;" OwnerUserId="2182" LastEditorUserId="2182" LastEditDate="2013-10-31T19:27:03.100" LastActivityDate="2013-10-31T19:27:03.100" />
  <row Id="2009" PostTypeId="1" AcceptedAnswerId="2010" CreationDate="2013-11-01T15:22:32.457" Score="1" ViewCount="44" Body="&lt;p&gt;This is a follow up to &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://robotics.stackexchange.com/questions/2000/maintaining-positive-definite-property-for-covariance-in-an-unscented-kalman-fil/2004#2004&quot;&gt;Maintaining positive-definite property for covariance in an unscented Kalman filter update&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;...but it's deserving of its own question, I think.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am processing measurements in my EKF for a subset of the variables in my state. My state vector is of cardinality 12. I am directly measuring my state variables, which means my state-to-measurement function $h$ is the identity. I am trying to update the first two variables in my state vector, which are the x and y position of my robot. My Kalman update matrices currently look like this:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;State $x$ (just test values):&#xA;$$&#xA;\left(\begin{array}{ccc}&#xA;0.4018 &amp;amp; 0.0760&#xA;\end{array} \right) &#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Covariance matrix $P$ (pulled from log file): &#xA;$$&#xA;\left(\begin{array}{ccc}&#xA;0.1015 &amp;amp; -0.0137 &amp;amp; -0.2900 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0.0195 &amp;amp; 0.0233 &amp;amp; 0.1004 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\&#xA;-0.0137 &amp;amp; 0.5825 &amp;amp; -0.0107 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0.0002 &amp;amp; -0.7626 &amp;amp; -0.0165 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\&#xA;-0.2900 &amp;amp; -0.0107 &amp;amp; 9.6257 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0.0015 &amp;amp; 0.0778 &amp;amp; -2.9359 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\&#xA;0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0.0100 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\&#xA;0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0.0100 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\&#xA;0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0.0100 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\&#xA;0.0195 &amp;amp; 0.0002 &amp;amp; 0.0015 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0.0100 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\&#xA;0.0233 &amp;amp; -0.7626 &amp;amp; 0.0778 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1.0000 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\&#xA;0.1004 &amp;amp; -0.0165 &amp;amp; -2.9359 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1.0000 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\&#xA;0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0.0100 &amp;amp; 0 &amp;amp; 0 \\&#xA;0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0.0100 &amp;amp; 0 \\&#xA;0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0.0100 \\&#xA;\end{array} \right) &#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Measurement $z$ (just test values):&#xA;$$&#xA;\left(\begin{array}{ccc}&#xA;2 &amp;amp; 2&#xA;\end{array} \right) &#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&quot;Jacobean&quot; $J$:&#xA;$$&#xA;\left(\begin{array}{ccc}&#xA;1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\&#xA;0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\&#xA;\end{array} \right) $$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Measurement covariance $R$ (just test values):&#xA;$$&#xA;\left(\begin{array}{ccc}&#xA;5 &amp;amp; 0 \\&#xA;0 &amp;amp; 5 \\&#xA;\end{array} \right) $$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Kalman gain $K = PJ^T(JPJ^T + R)^{-1}$:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$&#xA;\left(\begin{array}{ccc}&#xA;0.0199 &amp;amp; -0.0024 \\&#xA;-0.0024 &amp;amp; 0.1043 \\&#xA;-0.0569 &amp;amp; -0.0021 \\&#xA;0 &amp;amp; 0 \\&#xA;0 &amp;amp; 0 \\&#xA;0 &amp;amp; 0 \\&#xA;0.0038 &amp;amp; 0.0000 \\&#xA;0.0042 &amp;amp; -0.1366 \\&#xA;0.0197 &amp;amp; -0.0029 \\&#xA;0 &amp;amp; 0 \\&#xA;0 &amp;amp; 0 \\&#xA;0 &amp;amp; 0 \\&#xA;\end{array} \right) $$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$K$ is 12x2, meaning that my innovation - and therefore both measurement and current state - would need to be 2x1 in order to have a 12x1 result to add to the current full state:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$x' = x + K(z - h(x_s))$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;where $x_s$ is a vector containing only the parts of the full state vector that I am measuring. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here's my question: $K(z - h(x_s))$ yields&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$&#xA;\left(\begin{array}{ccc}&#xA;    0.0272 \\&#xA;    0.1969 \\&#xA;   -0.0948 \\&#xA;         0 \\&#xA;         0 \\&#xA;         0 \\&#xA;    0.0062 \\&#xA;   -0.2561 \\&#xA;    0.0258 \\&#xA;         0 \\&#xA;         0 \\&#xA;         0 \\&#xA;\end{array} \right) $$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Does it make sense that this vector, which I will add to the current state, has non-zero values in positions other that 1 and 2 (the x and y positions of my robot)? The other non-zero locations correspond to the robot's z location, and the x, y, and z velocities. It seems strange to me that a measurement of x and y should yield changes to other variables in the state vector. Am I incorrect in this assumption?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Incidentally, the covariance update works very well with the Jacobean in this form, and maintains its positive-definite property.&lt;/p&gt;&#xA;" OwnerUserId="2176" LastEditorUserId="2176" LastEditDate="2013-11-01T15:40:46.727" LastActivityDate="2013-11-01T17:32:16.437" Title="EKF partial state update question" Tags="&lt;kalman-filter&gt;" AnswerCount="1" />
  <row Id="2010" PostTypeId="2" ParentId="2009" CreationDate="2013-11-01T17:32:16.437" Score="2" Body="&lt;p&gt;According to your covariance matrix it does make sense. The third column of the first row is sigma_xz, and is nonzero, which means, according to your covariance matrix, the random variable z is correlated to the random variable x, and so changes in x will affect z. If you further analyze your covariance matrix, it seems that Z is correlated to Y (element (2,3) of covariance matrix is nonzero) and, of course, itself (element (3,3) of covariance matrix). For the velocities, it certainly makes sense that updates in position will update your velocity because the EKF is simply capturing information regarding changes in state. Again if you look at the covariance matrix, I assume the 7th, 8th and 9th elements of your state vector are the velocity in x, y and z. In the covariance matrix, the elements (1,7), (1,8), and (1,9) are all nonzero so the 3 velocities are correlated to your x position...further analysis shows that they're also correlated to your Y and Z position by similar arguments.&lt;/p&gt;&#xA;" OwnerUserId="1960" LastActivityDate="2013-11-01T17:32:16.437" />
  <row Id="2011" PostTypeId="1" CreationDate="2013-11-01T22:51:49.267" Score="2" ViewCount="126" Body="&lt;p&gt;I am trying to control the &lt;a href=&quot;https://www.sparkfun.com/products/10336&quot; rel=&quot;nofollow&quot;&gt;Rover 5 robot&lt;/a&gt; using an Android app with a touch-based joystick control in the app UI. I want to calculate the speed of the left and right motors in the rover when joystick is moved.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From the joystick, I get two values, pan and tilt. I convert them into the &lt;a href=&quot;http://en.wikipedia.org/wiki/Polar_coordinate_system&quot; rel=&quot;nofollow&quot;&gt;polar coordinate system&lt;/a&gt; with &lt;code&gt;r&lt;/code&gt; and &lt;code&gt;theta&lt;/code&gt;. Where r ranges from 0 to 100 and theta from 0 to 360. I want to derive an equation which can convert the &lt;strong&gt;&lt;code&gt;(r, theta)&lt;/code&gt;&lt;/strong&gt; to &lt;strong&gt;&lt;code&gt;(left_speed, right_speed)&lt;/code&gt;&lt;/strong&gt; for rover. The speed values also are in the [0;100] range.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now, here is what I have figured out till now. For any value of &lt;code&gt;r&lt;/code&gt;, &lt;br&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If &lt;code&gt;theta = 0&lt;/code&gt; then &lt;code&gt;left_speed = r, right_speed = -r&lt;/code&gt; (turning right on spot) &lt;br&gt;&#xA;If &lt;code&gt;theta = 90&lt;/code&gt; then &lt;code&gt;left_speed = r, right_speed = r&lt;/code&gt; (moving forward at speed r) &lt;br&gt;&#xA;If &lt;code&gt;theta = 180&lt;/code&gt; then &lt;code&gt;left_speed = -r, right_speed = r&lt;/code&gt; (turning left on spot) &lt;br&gt;&#xA;If &lt;code&gt;theta = 270&lt;/code&gt; then &lt;code&gt;left_speed = -r, right_speed = -r&lt;/code&gt; (moving backwards at speed r) &lt;br&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For other values, I want it moving and turning simultaneously. For example,&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If &lt;code&gt;theta = 45&lt;/code&gt; then &lt;code&gt;left_speed = alpha*r, right_speed = beta*r&lt;/code&gt; (moving forward while turning right) &lt;br&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, basically for any &lt;code&gt;(r, theta)&lt;/code&gt;, I can set speeds as,&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;(left_speed, right_speed) = (alpha*r, beta*r)&lt;/code&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I need to formulate an equation where I can generalize all these cases by finding &lt;code&gt;alpha&lt;/code&gt; and &lt;code&gt;beta&lt;/code&gt; based on &lt;code&gt;theta&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How can I do this? Is there is any existing work I can refer to?&lt;/p&gt;&#xA;" OwnerUserId="1144" LastEditorUserId="1906" LastEditDate="2014-01-16T00:20:12.743" LastActivityDate="2014-01-16T00:20:12.743" Title="How to calculate the right and left speed for a tank-like rover?" Tags="&lt;control&gt;&lt;kinematics&gt;&lt;movement&gt;" AnswerCount="2" CommentCount="2" />
  <row Id="2012" PostTypeId="2" ParentId="2011" CreationDate="2013-11-02T05:21:34.647" Score="1" Body="&lt;p&gt;What you want is angular velocity proportional to the cosine of the angle, it seems, with positive to the right, and negative to the left.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, since we know that angular velocity is given by $\frac{V_l - V_r}{D}$ where $D$ is the diameter of the robot, we're all set.  Try this:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;if $\theta\ge0$ and $\theta\le90$: $V_l \gets r$ and $V_r \gets r\sin(2\theta-90)$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;if $\theta &amp;lt; 0$ and $\theta\geq-90$: $V_r \gets -r$ and $V_l \gets r\sin(2\theta+90)$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Swap the velocities for the other quadrants. Note, this won't &quot;feel&quot; like driving a car, as moving the stick to the lower-right will turn backwards and rotate right, whereas a car in reverse with the wheel right will move backwards and turn leftward.  Just a weirdness of differential drives...  You can adjust for this by just applying the fourth quadrant rules to the third quadrant $\theta$ and visa-versa.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I used $\theta \in [-180,+180]$, which you can get by:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$\theta \gets \text{atan2}(\sin\theta,\cos\theta)$ (watch your units though, atan2 is usually radians.&lt;/p&gt;&#xA;" OwnerUserId="163" LastActivityDate="2013-11-02T05:21:34.647" CommentCount="1" />
  <row Id="2013" PostTypeId="2" ParentId="1976" CreationDate="2013-11-02T10:15:11.100" Score="0" Body="&lt;p&gt;I've worked with the same sonar in a similar setting, and your only real option (if you can't do anything to the pool itself) is to find an open water testing area. You could also contact BlueView. They're pretty responsive.&lt;/p&gt;&#xA;" OwnerUserId="2176" LastActivityDate="2013-11-02T10:15:11.100" CommentCount="1" />
  <row Id="2014" PostTypeId="2" ParentId="1978" CreationDate="2013-11-02T13:01:09.793" Score="2" Body="&lt;p&gt;You have to calibrate the accelerometer to compensate for this. Usually, calibrating an accelerometer consists of finding a scaling factor and an offset vector. So the calibrated measurement vector Z can be written as:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Z = aX + B, where a is the scaling factor, B the offset vector and X is the 'raw' measurement vector.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you mount the accelerometer on a device, the accelerometer axis system should be aligned with the device body axis system. If this is not the case, for example if the pcb is rotated or upside down, the calibrated measurement Z should be converted to the body axis system using a rotation matrix. You can combine the rotation matrix with the scaling factor a, so you get:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Z = AX + B. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;A is now a 3x3 matrix. Z is the calibrated measurent in the device body axis system.&#xA;The values of the 3x3 matrix A and the 3-element vector B are found by putting the device in a number of known, fixed orientations, so you know Z. By measuring X, you get a set of linear equations that you can solve to find A and B.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Hope this helps.&lt;/p&gt;&#xA;" OwnerUserId="2186" LastActivityDate="2013-11-02T13:01:09.793" />
  <row Id="2015" PostTypeId="2" ParentId="1978" CreationDate="2013-11-02T22:30:28.927" Score="1" Body="&lt;p&gt;This behavior is usually specified in the datasheet. For example, in table 1 of the datasheet of the BMA020 accelerometer you have the entry &quot;Sensitivity&quot;. Probably you are operating your sensor with a 2g range. If your sensor has a temperature of 25°C, according to the datasheet the raw output of your sensor is typically 256 LSB if it is exposed to a acceleration of 1.0 g. As specified in the datasheet, this is only the typical value. Each manufactured sensor is a little bit different and thus the &quot;min&quot; and &quot;max&quot; columns define other possible values, depending on your specific sensor. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In your question you talk about measurements in g units and not in LSB. Thus, the code operating your accelerometer already converts the raw measurements to g units. The conversion algorithm can range from very simple algorithms to very sophisticated algorithms. An ideal conversion algorithm would incorporate all errors your sensor makes due to production variations and due to the current operation conditions. To compensate for the production variations this conversion algorithm should make use of calibration values which you found for your specific accelerometer or which are known from factory calibration (expensive sensors). Additionally, if you look at your datasheet again, you see that the sensitivity of your accelerometer depends on the operation temperature. Thus, if the defined error due to temperature change is too high for your application, you need to add an temperature sensor and your conversion algorithm should use the temperature to correct for this error too. There are also additional error sources defined in the datasheet and the algorithm for converting your raw measurements to g units can get very sophisticated. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thus, the reason why your sensors don't output 1 g is simply that you're using some conversion algorithm to get from the raw sensor readings to g units and this algorithm probably neither uses any calibrated values specific to your sensor nor does it incorporate the current environment conditions. &lt;/p&gt;&#xA;" OwnerUserId="2189" LastActivityDate="2013-11-02T22:30:28.927" />
  <row Id="2016" PostTypeId="2" ParentId="2011" CreationDate="2013-11-02T22:40:56.483" Score="3" Body="&lt;p&gt;You're trying to find a formula to convert a given $(r, \theta)$ to left and right thrust percentages, where $r$ represents your throttle percentage.  The naive implementation is to base your function on 100% throttle:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;At $0 ^{\circ}$, left and right thrust are equal to $r$&lt;/li&gt;&#xA;&lt;li&gt;At $\pm45 ^{\circ}$, one side's thrust equals $r$ and the other side's equals 0&lt;/li&gt;&#xA;&lt;li&gt;At $\pm 90 ^{\circ}$, one side's thrust equals $r$ and the other side's equals $-r$&lt;/li&gt;&#xA;&lt;li&gt;At $180 ^{\circ}$, left and right thrust are equal to $-r$&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;This produces a function like the following:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/ZaZpz.png&quot; alt=&quot;Thrust ratios for 100% throttle&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The problem with this implementation is that &lt;em&gt;you are only providing the desired $r$ when $\theta$ is at an exact multiple of $90 ^{\circ}$&lt;/em&gt;.  At all other points, you sacrifice total speed for control.  You can see this in the graph: &quot;Absolute Thrust&quot;, the amount of thrust being delivered by both motors, is not (and cannot be) constant in this regime.  Simply scaling this function is not optimal.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The maximum absolute thrust that can be sustained over the entire range of $\theta$ occurs when $r=50\%$ -- &lt;strong&gt;this is what your function should be based on&lt;/strong&gt;.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/QSS1W.png&quot; alt=&quot;Thrust ratios for 100% throttle&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In this implementation, total thrust remains constant between $\pm45 ^{\circ}$, and absolute thrust is constant no matter what direction is chosen -- the motors trade off their thrust to maintain the desired $r$.  Above $r=50\%$, the range of angles where your total thrust can satisfy $r$ begins to shrink -- you begin to sacrifice control for speed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This produces a python function like the following:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;# assumes theta in degrees and r = 0 to 100 %&#xA;# returns a tuple of percentages: (left_thrust, right_thrust)&#xA;def throttle_angle_to_thrust(r, theta):&#xA;    theta = ((theta + 180) % 360) - 180  # normalize value to [-180, 180)&#xA;    r = min(max(0, r), 100)              # normalize value to [0, 100]&#xA;    v_a = r * (45 - theta % 90) / 45          # falloff of main motor&#xA;    v_b = min(100, 2 * r + v_a, 2 * r - v_a)  # compensation of other motor&#xA;    if theta &amp;lt; -90: return -v_b, -v_a&#xA;    if theta &amp;lt; 0:   return -v_a, v_b&#xA;    if theta &amp;lt; 90:  return v_b, v_a&#xA;    return v_a, -v_b&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;The result is the following:&#xA;&lt;img src=&quot;http://i.stack.imgur.com/w7yVQ.gif&quot; alt=&quot;animated right/left function&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-11-04T21:57:54.870" LastActivityDate="2013-11-04T21:57:54.870" CommentCount="4" />
  <row Id="2017" PostTypeId="2" ParentId="1935" CreationDate="2013-11-03T14:04:53.690" Score="0" Body="&lt;p&gt;If you want to be cheap....you could go to a junk yard and grab a linear actuator used for opening and closing car door windows.  &lt;/p&gt;&#xA;" OwnerUserId="2190" LastActivityDate="2013-11-03T14:04:53.690" CommentCount="1" />
  <row Id="2018" PostTypeId="1" CreationDate="2013-11-04T10:42:55.843" Score="0" ViewCount="135" Body="&lt;p&gt;I am new in robotics. May be this question looks like too naive but i want to know which is a better board among Arduino Uno R3 or Roboduino ATMega168 or Arduino Mega 2560 R3 for my purpose mention below - &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;A simple robot with wheels, can move around.&lt;/li&gt;&#xA;&lt;li&gt;Can have IR sensors and camera.&lt;/li&gt;&#xA;&lt;li&gt;Is powerful enough to deal with computer vision computations.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Arduino Mega 2560 R3 looks more powerful than the other too, I just want to know if my purpose can be solved with other two boards too?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks&lt;/p&gt;&#xA;" OwnerUserId="2191" LastActivityDate="2013-11-20T11:15:47.787" Title="Arduino Uno R3 or Roboduino ATMega168 or Arduino Mega 2560 R3 which board is better for small robots" Tags="&lt;arduino&gt;" AnswerCount="3" CommentCount="1" ClosedDate="2013-12-08T21:20:54.097" />
  <row Id="2019" PostTypeId="2" ParentId="2018" CreationDate="2013-11-04T13:37:34.000" Score="1" Body="&lt;p&gt;The Mega is a great board, I use it for my robot. If your robot is small and space is limited, the size of the Mega could be an issue...&#xA;Hopefully, SeeedStudio has made and Seeeduino Mega which is almost the size of an Arduino UNO.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For computer vision though, I'm not sure the Mega will be powerfull enough. And if it is, it won't be able to do anything else during the computation (because of the way the Arduino works).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So maybe you should take a look at the Raspberry Pi. It has great camera modules you can use and is powerful enough for some computation. There are shields avalaible to connect and easily use Arduino shields for your motors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Hope it helps! :)&lt;/p&gt;&#xA;" OwnerUserId="2031" LastActivityDate="2013-11-04T13:37:34.000" CommentCount="3" />
  <row Id="2020" PostTypeId="2" ParentId="2018" CreationDate="2013-11-04T13:40:58.257" Score="2" Body="&lt;p&gt;I'm not sure you can achieve computer vision on any of those chips. &#xA;Way to go is to stream video to distributed PC, make calculations, stream commands to arduino. That could probably work, but there is also a question of how much frames you could grab from camera with Arduino.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Raspberry Pi would give you around 9fps in OpenCV while recognizing faces. Maybe you could achieve around 15-20 top if you just need movement detection...&lt;/p&gt;&#xA;" OwnerUserId="973" LastActivityDate="2013-11-04T13:40:58.257" CommentCount="2" />
  <row Id="2021" PostTypeId="1" AcceptedAnswerId="2051" CreationDate="2013-11-05T07:12:11.477" Score="2" ViewCount="206" Body="&lt;p&gt;I'm using the telemetry kit from &lt;a href=&quot;http://store.3drobotics.com/products/3dr-radio&quot; rel=&quot;nofollow&quot;&gt;3DR robotics&lt;/a&gt; (433MHz) to interface with Ardupilot Mega 2.6, controlling a quadcopter. The &lt;a href=&quot;http://planner.ardupilot.com/&quot; rel=&quot;nofollow&quot;&gt;Mission Planner&lt;/a&gt; (v1.2.84) by Michael Oborne works well with the telemetry kit, transmitting flight data (IMU, compass, GPS etc.) from the quadcopter to the GCS and displaying them in their GUI.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, I would like to see the same data in the hyperterminal (windows system). The radio receiver on the GCS connects to my PC through a USB drive. I have tried calling the remote radio station using all possible Baud rates, starting from 110 to 921600 (including 57600). I've set the &lt;strong&gt;data bits to 8&lt;/strong&gt; and &lt;strong&gt;stop bits to 1&lt;/strong&gt;. &lt;strong&gt;'None'&lt;/strong&gt; for &lt;strong&gt;parity&lt;/strong&gt; and &lt;strong&gt;flow control&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, all that I ever get on my terminal is either gibberish or no data at all. I also tried burning this &lt;a href=&quot;http://vps.oborne.me/3drradioconfig.zip&quot; rel=&quot;nofollow&quot;&gt;software&lt;/a&gt; to the radio receiver and tried using AT commands on the radio. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;It connects OK with '+++', but keeps returning error for AT1, ATT etc.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Please give me an idea about how to get flight data at the hyperterminal.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks.&lt;/p&gt;&#xA;" OwnerUserId="1949" LastActivityDate="2013-11-11T15:54:36.020" Title="Telemetry with Ardupilot 2.6" Tags="&lt;quadcopter&gt;&lt;ardupilot&gt;" AnswerCount="2" CommentCount="5" />
  <row Id="2022" PostTypeId="1" AcceptedAnswerId="2023" CreationDate="2013-11-05T11:10:07.917" Score="3" ViewCount="59" Body="&lt;p&gt;This is my first question on this site, might be a little subjective :)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is an ongoing process of many cool cyclonic changes of technology in the electronics and software industry.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Concurrency and Parallelism&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What will be the implications of GPGPU, Multi-core  and &quot;programming in the large&quot; model in the specific case of embedded software, and how will it influence the styles and conventions in the community?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Single board multicore hardware like soon to be released Parallela can be an example?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Programming language research&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The results have been excellent. Functional Programming has supposedly started reaching the masses. It was late night previous weekend when I briefly skimmed through an example of functional reactive programming to solve real time problems. AI people are also suggesting that we should be programming our robots in Declarative Domain Specific languages soon. It would be nice to know the implications on the robotics community. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;There has been a tremendous growth of frameworks like ROS and Urbi too!! That should be the region to look upon.. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Most of the robotics, embedded and high performance AI codebase directly depends on C/C++ , and though languages like Rust and D are bubbling up, wouldn't it take massive amount of time to adopt the new languages, if ever adaptation begins? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Correct me, but it seems like a lot of time has passed and there are not many major production results from the AI community. I've heard about cognitive architectures of old like ACT-R and 4CAPS. They seem to be in hibernation mode! &lt;/p&gt;&#xA;&#xA;&lt;p&gt;There seems to be a lot of work lately on otherwise intelligent systems (solved problems) like Computer vision and Data mining, but these problems cater to supercomputing and industrial crowd more. Could there be any possible shift towards low powered systems soon?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks&lt;/p&gt;&#xA;" OwnerUserId="2196" LastActivityDate="2013-11-05T13:28:38.440" Title="How will the currently evaluated computer technology influence robotics and embedded systems in the forseeable future?" Tags="&lt;software&gt;&lt;artificial-intelligence&gt;&lt;programming-languages&gt;&lt;beginner&gt;&lt;embedded-systems&gt;" AnswerCount="1" CommentCount="1" FavoriteCount="1" ClosedDate="2013-11-05T22:44:21.890" />
  <row Id="2023" PostTypeId="2" ParentId="2022" CreationDate="2013-11-05T11:50:32.130" Score="1" Body="&lt;p&gt;There's a lot of advancement on the software side, but there are many reasons why we don't currently see them on robots.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;First, notice that there are a huge variety of robots already built or possibly built in the future. So let's look at a couple of them:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Manipulators: A manipulator is just an arm. You define a task for it, it does it. It's dumb, it's big and it's plugged in the wall at some factory. Do you really need AI or parallel processing for a manipulator? Does the programming language even matter? Probably not.&lt;/li&gt;&#xA;&lt;li&gt;Small mobile robots: a variety of robots are small, or could be small. The biggest issue on those robots is power. To process heavily, you need more power. To provide more power, you need bigger batteries. To carry bigger batteries you need stronger motors. Stronger motors are big and need a bigger support. In short, small robots have to be really energy efficient, that's why they also can't be processing too much. GPGPU's and complicated AI is usually off limits for those robots.&lt;/li&gt;&#xA;&lt;li&gt;Humanoids: This is probably what you have been thinking when you asked the question. So let's continue this answer assuming you are talking about humanoids, or more generally big mobile robots.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;What will be the implications of GPGPU, Multi-core and &quot;programming in the large&quot; model in the specific case of embedded software,&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;It would be great! Besides the fact that you need proper hardware (actual computers vs. microcontrollers), it would be great. I believe this would specifically be helpful on areas where there is need for processing of huge input data, such as vision or tactile input.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;and how will it influence the styles and conventions in the community?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Probably not much. Software is done in modules. Someone writes an odometry module and you use it. If they change the odometry implementation underneath, you won't notice it (much). Using GPGPUs is low-level enough to be part of lower level libraries, and often the actual users (programmers) of the robot would be unaware of it. Multi-core processing is all too easy and I think it's already widely used (you just make threads!)&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Functional Programming has supposedly started reaching the masses. It was late night previous weekend when I briefly skimmed through an example of functional reactive programming to solve real time problems. AI people are also suggesting that we should be programming our robots in Declarative Domain Specific languages soon. It would be nice to know the implications on the robotics community.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Basically all non-joke (and even some joke) programming languages we have are turing-complete. This means that they can all get the job done. So choosing a language is really just a matter of convenience. Currently, C is the ubiqutous languange for every architecture. Everything can link to C and C is compiled on the remotest microcontroller on this planet. I don't think C could be put aside.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For higher level programming, I don't see any reason why any language couldn't be used. If the robot is controlled by a computer (vs. a microcontroller), it can probably run anything compiled or interpreted in any language.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Regarding real-time, probably you are misusing the word. If you are actually referring to an actual &lt;a href=&quot;https://en.wikipedia.org/wiki/Real-time_computing&quot; rel=&quot;nofollow&quot;&gt;real-time system&lt;/a&gt;, then probably the biggest obstacles are the tools. Believe it or not, there are not many good ones. I program in real-time and trust me, there's something wrong with each of them. Still, you'd probably be forced to write in C or C++ if you want to use any of those tools.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;There has been a tremendous growth of frameworks like ROS and Urbi too!! That should be the region to look upon.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;I don't know Urbi, but I know ROS. ROS is quite famous, and everything you make, people immediately request a ROS module. It's nice, it works, but it's not perfect. Biggest flaw is that it can't be real-time, but they can't really be blamed. What I mean is, it's not a region to look upon, it's a region where people are already at.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Most of the robotics, embedded and high performance AI codebase directly depends on C/C++, and though languages like Rust and D are bubbling up, wouldn't it take massive amount of time to adopt the new languages, if ever adaptation begins?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;It sure will. As for embedded systems, I doubt it would ever change away from C, definitely not to a functional language. C is quite low-level yet very high-level. It's at the exact sweet spot for embedded programming. You can be portable yet have access to all hardware.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Embedded programming is in direct violation of most of what's important in a functional language. The fact that you are working with hardware means that the functions can't be pure (in Haskell, they would be IO). So what would be the benefit of functional programming if most functions are not-pure and their results can't be cached? Besides, it's not even practical to load a whole interpreter of a functional language in a tiny microcontroller and hope to be able to use all sorts of dynamic caching during runtime to compensate for lack of non-functional language structures.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In short for microcontrollers, functional languages simply aren't fit. For &quot;high performance AI codebases&quot;, there is again no reason why they can't be used. It's just that people have to pick up one of those languages and start using it. Biggest problem is though that People are lazy and don't like change.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Correct me, but it seems like a lot of time has passed and there are not many major production results from the AI community. I've heard about cognitive architectures of old like ACT-R and 4CAPS. They seem to be in hibernation mode!&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;They are not in hibernation mode. The nature of the research has changed. Take a look at &lt;a href=&quot;https://en.wikipedia.org/wiki/Artifical_intelligence#History&quot; rel=&quot;nofollow&quot;&gt;a very brief history of AI on Wikipedia&lt;/a&gt;. Whereas in the 80s you would see for example a lot of algorithms developed on solving NP-complete problems, now you see artifical intelligence for example in Kinect that you usually don't think of as &quot;intelligent&quot;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is also a lot of way more complicated research going on such as cognitive science and others. My personal feeling is that they are still maturing and not yet at a stage that could be widely used. Either that, or I have just been ignorant about it myself.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;There seems to be a lot of work lately on otherwise intelligent systems (solved problems) like Computer vision and Data mining, but these problems cater to supercomputing and industrial crowd more. Could there be any possible shift towards low powered systems soon?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Could there? Yes. Would there? Probably not. Like I said before, heavy processing requires power and power is very precious on a (mobile) robot. There would however definitely be a middle-ground used in robotics. Perhaps not a super complete AI, but a dumbed down, simpler one (but still more intelligent than current) would be placed on robots.&lt;/p&gt;&#xA;" OwnerUserId="158" LastEditorUserId="158" LastEditDate="2013-11-05T13:28:38.440" LastActivityDate="2013-11-05T13:28:38.440" />
  <row Id="2024" PostTypeId="1" AcceptedAnswerId="2026" CreationDate="2013-11-06T00:19:13.383" Score="1" ViewCount="69" Body="&lt;p&gt;I have an old beat-up netbook that is currently collecting dust. I've also only taken stuff apart, without having to worry about putting it back together, so please bear with my possibly stupid questions. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;a) I imagine it's possible to wire this baby up to servos, breadboards, and all that good stuff. Am I correct? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;b) I'd like to start with some simple Raspberry Pi-like projects (think automating my irrigation system, feeding the dog from work, etc). Obviously barring the energy expenditure, wouldn't a netbook be more apt than a Raspberry Pi for handling this type of thing?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;c) I have basic Python experience, but I wouldn't mind picking up more as I go. Would that be sufficient?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cheers!&lt;/p&gt;&#xA;" OwnerUserId="2198" LastActivityDate="2013-11-06T09:31:32.717" Title="Roboticize an old netbook?" Tags="&lt;raspberry-pi&gt;&lt;python&gt;" AnswerCount="1" CommentCount="1" ClosedDate="2013-11-09T06:34:20.903" />
  <row Id="2025" PostTypeId="1" CreationDate="2013-11-06T08:06:02.100" Score="0" ViewCount="24" Body="&lt;p&gt;I am trying to use GPRS functionality of the GSM/GPRS modem for sending data to the remote server but i am unable to do so.I had posted a question on Arduino Forum but didn't get any reply.&lt;a href=&quot;http://forum.arduino.cc/index.php?topic=196441.msg1449676#msg1449676&quot; rel=&quot;nofollow&quot;&gt;Here is the link for the question&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Well my Main concern is &#xA;i) I am using a GPRS/GSM Modem and i am not sure about the Power requirements of the Modem.At present i am using a 9V and 1 amp supply but the network LED on the modem is dignifying that Modem is not getting the network. So can this be because of the insufficient supply to the modem?&lt;/p&gt;&#xA;" OwnerUserId="1322" LastActivityDate="2013-11-06T08:06:02.100" Title="Using GPRS and GSM Simulatneously" Tags="&lt;arduino&gt;&lt;communication&gt;" />
  <row Id="2026" PostTypeId="2" ParentId="2024" CreationDate="2013-11-06T09:31:32.717" Score="0" Body="&lt;p&gt;Of course this can be done, however the important bit isn't really the netbook here. The important bit is the type of interface you decide to use and the command language you code in to control that interface.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Your netbook probably has USB and possibly serial - but you need to have a way to connect these to relays and voltage control devices.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;X10 or NexTag produce a range of USB compatible interfaces, and provide a controller language. They provide a very simple, beginner's route to home automation and control.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For more fun, you could build your own serial interface board - which converts the signals from the 9 serial pins to useful output, but this is more of an electronics project - not for the faint hearted :-)&lt;/p&gt;&#xA;" OwnerUserId="67" LastActivityDate="2013-11-06T09:31:32.717" CommentCount="2" />
  <row Id="2027" PostTypeId="1" CreationDate="2013-11-06T10:05:13.153" Score="0" ViewCount="76" Body="&lt;p&gt;I'm reading &lt;a href=&quot;http://wiki.ros.org/amcl&quot; rel=&quot;nofollow&quot;&gt;amcl&lt;/a&gt; document on ROS Wiki. In its subscribed topics there is not odometry topic, why? It works only with laser?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Subscribed Topics:&lt;/strong&gt; (From ROS Wiki)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;scan (sensor_msgs/LaserScan)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;tf (tf/tfMessage)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;initialpose (geometry_msgs/PoseWithCovarianceStamped)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;map (nav_msgs/OccupancyGrid)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And my next question is how can I use &lt;code&gt;amcl&lt;/code&gt; in &lt;code&gt;Gazebo&lt;/code&gt; simulator for turtlebot? Any tutorial available?&lt;/p&gt;&#xA;" OwnerUserId="2202" LastActivityDate="2013-11-21T08:26:32.620" Title="ROS AMCL does not need odometry data?" Tags="&lt;slam&gt;&lt;ros&gt;&lt;navigation&gt;" AnswerCount="1" />
  <row Id="2028" PostTypeId="1" AcceptedAnswerId="2035" CreationDate="2013-11-06T12:28:56.787" Score="1" ViewCount="241" Body="&lt;p&gt;I've got a code where I have a motor running back and forth and buttons connected to a scanner, when I press the buttons it causes the motor to stop  and over rides it. I would like them to run parallel to each other so the codes don't interrupt each other.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here is my code&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#include &amp;lt;AccelStepper.h&amp;gt;&#xA;&#xA;// Define some steppers and the pins they will use&#xA;&#xA;AccelStepper stepper1(AccelStepper::FULL2WIRE, 2, 3);&#xA;&#xA;const int buttonPin = 4;&#xA;const int button2Pin = 14;&#xA;const int pulseopto1 = 9;&#xA;const int startScan = 11;&#xA;&#xA;int buttonState = 0;&#xA;long previousMillis = 0;&#xA;long interval = 5;&#xA;&#xA;void setup()&#xA;{&#xA;    pinMode(buttonPin, INPUT);&#xA;    pinMode(button2Pin, INPUT);&#xA;    pinMode(pulseopto1, OUTPUT);&#xA;    pinMode(startScan, OUTPUT); &#xA;    stepper1.setMaxSpeed(40000.0);&#xA;    stepper1.setAcceleration(100000.0);&#xA;    stepper1.moveTo(25000);&#xA;}&#xA;&#xA;void loop()&#xA;{&#xA;    buttonState = digitalRead(buttonPin);&#xA;&#xA;    if (buttonState == LOW)&#xA;    {&#xA;        digitalWrite(startScan, HIGH);&#xA;    }&#xA;    else (buttonState == HIGH);&#xA;    {&#xA;        digitalWrite(startScan, LOW);&#xA;    }&#xA;&#xA;    {&#xA;        buttonState = digitalRead(button2Pin);&#xA;&#xA;        if (buttonState == LOW)&#xA;        {&#xA;            // turn LED on:&#xA;            digitalWrite(pulseopto1, HIGH);&#xA;            delay(5);&#xA;            digitalWrite(pulseopto1, LOW);&#xA;            delay(5);&#xA;        }&#xA;        else&#xA;        {&#xA;            // turn LED off:&#xA;            digitalWrite(pulseopto1, LOW);&#xA;        }&#xA;    }&#xA;&#xA;    // Change direction at the limits&#xA;    if (stepper1.distanceToGo() == 0)&#xA;    {&#xA;        stepper1.moveTo(-stepper1.currentPosition());&#xA;    }&#xA;&#xA;    stepper1.run();&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="2091" LastEditorUserId="142" LastEditDate="2013-11-06T14:16:24.163" LastActivityDate="2013-11-08T23:28:35.303" Title="Is it possible to run multiple loops at the same time? (Arduino)" Tags="&lt;arduino&gt;&lt;stepper-motor&gt;&lt;c&gt;" AnswerCount="4" CommentCount="4" />
  <row Id="2029" PostTypeId="2" ParentId="2028" CreationDate="2013-11-06T14:06:45.303" Score="0" Body="&lt;p&gt;What do you mean by override? Does the motor stop or does it start turning in the wrong direction?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is something weird going on with the brackets in the loop() function&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;if (buttonState == LOW)&#xA;{&#xA;    digitalWrite(startScan, HIGH);&#xA;}&#xA;else (buttonState == HIGH);  //This shouldn't be here. Just use else&#xA;{&#xA;    digitalWrite(startScan, LOW); &#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I'm not sure, but I don't think you need to call stepper1.run() in the loop function. Try placing it at the end of the setup() function instead.&lt;/p&gt;&#xA;" OwnerUserId="2206" LastActivityDate="2013-11-06T14:06:45.303" CommentCount="1" />
  <row Id="2030" PostTypeId="2" ParentId="2028" CreationDate="2013-11-06T19:07:25.987" Score="2" Body="&lt;p&gt;I think you should look into the Arduino's attachInterrupt function. You would connect the buttons to a specific interrupt pin on the Arduino and then write a small simple interrupt handler that would be called when that interrupt fires. You can configure the interrupt to fire while low, on a rising edge, on a falling edge, or on a change of the interrupt pin. This way you don't have to poll your buttons, and it will make your main loop cleaner/easier to write.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here's the arduino webpage for attachInterrupt(): &lt;a href=&quot;http://arduino.cc/en/Reference/attachInterrupt&quot; rel=&quot;nofollow&quot;&gt;http://arduino.cc/en/Reference/attachInterrupt&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;edit: You should also comment your code so we know what you are trying to do, and possibly give us a description of your hardware setup (what are pins of Arduino actually connected to).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Given the syntax error that TheRussian pointed out, I don't understand how this code compiles.&lt;/p&gt;&#xA;" OwnerUserId="1960" LastEditorUserId="1960" LastEditDate="2013-11-06T19:13:38.213" LastActivityDate="2013-11-06T19:13:38.213" />
  <row Id="2031" PostTypeId="1" AcceptedAnswerId="2033" CreationDate="2013-11-07T06:17:38.840" Score="3" ViewCount="85" Body="&lt;p&gt;In &lt;strong&gt;ROS&lt;/strong&gt; I've recorded a bag file from a custom robot (in real world) that does not provide covariance matrix and I want to use &lt;code&gt;/odom&lt;/code&gt; to feed an &lt;strong&gt;EKF&lt;/strong&gt;, but covariance matrix is 0. How can I calculate it?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:&#xA;Covariance matrix is needed by EKF to estimate position.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It's a sample of &lt;code&gt;/odom&lt;/code&gt;:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;pose: &#xA;  pose: &#xA;    position: &#xA;      x: 0.082&#xA;      y: 0.507&#xA;      z: 0.0&#xA;    orientation: &#xA;      x: 0.0&#xA;      y: 0.0&#xA;      z: -0.789272088731&#xA;      w: 0.614043622188&#xA;  covariance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]&#xA;twist: &#xA;  twist: &#xA;    linear: &#xA;      x: 0.104&#xA;      y: 0.0&#xA;      z: 0.0&#xA;    angular: &#xA;      x: 0.0&#xA;      y: 0.0&#xA;      z: 0.0663225115758&#xA;  covariance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="2202" LastActivityDate="2013-11-07T13:33:51.217" Title="Calculate covariance matrix from x,y,z data" Tags="&lt;localization&gt;&lt;ros&gt;&lt;odometry&gt;" AnswerCount="1" FavoriteCount="1" />
  <row Id="2032" PostTypeId="1" CreationDate="2013-11-07T10:57:25.743" Score="1" ViewCount="48" Body="&lt;p&gt;from the designs usually shown in the rocker bogie systems, the whole weight of platform seems to be supported by one rod only, be it differential bar or gear. so isn't it a bit unstable system because if we have arms of rover at one end we will have a high torque about that rod. can anybody suggest a better design without sacrificing the functionality of rover?? &lt;/p&gt;&#xA;" OwnerUserId="2212" LastActivityDate="2013-11-07T10:57:25.743" Title="Rocker bogie suspension" Tags="&lt;mobile-robot&gt;&lt;design&gt;&lt;wheeled-robot&gt;" CommentCount="2" />
  <row Id="2033" PostTypeId="2" ParentId="2031" CreationDate="2013-11-07T13:33:51.217" Score="2" Body="&lt;p&gt;Well, you &lt;em&gt;can't&lt;/em&gt; estimate the covariance from the state.  You need the equations used to &lt;em&gt;find&lt;/em&gt; the state.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is because the covariance (along with the markov assumption) represents &lt;em&gt;how&lt;/em&gt; the robot got to the state.   A robot at location (10,5,1) does not always have the same covariance matrix, right? You need to know what actions brought it to that state.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Barring any ros-based solution (are you sure the SLAM / EKF nodes can't do this for you?) you'll have to do this:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Find the kinematics model for the robot (differential drive, ackerman, whatever)&lt;/li&gt;&#xA;&lt;li&gt;Read in the odometery and control command, and use the kinematics equations and control inputs as the &lt;em&gt;u&lt;/em&gt; and &lt;em&gt;f()&lt;/em&gt; for the EKF (using &lt;a href=&quot;https://en.wikipedia.org/wiki/Extended_Kalman_filter#Discrete-time_predict_and_update_equations&quot; rel=&quot;nofollow&quot;&gt;this&lt;/a&gt;) as a reference.&lt;/li&gt;&#xA;&lt;li&gt;Find the Jacobian of the kinematics equations with respect to each state element&lt;/li&gt;&#xA;&lt;li&gt;Feed the Jacobian and control / odometery into the EKF as the &lt;em&gt;F&lt;/em&gt; term (using &lt;a href=&quot;https://en.wikipedia.org/wiki/Extended_Kalman_filter#Discrete-time_predict_and_update_equations&quot; rel=&quot;nofollow&quot;&gt;this&lt;/a&gt;) as a reference.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;In case you are wondering, yes this effectively reproduces the work done by the /odom node, since the output of the kinematics equations is precisely what /odom reports. &lt;/p&gt;&#xA;" OwnerUserId="163" LastActivityDate="2013-11-07T13:33:51.217" />
  <row Id="2034" PostTypeId="1" CreationDate="2013-11-08T04:32:55.670" Score="1" ViewCount="89" Body="&lt;p&gt;It would be incredibly useful if I could print my own gearing solutions, &lt;em&gt;even if I have to print the gears one at a time.&lt;/em&gt;  However, I do not know how the market's cheapest printers will accommodate this task.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;--The gears need be 2-3 inches in diameter, and they will bear only a very light load (much less than 1 foot pound), so the material need not be strong or machinable. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;--The tolerances need only be sufficient for the teeth to mate robustly, preventing any hang.  &lt;em&gt;Unfortunately, I do not have a sense of what tolerances will allow gears to mate properly.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;--(If the machine is precise enough to print a hole to statically mate with a shaft of a specified dimensions due to friction, excellent.  If not, I can probably improvise a tiny shaft hole with adhesive.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;--Because this may be used in close proximity to pavement, a melting temperature in excess of 100F is desirable but not required.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;--Because any given element will interact kinetically only with other elements that have also been 3D printed (except a metallic shaft), compatibility with external resources is not required.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would be grateful to anyone who could shed some light on this issue!&lt;/p&gt;&#xA;" OwnerUserId="1032" LastEditorUserId="158" LastEditDate="2013-12-26T01:10:46.913" LastActivityDate="2013-12-26T01:10:46.913" Title="Cheapest 3D printer for gears?" Tags="&lt;wheeled-robot&gt;" AnswerCount="1" CommentCount="2" FavoriteCount="1" />
  <row Id="2035" PostTypeId="2" ParentId="2028" CreationDate="2013-11-08T06:51:12.317" Score="0" Body="&lt;p&gt;The short answer is yes, but the long answer is that you're approaching the code the wrong way and will need to rewrite things a bit.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It looks like you're attempting to read a button and have it flash some LEDs while at the same time having your stepper move back and forth.  The problem is your &lt;code&gt;delay(5);&lt;/code&gt; commands, which pause the execution of your code.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Instead, you'll have to make use of the &lt;code&gt;millis();&lt;/code&gt; function to read the current time at each iteration through the loop.  Both the stepper movement and the LED flashes are functions of time, so just write those functions and set them on every iteration.&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;long stepperPosition(long t)&#xA;{&#xA;    // YOUR CODE GOES HERE, like a sine or triangular waveform&#xA;    // it might also depend on stepper1.distanceToGo() == 0&#xA;    return sine(t * TIME_SCALE_FACTOR) * MAGNITUDE;&#xA;}&#xA;&#xA;bool ledState(long t)&#xA;{&#xA;    // return HIGH if we're in the first &quot;interval&quot; millis after pressing&#xA;    // after that, return LOW to turn off the LED&#xA;    if (t &amp;lt; buttonPressTime + interval)&#xA;        return HIGH;&#xA;    else&#xA;        return LOW;&#xA;}&#xA;&#xA;void loop()&#xA;{&#xA;    long now = millis();&#xA;&#xA;    // set the LED directly from the button state&#xA;    digitalWrite(startScan, LOW == digitalRead(buttonPin));&#xA;&#xA;    // record the time of the button press for use in our function&#xA;    if (digitalRead(button2Pin) == LOW)&#xA;        buttonPressTime = now;&#xA;&#xA;    // set LED based on time function&#xA;    digitalWrite(pulseopto1, ledState(now));&#xA;&#xA;    // set stepper based on time function&#xA;    stepper1.moveTo(stepperPosition(now));&#xA;    stepper1.run();&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;In this code, both the LED and stepper are controlled &quot;in parallel&quot; -- they are both set during each iteration, with no conditional delays.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-11-08T06:51:12.317" />
  <row Id="2036" PostTypeId="1" AcceptedAnswerId="2040" CreationDate="2013-11-08T17:49:30.283" Score="1" ViewCount="92" Body="&lt;p&gt;I'm dealing with a board that no matter what I do I can't seem to make CAN work over 125&amp;nbsp;kbit/s. I'll give some detail about the board on the bottom, but I'm going to keep this question generic.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;First of all, regarding hardware. From what I've gathered, there isn't any need for a &lt;a href=&quot;https://en.wikipedia.org/wiki/Pull-up_resistor&quot; rel=&quot;nofollow&quot;&gt;pull-up resistor&lt;/a&gt; on the TX of CAN. Is that correct? It may perhaps be chip-specific, but wherever I see, it seems that the TX/RX lines are directly connected to the transceiver.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Second, regarding bit-timing: Using different calculators, for example, &lt;a href=&quot;http://www.kvaser.com/en/support/bit-timing-calculator.html&quot; rel=&quot;nofollow&quot;&gt;Kvaser&lt;/a&gt; or &lt;a href=&quot;http://www.intrepidcs.com/support/mbtime.htm&quot; rel=&quot;nofollow&quot;&gt;the one from Microchip&lt;/a&gt;, I can see the following configuration (for 64&amp;nbsp;kHz input clock):&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;             SYNC     PROP     PHASE1      PHASE2       BRP (prescaler)&#xA;&#xA;125  kbit/s   1        1        3           3            32&#xA;250  kbit/s   1        1        3           3            16&#xA;500  kbit/s   1        1        3           3             8&#xA;1000 kbit/s   1        1        3           3             4&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I've seen this from more than one source. Furthermore, the numbers fit to the formula in the datasheet of the microcontroller.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, only the configuration for 125&amp;nbsp;kbit/s works for me. I'm using &lt;a href=&quot;http://www.esd-electronics-usa.com/esd-electronics-usa/canreal.htm&quot; rel=&quot;nofollow&quot;&gt;CANreal&lt;/a&gt; to monitor the messages.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've tried different configurations for the CAN, for example with 16 time quanta instead of 8 as well as changing my microcontroller's clock to 16&amp;nbsp;MHz and using again different values. Regardless of all that, speeds higher than 125&amp;nbsp;kbit/s result in only errors and warnings in CANreal (which are taken from the CAN driver). Note that the same CAN board, driver and software works with 1&amp;nbsp;Mbit/s with some other hardware I have.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This all is made harder since, as soon as I put a probe from my oscillator on the TX line, it becomes a continuous 0-1 alteration like the following:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;      __------     __------     __------     __------     __------&#xA;     /       |    /       |    /       |    /       |    /       |&#xA;   /         |  /         |  /         |  /         |  /         |&#xA;  /          | /          | /          | /          | /          |&#xA;  |          | |          | |          | |          | |          |&#xA;  |          |_|          |_|          |_|          |_|          |&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Which is not something I would be outputting by software. In fact, as soon as I remove the probe, the messages start arriving (again, only at 125&amp;nbsp;Mbit/s). So basically, I don't seem to be able to have any oscillator debugging available.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Back to my &quot;first of all, regarding hardware&quot;, the shape of the signal suggests a pull-up resistor may be necessary, but I haven't seen the need for that in any datasheet I found. Furthermore, my microcontroller configures the pin when used as CAN, so I don't have control over making it push-pull (since it looks like it's &lt;a href=&quot;http://en.wikipedia.org/wiki/Open_collector#MOSFET&quot; rel=&quot;nofollow&quot;&gt;open-drain&lt;/a&gt;). Not to mention the microcontroller doesn't even have a configuration to make the pin push-pull.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there any hidden parameter somewhere that should also be set? Is a pull-up resistor necessary after all? Why would the oscillator probe cause such a behavior?&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Details from the board:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Microcontroller&quot; rel=&quot;nofollow&quot;&gt;MCU&lt;/a&gt;: P18F45K80. CAN is connected to its default RB2 and RB3.&lt;/li&gt;&#xA;&lt;li&gt;CAN transceiver: ISO1050  &lt;/li&gt;&#xA;&lt;li&gt;Compiler: &lt;a href=&quot;https://en.wikipedia.org/wiki/Mikroelektronika#Products&quot; rel=&quot;nofollow&quot;&gt;mikroC&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="158" LastEditorUserId="1906" LastEditDate="2013-11-22T17:12:59.630" LastActivityDate="2013-11-22T17:12:59.630" Title="Making high CAN baud rates work" Tags="&lt;microcontroller&gt;&lt;can&gt;" AnswerCount="1" CommentCount="11" FavoriteCount="2" />
  <row Id="2037" PostTypeId="2" ParentId="2034" CreationDate="2013-11-08T21:45:36.720" Score="1" Body="&lt;p&gt;I run a rep-rap (Mendel Max) 3d printer ~ $1500AUD (built from scratch). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I can't really comment on the print quality of other printers, but my statements about materials will hold for other printers.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have printed usable gears down to about 1/2 inch diameter.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;PLA has a melting point of about 150 Celsius and starts softening at about 60 Celsius, you could also print in ABS which has a slightly higher melting point but it gives of more toxic gases when heated for printing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;PLA is surprisingly strong, I've stood on a 40mm cube with out it breaking. I recently glued some PLA to a piece of MDF, when separating the materials the MDF broke - NOT the PLA.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are various gear libraries on thingy-verse which make it easy to create meshing gears of the desired size.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Realistically if you build a 3d printer your self as I did, it will be months before you are printing usable gears.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can quite reliably print the hole in the center of the gear to take a shaft, as well as printing bearing mounts.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is a serious learning curve if you build your own 3d printer, that's not a bad thing - just be prepared for it!&lt;/p&gt;&#xA;" OwnerUserId="1819" LastActivityDate="2013-11-08T21:45:36.720" CommentCount="2" />
  <row Id="2038" PostTypeId="2" ParentId="2028" CreationDate="2013-11-08T23:28:35.303" Score="1" Body="&lt;p&gt;It looks like the reason (one of) why the motor stops is due to the following code:-&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;if (buttonState == LOW)&#xA;    {&#xA;        digitalWrite(startScan, HIGH);&#xA;    }&#xA;    else (buttonState == HIGH); --&amp;gt; this is a statement due to the semicolon.&#xA;    {&#xA;        digitalWrite(startScan, LOW); --&amp;gt; this statement will get executed even when buttonState is LOW.&#xA;    }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;CHange this to the following and check.&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;if (buttonState == LOW)&#xA;    {&#xA;        digitalWrite(startScan, HIGH);&#xA;    }&#xA;    else if (buttonState == HIGH)&#xA;    {&#xA;        digitalWrite(startScan, LOW);&#xA;    }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Try splitting the 2 activities using a task scheduler.&#xA;My $0.02.&lt;/p&gt;&#xA;" OwnerUserId="2215" LastActivityDate="2013-11-08T23:28:35.303" />
  <row Id="2039" PostTypeId="1" CreationDate="2013-11-09T12:46:33.837" Score="1" ViewCount="57" Body="&lt;p&gt;i want to model the quadrotor using experimental method &quot;i have not built it yet&quot; what i want to do is: turn only one motor at a specific speed ,then plot the x,y,z and the angles then identify the transfert functions from the plots,x/w1,y/w1,... and so on, but i don't know if it's possible or what graphs i will have,so if you know about the subject or maybe tried something like that, and feel free to add anything you think might be helpfull&lt;/p&gt;&#xA;" OwnerUserId="2217" LastEditorUserId="2217" LastEditDate="2013-11-11T11:03:34.290" LastActivityDate="2013-11-11T11:03:34.290" Title="quadrotor experimental identification" Tags="&lt;control&gt;&lt;quadcopter&gt;&lt;quadrotor&gt;&lt;brushless-motor&gt;&lt;uav&gt;" CommentCount="1" FavoriteCount="0" ClosedDate="2013-12-08T21:21:58.633" />
  <row Id="2040" PostTypeId="2" ParentId="2036" CreationDate="2013-11-09T14:38:05.243" Score="1" Body="&lt;h2&gt;scope probe&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;I can sympathize with how frustrating it is when attaching an oscilloscope probe to debug a problem makes the system act differently.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A standard 1X probe (1:1 probe) will load a circuit with a capacitance of about 110 pF.&#xA;Many people use a 10X probe or a 100X probe, giving 1/10 or 1/100 the loading on the circuit -- hopefully small enough to be insignificant.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;ISO1050&lt;/h2&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;a pull-up resistor on the TX of CAN.&#xA;  ...&#xA;  the shape of the signal suggests a pull-up resistor may be necessary, but&#xA;  I haven't seen the need for that in any datasheet I found.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;I think this is it.&#xA;Page 4 of the &lt;a href=&quot;http://www.ti.com/lit/ds/slls983h/slls983h.pdf&quot; rel=&quot;nofollow&quot;&gt;datasheet for the ISO1050&lt;/a&gt; specifically says&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;NOTE&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;TXD is very weakly internally pulled up to VCC1. An external pull&#xA;  up resistor should be used ... &#xA;  An adequate external pullup resistor must be used to&#xA;  ensure that the TXD output of the microprocessor maintains adequate&#xA;  bit timing input to the input on the transceiver.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;h2&gt;PIC18F45K80&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;I'm assuming you're using the Microchip PIC18F45K80.&#xA;The &lt;a href=&quot;http://ww1.microchip.com/downloads/en/DeviceDoc/39977f.pdf&quot; rel=&quot;nofollow&quot;&gt;PIC18F66K80 family datasheet&lt;/a&gt; has a lot of useful information about the Microchip PIC18F45K80.&#xA;In particular, I think you might find section 27.0 ECAN MODULE useful.&#xA;Subsection 27.2.5 mentions ENDRHI: Enable Drive High bit, where&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ENDRHI = 1: CANTX pin will drive VDD when recessive &lt;/li&gt;&#xA;&lt;li&gt;ENDRHI = 0: CANTX pin will be tri-state when recessive&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Subsection 27.3.1 CONFIGURATION MODE implies that ENDRHI (and all other configuration bits) must be set in configuration mode, and cannot be changed while the CAN module is active.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I suspect that &lt;em&gt;either&lt;/em&gt; the pull-up resistor &lt;em&gt;or&lt;/em&gt; setting ENDRHI to 1 would be adequate.&#xA;However, if I were you, I would run some tests with &lt;em&gt;both&lt;/em&gt; a 10 KOhm pull-up resistor &lt;em&gt;and&lt;/em&gt; ENDRHI set to 1.&lt;/p&gt;&#xA;" OwnerUserId="187" LastActivityDate="2013-11-09T14:38:05.243" CommentCount="1" />
  <row Id="2041" PostTypeId="2" ParentId="1919" CreationDate="2013-11-10T01:47:43.657" Score="0" Body="&lt;p&gt;The vast majority of the time, I end up cutting off whatever connector is at the end of the cable hanging out of the stepper motor, and crimping on something else compatible with the board I want to connect it to.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Occasionally the board I want to connect it to has some sort of cage clamp terminal strips (also known as spring clamp terminal strips) or some other terminal block, so I can cram in the raw bare wires without any connector on the end.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As &lt;a href=&quot;http://robotics.stackexchange.com/questions/100/what-connectors-are-most-reliable/252#252&quot;&gt;I mentioned earlier&lt;/a&gt;, many RepRaps use 8P8C &quot;RJ45&quot; &quot;Ethernet&quot; connectors to carry power over CAT5 cable, usually in a way completely incompatible with any power-over-Ethernet standard or any Ethernet data standard.&#xA;&lt;a href=&quot;http://reprap.org/wiki/RepRap_project_FAQ#wires_and_connectors&quot; rel=&quot;nofollow&quot;&gt;&quot;Why do many RepRaps have RJ45 connectors?&quot;&lt;/a&gt;; &lt;a href=&quot;http://reprap.org/wiki/CupCakeWiring#Plug_in_Extruders_.2F_Toolheads&quot; rel=&quot;nofollow&quot;&gt;a&lt;/a&gt;; &lt;a href=&quot;http://reprap.org/wiki/Extruder_Controller_2.2#RS485_Comms_.2B_Power&quot; rel=&quot;nofollow&quot;&gt;b&lt;/a&gt;; &lt;a href=&quot;http://reprap.org/wiki/Motherboard_1.2#RS485_Comms_.2B_Power&quot; rel=&quot;nofollow&quot;&gt;c&lt;/a&gt;; &lt;a href=&quot;http://reprap.org/wiki/Monotronics&quot; rel=&quot;nofollow&quot;&gt;d&lt;/a&gt;; etc.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;( Quite a few people, for reasons inexplicable to me, insist on removing those 8P8C sockets and using their own favorite connector -- &lt;a href=&quot;http://reprap.org/wiki/PCB_adaptions_for_Mendel&quot; rel=&quot;nofollow&quot;&gt;http://reprap.org/wiki/PCB_adaptions_for_Mendel&lt;/a&gt; ).&lt;/p&gt;&#xA;" OwnerUserId="187" LastActivityDate="2013-11-10T01:47:43.657" />
  <row Id="2042" PostTypeId="1" AcceptedAnswerId="2046" CreationDate="2013-11-10T08:53:08.697" Score="2" ViewCount="83" Body="&lt;p&gt;I am building a machine and need 2 Stepper Motor for that.&#xA;The motors are driven using by a 3.3v arm device.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have made the following selections regarding the stepper motor, stepper motor driver and the power supply.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.circuitspecialists.com/12-volt-3.5-amp-power-supply.html&quot; rel=&quot;nofollow&quot;&gt;Power Supply 12 Volt Power Supply - 3.5 Amp Single Output&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.pololu.com/product/1200&quot; rel=&quot;nofollow&quot;&gt;Stepper Motors Stepper Motor: Unipolar/Bipolar, 200 Steps/Rev, 42×48mm, 4V, 1.2 A/Phase&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.pololu.com/product/2133&quot; rel=&quot;nofollow&quot;&gt;Stepper Motor Driver DRV8825 Stepper Motor Driver Carrier, High Current&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I tried my best to research the compatibility and came up with these.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is this a good selection considering the fact that the Power Supply will be driving 2 of these motors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I will be running the motors at 1/16 step for high resolution.As far as the speed is concerned,it's going to be pretty slow but they will be running continuously for hours in end.Basically what I am trying to do here is make a V-Plotter.As far I can tell, there will be loads of start stop motion in the motors though.&lt;/p&gt;&#xA;" OwnerUserId="1139" LastEditorUserId="1139" LastEditDate="2013-11-11T02:44:45.857" LastActivityDate="2013-11-11T04:31:54.027" Title="Choosing correct power supply for Stepper Motors" Tags="&lt;stepper-motor&gt;&lt;power&gt;&lt;stepper-driver&gt;" AnswerCount="1" CommentCount="2" FavoriteCount="1" />
  <row Id="2043" PostTypeId="1" CreationDate="2013-11-10T20:05:09.600" Score="0" ViewCount="44" Body="&lt;p&gt;I'm trying to figure out a completely hands free phone solution for a paralyzed person.&#xA;I've tried the moto x android phone as well as a jailbroken iphone with &lt;a href=&quot;http://lifehacker.com/5878522/make-siris-voice-control-completely-hands+free&quot; rel=&quot;nofollow&quot;&gt;siri always listening&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The problem with the above mentioned phones is that one can't stop the current command by voice.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here are a couple of examples:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;If you initiate a phone call you cannot cancel it&lt;/li&gt;&#xA;&lt;li&gt;If a song is playing you cannot skip or stop it from playing&lt;/li&gt;&#xA;&lt;li&gt;You can't hang up by voice&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Therefore I was wondering, is there a device which can act as the home button which can be activated with voice?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any help would be much appreciated.&lt;/p&gt;&#xA;" OwnerUserId="2219" LastActivityDate="2013-11-10T20:05:09.600" Title="Totally hands free phone for paralyzed person" Tags="&lt;arduino&gt;&lt;control&gt;&lt;microcontroller&gt;" CommentCount="1" />
  <row Id="2044" PostTypeId="2" ParentId="1400" CreationDate="2013-11-10T23:29:52.210" Score="1" Body="&lt;p&gt;There is no easy way of doing it. I've done it in many of my projects, the best method I found was to use &lt;a href=&quot;http://opencv.org/&quot; rel=&quot;nofollow&quot;&gt;http://opencv.org/&lt;/a&gt; to capture the frames, and overlay each frame with your data before displaying it again. The code below gives you an idea (written in the old opencv version 1 syntax)&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;/**&#xA;* Display the video from webcam and overlay text&#xA;*/&#xA;&#xA;#include &amp;lt;stdio.h&amp;gt;&#xA;#include &quot;cv.h&quot;&#xA;#include &quot;highgui.h&quot;&#xA;&#xA;int main(int argc, char** argv)&#xA;{&#xA;&#xA;    CvCapture *capture;&#xA;    IplImage  *frame;&#xA;    double    t, ms = 0;&#xA;&#xA;    bool finished = false;&#xA;    /* initialize webcam */&#xA;    capture = cvCaptureFromCAM(0);&#xA;&#xA;    CvFont myFont;&#xA;&#xA;    //Initialise font&#xA;    cvInitFont(&amp;amp;myFont,CV_FONT_HERSHEY_COMPLEX_SMALL ,1.5f,1.5f,0,1,8);&#xA;&#xA;    while (!finished)&#xA;    {&#xA;        /* display frame */&#xA;        frame = cvQueryFrame(capture);&#xA;        cvPutText( frame, &quot;My Text&quot;, cvPoint(50,50), &amp;amp;myFont , cvScalar(128) );&#xA;        // use other functions to draw something &#xA;        cvShowImage(&quot;Stream&quot;,frame);&#xA;    }&#xA;&#xA;    /* free memory */&#xA;    cvReleaseCapture(&amp;amp;capture);&#xA;    return 0;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;It also depends if you want to write your own code, or if you want a simple off the shelf solution. If you are writing your own code, then have a look at some of my scene rendering components, &lt;a href=&quot;https://sourceforge.net/p/visionmagic/code/ci/master/tree/src/modules/sceneRendering/&quot; rel=&quot;nofollow&quot;&gt;https://sourceforge.net/p/visionmagic/code/ci/master/tree/src/modules/sceneRendering/&lt;/a&gt; , not perfect, but will give you an idea on how to render things in OpenGL, and Qt.&lt;/p&gt;&#xA;" OwnerUserId="642" LastActivityDate="2013-11-10T23:29:52.210" />
  <row Id="2045" PostTypeId="1" AcceptedAnswerId="2052" CreationDate="2013-11-11T01:09:54.447" Score="2" ViewCount="56" Body="&lt;p&gt;I'm interested in getting a Create for a project I'll be working on, and wanted some information about it from somebody that already has one:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;How much weight can it safely carry? I talked with Irobot's tech support and they told me the maximum is 5lb, but searching on the internet it seems like this limit is actually not as strict as it appears to be. I'm asking because I'd need to put a 3kg laptop on top of it, which would mean ~3.5-4kg if you also consider the kinect and eventual supports for both. I guess I could use a netbook and send the data I need to another computer, but I wanted to avoid the additional overhead of the wireless link.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;For how long does it run using AA batteries? I'm inclined on not getting the battery pack, since I'd be using the robot in europe, so I'd also need a transformer if I went with the battery pack option.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Thanks!&lt;/p&gt;&#xA;" OwnerUserId="2222" LastActivityDate="2013-11-11T19:36:52.223" Title="Questions about Irobot Create" Tags="&lt;mobile-robot&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="2046" PostTypeId="2" ParentId="2042" CreationDate="2013-11-11T04:31:54.027" Score="2" Body="&lt;p&gt;As long as the steppers are running relatively slowly, let's say a few hundred steps per second, you should be fine.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Your driver uses PWM to control the current through the motor windings.  In microstepping mode the driving waveform at the motor terminals looks like a sine and cosine (sines offset by 90 degrees) and the driver modulates the outputs to maintain the current to the windings.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The 1.2A appears to be peak current.  So at standstill we're talking 1.2A*4V = 4.8W max per phase (though a microstepping driver will never drive those two phases &quot;fully&quot; simultaneously).  At any rate, at very slow speeds/standing we're talking about ~13W for the two motors vs. your 40W power supply.  So no problem.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As you start speeding things up two things happen: &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;The motors starts acting as a generator producing counter-EMF (and we don't know the Ke constant for those motors).  Now to maintain the same current your driver has to overcome this counter-EMF.  This is why you want the highest voltage you can get if you're planning to run your motors at speed.&lt;/li&gt;&#xA;&lt;li&gt;We are going through the microstepping waveform and really start caring more about the RMS current (So we can effectively divide by ~1.4 since the power supply doesn't care about peak current as much over very short durations).  So about 0.86A RMS per phase.  That adds up to ~3.42A which is still lower (though not by much, than your 3.5A supply).&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;So as long as you're well below a speed where your back-EMF is ~8V you're fine.  If you plan to go to this point or above it you'll run out of voltage and you're also left with relatively small margins on power.  It also depends on how much power you need for the rest of your system.  Unfortunately I'm not quite sure how to calculate the back-EMF constant (Ke) from your motor parameters.  Looking at the pulling torque curve (given with a 24V supply) I would guess that up to 1000-2000pps you'll still be OK and it looks like the torque is dropping by ~25% over ~1500pps so it's probably in the range of 6V/1500pps (very rough guess).  Since we know the inductance maybe someone can show us how to calculate back-EMF constant (I'd be interested in learning)...&lt;/p&gt;&#xA;" OwnerUserId="1584" LastActivityDate="2013-11-11T04:31:54.027" CommentCount="2" />
  <row Id="2047" PostTypeId="2" ParentId="2021" CreationDate="2013-11-11T04:41:19.747" Score="1" Body="&lt;p&gt;From what I understand, this telemetry kit uses Mavlink as a protocol for data transfer and unless I follow the specific header, footer, data etc format for Mavlink, I will invariably end up with gibberish on my hyperterminal. This means in order to read and modify the telemetry data, I'd have to develop a Mavlink engine from scratch, right?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/A6fuf.png&quot; alt=&quot;Mavlink Data Format&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would like to know if this problem can be cut short by using XBee radio Tx-Rx pair instead of the one 3DR is providing?&lt;/p&gt;&#xA;" OwnerUserId="1949" LastActivityDate="2013-11-11T04:41:19.747" CommentCount="8" />
  <row Id="2048" PostTypeId="1" AcceptedAnswerId="2072" CreationDate="2013-11-11T07:09:21.587" Score="0" ViewCount="102" Body="&lt;p&gt;I am trying to get precise control over the speed of rover 5 based robot. It has four PWM controlled motors and 4 Optical Quadrature Encoders. I am using &lt;a href=&quot;https://www.sparkfun.com/products/11593&quot; rel=&quot;nofollow&quot;&gt;4-channel motor controller&lt;/a&gt; with &lt;a href=&quot;https://www.sparkfun.com/products/10336&quot; rel=&quot;nofollow&quot;&gt;rover 5 chassis&lt;/a&gt;. I am using arduino Nano for control. I am able to read encoder INT output and change PWM based on pulse width to control speed. But, as a result, I am getting heavy oscillations in the control output. That makes, the robot to move in steps, as PWM is changing constantly. I need an algorithm which can minimize this ringing and have a smooth moving robot. Here is my arduino code snippet.&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;void setup() {&#xA;    Serial.begin(9600);&#xA;    init_motors();&#xA;    init_encoders();        &#xA;    req_speed[0] = 20;&#xA;    req_speed[1] = 20;&#xA;    req_speed[2] = 20;&#xA;    req_speed[3] = 20;&#xA;}&#xA;&#xA;void loop() {&#xA;  update_encoders();&#xA;  update_motors();&#xA;}&#xA;&#xA;void update_motors() {&#xA;  int i, err;&#xA;  unsigned long req_width;&#xA;  if(micros() - mtime &amp;gt; 2999) {&#xA;    mtime = micros();&#xA;&#xA;    for(i=0; i&amp;lt;4; i++) {&#xA;      digitalWrite(pins_dir[i], req_speed[i]&amp;gt;0);&#xA;      if(mtime - change_time[i] &amp;gt; 50000ul &amp;amp;&amp;amp; req_speed[i] != 0) {&#xA;        cur_pwm[i] += 5;&#xA;      } &#xA;      if(req_speed[i] &amp;gt; 0)&#xA;        cur_err[i] = req_speed[i]*10  - cur_speed[i];&#xA;      else&#xA;        cur_err[i] = (-req_speed[i]*10)  - cur_speed[i];&#xA;      if(cur_err[i] &amp;gt; 0 &amp;amp;&amp;amp; cur_pwm[i] &amp;lt; 255) {&#xA;        cur_pwm[i]++;&#xA;      } else if(cur_err[i] &amp;lt; 0 &amp;amp;&amp;amp; cur_pwm[i] &amp;gt; 0) {&#xA;        cur_pwm[i]--;&#xA;      }&#xA;      analogWrite(pins_pwm[i], cur_pwm[i]);&#xA;    }&#xA;  }&#xA;}&#xA;&#xA;void update_encoders() {&#xA;  int i;&#xA;  unsigned long w;&#xA;  enc_new = PINC &amp;amp; B00001111;&#xA;  unsigned long etime = micros();&#xA;  for (i=0; i&amp;lt;4; i++) {&#xA;    if((enc_old &amp;amp; (1 &amp;lt;&amp;lt; i)) &amp;lt; (enc_new &amp;amp; (1 &amp;lt;&amp;lt; i)))&#xA;    {&#xA;      w = (unsigned long)(((etime - change_time[i])));&#xA;      pulse_width[i] = (w + pulse_width_h1[i] + pulse_width_h2[i])/3;&#xA;      pulse_width_h2[i] = pulse_width_h1[i];&#xA;      pulse_width_h1[i] = pulse_width[i];&#xA;      change_time[i]=etime;&#xA;      pulse_count[i]++;&#xA;      cur_speed[i] = (3200000ul / pulse_width[i]);&#xA;    }&#xA;  }&#xA;  enc_old=enc_new;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Here req_speed is between -100 to 100, where sign indicates direction. Please consider all undefined variables as globals. I experimentally measured that, when motor is running at full speed, the pulse width is around 3200us.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Encoders' INT outputs (XOR of A and B) are connected to A0 thru A3. Motor PWM is connected to D3, D5, D6, D9. Please let me suggest any improvements to this code and advice me about what am I missing here.&lt;/p&gt;&#xA;" OwnerUserId="1144" LastActivityDate="2013-11-16T01:39:10.520" Title="Encoder based speed control for Rover 5" Tags="&lt;arduino&gt;&lt;motor&gt;&lt;pwm&gt;" AnswerCount="2" />
  <row Id="2051" PostTypeId="2" ParentId="2021" CreationDate="2013-11-11T15:54:36.020" Score="1" Body="&lt;p&gt;MAVLink is an encoded message. In order for you to get specific data out of it you will need to decode it in some way. There are a number of ways of doing this including writing your own code and attaching MAVlink to it. This is described here: &lt;a href=&quot;http://qgroundcontrol.org/dev/mavlink_onboard_integration_tutorial&quot; rel=&quot;nofollow&quot;&gt;http://qgroundcontrol.org/dev/mavlink_onboard_integration_tutorial&lt;/a&gt;. In order to use this you will have to have downloaded the mavlink libraries from the repository here: &lt;a href=&quot;https://github.com/mavlink/mavlink&quot; rel=&quot;nofollow&quot;&gt;https://github.com/mavlink/mavlink&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are wanting a platform independent java based implementation, a friend of mine Owen McAree developed MAVNode a Node.js based decoder for MAVLink which will decode the messages you require. It is a nvm repository &lt;a href=&quot;https://npmjs.org/package/mavlink&quot; rel=&quot;nofollow&quot;&gt;https://npmjs.org/package/mavlink&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="925" LastActivityDate="2013-11-11T15:54:36.020" CommentCount="1" />
  <row Id="2052" PostTypeId="2" ParentId="2045" CreationDate="2013-11-11T19:36:52.223" Score="1" Body="&lt;p&gt;The weight of just the 6.6 pound laptop is already 32% over capacity, so you may need to consider lightening the load. If not then you risk lower performance, higher stresses on the robot and possibly even burning out one or more motors under stress testing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On the matter of battery life, according to the &lt;a href=&quot;http://www.irobot.com/filelibrary/pdfs/hrd/create/Create%20Manual_Final.pdf&quot; rel=&quot;nofollow&quot;&gt;iRobot Create Manual&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Alkaline batteries will power the robot (on a hard floor with no payloads or&#xA;  attachments) for up to 1.5 hours if the robot is constantly moving.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;So this is less than half the run time of the APS battery:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The iRobot Create robot (without a payload or other attachments) will run for&#xA;  up to 3.5 hours with a fully charged APS battery.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="37" LastActivityDate="2013-11-11T19:36:52.223" />
  <row Id="2053" PostTypeId="1" CreationDate="2013-11-12T06:50:00.757" Score="2" ViewCount="96" Body="&lt;p&gt;I have a chip that is labeled L293D with a small 'ST' logo, which does not behave like I believe a L239D should:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have the chip on a breadboard with pins 4,5,12 and 13 connected to the ground rail. The positive rail gets 6V from a battery pack.&#xA;A motor is connected to pins 3 and 6.&#xA;Pin 2 is connected to the positive rail.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now, when I connect pin 1 (enable 1) to the positive rail, the motor spins, which is expected.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The weird thing is that if I connect pin 16 instead of pin 1 to positive, the motor spins, as well. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, with the motor connected to 11 and 14, and 15 connected to positive, the motor spins if I connect pin 1 or pin 16 to positive, but not if I connect pin 9 (which should be the enable pin for that side).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Does any of that make sense? Am I missing something here?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks!&lt;/p&gt;&#xA;" OwnerUserId="2228" LastActivityDate="2013-11-13T08:31:37.093" Title="Odd L293D behavior: Pin 16 seems to act as enable" Tags="&lt;motor&gt;&lt;h-bridge&gt;" AnswerCount="2" />
  <row Id="2054" PostTypeId="2" ParentId="2053" CreationDate="2013-11-12T09:25:39.153" Score="2" Body="&lt;p&gt;The behaviour you're describing seems to be correct (as described in the &lt;a href=&quot;http://www.ti.com/lit/gpn/l293&quot; rel=&quot;nofollow&quot;&gt;Texas Instruments L293 datasheet&lt;/a&gt; - which should be the same as ST's variant). Here's an example of how to wire 3 different motors (please note the indicated diodes are internal to the L293).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/VSY5i.png&quot; alt=&quot;Copied from TI L293 Datasheet&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The idea is that Vcc1 (pin 16) should be associated with your logic inputs: pins 1, 2, 7, 9, 10 and 15 (in other words, if your micro is powered from 3V3, Vcc1 should be 3V3). On the other hand, if you run your motors from 6V, Vcc2 (pin 8) should be 6V (or whichever voltage you use to drive the motors).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For reference, here's the pinout of the TI L293.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/ep9A5.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Update:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The TI variant does indeed seem to be the same as &lt;a href=&quot;http://www.st.com/web/catalog/sense_power/FM142/CL851/SC1790/SS1555/PF63141&quot; rel=&quot;nofollow&quot;&gt;ST's L293D (see powerdip package)&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="1775" LastEditorUserId="1775" LastEditDate="2013-11-12T16:34:08.153" LastActivityDate="2013-11-12T16:34:08.153" CommentCount="0" />
  <row Id="2055" PostTypeId="2" ParentId="653" CreationDate="2013-11-12T12:35:34.707" Score="2" Body="&lt;p&gt;A lot of the different options with regards to language are listed on the NXT wiki page &lt;a href=&quot;http://en.wikipedia.org/wiki/Lego_Mindstorms_NXT_2.0&quot; rel=&quot;nofollow&quot;&gt;http://en.wikipedia.org/wiki/Lego_Mindstorms_NXT_2.0&lt;/a&gt;. &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;NXT-G&lt;/strong&gt; NXT-G is the programming software included in the&#xA;standard base kit. It is based on LabVIEW graphical programming. It&#xA;features an interactive drag-and-drop environment. LabVIEW&#xA;Toolkit[edit] NXT-G is powered by LabVIEW, an industry standard in&#xA;programming. Created by National Instruments, LabVIEW uses data flow&#xA;programming to create a virtual instrument. To allow for more&#xA;advanced programming, in the graphical sense, National Instruments&#xA;released a Toolkit for the NXT. Version 1.0 came out in December&#xA;2006 Since its release, several bugs have been found and new sensors have been created. While the toolkit does allow for the creation of new sensors, National Instruments has yet to formally release an update&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Lego::NXT&lt;/strong&gt; Lego::NXT provides an API between Perl and&#xA;NXT. &lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Ada&lt;/strong&gt; A port of GNAT is available for the NXT. It requires&#xA;nxtOSEK to run. The port includes Ada bindings to the NXT hardware&#xA;and nxtOSEK. &lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Next Byte Codes &amp;amp; Not eXactly C&lt;/strong&gt; Next Byte Codes&#xA;(NBC) is a simple open-source language with an assembly language&#xA;syntax that can be used to program the NXT brick. Not eXactly C (NXC)&#xA;is a high level open-source language, similar to C, built on top&#xA;of the NBC compiler. It can also be used to program the NXT brick.&#xA;NXC is basically NQC for the NXT. It is the most widely used&#xA;third-party programming language. &lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;ROBOTC&lt;/strong&gt; ROBOTC is an&#xA;Integrated development environment targeted towards students that is&#xA;used to program and control LEGO NXT, VEX, RCX, and Arduino robots&#xA;using a programming language based on the C programming language.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;RoboMind&lt;/strong&gt; RoboMind is an educational programming environment&#xA;that offers a concise scripting language for programming a simulated&#xA;robot. These internationalized scripts can, however, also directly be&#xA;exported to Lego Mindstorms robots. It does not require custom&#xA;firmware in order to run. &lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;NXTGCC&lt;/strong&gt; NXTGCC is a GCC toolchain for&#xA;programming the NXT firmware in C. URBI[edit] URBI is a parallel and&#xA;event-driven language, with interfaces to C++/Java and Matlab. It&#xA;also has a component architecture (UObject) for distributed&#xA;computation. Urbi is compatible with many robots, including Nao (cf&#xA;Robocup), Bioloid or Aibo. &lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;leJOS NXT&lt;/strong&gt; leJOS NXT is a high&#xA;level open source language based on Java that uses custom firmware&#xA;developed by the leJOS team.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;nxtOSEK&lt;/strong&gt; To be able to write in&#xA;C (programming language)/C++, nxtOSEK can be used, but that requires&#xA;custom firmware too.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;MATLAB and Simulink&lt;/strong&gt; MATLAB is a&#xA;high-level programming language for numerical computing, data&#xA;acquisition and analysis. It can be used to control LEGO NXT robots&#xA;over a Bluetooth serial port (serial port communication is part of&#xA;the base functionality of MATLAB) or via a USB connection; for&#xA;example using the RWTH - Mindstorms NXT Toolbox (free &amp;amp; open-source).&#xA;Simulink is a MATLAB-based environment for modeling and simulating&#xA;dynamic systems. Using Simulink, a user can design control&#xA;algorithms, automatically generate C code for those algorithms, and&#xA;download the compiled code onto the LEGO NXT. MATLAB and Simulink&#xA;code for NXT programming is freely available. &lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Lua&lt;/strong&gt; pbLua is an&#xA;implementation of the Lua programming language, a general purpose&#xA;scripting language, for Lego Mindstorms. FLL &lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;NXT Navigation&lt;/strong&gt; FLL&#xA;Nxt Navigation An open source program to help navigation on the FLL&#xA;competition table. Uses NXT-G and .txt files to write programs.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;ruby-nxt&lt;/strong&gt; ruby-nxt is a library to program the NXT for the Ruby&#xA;programming language. Unlike the other languages for the NXT the code&#xA;isn't compiled to a binary file. Instead the code is directly&#xA;transmitted to the NXT via a bluetooth connection. This method of&#xA;execution is significantly slower than executing compiled code&#xA;directly. Robotics. &lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;NXT&lt;/strong&gt; Robotics.NXT is a Haskell interface to&#xA;NXT over Bluetooth. It supports direct commands, messages and many&#xA;sensors (also unofficial). It has also support for a simple&#xA;message-based control of a NXT brick via remotely executed program&#xA;(basic NXC code included).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;As previously mentioned the chart in  &lt;a href=&quot;http://teamhassenplug.org/NXT/NXTSoftware.html&quot; rel=&quot;nofollow&quot;&gt;http://teamhassenplug.org/NXT/NXTSoftware.html&lt;/a&gt; is a good comparison.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Which language is the most robust on the platform?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Although I agree that the question is far too ambiguous, after using NXT-G, Matlab, Labview and a number of the other interfaces, I have found that the BricxCC IDE and the NXC is very easy to use with great contextual help and a lot of examples. It allows a lot more programming freedom that the visual based solutions do not offer. I have not attempted to use the higher level programming languages such as Java and C++ because most of the applications that I have been using would not have benefited from the advanced functions. If you are wanting these advanced functions is NXT the right hardware?&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;One might also like to know (1) which (if any) of these alternatives supports hard real-time systems&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;This post for the LeJOS discuses this with regards to Java: &lt;a href=&quot;http://www.lejos.org/forum/viewtopic.php?f=18&amp;amp;t=4619&quot; rel=&quot;nofollow&quot;&gt;http://www.lejos.org/forum/viewtopic.php?f=18&amp;amp;t=4619&lt;/a&gt; :- &quot;The NXT firmware switches thread contexts every 1ms. Also, the scheduler of the NXT firmware is much more predictable. For example, a thread with high priority would be preferred by the scheduler over any thread with lower priority. So high priority threads could be pretty sure to be scheduled as soon as possible. The motor regulation was typically running as a high priority thread. But as you already guessed, the NXT firmware was no realtime system either. Threads with the same priority are served round-robin. Oh and once in a while, the garbage collector will halt the whole JVM. This is always true for the NXT. But the Oracle JVM used on the EV3 uses concurrent garbage collectors. However, in the worst case, even those fall back to halting the whole JVM. The trick to avoid that is to reuse object, arrays, and such stuff as far as possible in performance critical code paths.&quot;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;how much memory on the NXT is left over for my &quot;user-level&quot; programs and data after the language-support infrastructure libraries are loaded&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;This post for the LeJOS discuses this with regards to Java: &lt;a href=&quot;http://www.lejos.org/nxt/nxj/tutorial/AdvancedTopics/UnderstandingFilesLCPMemTools.htm&quot; rel=&quot;nofollow&quot;&gt;http://www.lejos.org/nxt/nxj/tutorial/AdvancedTopics/UnderstandingFilesLCPMemTools.htm&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&quot;The NXT has 256kb of flash memory. A fixed section at the start of the flash memory is allocated to the system. It is used to hold the firmware, followed by the startup menu. The rest of this system area is unused. The size of the system area varies between releases.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The firmware is written in C, with some ARM assembly language. The startup menu is written in Java (in the startup project in SVN).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Flash memory is read and written in 256-byte pages. The first page after the system area is used for persistent system settings administered by the startup menu.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The rest of the flash memory is used for the user file system. The first two pages hold the file table (directory), and the rest of the pages hold user files. Files are held as a contiguous set of bytes – i.e they use a single range of page numbers with no gaps. This allows a file to be addressed as a region of memory.&quot;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;do any of these alternatives support interrupt handlers&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;One way of programming interrupt handlers on the NXT is to program at a lower level: &lt;a href=&quot;http://www.tau.ac.il/~stoledo/lego/nxt-native/&quot; rel=&quot;nofollow&quot;&gt;http://www.tau.ac.il/~stoledo/lego/nxt-native/&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&quot;It's pretty easy to get started. You need two tools: the GNU development tools for ARM processors, and some way to download the resulting programs to the NXT. I use nexttool to download programs to the NXT, but I suppose that you could use NXT-G as well. There are several distributions of the GNU tools for ARM around. I usually use a distribution called WinARM, which is for windows; GNUARM and YAGARTO are two other options (I have used GNUARM on Linux).&quot;&lt;/p&gt;&#xA;" OwnerUserId="925" LastEditorUserId="925" LastEditDate="2013-11-13T15:53:33.973" LastActivityDate="2013-11-13T15:53:33.973" CommentCount="2" />
  <row Id="2056" PostTypeId="1" CreationDate="2013-11-12T13:26:18.287" Score="1" ViewCount="360" Body="&lt;p&gt;I am working right now with Arduino UNO and HC-05 bluetooth module.I followed the instruction given on &lt;a href=&quot;http://www.instructables.com/id/Modify-The-HC-05-Bluetooth-Module-Defaults-Using-A/?ALLSTEPS&quot; rel=&quot;nofollow&quot;&gt;this link for wiring&lt;/a&gt;. So there are 2 mode of working with this HC-05 module&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Simple serial communication&lt;/li&gt;&#xA;&lt;li&gt;Working in AT command mode so as to change the parameters of HC-05 module&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;As long as I work in simple serial communication mode, everything works fine but when I tried to change the parameters of module, it didn't work out. For working in At command mode, PIN NO 34 of HC-05 module needs to be high which I had taken care of. Lately I found that in mu module they had knowingly not connected the Berg strip to PIN 34, so I connected the PIN directly, even though I am not able to change the parameters of module and when I write any command on COM port of arduino IDE, I get this response&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;Enter AT commands:&#xA;ERROR:(0)&#xA;ÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿõÿýì¢^&#xA;ERROR:(0)&#xA;ÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿõÿýì¢^&#xA;ERROR:(0)&#xA;ÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿõÿýì¢^&#xA;ERROR:(0)&#xA;ÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿõÿýì¢^&#xA;ERROR:(0)&#xA;ÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿõÿýì¢^&#xA;ERROR:(0)&#xA;ÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿõÿýì¢^&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I think that garbage is due to my code&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here is my code:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#include &amp;lt;SoftwareSerial.h&amp;gt;&#xA;&#xA;SoftwareSerial BTSerial(10, 11); // RX | TX&#xA;&#xA;void setup()&#xA;{&#xA;  pinMode(9, OUTPUT);  &#xA;  digitalWrite(9, HIGH);&#xA;  Serial.begin(9600);&#xA;  Serial.println(&quot;Enter AT commands:&quot;);&#xA;  BTSerial.begin(38400);  &#xA;}&#xA;&#xA;void loop()&#xA;{&#xA;  uint8_t x;&#xA;  char CommandFromSerial[50]=&quot; &quot;;&#xA;  char ResponseFromBluetooth[50]= &quot; &quot;;&#xA;&#xA;  if ((Serial.available())){&#xA;    if(Serial.available()&amp;gt;0){&#xA;      for(x=0;x&amp;lt;50;x++)&#xA;        CommandFromSerial[x]=Serial.read();&#xA;      BTSerial.println(CommandFromSerial);&#xA;    }&#xA;  }&#xA;&#xA;  if ((BTSerial.available())){&#xA;    if(BTSerial.available()&amp;gt;0)&#xA;      for(x=0;x&amp;lt;50;x++)&#xA;        ResponseFromBluetooth[x]=BTSerial.read();&#xA;    Serial.println(ResponseFromBluetooth);&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I am not able to figure out what I am doing wrong. I used this command on COM port &#xA;&lt;code&gt;AT\r\n&lt;/code&gt; and many other commands but every time I get the same response.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Did I mess up with my bluetooth module unknowingly?&lt;/p&gt;&#xA;" OwnerUserId="1322" LastEditorUserId="158" LastEditDate="2013-11-12T15:18:17.667" LastActivityDate="2014-01-12T11:45:03.690" Title="Bluetooth module HC-05 giving ERROR :(0)" Tags="&lt;arduino&gt;&lt;c&gt;&lt;communication&gt;&lt;serial&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="2057" PostTypeId="2" ParentId="2053" CreationDate="2013-11-13T08:31:37.093" Score="0" Body="&lt;p&gt;The correct way to wire the pins out on a L293D is as follows:&lt;br&gt;&#xA;Pin 1 &amp;amp; 9 are enable pins should be tied to +5 if pulled low the outputs will be turned off regardless of the input states. &lt;br&gt;&#xA;Pins 4,5, 13, 12 are ground pins and ideally connected to the micro-controller ground connection. &lt;br&gt;&#xA;Pin2, Pin7, Pin10 and Pin15 are logic input pins. These are control pins and should be connected to micro-controller pins. &lt;br&gt;&#xA;Pins 2 &amp;amp; 7 control the left motor and 10 &amp;amp; 15 control the right motor.&#xA;Pin3, Pin6, Pin11, and Pin14 are output pins. Tie Pin3 and Pin6 to the first motor, Pin11 and Pin14 to second motor.&lt;br&gt;&#xA;Pin 16 enables the IC should be connected to a +5v Regulated Supply&#xA;Pin 8 powers the motors &lt;br&gt;&#xA;More details:&#xA;&lt;a href=&quot;http://www.robotplatform.com/howto/L293/motor_driver_1.html&quot; rel=&quot;nofollow&quot;&gt;http://www.robotplatform.com/howto/L293/motor_driver_1.html&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="2099" LastActivityDate="2013-11-13T08:31:37.093" />
  <row Id="2058" PostTypeId="2" ParentId="2056" CreationDate="2013-11-13T09:45:54.440" Score="0" Body="&lt;p&gt;Wouldn't have thought you have messed up your bluetooth module or it's a problem with your code; it could be the firmware loaded on the module.&lt;BR&gt;&lt;BR&gt;&#xA;I too have encountered problems getting those HC-05 &quot;linvor&quot; modules to respond to AT command set. If the only AT commands that module responds to is AT  and setting the name; then you have a slave module. These have been loaded with limited firmware which doesn't respond to other AT commands given. &lt;BR&gt;&#xA;You need the ones which are master's as they will respond to the other AT commands and have better firmware installed on them.&#xA;&lt;br&gt;&lt;br&gt;&#xA;Found this out by trial and error as I have 2 modules which I was trying to configure so they paired up without user intervention and failing. I bought my modules on eBay from a seller with a ID for emailforyou which gave good information within the description; which informed me that in order to get each module to pair up you need a master &amp;amp; slave. I bought 2 surface mount masters but also opted to get a 6 pin (assembled) HC-06 Master/Slave module as well from the above seller. &lt;br&gt;&#xA;&lt;strong&gt;Updated&lt;/strong&gt; &lt;br&gt;&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#include &amp;lt;SoftwareSerial.h&amp;gt;&#xA;&#xA;SoftwareSerial BTSerial(16, 17); // RX | TX&#xA;&#xA;void setup()&#xA;{&#xA;  pinMode(11, OUTPUT);  // this pin will pull the HC-05 pin 34 (key pin) HIGH to switch module to AT mode&#xA;  digitalWrite(11, HIGH);&#xA;  Serial.begin(9600);&#xA;  Serial.println(&quot;Enter AT commands:&quot;);&#xA;  BTSerial.begin(9600);  // HC-05 default speed in AT command more&#xA;                         // was 38400 but changed it to 9600&#xA;}&#xA;&#xA;void loop()&#xA;{&#xA;&#xA;  // Keep reading from HC-05 and send to Arduino Serial Monitor&#xA;  if (BTSerial.available())&#xA;    Serial.write(BTSerial.read());&#xA;&#xA;  // Keep reading from Arduino Serial Monitor and send to HC-05&#xA;  if (Serial.available())&#xA;    BTSerial.write(Serial.read());&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="2099" LastEditorUserId="2099" LastEditDate="2013-11-13T11:18:34.893" LastActivityDate="2013-11-13T11:18:34.893" CommentCount="9" />
  <row Id="2059" PostTypeId="2" ParentId="1877" CreationDate="2013-11-13T10:02:08.677" Score="0" Body="&lt;p&gt;If starting out with programming use C/C++ as most of the examples using OpenCV on the internet use that language but there are interfaces for many other languages. I.E. Java, Python, C++, C &lt;BR&gt;&#xA;More details: &lt;a href=&quot;http://opencv.org/&quot; rel=&quot;nofollow&quot;&gt;http://opencv.org/&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="2099" LastActivityDate="2013-11-13T10:02:08.677" />
  <row Id="2060" PostTypeId="2" ParentId="1991" CreationDate="2013-11-13T15:01:20.960" Score="1" Body="&lt;p&gt;The swissranger is a RF-modulated light sources with phase detectors which is one type of time of flight camera. The other type is Range Gated Imager. The Wiki Page for time-of-flight cameras &lt;a href=&quot;http://en.wikipedia.org/wiki/Time-of-flight_camera&quot; rel=&quot;nofollow&quot;&gt;http://en.wikipedia.org/wiki/Time-of-flight_camera&lt;/a&gt;  states this for the Range Gated imagers: &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&quot;Range gated imagers can also be used in 2D imaging to suppress anything outside a specified distance range, such as to see through fog. A pulsed laser provides illumination, and an optical gate allows light to reach the imager only during the desired time period.&quot;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It also states that:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&quot;The ZCam by 3DV Systems is a range-gated system.&quot;&lt;/p&gt;&#xA;" OwnerUserId="925" LastActivityDate="2013-11-13T15:01:20.960" CommentCount="3" />
  <row Id="2061" PostTypeId="2" ParentId="1877" CreationDate="2013-11-14T10:48:34.290" Score="2" Body="&lt;p&gt;Though I did not use hand gestures, I used color based object tracking for my undergrad project. I did it through MATLAB as at that point of time I had no idea about Open-CV. I am guessing you will have a laptop for image processing and send commands run-time to your robot.&#xA;Ok first thing, sending serial commands though the serial port / USB port / wifi to your robot will be damn easy (at-least in the computer part - sending). You can do your gesture recognition using low resolution say 240*240. This will be fast considering a moderately new machine. &lt;strong&gt;MATLAB is itself not slow&lt;/strong&gt;. It is your &lt;strong&gt;implementation and algorithms&lt;/strong&gt; used which determines slow or fast. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now if you want to do the entire thing in a mobile platform say Android, MATLAB is out of the question. Or if you are using any embedded platform then Open-CV is the way to go. You will have to code the communication part of things too as OpenCV does not have any serial communication or related toolbox. But even with Open-CV your &lt;strong&gt;implementation and algorithms&lt;/strong&gt; will determine slow or fast.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In open-CV 2.0 the new C++ interface is much better and also faster than the old openCV 1.0 functions. You also have OO with OpenCV 2.0 and using CVMat is much more related and easy like MATLAB than the native IPLImage interface.&lt;/p&gt;&#xA;" OwnerUserId="2236" LastActivityDate="2013-11-14T10:48:34.290" />
  <row Id="2062" PostTypeId="1" CreationDate="2013-11-05T00:32:35.767" Score="2" ViewCount="42" Body="&lt;p&gt;I'm working on a legged robot and generating joint torques. Basically the robot seems to be statically stable to some extend. The robot goes instable if the center of pressure moves to the border of the feet. I'm looking for some method to move away the center of pressure  from the feet edges after having calculated my joint torques. In Sentis thesis ( &lt;a href=&quot;http://ai.stanford.edu/~lsentis/files/Thesis-Sentis-2007.pdf&quot; rel=&quot;nofollow&quot;&gt;http://ai.stanford.edu/~lsentis/files/Thesis-Sentis-2007.pdf&lt;/a&gt; ) , it is mentioned that he somehow manages to cancel out the internal forces to keep the feet flat against the supporting surfaces. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Does anyone has got experience in dealing with internal forces? As far as I understood the literature one can modify the nullspace of the calculated torques to achieve that the COP remains in the geometrical center of the considered foot. I'm looking for methods apart from the virtual linkage model as it did not seem to work for me or someone with whom I could discuss the virtual linkage model described in ( &lt;a href=&quot;http://ai.stanford.edu/~lsentis/files/tro-2010.pdf&quot; rel=&quot;nofollow&quot;&gt;http://ai.stanford.edu/~lsentis/files/tro-2010.pdf&lt;/a&gt; ) as I might not have it understood it correctly.&lt;/p&gt;&#xA;" OwnerDisplayName="someguy" LastEditorUserId="158" LastEditDate="2014-01-10T10:54:29.103" LastActivityDate="2014-01-10T10:54:29.103" Title="Guidance for compensating internal forces on closed loop chain" Tags="&lt;stability&gt;&lt;legged&gt;" AnswerCount="0" CommentCount="1" FavoriteCount="1" />
  <row Id="2063" PostTypeId="1" AcceptedAnswerId="2066" CreationDate="2013-11-14T20:32:20.550" Score="2" ViewCount="96" Body="&lt;p&gt;I am trying to use a push button in order to know and print number of time a push button is pressed using a counter.But everytime i press the button , counter get incremented to sometime 3 and sometime 5 and some time counter does start &gt;100 and continue.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I had preferred the &lt;a href=&quot;http://arduino.cc/en/Tutorial/Button&quot; rel=&quot;nofollow&quot;&gt;this link&lt;/a&gt; for wiring PUSH button with arduino.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;and here is my code&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;const int buttonPin = 2;     // the number of the pushbutton pin&#xA;const int ledPin =  13;      // the number of the LED pin&#xA;&#xA;// variables will change:&#xA;int buttonState = 0;         // variable for reading the pushbutton status&#xA;int count = 0;&#xA;void setup() {&#xA;  // initialize the LED pin as an output:&#xA;  pinMode(ledPin, OUTPUT);      &#xA;  // initialize the pushbutton pin as an input:&#xA;  pinMode(buttonPin, INPUT);   &#xA;  pinMode(buttonPin, INPUT); &#xA;  Serial.begin(9600);&#xA;    buttonState = digitalRead(buttonPin);&#xA;  digitalWrite(ledPin,LOW);  &#xA;}&#xA;&#xA;void loop(){&#xA;    // read the state of the pushbutton value:&#xA;  buttonState = digitalRead(buttonPin);&#xA;&#xA;  // check if the pushbutton is pressed.&#xA;  // if it is, the buttonState is HIGH:&#xA;  if (buttonState == HIGH) {&#xA;&#xA;    // turn LED on:    &#xA;    digitalWrite(ledPin, HIGH); &#xA;    count = count + 1;  &#xA;    Serial.print(count);&#xA;  } &#xA;  else {&#xA;    // turn LED off:&#xA;    digitalWrite(ledPin, LOW); &#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I dont know why count is coming absurdly and unevenly.&lt;/p&gt;&#xA;" OwnerUserId="1322" LastActivityDate="2013-11-20T16:47:28.790" Title="Unable to read pushbutton press properly in Arduino" Tags="&lt;arduino&gt;&lt;c&gt;&lt;serial&gt;" AnswerCount="2" />
  <row Id="2065" PostTypeId="2" ParentId="2063" CreationDate="2013-11-14T22:12:56.060" Score="3" Body="&lt;p&gt;What your experiencing is known as &quot;button bounce&quot;. When you push a standard pushbutton, it actually makes and breaks contact many times very quickly for a few microseconds, usually enough to make the processor detect between 10 and 100 pushes, or more. There are many different methods of &quot;debouncing&quot; a pushbutton. The easiest approach is to add a small delay in your code right after you check if the pushbutton is pressed:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;if(buttonState == HIGH){&#xA;    delay(10);&#xA;    //turn the light on, etc. &#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;There are other methods, both hardware and software. The most elegant method which will not interrupt the running of other code is to have a timer that scans the pushbutton periodically (i.e. every 5 milliseconds or so), and sets a boolean variable to TRUE when it detects a push. You could also rig up a small capacitor to the button; the schematic is available on the internet. &lt;/p&gt;&#xA;" OwnerUserId="176" LastActivityDate="2013-11-14T22:12:56.060" CommentCount="1" />
  <row Id="2066" PostTypeId="2" ParentId="2063" CreationDate="2013-11-15T00:15:59.420" Score="4" Body="&lt;p&gt;Chris is right, the problem is that the mechanical contact of the switch is bouncing. However, I disagree with his statement that the most elegant solution is polling. Polling is very inefficient for the task of counting how many times a button was pressed, and so I decided to post my own answer for clarification:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Interrupts are what you want. Polling is used when you want to constantly capture information, for example from a range sensor. Interrupts give you time sensitive control, and only performs processing at the exact time you need it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For a more thorough answer...&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This design problem is commonly referred to as &quot;switch debouncing.&quot; As Chris correctly mentions, you can do this in hardware or software. The optimal method of implementation with respect to count accuracy and CPU load is to use hardware to smooth out the signal and connect your button to an interrupt pin on the Arduino. You can then use the built in attachInterrupt() function to eliminate the need to poll constantly. Polling is a waste of CPU power. The attachInterrupt() function will assign an interrupt handler that will be called whenever the interrupt pin sees a RISING or FALLING edge (this depends on how you have your switch electrically connected), or even more generally on a CHANGE. This would look similar to the following:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;attachInterrupt(0, buttonHandler, RISING);&#xA;&#xA;void buttonHandler() {&#xA;   // turn LED on:    &#xA;  digitalWrite(ledPin, HIGH); &#xA;  count = count + 1;  &#xA;  Serial.print(count);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;This page explains the problem of switch debouncing and shows some example hardware circuits you can easily implement: &lt;a href=&quot;http://www.elexp.com/t_bounc.htm&quot; rel=&quot;nofollow&quot;&gt;http://www.elexp.com/t_bounc.htm&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note: You probably won't be able to see the led go HIGH because it will be handled so quickly. This code will increment the count once every time the button is pressed or released, depending on whether you attach the interrupt to the rising or falling edge of the signal.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Edit for OP's comment:&#xA;If you want the serial.print to say that the button is pressed the entire time, then add a while loop in the interrupt:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;void buttonHandler() {&#xA;   // turn LED on:    &#xA;  digitalWrite(ledPin, HIGH); &#xA;  count = count + 1;&#xA;  Serial.print(count);&#xA;  while(digitalRead(buttonPin)) //This will loop until the button is released&#xA;    Serial.print(&quot;ON&quot;);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Please note that this will cause your program to stay inside the interrupt handler, and your main function will not execute. In your main function, you can then have a Serial.print(&quot;OFF&quot;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You may also be able to use a boolean that is set to true in your interrupt handler:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;void buttonHandler() {&#xA;   // turn LED on:    &#xA;  digitalWrite(ledPin, HIGH); &#xA;  count = count + 1;  &#xA;  Serial.print(count);&#xA;  buttonWasPressed = true;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;That way, in your main you can have an if statement to prevent your code from having to loop in the interrupt handler:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;void loop() {&#xA;  if(buttonWasPressed) {&#xA;    while(digitalRead(buttonPin)) {&#xA;      Serial.print(&quot;ON&quot;);&#xA;    }&#xA;    buttonWasPressed = false;&#xA;  }&#xA;  else&#xA;    Serial.print(&quot;OFF&quot;);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="1960" LastEditorUserId="1960" LastEditDate="2013-11-20T16:47:28.790" LastActivityDate="2013-11-20T16:47:28.790" CommentCount="3" />
  <row Id="2068" PostTypeId="1" AcceptedAnswerId="2069" CreationDate="2013-11-15T12:58:46.770" Score="8" ViewCount="127" Body="&lt;p&gt;I have an &lt;a href=&quot;http://en.wikipedia.org/wiki/Radio-controlled_model&quot; rel=&quot;nofollow&quot;&gt;RC&lt;/a&gt; car. The battery provides power to the &lt;a href=&quot;https://en.wikipedia.org/wiki/electronic_speed_control&quot; rel=&quot;nofollow&quot;&gt;ESC&lt;/a&gt; and then the ESC provides 6&amp;nbsp;V back out to the receiver. Instead of the receiver I have a Raspberry Pi, which uses the 6&amp;nbsp;V, steps it down to 5&amp;nbsp;V and provides power to the Raspberry Pi.&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;The problem&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Every time we go full power*, there is a lack of voltage and the Raspberry Pi seems to hard reset.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;* By full power we mean direct to 100% and not ranging from 0-100&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am not an expert in electrical circuits, but some of the suggestions are to use a capacitor to provide the missing 5&amp;nbsp;V in the interim. How do I prevent the Raspberry Pi from dying in the event of full power?&lt;/p&gt;&#xA;" OwnerUserId="2241" LastEditorUserId="1906" LastEditDate="2014-01-11T15:25:12.277" LastActivityDate="2014-01-11T15:25:12.277" Title="My Raspberry Pi is losing power in a surge" Tags="&lt;raspberry-pi&gt;&lt;electronics&gt;&lt;esc&gt;" AnswerCount="3" CommentCount="3" />
  <row Id="2069" PostTypeId="2" ParentId="2068" CreationDate="2013-11-15T13:48:56.520" Score="3" Body="&lt;p&gt;Since you're running directly from a battery I would say it's safe to just add as much decoupling (in other words caps across your input power) as possible, since the only real downside (that I think is relevant to your setup) to adding a lot of capacitance is increased in-rush current (since the capacitor naturally acts as a short-circuit during charge-up).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In certain circumstances however the high current draw associated with excessive decoupling during initial start-up should be avoided. An example is when you use a switching converter to step a voltage up/down. If the converter has built in over current protection (and no slow start feature), the short-circuit caused by the uncharged caps will cause the converter to stagger (starting up, over current and starting up again), and never fully reach its target voltage. However, since you're running directly from a battery this shouldn't be a problem, since a battery can be driven way above it's rated current capacity (for short periods).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another thing to also remember is that since there exists a large energy store across your power rails (the capacitors), the system might take a while to discharge (after being powered off). In other words, your Pi will probably run for another 30 seconds (depending on how much capacitance you add) or so after you disconnect your main battery.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Finally, always try to add capacitors that's rated at at least twice your operating voltage (for instance, if you have 6V batteries try to get 16V caps). Motors that reverses their direction very quickly may induce sufficiently large voltage spikes back into your system, and cause your caps to explode (hopefully your motor driver has sufficient clamping diodes).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would say a single 1000 uF electrolytic cap would be more than enough decoupling. If your Pi continues to brown-out, I guess the more appropriate cause would be your batteries not being able to supply the required current. Remember, the reason you Pi is restarting (or browning out) is due to the supply voltage dipping because the batteries are unable to supply the current the motors require. Adding capacitors will help with surges in currents (such as motors accelerating), but obviously won't solve long term high current draw.&lt;/p&gt;&#xA;" OwnerUserId="1775" LastEditorUserId="1775" LastEditDate="2013-11-15T13:58:24.847" LastActivityDate="2013-11-15T13:58:24.847" CommentCount="4" />
  <row Id="2070" PostTypeId="2" ParentId="2068" CreationDate="2013-11-15T17:20:36.763" Score="4" Body="&lt;p&gt;It sounds like you're experiencing a &quot;brown out&quot; caused when the excessive current draw from the battery causes a drop in the supply voltage.  This is due to the fact that batteries have internal resistance (a.k.a &lt;a href=&quot;http://en.wikipedia.org/wiki/Output_impedance#Batteries&quot; rel=&quot;nofollow&quot;&gt;output impedance&lt;/a&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/o8c50.png&quot; alt=&quot;internal resistance&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In this example, if the load drops to $0.2\Omega$, the internal resistance of the battery will cause the output voltage to be divided equally with the external resistance -- the load will only see 5V.  It's possible that your 6V supply is dropping to 3V (or less) under load, in much the same way.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;A capacitor will delay this effect, but what you really need is a voltage regulator -- many are available in an integrated circuit (IC) package.  Some voltage regulators will step up voltage when insufficient, but most simply lower a supply voltage to the voltage needed by a component like your RPi (in which case, your battery voltage would have to be increased so that it never dipped below 5V under full motor load).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Alternatively, you could use a separate battery pack for the RPi.  This is a common solution for mobile robots, because it ensures that when the robot is immobilized due to lack of power, radio communication with the onboard PC will not be lost.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2013-11-17T23:11:33.453" LastActivityDate="2013-11-17T23:11:33.453" CommentCount="4" />
  <row Id="2071" PostTypeId="2" ParentId="2048" CreationDate="2013-11-15T19:58:25.887" Score="0" Body="&lt;p&gt;I'll be honest, I don't understand what some of your code is doing. Why is there a 4bit mask for the encoders? Is this the direction? What is pulse_width_h1 vs pulse_width_h2...please comment your code and I will be able to help you. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In addition, your controller is odd. It looks like you're simply adding 1 or -1 depending on the sign of the error. You should look into a PID controller. These are easy to implement and VERY commonly used to implement velocity control. You can start with just a P (proportional) term. The idea is to tune your gain K_p until the system behaves as desired.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To reiterate...please comment your code and I can edit this post to provide a better answer.&lt;/p&gt;&#xA;" OwnerUserId="1960" LastActivityDate="2013-11-15T19:58:25.887" CommentCount="1" />
  <row Id="2072" PostTypeId="2" ParentId="2048" CreationDate="2013-11-16T01:34:02.520" Score="0" Body="&lt;p&gt;I looked at the PID controller basics and found that its the canonical solution for this kind of speed control problem. I used the arduino PID library and it worked pretty well. I had to spend some time figuring out the PID parameters (Kp, Ki, Kd) manually by trial and error. But,  with this, I am now able to get my motors running at the required speed with pretty much stable behaviour. You can take a look the new PID based code &lt;a href=&quot;https://github.com/punitsoni/rv_arduino/blob/master/rv_arduino.ino&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1144" LastEditorUserId="1144" LastEditDate="2013-11-16T01:39:10.520" LastActivityDate="2013-11-16T01:39:10.520" />
  <row Id="2074" PostTypeId="1" AcceptedAnswerId="2076" CreationDate="2013-11-17T06:08:31.293" Score="0" ViewCount="31" Body="&lt;p&gt;I could swear that it was working for a while. I got back to my desk, tried it again, and it's no longer working. Could I have fried the NO pins on both sides? This is a DPDT relay. Everything works normally on the NC pins. I have never applied more than 5V. I do hear the relay click when I apply 5V to the coil. But when I measure voltage on the NO pins, I get 0V. Has anyone else seen this? I have two of these relays and I can't seem to get voltage on the NO pins with either relay. I should clarify that I'm expecting the same 5V power source to power both the coil and the common pins. If the NC pins work then I don't see why the NO pins shouldn't. In both cases the 5V is shared between the coil and any load attached to the NC/NO pins. I did try driving the entire circuit off a 9V power supply, but that did not change the results (and that does contradict my earlier statement that I've never applied more than 5V to this relay). My circuit is based on Charles Platt's &quot;Make: Electronics&quot;, p. 59.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here's a pic of the schematic I am following, except that I am using a 5V relay and a 5V power supply (USB port) and I am using piezo buzzers without resistors instead of LEDs.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/nYbnL.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="2247" LastEditorUserId="2247" LastEditDate="2013-11-17T15:14:22.100" LastActivityDate="2013-11-17T22:59:06.723" Title="Omron G5V-2 relay NO pins not working" Tags="&lt;electronics&gt;" AnswerCount="1" />
  <row Id="2075" PostTypeId="1" CreationDate="2013-11-17T14:44:29.527" Score="3" ViewCount="111" Body="&lt;p&gt;I'm looking for particle filter implementation in ROS to use in mobile robot localization, but it seems the only available package is &lt;a href=&quot;http://wiki.ros.org/amcl&quot; rel=&quot;nofollow&quot;&gt;amcl&lt;/a&gt; (Adaptive Monte Carlo), I'm not sure is it possible to use it as particle filter or not, and if it's feasible, how?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The robot (wheeled robot) provides odometry data and another data source is &lt;code&gt;Kinect&lt;/code&gt;, that provides visual odometry data using &lt;a href=&quot;http://wiki.ros.org/fovis&quot; rel=&quot;nofollow&quot;&gt;fovis&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="2202" LastActivityDate="2013-11-19T15:31:49.787" Title="Particle filter implementation in ROS" Tags="&lt;mobile-robot&gt;&lt;localization&gt;&lt;ros&gt;&lt;particle-filter&gt;" AnswerCount="1" />
  <row Id="2076" PostTypeId="2" ParentId="2074" CreationDate="2013-11-17T18:41:09.620" Score="1" Body="&lt;p&gt;Problem solved. It turns out that the pin assignment on my relay is different from that in the book. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here's the schematic for my actual relay (notice that the pin assignment is CO,NC,NO instead of NC,CO,NO as in the book)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Schematic of my actual relay:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/u7HMx.jpg&quot; alt=&quot;OMRON G5V-2&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="2247" LastEditorUserId="350" LastEditDate="2013-11-17T22:59:06.723" LastActivityDate="2013-11-17T22:59:06.723" />
  <row Id="2077" PostTypeId="1" CreationDate="2013-11-18T02:42:12.970" Score="3" ViewCount="88" Body="&lt;p&gt;I frequently bang my head on my desk after performing a task poorly. I would like to eliminate the unnecessary middle step of actually performing a task poorly. As such, I would like to design a system to hold my head and repeatedly strike it against my desk. Alternatively, a system that holds the desk and repeatedly strikes it against my head would be acceptable. Requirements are at least 2 strikes per second maximum with ~50cm travel.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can anybody make any recommendations for a system to base this device off of? Denso products, while small and affordable, do not have the required load capacity (some users may have a rather large head, and involuntary resistance is to be expected -- at least near the start of the cycle). I am thinking of something more industrial, perhaps:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/irpHH.jpg&quot; alt=&quot;Fanuc R-2000iA&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="2248" LastActivityDate="2013-11-18T02:42:12.970" Title="Recommendations for system to repeatedly force contact between head and desk" Tags="&lt;robotic-arm&gt;" CommentCount="4" FavoriteCount="1" ClosedDate="2013-11-21T01:59:03.820" />
  <row Id="2079" PostTypeId="2" ParentId="2068" CreationDate="2013-11-18T13:06:20.337" Score="4" Body="&lt;p&gt;I must agree with the other two answers, however the main issue is that you do not have enough voltage into your regulator (I see from your comment to Ian that you are using a Pololu D15V35F5S3 Regulator). If you refer to the &lt;a href=&quot;http://www.pololu.com/product/2110&quot; rel=&quot;nofollow&quot;&gt;Pololu D15V35F5S3 Product Description&lt;/a&gt;, down at the bottom you will find the following graph:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/ugMfs.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Looking at the red line for 5V output: Note for all currents greater than zero, the dropout voltage is greater than 1V. (The minimum input voltage necessary to achieve 5V output is 5V + dropout voltage.) The more current used by your 5V loads (Pi), the greater the dropout. The problem is compounded by any voltage drop in your 6V source due to current surges (see Ian's answer).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You either need a higher input voltage, a lower dropout regulator (this may be difficult and insufficient), a different regulator (buck-boost), or a different power source for the Pi.&lt;/p&gt;&#xA;" OwnerUserId="1844" LastEditorUserId="1844" LastEditDate="2013-11-18T15:04:51.773" LastActivityDate="2013-11-18T15:04:51.773" CommentCount="4" />
  <row Id="2080" PostTypeId="2" ParentId="2075" CreationDate="2013-11-19T15:12:24.377" Score="3" Body="&lt;p&gt;Monte Carlo localization is just another name for a particle filter. Monte Carlo methods are a broader name for computational algorithms that rely on random sampling. A particle filter is a specific application of the general Monte Carlo method for localization, and so it is simply referred to sometimes as Monte Carlo localization.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you ask Lord Google, he'll tell you everything you want to know:&#xA;&lt;a href=&quot;http://en.wikipedia.org/wiki/Monte_Carlo_localization&quot; rel=&quot;nofollow&quot;&gt;http://en.wikipedia.org/wiki/Monte_Carlo_localization&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Sebastian Thrun has a great book called Probabilistic Robotics that talks about MCL (Monte Carlo Localization) if you're interested in something more formal.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Edit: I just read the amcl rosnode wiki page and it actually mentions pretty much exactly what I've said here...I'm sure if you just read the node's wiki page you'll find your answers. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The amcl rosnode currently works with laser range data (i.e. from a LIDAR), so you'll have to extend it if you want to take advantage of a Kinect. It seems like you'll need some form of sensor measurement, as opposed to pure odometry. You could combine the odometry readings from the wheels &amp;amp; the visual odometry in a Kalman Filter, but with no sensor readings to update your position and fix errors based on a map, you'll just accumulate error and you'd have no sensor update in your MCL. You should be able to generate range data using the Kinect for the purpose of applying it as the sensor update in the MCL algorithm, and it might even be possible to publish this as laser data in ROS if you reformat it. This would allow you to interface directly with the existing amcl package.&lt;/p&gt;&#xA;" OwnerUserId="1960" LastEditorUserId="1960" LastEditDate="2013-11-19T15:31:49.787" LastActivityDate="2013-11-19T15:31:49.787" />
  <row Id="2081" PostTypeId="1" CreationDate="2013-11-20T07:41:16.627" Score="1" ViewCount="47" Body="&lt;p&gt;I am looking for some material to build a soft clear protective covering for RGB LEDs. The material needs to be close to transparent to allow light to shine through, be soft and compliant but sturdy enough to withstand someone standing on it. The ultimate goal is to have a floor of these LEDs that someone can jump in barefoot and change led colors. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have tried Gel Candle Wax and Silicone but neither worked very well. I am looking for other material ideas and this was the most relevant of the StackExchanges that I could find. &lt;/p&gt;&#xA;" OwnerUserId="2263" LastActivityDate="2013-12-16T12:41:46.360" Title="Soft LED Protection Material" Tags="&lt;arduino&gt;" AnswerCount="1" CommentCount="5" />
  <row Id="2082" PostTypeId="2" ParentId="2018" CreationDate="2013-11-20T11:15:47.787" Score="1" Body="&lt;p&gt;Choosing which board/chip to use would also depend on the number of Input/Output ports you are going to need.&lt;br&gt;&#xA;Uno has analogue 6 in / 0 out, digital IO 14/ 6 do PWM, 1 serial port (tx,rx)&lt;br&gt;&#xA;Mega 2560 has 16 analogue / 0 out ports, digital IO 54/ 15 do PWM, 4 serial ports.&lt;br&gt;&#xA;The robodunio ATMega168 has the same spec as the UNO but the clock speed is lower; It's also based upon the freedunio.&lt;br&gt;&#xA;&lt;a href=&quot;http://arduino.cc/en/Products.Compare&quot; rel=&quot;nofollow&quot;&gt;http://arduino.cc/en/Products.Compare&lt;/a&gt; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;You will find it hard to process video feed with each of these chips. You could process the video on a Pi as all ready suggested or use other hardware to to process the video feed then pass the resulting information to the arduino's to enable movement processing or some other action needed.  &lt;/p&gt;&#xA;" OwnerUserId="2099" LastActivityDate="2013-11-20T11:15:47.787" />
  <row Id="2083" PostTypeId="1" AcceptedAnswerId="2191" CreationDate="2013-11-20T14:42:44.193" Score="1" ViewCount="57" Body="&lt;p&gt;I am using Arduino UNO to read a push button every time it is pressed.Earlier i was simply reading the Digital IO pin to read the count and then i faced the condition of switch debounce regarding which i had asked a &lt;a href=&quot;http://robotics.stackexchange.com/questions/2063/unable-to-read-pushbutton-press-properly-in-arduino&quot;&gt;question here&lt;/a&gt; and get to know that i must use Interrupt instead of reading a digital IO pin but even after using interrupt, i was facing the problem of Switch Debouncing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So i used &lt;a href=&quot;http://www.arduino.cc/en/Tutorial/Debounce&quot; rel=&quot;nofollow&quot;&gt;this link&lt;/a&gt; and code given on this link&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;const int buttonPin = 2;    // the number of the pushbutton pin&#xA;const int ledPin = 13;      // the number of the LED pin&#xA;&#xA;// Variables will change:&#xA;int ledState = HIGH;         // the current state of the output pin&#xA;int buttonState;             // the current reading from the input pin&#xA;int lastButtonState = LOW;   // the previous reading from the input pin&#xA;&#xA;// the following variables are long's because the time, measured in miliseconds,&#xA;// will quickly become a bigger number than can be stored in an int.&#xA;long lastDebounceTime = 0;  // the last time the output pin was toggled&#xA;long debounceDelay = 50;    // the debounce time; increase if the output flickers&#xA;&#xA;void setup() {&#xA;  pinMode(buttonPin, INPUT);&#xA;  pinMode(ledPin, OUTPUT);&#xA;&#xA;  // set initial LED state&#xA;  digitalWrite(ledPin, ledState);&#xA;}&#xA;&#xA;void loop() {&#xA;  // read the state of the switch into a local variable:&#xA;  int reading = digitalRead(buttonPin);&#xA;&#xA;  // check to see if you just pressed the button&#xA;  // (i.e. the input went from LOW to HIGH),  and you've waited&#xA;  // long enough since the last press to ignore any noise:  &#xA;&#xA;  // If the switch changed, due to noise or pressing:&#xA;  if (reading != lastButtonState) {&#xA;    // reset the debouncing timer&#xA;    lastDebounceTime = millis();&#xA;  }&#xA;&#xA;  if ((millis() - lastDebounceTime) &amp;gt; debounceDelay) {&#xA;    // whatever the reading is at, it's been there for longer&#xA;    // than the debounce delay, so take it as the actual current state:&#xA;&#xA;    // if the button state has changed:&#xA;    if (reading != buttonState) {&#xA;      buttonState = reading;&#xA;&#xA;      // only toggle the LED if the new button state is HIGH&#xA;      if (buttonState == HIGH) {&#xA;        ledState = !ledState;&#xA;      }&#xA;    }&#xA;  }&#xA;&#xA;  // set the LED:&#xA;  digitalWrite(ledPin, ledState);&#xA;&#xA;  // save the reading.  Next time through the loop,&#xA;  // it'll be the lastButtonState:&#xA;  lastButtonState = reading;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;and change &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt; long debounceDelay = 50;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;to 10(means read any thing ina time gap of 10 mili second) as the code says.Now what is happening, code is running on the board and after some time my board get hang and LED stop toggling on any press of push button and then i had to manually reset my board.I also want to add upon a thing that i am also using a serial port in between when LED toggles or switch is pressed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am totally confused why this is happening.There can beone possibility that this is happening because i reduced time gap between two consecutive events to 10 from 50 miliseconds and that might be making AVR get hanged and thus require a manual reset.&lt;/p&gt;&#xA;" OwnerUserId="1322" LastActivityDate="2013-12-26T10:26:42.393" Title="Arduino Uno getting a type of &quot;HANGED&quot; while runing samll code of switc debounce and Serial print" Tags="&lt;arduino&gt;&lt;c&gt;&lt;serial&gt;&lt;communication&gt;" AnswerCount="1" CommentCount="5" />
  <row Id="2084" PostTypeId="1" CreationDate="2013-11-20T16:25:12.700" Score="1" ViewCount="60" Body="&lt;p&gt;I have a bag file that contains couple of topics needed for localization, odometry data, kinect data and &lt;code&gt;/tf&lt;/code&gt;. What I want is watching robot's movement path in &lt;code&gt;rviz&lt;/code&gt; after initializing robot position (even I don't know how to initial it). Any help?&lt;/p&gt;&#xA;" OwnerUserId="2202" LastEditorUserId="2202" LastEditDate="2013-11-20T17:01:54.167" LastActivityDate="2013-11-20T17:01:54.167" Title="Fake localization using bag file in ROS" Tags="&lt;localization&gt;&lt;ros&gt;" CommentCount="6" />
  <row Id="2085" PostTypeId="2" ParentId="939" CreationDate="2013-11-21T05:03:51.717" Score="1" Body="&lt;p&gt;This guy put a spring in between his 2nd servo to protect them from any slight differences... Maybe this is what you're looking for? &lt;a href=&quot;http://youtu.be/jqsmai2Nafk?t=1m13s&quot; rel=&quot;nofollow&quot;&gt;http://youtu.be/jqsmai2Nafk?t=1m13s&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="2266" LastActivityDate="2013-11-21T05:03:51.717" />
  <row Id="2086" PostTypeId="2" ParentId="2027" CreationDate="2013-11-21T08:26:32.620" Score="1" Body="&lt;p&gt;amcl receives the integrated odometry information over the tf topic between base_link and odom and then computes the correction between the odom frame and the map frame as the odometry accumulates drift. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Framed defined in &lt;a href=&quot;http://www.ros.org/reps/rep-0105.html&quot; rel=&quot;nofollow&quot;&gt;REP 105&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="161" LastActivityDate="2013-11-21T08:26:32.620" />
  <row Id="2087" PostTypeId="1" CreationDate="2013-11-22T12:48:56.097" Score="0" ViewCount="48" Body="&lt;p&gt;I am making a mobile base for a robot with wheels. I want to use a Kinect like a movement sensor (to avoid obstacles, recognition of people, etc...) but I read that there is 2 models, the 360 and the Developer.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Which Kinect works well for my job? And another thins, its there another thing that can I use like a movement sensor? To see diferent posibilities,&lt;/p&gt;&#xA;" OwnerUserId="2269" LastActivityDate="2013-11-22T12:48:56.097" Title="Which Kinect to a movement base?" Tags="&lt;mobile-robot&gt;&lt;wheeled-robot&gt;&lt;kinect&gt;" CommentCount="3" ClosedDate="2014-01-14T19:52:09.713" />
  <row Id="2088" PostTypeId="1" CreationDate="2013-11-23T12:37:27.940" Score="4" ViewCount="58" Body="&lt;p&gt;For a certain robotic application (actually for the FTC challenge this year) our team is performing an operation where a servo-driven arm could potentially be forced into an unknown position. We are using NXT+Tetrix.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Since this could damage a powered servo working against this forced position (servo holding arm weight on fixed base is now trying to move heavy base relative to fixed arm), we are thinking about somehow de-powering our servos (or servo controller), in order to get the servos to &quot;relax&quot; and accept the mechanically-forced position.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Originally, we were thinking of having our RobotC code determine the physical position of a given servo and set its desired position to there every loop, limiting how much a servo would try to fight the movement, but to our dismay, &lt;code&gt;ServoValue[fooServo]&lt;/code&gt; actually gives us the setpoint, and not the physical location (due to the servo being unable to provide this information).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We also considered setting &lt;code&gt;ServoChangeRate[fooServo]&lt;/code&gt; to 1(the minimal value) but this only changes the rate of the target location changing relative to the previous target.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, we're concluding that the only way to really do this is to fully depower the servos. Is this possible on NXT/Tetrix with RobotC?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A few notes:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;I realized as well that one could suggest to rig an encoder(associated with a Tetrix motor that does not need an encoder) onto the rotating area. That actually would not work for mechanical constraints.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;I looked into setting &lt;code&gt;PWM enable&lt;/code&gt; as shown &lt;a href=&quot;http://stuyfissionfusiondevelopment.googlecode.com/files/HiTechnic%20Servo%20Controller%20Brief%20v1.2.pdf&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt; but am not sure how to send the i2c commands needed. If someone could clue me in to how these commands would be sent in terms of c code, that would be very helpful.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="964" LastEditorUserId="964" LastEditDate="2013-11-25T21:35:17.363" LastActivityDate="2013-11-25T21:35:17.363" Title="Powering down servos completely in RobotC+Tetrix" Tags="&lt;power&gt;&lt;rcservo&gt;&lt;nxt&gt;&lt;robotc&gt;" CommentCount="1" />
  <row Id="2089" PostTypeId="1" CreationDate="2013-11-24T06:28:48.743" Score="1" ViewCount="47" Body="&lt;p&gt;I recently purchased at EY-80 from electrodragon: &lt;a href=&quot;http://www.electrodragon.com/?product=all-in-one-9-axis-motion-sensor-gyroscope-accelerometer-magnetometer-barometer&quot; rel=&quot;nofollow&quot;&gt;EY-80 All in one 9-Axis Motion Sensor (Gyro + Acceler + Magneto + Baro)&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am having a hard time compiling the &lt;a href=&quot;https://github.com/Edragon/Arduino_sketch/wiki&quot; rel=&quot;nofollow&quot;&gt;example code&lt;/a&gt; on my arduino:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/C7xKr.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is what is happening.  So far, I am only copy and pasting the code.  Any help? (I am somewhat new to programming, so don't fully understand all of the code)&lt;/p&gt;&#xA;" OwnerUserId="779" LastEditorUserId="37" LastEditDate="2013-11-25T12:07:56.047" LastActivityDate="2013-11-25T17:43:30.723" Title="Compiling Code for EY-80" Tags="&lt;arduino&gt;&lt;sensors&gt;&lt;gyroscope&gt;" AnswerCount="1" CommentCount="2" />
  <row Id="2090" PostTypeId="1" CreationDate="2013-11-24T11:09:41.173" Score="4" ViewCount="84" Body="&lt;p&gt;I am about to make an rc car which uses a wifi connection. The body for the car would be made from aluminium and the wifi receiver will be placed inside this aluminium casing. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;How do I make sure that this will work?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Would I be forced to change my material or can I just make an extension for the receiver and make sure it is out of the casing? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If so , would that really help me?&lt;/p&gt;&#xA;" OwnerUserId="1989" LastActivityDate="2013-11-28T20:30:29.987" Title="Wifi to pass through aluminium" Tags="&lt;wifi&gt;" AnswerCount="2" CommentCount="1" />
  <row Id="2091" PostTypeId="1" CreationDate="2013-11-24T23:38:07.977" Score="3" ViewCount="217" Body="&lt;p&gt;I am using an Arduino Uno to control an ESC for my (in progress) quadrocopter.  I am currently using the servo library to control the ESC, which works great.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Except..&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A count of 100 is max speed, meaning I only have 10 speeds between 90 (stopped) and 100 (motor at full power) to correctly run my quadrocopter, I would like to have many more speed options.  Any ideas?  I'm having a hard time using a PWM signal, I might not be doing it right though.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My current code is &lt;a href=&quot;https://github.com/toozinger/Quad/blob/master/run_motor_as_servo.ino&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#include &amp;lt;Servo.h&amp;gt;&#xA;&#xA;Servo myservo; // create servo object to control a servo&#xA;                // a maximum of eight servo objects can be created&#xA;&#xA;int pos = 0; // variable to store the servo position&#xA;&#xA;void setup()&#xA;{&#xA;  myservo.attach(8); // attaches the servo on pin 8 to the servo object&#xA;}&#xA;&#xA;void loop()&#xA;{&#xA;&#xA; int maxspeed=100;&#xA; int minspeed=0;&#xA; int delaytime=5;&#xA; int count;&#xA;&#xA; for(count=0; count &amp;lt;1; count+=1) {&#xA;  for(pos = minspeed; pos &amp;lt; maxspeed; pos += 1) // goes from 0 degrees to 180 degrees&#xA;  { // in steps of 1 degree&#xA;    myservo.write(pos); // tell servo to go to position in variable 'pos'&#xA;    delay(delaytime); // waits 15ms for the servo to reach the position&#xA;  }&#xA;  for(pos = maxspeed; pos&amp;gt;=minspeed; pos-=1) // goes from 180 degrees to 0 degrees&#xA;  {&#xA;    myservo.write(pos); // tell servo to go to position in variable 'pos'&#xA;    delay(delaytime); // waits 15ms for the servo to reach the position&#xA;  }&#xA;  if(count&amp;gt;1){&#xA;    break;&#xA;  }&#xA; }&#xA;&#xA; myservo.write(92);&#xA; delay(100000);&#xA; myservo.write(90);&#xA; delay(10000000);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="779" LastEditorUserId="37" LastEditDate="2013-11-25T12:20:51.923" LastActivityDate="2013-11-25T13:50:16.310" Title="How to use Arduino for ESC control?" Tags="&lt;arduino&gt;&lt;control&gt;&lt;quadcopter&gt;&lt;esc&gt;&lt;servomotor&gt;" AnswerCount="2" FavoriteCount="2" />
  <row Id="2092" PostTypeId="2" ParentId="2090" CreationDate="2013-11-24T23:59:31.227" Score="5" Body="&lt;p&gt;You can use an external onmidirectional wifi antenna, like &lt;a href=&quot;http://www.ebay.com/sch/i.html?_nkw=omni%20wifi%20antenna&amp;amp;_fscr=1&quot; rel=&quot;nofollow&quot;&gt;these on ebay&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If your wifi chip does not have a U-FL connector, you can use a SMA to U-FL adapter or directly a SMA Antenna.&lt;/p&gt;&#xA;" OwnerUserId="2281" LastEditorUserId="37" LastEditDate="2013-11-25T12:14:39.773" LastActivityDate="2013-11-25T12:14:39.773" />
  <row Id="2093" PostTypeId="2" ParentId="2091" CreationDate="2013-11-25T02:54:30.603" Score="3" Body="&lt;p&gt;Your code uses the typical &lt;code&gt;servo.attach(pin)&lt;/code&gt; where you can use the overload of &lt;code&gt;servo.attach(pin, min, max)&lt;/code&gt; to set the min and max microseconds of the pulse width to match the desired ranges for you ESC. Additionally to make it a bit more clear where &lt;code&gt;myservo.write(90);&lt;/code&gt; is used to set the angle, you can use &lt;code&gt;myservo.writeMicroseconds(1500);&lt;/code&gt; to set the duration of the pulse directly in microseconds. &lt;/p&gt;&#xA;" OwnerUserId="821" LastEditorUserId="37" LastEditDate="2013-11-25T12:21:34.817" LastActivityDate="2013-11-25T12:21:34.817" />
  <row Id="2094" PostTypeId="2" ParentId="2091" CreationDate="2013-11-25T13:50:16.310" Score="3" Body="&lt;p&gt;The servo.write(angle) function is designed to accept angles from 0 to 180.&#xA;(The value 180 is significantly larger than 100).&#xA;Could you tell me where in &lt;a href=&quot;http://playground.arduino.cc/ComponentLib/Servo&quot; rel=&quot;nofollow&quot;&gt;the Servo documentation&lt;/a&gt; you read &quot;&lt;em&gt;100 (motor at full power)&lt;/em&gt;&quot;, so we can fix that typo?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Please change the line&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;int maxspeed=100; /* wrong */&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;to&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;int maxspeed=180;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Also, please run &lt;code&gt;servo.refresh()&lt;/code&gt; periodically to keep the servos updated -- perhaps something like:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;for(pos = maxspeed; pos&amp;gt;=minspeed; pos-=1) // goes from 180 degrees to 0 degrees&#xA;{&#xA;    myservo.write(pos); // set the servo position&#xA;    myservo.refresh(); // tell servo to go to the set position&#xA;    delay(delaytime); // waits 15ms for the servo to reach the position&#xA;};&#xA;// ...&#xA;myservo.write(92);&#xA;for( long int delaytime = 0; delaytime &amp;lt; 100000; delaytime+=10 ){&#xA;    myservo.refresh(); // tell servo to go to the set position&#xA;    delay(10);&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;As mpflaga pointed out, you can get more precision by setting the pulse width directly in microseconds with&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;myservo.writeMicroseconds(1000); // typical servo minimum; some go down to 600 or less&#xA;myservo.writeMicroseconds(2000); // typical servo maximum; some go up to 2500 or more&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;p.s.:&#xA;Have you seen &lt;a href=&quot;http://arduino.cc/en/Tutorial/BlinkWithoutDelay&quot; rel=&quot;nofollow&quot;&gt;&quot;blink without delay&quot;&lt;/a&gt; ?&#xA;That technique makes it much easier to read sensors and update servo positions with consistent heartbeat timing.&lt;/p&gt;&#xA;" OwnerUserId="187" LastActivityDate="2013-11-25T13:50:16.310" CommentCount="1" />
  <row Id="2095" PostTypeId="2" ParentId="2089" CreationDate="2013-11-25T17:43:30.723" Score="1" Body="&lt;p&gt;After talking to a friend, I found out what I did wrong.&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;I needed to include all of the #include libraries.&lt;/li&gt;&#xA;&lt;li&gt;I downloaded one of the libraries in html, instead of raw .h format which was messing up the program, so I downloaded the correct version.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;The program is now working, and collecting data well!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you find your readings to be off, change the update delay from 500ms to 20ms and the readings will drastically improve.&lt;/p&gt;&#xA;" OwnerUserId="779" LastActivityDate="2013-11-25T17:43:30.723" />
  <row Id="2096" PostTypeId="1" CreationDate="2013-11-27T07:59:50.847" Score="4" ViewCount="42" Body="&lt;p&gt;I'm trying to add my own robot in Morse 1.1 (using Ubuntu 12.04). I am struggling to add an armature actuator and armature pose sensor to an existing robot. Can someone please explain how this can be done (preferably with some sample code and using the socket interface).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks. &lt;/p&gt;&#xA;" OwnerUserId="2292" LastActivityDate="2013-11-27T07:59:50.847" Title="Using Armatures in Morse Robotic Simulator" Tags="&lt;mobile-robot&gt;&lt;sensors&gt;&lt;simulator&gt;&lt;python&gt;" />
  <row Id="2097" PostTypeId="2" ParentId="2090" CreationDate="2013-11-28T20:30:29.987" Score="0" Body="&lt;p&gt;Your Wifi signals should be able to penetrate aluminum. Wifi uses radio waves which can go through some thick material. I know that Wifi signals pass through steel. The best way for you to know is to try. If it does not work, drill a hole in your casing and use an antennae.&lt;/p&gt;&#xA;" OwnerUserId="1309" LastActivityDate="2013-11-28T20:30:29.987" />
  <row Id="2098" PostTypeId="1" CreationDate="2013-11-29T06:02:52.177" Score="1" ViewCount="83" Body="&lt;p&gt;I searched for GPS devices that provide 1 sec updates to server, but I have not found any.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I found this &lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;T=30s.Module has sent a monitoring data packet. After 12 seconds the&#xA;  server sends an acknowledgement. In 18 seconds later (T = 30s) module&#xA;  sends the next monitoring data packet&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Are there any products that take less than this time?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Why do gps devices take this much time to send data?&lt;/p&gt;&#xA;" OwnerUserId="2301" LastEditorUserId="350" LastEditDate="2013-11-30T15:36:42.660" LastActivityDate="2013-11-30T16:28:57.007" Title="Are there any GPS sensors that provide data at 1Hz or faster?" Tags="&lt;sensors&gt;&lt;gps&gt;" AnswerCount="2" />
  <row Id="2100" PostTypeId="2" ParentId="2098" CreationDate="2013-11-29T21:25:35.530" Score="1" Body="&lt;p&gt;Many GPS receivers will output data more often than 1Hz. For example, the &lt;a href=&quot;https://www.sparkfun.com/products/11058&quot; rel=&quot;nofollow&quot;&gt;Venus GPS&lt;/a&gt;, which can produce readings at 10Hz.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/JjnBp.jpg&quot; alt=&quot;Venus GPS&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2013-11-29T21:25:35.530" />
  <row Id="2101" PostTypeId="1" CreationDate="2013-11-29T21:40:42.333" Score="3" ViewCount="90" Body="&lt;p&gt;As I understand it, a Kalman filter uses a mathematical model of the robot to predict the robot's state at t+1. It then combines that prediction with information from sensors to get a better sense of the state.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If the robot is an aeroplane, how accurate/realistic does the model need to be? Can I get away with simple position and velocity, or do I therefore need an accurate flight model with computational fluid dynamics?&lt;/p&gt;&#xA;" OwnerUserId="40" LastActivityDate="2014-01-09T18:39:09.647" Title="Do I need an accurate flight model for a UAV?" Tags="&lt;kalman-filter&gt;&lt;uav&gt;" AnswerCount="1" FavoriteCount="1" />
  <row Id="2103" PostTypeId="2" ParentId="2098" CreationDate="2013-11-30T16:28:57.007" Score="1" Body="&lt;p&gt;The 1-second processing time is based on the fact that GPS technology uses &lt;a href=&quot;http://en.wikipedia.org/wiki/Code_division_multiple_access&quot; rel=&quot;nofollow&quot;&gt;CDMA&lt;/a&gt; to allow the receiver to pick up all satellite signals simultaneously.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;For GPS to work, your receiver must perform several steps:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(Step 0) Locate which satellites are overhead (this can be assisted by something called an &lt;a href=&quot;http://en.wikipedia.org/wiki/GPS_signals#Almanac&quot; rel=&quot;nofollow&quot;&gt;almanac&lt;/a&gt;).  This step only happens when the unit is first powered on.&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;The signals from all visible satellites are received one the same frequencies simultaneously, and amplified.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;The spread-spectrum digital signal is extracted by mixing the received signal with a local carrier (&lt;a href=&quot;http://www.ele.uri.edu/Courses/ele436/labs/DSSS.pdf&quot; rel=&quot;nofollow&quot;&gt;more info, PDF&lt;/a&gt;).&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;For each satellite (of at least 4), a pseudo-random code is generated to match the code of that given satellite.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;The remote (sender) and local (receiver) codes are synchronized.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;The incoming signal is decoded using the now-synchronized code. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;The decoded signal contains a known pseudorandom sequence, which is matched against a local sequence to determine the distance from the satellite that transmitted the signal (this is based on the time offset between the sequences).  &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;When all signals have been decoded, any clock inaccuracies are corrected and the position can be calculated.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Repeat.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Notice that each satellite's signal has its own code, which helps it stand out from all the other satellite signals.  Simpler GPS units will process these decoding steps sequentially, while more sophisticated units use multiple receivers to process the signals in parallel.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can further speed up the reporting rate of a GPS by combining the updates with an estimation based on odometry, an accelerometer, etc.  &lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-11-30T16:28:57.007" />
  <row Id="2104" PostTypeId="1" AcceptedAnswerId="2129" CreationDate="2013-11-30T21:58:59.943" Score="2" ViewCount="43" Body="&lt;p&gt;I'm trying to figure out a way that I can calculate the probability that a particle will survive the re-sampling step in the particle filter algorithm.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For the simple case of multinomial re-sampling, I can assume that we can model the process like a Binomial distribution if we only care about one sample/particle.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So if the particle was a weight of w that is also the probability that it will get selected in a step of the re-sampling. So we use 1 - P(k, p, n) where P is the Binomial distribution, k is 0 (we did not select the particle in all our tries), p is equal to w and n is equal to M, the number of particles.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What is the case though in the systematic re-sampling, where the probability of a particles being selected is proportional but not equal to its weight?&lt;/p&gt;&#xA;" OwnerUserId="2309" LastActivityDate="2013-12-07T17:57:17.470" Title="How to calculate probability of particle survival for particle filter?" Tags="&lt;particle-filter&gt;" AnswerCount="1" CommentCount="2" />
  <row Id="2105" PostTypeId="1" AcceptedAnswerId="2113" CreationDate="2013-12-01T02:11:11.960" Score="2" ViewCount="141" Body="&lt;p&gt;Basically, I want to detect an ultrasonic beacon in a radius around the robot.&#xA;The beacon would have a separate ultrasonic emitter while the robot would have the spinning receiver.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Are there any existing ultrasonic sensors that would meet this use case or am I stuck hacking one together myself?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is ultrasonic even the best choice? I was hoping that the beacon would be kept in a pocket, so I figured optical sensors were out.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Edit: The beacon and robot will both be mobile so fixed base stations are not an option.&lt;/p&gt;&#xA;" OwnerUserId="1952" LastEditorUserId="1952" LastEditDate="2013-12-01T21:31:26.810" LastActivityDate="2013-12-12T06:58:37.410" Title="360 degree ultrasonic beacon sensor" Tags="&lt;sensors&gt;" AnswerCount="2" CommentCount="3" />
  <row Id="2106" PostTypeId="1" CreationDate="2013-12-01T20:19:07.187" Score="2" ViewCount="72" Body="&lt;p&gt;Having read the article &quot;This Car Has Electric Brains&quot; in Popular Mechanics, August 1958 (&lt;a href=&quot;http://books.google.com/books?id=jd8DAAAAMBAJ&amp;amp;lpg=PA128&amp;amp;dq=automatic%20car&amp;amp;pg=PA128#v=onepage&amp;amp;q&amp;amp;f=false&quot; rel=&quot;nofollow&quot;&gt;http://books.google.com/books?id=jd8DAAAAMBAJ&amp;amp;lpg=PA128&amp;amp;dq=automatic%20car&amp;amp;pg=PA128#v=onepage&amp;amp;q&amp;amp;f=false&lt;/a&gt;) I have some questions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How practical were his methods? Was his work acquired by a car manufacturer or some other company? Were his methods developed futher?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How did his corner navigation work? I don't think he needed to know the distances of road segments; I think he could have used sonar or radar to detect a corner but if cars were entering the corner before him, he could misinterpret those cars as a wall and the absence of a corner. Additionaly I think he'd need two sonar/radar systems on both sides of the cars which aren't mentioned; all that's mentioned is a set of relays.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What is the compensator that is mentioned (it's said to function as a gyroscope)? I cannot find any information on this device (that I'm sure is relevant).&lt;/p&gt;&#xA;" OwnerUserId="2310" LastEditorUserId="2310" LastEditDate="2013-12-01T20:24:23.510" LastActivityDate="2013-12-01T20:24:23.510" Title="What happened to Butler's car?" Tags="&lt;design&gt;&lt;navigation&gt;" CommentCount="2" />
  <row Id="2107" PostTypeId="2" ParentId="758" CreationDate="2013-12-02T17:18:37.163" Score="0" Body="&lt;p&gt;I test positive for aspergers syndrome on highly validated tests and I can read facial expressions sufficiently well to notice certain patterns in my daily interactions and one of the most noticeable &quot;common&quot; patterns is the disgust/revulsion pattern. The sequencing is pretty simple, I start talking, within 500ms of hearing my talking, the face of the respondent contorts in a most hideous way, and then they immediately start wanting to leave/get-away by whatever means possible. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Researching the uncanny valley, as part of my studies into all things related to aspergers syndrome, I couldn't help but notice the similarity of the reactions I get and the reactions described on wikipedia.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Knowing of the evolutionary significance of autism spectrum disorders (Mainly, less of them work, they earn less money on average and, anecdotally, they tend to have fewer friends/girlfriends than average... and money has its evolutionary underpinnings...), it would seem to me there's probably an evolutionary connection between autism and the uncanny valley concept.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now, according to the tests, I'm a &quot;light sufferer&quot;(I feel like I suffer plenty, though, BELIEVE me.), so I can read facial expressions in a way that more severely affected apparently can't(?). So, I appear to be right between the extremes of blends-in-and-reads-people-well/doesn't-blend-in-and-can't-read-people-well, getting the worst of both worlds.&lt;/p&gt;&#xA;" OwnerUserId="2314" LastActivityDate="2013-12-02T17:18:37.163" />
  <row Id="2108" PostTypeId="2" ParentId="39" CreationDate="2013-12-02T18:00:12.543" Score="0" Body="&lt;p&gt;The robotics team I lead at NCSU has implemented the ability to drive our holonomic robot using a Leap motion controller. Here's a &lt;a href=&quot;https://www.youtube.com/watch?v=BDgmRz1Gb7Q#t=0&quot; rel=&quot;nofollow&quot;&gt;demo video&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Our codebase is in Python, so we used the Python Leap library, which was quite simple and friendly. Our Leap-related code is only about 150 lines. Our client basically takes pitch, yaw and roll data from the Leap controller and converts it into movements, which it uses to make calls to our bot's API using ZMQ. I can share the code with you if you're interested in additional details (currently in a private GitHub repo pending our contest, but it's open sourced under the BSD two-clause license).&lt;/p&gt;&#xA;" OwnerUserId="2173" LastActivityDate="2013-12-02T18:00:12.543" />
  <row Id="2109" PostTypeId="1" CreationDate="2013-12-02T20:52:32.100" Score="2" ViewCount="26" Body="&lt;p&gt;POMDPs are used when we cannot observe all the states.&#xA;However, I cannot figure out when these POMDPs can be useful in robotics. What is a good example of the use of POMDPs? (I have read one paper where they used them, but I didn't find it obvious why pomdps should be used) What would be good projects ideas based on POMDPs?&lt;/p&gt;&#xA;" OwnerUserId="2316" LastEditorUserId="2316" LastEditDate="2013-12-02T21:01:06.863" LastActivityDate="2013-12-03T18:10:47.260" Title="POMDPs in robotics" Tags="&lt;algorithm&gt;&lt;artificial-intelligence&gt;" AnswerCount="1" CommentCount="1" FavoriteCount="1" />
  <row Id="2110" PostTypeId="1" AcceptedAnswerId="2112" CreationDate="2013-12-02T22:23:42.537" Score="1" ViewCount="112" Body="&lt;p&gt;I have a WL v262 quadcopter and I want to control it using Arduino instead of the joysticks on the transmitter. I opened up the transmitter and saw that each joystick has 2 potentiometers on the PCB and that the voltage for each pot goes from 0-3.3V. I used arduino's PWM and a low pass filter and connected the output of the filtered output to the potentiometer's analog pin which is connected to the PCB (I cannot desolder and take out the pots from the PCB) but even with this $V_{out}$ going onto the analog pin, my transmitter's display gave ???? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now I am really confused and frustrated because I don't know how else to control this transmitter other than attaching stepper motors to the joysticks and manually controlling the transmitter but this is really my last resort. Can someone help me with this? I have spent hours and hours trial and error but I am getting nowhere. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here is the PCB of the transmitter:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/Kd2Rw.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/vxRRg.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;" OwnerUserId="2318" LastEditorUserId="350" LastEditDate="2013-12-05T16:14:35.830" LastActivityDate="2013-12-05T16:14:35.830" Title="RC Transmitter Quadcopter with Arduino" Tags="&lt;arduino&gt;&lt;sensors&gt;&lt;radio-control&gt;&lt;wireless&gt;" AnswerCount="1" />
  <row Id="2111" PostTypeId="1" CreationDate="2013-12-02T22:40:44.637" Score="2" ViewCount="128" Body="&lt;p&gt;A Google search on &quot;bloodstream nanobots&quot; yields thousands of results and just on the first page, many results of blog posts that date back to 2009. It is nearly 4 years later. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've had no luck in finding any information on actual APPROVAL of these bots.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Are there any countries at all who have approved this? People seem to have talked about it like crazy 4 years ago, yet, we're still not seeing anything.&lt;/p&gt;&#xA;" OwnerUserId="2319" LastEditorUserId="1445" LastEditDate="2013-12-22T12:49:32.957" LastActivityDate="2013-12-22T12:49:32.957" Title="Have bloodstream nanobots been approved in any countries?" Tags="&lt;microcontroller&gt;" AnswerCount="1" />
  <row Id="2112" PostTypeId="2" ParentId="2110" CreationDate="2013-12-03T00:51:06.893" Score="1" Body="&lt;p&gt;Did it actually output only &quot;????&quot;&#xA;Does removing the PWM restore normal operation?&#xA; It is likely that the load from the PWM is not initially within correct voltage range at RC's bootup and it is detecting this and faulting.&#xA;With the Pot's still inplace the range will be limited, but you could try to match it. Initially (and even while ????'ing) try to set the PWM's output to be the same voltage as when it is not connected. This may solve your ???? problem.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I also note from your picture the Transmitter module at top between joy sticks. I would suspect that you can better decipher the stream of information sent into this module by the controller and send your own information. This would be similar to what I did for &lt;a href=&quot;https://github.com/mpflaga/Arduino-IRremote&quot; rel=&quot;nofollow&quot;&gt;IR Helicopter controllers &lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="821" LastActivityDate="2013-12-03T00:51:06.893" CommentCount="3" />
  <row Id="2113" PostTypeId="2" ParentId="2105" CreationDate="2013-12-03T01:25:17.250" Score="0" Body="&lt;p&gt;If you were to place 3 ultrasonic microphones/sensors in a triangle layout you should be able to determine the direction of the beacon based on the time difference the ping arrives at each sensor with some straightforward trigonometry. They'd all have to be facing in the same direction (probably upwards) and you may have to find some way to make them omnidirectional. The further apart you can space the sensors, the more accurate the calculation will be.&lt;/p&gt;&#xA;" OwnerUserId="366" LastActivityDate="2013-12-03T01:25:17.250" CommentCount="12" />
  <row Id="2114" PostTypeId="1" AcceptedAnswerId="2118" CreationDate="2013-12-03T17:00:28.630" Score="2" ViewCount="46" Body="&lt;p&gt;I am interested in getting an arducopter with an ardupilot(APM). I read through the documentation and from what I understand, ardupilot is the low level hardware and firmware that directly controls the motors of the arducoptor. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would like to know if there is a higher level programmatic interface to the ardupilot? The mission planner provides a user interface to control the ardupilot. But is there a programmatic interface to control it?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In other words, would it be possible for a user written 'linux process' to receive and send sensory data to and from the ardupilot respectively?&lt;/p&gt;&#xA;" OwnerUserId="466" LastEditorUserId="350" LastEditDate="2013-12-05T16:07:04.070" LastActivityDate="2013-12-05T16:07:04.070" Title="sending and receiving parameters to ardupilot" Tags="&lt;quadrotor&gt;&lt;ardupilot&gt;" AnswerCount="1" />
  <row Id="2115" PostTypeId="2" ParentId="2109" CreationDate="2013-12-03T18:10:47.260" Score="1" Body="&lt;p&gt;A good rule of thumb is that where ever an MDP is useful in theory a POMDP would likely need to be used in reality.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To answer your question directly I would direct you to some of the latest work coming out of the &lt;a href=&quot;http://arl.cs.utah.edu/&quot; rel=&quot;nofollow&quot;&gt;Algorithmic Robotics Lab&lt;/a&gt;. My advisor and I recently developed a method wherein we use a POMDP at the core of a new grey-box system identification method. In this method we know an approximate kinematic or dynamic model of the robot in question. We do not however know some of the associated parameters (e.g. mass, center of mass). One way to learn the parameters is to use an extended Kalman filter (EKF) to monitor the system while the motor babbling. However more can be learned if the dynamics are excited correctly. To achieve this part we use a POMDP to plan controls. The details can be found in our paper &lt;a href=&quot;http://arl.cs.utah.edu/research/ope/&quot; rel=&quot;nofollow&quot;&gt;Online Parameter Estimation via Real-time Replanning of Continuous Gaussian POMDPs&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2013-12-03T18:10:47.260" CommentCount="1" />
  <row Id="2116" PostTypeId="2" ParentId="1083" CreationDate="2013-12-03T22:33:04.933" Score="0" Body="&lt;p&gt;For the i =2, with alpha(i-1), it should be 0 if Z1 and Z2 are parallel &lt;/p&gt;&#xA;" OwnerUserId="2322" LastActivityDate="2013-12-03T22:33:04.933" CommentCount="1" />
  <row Id="2117" PostTypeId="1" CreationDate="2013-12-03T22:49:16.563" Score="3" ViewCount="59" Body="&lt;p&gt;For examples if i have this robotic arm:&#xA;&lt;a href=&quot;http://www.youtube.com/watch?v=bKafht51Juw&quot; rel=&quot;nofollow&quot;&gt;Example&lt;/a&gt;, for the base rotation (5th DOF in the clip at 0:58), we know that the Z axis for that joint will be the same as the Z axis for the base frame{0}, but I don't know about Y and Z axises of the base rotation respects to the base frame, should they be the same or not ?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And one more thing, for defining the frame of the base rotation (at 0:58 in the clip), the vertical arm pitch (at 0.47 in the clip) and the horizontal arm pitch (at 0:46 in the clip), it's pretty easy, but I don't know how to continue for defining the frame of wrist roll (at o.12 in the clip) and wrist pitch (0.23 in the clip) since the angle between the Z axis of wrist roll and the wrist pitch is now 90o.&#xA;&lt;br&gt; Thank you very much.&lt;/p&gt;&#xA;" OwnerUserId="2322" LastActivityDate="2013-12-06T14:43:58.753" Title="Defining frames for 5DOF robotics arm" Tags="&lt;localization&gt;&lt;kinematics&gt;&lt;robotic-arm&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="2118" PostTypeId="2" ParentId="2114" CreationDate="2013-12-03T22:52:47.857" Score="1" Body="&lt;p&gt;Yes, there is programmatic interface. Like many autopilot systems the Ardupilot uses a protocol called &lt;a href=&quot;http://qgroundcontrol.org/mavlink/start&quot; rel=&quot;nofollow&quot;&gt;Mavlink&lt;/a&gt;. It allows for both sending commands and receiving telemetry data. It also allows for managing the data that is sent to the ground control system to avoid overburdening ones communication link. There is support for Mavlink in C and python as well as a ROS library (see &lt;a href=&quot;https://github.com/mavlink&quot; rel=&quot;nofollow&quot;&gt;Mavlink Github&lt;/a&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Furthermore this can be used for onboard control via a single board computer (SBC) such as a Raspberry Pi, Gumstix, or PCduino by interfacing the preferred SBC with the Ardupilot XBee port which is really just a TTL level serial.&lt;/p&gt;&#xA;" OwnerUserId="177" LastEditorUserId="177" LastEditDate="2013-12-04T06:53:26.297" LastActivityDate="2013-12-04T06:53:26.297" CommentCount="2" />
  <row Id="2119" PostTypeId="1" CreationDate="2013-12-04T17:35:23.833" Score="2" ViewCount="120" Body="&lt;p&gt;For a university course I have been asked to design a rough &quot;specification&quot; for a system that will deburr a plastic box that appears in a workspace. Due to irregularities in the boxes edges I cannot use simple position control and must use force control.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have so far decided on;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Using an IR sensor to detect the box has appeared in the workspace.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Use an Epson 2 axis robot to move around the work piece&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Use an ATI 6 axis force sensor to maintain a constant force against the edge of the box as the deburrer/robot moves around it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there a simple means of detecting the end of each side of the box ?&#xA;A 0N force value would indicate reaching the edge of a box but it could also mean a breakage in the box which was also specified. How can I distinguish between the two ?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also does my work so far sound sensible ?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks for any help&lt;/p&gt;&#xA;" OwnerUserId="2330" LastActivityDate="2013-12-17T23:54:08.467" Title="Deburring Robot (Plastic Box)" Tags="&lt;control&gt;" AnswerCount="3" />
  <row Id="2120" PostTypeId="2" ParentId="2119" CreationDate="2013-12-05T00:06:44.130" Score="0" Body="&lt;p&gt;Supposing all the boxes (or all the boxes being run in a batch) are the same size, and that they have rectangular cross-sections, consider fastening an L-shaped fixture to the workspace surface, at a location somewhat aside from the point where the box usually appears.  When the box does appear, push it against the L stop via a moving L-shaped fixture that is spring-loaded and has a fair amount of travel.  Upon detecting that the springs have compressed enough (or upon activation of limit switches, etc.) latch the moving L into place.  Now the box's  orientation (that is, which of four possible rotations has occurred) can be tested using force sensors, limit switches, or optical sensors.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Even with the box in a known location and orientation, it appears (from your mention of box-edge irregularities) that use of force sensors still is necessary, but presumably you will know where the end-product edges should be, so can keep deburring until the force sensors indicate close-enough results.&lt;/p&gt;&#xA;" OwnerUserId="478" LastActivityDate="2013-12-05T00:06:44.130" CommentCount="1" />
  <row Id="2121" PostTypeId="1" CreationDate="2013-12-05T01:15:41.073" Score="4" ViewCount="38" Body="&lt;p&gt;Suppose I have a particle filter which contains an attitude state (we'll use a unit quaternion from the body to the earth frame for this discussion) $\mathbf{q}_b^e$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What methods should or should not be used for resampling? Many resampling schemes (e.g. &lt;a href=&quot;http://www.stat.columbia.edu/~liam/teaching/neurostat-spr12/papers/EM/resampling.pdf&quot; rel=&quot;nofollow&quot;&gt;this paper&lt;/a&gt;) seem to require the variance to be calculated at some stage, which is not trivial for $SO\{3\}$. Or, the variance is required when performing roughening.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Are there any good papers on resampling attitude states?  Especially those that re-sample complete poses (e.g. position and attitude)?&lt;/p&gt;&#xA;" OwnerUserId="959" LastEditorUserId="177" LastEditDate="2013-12-05T03:19:20.263" LastActivityDate="2013-12-06T16:35:49.323" Title="Resampling attitude states (quaternions, rotation matrix) in a Particle Filter" Tags="&lt;particle-filter&gt;&lt;attitude&gt;&lt;pose&gt;" AnswerCount="1" />
  <row Id="2122" PostTypeId="2" ParentId="344" CreationDate="2013-12-05T20:39:39.243" Score="1" Body="&lt;p&gt;There is a nice closed form to this.  Let's say that we don't care what $r_z$ is (i.e. we don't care how we &lt;em&gt;change&lt;/em&gt; it).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$&#xA;\mathbf{J}^{-1}\dot{\mathbf{X}}=&#xA;\dot{\mathbf{\Theta}}=&#xA;\begin{bmatrix}&#xA;\vec{j_{1}} &amp;amp; \vec{j_{2}} &amp;amp; \vec{j_{3}} &amp;amp; \vec{j_{4}} &amp;amp; \vec{j_{5}} &amp;amp; \vec{j_{6}}&#xA;\end{bmatrix}&#xA;\begin{bmatrix}&#xA;\dot{x}\\&#xA;\dot{y}\\&#xA;\dot{z}\\&#xA;\dot{r_x}\\&#xA;\dot{r_y}\\&#xA;\dot{r_z}&#xA;\end{bmatrix}&#xA;=&#xA;\begin{bmatrix}&#xA;\dot{\theta_1}\\&#xA;\dot{\theta_2}\\&#xA;\dot{\theta_3}\\&#xA;\dot{\theta_4}\\&#xA;\dot{\theta_5}\\&#xA;\dot{\theta_6}\\&#xA;\end{bmatrix}&#xA;$$&#xA;Where $\vec{j_{i}}$ is the $i^{th}$ column of $\mathbf{J}^{-1}$.&#xA;We can break up $\dot{\mathbf{\Theta}}$ into the portion that depends on $\dot{r_z}$ and the portion that doesn't.&#xA;$$&#xA;\dot{\mathbf{\Theta}}=&#xA;\dot{\mathbf{\Theta}}_{\dot{x}\dots \dot{r_y}} + \dot{\mathbf{\Theta}}_{\dot{r_z}}&#xA;\\&#xA;\dot{\mathbf{\Theta}}_{\dot{r_z}}=&#xA;\vec{j_{6}}&#xA;\dot{r_z}&#xA;$$&#xA;So now the game has become, let's minimize &#xA;$$&#xA;(\dot{\mathbf{\Theta}}_{\dot{x}\dots \dot{r_y}} + \dot{\mathbf{\Theta}}_{\dot{r_z}})^T&#xA;D(\dot{\mathbf{\Theta}}_{\dot{x}\dots \dot{r_y}} + \dot{\mathbf{\Theta}}_{\dot{r_z}})&#xA;$$ &#xA;for some diagonal matrix $D$ like ronalchn said above.  I'm going to use $A=\dot{\mathbf{\Theta}}_{\dot{x}\dots \dot{r_y}}$ and $B=\dot{\mathbf{\Theta}}_{\dot{r_z}^*}$ for easier viewing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We can expand this out to&#xA;$$&#xA;A^TDA+2B^TDA+B^TDB\\&#xA;\text{or}\\&#xA;A^TDA+2\dot{r_z}\vec{j_{6}}^TDA+\dot{r_z}^2\vec{j_{6}}^TD\vec{j_{6}}&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now we have an easy equation to differentiate on $\dot{r_z}$.  We find the derivative with respect to $\dot{r_z}$ and set it to $0$.&#xA;$$&#xA;2\vec{j_{6}}^TDA+2\dot{r_z}\vec{j_{6}}^TD\vec{j_{6}}=0\\&#xA;\dot{r_z} = \frac{-\vec{j_6}^TDA}{\vec{j_6}^TD\vec{j_6}}&#xA;$$&#xA;This minimizes the joint angle &quot;distance&quot; between your two poses.&lt;/p&gt;&#xA;" OwnerUserId="2175" LastEditorUserId="2175" LastEditDate="2013-12-18T18:31:22.517" LastActivityDate="2013-12-18T18:31:22.517" />
  <row Id="2123" PostTypeId="2" ParentId="2117" CreationDate="2013-12-05T21:32:45.513" Score="1" Body="&lt;p&gt;Follow the &lt;a href=&quot;http://en.wikipedia.org/wiki/Denavit%E2%80%93Hartenberg_parameters&quot; rel=&quot;nofollow&quot;&gt;Denavit-Hartenburg&lt;/a&gt; parameters, and you'll get easy equations for the transformation matrices between each frame.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The $z_n$-axis is in the direction of the $(n+1)^{th}$ joint axis&lt;/li&gt;&#xA;&lt;li&gt;The $x_n$-axis is collinear to the common normal: $x_n = z_n × z_{n-1}$ If there is no unique common normal (parallel $z$ axes), the direction of $x_n$ is from $z_{n-1}$ to $z_n$.&lt;/li&gt;&#xA;&lt;li&gt;The $y$-axis follows from the $x$- and $z$-axis by choosing it to be a right-handed coordinate system.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="2175" LastActivityDate="2013-12-05T21:32:45.513" />
  <row Id="2124" PostTypeId="1" CreationDate="2013-12-06T11:10:46.623" Score="3" ViewCount="29" Body="&lt;p&gt;I would like to know if anyone here has used the Blueview SDK (Linux) for retrieval of images from the pings obtained by a multibeam sonar (P450, P900, etc.) ?&#xA;If so, I'd like to know why would anyone get a &lt;em&gt;null head&lt;/em&gt; when I trying to retrieve the head (eventually for the pings to be converted to an image) using the &lt;code&gt;BVT_GetHead()&lt;/code&gt; method. My snippet for retrieving the image from a &lt;code&gt;.son&lt;/code&gt; file (some_son_data.son) is given below:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;int main() {&#xA;    BVTSonar son = BVTSonar_Create();&#xA;    BVTSonar_Open(son, &quot;FILE&quot;, &quot;some_son_data.son&quot;);&#xA;&#xA;    if (NULL != son) cout &amp;lt;&amp;lt; &quot;son not null&quot; &amp;lt;&amp;lt; endl;&#xA;    BVTHead head = NULL ;&#xA;    BVTSonar_GetHead(son, 0, &amp;amp;head);&#xA;    return 0;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="2340" LastActivityDate="2013-12-06T11:10:46.623" Title="Image retrieval through a multibeam imaging sonar" Tags="&lt;auv&gt;&lt;sonar&gt;" CommentCount="2" />
  <row Id="2125" PostTypeId="2" ParentId="2121" CreationDate="2013-12-06T14:30:17.367" Score="2" Body="&lt;p&gt;Most particle filter implementations will use some kind of importance sampling, which does not require you to make an assumption on the underlying distribution. This is one of the main reasons for using a particle filter in the first place. Importance sampling does not sample from the estimated distribution, but from your set of weighted samples.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This includes the ones in your linked paper. All the references to variance in there speak of the variance which is introduced by that particular re-sampling scheme. It is a measure on the quality of the re-sampling, since you do not want to introduce unnecessary uncertainty in your estimate of the true distribution by the particles. You do not need to calculate the variances of your particles for the re-sampling.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On the question which one work best? Your paper has some of the answers. I also made a &lt;a href=&quot;http://robotics.stackexchange.com/a/484/127&quot;&gt;post&lt;/a&gt; on the subject using less maths. In most cases some form of stratified resampling will be better than the multinomial scheme. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The only case I could think of where you would need to calculate the variance of your SO(3) distribution as well would be when you wanted to verify the variance your resampling introduces. In that case, what I would do is to calculate the mean of the orientation (as you said, not trivial), and then use the variance of differences to the mean as scaled axis of rotation representation. But as I said. I don't think you need this.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One word of caution: sampling over the full 6D pose is in most cases not recommended. You need a serious amount of particles for this. Even if you needed only 10 particles per dimension to represent your distribution appropriately - which often is not enough - this could mean that you need up to one million particles in 6D. Lots of memory and processing power...&lt;/p&gt;&#xA;" OwnerUserId="127" LastEditorUserId="127" LastEditDate="2013-12-06T16:35:49.323" LastActivityDate="2013-12-06T16:35:49.323" />
  <row Id="2127" PostTypeId="1" CreationDate="2013-12-07T05:37:07.330" Score="0" ViewCount="35" Body="&lt;p&gt;I'd like some well put video series of like 30 videos. Or anything but it needs to thorough and in easy English...less mundane. So far all resources i have found either go upto resistors code or of projects that tell you do this and this and this and tada you got this.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there really no online resource for people to learn electronics. I want further master analog and do move on to digital cause it's better to spend 0.40 cents.... than&#xA; spend $95 on components and get the whole thing on tiny chip.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Please bare with me like six months i have been searching for legit source, material that is meant to teach you. I like pictures and colors. &lt;/p&gt;&#xA;" OwnerUserId="1892" LastActivityDate="2013-12-08T18:46:10.843" Title="where can i learn electronics from intro to advance digital" Tags="&lt;electronics&gt;" AnswerCount="1" CommentCount="2" ClosedDate="2013-12-07T17:16:32.233" />
  <row Id="2128" PostTypeId="2" ParentId="2127" CreationDate="2013-12-07T07:39:25.390" Score="2" Body="&lt;p&gt;MOOCS are so popular nowadays, that I'm not sure you haven't check it out. Anyway, let's give it a shot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Please, have a look at this courses:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;edx.org&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://www.edx.org/course-list/allschools/electronics/allcourses&quot; rel=&quot;nofollow&quot;&gt;https://www.edx.org/course-list/allschools/electronics/allcourses&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;www.coursera.org&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can also check out &lt;a href=&quot;http://www.coursera.org&quot; rel=&quot;nofollow&quot;&gt;www.coursera.org&lt;/a&gt;. it's similar to mentioned above.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;MIT OpenCourseware&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And last but not least, you can also try to find something here:&#xA;&lt;a href=&quot;http://ocw.mit.edu/courses/find-by-topic/#cat=engineering&amp;amp;subcat=electricalengineering&amp;amp;spec=electronics&quot; rel=&quot;nofollow&quot;&gt;MIT OpenCourseware electronics&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1298" LastEditorUserId="1298" LastEditDate="2013-12-08T18:46:10.843" LastActivityDate="2013-12-08T18:46:10.843" />
  <row Id="2129" PostTypeId="2" ParentId="2104" CreationDate="2013-12-07T17:46:43.520" Score="2" Body="&lt;p&gt;Let&#xA;$w_1 \dots w_n$ be the weights of $n$ particles, $p_i \triangleq \frac{w_i}{\sum\limits_{j=1}^{n}w_j}, \sum\limits_{j=1}^{n} p_j = 1$, then as you posted, the probability of the $i$th particle surviving in the resampling procedure for multinomial resampling is:&#xA;$$&#xA;P(Survival_i) = 1 - (1 - p_i)^n&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In systematic resampling, one concatenate $p_1 \dots p_n$ as a ring of interval [0,1). First select $\tilde{u} \sim U[0,1)$, and take $n$ points $u_k = \frac{k-1 + \tilde{u}}{n}, k = 0, \dots n-1$ equally spaced $\frac{1}{n}$ apart from each other on that ring, and take the $n$ samples which have partitions $p_i$ covering the $n$ points. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Therefore, if $p_i \geq \frac{1}{n}$, the probability of survival for the $i$th particle is 1. If $p_i &amp;lt; \frac{1}{n}$, the probability of survival depends on $u_k$. Without loss of generality, let's always assume $i=1, p_1 &amp;lt; \frac{1}{n}$, and consider the probability of the first particle not being selected (you can always re-index the particles to see this is valid for all $i$). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In order for the first particle not to be selected, there need to be two equally spaced points $\{u_j, u_{j+1}, | j = 0 \dots n-1\}$ such that $u_j &amp;lt; 0$ and $u_{j+1} &amp;gt; p_1$. The probability of this event happening for $j=0$ is equal to $\frac{1}{n}-p_1$ (consider the ring interval $[1-\frac{1}{n}+p_1, 1)$). The probability of the first particle not to be selected, is a combination of $n$ exclusive events $j=0, \dots n-1$. Therefore the probability of the first particle not selected is $n\times (\frac{1}{n}-p_1) = 1-n p_1$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Same derivation for other particles $i=1\dots n$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In conclusion,&#xA;$$&#xA;P(Survival_i) = 1, \text{if } p_i &amp;gt;= \frac{1}{n}\\&#xA;P(Survival_i) = np_i, \text{if } p_i &amp;lt; \frac{1}{n}&#xA;$$&lt;/p&gt;&#xA;" OwnerUserId="1064" LastEditorUserId="1064" LastEditDate="2013-12-07T17:57:17.470" LastActivityDate="2013-12-07T17:57:17.470" CommentCount="1" />
  <row Id="2130" PostTypeId="1" AcceptedAnswerId="2136" CreationDate="2013-12-07T18:43:21.297" Score="2" ViewCount="54" Body="&lt;p&gt;&lt;strong&gt;UPDATE:&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;http://stackoverflow.com/questions/20445147/transform-image-using-roll-pitch-yaw-angles-image-rectification/20469709#20469709&quot;&gt;This exact problem&lt;/a&gt; has been solved in StackOverflow. Please read this post there for further explanation and a working solution. Thanks!&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am working on an application where I need to rectify an image taken from a mobile camera platform. The platform measures roll, pitch and yaw angles, and I want to make it look like the image is taken from directly above, by some sort of transform from this information. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In other words, I want a perfect square lying flat on the ground, photographed from afar with some camera orientation, to be transformed, so that the square is perfectly symmetrical afterwards. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have been trying to do this through OpenCV(C++) and Matlab, but I seem to be missing something fundamental about how this is done.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In Matlab, I have tried the following:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;%% Transform perspective&#xA;img = imread('my_favourite_image.jpg');&#xA;R = R_z(yaw_angle)*R_y(pitch_angle)*R_x(roll_angle);&#xA;tform = projective2d(R);   &#xA;outputImage = imwarp(img,tform);&#xA;figure(1), imshow(outputImage);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Where R_z/y/x are the standard rotational matrices (implemented with degrees).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For some yaw-rotation, it all works just fine:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;R = R_z(10)*R_y(0)*R_x(0);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Which gives the result:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/pyiNq.jpg&quot; alt=&quot;Image rotated 10 degrees about the Z-image axis&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If I try to rotate the image by the same amount about the X- or Y- axes, I get results like this:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;R = R_z(10)*R_y(0)*R_x(10);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/cbZoE.jpg&quot; alt=&quot;Image rotated 10 degrees about the X-image axis&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, if I rotate by 10 degrees, divided by some huge number, it starts to look OK. But then again, this is a result that has no research value what so ever:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;R = R_z(10)*R_y(0)*R_x(10/1000);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/kssGS.jpg&quot; alt=&quot;Image rotated 10/1000 degrees about the X-image axis&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can someone please help me understand why rotating about the X- or Y-axes makes the transformation go wild? Is there any way of solving this without dividing by some random number and other magic tricks? Is this maybe something that can be solved using Euler parameters of some sort? Any help will be highly appreciated!&lt;/p&gt;&#xA;" OwnerUserId="2347" LastEditorUserId="2347" LastEditDate="2013-12-09T11:47:08.833" LastActivityDate="2013-12-09T19:31:21.323" Title="Transform Image Using Roll-Pitch-Yaw Angles (image rectification)" Tags="&lt;computer-vision&gt;&lt;cameras&gt;" AnswerCount="1" />
  <row Id="2131" PostTypeId="1" CreationDate="2013-12-07T20:34:39.493" Score="2" ViewCount="64" Body="&lt;p&gt;I am trying to build an advanced coloured lines following robot with the ability to differentiate between many different coloured lines and follow it. I am finding for the right sensor that will help my robot achieve its objective.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As i was researching I came across the Ev3 colour sensor which can detect upto 7 colours.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is this sensor suitable for my project?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What other sensors can I use and how?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thank You&lt;/p&gt;&#xA;" OwnerUserId="2348" LastActivityDate="2013-12-07T20:34:39.493" Title="line following robot with ev3 colour sensor" Tags="&lt;mobile-robot&gt;&lt;sensors&gt;&lt;line-following&gt;" CommentCount="1" />
  <row Id="2132" PostTypeId="1" CreationDate="2013-12-07T23:40:08.260" Score="0" ViewCount="26" Body="&lt;p&gt;I am trying to get the usb.find command to work properly in a python script I'm writing on Angstrom for the Beagleboard.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here is my code:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#!/usr/bin/env python&#xA;&#xA;import usb.core &#xA;import usb.util &#xA;import usb.backend.libusb01 as libusb&#xA;&#xA;&#xA;PYUSB_DEBUG_LEVEL = 'debug'&#xA;# find our device&#xA;# Bus 002 Device 006: ID 1208:0815&#xA;#  idVendor           0x1208&#xA;#  idProduct          0x0815&#xA;# dev = usb.core.find(idVendor=0xfffe, idProduct=0x0001)&#xA;# iManufacturer           1 TOROBOT.com&#xA;&#xA;dev = usb.core.find(idVendor=0x1208, idProduct=0x0815,&#xA;backend=libusb.get_backend() )&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I don't know what's missing, but here is what I do know.&#xA;When I don't specify the backend, no backend is found.  When I do specify the backend &quot;usb.backend.libusb01&quot; I get the following error: &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;root@beagleboard:~/servo# ./pyServo.py&#xA;Traceback (most recent call last):&#xA;  File &quot;./pyServo.py&quot;, line 17, in &amp;lt;module&amp;gt;&#xA;    dev = usb.core.find(idVendor=0x1208, idProduct=0x0815, backend=libusb.get_backend() )&#xA;  File &quot;/usr/lib/python2.6/site-packages/usb/core.py&quot;, line 854, in find&#xA;    return _interop._next(device_iter(k, v))&#xA;  File &quot;/usr/lib/python2.6/site-packages/usb/_interop.py&quot;, line 60, in _next&#xA;    return next(iter)&#xA;  File &quot;/usr/lib/python2.6/site-packages/usb/core.py&quot;, line 821, in device_iter&#xA;    for dev in backend.enumerate_devices():&#xA;  File &quot;/usr/lib/python2.6/site-packages/usb/backend/libusb01.py&quot;, line 390, in enumerate_devices&#xA;    _check(_lib.usb_find_busses())&#xA;  File &quot;/usr/lib/python2.6/ctypes/__init__.py&quot;, line 366, in __getattr__&#xA;    func = self.__getitem__(name)&#xA;  File &quot;/usr/lib/python2.6/ctypes/__init__.py&quot;, line 371, in __getitem__&#xA;    func = self._FuncPtr((name_or_ordinal, self))&#xA;AttributeError: python: undefined symbol: usb_find_busses&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;What am I missing so that this will work properly?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thank you.&lt;/p&gt;&#xA;" OwnerUserId="947" LastActivityDate="2013-12-07T23:40:08.260" Title="What dependencies do I need for USB programing in python with pyUSB?" Tags="&lt;rcservo&gt;&lt;python&gt;&lt;usb&gt;" CommentCount="2" />
  <row Id="2133" PostTypeId="1" CreationDate="2013-12-08T05:20:59.900" Score="0" ViewCount="14" Body="&lt;p&gt;Given a robot with 2 wheels with radius r on one axle with length D, I want to set the wheel speed so that it turns to an angle phi as fast as possible. The timestep t is 64 milliseconds.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I thought the wheel speed could be set to v = ((desired_heading-actual_heading) * circumference_wheel_trajectory)/(2*pi * t * wheel_radius). This will converge to a somewhat right angle, eventually, but its very slow and becomes slower as I approach the angle I want to be at.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there an alternative/better way to do this?&lt;/p&gt;&#xA;" OwnerDisplayName="user1815201" LastActivityDate="2013-12-08T18:26:03.387" Title="Turning a differential drive robot to a specific angle" Tags="&lt;kinematics&gt;" CommentCount="2" ClosedDate="2013-12-08T18:34:03.110" />
  <row Id="2135" PostTypeId="1" CreationDate="2013-12-08T20:54:03.207" Score="2" ViewCount="50" Body="&lt;p&gt;I'm just wondering that is there any case that when algebraic way can't solve the problem while the geometric can ? Cause I'm working on a 2DOF robotics arm &lt;a href=&quot;http://www.quanser.com/Products/2dof_serial_flexible_joint&quot; rel=&quot;nofollow&quot;&gt;This one&lt;/a&gt;, I know the length of L1 and L2, location that I want for the end effector, then I tried calculating the angles by using algebraic but it gave me cos(alpha) &gt; 1, but when I tried solving with geometric, I can find the solution, so is it because I use a wrong way in algebraic ? &#xA;&lt;br&gt;Thank you very much.&lt;/p&gt;&#xA;" OwnerUserId="2322" LastActivityDate="2013-12-08T20:54:03.207" Title="Algebraic and geometric in inverse kinematic" Tags="&lt;localization&gt;&lt;kinematics&gt;&lt;robotic-arm&gt;&lt;inverse-kinematics&gt;" CommentCount="1" />
  <row Id="2136" PostTypeId="2" ParentId="2130" CreationDate="2013-12-09T19:31:21.323" Score="1" Body="&lt;p&gt;&lt;strong&gt;SOLUTION:&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;http://stackoverflow.com/questions/20445147/transform-image-using-roll-pitch-yaw-angles-image-rectification/20469709#20469709&quot;&gt;This exact problem&lt;/a&gt; has been solved in StackOverflow. Please read this post there for further explanation and a working solution. Thanks!&lt;/em&gt;&lt;/p&gt;&#xA;" OwnerUserId="2347" LastActivityDate="2013-12-09T19:31:21.323" />
  <row Id="2137" PostTypeId="2" ParentId="2119" CreationDate="2013-12-10T01:35:57.107" Score="1" Body="&lt;p&gt;Use the robot to hold and index the plastic box and use flame to deburr the plastic.&#xA;I owned a machine shop and deburred plastic for a living.&#xA;No force necessary just the correct flame and speed.&#xA;Good luck&lt;/p&gt;&#xA;" OwnerUserId="2359" LastActivityDate="2013-12-10T01:35:57.107" />
  <row Id="2138" PostTypeId="1" AcceptedAnswerId="2163" CreationDate="2013-12-10T16:10:54.943" Score="2" ViewCount="34" Body="&lt;p&gt;Is there a node or package that can send commands to &lt;code&gt;/cmd_vel&lt;/code&gt; to move &lt;strong&gt;ATRV-Jr&lt;/strong&gt; like 2 meters forward or turn it 90 degree to right/left? I don't want to tell the robot to move with specified speed. For example when I use this command &lt;code&gt;rostopic pub /cmd_vel geometry_msgs/Twist '[1.0,0.0,0.0]' '[0.0,0.0,0.0]'&lt;/code&gt; the robot starts moving forward until I send another command or send &lt;code&gt;break&lt;/code&gt; command.&lt;/p&gt;&#xA;" OwnerUserId="2202" LastActivityDate="2013-12-18T11:59:42.077" Title="Move ATRV robot to specific distance using ROS" Tags="&lt;mobile-robot&gt;&lt;ros&gt;&lt;navigation&gt;" AnswerCount="1" />
  <row Id="2139" PostTypeId="2" ParentId="2101" CreationDate="2013-12-10T18:33:37.373" Score="0" Body="&lt;p&gt;Depends on how stable you want the UAV to be. If the air is still, probably position/velocity/acceleration added with friction and &lt;a href=&quot;https://en.wikipedia.org/wiki/Drag_%28physics%29&quot; rel=&quot;nofollow&quot;&gt;drag&lt;/a&gt; would be a pretty accurate model and is not too difficult.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, air is not still, and no matter what model you make, you can't predict wind. Neither it's strength nor direction. The effect of wind especially makes the calculation of drag difficult as it depends on the aerodynamicity of the UAV in the direction of the wind.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;That said, unless someone here has created before a similar UAV to the one you are building, and used it in the same application as yours, I don't think you can get a clear answer. Best way would be to try it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My suggestion is to try building a model that doesn't ignore the basics (e.g. basic fluid dynamics), but don't go out of your way either. If it turns out that it's not good enough, then ask for help on the particular behavior.&lt;/p&gt;&#xA;" OwnerUserId="158" LastActivityDate="2013-12-10T18:33:37.373" CommentCount="2" />
  <row Id="2141" PostTypeId="2" ParentId="1765" CreationDate="2013-12-10T19:15:46.160" Score="0" Body="&lt;p&gt;Inaccuracy due to multipath bounces is negligible compared to inaccuracy due to seeing fewer satellites, as Matthew Gordon answers.  So on a land vehicle, roof is best.  Towbar is very poor.&lt;/p&gt;&#xA;" OwnerUserId="2363" LastActivityDate="2013-12-10T19:15:46.160" />
  <row Id="2144" PostTypeId="2" ParentId="2105" CreationDate="2013-12-12T06:58:37.410" Score="0" Body="&lt;p&gt;I'm not going to mark this as the answer unless others agree it is the answer, but I found an omnidriectional ultrasonic transmitter/receiver: &lt;a href=&quot;http://www.metrolog.net/transdutores/piezofilm/ultra40k.php?lang=en&quot; rel=&quot;nofollow&quot;&gt;http://www.metrolog.net/transdutores/piezofilm/ultra40k.php?lang=en&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I haven't used it or tested it yet, but it seems promising.&lt;/p&gt;&#xA;" OwnerUserId="1952" LastActivityDate="2013-12-12T06:58:37.410" />
  <row Id="2145" PostTypeId="1" CreationDate="2013-12-12T15:23:00.233" Score="1" ViewCount="23" Body="&lt;p&gt;I am taking information for my project and I need to see libraries ans SDKs. Searching in the web I found that OpenNI has a lot of functions and when I try to found another SDK, I dont find any other. I am working with a Kinect and a XTION so I need an SDK who works in both. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there any other SDK o set of libraries that works well in both?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks!&lt;/p&gt;&#xA;" OwnerUserId="2269" LastEditorUserId="197" LastEditDate="2014-01-15T14:14:56.907" LastActivityDate="2014-01-15T14:14:56.907" Title="Another SDK like OpenNI" Tags="&lt;kinect&gt;&lt;openni&gt;" AnswerCount="1" />
  <row Id="2146" PostTypeId="1" AcceptedAnswerId="2157" CreationDate="2013-12-13T06:41:12.867" Score="1" ViewCount="26" Body="&lt;p&gt;I am trying to manually calibrate the on-board accelerometer of an APM 2.6 controller.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am using the following code (I found this somewhere, don't remember where) with Arduino 1.0.5 (in Windows environment) to fetch the accelerometer and gyro data:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;  #include &amp;lt;SPI.h&amp;gt;&#xA;  #include &amp;lt;math.h&amp;gt;&#xA;&#xA;  #define ToD(x) (x/131)&#xA;  #define ToG(x) (x*9.80665/16384)&#xA;&#xA;  #define xAxis 0&#xA;  #define yAxis 1&#xA;  #define zAxis 2&#xA;&#xA;  #define Aoffset 0.8&#xA;&#xA;  int time=0;&#xA;  int time_old=0;&#xA;&#xA;  const int ChipSelPin1 = 53;&#xA;&#xA;  float angle=0;&#xA;  float angleX=0;&#xA;  float angleY=0;&#xA;  float angleZ=0;&#xA;&#xA;&#xA;&#xA;  void setup() {&#xA;     Serial.begin(9600);  &#xA;&#xA;     pinMode(40, OUTPUT);&#xA;     digitalWrite(40, HIGH);&#xA;&#xA;&#xA;     SPI.begin();  &#xA;     SPI.setClockDivider(SPI_CLOCK_DIV16); &#xA;&#xA;     SPI.setBitOrder(MSBFIRST); &#xA;     SPI.setDataMode(SPI_MODE0);&#xA;&#xA;&#xA;      pinMode(ChipSelPin1, OUTPUT);&#xA;&#xA;     ConfigureMPU6000();  // configure chip&#xA;    }&#xA;&#xA;void loop()&#xA;&#xA;{&#xA; Serial.print(&quot;Acc X &quot;);&#xA;&#xA;&#xA;  Serial.print(AcceX(ChipSelPin1));&#xA;  Serial.print(&quot;   &quot;);&#xA;  Serial.print(&quot;Acc Y &quot;);&#xA;  Serial.print(AcceY(ChipSelPin1));&#xA;  Serial.print(&quot;   &quot;);&#xA;  Serial.print(&quot;Acc Z &quot;);  &#xA;  Serial.print(AcceZ(ChipSelPin1));  &#xA;  Serial.print(&quot; Gyro X &quot;);  &#xA;  Serial.print(GyroX(ChipSelPin1)); &#xA;  Serial.print(&quot; Gyro Y &quot;);  &#xA;  Serial.print(GyroY(ChipSelPin1)); &#xA;  Serial.print(&quot; Gyro Z &quot;);  &#xA;  Serial.print(GyroZ(ChipSelPin1)); &#xA;  Serial.println();&#xA;}&#xA;&#xA;&#xA;void SPIwrite(byte reg, byte data, int ChipSelPin) {&#xA;  uint8_t dump;&#xA;  digitalWrite(ChipSelPin,LOW);&#xA;  dump=SPI.transfer(reg);&#xA;  dump=SPI.transfer(data);&#xA;  digitalWrite(ChipSelPin,HIGH);&#xA;}&#xA;&#xA;&#xA;uint8_t SPIread(byte reg,int ChipSelPin) {&#xA;  uint8_t dump;&#xA;  uint8_t return_value;&#xA;  uint8_t addr=reg|0x80;&#xA;  digitalWrite(ChipSelPin,LOW);&#xA;  dump=SPI.transfer(addr);&#xA;  return_value=SPI.transfer(0x00);&#xA;  digitalWrite(ChipSelPin,HIGH);&#xA;  return(return_value);&#xA;}&#xA;&#xA;&#xA;int AcceX(int ChipSelPin) {&#xA;  uint8_t AcceX_H=SPIread(0x3B,ChipSelPin);&#xA;  uint8_t AcceX_L=SPIread(0x3C,ChipSelPin);&#xA;  int16_t AcceX=AcceX_H&amp;lt;&amp;lt;8|AcceX_L;&#xA;  return(AcceX);&#xA;}&#xA;&#xA;&#xA;int AcceY(int ChipSelPin) {&#xA;  uint8_t AcceY_H=SPIread(0x3D,ChipSelPin);&#xA;  uint8_t AcceY_L=SPIread(0x3E,ChipSelPin);&#xA;  int16_t AcceY=AcceY_H&amp;lt;&amp;lt;8|AcceY_L;&#xA;  return(AcceY);&#xA;}&#xA;&#xA;&#xA;int AcceZ(int ChipSelPin) {&#xA;  uint8_t AcceZ_H=SPIread(0x3F,ChipSelPin);&#xA;  uint8_t AcceZ_L=SPIread(0x40,ChipSelPin);&#xA;  int16_t AcceZ=AcceZ_H&amp;lt;&amp;lt;8|AcceZ_L;&#xA;  return(AcceZ);&#xA;}&#xA;&#xA;&#xA;int GyroX(int ChipSelPin) {&#xA;  uint8_t GyroX_H=SPIread(0x43,ChipSelPin);&#xA;  uint8_t GyroX_L=SPIread(0x44,ChipSelPin);&#xA;  int16_t GyroX=GyroX_H&amp;lt;&amp;lt;8|GyroX_L;&#xA;  return(GyroX);&#xA;}&#xA;&#xA;&#xA;int GyroY(int ChipSelPin) {&#xA;  uint8_t GyroY_H=SPIread(0x45,ChipSelPin);&#xA;  uint8_t GyroY_L=SPIread(0x46,ChipSelPin);&#xA;  int16_t GyroY=GyroY_H&amp;lt;&amp;lt;8|GyroY_L;&#xA;  return(GyroY);&#xA;}&#xA;&#xA;&#xA;int GyroZ(int ChipSelPin) {&#xA;  uint8_t GyroZ_H=SPIread(0x47,ChipSelPin);&#xA;  uint8_t GyroZ_L=SPIread(0x48,ChipSelPin);&#xA;  int16_t GyroZ=GyroZ_H&amp;lt;&amp;lt;8|GyroZ_L;&#xA;  return(GyroZ);&#xA;}&#xA;&#xA;&#xA;//--- Function to obtain angles based on accelerometer readings ---//&#xA;float AcceDeg(int ChipSelPin,int AxisSelect) {&#xA;  float Ax=ToG(AcceX(ChipSelPin));&#xA;  float Ay=ToG(AcceY(ChipSelPin));&#xA;  float Az=ToG(AcceZ(ChipSelPin));&#xA;  float ADegX=((atan(Ax/(sqrt((Ay*Ay)+(Az*Az)))))/PI)*180;&#xA;  float ADegY=((atan(Ay/(sqrt((Ax*Ax)+(Az*Az)))))/PI)*180;&#xA;  float ADegZ=((atan((sqrt((Ax*Ax)+(Ay*Ay)))/Az))/PI)*180;&#xA;  switch (AxisSelect)&#xA;  {&#xA;    case 0:&#xA;    return ADegX;&#xA;    break;&#xA;    case 1:&#xA;    return ADegY;&#xA;    break;&#xA;    case 2:&#xA;    return ADegZ;&#xA;    break;&#xA;  }&#xA;}&#xA;&#xA;&#xA;//--- Function to obtain angles based on gyroscope readings ---//&#xA;float GyroDeg(int ChipSelPin, int AxisSelect) {&#xA;  time_old=time;&#xA;  time=millis();&#xA;  float dt=time-time_old;&#xA;  if (dt&amp;gt;=1000)&#xA;  {&#xA;    dt=0;&#xA;  }&#xA;  float Gx=ToD(GyroX(ChipSelPin));&#xA;  if (Gx&amp;gt;0 &amp;amp;&amp;amp; Gx&amp;lt;1.4)&#xA;  {&#xA;    Gx=0;&#xA;  }&#xA;  float Gy=ToD(GyroY(ChipSelPin));&#xA;  float Gz=ToD(GyroZ(ChipSelPin));&#xA;  angleX+=Gx*(dt/1000);&#xA;  angleY+=Gy*(dt/1000);&#xA;  angleZ+=Gz*(dt/1000);&#xA;  switch (AxisSelect)&#xA;  {&#xA;    case 0:&#xA;    return angleX;&#xA;    break;&#xA;    case 1:&#xA;    return angleY;&#xA;    break;&#xA;    case 2:&#xA;    return angleZ;&#xA;    break;&#xA;  }&#xA;}&#xA;&#xA;&#xA;void ConfigureMPU6000()&#xA;{&#xA;  // DEVICE_RESET @ PWR_MGMT_1, reset device&#xA;  SPIwrite(0x6B,0x80,ChipSelPin1);&#xA;  delay(150);&#xA;&#xA;  // TEMP_DIS @ PWR_MGMT_1, wake device and select GyroZ clock&#xA;  SPIwrite(0x6B,0x03,ChipSelPin1);&#xA;  delay(150);&#xA;&#xA;  // I2C_IF_DIS @ USER_CTRL, disable I2C interface&#xA;  SPIwrite(0x6A,0x10,ChipSelPin1);&#xA;  delay(150);&#xA;&#xA;  // SMPRT_DIV @ SMPRT_DIV, sample rate at 1000Hz&#xA;  SPIwrite(0x19,0x00,ChipSelPin1);&#xA;  delay(150);&#xA;&#xA;  // DLPF_CFG @ CONFIG, digital low pass filter at 42Hz&#xA;  SPIwrite(0x1A,0x03,ChipSelPin1);&#xA;  delay(150);&#xA;&#xA;  // FS_SEL @ GYRO_CONFIG, gyro scale at 250dps&#xA;  SPIwrite(0x1B,0x00,ChipSelPin1);&#xA;  delay(150);&#xA;&#xA;  // AFS_SEL @ ACCEL_CONFIG, accel scale at 2g (1g=8192)&#xA;  SPIwrite(0x1C,0x00,ChipSelPin1);&#xA;  delay(150);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;My objective use to calibrate the accelerometers (and gyro), so that I can use them without having to depend on Mission Planner.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm reading values like:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;Acc X 288   Acc Y -640   Acc Z 16884 Gyro X -322 Gyro Y 26 Gyro Z 74&#xA;Acc X 292   Acc Y -622   Acc Z 16854 Gyro X -320 Gyro Y 24 Gyro Z 79&#xA;Acc X 280   Acc Y -626   Acc Z 16830 Gyro X -328 Gyro Y 23 Gyro Z 71&#xA;Acc X 258   Acc Y -652   Acc Z 16882 Gyro X -314 Gyro Y 22 Gyro Z 78&#xA;Acc X 236   Acc Y -608   Acc Z 16866 Gyro X -321 Gyro Y 17 Gyro Z 77&#xA;Acc X 238   Acc Y -642   Acc Z 16900 Gyro X -312 Gyro Y 26 Gyro Z 74&#xA;Acc X 226   Acc Y -608   Acc Z 16850 Gyro X -321 Gyro Y 26 Gyro Z 68&#xA;Acc X 242   Acc Y -608   Acc Z 16874 Gyro X -325 Gyro Y 27 Gyro Z 69&#xA;Acc X 236   Acc Y -576   Acc Z 16836 Gyro X -319 Gyro Y 19 Gyro Z 78&#xA;Acc X 232   Acc Y -546   Acc Z 16856 Gyro X -321 Gyro Y 24 Gyro Z 68&#xA;Acc X 220   Acc Y -624   Acc Z 16840 Gyro X -316 Gyro Y 30 Gyro Z 77&#xA;Acc X 252   Acc Y -594   Acc Z 16874 Gyro X -320 Gyro Y 19 Gyro Z 59&#xA;Acc X 276   Acc Y -622   Acc Z 16934 Gyro X -317 Gyro Y 34 Gyro Z 69&#xA;Acc X 180   Acc Y -564   Acc Z 16836 Gyro X -320 Gyro Y 28 Gyro Z 68&#xA;Acc X 250   Acc Y -596   Acc Z 16854 Gyro X -329 Gyro Y 33 Gyro Z 70&#xA;Acc X 220   Acc Y -666   Acc Z 16888 Gyro X -316 Gyro Y 19 Gyro Z 71&#xA;Acc X 278   Acc Y -596   Acc Z 16872 Gyro X -307 Gyro Y 26 Gyro Z 78&#xA;Acc X 270   Acc Y -642   Acc Z 16898 Gyro X -327 Gyro Y 28 Gyro Z 72&#xA;Acc X 260   Acc Y -606   Acc Z 16804 Gyro X -308 Gyro Y 31 Gyro Z 64&#xA;Acc X 242   Acc Y -650   Acc Z 16906 Gyro X -313 Gyro Y 31 Gyro Z 78&#xA;Acc X 278   Acc Y -628   Acc Z 16898 Gyro X -309 Gyro Y 22 Gyro Z 67&#xA;Acc X 250   Acc Y -608   Acc Z 16854 Gyro X -310 Gyro Y 23 Gyro Z 75&#xA;Acc X 216   Acc Y -634   Acc Z 16814 Gyro X -307 Gyro Y 27 Gyro Z 83&#xA;Acc X 228   Acc Y -604   Acc Z 16904 Gyro X -326 Gyro Y 17 Gyro Z 75&#xA;Acc X 270   Acc Y -634   Acc Z 16898 Gyro X -320 Gyro Y 31 Gyro Z 77&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;From what I understand, SPIread(...,...) returns an analog voltage value from the data pins of the sensor, which happens to be proportional to the acceleration values. Right?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;My question is:&lt;/strong&gt; How do I go about calibrating the accelerometer?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What I've tried till date:&lt;/strong&gt; I've tried the &quot;place horizontal... place nose down... left side, right side&quot; technique used by mission planner. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Basically, when placed on horizontal position, the sensor is experiencing +1g on it's Z axis and 0g in X and Y axis. Left/right side provides ±1g on Y axis and nose down/up provides ±1g on X axis. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now for every orientation, I've passed the raw sensor data through a LPF and then computed the mean, median and SD of this sensor data over 100 iterations. I store this mean, median and SD value in the EEPROM for each axis (one for +1g and one for 0g).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now, when I use the sensor, I load the stats from the EEPROM, match the mean/median and standard deviation with the current reading of 4/5 iterations. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here I'm working under the assumption that the values between 0g and +1g (and anything above 1g) can be interpolated/extrapolated from the data using a linear plot. &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Is this the correct approach for calibration?&lt;/li&gt;&#xA;&lt;li&gt;Can you suggest a better way?&lt;/li&gt;&#xA;&lt;li&gt;I noticed that the maxima/minima for each axis is different. Is this&#xA;the expected outcome or is there something wrong in the code?&lt;/li&gt;&#xA;&lt;li&gt;What do I do with the gyro? How to calibrate for angular&#xA;acceleration?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="1949" LastEditorUserId="1949" LastEditDate="2013-12-13T06:49:09.373" LastActivityDate="2013-12-17T19:21:09.747" Title="APM Accelerometer Calibration" Tags="&lt;arduino&gt;&lt;accelerometer&gt;&lt;ardupilot&gt;" AnswerCount="1" CommentCount="0" />
  <row Id="2147" PostTypeId="1" CreationDate="2013-12-13T12:48:32.227" Score="1" ViewCount="133" Body="&lt;p&gt;I am totally new to the camera interface and usage in an Embedded project, and would like to use a CMOS vision sensor &lt;a href=&quot;https://www.sparkfun.com/products/8667&quot; rel=&quot;nofollow&quot;&gt;like this&lt;/a&gt;.This project further will be used to power a small robot with on-board video processing power using processors like ARM 9.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I do have a limitation that until now I have worked only on 8-bit micro-controllers like the atmega 8, 16, 32 and on the Arduino platform. I think that for better processing we can use Arduino Due.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;With the data sheet for the CMOS camera above, we can build its breakout board. But what next? I haven't I found any useful resources while searching. All I need to do is to capture a small video and store it in a SD card.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have seen &lt;a href=&quot;http://www.cmucam.org/projects/cmucam1/wiki/Wiki&quot; rel=&quot;nofollow&quot;&gt;these links&lt;/a&gt; but they haven't proved to be very useful as they don't provide me the required form factor. I am looking to interface this module to a customized board.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So what so I need to understand about what commands they accept for their proper functioning like starting to take video and posting them out on a output pin.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If we get a video on a output pin, to which pin should I take that output to on my controller, i.e. on UART or I2C or SPI?&lt;/p&gt;&#xA;" OwnerUserId="1322" LastEditorUserId="1322" LastEditDate="2013-12-20T06:22:26.240" LastActivityDate="2013-12-20T06:22:26.240" Title="How can I interface my CMOS camera module to an Arduino?" Tags="&lt;arduino&gt;&lt;microcontroller&gt;&lt;computer-vision&gt;&lt;cameras&gt;&lt;c&gt;" AnswerCount="1" CommentCount="3" FavoriteCount="1" ClosedDate="2013-12-18T11:34:14.680" />
  <row Id="2148" PostTypeId="1" CreationDate="2013-12-14T04:51:32.740" Score="2" ViewCount="57" Body="&lt;p&gt;I am new to robotics and control and I have been thinking about how to deal with problems in real life. I have passed a course in control, but I do not have any idea about control for discrete/digital systems.&lt;br&gt;&#xA;There are a lot of robots and in general dynamic systems which are controlled by microcontrollers or computers with some software, i.e. simulink. Usually there are sensors which send feedback to the microcontroller or the computer and the controller sends a signal w.r.t the input signal from sensors. I was wondering how we decide if the system is discrete or continuous? How one can decide if he should use discrete or continuous blocks in simulink to control a dynamic system. Does it really matter which one we use?&lt;br&gt;&#xA;After all computers are digital and I think it is easier to work with digital signals and also  do we really have continuous signal? I have not passed any signals course, so my questions might be really easy. I did not find any other place for my question.&lt;/p&gt;&#xA;" OwnerUserId="2388" LastActivityDate="2013-12-14T04:51:32.740" Title="Continuous or Discrete" Tags="&lt;control&gt;&lt;microcontroller&gt;" CommentCount="2" FavoriteCount="0" />
  <row Id="2149" PostTypeId="1" CreationDate="2013-12-14T07:35:27.447" Score="1" ViewCount="93" Body="&lt;p&gt;I am currently working on a project for school where I need to implement an extended Kalman Filter for a point robot with a laser scanner. The Robot can rotate with 0 degree turn radius and drive forward. All motions are piecewise linear (drive,rotate,drive).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We are using a simulator so there is no acceleration, all motion is instantaneous. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;We also have a known map (png image) that we need to localize in. We can ray trace in the image in order to simulate laser scans. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;My partner and I are little confused as to the motion and sensor models we'll need to use. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So far we are modelling the state as a vector $(x,y,\theta)$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We are using the update equations as follows&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;void kalman::predict(const nav_msgs::Odometry msg){&#xA;    this-&amp;gt;X[0] += linear * dt * cos( X[2] ); //x&#xA;    this-&amp;gt;X[1] += linear * dt * sin( X[2] ); //y&#xA;    this-&amp;gt;X[2] += angular * dt; //theta&#xA;&#xA;    this-&amp;gt;F(0,2) = -linear * dt * sin( X[2] ); //t+1 ?&#xA;    this-&amp;gt;F(1,2) =  linear * dt * cos( X[2] ); //t+1 ?&#xA;&#xA;    P = F * P * F.t() + Q;&#xA;&#xA;    this-&amp;gt;linear = msg.twist.twist.linear.x;&#xA;    this-&amp;gt;angular = msg.twist.twist.angular.z;&#xA;    return;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;We though we had everything working until we noticed that we forgot to initialize &lt;code&gt;P&lt;/code&gt; and that it was zero, meaning that there was no correction happening. Apparently our propagation was very accurate as we haven't yet introduced noise into the system.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For the motion model we are using the following matrix for F:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$F = \begin{bmatrix}1 &amp;amp; 0 &amp;amp; -v*\Delta t*sin(\theta)  &#xA;\\ 0 &amp;amp; 1 &amp;amp; v*\Delta t*cos(\theta)   &#xA;\\ 0 &amp;amp; 0 &amp;amp; 1 &#xA;\end{bmatrix}$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As its the Jacobian of our update formulas. Is this correct?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For the sensor model we are approximating the Jacobian (H) by taking finite differences of the robots $x$, $y$ and $\theta$ positions and ray tracing in the map. We talked to the TA who said that this would work but I'm still unsure it will. Our prof is away so we can't ask him unfortunately. We are using 3 laser measurements per correction step so H is a 3x3. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The other issue where having how to initialize P. We tried 1,10,100 and they all place the robot outside the map at (-90,-70) when the map is only 50x50.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The code for our project can be found here: &lt;a href=&quot;https://github.com/en4bz/kalman/blob/master/src/kalman.cpp&quot; rel=&quot;nofollow&quot;&gt;https://github.com/en4bz/kalman/blob/master/src/kalman.cpp&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any advice is greatly appreciated.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;At this point I've gotten the filter to stabilize with basic movement noise but no actual movement. As soon as the robot starts to move the filter diverges quite quickly and exits the map. &lt;/p&gt;&#xA;" OwnerUserId="2391" LastEditorUserId="2391" LastEditDate="2013-12-20T02:30:37.380" LastActivityDate="2013-12-20T02:30:37.380" Title="Extended Kalman Filter with Laser Scan + Known Map" Tags="&lt;mobile-robot&gt;&lt;ros&gt;&lt;ekf&gt;" />
  <row Id="2150" PostTypeId="2" ParentId="1787" CreationDate="2013-12-15T09:23:21.943" Score="0" Body="&lt;p&gt;Finally Success:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I found that the Torobot USB board could be communicated with an Arduino serial driver.  Conveniently this is available through opkg:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;opkg install kernel-module-cdc-acm&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;When the board is plugged in, it comes up as&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;/dev/ttyACM0 &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;From here you can  simply echo commands to the device.  &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;echo &quot;#8P1500T100&quot; &amp;gt; /dev/ttyACM0&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;This basically says &quot;set servo 8 to position 1500 with speed 100&quot;&lt;/p&gt;&#xA;" OwnerUserId="947" LastActivityDate="2013-12-15T09:23:21.943" />
  <row Id="2151" PostTypeId="1" CreationDate="2013-12-15T14:06:41.427" Score="0" ViewCount="71" Body="&lt;p&gt;I am planning on building a robot with wheels (later legs, if possible), that can move around the room and analyze certain things, using a couple sensors.&#xA;In the later steps more functions such a grabbing are the things I want to add.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Could you recommend me a micro controller?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My concern about Arduino is that there aren't enough slots, Raspberry Pi seems like it constantly needs a screen for the user.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am a complete amateur when it comes to robotics. However, I am quite familiar with the computer languages Java and Python. Since I wrote a fun app for Android for myself I would love the robot to be compatible with Android, too.&lt;/p&gt;&#xA;" OwnerUserId="2395" LastEditorUserId="37" LastEditDate="2013-12-17T23:58:11.000" LastActivityDate="2013-12-17T23:58:11.000" Title="What micro controller should I use?" Tags="&lt;arduino&gt;&lt;raspberry-pi&gt;&lt;beginner&gt;" AnswerCount="2" CommentCount="2" ClosedDate="2013-12-17T15:40:28.697" />
  <row Id="2152" PostTypeId="2" ParentId="2151" CreationDate="2013-12-15T22:44:20.293" Score="0" Body="&lt;p&gt;I've used Arduino for a while now, and am very happy with it. It doesn't always need a screen to control it, as you can program it from the computer then run it from the wall. Your concern of low pins on the Arduino is irrelevant, as you could get the Arduino Mega to supply al lthe pins you need. If that is not enough, there are plenty of multiplexer shields you can get to stack on top to give it all the pins you need. However, the Arduino language is different from anything else, and the Raspbery-Pi uses Python, which I am very familiar with. I have not worked with the Raspberry-Pi before, so I don't know all of its functionality.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;All in all, I would reccomend the Arduino. Of course, it is your choice, so I also suggest you do some research on your own to figure out if the board you choose has all the functionality you want.&lt;/p&gt;&#xA;" OwnerUserId="583" LastActivityDate="2013-12-15T22:44:20.293" />
  <row Id="2153" PostTypeId="2" ParentId="2151" CreationDate="2013-12-16T04:39:39.437" Score="3" Body="&lt;p&gt;Firstly, this is a stupid nit-picky thing, but neither the Arduino nor RPi are micro controllers. Anyways, to answer your question:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Neither of your concerns are really problems. Arduinos come in all kinds of sizes and ALL of them should have enough pins to do what you want. And the RPi can easily be run headless, and programs can be run at startup with methods such as &lt;a href=&quot;http://www.raspberrypi-spy.co.uk/2013/07/running-a-python-script-at-boot-using-cron/&quot; rel=&quot;nofollow&quot;&gt;cron&lt;/a&gt; or by &lt;a href=&quot;http://www.raspberry-projects.com/pi/pi-operating-systems/raspbian/auto-running-programs&quot; rel=&quot;nofollow&quot;&gt;adding it to rc.local&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To simplify things your sensors, I would suggest going with the Arduino, since most sensors use 5v like the arduino does, whereas the Pi uses 3.3v. However, since the Arduino's programmed in a C variant, you may want to use the RPi because it works with Python natively, and you could use Java if you really wanted.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But all in all it comes down to preference, both could get the job done.&lt;/p&gt;&#xA;" OwnerUserId="2399" LastActivityDate="2013-12-16T04:39:39.437" CommentCount="2" />
  <row Id="2154" PostTypeId="2" ParentId="2145" CreationDate="2013-12-16T07:26:51.223" Score="1" Body="&lt;p&gt;Try the Point Clound Library (PCL). They claim to have support for both. I've used it with Kinect, it works quite well. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;------&gt; &lt;a href=&quot;http://pointclouds.org/&quot; rel=&quot;nofollow&quot;&gt;Point Cloud Library&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="2391" LastActivityDate="2013-12-16T07:26:51.223" />
  <row Id="2155" PostTypeId="2" ParentId="2081" CreationDate="2013-12-16T12:41:46.360" Score="1" Body="&lt;p&gt;Sounds like what you need is transparent vinyl. Opaque vinyl is routinely used as a floor covering ('Cushionfloor', for example)where it is durable and easy to use. The transparent product is readily available, and the price varies because of polishing treatments to render it more window glass like. As you're just shining LEDs thorough it, the cheapest kind should work well. It comes in sheets up to at least 1 mm thick, and you could sandwich layers. I can get 5' by 7' sheets here in Canada for approx ~2$...its sold in many stores as a tablecloth protector. There is also a thicker version with molded nubs that is sold as a floor runner - typically 2' wide and cut to length by many hardware stores. If installed upside down, the LEDs and wires could probably be wound through the nubs, affording them considerable protection.&lt;/p&gt;&#xA;" OwnerUserId="2402" LastActivityDate="2013-12-16T12:41:46.360" />
  <row Id="2156" PostTypeId="1" CreationDate="2013-12-16T17:15:25.567" Score="1" ViewCount="44" Body="&lt;p&gt;I am testing an industrial robot (&lt;a href=&quot;http://www.abb.us/product/seitp327/aebd514c0e25af94c125714c0044106a.aspx&quot; rel=&quot;nofollow&quot;&gt;ABB IRB 1410&lt;/a&gt;) using three simple Micron Dial gauges to get x,y,z values at particular point by varying Speed, Load and distance from home position. &#xA;My questions are,&#xA;Whether these three parameters influencing the repeatability or only the accuracy?&#xA;Using dial gauges, without any relation to the Base frame, is it possible to measure accuracy?&#xA;Is any other cost effective method to measure the repeatability and accuracy like above method?&lt;/p&gt;&#xA;" OwnerUserId="2405" LastEditorUserId="350" LastEditDate="2013-12-31T17:43:47.273" LastActivityDate="2013-12-31T17:43:47.273" Title="How to calibrate an industrial Robot?" Tags="&lt;industrial-robot&gt;&lt;calibration&gt;" AnswerCount="1" FavoriteCount="1" />
  <row Id="2157" PostTypeId="2" ParentId="2146" CreationDate="2013-12-17T19:21:09.747" Score="1" Body="&lt;p&gt;You can use least square approach and solve this problem using Gauss-Newton method. Following blog post sums it up very well. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://chionophilous.wordpress.com/2011/08/26/accelerometer-calibration-iii-improving-accuracy-with-least-squares-and-the-gauss-newton-method/&quot; rel=&quot;nofollow&quot;&gt;http://chionophilous.wordpress.com/2011/08/26/accelerometer-calibration-iii-improving-accuracy-with-least-squares-and-the-gauss-newton-method/&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="2118" LastActivityDate="2013-12-17T19:21:09.747" CommentCount="1" />
  <row Id="2158" PostTypeId="1" AcceptedAnswerId="2166" CreationDate="2013-12-17T23:12:35.343" Score="6" ViewCount="94" Body="&lt;p&gt;I'd like to build a robot as small as possible and with as few &quot;delicate&quot; parts as possible (the bots will be bashing into each other).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I was wondering if it was possible to use a small chip that could receive bluetooth/IR/wifi commands to move the motors, and in turn, send back feedback based on sensors such as an accelerometer (to detect impact).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I can probably achieve something like this with the &lt;a href=&quot;http://www.piborg.org/picypack&quot; rel=&quot;nofollow&quot;&gt;PiCy&lt;/a&gt; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://i.stack.imgur.com/vjVzf.jpg&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/vjVzfm.jpg&quot; alt=&quot;picy&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;however this is slightly bigger than I'd like (due to the size of the Pi) and I'm not sure how long the Pi would last taking continuous impacts.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'd therefore like to try to offset the brain (the Pi) to the side of the arena and just use a small chip to receive move commands, and send back data from the accelerometer.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Do you have any recommendations for such a chip? Wifi would be my choice but if it impacts the size I could try BT&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Edit: After further research it seems an Arduino nano with a WiFi RedBack shield might do the job along with something like this for the motors: &lt;a href=&quot;http://www.gravitech.us/2mwfecoadfor.html&quot; rel=&quot;nofollow&quot;&gt;http://www.gravitech.us/2mwfecoadfor.html&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1682" LastEditorUserId="350" LastEditDate="2013-12-18T14:56:31.097" LastActivityDate="2013-12-18T21:44:14.207" Title="Making a tiny robot by using a remote brain" Tags="&lt;raspberry-pi&gt;&lt;rcservo&gt;&lt;accelerometer&gt;" AnswerCount="3" />
  <row Id="2159" PostTypeId="1" CreationDate="2013-12-17T23:47:05.587" Score="1" ViewCount="54" Body="&lt;p&gt;&lt;a href=&quot;http://www.youtube.com/watch?v=4Vh_R1NlmX0&quot; rel=&quot;nofollow&quot;&gt;http://www.youtube.com/watch?v=4Vh_R1NlmX0&lt;/a&gt; is from 2011 SWARM and shows RC aircraft or combat wings trying to hit each other in the air. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Scoring a hit is pretty rare, and I'd like to increase a pilot's chances by using a computer targeting system.  It would be an offline system that gets data from sensors on the airplane.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What sensor(s) would work for this application?&lt;/p&gt;&#xA;" OwnerUserId="2414" LastActivityDate="2013-12-17T23:47:05.587" Title="computer aided RC airplane combat" Tags="&lt;mobile-robot&gt;&lt;sensors&gt;" CommentCount="7" FavoriteCount="1" />
  <row Id="2160" PostTypeId="2" ParentId="2119" CreationDate="2013-12-17T23:54:08.467" Score="0" Body="&lt;p&gt;If your force sensor is sliding along the inside of the box, the end of each side will be felt by the change in the wall's orientation. If you are feeling along the outside of the box, when the 'finger' loses contact, have the finger sweep a circle. If its a hole in the box, then picking the right radius circle will re-establish contact with the box wall. If its a corner, then contact will be re established at an angle - typically +/- 90 degrees from the course the finger was following before it lost contact. I presume the deburrer is operating in concert with the contact sensor, but if the box is secured against movement, and time is not an issue, the box edge could be mapped before a deburring pass initiated. Also, the touch sensor may be able to detect the irregularity of the burr, not only to signal end of deburr, but being able to modify the deburring technique to match the burr's heaviness.&lt;/p&gt;&#xA;" OwnerUserId="2402" LastActivityDate="2013-12-17T23:54:08.467" />
  <row Id="2161" PostTypeId="2" ParentId="2147" CreationDate="2013-12-18T03:59:38.130" Score="2" Body="&lt;p&gt;&quot;All I need to do&quot;.... Famous last words. This is a very complicated project to attempt for multiple reasons. I'll try to break down these challenges. For documentation, the datasheet has all the information that you need, but there is probably not any code available that is ready to use. Sparkfun has recently introduced a 'degree of difficulty' rating for parts, and from what I can discern just using the camera is beyond your current skill level. This doesn't mean you can't do the project, but you will be learning a lot along the way :)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To break this project down, you have a few challenges. First, you have a I2C &lt;em&gt;control&lt;/em&gt; interface, and a &lt;em&gt;parallel&lt;/em&gt; data output. There are a few other pins, such as the various power supplies required and the CLK, Hsync, and Vsync pins. The I/O connections aren't too complicated, but there are two different power supply domains (1.5V and 2.8V that you need &lt;em&gt;in addition to&lt;/em&gt; your Arduino supply.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Once you have the circuit connected electrically, then you need to implement the camera control codes. This will allow you to at least set the resolution and FPS on the camera, and probably control when the camera captures images.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then you need to transfer the image data from the camera to your microcontroller. This is done as parallel data transferred one byte at a time, and the entire sensor is row/column scanned to output the image as raw data. This means that you need at least as much RAM as the resolution of the image you are receiving. Also, the minimum transfer rate listed in the datasheet is basically 12 MBytes / sec, which is probably difficult to implement with a regular Arduino. The RAM required per frame ranges from 7MByte for full resolution, down to &#xA;25kByte for the subQCIF resolution. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Once you have an image in memory, then you need to encode each frame into some video format because even at the lowest bitrate you will be recording 370kByte/sec as a raw data. Video encoding is probably very difficult to do on an Arduino (or without a video encoding library and/or core). Encoding will require additional RAM on the device, and will vary depending on the codec you use.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Once you have encoded the video into some format, you will need to transfer it to the SD card. Again, video takes a lot of bandwidth, and it is unlikely that an Arduino will be able to interface with a SD card in a way that will provide enough bandwidth for transferring video in real-time. (AFAIK, most Arduinos access SD cards through the SPI interface - this will be very slow compared to what you need).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;All in all, there are a lot of challenges to recording video from a raw sensor. They aren't insurmountable, but they are significant.&lt;/p&gt;&#xA;" OwnerUserId="2415" LastActivityDate="2013-12-18T03:59:38.130" CommentCount="1" />
  <row Id="2162" PostTypeId="2" ParentId="2158" CreationDate="2013-12-18T07:41:41.340" Score="0" Body="&lt;p&gt;There are two approaches to build the robots you describe.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The first, as you suggest, is to decouple the processing power from the rest of the robot which holds the sensors and actuators. To do that you need some communication between the processing unit (PC/RPi/Other microcontroller) and your robot. A low-cost solution for this is to use cheap Bluetooth modules (search ebay for 'Serial Bluetooth Module', they should't cost more than $5). On the robot side you will need a microcontroller as well since you need to receive the data from the Bluetooth, process it and convert it to control signals for the motors. Additionally, the same microcontroller will be responsible for reading the sensors and transmitting the data back to the remote processing unit.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The second approach is to have a single processing unit which is located on the robot. The same controller will read the sensors, provide the intelligence and control the motors. Because the robot you describe it simple, this controller could be implemented on simple microcontroller. You can create your own controller (using PIC/AVR/ARM) or you can use a ready solution like an Arduino, BasicStamp etc. Optionally you can have Bluetooth connection with a PC for telemetry (observing the sensors values and/or manually controlling the robot).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For your project, the second approach seems more appealing. It will cost much less and robots will react faster since the processing is done directly on the robot. Also since the first approach requires a processing unit on the robot as well it seems like an overkill to use a second unit for processing. On the other hand, the first approach allows you to develop your robot controller in a higher level system (PC/RPi) which depending on your experience, may be a more comfortable environment.&lt;/p&gt;&#xA;" OwnerUserId="1445" LastEditorUserId="1445" LastEditDate="2013-12-18T18:57:11.870" LastActivityDate="2013-12-18T18:57:11.870" CommentCount="4" />
  <row Id="2163" PostTypeId="2" ParentId="2138" CreationDate="2013-12-18T11:59:42.077" Score="0" Body="&lt;p&gt;I've found this usefull:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#!/usr/bin/env python&#xA;import roslib; roslib.load_manifest('robot_mover')&#xA;import rospy&#xA;&#xA;from geometry_msgs.msg import Twist&#xA;&#xA;def mover():&#xA;    pub = rospy.Publisher('cmd_vel', Twist)&#xA;    rospy.init_node('robot_mover')&#xA;&#xA;    twist = Twist()&#xA;    twist.linear.x = 0.1; # move forward at 0.1 m/s   &#xA;&#xA;    rospy.loginfo(&quot;Moving the robot forward.&quot;)&#xA;    pub.publish(twist)&#xA;    rospy.sleep(1)&#xA;&#xA;    rospy.loginfo(&quot;Moving the robot backward.&quot;)&#xA;    twist.linear.x = -0.1; # move backward at 0.1 m/s&#xA;    pub.publish(twist)&#xA;    rospy.sleep(1);&#xA;&#xA;    rospy.loginfo(&quot;Turning the robot left.&quot;);&#xA;    twist = Twist();&#xA;    twist.angular.z = 0.5&#xA;    pub.publish(twist)&#xA;    rospy.sleep(1);&#xA;&#xA;    rospy.loginfo(&quot;Turning the robot right.&quot;);&#xA;    twist.angular.z = -0.5&#xA;    pub.publish(twist)&#xA;    rospy.sleep(1);&#xA;&#xA;    rospy.loginfo(&quot;Stopping!&quot;)&#xA;    twist = Twist()&#xA;    pub.publish(twist)&#xA;&#xA;    rospy.loginfo(&quot;Node exiting.&quot;);&#xA;&#xA;if __name__ == '__main__':&#xA;    try:&#xA;        mover()&#xA;    except rospy.ROSInterruptException: pass&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Source: &lt;a href=&quot;http://pharos.ece.utexas.edu/wiki/index.php/Writing_A_Simple_Node_that_Moves_the_iRobot_Create_Robot&quot; rel=&quot;nofollow&quot;&gt;http://pharos.ece.utexas.edu/wiki/index.php/Writing_A_Simple_Node_that_Moves_the_iRobot_Create_Robot&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="2202" LastActivityDate="2013-12-18T11:59:42.077" />
  <row Id="2164" PostTypeId="2" ParentId="2158" CreationDate="2013-12-18T15:18:18.047" Score="1" Body="&lt;p&gt;You might find that the rPI boards are more durable than you expected.  There isn't much mass to them, so a small amount of rubber or foam padding (to reduce rattling around) should be sufficient to protect them -- provided that your robots aren't bashing together with enough force to crack the plastic casing around them.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Offloading the processing onto a remote (and likely more powerful) system will give you a few advantages, like the ones you've noted -- less weight, less to break, less battery required to move the thing around.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The downsides will be the bandwidth limitations, and the latency.  Once you introduce the delay of wireless transmissions, you go from a hardware-based loop that can handle in the ballpark of thousands of iterations per second to a networking-based loop that can handle only dozens of iterations per second.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;For best results, your design should do as much control processing as possible on the local hardware, and use the remote connection for higher-level planning decisions that only will need to be received a few times per second.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-12-18T15:18:18.047" CommentCount="1" />
  <row Id="2165" PostTypeId="1" CreationDate="2013-12-18T16:25:12.583" Score="1" ViewCount="31" Body="&lt;p&gt;I'm building a project that uses a cell phone to control a microcontroller via Bluetooth.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've decided to use the HC-05 Bluetooth module.&#xA;&lt;br&gt;HC-05 Manual: &lt;a href=&quot;http://www.exp-tech.de/service/datasheet/HC-Serial-Bluetooth-Products.pdf&quot; rel=&quot;nofollow&quot;&gt;http://www.exp-tech.de/service/datasheet/HC-Serial-Bluetooth-Products.pdf&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And the phone I'm using is the Nokia C3-00 (series 40).&#xA;&lt;br&gt;&lt;a href=&quot;http://developer.nokia.com/Devices/Device_specifications/C3-00/&quot; rel=&quot;nofollow&quot;&gt;http://developer.nokia.com/Devices/Device_specifications/C3-00/&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The HC-05 module uses the SPP Bluetooth profile while my phone only supports DUN, FTP, GAP, GOEP, HFP, HSP, OPP, PAN, SAP, SDAP profiles. But to my knowledge the phone API utilizes RFCOMM.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Question is, can I use this Bluetooth module with my phone?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks in advance and my apologies if my question is too trivial as I'm quite new to Bluetooth.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;-Shaun &lt;/p&gt;&#xA;" OwnerUserId="2422" LastActivityDate="2013-12-18T16:25:12.583" Title="SPP Bluetooth profile compatibility with phone" Tags="&lt;microcontroller&gt;" />
  <row Id="2166" PostTypeId="2" ParentId="2158" CreationDate="2013-12-18T21:01:21.683" Score="0" Body="&lt;p&gt;I think I may have found the perfect controller for this project:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.robotshop.com/en/dagu-micro-magician-robot-controller.html&quot; rel=&quot;nofollow&quot;&gt;http://www.robotshop.com/en/dagu-micro-magician-robot-controller.html&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The Micro Magician will allow me to control 2 simple DC motors, detect impacts and crashes with the accelerometer AND receive move commands from the IR receiver! Pretty awesome for the size. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The only piece left in the puzzle is sending back the data to the remote controller (accelerometer data). I'm not sure if I could attach an IR transmitter or maybe BT/Wifi? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Edit: looks like this could do the job! &lt;a href=&quot;http://www.dawnrobotics.co.uk/dagu-arduino-bluetooth-module/&quot; rel=&quot;nofollow&quot;&gt;http://www.dawnrobotics.co.uk/dagu-arduino-bluetooth-module/&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now to find small motors...&lt;/p&gt;&#xA;" OwnerUserId="1682" LastEditorUserId="1682" LastEditDate="2013-12-18T21:44:14.207" LastActivityDate="2013-12-18T21:44:14.207" CommentCount="1" />
  <row Id="2167" PostTypeId="1" CreationDate="2013-12-19T06:06:10.373" Score="2" ViewCount="225" Body="&lt;p&gt;I'm trying to get a quad rotor to fly. The on board controller is an Ardupilot Mega 2.6, being programmed by Arduino 1.0.5.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm trying to fly it in simple autonomous mode, no Radio controller involved. I've done a thorough static weight balancing of the assembly (somewhat like this: &lt;a href=&quot;http://www.youtube.com/watch?v=3nEvTeB2nX4&quot; rel=&quot;nofollow&quot;&gt;http://www.youtube.com/watch?v=3nEvTeB2nX4&lt;/a&gt;) and the propellers are balanced correctly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm trying to get the quadcopter to lift using this code:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#include &amp;lt;Servo.h&amp;gt;&#xA;&#xA;&#xA;int maxspeed = 155;&#xA;int minspeed = 0;&#xA;&#xA;Servo motor1;&#xA;Servo motor2;&#xA;Servo motor3;&#xA;Servo motor4;&#xA;&#xA;int val = 0;&#xA;int throttleCurveInitialGradient = 1;&#xA;&#xA;void setup()&#xA;{&#xA;&#xA;&#xA;val = minspeed;&#xA;&#xA;motor1.attach(7);&#xA;motor2.attach(8);&#xA;motor3.attach(11);&#xA;motor4.attach(12);&#xA;&#xA;&#xA;}&#xA;&#xA;&#xA;void loop()&#xA;{&#xA;setAllMotors(val);&#xA;delay(200);&#xA;val&amp;gt;maxspeed?true:val+=throttleCurveInitialGradient;&#xA;}&#xA;&#xA;void setAllMotors(int val)&#xA;  {&#xA;    motor1.write(val);&#xA;    motor2.write(val);&#xA;    motor3.write(val);&#xA;    motor4.write(val);&#xA;  }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;But the issue is, as soon as the quadcopter takes off, it tilts heavily in one direction and topples over. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;It looks like one of the motor/propeller is not generating enough thrust for that arm to take-off. I've even tried offsetting the weight balance against the direction that fails to lift, but it doesn't work (and I snapped a few propellers in the process);&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Is there something wrong with the way the ESCs are being fired using&#xA;the Servo library?&lt;/li&gt;&#xA;&lt;li&gt;If everything else fails, am I to assume there is something wrong&#xA;with the motors?&lt;/li&gt;&#xA;&lt;li&gt;Do I need to implement a PID controller for self-balancing the roll&#xA;and pitch just to get this quadrotor to take off?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Edit 1:&lt;/strong&gt;    Thanks for all the replies.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I got the PID in place. Actually, it is still a PD controller with the integral gain set to zero. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here's how I'm writing the angles to the servo:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;motor1.write((int)(val + (kP * pError1) +(kI * iError1) +(kD * dError1)));  //front left&#xA;motor2.write((int)(val + (kP * pError2) +(kI * iError2) +(kD * dError2)));  //rear right&#xA;motor3.write((int)(val + (kP * pError3) +(kI * iError3) +(kD * dError3)));  //front right&#xA;motor4.write((int)(val + (kP * pError4) +(kI * iError4) +(kD * dError4)));  //rear left &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;kI is zero, so I'll ignore that.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;With the value of kP set somewhere between 0.00051 to 0.00070, I'm getting an oscillation of steady amplitude around a supposed mean value. But the problem is, the amplitude of oscillation is way too high. It is somewhere around +/- 160 degrees, which looks crazy even on a tightly constrained test rig. &lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;[  &lt;strong&gt;Edit 2:&lt;/strong&gt; &lt;em&gt;How I calculate the term 'pError'&lt;/em&gt; - Simple linear thresholding. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've a precomputed data of the average readings (mean and SD) coming out of the gyro when the IMU is steady. Based on the gyro reading, I classify any motion of the setup as left, right, forward or backward. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;For each of these motion, I increase the pError term for two of the motors, i.e, for right tilt, I add pError terms to motors 2 &amp;amp; 3, for left tilt, I add pError term to motors 1 &amp;amp; 4 etc. (check the comment lines in the code snippet given above). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The magnitude of error I assign to the pError term is = &lt;em&gt;abs(current gyro reading) - abs(mean steady-state gyro reading)&lt;/em&gt;. This value is always positive, therefore the side that is dipping downwards will always have a positive increment in RPM.  ]&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;As I crank up the derivative gain to around 0.0010 to 0.0015, the oscillation dampens rapidly and the drone comes to a relatively stable attitude hold, but not on the horizontal plane. The oscillation dies down (considerably, but not completely) only to give me a stable quadrotor tilted at 90 - 100 degrees with horizontal. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm using only the gyros for calculating the error. The gyros were self calibrated, hence I do expect a fair amount of noise and inaccuracy associated with the error values. &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Do you think that is the primary reason for the high amplitude&#xA;oscillation?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;One other probable reason might be the low update frequency of the errors. I'm updating the errors 6 times a second. &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Could that be a probable reason it is taking longer to stabilise the&#xA;error?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;And, for the steady state error after the wild oscillations dampen, is it necessary to fine tune the integral gain to get rid of that?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Please help.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Edit 3:&lt;/strong&gt;  I cranked up the frequency of operation to 150+ Hz and what I get now is a very controlled oscillation (within +/- 10 degrees). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm yet to tune the derivative gain, following which I plan to recompute the errors for the integral gain using a combination of gyro and accelerometer data. &lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Edit 4:&lt;/strong&gt;  I've tuned the P and D gain, resulting in +/- 5 degrees oscillation(approx). I can't get it to any lower than this, no matter how much I try.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are two challenges about which I'm deeply concerned:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;After 5 to 8 seconds of flight, the quadcopter is leaning into one side, albeit slowly. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;A) Can this drift be controlled by tuning the integral gain?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;B) Can the drift be controlled by using accelerometer + gyro fused data?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;C) Given that my drone still shows +/- 5 degrees oscillation, can I consider this the optimal set point for the proportional and derivative gains? Or do I need to search more? (In which case, I'm really at my wits end here!) &lt;/p&gt;&#xA;" OwnerUserId="1949" LastEditorUserId="1949" LastEditDate="2013-12-31T10:26:59.590" LastActivityDate="2014-01-15T14:55:45.973" Title="Quadcopter instability with simple takeoff in autonomous mode" Tags="&lt;arduino&gt;&lt;quadcopter&gt;&lt;quadrotor&gt;&lt;pid&gt;&lt;ardupilot&gt;" AnswerCount="5" CommentCount="6" />
  <row Id="2169" PostTypeId="2" ParentId="2167" CreationDate="2013-12-19T20:57:35.733" Score="5" Body="&lt;p&gt;Even very small errors can bother the balancing. Small errors such as: &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Weight of the quadcopter is unbalanced. &lt;/li&gt;&#xA;&lt;li&gt;One motor is rotating faster/slower than others due to manufacturing or your power-source. &lt;/li&gt;&#xA;&lt;li&gt;Air resistance and wind. &lt;/li&gt;&#xA;&lt;li&gt;Unbalanced propellers due to manufacturing.&lt;/li&gt;&#xA;&lt;li&gt;Strong magnetic forces.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;You simple can not send the same motor speed to all motors and expect it to hover. &#xA;You do need a sensor which can read the tilting of the robot and adjust the motor speeds based on the tilt angles. To do that you need to implement a PID controller (The simplest method).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As far as I know there are some PID controller for arudino. But you could always write your own simple version of a PID controller.&lt;/p&gt;&#xA;" OwnerUserId="2360" LastActivityDate="2013-12-19T20:57:35.733" CommentCount="4" />
  <row Id="2170" PostTypeId="2" ParentId="2167" CreationDate="2013-12-19T22:19:03.310" Score="3" Body="&lt;p&gt;Quadcopter is inherently unstable system. So you have to apply some feedback controller (eg. PID) to keep it airborne. Even if you apply some basic PID using angular rates and angles, you still have to provide manual correction for drift till PID gains are perfectly set. So using radio control for manual control is really helpful during initial development stage.&lt;/p&gt;&#xA;" OwnerUserId="2118" LastActivityDate="2013-12-19T22:19:03.310" />
  <row Id="2171" PostTypeId="5" CreationDate="2013-12-19T23:04:50.987" Score="0" ViewCount="3" Body="" OwnerUserId="-1" LastEditorUserId="-1" LastEditDate="2013-12-19T23:04:50.987" LastActivityDate="2013-12-19T23:04:50.987" />
  <row Id="2172" PostTypeId="4" CreationDate="2013-12-19T23:04:50.987" Score="0" Body="Quadcopter aka Quadrotor is a flying robot which uses four rotors for lift, stability and control." OwnerUserId="2118" LastEditorUserId="2118" LastEditDate="2013-12-25T10:19:45.313" LastActivityDate="2013-12-25T10:19:45.313" />
  <row Id="2173" PostTypeId="1" CreationDate="2013-12-19T23:13:08.690" Score="1" ViewCount="26" Body="&lt;p&gt;I am a beginner of both ROS, Kinect and Ubuntu. What i want is to visualize kinect data on rviz environment then run object recognition on it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've tried a few tutorials but had no luck. All I got was an empty rviz world.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Since I am a beginner I would appreciate any step-by-step intructions (preferably for hydro or groovy).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would also like to note that I've menaged to get visual from kinect so the device is working fine.&lt;/p&gt;&#xA;" OwnerUserId="2433" LastActivityDate="2014-01-19T02:16:38.423" Title="Visualizing kinect data on rviz" Tags="&lt;ros&gt;&lt;kinect&gt;" AnswerCount="1" />
  <row Id="2174" PostTypeId="2" ParentId="2173" CreationDate="2013-12-20T01:18:44.983" Score="0" Body="&lt;p&gt;For ROS-related questions, &lt;a href=&quot;http://answers.ros.org/&quot; rel=&quot;nofollow&quot;&gt;its QA forum&lt;/a&gt; is the best place to ask question like this.&lt;/p&gt;&#xA;" OwnerUserId="60" LastActivityDate="2013-12-20T01:18:44.983" />
  <row Id="2175" PostTypeId="2" ParentId="2111" CreationDate="2013-12-20T18:53:25.083" Score="2" Body="&lt;p&gt;Short Answer: No.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;While there is a lot of media hype, and patent applications, there isn't any nanobots being commercially manufactured. Its unlikely that any legislative or FDA approval would happen before there are working demonstration models of actual utility.&#xA;There are several significant problems that have to be solved before we see any kind of production models: a lack of nanoscale processors and dependable nanoscale power supplies probably being the two biggest problems. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would estimate 20+ years before they become mainstream.&lt;/p&gt;&#xA;" OwnerUserId="2402" LastActivityDate="2013-12-20T18:53:25.083" />
  <row Id="2176" PostTypeId="2" ParentId="1603" CreationDate="2013-12-20T19:23:32.223" Score="0" Body="&lt;p&gt;The camera is enough to locate the robot if its mounted high enough,unless the robot is hidden by furniture. If the furniture hides the robot from the camera, it will hide it from a&#xA;IR Beacon.&#xA;If you start the robot in a visible position, don't have too much cover, and use dead reckoning when under cover, you should be okay.The dead reckoning will add error to the robot's known position, but really, how much time is it going to spend underneath a table?&#xA;The position can be corrected when the robot comes back into view.&lt;/p&gt;&#xA;" OwnerUserId="2402" LastActivityDate="2013-12-20T19:23:32.223" />
  <row Id="2179" PostTypeId="2" ParentId="1603" CreationDate="2013-12-22T19:18:12.373" Score="0" Body="&lt;p&gt;First run the Canny edge detector on the captured image. Next dilate the edges by 1 or 2 pixels in the image. Then search the colour image for what ever colour you are looking for. generally pure R,G,or B are good as they aren't very natural. This allows you to localize in the image. Now run the wave front algorithm in the Canny image. It's not very hard to implement its just breadth first search where neighbours are pixels and pixels with value 255 (white) aren't added to the search queue as they are walls. You may want to convert the canny image from 8bit to 16bit so that you can move more than 255 pixels. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The only problem is that is assumes the ground plane has no edges (i.e. not tile or hardwood floor) and it can't deal with obstacles like tables that one can navigate under. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In order to remedy this you would have to find the ground plane somehow. This could be done with a stereo camera or a Kinect. &lt;/p&gt;&#xA;" OwnerUserId="2391" LastActivityDate="2013-12-22T19:18:12.373" />
  <row Id="2180" PostTypeId="1" AcceptedAnswerId="2181" CreationDate="2013-12-23T12:22:29.310" Score="1" ViewCount="74" Body="&lt;p&gt;If not all, but major types of lawn mower robots are rotary mowers.&#xA;I presume&lt;sup&gt;1&lt;/sup&gt; that reel mower is more efficient, and is said to leave a better lawn health and cut. So, why industry go to the other option?&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;sup&gt;1 - I'm assuming the efficiency, as electrical rotary mowers have at least 900W universal-motors or induction motors, and a manual reel mower is capable nearly the same cutting speed.&lt;/sup&gt;&lt;/p&gt;&#xA;" OwnerUserId="2447" LastEditorUserId="2447" LastEditDate="2014-01-06T18:17:32.180" LastActivityDate="2014-01-06T18:17:32.180" Title="Lawn mower robot (type of cutter)" Tags="&lt;motor&gt;&lt;mechanism&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="2181" PostTypeId="2" ParentId="2180" CreationDate="2013-12-23T15:28:43.740" Score="3" Body="&lt;p&gt;Rotary mowers are mechanically simpler, so cheaper to make. The rotary mower is more tolerant of getting dull, and if you run over something like small trees or rocks, the blades take less damage, and the motor is harder to jam and stall.&#xA;The blades are also easier to sharpen.&#xA;For this simplicity, you get a poorer cut, and more grass damage.&#xA;I do agree, though, that the reel mower would be more efficient. You'd probably need more sensors though, to watch for jamming.&lt;/p&gt;&#xA;" OwnerUserId="2402" LastActivityDate="2013-12-23T15:28:43.740" CommentCount="0" />
  <row Id="2182" PostTypeId="1" CreationDate="2013-12-24T13:39:37.847" Score="1" ViewCount="79" Body="&lt;p&gt;I was wondering, my team and me are working on a robot communication-oriented and we wanted to add speech recognition on it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What technology should I use ?&lt;/p&gt;&#xA;" OwnerUserId="2455" LastActivityDate="2013-12-25T20:13:59.860" Title="What should I use for speech recognition?" Tags="&lt;software&gt;" AnswerCount="3" CommentCount="1" ClosedDate="2014-01-06T20:04:21.143" />
  <row Id="2183" PostTypeId="2" ParentId="2182" CreationDate="2013-12-24T14:03:41.747" Score="2" Body="&lt;p&gt;You must go through softwares like matlab(licensed). Open source versions are also available like QtOctave and FreeMat.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You must have a sound knowledge about Digital Signal Procesing , different type of Filters etc..&lt;/p&gt;&#xA;" OwnerUserId="2456" LastActivityDate="2013-12-24T14:03:41.747" CommentCount="2" />
  <row Id="2184" PostTypeId="2" ParentId="2182" CreationDate="2013-12-24T18:10:12.860" Score="1" Body="&lt;p&gt;I don't think there is any &quot;must&quot; for you task. In turn, it depends on what your robot platform is. In the context of embedded systems, MATLAB could be cumbersome.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I don't know what your robot system is like, but maybe this &lt;a href=&quot;http://www.pirobot.org/blog/0022/&quot; rel=&quot;nofollow&quot;&gt;article&lt;/a&gt; based on ROS and Sphinx is a good starting point?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, for the purpose of understanding speech recognition technologies, the &lt;a href=&quot;http://htk.eng.cam.ac.uk/&quot; rel=&quot;nofollow&quot;&gt;HTK toolkit&lt;/a&gt; and the &lt;a href=&quot;http://en.wikipedia.org/wiki/HTK_%28software%29&quot; rel=&quot;nofollow&quot;&gt;HTK book&lt;/a&gt; are a good reference.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For a general idea of the state-of-art research on speech recognition, you can also visit &lt;a href=&quot;http://www-i6.informatik.rwth-aachen.de/rwth-asr/&quot; rel=&quot;nofollow&quot;&gt;http://www-i6.informatik.rwth-aachen.de/rwth-asr/&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1064" LastActivityDate="2013-12-24T18:10:12.860" CommentCount="1" />
  <row Id="2185" PostTypeId="2" ParentId="2156" CreationDate="2013-12-25T01:08:15.700" Score="1" Body="&lt;p&gt;Without relation to the base frame, or to some physical point, absolute accuracy cannot be measured.&#xA;You can measure repeatability via a dial gauge and any fixed point, but absolute accuracy will require careful measurements from wherever on the robot that 0,0,0 is referenced from. &#xA;Repeatability requires only one point of reference, although you will get a better idea of over all performance if you use several points. But accuracy has to be a measurement between TWO points.&#xA;One being a reference point - such as the base frame, and the other can be arbitrary.&#xA;If you have a long accurate ruler,or rod of known length, this could be clamped into any arbitrary position, and the arm  made to run from one end to the other, and then measure the offset from that. That would give you some idea of how accurate it is across the section of its reach, which would be probably pretty close to its absolute accuracy.&#xA;Errors would be introduced by the rulers inaccuracys in length, and bend.&lt;/p&gt;&#xA;" OwnerUserId="2402" LastActivityDate="2013-12-25T01:08:15.700" CommentCount="3" />
  <row Id="2186" PostTypeId="1" AcceptedAnswerId="2188" CreationDate="2013-12-25T17:00:21.147" Score="2" ViewCount="82" Body="&lt;p&gt;That is what I came to understand while reading here and there about flashing a new bootloader/understanding what a bootloader is etc etc&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The bootloader is supposed to be the first thing that runs when I power up my Arduino Duemilanove (or micro controllers in general). It does some setup then runs my app. It also listens to the usb cable so that if I upload some code it erases the old one and run the new one. There are 2 sections in the memory, one for the bootloader (S1) and one for the app (S2). Code on S1 can write to S2 but not to S1 (or strongly discouraged I don't remember).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are things that I don't understand though :&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;If I upload some new code &lt;em&gt;while my app is running&lt;/em&gt;, the upload works. What happened ? I thought that the bootloader gave hand to my app&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;How can we flash a new bootloader ? If the bootloader is the thing that runs on section 1 (S1) and can only write to S2 and if the bootloader is the only thing that listens to new code uploads, ...&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Can you help me correct my thoughts and answer my questions ? Many thanks !&lt;/p&gt;&#xA;" OwnerUserId="2396" LastActivityDate="2013-12-25T21:49:46.243" Title="Understanding Arduino bootloader" Tags="&lt;arduino&gt;&lt;microcontroller&gt;" AnswerCount="1" CommentCount="2" />
  <row Id="2187" PostTypeId="2" ParentId="2182" CreationDate="2013-12-25T20:13:59.860" Score="0" Body="&lt;p&gt;You may find the Natural Language Tool Kit useful.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://nltk.org/&quot; rel=&quot;nofollow&quot;&gt;http://nltk.org/&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="2391" LastActivityDate="2013-12-25T20:13:59.860" CommentCount="1" />
  <row Id="2188" PostTypeId="2" ParentId="2186" CreationDate="2013-12-25T20:16:17.537" Score="2" Body="&lt;p&gt;(1) On several Arduino models, there's a 100 nF capacitor (at red dot in diagram) connected between DTR# on the FT232RL (or equivalent) chip and the RESET pin on the CPU.&#xA;&lt;img src=&quot;http://i.stack.imgur.com/IHRoq.jpg&quot; alt=&quot;portion of schematic from arduino-duemilanove-schematic.pdf&quot;&gt;  (Obtain file &lt;a href=&quot;http://arduino.cc/en/uploads/Main/arduino-duemilanove-schematic.pdf&quot; rel=&quot;nofollow&quot;&gt;arduino-duemilanove-schematic.pdf&lt;/a&gt; to see whole schematic.  Also see arduino.cc &lt;a href=&quot;http://arduino.cc/en/Main/arduinoBoardDuemilanove&quot; rel=&quot;nofollow&quot;&gt;Duemilanove&lt;/a&gt; page.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;DTR# normally sits high, and RESET normally is high due to an internal pullup resistor (eg 20K-50KΩ) so C13 usually has 0 volts across it.  In the Arduino process for programming via USB-serial, a programming cycle starts with DTR# being pulled down for 22ms &#xA;(&lt;a href=&quot;http://playground.arduino.cc/Learning/AutoResetRetrofit&quot; rel=&quot;nofollow&quot;&gt;1&lt;/a&gt;,&lt;a href=&quot;http://playground.arduino.cc/Main/DisablingAutoResetOnSerialConnection&quot; rel=&quot;nofollow&quot;&gt;2&lt;/a&gt;), which pulls RESET low long enough to reset the processor.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;After the reset, the bootloader initializes; stores the received program into flash memory; then runs the stored program.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note, auto-reset can be disabled (on some Arduino models) by cutting a jumper (eg, RESET-EN).  See the “Automatic (Software) Reset” sections or similar of &lt;a href=&quot;http://playground.arduino.cc/Learning/AutoResetRetrofit&quot; rel=&quot;nofollow&quot;&gt;1&lt;/a&gt;,&lt;a href=&quot;http://playground.arduino.cc/Main/DisablingAutoResetOnSerialConnection&quot; rel=&quot;nofollow&quot;&gt;2&lt;/a&gt;,&lt;a href=&quot;http://arduino.cc/en/Main/ArduinoBoardFioTips&quot; rel=&quot;nofollow&quot;&gt;3&lt;/a&gt;,&lt;a href=&quot;http://arduino.cc/en/Main/arduinoBoardUno&quot; rel=&quot;nofollow&quot;&gt;4&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(2) To &lt;a href=&quot;http://arduino.cc/en/Hacking/Bootloader&quot; rel=&quot;nofollow&quot;&gt;flash a new bootloader&lt;/a&gt;, you attach a programmer to either the 6-pin ICSP header (marked by green dot in diagram) or to J3 (blue dot).  (Using J3 may require manually pressing S1 to reset the CPU before programming; see &lt;a href=&quot;http://playground.arduino.cc/Main/DisablingAutoResetOnSerialConnection&quot; rel=&quot;nofollow&quot;&gt;2&lt;/a&gt;.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A bootloader is a program that accepts data to store into flash; or, if no program begins arriving in the first half second or so after a reset (see refs 1-4 above), it starts a previously loaded program.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Programming via &lt;a href=&quot;http://en.wikipedia.org/wiki/Serial_Peripheral_Interface_Bus&quot; rel=&quot;nofollow&quot;&gt;SPI&lt;/a&gt; (the Serial Peripheral Interface Bus, which uses the SCK, MISO, MOSI, SS pins of ICSP header for high speed full duplex serial data transfer) by contrast is a hardware operation that does not run a program from flash.  Like &lt;a href=&quot;http://en.wikipedia.org/wiki/JTAG#Storing_firmware&quot; rel=&quot;nofollow&quot;&gt;JTAG&lt;/a&gt;, it's one of the built-in hardware-level programming protocols in typical AVR chips.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;During SPI programming, RESET is held low and the AVR is like a puppet carrying out directives issued to it by the programmer device.  The AVR is not executing a user-accessible stored program during programming; it is carrying out low-level directives issued to it by the programmer device.  A programming directive precedes each bit of data on the SPI bus.  For an explanation of the serial programming algorithm, see (eg) section 30.8 in doc2549.pdf, ATmega manual #2549P–AVR–10/2012.  Section 30.8.2 on p. 350-351 explains the method.  Table 30-17 on p. 352 shows the directives used to control programming.  These include “Programming Enable”,  “Chip Erase”, “Load Extended Address byte”, “Write Program Memory Page”, etc. &lt;/p&gt;&#xA;" OwnerUserId="478" LastEditorUserId="478" LastEditDate="2013-12-25T21:49:46.243" LastActivityDate="2013-12-25T21:49:46.243" CommentCount="2" />
  <row Id="2189" PostTypeId="1" AcceptedAnswerId="2193" CreationDate="2013-12-25T22:14:34.500" Score="1" ViewCount="144" Body="&lt;p&gt;I'm a newbie in UAV stuff, your advice would be very helpful, i want to start mapping using fixed wing UAV, but my main choice was APM 2.6, but after some researches, i found that APM 2.6 won't be actively maintained in the future because the future releases will be PixHawk.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;i wonder if i should choose APM 2.6 for its stability, on the other side i don't see the benefits of Pixhawk apart having long time support. or being a newbie i should start with something experimental like APM 2.5.2 (cheap chinese version for APM).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks in advance&lt;/p&gt;&#xA;" OwnerUserId="2463" LastEditorUserId="2463" LastEditDate="2013-12-26T08:18:17.720" LastActivityDate="2013-12-27T13:19:35.927" Title="What autopilot to purchase APM 2.6 or PixHawk?" Tags="&lt;uav&gt;" AnswerCount="1" ClosedDate="2014-01-06T20:02:56.087" />
  <row Id="2190" PostTypeId="2" ParentId="2167" CreationDate="2013-12-26T08:54:48.070" Score="2" Body="&lt;p&gt;Is it always the same side that topples? If so, one obvious thing to try to eliminate the possibility that one of your motors is faulty, is to simply switch motor positions and see if the side that topples changes.&lt;/p&gt;&#xA;" OwnerUserId="1687" LastActivityDate="2013-12-26T08:54:48.070" CommentCount="1" />
  <row Id="2191" PostTypeId="2" ParentId="2083" CreationDate="2013-12-26T10:26:42.393" Score="1" Body="&lt;p&gt;It get solved automatically and that give me clear hint that when i was using 9v 1 Amp adaptor, because of heat Arduino was getting a type of HANGED..but when i powered it with USB cable..it works fine now.&lt;/p&gt;&#xA;" OwnerUserId="1322" LastActivityDate="2013-12-26T10:26:42.393" />
  <row Id="2192" PostTypeId="1" CreationDate="2013-12-27T10:07:15.863" Score="2" ViewCount="73" Body="&lt;p&gt;Everybody here is probably aware of the Sharp distance sensors (GP2Y0 series, e.g. GP2Y0A02YK0F). They use a diode to emit infrared light and measure the angle of the reflected light with a PSD (i.e. they do triangulation). This seems rather obvious and I dont think it is patented (anymore?), so... why are they effectively the only producers?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am only aware of a few similar but incomparable devices (sensors of ambient light and distance or proximity like Si114x). Which other comparable products are out there?&lt;/p&gt;&#xA;" OwnerUserId="2467" LastActivityDate="2013-12-27T10:07:15.863" Title="Why does Sharp practically have a monopoly on IR distance sensors?" Tags="&lt;sensors&gt;&lt;manufacturing&gt;" CommentCount="3" />
  <row Id="2193" PostTypeId="2" ParentId="2189" CreationDate="2013-12-27T13:19:35.927" Score="1" Body="&lt;p&gt;Pixhawk is released very recently so there is a possibility of bugs associated with software and hardware  which will be fixed as more people use it, report bugs and correct them. APM 2.6 is very much ready to go with lots of reviews and support available online.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So if you wish to be in this field for significantly long time then I would suggest go for Pixhawk. If you are very new with system and also planning to tweak around with code then APM 2.6 is good start.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Chinese version of APM 2.5.2 is surely cheap option to start but beware as there is no warranty on hardware you get.&lt;/p&gt;&#xA;" OwnerUserId="2118" LastActivityDate="2013-12-27T13:19:35.927" />
  <row Id="2195" PostTypeId="1" AcceptedAnswerId="2198" CreationDate="2013-12-28T06:53:49.067" Score="1" ViewCount="25" Body="&lt;p&gt;We are planning to recalibrate ABB IRB 1410 robot and conduct series of accuracy &amp;amp; repeatability tests using FaroArm.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My questions are&lt;/p&gt;&#xA;&#xA;&lt;p&gt;i) Is there any physical identification marker on the robot which can be used to identify the location of base co-ordinate frame?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;ii) If locating the base frame is not possible, can accuracy be measured from fixed arbitrary point in space?&lt;/p&gt;&#xA;" OwnerUserId="105" LastActivityDate="2013-12-28T14:45:19.957" Title="Re-Calibration of an articulated industrial robot" Tags="&lt;industrial-robot&gt;&lt;calibration&gt;" AnswerCount="1" />
  <row Id="2196" PostTypeId="1" CreationDate="2013-12-28T11:02:39.763" Score="2" ViewCount="101" Body="&lt;p&gt;BEAM robotics seem to be a good approach to teach learners about electronics in robotics. But can these robots be like regular programmed &quot;cognitive&quot; robots? Can these robots, with just analog circuits, take us to the level of robotic assistants, worker robots and other kinds of self sufficient autonomous robots?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I specifically want to know that, when creating mission critical robots -&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;1) What are the areas in robotics which are practically impossible without a real time software system?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;2) What areas of the field can be done without programming? If yes, are these areas feasible without an onboard software system?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;3) Could an intelligent space rover, work without a cpu in the future?&lt;/p&gt;&#xA;" OwnerUserId="2196" LastEditorUserId="2196" LastEditDate="2013-12-28T11:12:47.423" LastActivityDate="2013-12-30T20:17:08.263" Title="Robots without microcontrolers (beam robots). Are they technologically limited?" Tags="&lt;control&gt;&lt;software&gt;&lt;electronics&gt;&lt;artificial-intelligence&gt;&lt;embedded-systems&gt;" AnswerCount="3" />
  <row Id="2197" PostTypeId="1" CreationDate="2013-12-28T14:10:27.757" Score="-1" ViewCount="33" Body="&lt;p&gt;I'm having an event for a boat race.Simple boat has to be made.All i have is 5 days.The restriction is 24V motor not more than 1000 rpm.What best material and shape will you suggest to make a boat.I know basic circuits.We have to make a boat with a wired circuit.That circuiting i can do but what can be an ideal shape for boat with maximum speed it can achieve? &lt;/p&gt;&#xA;" OwnerUserId="2474" LastActivityDate="2013-12-29T14:29:38.963" Title="How can i make a boat" Tags="&lt;activerobot&gt;" AnswerCount="1" CommentCount="1" ClosedDate="2014-01-06T20:05:20.007" />
  <row Id="2198" PostTypeId="2" ParentId="2195" CreationDate="2013-12-28T14:45:19.957" Score="1" Body="&lt;p&gt;There is reference points on the robot for calibration, including one on the base.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Page 123 of this manual lists them: &#xA;&lt;a href=&quot;http://lecture.sccsc.edu/amt/AMT%20206%20Electricity%20and%20Automation/ABB%20IRB%20140%20Robot/files/3HAC026320-001_revB_en.pdf&quot; rel=&quot;nofollow&quot;&gt;http://lecture.sccsc.edu/amt/AMT%20206%20Electricity%20and%20Automation/ABB%20IRB%20140%20Robot/files/3HAC026320-001_revB_en.pdf&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;ABB does not calibrate the robot by finding the x,y,z position of the effector hand by direct measurement. They calculate it by zeroing the joints rotation sensors, and using that to 'blind reckon' x,y,z position from the 'home position'&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The problem is that the manufacturers calibration system requires the manufacturers special pendulum calibration tool. More details on the mark locations and the calibration process is this manual:&#xA;&lt;a href=&quot;http://www2.tec.ilstu.edu/students/ABB%20Robots/IRB1600_Manuals/files/3HAC16578-1_revC_en.pdf&quot; rel=&quot;nofollow&quot;&gt;http://www2.tec.ilstu.edu/students/ABB%20Robots/IRB1600_Manuals/files/3HAC16578-1_revC_en.pdf&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You may be able to rent the calibrator from ABB.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you don't have the calibration tool, then you may be able to reference using a machinists level, a accurate ruler, and a fair amount of patience! &lt;/p&gt;&#xA;" OwnerUserId="2402" LastActivityDate="2013-12-28T14:45:19.957" />
  <row Id="2199" PostTypeId="2" ParentId="2196" CreationDate="2013-12-28T21:34:34.533" Score="3" Body="&lt;p&gt;If we are defining BEAM robots as ones that do not use microprocessors, and only use analog circuits, then yes I think it is possible, but not practical.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A microprocessor is essentially a programmable circuit, and if we define what we want our robot to do, then we should be able to program the hardware (by building the proper circuit) without needing a microprocessor and programming software for it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To answer your sub questions:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;1) Without a real-time software system you can still have a real-time hardware system, so the only areas that would be impossible are areas where the robot needs to be functionally flexible and programmable post-manufacturing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;2) As answered in 1), all robots can be manufactured without software as long as the &quot;programming&quot; is defined in the hardware circuitry and doesn't need to change.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;3) Yes.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note: I'm not a hardware expert, please correct me if I'm wrong.&lt;/p&gt;&#xA;" OwnerUserId="1687" LastActivityDate="2013-12-28T21:34:34.533" CommentCount="2" />
  <row Id="2204" PostTypeId="2" ParentId="2197" CreationDate="2013-12-29T14:29:38.963" Score="2" Body="&lt;p&gt;Believe it or not, but the maximum speed a boat can achieve is related to its length.  See &lt;a href=&quot;http://en.wikipedia.org/wiki/Hull_speed&quot; rel=&quot;nofollow&quot;&gt;http://en.wikipedia.org/wiki/Hull_speed&lt;/a&gt;.  The longer the better.  The front and rear designs also have a large contribution to drag.  The pointier the better.  That's why crew racing boats are very long and pointy.  Boats with a flat stern (like a lot of speed boats) go fast because the boat planes at high speed (gets up on top of the water instead of plow through it).  So the flat back doesn't really affect them as much.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am not sure if you will be able to make your model boat plane or not with those motor specs.  But i will also say that your prop also has a big part in the speed of the boat.  If you have the same motor, but with different props, the boat can have very different speeds.  Depending on the number, angle, and shape of the blades, the prop can be torqueier for slow speeds, or faster for higher speeds.  Kind of like a transmission after a motor.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Naval architecture is a large field, that i admittedly know very little about.  I only know some of these very high level concepts.  Hopefully these rules of thumb will help you out.&lt;/p&gt;&#xA;" OwnerUserId="110" LastActivityDate="2013-12-29T14:29:38.963" />
  <row Id="2205" PostTypeId="1" AcceptedAnswerId="2207" CreationDate="2013-12-29T14:59:04.927" Score="1" ViewCount="45" Body="&lt;p&gt;I'm having a problem with controlling my BLDC motor when starting up and when running in low rpm. I have a custom board to measure rotation of the motor using an optical sensor and send servo pwm commands to an &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/__14630__Turnigy_TrackStar_18A_1_18th_Scale_Brushless_Car_ESC_.html&quot; rel=&quot;nofollow&quot;&gt;esc&lt;/a&gt;.&#xA;The problem is, that I can't start the motor smoothly. When I slowly increase the control signal, it starts stuttering and then jumps directly up to about 1500rpm.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there a way to improve this situation without using a sensored motor/esc combo?&lt;/p&gt;&#xA;" OwnerUserId="482" LastActivityDate="2013-12-29T21:57:07.097" Title="Low speed control of bldc motors" Tags="&lt;motor&gt;&lt;control&gt;&lt;brushless-motor&gt;" AnswerCount="1" CommentCount="2" FavoriteCount="1" />
  <row Id="2206" PostTypeId="2" ParentId="1466" CreationDate="2013-12-29T21:17:07.600" Score="-1" Body="&lt;p&gt;It's very possible, I stumbled upon a vimeo clip once showing a flying quadrocopter, landing on water and continuing it's journey under water... It was &quot;flying&quot; under water using the 4 props to balance and propel on low rpm. I guess that accidently opening full throttle under water would blow up the electronics, flying into the water directly would kill the props.&#xA;Hope you can find such movies and see how it works.&lt;/p&gt;&#xA;" OwnerUserId="2479" LastActivityDate="2013-12-29T21:17:07.600" />
  <row Id="2207" PostTypeId="2" ParentId="2205" CreationDate="2013-12-29T21:57:07.097" Score="2" Body="&lt;p&gt;Brushless DC motors should have excellant lower speed performance.  Your problem is probably not the motor but rather the electronic speed controller.  Those sensorless controllers generally don't perform well in low speeds because there is very little signal for them to key on.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It also sounds like you may be &quot;fighting&quot; the ESC's built in controller with your own control loop on top of it.  The first thing I would check is what's the lowest speed command the ESC can reliably take before trying to close a loop with an additional sensor.  What is your loop doing?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you want to build your own system you may want to replace the ESC with an amplifier and change your control algorithm to control the current/torque rather than speed.  Since you have your own position sensor it may somehow be possible to fake out the back-emf signature the ESC is looking for but this isn't easy and is probably a waste of time.&lt;/p&gt;&#xA;" OwnerUserId="1584" LastActivityDate="2013-12-29T21:57:07.097" />
  <row Id="2209" PostTypeId="1" AcceptedAnswerId="2212" CreationDate="2013-12-30T06:53:20.663" Score="2" ViewCount="140" Body="&lt;p&gt;I am beginning to learn about the hardware aspect of robotics, and in order for a lot of this new information to be useful to me (whether on this site or elsewhere) I will need a basic understanding of the terminology.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One thing that comes up repeatedly is different electric motors: servo, DC motor, brushless motor, step motor, gear motor... etc&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there a comprehensive list? Or at least a list of the most common ones, and their descriptions / differences?&lt;/p&gt;&#xA;" OwnerUserId="1687" LastActivityDate="2013-12-31T18:38:50.537" Title="What are the different types of electric motors?" Tags="&lt;motor&gt;" AnswerCount="2" CommentCount="1" FavoriteCount="1" />
  <row Id="2210" PostTypeId="2" ParentId="2196" CreationDate="2013-12-30T12:27:45.417" Score="3" Body="&lt;p&gt;I think you are mixing the idea of BEAM robotics (why that, I prefer to not use this term), with analog electronics.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Analog circuits are in major applications more fast than a micro processed one, that have a clock to process instructions. The &quot;problem&quot; with analogs is in part with noise, but early computers are made analog, &lt;em&gt;operational amplifiers&lt;/em&gt; are made to do computation with analog circuits.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The 74LS series, have a bunch of digital discrete ICs, they are not microprocessors, but can be flip-flops of some types, bus drivers, gate logic, and can do&#xA;a lot of &quot;processing&quot;, again generally faster than a microprocessor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But, today digital electronics and micro-controller or processors reached a point where cost is acceptable even for the hobbyist. Sometimes is more easy to make a software than the equivalent analog circuit if possible. There a number of reasons.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But you can see that micro-controllers still have analog circuits for the user, like analog comparators, A/D and D/A converters, and much more depending on the application, so &lt;strong&gt;majority of circuits are mixed type&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;But Software-less robots, spacecrafts etc. might never be close to feasible. Right?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;That is really application and project dependent, and at some degree opinion based.&#xA;Op amps for example with an analog encoder, could close a PID loop, very fast ones.&#xA;But the signal to the PID would come from a software and a D/A. &lt;strong&gt;So I don't say its impossible, but there's no subject to go this way, but again, they are in major projects mixed circuits, not only digital&lt;/strong&gt;&lt;/p&gt;&#xA;" OwnerUserId="2447" LastActivityDate="2013-12-30T12:27:45.417" />
  <row Id="2212" PostTypeId="2" ParentId="2209" CreationDate="2013-12-30T12:47:18.587" Score="4" Body="&lt;p&gt;There are too much of types to someone describe. I think a simple research will help you.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Reading the other responses I will put something, to put things like they are.&lt;/p&gt;&#xA;&#xA;&lt;h1&gt;Servo-motor&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Near any motor can be a servo motor or not&lt;/strong&gt;. That means a brushed-motor, brush-less motor, stepper-motor (that is a brush-less motor) can be a servo-motor or not. Servo-motors have a feed-back loop to know some variables like the position or speed, or both, and correct according to the signal you put. BUT, that is made by a controller, the motor just has the sensors to provide the signals.&lt;/p&gt;&#xA;&#xA;&lt;h1&gt;Brushed-motors&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;As the name suggests, these motors have a rotating part that is energized (major part is the rotor), and to energize it brushes are used. &lt;strong&gt;There's many types of brushed-motors&lt;/strong&gt;. &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;They can do its commutation mechanically, in the brushes, what generates sparks, less efficiency, EMI and RFI and more brush wear.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;They can do the switching externally, and the brushes runs on continuous ring of contact, their only function is to supply power, the commutation is done by a controller.&#xA;There's nearly no sparks at the brushes (although as the ring wear this can led to bumps of the brush in the ring what result in sparks).&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Their stator can be of magnets (normally the motor found on toys), or can be coils too (electro-magnets) as the motors found in power-tools.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/commons/thumb/f/f6/Right_Motor_Internal.JPG/180px-Right_Motor_Internal.JPG&quot; alt=&quot;Four brushes motor, showing its brushes and contact ring, and the mechanical commutation. The brushes are inside the &amp;quot;yellow&amp;quot; casing, that holds the brush with a spring to force it over the contact ring.&quot;&gt;&lt;br&gt;&#xA;&lt;sup&gt;Four brushes motor partially open, showing its brushes and contact ring, and the mechanical commutation. The brushes are inside the &quot;yellow&quot; casing, that holds the brush with a spring to force it over the contact ring. The brushes are made mainly from carbon, yet have other materials, the brush wear is visible on the contact ring&lt;/sup&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/commons/4/42/Brushed_dc_motor_dissembled.jpg&quot; alt=&quot;From left to right. Brushes of a small motor, rotor with contact ring and coils, stator and case with magnets&quot;&gt;&lt;br&gt;&#xA;&lt;sup&gt;From left to right. Brushes of a small motor, rotor with contact ring and coils, stator and case with magnets&lt;/sup&gt;&lt;/p&gt;&#xA;&#xA;&lt;h1&gt;Brush-less motors&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;Brush-less motors supply the power to the rotating part of the motor (rotor) by other means.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Induction motors&lt;/strong&gt;, as the name suggest, supply the power by induction. These motors are&#xA;the most common in industry, they are very efficient (normally ~90%). As other motors&#xA;they can have mechanical brake to have fast deceleration and holding breaking. (Ex: cable elevators).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/commons/thumb/5/58/Stator_and_rotor_by_Zureks.JPG/320px-Stator_and_rotor_by_Zureks.JPG&quot; alt=&quot;Induction motor partially opened. The rotor, these small cuts in the metal form a low impedance coil, and case with its coils. The fins on the case help to dissipate the generated heat. Depending on the motor it normally have a fan attached to the axle, or use other motor for forced ventilation, for example the motor runs slow.&quot;&gt;&lt;br&gt;&#xA;&lt;sup&gt;Induction motor partially opened. The rotor, these small cuts in the metal form a low impedance coil, and case with its coils. The fins on the case help to dissipate the generated heat. Depending on the motor it normally have a fan attached to the axle, or use other motor for forced ventilation, for example the motor runs slow.&lt;/sup&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;DC brush-less motors&lt;/strong&gt; have magnets in their rotor, so no electrical power supply is necessary to the rotor. Normally the magnets have high force to power ratio, see Neodymium magnets for example, and so the rotor&lt;sup&gt;&lt;b&gt;1&lt;/b&gt;&lt;/sup&gt; has low mass and consequently low inertia. That said, it can start and stop at higher rates/accelerations than other motors with less wear.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Stepper-motors&lt;/strong&gt; are a type of brush-less motor, but with more poles, that means that applying power to the correct phase you can &lt;em&gt;presume&lt;/em&gt; the position of the rotor&lt;sup&gt;&lt;b&gt;2&lt;/b&gt;&lt;/sup&gt;. But the rotor can &lt;em&gt;slip&lt;/em&gt;, called &quot;lose step&quot;, and so you lost the position synchronism. That means that if use a stepper motor for precise positioning you need to be sure that the motor can handle the load and not slip. How can you be sure of the position? Put a position sensor on the axle of the motor, this with a controller turns it into a servo-motor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/commons/thumb/c/cf/Stepper_motor.jpg/320px-Stepper_motor.jpg&quot; alt=&quot;Stepper motor partially open. This is probably a hybrid type, with the rotor being magnetized and with gear like shape. Some steppers have round rotors, but the rotor is still magnetized with a high number of poles.&quot;&gt;&lt;br&gt;&#xA;&lt;sup&gt;Stepper motor partially open. This is probably a hybrid type, with the rotor being magnetized and with gear like shape. Some steppers have round rotors, but the rotor is still magnetized with a high number of poles.&lt;/sup&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As they don't have brushes, normally the only mechanical contact between rotor and stator are the bearings. That why they have low maintenance, high efficiency, nearly no sparks&lt;sup&gt;&lt;b&gt;3&lt;/b&gt;&lt;/sup&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;sup&gt;1 - the rotor refereed can be the inner or outer part of the motor, the part that don't rotate relative to the power supply I would consider the stator.&lt;/sup&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;sup&gt;2 - That can be applied to others motors as well. A DC brush-less non-stepper motor, with 3 poles for example, would give you 120° of precision, but what you do is modulate the power applied to each coil (ex: less power to one more to the other) so that you get the positions between. That is used on some steppers motors to, and is called micro-stepping.&lt;/sup&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;sup&gt;3 - although major times that means spark free, one possible mean of spark is from static energy on the rotor, that sometimes find the bearings as the short circuit to discharge, resulting in wear to the bearing, but that in not so common and have some means of counter-measure.&lt;/sup&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is only a small list of electrical motors types.&lt;/p&gt;&#xA;&#xA;&lt;h1&gt;Mechanical transmission&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Note: You called that gearing but it's not the only way to do it. I will refer to mechanical transmission&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;That is other topic. Motors run efficiently and have more torque at certain rotations, so you put for example a reducing transmission and get less speed and more torque.&#xA;Suppose a motor spin at 4000 RPM and have a 0.1Kg-cm of torque, assuming a reduction of 100:1 (that is 100 turn in the input result in 1 turn at the output) you should get 400 RPM and 1Kg-cm of torque.&lt;sup&gt;&lt;b&gt;1&lt;/b&gt;&lt;/sup&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;sup&gt;1 - This is a theoretical example, the transmissions are not 100% efficiently so you lose some power&lt;/sup&gt;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Some types of transmissions that can have different ratios&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Gears, Hydraulics, chain sprocket, belts. There's more of course, and each of that have their subtypes. Ex: Gear reductions can be worm-gear, planetary, etc.&#xA;On some applications you can use pulleys, like cranes, elevators.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;All images courtesy of Wikimedia commons &lt;a href=&quot;http://commons.wikimedia.org&quot; rel=&quot;nofollow&quot;&gt;http://commons.wikimedia.org&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;" OwnerUserId="2447" LastEditorUserId="2447" LastEditDate="2013-12-31T18:38:50.537" LastActivityDate="2013-12-31T18:38:50.537" CommentCount="7" />
  <row Id="2213" PostTypeId="2" ParentId="2209" CreationDate="2013-12-30T17:13:27.840" Score="1" Body="&lt;p&gt;There are many forms of electric motors.  However, a few common ones for hobby robots include:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Servo motor&lt;/strong&gt;: This type of motor takes input from a PWM signal, and orients itself to a specific direction based on the signal.  These tend to contain internal gears, so they do not have a high free speed.  Also, torque on such motors tends to be lower than their non-servo counterparts.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Continuous rotation servo&lt;/strong&gt;: Like the above, but the PWM signal controls speed instead of direction.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Brushed motor&lt;/strong&gt;: This is the basic type of motor you will often see in toys, etc.  Motor power is controlled via the voltage across the input lines, not via PWM.  You often need a motor controller to interface your robot with one of these.  These often spin at very high RPM, and need external gearing (or a &quot;gearhead&quot; package) to reduce them to a usable level.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Brushless motor&lt;/strong&gt;: I'm not too familiar with these, but they are similar to the brushed motor above.  Because of the lack of brushes, there is less (or none--not sure) internal sparking in the motor; this can be useful when operating in certain environments where small sparks can start fires.  These, too, also spin at high rates of speed.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Stepper motors&lt;/strong&gt;: These operate by turning on/off magnets positioned around the motor.  These tend to have high torque, and tend to cost more than a simple brushed.  Because of their construction, these motors can &quot;brake&quot; and hold certain positions steady.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="314" LastActivityDate="2013-12-30T17:13:27.840" CommentCount="2" />
  <row Id="2214" PostTypeId="2" ParentId="2196" CreationDate="2013-12-30T20:17:08.263" Score="2" Body="&lt;p&gt;BEAM robots are generally simple circuits that exhibit some emergent behavior that (superficially) mimics biological behavior.  Generally speaking, there is no hard criteria for what a BEAM robot must accomplish -- they are not built to handle tasks that require reliability or repeatability.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;While BEAM robotics should in theory be able to handle any tasks that a microcontroller could handle, the style of construction is not geared toward ease of troubleshooting or debugging -- essential tasks for the development of any complex behavior.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Analog circuits in general are capable of very critical real-time tasks, such as &lt;a href=&quot;http://www.computerhistory.org/revolution/real-time-computing/6/128&quot; rel=&quot;nofollow&quot;&gt;guiding rockets&lt;/a&gt;; see -- for example -- &lt;a href=&quot;http://www.ti.com/ww/en/bobpease/&quot; rel=&quot;nofollow&quot;&gt;the work of Bob Pease&lt;/a&gt;.  But compare the ease of development by changing a few lines of code to testing and rewiring a system like the Hawk Missile autopilot:&#xA;&lt;a href=&quot;http://www.computerhistory.org/revolution/real-time-computing/6/128/530?position=0&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/KclBRm.jpg&quot; alt=&quot;Hawk Missile Autopilot&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Analog electronics aren't incapable, they're just (in these sorts of cases) impractical.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2013-12-30T20:17:08.263" CommentCount="1" />
  <row Id="2215" PostTypeId="1" AcceptedAnswerId="2220" CreationDate="2013-12-31T07:15:35.533" Score="5" ViewCount="166" Body="&lt;p&gt;In software engineering startups, you generally go to a room with a computer or bring your own laptop, and write code. I'm interested in how robotics startups work: is there a separate location for designing the robots? Take for example, &lt;a href=&quot;http://anki.com/&quot;&gt;Anki&lt;/a&gt;. Do they have separate research labs for designing robots? How does a robot get from a single design to being manufactured?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I couldn't find a better place on SE to post this (the startups business section is defunct): please link me to another SE site if there is a better place to ask this question. Thank you.&lt;/p&gt;&#xA;" OwnerUserId="2488" LastEditorUserId="2488" LastEditDate="2013-12-31T10:01:05.837" LastActivityDate="2014-01-01T05:22:34.003" Title="How do robotics startups work?" Tags="&lt;manufacturing&gt;" AnswerCount="2" CommentCount="1" FavoriteCount="4" />
  <row Id="2216" PostTypeId="1" CreationDate="2013-12-31T20:16:13.710" Score="1" ViewCount="34" Body="&lt;p&gt;I have a BOE bot PBasic2 stamp based robot that came with rubberband &quot;tires&quot; for the wheel. however, they are very tight and I can't figure out how to get them onto the plastic hubs.&#xA;the furthest I've gotton was mostly covering the outside, but when trying to make it less crooked it came off again.&#xA;is there some trick to getting those pesky tires to stay on?&lt;/p&gt;&#xA;" OwnerUserId="2490" LastActivityDate="2014-01-01T06:23:14.323" Title="what method should I use for putting rubber bands on wheels?" Tags="&lt;wheeled-robot&gt;" AnswerCount="1" />
  <row Id="2217" PostTypeId="1" CreationDate="2013-12-31T23:43:10.487" Score="0" ViewCount="52" Body="&lt;p&gt;I'm programming a &lt;strong&gt;PIC16F77&lt;/strong&gt; with &lt;strong&gt;ProPic 2&lt;/strong&gt; which communicates via serial port. As I don't have this port in my PC, I used serial to USB adapter.&#xA;I'm using &lt;strong&gt;ICProg&lt;/strong&gt; in &lt;strong&gt;Windows 8&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've proggrammed it before but it was in Windows XP using the driver who specifies in &lt;a href=&quot;http://www.ic-prog.com/index1.htm&quot; rel=&quot;nofollow&quot;&gt;http://www.ic-prog.com/index1.htm&lt;/a&gt; and worked perfectly.&#xA;But in this OS the only difference is the adapter, the program gives some errors while loading the driver:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;&quot;Error occured (Access is denied) while loading the driver!&quot;&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;&quot;Privileged instruction&quot;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="2380" LastEditorUserId="350" LastEditDate="2014-01-03T17:36:44.690" LastActivityDate="2014-01-03T17:36:44.690" Title="Access denied during PIC Programming in Windows XP" Tags="&lt;microcontroller&gt;" AnswerCount="2" CommentCount="1" />
  <row Id="2218" PostTypeId="1" AcceptedAnswerId="2219" CreationDate="2014-01-01T02:05:32.327" Score="1" ViewCount="85" Body="&lt;p&gt;I have a &lt;a href=&quot;http://letsmakerobots.com/files/userpics/u1533/Descriptive_photo_600_0.jpg&quot; rel=&quot;nofollow&quot;&gt;Micro Magician v2 micro controller&lt;/a&gt;. It has a A3906 Dual FET “H” bridge motor driver built in.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the manual it states &quot;Electronic braking is possible by driving both inputs high.&quot; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;My first question is, what is the purpose of these brakes? If I set the left/right motor speed to 0, the robot stops immediately anyway. What advantage is there to using these brakes, or am I taking the word &quot;brake&quot; too literally?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My second question is, the driver has &quot;motor stall flags that are normally held high by pullup resistors and will go low when a motor draws more than the 910mA current limit. Connect these to spare digital inputs so your program will know if your robot gets stuck.&quot; But when my robot hits a wall, the wheels just keep on spinning (slipping if you will), I take it these stall flags can be used on a rough surface where the wheels have more friction?&lt;/p&gt;&#xA;" OwnerUserId="1682" LastEditorUserId="2447" LastEditDate="2014-01-03T03:28:56.500" LastActivityDate="2014-01-03T03:28:56.500" Title="What is the purpose of electronic braking in motors?" Tags="&lt;motor&gt;&lt;h-bridge&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="2219" PostTypeId="2" ParentId="2218" CreationDate="2014-01-01T02:24:39.783" Score="4" Body="&lt;p&gt;Question 1: If you are satisfied with your robots stopping distance, than you don't need electronic braking. With a heavier or faster robot, its quite useful. The larger the machine, the more inertia becomes a important design factor. For example, a form of electronic braking is used by open-pit mining dump trucks. Ordinary dump trucks, being much smaller, make do with ordinary brakes.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Question 2: The stall flags are useful to detect that the wheel is &lt;em&gt;not&lt;/em&gt; moving despite full power being applied. I'm presuming we're still talking about a small robot here - what would happen if the wheel got tangled in something like a long hair or thread? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I had a two-inch long robot once that got its powered wheels jammed on a tiny piece of toothpick it encountered while crossing a carpet. Freak luck, but it does happen. If you only run your robot on clean surfaces, and it'll spin the tires when it bumps into something, than you probably don't need the flags. Personally, though, I would use them -- but I'm a belt AND suspenders kinda guy.&lt;/p&gt;&#xA;" OwnerUserId="2402" LastActivityDate="2014-01-01T02:24:39.783" CommentCount="1" />
  <row Id="2220" PostTypeId="2" ParentId="2215" CreationDate="2014-01-01T03:25:54.087" Score="7" Body="&lt;p&gt;I work at a robotics startup. To sum up my long answer below,  robotics startups are &lt;i&gt;slower, more expensive, and often more distributed in location&lt;/i&gt; than their more famous software counterparts. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Robotics or hardware startups do have a lab for design. It holds owned or rented equipment:  3D printers, machine shop lathes and drills, soldering stations and power supplies, and ONLY 1 really nice oscilloscope that everyone has to share. All the engineers will have a laptop- they may often share licenses for the expensive software like MATLAB and SolidWorks. They work outside the lab whenever possible, because the lab has no windows. Sometimes they make work from home. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The main Engineering work of a robotics startup is to go from a prototype to product. Signs of a prototype that needs to be commercialized include pieces made from&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Arduino boards&lt;/li&gt;&#xA;&lt;li&gt;RC Hobbyist servos and batteries&lt;/li&gt;&#xA;&lt;li&gt;cardboard&lt;/li&gt;&#xA;&lt;li&gt;duct-tape &lt;/li&gt;&#xA;&lt;li&gt;80/20 framework&lt;/li&gt;&#xA;&lt;li&gt;Legos&lt;/li&gt;&#xA;&lt;li&gt;3D printed parts&lt;/li&gt;&#xA;&lt;li&gt;Hand machined metal parts&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;These parts, for reasons of cost and scaleability and reliability, must be replaced with custom molded plastic, metal, composites, cheaper PCBs, standardized fasteners, and consumer grade batteries and power supply electronics. This process is months to years long and uses at least 3 engineering disciplines. It's very expensive. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;At the same time, the Sales and Marketing and Finance employees (and also Engineering employees if the company is any good) are working to move from an &lt;i&gt;idea&lt;/i&gt; to a &lt;i&gt;business&lt;/i&gt;. This selling and fundraising is where the money to do the Engineering work comes from.  You'll notice that Anki site you linked to is billing the product as a toy, not as a military transport robot. This seems obvious, but it has significant engineering implications for what your robot will be expected to do, how long it will last, and how much you can sell it for. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;All these people are busily burning up money, sometimes to the tune of  millions of dollars. To fight some of this battle, most robotics companies outsource A LOT to consultants and contractors: a consultant might build your website, design your business cards, redesign your plastic shell to be injection molded instead of 3D printed,  test your power supplies for safety, and write your user manual. You should NOT outsource complaints handling and tech support initially, because if you do, you'll lose a lot of valuable information about your first products.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;As a startup, once you are actually ready to produce a product (Double check- if there are still pieces of your robot made from the bullet list above, then you aren't ready), you will probably hire a Contract Manufacturer to make your first robots because you can't afford all the equipment or employees to make them yourself. You will pay them to follow your instructions to make your robot and test units before they are sold. You will discover, over the course of several months and dozens of angry user phone calls, that your written instructions weren't clear enough and robots have shipped broken. You will fix it. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Your coworkers and consultants and contractors are located all over the country and world, not in your lab. In the case of suppliers and contract manufacturers, someone at your company is paid to visit them and audit their work, and report the results back. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;All this costs more time and money than the stereotypical software startup. It rarely includes extra money for Silicon-Valley-style perks such as gyms and gourmet smoothies[1].  The logistics of a robotics startup are close to insanity. The payoff margins are smaller than software, and the costs are higher. About the only good news is that no one can bit-torrent your robot for free, and because it is so hard to build a sustainable robot business, there are fewer people willing to fight the battle. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;But, I get to say I design robots for a living, and that's worth a LOT. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;-Crazy System Engineer apologizes for long answer. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note 1:  The perk of free coffee IS included.  In my professional opinion, no one has EVER made engineers pay for coffee. &lt;/p&gt;&#xA;" OwnerUserId="2492" LastActivityDate="2014-01-01T03:25:54.087" CommentCount="4" />
  <row Id="2221" PostTypeId="2" ParentId="2215" CreationDate="2014-01-01T05:13:38.663" Score="4" Body="&lt;p&gt;I can share my experience at a startup where we built what was essentially special purpose robots.  I'm sure there's a wide spectrum though.  A lot depends on the complexity of your robot or machine and the target market for it.  Is it something that will be manufactured in 10's of units and sold for millions a dollar a piece or something that will be manufactured in the millions and sold for hundreds of dollars.  There are many other factors as well.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;We had mechanical engineers, electrical engineers, software engineers, physicists, system integrators.  When you're at the &quot;garage&quot; stage you may have 0-1 of each but the general ideas still apply.&lt;/li&gt;&#xA;&lt;li&gt;Physically we had some lab spaces where the machines would be built/integrated/tested and around them was the team work area/offices.&lt;/li&gt;&#xA;&lt;li&gt;You start from a concept/high level system design.&lt;/li&gt;&#xA;&lt;li&gt;The system will typically be decomposed into separate parts/assemblies.&lt;/li&gt;&#xA;&lt;li&gt;Typically the design is iterated on.  Some assemblies may be designed, built, tested and then changed.  The system design can evolve as well.&lt;/li&gt;&#xA;&lt;li&gt;If you walked into our labs there'd always be some piece of the machine being run through cycle testing or some other functional tests.  Things clicking and humming all over the place ;-)&lt;/li&gt;&#xA;&lt;li&gt;In our startup we didn't make any parts in house.  We had some close machine shop contractors manufacture all the parts we needed for development.  I know some startups will have a machine shop with a CNC mill/lathe for rapid turnaround of parts.&lt;/li&gt;&#xA;&lt;li&gt;We did do all the assembly and integration in house.&lt;/li&gt;&#xA;&lt;li&gt;Over time the design is finalized and various production drawings, procedures, and BOMs are made for the entire machine.  Those include all the manufactured parts, the off-the-shelf parts, things like printed circuit boards etc.&lt;/li&gt;&#xA;&lt;li&gt;Throughout this software is being developed side by side with everything else and needs to change to match the changing system and requirements (that's my job :-) )&lt;/li&gt;&#xA;&lt;li&gt;There are various other business activities ongoing as well.  Talking to customers, HR, finance...&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;It's not as easy to prototype as it is with pure software.  Arguably if you're building a small web site you can bootstrap your business with no investment.  If you're building a robotic company it's probably not possible.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I hope this gives some idea of my experience.  Feel free to ask more questions.&lt;/p&gt;&#xA;" OwnerUserId="1584" LastEditorUserId="1584" LastEditDate="2014-01-01T05:22:34.003" LastActivityDate="2014-01-01T05:22:34.003" />
  <row Id="2222" PostTypeId="1" CreationDate="2014-01-01T05:18:43.353" Score="2" ViewCount="88" Body="&lt;p&gt;Over the last couple of years I've had good success with my technology startups and now looking to enter into robotics. I was interested in robotics and automation ever since I was a kid (yes, that sounds nerdy). So my question is: Where to get started, what to build? and how to sell? And lastly, how difficult it is to sell in this industry?&lt;/p&gt;&#xA;" OwnerUserId="2493" LastActivityDate="2014-01-04T01:44:43.550" Title="I am an entrepreneur and I want to start building robots for businesses, where do I start?" Tags="&lt;industrial-robot&gt;" AnswerCount="2" CommentCount="2" FavoriteCount="1" ClosedDate="2014-01-06T20:04:29.877" />
  <row Id="2223" PostTypeId="2" ParentId="2216" CreationDate="2014-01-01T06:23:14.323" Score="1" Body="&lt;p&gt;A BOE wheel is shown below. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/6T37l.png&quot; alt=&quot;boe wheel&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To get the tire (the outer rubber ring) onto the wheel, pulling a thin string around between the wheel and tire might work.  However, you might also try slightly heating the ring (eg, with a hair dryer), which is likely to make the ring slightly more flexible and stretchy.  Be careful not to overheat the ring.  Uncontrolled hot air from a heat gun probably is too warm and would risk melting the ring.  &lt;/p&gt;&#xA;" OwnerUserId="478" LastActivityDate="2014-01-01T06:23:14.323" CommentCount="1" />
  <row Id="2224" PostTypeId="1" CreationDate="2014-01-01T15:24:26.417" Score="2" ViewCount="97" Body="&lt;p&gt;I am wondering if it would be possible to get Kinect to work with Udoo board (Quad). I have found that there is now support for &lt;a href=&quot;http://wiki.ros.org/hydro/Installation/UDOO&quot; rel=&quot;nofollow&quot;&gt;ROS + Udoo&lt;/a&gt;. Also saw a question asked about &lt;a href=&quot;http://answers.ros.org/question/113131/can-use-freenect-library-for-asus-xtion/&quot; rel=&quot;nofollow&quot;&gt;Xtion + Udoo&lt;/a&gt; which shows some more interest. It would really be great if it could be possible for Kinect+Udoo. Was hoping to implement perhaps a miniature version of TurtleBot. I wish someone could give some insights on this matter. Thanks.&lt;/p&gt;&#xA;" OwnerUserId="2495" LastEditorUserId="2495" LastEditDate="2014-01-03T01:20:23.900" LastActivityDate="2014-01-03T01:20:23.900" Title="Udoo board + Kinect sensor?" Tags="&lt;ros&gt;&lt;kinect&gt;&lt;arm&gt;&lt;embedded-systems&gt;" />
  <row Id="2225" PostTypeId="2" ParentId="2222" CreationDate="2014-01-01T20:05:47.417" Score="0" Body="&lt;p&gt;To answer your questions:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Where to get started?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Start with an idea, talk to some experts about feasibility, hire someone to build a prototype, then get funding and produce your final product.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;What to build?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Build something that is useful, if you want it to be marketable.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;How to sell?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The same way you sell anything else... market it to the right demographic.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;How difficult it is to sell in this industry?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Can't answer this, because it largely depends on what you're selling and how good you are at selling things.&lt;/p&gt;&#xA;" OwnerUserId="1687" LastActivityDate="2014-01-01T20:05:47.417" />
  <row Id="2226" PostTypeId="2" ParentId="1955" CreationDate="2014-01-02T11:56:18.640" Score="1" Body="&lt;p&gt;As you can reduce the path planning and collision avoidance of aircraft down to 2D if you do not include separation by height, I will use aerospace as the example. One school of thought is that collision avoidance is different from path planning, because in high level path planning you can assume that you have complete knowledge of the other aircraft or obstacles that&#xA;you are avoiding. In collision avoidance you&#xA;are limited by the sensors available. The levels of mission planning are shown in the Figure:- &lt;a href=&quot;http://i.stack.imgur.com/UrJBA.png&quot; rel=&quot;nofollow&quot;&gt;Planning Hierarchy with Spatial Decomposition&lt;/a&gt;, collision avoidance is most&#xA;applicable to the safety or low level trajectory planning. Also shown in this figure&#xA;are the time requirements for data from each&#xA;of the systems. Collision avoidance is the&#xA;point at which, if you do not alter course&#xA;you will crash. The two places where this&#xA;can be observed are in controlled airspace&#xA;within the terminal region (airports) and where&#xA;the airways intersect. Rules of the Air dictate a set of rules, which if followed prevent this happening. Pilots are not very&#xA;good at see-and avoid as they are required&#xA;to perform stability and control, communications and high level mission planning. This&#xA;means that collisions are not detected as early&#xA;as they should be and then become a critical last second maneuver.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In large aircraft, Traffic Collision Avoidance System (TCAS) is used to make the pilots aware of&#xA;where approaching aircraft are. TCAS is a co-operative system, which works on the assumption&#xA;that both aircraft will have TCAS. If only one aircraft has TCAS, for example a large aircraft &#xA;flying&#xA;towards a micro-light, a collision will occur. The large aircraft may turn in one direction, and the&#xA;micro-light (who has had no communication with the aircraft) may turn in the same direction. As&#xA;mentioned above the issue is with small aircraft, which are unable to carry the large, power hungry&#xA;TCAS systems. Larger gliders carry a FLARM system (The name is inspired from Flight Alarm),&#xA;which broadcasts its own position and speed vector; but this does not communicate with TCAS, it&#xA;just senses the approaching aircraft (only it has FLARM also, leaving the same problem mentioned&#xA;with the micro-light).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;These systems, which will be on most aircraft in the next ten to fifteen years, have in&#xA;influenced many experts in this field, to assume that the position of all aircraft within the operating area will be known. Though it should be noted that, whilst this would be a logical conclusion to draw in controlled airspace, in uncontrolled airspace this cannot be definitively said, because it does not account for the aforementioned small aircraft that are unable to carry such systems.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In order to deal with the situations described above in uncontrolled airspace there are three types&#xA;of collision detection sensors:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Cooperative : That tell you where they are (e.g. ADS-B)  &lt;/li&gt;&#xA;&lt;li&gt;Passive : Take data in (e.g. Camera's)  &lt;/li&gt;&#xA;&lt;li&gt;Active : Send out signals to receive&#xA;information back (e.g. Radar/Sonar or Lasers)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;After the sensor data is acquired, in order to work out where to go, the sensor data is analysed&#xA;using Collision Avoidance Algorithms:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Potential Fields : Real time obstacle avoidance method. `Robot&#xA;motion can be considered as a particle that moves in a gradient&#xA;vector field generated by positive and negative electric particles'&#xA;The advantage is that it is simple. The disadvantage is the local&#xA;minima condition where the robot can get stuck between two walls or&#xA;obstacles.&lt;/li&gt;&#xA;&lt;li&gt;Vortex Potential Field : In order to reduce the problem of the local minima, a vortex can be added to the potential field, the disadvantage of this is that it forces the vehicle one way round the obstacle and this can lead to a sub-optimal path.&lt;/li&gt;&#xA;&lt;li&gt;Bug Algorithms : Simple to find optimal leave points, the 'simplicity    of these algorithms leads to a number of shortcomings. None of these    algorithms take into account robot kinematics which is a severe    limitation.'&lt;/li&gt;&#xA;&lt;li&gt;Roadmap : Captures the connectivity of the robots free space into one&#xA;dimensional curves 'If more than one continuous paths can be found,&#xA;the shortest patch might be selected according to Dijstra's algorithm&#xA;or the A* algorithm' Drawbacks are `time and storage complexities&#xA;when the environment is complex'&lt;/li&gt;&#xA;&lt;li&gt;3D Geometric : 'does not require the solution of any programming&#xA;problem, thus resulting suitable for real time applications'&lt;/li&gt;&#xA;&lt;li&gt;Azimuth Approach : Using passive camera video feeds and image&#xA;processing techniques to spot the aircraft and detects a collision&#xA;based on change in azimuth angle. This method can be very processor&#xA;intensive.&lt;/li&gt;&#xA;&lt;li&gt;Collision Cone : Transforms the velocities of both aircraft into&#xA;relative velocities. A safety region is drawn around the obstacle&#xA;aircraft and a cone is used to connect the region to the avoiding&#xA;aircraft. A potential collision is detected when the relative&#xA;velocities are within the cone.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;A number of path planning algorithms have been discussed in the other answers so I will not repeat them here.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In conclusion you need to fully understand the problem you are dealing with before you can design a collision avoidance algorithm or path planning algorithm to suit the purpose. Many collision avoidance algorithms and path planning algorithms are compared using a simple bicycle model which may or may not be representative of your final application. If the model is not representative then its like tuning a controller for one system then implementing it on another.&lt;/p&gt;&#xA;" OwnerUserId="925" LastActivityDate="2014-01-02T11:56:18.640" />
  <row Id="2227" PostTypeId="1" CreationDate="2014-01-02T13:32:01.477" Score="1" ViewCount="94" Body="&lt;p&gt;I'm building a quadcopter. It will be controlled by a Beaglebone black with several Sensors and a cam.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I new to the quadcopter stuff, therefore it would be nice if someone could have a look at my setup before I buy the parts.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Frame: &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/__29600__Hobbyking_X650F_Glass_Fiber_Quadcopter_Frame_550mm.html&quot; rel=&quot;nofollow&quot;&gt;X650F - 550mm&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Battery: &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/uh_viewItem.asp?idProduct=20676&quot; rel=&quot;nofollow&quot;&gt;Turnigy nano-tech 5000mah 4S 25~50C Lipo Pack&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Motor: &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/__25080__NTM_Prop_Drive_28_30S_800KV_300W_Brushless_Motor_short_shaft_version_.html&quot; rel=&quot;nofollow&quot;&gt;NTM Prop Drive 28-30S 800KV / 300W Brushless Motor&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;ESC: &lt;a href=&quot;http://www.goodluckbuy.com/hobbywing-brushless-esc-4in1-25a-x-4-skywalker-quattro-throttle-hub-for-quadcopter-.html&quot; rel=&quot;nofollow&quot;&gt;Skywalker 4x 25A Brushless&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;This sums up to ~ 2kg. Giving me still some room for about 700g payload.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What do you think? Did I miss something important? Better ideas for some parts?&lt;/p&gt;&#xA;" OwnerUserId="2500" LastActivityDate="2014-01-04T19:46:11.760" Title="Quadcopter configuration" Tags="&lt;quadcopter&gt;" AnswerCount="2" CommentCount="2" ClosedDate="2014-01-06T20:05:00.537" />
  <row Id="2228" PostTypeId="1" CreationDate="2014-01-02T22:22:11.337" Score="2" ViewCount="61" Body="&lt;p&gt;I would like to ask a question about zero crossing event in a trapezoidal commutation on a brush-less DC motor. Here is a waveform that shows that the zero crossing event occurs every 180 electrical degrees in a sinusoidal commutation:&lt;br&gt; &lt;img src=&quot;http://i.stack.imgur.com/lcZrH.png&quot; alt=&quot;sinusoidal&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But what about trapezoidal commutation. Here is the waveform that I found about the trapezoidal commutation:&lt;br&gt; &lt;img src=&quot;http://i.stack.imgur.com/jIez1.png&quot; alt=&quot;trapezoidal&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So as you see, the zero crossing occurs 30 electrical degrees after the previous commutation and 30 electrical degrees before the next commutation.&#xA;In a motor with one pole pair, we would have 30 electrical degrees = 30 mechanical degrees, so we would have this waveform: &lt;img src=&quot;http://i.stack.imgur.com/T5BCZ.png&quot; alt=&quot;zero crossing&quot;&gt;&#xA;You see that the zero crossing in phase A occurs when the magnet faces the phase C, or in other words, after 30 electrical degrees from the last commutation.&#xA;My question in why does the zero crossing happen at that moment, why not after 60 electrical degrees, or 15 electrical degrees?&#xA;Is it related to some law's of induction? What are those law and how do this law's appear in this motor?&#xA;Can someone explain to me this with some pics?&lt;/p&gt;&#xA;" OwnerUserId="2504" LastEditorUserId="2447" LastEditDate="2014-01-06T19:49:12.463" LastActivityDate="2014-01-06T19:49:12.463" Title="Zero crossing events with brushless DC motors" Tags="&lt;brushless-motor&gt;" AnswerCount="2" />
  <row Id="2229" PostTypeId="2" ParentId="2228" CreationDate="2014-01-03T09:47:06.123" Score="1" Body="&lt;h1&gt;First, some background to make sure we are clear on the basics:&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;1 mechanical degree&lt;/strong&gt; = 1/360th of a full mechanical rotation&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;1 electrical degree&lt;/strong&gt; = 1/360th of a full AC cycle&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Zero crossing&lt;/strong&gt; = the point where the voltage equals 0&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/commons/0/03/Zero_crossing.svg&quot; alt=&quot;zero crossing waveform explanation&quot;&gt;&#xA;&lt;br&gt;&lt;sup&gt;Image from &lt;a href=&quot;http://upload.wikimedia.org/wikipedia/commons/0/03/Zero_crossing.svg&quot; rel=&quot;nofollow&quot;&gt;http://upload.wikimedia.org/wikipedia/commons/0/03/Zero_crossing.svg&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now, in an electric motor with 2 poles, a full AC cycle is needed to make 1 full mechanical rotation. So 1 electrical degree = 1 mechanical degree, and the zero crossing occurs twice, i.e once every 180 degrees.&lt;/p&gt;&#xA;&#xA;&lt;h1&gt;&quot;Sensored&quot; Mode&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;You say that in sensored mode, the hall sensor tells you to commutate once every 60 degrees, so your zero crossing occurs once per 60 degrees, and the full AC cycle once per 120 mechanical degrees, which means you make 3 full AC cycles per 1 mechanical rotation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;That means your &quot;sensored&quot; motor has 6 poles (3 pole pairs).&lt;/p&gt;&#xA;&#xA;&lt;h1&gt;Sensorless Mode&lt;/h1&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;I found while searching that the zero crossing happens 30 electrical degrees after the previous commutation&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Where did you find this? Looking at the linked chart above, shouldn't the commutation occur every 180 electrical degrees &lt;em&gt;always&lt;/em&gt;? And the zero crossing should always be in the middle between 2 commutations, which means it is always going to happen 90 electrical degrees after (or before) a commutation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you meant 30 &lt;strong&gt;mechanical degrees&lt;/strong&gt;, then we can say the commutation happens every 60 mechanical degrees (also the zero crossing happens every 60 mechanical degrees). This means a full AC cycle takes 120 mechanical degrees, so 3 full AC cycles per 1 mechanical rotation, which agrees with the information from the &quot;sensored&quot; mode.&lt;/p&gt;&#xA;" OwnerUserId="1687" LastEditorUserId="2447" LastEditDate="2014-01-06T19:48:33.617" LastActivityDate="2014-01-06T19:48:33.617" CommentCount="0" />
  <row Id="2230" PostTypeId="2" ParentId="2217" CreationDate="2014-01-03T12:24:09.233" Score="1" Body="&lt;p&gt;If you're running this from command prompt, try this when launching command prompt: Right click. Run as administrator.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then use as usual.&lt;/p&gt;&#xA;" OwnerUserId="2512" LastActivityDate="2014-01-03T12:24:09.233" />
  <row Id="2233" PostTypeId="2" ParentId="2217" CreationDate="2014-01-03T14:14:31.200" Score="1" Body="&lt;p&gt;Certain low-level instructions are forbidden to be used by the User under Windows: unfortunately, these 'privileged' instructions can include port control commands.&#xA;Details: &lt;a href=&quot;http://support.microsoft.com/kb/112298/EN-US&quot; rel=&quot;nofollow&quot;&gt;http://support.microsoft.com/kb/112298/EN-US&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&quot; The inp(), outp(), and other I/O port related functions map to privileged processor instructions. For example, on Intel processors, the inp() and outp() functions end up calling the IN and OUT instructions. The privileged instruction exception occurs when these instructions are executed because typical Windows NT applications execute in a non privileged (user) mode. Only code executing in kernel mode has the necessary rights to execute privileged instructions.&quot;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Device drivers run in kernel mode: if you're getting this error on your program run, its trying to access on the low-level (which is kind of by definition what a port controller does)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Seeing as ic-prog.com's page on windows drivers was last changed on 06/09/08, which is not a good sign.&lt;/p&gt;&#xA;" OwnerUserId="2402" LastActivityDate="2014-01-03T14:14:31.200" />
  <row Id="2234" PostTypeId="1" CreationDate="2014-01-03T15:59:07.897" Score="1" ViewCount="24" Body="&lt;p&gt;I would like to ask a question about zero crossing event in a trapezoidal commutation on a brush-less DC motor. Here is the waveform that shows that the zero crossing event occurs every 180 electrical degrees in a sinusoidal commutation:&lt;br&gt; &lt;img src=&quot;http://i.stack.imgur.com/lcZrH.png&quot; alt=&quot;sinusoidal&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But what about trapezoidal commutation. Here is the waveform that I found about the trapezoidal commutation: &lt;br&gt;&lt;img src=&quot;http://i.stack.imgur.com/jIez1.png&quot; alt=&quot;trapezoidal&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So as you see, the zero crossing occurs 30 electrical degrees after the previous commutation and 30 electrical degrees before the next commutation.&#xA;In a motor with one pole pair, we would have 30 electrical degrees = 30 mechanical degrees, so we would have this waveform: &lt;img src=&quot;http://i.stack.imgur.com/T5BCZ.png&quot; alt=&quot;zero crossing&quot;&gt;&#xA;You see that the zero crossing in phase A occurs when the magnet faces the phase C, or in other words, after 30 electrical degrees from the last commutation.&#xA;My question in why does the zero crossing happen at that moment, why not after 60 electrical degrees, or 15 electrical degrees?&#xA;Is it related to some law's of induction? What are those law and how do this law's appear in this motor?&#xA;Can someone explain to me this with some pics?&lt;/p&gt;&#xA;" OwnerUserId="2504" LastEditorUserId="2447" LastEditDate="2014-01-06T19:48:58.993" LastActivityDate="2014-01-06T19:48:58.993" Title="Zero crossing events in trapezoidal commutation" Tags="&lt;brushless-motor&gt;" CommentCount="2" ClosedDate="2014-01-06T20:04:07.923" />
  <row Id="2235" PostTypeId="2" ParentId="2228" CreationDate="2014-01-03T18:58:48.070" Score="4" Body="&lt;p&gt;Each of the three Hall Effect sensor signals is out of phase with the others by 120°. The same is true for the BEMF signals. The Hall Effect signals and the BEMF signals are 30° out of phase with each other.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From this &lt;a href=&quot;http://ww1.microchip.com/downloads/en/appnotes/00970a.pdf&quot; rel=&quot;nofollow&quot;&gt;Microchip App note&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Hall sensor signals are out of phase by 120 degrees to each other. At&#xA;  every 60 degrees, one of the Hall sensors makes a transition.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;The BEMF generated in the windings are also at 120 degrees out of&#xA;  phase to each other, but they are asynchronous  with the Hall sensor&#xA;  signals. In every energizing sequence, two phases are connected across&#xA;  the power supply and the third winding is left open. the BEMF voltage&#xA;  is monitored on the winding that is left open. With this, the BEMF&#xA;  voltage in windings increases when it is connected to power supply and&#xA;  reduces when it is connected to the return path. The transition takes&#xA;  place when the winding is left open in the sequence. The combination&#xA;  of all 3 zero cross over points are used to generate energizing&#xA;  sequence. The phase difference between the hall sensor and the BEMF&#xA;  signal is 30 degrees.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/TvnQs.png&quot; alt=&quot;Waveform of Hall sensor versus BEMF voltages&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/nokDK.png&quot; alt=&quot;Oscilloscope waveform of BEMF and Hall sensor signals&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So if you commutate 30° &lt;em&gt;after&lt;/em&gt; sensing a zero crossing, you are actually commutating at the same time you would be if you detected a change in the Hall Effect sensors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The reason the Hall Effect signals and the BEMF are out of phase is because they are measuring two different things. The Hall Effect sensors are measuring rotor position. The BEMF signals are measuring stator sequence energization. It is from that energization that we can extrapolate rotor position and determine correct commutation timing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From this &lt;a href=&quot;http://www.atmel.com/Images/doc7658.pdf&quot; rel=&quot;nofollow&quot;&gt;Atmel App note&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The optimum drive sequence is to drive PWM at 30° after zero crossing&#xA;  to be in phase with the rotor position as shown by the figure below.&#xA;  Driving earlier or later to this 30° will increase the current&#xA;  comsumption [sic] of the motor.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/uWkfZ.png&quot; alt=&quot;Thirty degree phase angle&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So why 30°? 30° is the amount of time it takes for the interaction between the stator magnetic field and the rotor magnetic field to begin to weaken to the point that stator's electrical field needs to be altered in order to strengthen the interaction between the two magnetic fields.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can actually play with this timing to some degree by doing things like rotating the Hall Effect sensors in order to achieve certain results and/or meet certain requirements. I go into this practice more in my answer to this question: &lt;a href=&quot;http://electronics.stackexchange.com/questions/53637/why-have-non-zero-timing-on-a-bldc&quot;&gt;Why Have Non-Zero Timing on a BLDC?&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="142" LastActivityDate="2014-01-03T18:58:48.070" />
  <row Id="2236" PostTypeId="1" CreationDate="2014-01-04T00:26:06.863" Score="2" ViewCount="106" Body="&lt;p&gt;I'm programming Lua for controlling computers and robots in-game in the Minecraft mod &lt;a href=&quot;http://computercraft.info&quot; rel=&quot;nofollow&quot;&gt;ComputerCraft&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;ComputerCraft has these robots called Turtles, that are able to move around in the &lt;em&gt;grid based&lt;/em&gt;(?) world of Minecraft. They are also equipped with sensors making them able to detect blocks (obstacles) adjacent to them. Turtles execute Lua programs written by a player.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As a hobby project I would like to program a &lt;code&gt;goto(x, y, z)&lt;/code&gt; function for my Turtles. Some Turtles actually have equipment to remove obstacles, but I would like to make them avoid obstacles and thus prevent the destruction of the in-game environment.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have no prior experience in robotics, but I have a B.Sc. in Computer Science and am now a lead web developer.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I did some research and found some basic strategies, namely &lt;em&gt;grid based&lt;/em&gt; and &lt;em&gt;quadtree based&lt;/em&gt;. As I have no experience in this area, these strategies might be old school.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note that Turtles are able to move in three dimensions (even hover in any height). I could share the obstacles as well as obstacle free coordinates in a common database as they are discovered if that would help me out, as most obstacles are stationary once they are placed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What are my best options in this matter? Are there any &lt;em&gt;easy fixes&lt;/em&gt;? Where do I look for additional resources?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thank you very much in advance! :-)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;EDIT&lt;/strong&gt;: Thank you for your feedback!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I started reading the book &lt;em&gt;Artificial Intelligence: A Modern Approach, 3rd Edition&lt;/em&gt; to get up to speed on basic theory as suggested by &lt;strong&gt;Ian&lt;/strong&gt;. Pointers to other educational resources are appreciated.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, I started developing a basic navigation algorithm for moving in unexplored areas, similar to what &lt;strong&gt;Cube&lt;/strong&gt; suggested.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The priority for me is as few moves as possible, as it costs time and fuel cells for each additional move (approx. 0.8 seconds and 1 fuel cell per move in either direction). I plan on using the Euclidean heuristics function in a Greedy Best-First Search for computing a path that is expected to be quite optimal in reducing the number of moves to reach the goal, if enough data is available from the shared database from previous exploration.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Each time an obstacle is reached, I plan to use the following very basic algorithm, exploiting the fact that Turtles are able to move vertically:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;1. Calculate direct horizontal path to the goal.&#xA;2. Turn to the direction of the next step of the path.&#xA;3. If an obstacle is detected in front of the Turtle go to 5. If this is the 4th time that an obstacle is detected in front of the Turtle after moving up, go to 6.&#xA;4. Move forward, go to 2.&#xA;5. If no obstacle is detected above the Turtle, move up and go to 3, else go to 7.&#xA;6. Backtrack to the coordinates the Turtle was in before moving upwards.&#xA;7. Turn left, go to 3.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;When using this algorithm, records are kept of the explored coordinates and uploaded to a shared database. However, there are some cases, that I did not consider:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;- When should it move down?&#xA;- What if the goal is not reachable from a coordinate directly above it?&#xA;- If no horizontal move in any direction is possible, how long should it backtrack?&#xA;- How to detect unreachable goals (obstacles can then be removed if requested)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Maybe if enough exploration data of the area is available, a Jump Point Search is performed to calculate an optimal path. However this assumes a 2D map. How can I take the 3rd dimension into account?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, what would be a good data structure to store the exploration data?&lt;/p&gt;&#xA;" OwnerUserId="2522" LastEditorUserId="2522" LastEditDate="2014-01-05T19:35:17.073" LastActivityDate="2014-01-05T19:35:17.073" Title="ComputerCraft (Minecraft mod) navigation: Collision avoidance and path planning/finding in 2D/3D space" Tags="&lt;mobile-robot&gt;&lt;navigation&gt;" AnswerCount="3" CommentCount="3" FavoriteCount="1" />
  <row Id="2237" PostTypeId="2" ParentId="2236" CreationDate="2014-01-04T01:23:58.680" Score="0" Body="&lt;p&gt;This is more of a Mathematical question. Said that you could apply some linear algebra to check if there are obstacles in a path. Your path is either a spline or line. The obstacle is either a point in a 2D/3D system or a plane in a 3D system. Now you can check if the line intersects with the point or the plane. &lt;a href=&quot;http://en.wikipedia.org/wiki/Line-plane_intersection&quot; rel=&quot;nofollow&quot;&gt;Line Plane intersection on Wikipedia &lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="2360" LastActivityDate="2014-01-04T01:23:58.680" CommentCount="1" />
  <row Id="2238" PostTypeId="2" ParentId="2222" CreationDate="2014-01-04T01:44:43.550" Score="0" Body="&lt;p&gt;Where to get started?&#xA;Start with an idea, write down its properties, requirements, scope of the robot, its audience. Sketch it on paper. Make a CAD model using Solidworks if you have. You can simulate many properties in Solidworks. You can also import a 3D model of the ECAD file and estimate the production cost. Learn electronics, programmering and take several courses in mathematics. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What to build?&#xA;Build what you would love to have or exist.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How to sell?&#xA;Anything can be sold to anybody at any price, if the product makes an impression on the buyer. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;How difficult it is to sell in this industry?&#xA;Robots nowadays are like computers 40 years ago. So the opportunities are huge. Having said that, the better it impresses the buyer the easier it gets sold. But generally robots related to &quot;Saving the environment&quot;, &quot;Saving human lives&quot;, &quot;Minimising crime&quot; are getting popular and get a lot of attention in the media.&lt;/p&gt;&#xA;" OwnerUserId="2360" LastActivityDate="2014-01-04T01:44:43.550" />
  <row Id="2239" PostTypeId="2" ParentId="2227" CreationDate="2014-01-04T02:03:24.940" Score="1" Body="&lt;p&gt;Looks good to me. You also need:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;propellers&lt;/li&gt;&#xA;&lt;li&gt;power distribution board which keeps thing more organised until you make your own PCB.&lt;/li&gt;&#xA;&lt;li&gt;A Li-Po battery charger with a compatible connector.&lt;/li&gt;&#xA;&lt;li&gt;Spare parts. (Many propellers, and few motors and ESCs)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Also visit &lt;a href=&quot;http://ecalc.ch/xcoptercalc.htm&quot; rel=&quot;nofollow&quot;&gt;xcoptercalc&lt;/a&gt; to 'simulate' the parts.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Be careful with the motors since there are some openings at the bottom making it easy for small metal dust to enter the motor. If metallic dust enters the motor, it is almost impossible to detach it from those permanent magnets.&lt;/p&gt;&#xA;" OwnerUserId="2360" LastEditorUserId="2360" LastEditDate="2014-01-04T14:13:41.833" LastActivityDate="2014-01-04T14:13:41.833" CommentCount="3" />
  <row Id="2240" PostTypeId="2" ParentId="2236" CreationDate="2014-01-04T12:37:51.250" Score="1" Body="&lt;p&gt;What comes to my mind first is some sort of bug algorithm. That is a path finding algorithm that has only small constant amount of memory and only sees (small) local parts of the world.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can imagine this as&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Go directly to the goal&lt;/li&gt;&#xA;&lt;li&gt;If there is an obstacle in a way, pick a direction and start going around it&lt;/li&gt;&#xA;&lt;li&gt;Once there is a free path again, goto 1&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Of cause there are some problems with this, I'm not entirely sure that this will work in 3D. Selecting a way around an obstacle will be a little trickier than just saying &quot;always go right&quot;.&#xA;Other than that, this algorithm can select a wrong direction and spend a long time going around the obstacle which it could avoid easily by going other way around it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://www.cs.cmu.edu/~motionplanning/lecture/Chap2-Bug-Alg_howie.pdf&quot; rel=&quot;nofollow&quot;&gt;These slides&lt;/a&gt; might help you with some of the details.&lt;/p&gt;&#xA;" OwnerUserId="482" LastEditorUserId="482" LastEditDate="2014-01-04T15:08:56.617" LastActivityDate="2014-01-04T15:08:56.617" CommentCount="2" />
  <row Id="2241" PostTypeId="2" ParentId="2227" CreationDate="2014-01-04T19:46:11.760" Score="1" Body="&lt;p&gt;You should have a prop balancer like &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/__19292__Turnigy_Magnetic_Precision_Prop_Balancer.html&quot; rel=&quot;nofollow&quot;&gt;this&lt;/a&gt; which will ensure that propellers are well balanced. Also you should have a Lipo alarm like &lt;a href=&quot;http://www.hobbyking.com/hobbyking/store/__18588__Hobbyking_2_8S_Cell_Checker_with_Low_Voltage_Alarm.html&quot; rel=&quot;nofollow&quot;&gt;this&lt;/a&gt; which can warn you when you are low on battery during fight.&lt;/p&gt;&#xA;" OwnerUserId="2118" LastActivityDate="2014-01-04T19:46:11.760" CommentCount="5" />
  <row Id="2242" PostTypeId="2" ParentId="2236" CreationDate="2014-01-04T20:08:25.470" Score="1" Body="&lt;p&gt;It looks like your research here is a little too specific -- you're working on the practical level before being up to speed on the theory.  Take a look at more of the higher-level concepts of motion planning and obstacle avoidance.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The &lt;em&gt;extremely&lt;/em&gt; simplified process is:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Expressing a high-level objective for the robot&lt;/li&gt;&#xA;&lt;li&gt;Based on data describing the current environment, creating a set of planned movements that meet the objective (using path planning algorithms like &lt;a href=&quot;http://en.wikipedia.org/wiki/A%2a_search_algorithm#Example&quot; rel=&quot;nofollow&quot;&gt;A* search&lt;/a&gt;)&lt;/li&gt;&#xA;&lt;li&gt;As time passes, collecting new data about the environment (e.g. current position, new obstacles) and re-planning the path&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Quadtrees and grids are just 2 ways of representing the environment itself; one of the practical problems involved in robotics is the sheer volume of data that can come in, and quadtrees offer a more memory-space-efficient representation of that data (see also, &lt;a href=&quot;http://en.wikipedia.org/wiki/Octree&quot; rel=&quot;nofollow&quot;&gt;octrees&lt;/a&gt; for 3D spaces) in return for some extra CPU time and complexity.  There are many such optimizations that you could make, but it sounds like you're considering them a little too early in the design process.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2014-01-04T20:08:25.470" />
  <row Id="2244" PostTypeId="1" CreationDate="2014-01-06T03:33:49.137" Score="3" ViewCount="109" Body="&lt;p&gt;I am trying to simulate a quadcopter model on Simulink. I want to implement a PID controller for each of X,Y,Z and phi,theta, psi angles. PID gets the error, as input, which is to be minimized.&#xA;For the X,Y and Z, the desired values are entered by the user and the actual values are calculated from the accelerometer data, hence, the error is the desired set value - actual value.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For phi,theta and psi, the actual values may be obtained from the gyroscope and accelerometer (sensor fusion) but I don't actually know how to calculate the desired values for each one of them since the user is usually interested in giving the position values X,Y and Z as desired not the angle values! The absence of the desired values prevents me form calculating the angular error which is needed for the PID controller.&lt;/p&gt;&#xA;" OwnerUserId="2533" LastEditorUserId="2447" LastEditDate="2014-01-08T14:29:45.643" LastActivityDate="2014-01-09T16:10:33.877" Title="How to know the desired orientation of a quadcopter?" Tags="&lt;design&gt;&lt;quadcopter&gt;&lt;pid&gt;&lt;quadrotor&gt;" AnswerCount="2" CommentCount="0" />
  <row Id="2245" PostTypeId="1" CreationDate="2014-01-06T08:49:17.403" Score="3" ViewCount="52" Body="&lt;p&gt;I'm reading Probabilistic Robotics by Thrun. In the Kalman filter section, they state that &#xA;$$&#xA;x_{t} =A_{t}x_{t-1} + B_{t}u_{t} + \epsilon_{t}&#xA;$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;where $\epsilon_{t}$ is the state noise vector.  And in&#xA;$$&#xA;z_{t} = C_{t}x_{t} + \delta_{t}&#xA;$$&#xA;where $\delta_{t}$ is the measurement noise. Now, I want to simulate a system in Matlab. Everything to me is straightforward except the state noise vector $\epsilon_{t}$. Unfortunately, majority of authors don't care much about the technical details. My question is what is the state noise vector? and what are the sources of it? I need to know because I want my simulation to be rather sensible. About the measurement noise, it is evident and given in the specifications sheet that is the sensor has uncertainty ${+ \atop -} e$.&lt;/p&gt;&#xA;" OwnerUserId="2155" LastActivityDate="2014-01-07T20:33:18.810" Title="Kalman Filter and the state noise vector?" Tags="&lt;kalman-filter&gt;&lt;noise&gt;" AnswerCount="2" FavoriteCount="2" />
  <row Id="2246" PostTypeId="5" CreationDate="2014-01-06T17:10:33.993" Score="0" ViewCount="7" Body="&lt;p&gt;Kinematics is the study of mechanics deal with motion of points and objects without regard to the cause of the motion, such as the movement of jointed robotic arm or the movement of pistons and tappets of an engine.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Forward_kinematics&quot; rel=&quot;nofollow&quot;&gt;Forward kinematic&lt;/a&gt;&lt;/strong&gt; equations describe the final position of a robotic arm or other system based on the joint parameters.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Inverse_kinematics&quot; rel=&quot;nofollow&quot;&gt;Inverse kinematic&lt;/a&gt;&lt;/strong&gt; equations describe the joint parameters necessary to move a robotic arm to a particular position.&lt;/p&gt;&#xA;" OwnerUserId="2540" LastEditorUserId="177" LastEditDate="2014-01-08T22:40:36.683" LastActivityDate="2014-01-08T22:40:36.683" />
  <row Id="2247" PostTypeId="4" CreationDate="2014-01-06T17:10:33.993" Score="0" Body="Kinematics is the branch of mechanics dealing with the motion of points and objects." OwnerUserId="2540" LastEditorUserId="2540" LastEditDate="2014-01-06T19:49:21.420" LastActivityDate="2014-01-06T19:49:21.420" />
  <row Id="2248" PostTypeId="2" ParentId="2245" CreationDate="2014-01-06T17:58:44.900" Score="2" Body="&lt;p&gt;In my understanding, $\epsilon_{t}$ accounts for the uncertainties of the state model. Uncertainties come from real life imperfections, for example the wheels are not completely round, or the weight distribution is not even, or the motors don't perform exactly as predicted by the model.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So when the robot executes a straight movement, it is expected to eventually reach a nearby position of that predicted by the model, a bit to the left or right.&lt;/p&gt;&#xA;" OwnerUserId="1445" LastActivityDate="2014-01-06T17:58:44.900" CommentCount="2" />
  <row Id="2249" PostTypeId="2" ParentId="1959" CreationDate="2014-01-06T19:03:19.243" Score="0" Body="&lt;p&gt;From wikipedia &lt;a href=&quot;http://en.wikipedia.org/wiki/Stepper_motor&quot; rel=&quot;nofollow&quot;&gt;http://en.wikipedia.org/wiki/Stepper_motor&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Because windings are better utilized, they are more powerful than a unipolar motor of the&lt;br&gt;&#xA;  same weight. This is due to the physical space occupied by the windings. A unipolar motor &#xA;  has twice the amount of wire in the same space, but only half used at any point in time, &#xA;  hence is 50% efficient (or approximately 70% of the torque output available). Though a &#xA;  bipolar stepper motor is more complicated to drive, the abundance of driver chips means &#xA;  this is much less difficult to achieve.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;If you read specifications for a stepper motor that can be wired as unipolar/bipolar, you will confirm this.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But if you have a 5 wire unipolar, the central one is common to the center tap of both coils. You need to remove this connection to use it as bipolar. If you have a 6 wire, yes it is meant for that, just ignore the two other wires (some motors have connectors so you can disconnect the wires), and run it as bipolar.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://www.esuli.it/wp-content/uploads/2011/10/stepperWiring.png&quot; alt=&quot;stepper motor wiring&quot;&gt;&#xA;&lt;br&gt;&lt;sup&gt;From &lt;a href=&quot;http://www.esuli.it/2011/10/11/converting-an-unipolar-stepper-to-bipolar/&quot; rel=&quot;nofollow&quot;&gt;http://www.esuli.it/2011/10/11/converting-an-unipolar-stepper-to-bipolar/&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&#xA;" OwnerUserId="2447" LastActivityDate="2014-01-06T19:03:19.243" />
  <row Id="2250" PostTypeId="1" CreationDate="2014-01-06T21:53:00.587" Score="1" ViewCount="79" Body="&lt;p&gt;I need to find a way to solve invrese kinematics for Comau SMART-3 robot. Could you give me a few hints where to start looking? I have no idea about robotics and I couldn't find an algorithm for this specific robot.&lt;/p&gt;&#xA;" OwnerUserId="2543" LastActivityDate="2014-01-06T21:53:00.587" Title="Finding inverse kinematics algorithm for a specific manipulator" Tags="&lt;inverse-kinematics&gt;" />
  <row Id="2251" PostTypeId="1" CreationDate="2014-01-06T22:15:12.180" Score="2" ViewCount="25" Body="&lt;p&gt;From what I've read so far, it seems that a &lt;em&gt;Rao-Blackwellized&lt;/em&gt; particle filter is just a normal particle filter used after marginalizing a variable from   &lt;/p&gt;&#xA;&#xA;&lt;p&gt;$p(r_t,s_t | y^t)$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm not really sure about that conclusion, so i would like to know the precise differences beetween these two types of filter. Thanks in advance.&lt;/p&gt;&#xA;" OwnerUserId="2541" LastEditorUserId="2541" LastEditDate="2014-01-06T22:28:07.983" LastActivityDate="2014-01-06T22:28:07.983" Title="difference beetween Rao-Blackwellized filters and regular ones" Tags="&lt;slam&gt;&lt;particle-filter&gt;" />
  <row Id="2252" PostTypeId="2" ParentId="2244" CreationDate="2014-01-06T22:25:47.173" Score="4" Body="&lt;p&gt;You're trying to implement more PIDs than you have &lt;a href=&quot;http://en.wikipedia.org/wiki/Degrees_of_freedom_%28engineering%29&quot; rel=&quot;nofollow&quot;&gt;degrees of freedom&lt;/a&gt;.  In a quadcopter, you have only 4: $(Z, \phi, \theta, \psi)$ i.e. (Altitude, Roll, Pitch, and Yaw). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.draganfly.com/uav-helicopter/draganflyer-x4/features/stability.php&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/3H4Ba.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;via (&lt;a href=&quot;http://www.draganfly.com/uav-helicopter/draganflyer-x4/features/stability.php&quot; rel=&quot;nofollow&quot;&gt;http://www.draganfly.com/uav-helicopter/draganflyer-x4/features/stability.php&lt;/a&gt;)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Interestingly, from a PID perspective you definitely &lt;em&gt;do&lt;/em&gt; have desired values for $\phi$ and $\theta$: you want them both to default to zero, so that your quadcopter hovers stably.  (You could also constrain $\psi$ to a fixed value like zero, but since the quadcopter is symmetric about the Z axis, all you really need to do is prevent excessive rotation by bumping up the 'D' term in the $\psi$ PID.)  The Z PID can then be tuned to ensure that you can set and hold a desired altitude.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So in the simplest case, the X and Y PIDs will end up sitting &quot;on top&quot; of the other PIDs.&lt;br&gt;&#xA;&lt;a href=&quot;http://i.stack.imgur.com/hUzW8.png&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/hUzW8.png&quot; alt=&quot;Processing chain&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In other words, the output of the X and Y PIDs will be (respectively) become the desired $\phi$ and $\theta$ angles that will nudge the quadcopter toward the desired position.  (Note that you'll have to convert the world-relative desired X and Y to quadcopter-relative X and Y to compensate for $\psi$.  &lt;a href=&quot;http://robotics.stackexchange.com/a/727/350&quot;&gt;This answer&lt;/a&gt; has more.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are more sophisticated ways to control aerial vehicles, but this is one of the easiest to learn.&lt;/p&gt;&#xA;" OwnerUserId="350" LastEditorUserId="350" LastEditDate="2014-01-09T16:10:33.877" LastActivityDate="2014-01-09T16:10:33.877" CommentCount="6" />
  <row Id="2253" PostTypeId="2" ParentId="1554" CreationDate="2014-01-07T00:24:11.563" Score="1" Body="&lt;p&gt;If you want sub-meter tracking of the moving object, GPS alone will not be sufficient.  I concur that passive vision-based techniques will require a huge amount of engineering to implement, not to mention substantial size, weight, and power.  I recommend using differential GPS techniques -- not exactly easy, but simpler from a system standpoint.  You will need a high-update rate GPS receiver that outputs Carrier Phase and Pseudo-Range data as well as a traditional GPS solution.  You will also need to transmit this additional data to your quadcopter from both a nearby reference station and the moving object.  It is useful to have a stationary reference station since its position is exactly known, so using the satellite ephemeris you can determine the propagation and timing errors from each satellite very precisely.  Since you know the approximate geometry to both the non-moving reference station and the moving object, and the paths to the satellites are approximately the same for both cases, you can adopt the precisely calculated propagation and timing errors learned from the reference station and apply them to the moving object.  Additional accuracy is gained by computing a relative position solution for both the quadcopter and the moving object that explains the observed changes in Carrier Phase over time as both of these move.  Since these are phase changes, the integer number of cycles is unknown and must be solved for using a well-known technique for finding integer solutions to least-square problems (name escapes me at the moment).  A Kalman Filter or Particle Filter is also typically needed to converge to the correct position solution using the carrier data after fusing with the pseudo-range-derived data.  Check out work done at Auburn University's Navlab for examples of this type of work.&lt;/p&gt;&#xA;" OwnerUserId="2546" LastActivityDate="2014-01-07T00:24:11.563" />
  <row Id="2254" PostTypeId="5" CreationDate="2014-01-07T17:00:31.163" Score="0" ViewCount="3" Body="&lt;p&gt;&lt;strong&gt;Inverse kinematics&lt;/strong&gt; uses kinematic equation to determine what joint parameters are required in the kinematic chain to move an end-effector into a particular position.  A &lt;a href=&quot;http://en.wikipedia.org/wiki/Kinematic_chain&quot; rel=&quot;nofollow&quot;&gt;kinematic chain&lt;/a&gt; is mathematical model of the rigid bodies and joint connectors in (for example) a robotic arm.&lt;/p&gt;&#xA;" OwnerUserId="2540" LastEditorUserId="350" LastEditDate="2014-01-07T19:48:11.047" LastActivityDate="2014-01-07T19:48:11.047" />
  <row Id="2255" PostTypeId="4" CreationDate="2014-01-07T17:00:31.163" Score="0" Body="Inverse kinematics is a subtopic of kinematics dealing with equations that describe the joint parameters necessary to move a robotic arm to a particular position. Also called motion planning." OwnerUserId="2540" LastEditorUserId="2540" LastEditDate="2014-01-07T19:48:54.330" LastActivityDate="2014-01-07T19:48:54.330" />
  <row Id="2256" PostTypeId="1" CreationDate="2014-01-07T17:37:26.657" Score="1" ViewCount="64" Body="&lt;p&gt;I Have an old &lt;a href=&quot;http://www.hifido.co.jp/photo/10/520/52010/b.jpg&quot; rel=&quot;nofollow&quot;&gt;audio amplifier&lt;/a&gt; that has those switches to turn it on. &#xA;I'm looking for the simplest motor/robotic arm (or any other relevant component) to control this switch - eventually via Raspberry Pi .&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Are there any options ?&lt;/p&gt;&#xA;" OwnerUserId="2552" LastActivityDate="2014-01-09T00:15:06.827" Title="Flipping an old manual switch (physical one)" Tags="&lt;motor&gt;&lt;raspberry-pi&gt;&lt;robotic-arm&gt;" AnswerCount="1" CommentCount="2" />
  <row Id="2257" PostTypeId="2" ParentId="2256" CreationDate="2014-01-07T18:40:33.953" Score="2" Body="&lt;p&gt;If you just want to control the switches and not the knobs, some options are:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Dual acting solenoids or two simple acting &lt;a href=&quot;http://www.magnetschultz.co.uk/uploads/images/product_images/return-springs-l.jpg&quot; rel=&quot;nofollow&quot;&gt;solenoids&lt;/a&gt;. &#xA;&lt;br&gt;&#xA;Needs just a pulse of current in one direction to operate. In some dual acting solenoids, you need to reverse current to reverse the direction of force.&#xA;&lt;br&gt;&lt;sup&gt;Image from &lt;a href=&quot;http://www.magnetschultz.co.uk&quot; rel=&quot;nofollow&quot;&gt;http://www.magnetschultz.co.uk&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;RC servo-motor. &lt;em&gt;(With that you can control the knobs too)&lt;/em&gt;&#xA;&lt;br&gt;Normally more force for a given size/weight of solenoid. Slower than a solenoid but depending on the model still in the $ ms $ for a 60° rotation. Has more moving parts than a solenoid, so more wear. Major ones have a brushed DC motor so have the brushes wear too. Anyway, should last for maybe a decade without problem. It's a servo-mechanism, so has position feedback and precision positioning. Have the drive electronics, but you need to provide a PWM signal relative to the position you want it to rotate.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://ecx.images-amazon.com/images/I/41dI3XxmxWL._SX300_.jpg&quot; rel=&quot;nofollow&quot;&gt;Car door lock actuator&lt;/a&gt;&lt;br&gt;Shares some of the properties from a RC Servo-motor, but has linear action like the solenoid, and don't have position feed-back (some have a open/closed feed-back). Needs a pulse of current to operate too, but needs reversing the current to reverse the direction of force.&#xA;&lt;br&gt;&lt;sup&gt;Image from &lt;a href=&quot;http://www.amazon.com/&quot; rel=&quot;nofollow&quot;&gt;http://www.amazon.com/&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;sup&gt;&lt;strong&gt;Note:&lt;/strong&gt; I presume by your question that you want to mechanical actuate the switch and electronic options are excluded.&lt;/sup&gt;&lt;/p&gt;&#xA;" OwnerUserId="2447" LastEditorUserId="2447" LastEditDate="2014-01-09T00:15:06.827" LastActivityDate="2014-01-09T00:15:06.827" />
  <row Id="2259" PostTypeId="2" ParentId="2245" CreationDate="2014-01-07T20:33:18.810" Score="0" Body="&lt;p&gt;The noise term $\epsilon_t$ is meant to capture uncertainty in the transition model, e.g. slippage due to an imperfect friction model for wheels. In other words, components of the model that were not incorporated either because they add to much computational complexity or simply cannot be modeled, such as disturbances that cannot be known in advance. It is usually assumed to be a zero mean Gaussian distributed random variable vector of the same size as the state variable $x$ that is independent between time steps. In other words, $x, \epsilon \in \mathbb{R}^n$ where $n$ is the dimension of the state-space, $\epsilon \sim \mathcal{N}(0,\Sigma)$, $\Sigma$ is the covariance of $\epsilon$, and $\epsilon_t$ and $\epsilon_{t+1}$ are identical and independently distributed. These assumptions permit closed form solutions to the Kalman filter which in term makes it relatively efficient to compute.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The noise term $\delta_t$ is basically the same but represents uncertainty in the sensing model. Usually $\epsilon_t$ and $\delta_t$ are not known a priori and need to be learned via some system identification method or can be learned from data using something like Expectation-Maximization.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2014-01-07T20:33:18.810" />
  <row Id="2260" PostTypeId="2" ParentId="2244" CreationDate="2014-01-07T21:45:13.247" Score="1" Body="&lt;p&gt;Defining the state of the quadcopter as $\bf{x} = \left[ \begin{matrix} \mathbf{p} &amp;amp; \mathbf{v} &amp;amp; \mathbf{r} &amp;amp; \mathbf{w} \end{matrix} \right]^T$ where $\mathbf{p}$, $\mathbf{v}$, $\mathbf{r}$, and $\mathbf{w}$ are the position, velocity, angular position, and angular velocity of the quadcopter respectively. A simplified transition model for a quadcopter using PD control is:&#xA;\begin{align}&#xA;\dot{\mathbf{p}} &amp;amp; = \mathbf{v} \\&#xA;\dot{\mathbf{v}} &amp;amp; = -g\mathbf{e}_3 + \text{exp}([\mathbf{r}])\mathbf{e}_3u_1/m \\&#xA;\dot{\mathbf{r}} &amp;amp; = \mathbf{w} + \frac{1}{2}[\mathbf{r}]\mathbf{w} + (1 - \frac{||\mathbf{r}||}{2\text{tan}(||\mathbf{r}||/2)})\frac{[\mathbf{r}]^2}{||\mathbf{r}||^2}\mathbf{w} \\&#xA;\dot{\mathbf{w}} &amp;amp; = \begin{bmatrix} k_1(u_2 - r_x) + k_2w_x \\ k_1(u_3 - r_y) + k_2w_y \\ 0 \end{bmatrix}&#xA;\end{align}&#xA;where $\mathbf{e}_3 = \left[ \begin{matrix} 0 &amp;amp; 0 &amp;amp; 1 \end{matrix} \right]^T$, $[\mathbf{r}]$ represents the skew-symmetric matrix of $\mathbf{r}$, $||\mathbf{r}||$ represents the magnitude of $\mathbf{r}$, $k_1$ and $k_2$ represent the proportional and derivative gains respectively, and the control $\mathbf{u} = \left[ \begin{matrix} u_1 &amp;amp; u_2 &amp;amp; u_3 \end{matrix} \right]^T$ is comprised of the desired total thrust $u_1$, the desired roll angle $u_2$, the desired pitch angle $u_3$, and assumes yaw remains the same. Note that this uses a PD controller because the integration term I is generally not useful for trajectory following.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Using this model you can, given the current state $\mathbf{x}$, calcualte how the state will change. This of course does not give you the desired angular positions about which you asked. Assuming the user expects the quadcopter to hover once it has reached the specified desired position $\mathbf{p} = [X, Y, Z]^T$ then we need $\mathbf{v} = \mathbf{r} = \mathbf{w} = \left[ \begin{matrix} 0 &amp;amp; 0 &amp;amp; 0 \end{matrix} \right]^T$ for the final state.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However that still does not give you the desired angles to transition between the initial state $\mathbf{x}_i$ and the final state $\mathbf{x}_f = \left[ \begin{matrix} \mathbf{p} &amp;amp; \mathbf{v} &amp;amp; \mathbf{r} &amp;amp; \mathbf{w} \end{matrix} \right]^T$. To get that you need a higher level controller to calculate a trajectory $\pi = (\mathbf{x}[], \mathbf{u}[], \tau)$ with $\mathbf{x} : [0, \tau] \rightarrow \mathcal{X}$, $\mathbf{u} : [0, \tau] \rightarrow \mathcal{U}$ for the state-space $\mathcal{X}$ and control space $\mathcal{U}$ and some travel time $\tau$. This trajectory will give you the desired angles at any given moment.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Unfortunately there are a lot of ways to calculate this trajectory. One possibility is to look at my own work in this area. Specifically my paper titled &lt;a href=&quot;http://arl.cs.utah.edu/research/krrtstar/&quot; rel=&quot;nofollow&quot;&gt;Kinodynamic RRT*: Asymptotically Optimal Motion Planning for Robots with Linear Dynamics&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2014-01-07T21:45:13.247" CommentCount="0" />
  <row Id="2261" PostTypeId="1" CreationDate="2014-01-08T05:16:57.413" Score="1" ViewCount="45" Body="&lt;p&gt;Can a gyroscopic sensor (comparable to the type that are typically used in smartphones) that is embedded in this black object &#xA;&lt;br&gt;&lt;img src=&quot;http://i.stack.imgur.com/4KvPC.jpg&quot; alt=&quot;some object&quot;&gt; &lt;br&gt;&#xA;that is rotating around the X axis measure the number of rotations around the X axis if the object may or may not also be rotating at the same time in random ways (number of partial or full rotations, speeds, and directions) around the Z axis?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If so, is the Z axis rotation irrelevant, or is there special mathematics involved in filtering out the affects of the Z rotation on the measurement of X axis rotation?  Or does another measurement such as acceleration or magnetism need to be used to solve the problem?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there any impact in using a 2-axis vs. a 3-axis gyroscopic sensor for this measurement scenario?&lt;/p&gt;&#xA;" OwnerUserId="2556" LastEditorUserId="2447" LastEditDate="2014-01-09T11:20:59.287" LastActivityDate="2014-01-09T13:58:33.453" Title="How to gyroscopically measure number of rotations on one axis when there is concurrent random motion on another axis" Tags="&lt;sensors&gt;&lt;gyroscope&gt;" AnswerCount="1" CommentCount="1" />
  <row Id="2262" PostTypeId="1" CreationDate="2014-01-08T09:07:46.643" Score="0" ViewCount="32" Body="&lt;p&gt;We want to create robot that will localize itself by the signals of wifi routers.&#xA;Which sensors should we buy to detect strength of 3 WiFi signal?&#xA;Which of following is necessary for us?&#xA;&lt;a href=&quot;http://www.dfrobot.com/index.php?route=product/category&amp;amp;path=45_80&quot; rel=&quot;nofollow&quot;&gt;http://www.dfrobot.com/index.php?route=product/category&amp;amp;path=45_80&lt;/a&gt;&#xA;or can be any other more suitable variants?&#xA;We are using arduino as a platform.&lt;/p&gt;&#xA;" OwnerUserId="2557" LastActivityDate="2014-01-08T16:48:28.607" Title="How to choose WiFi signal strength detecting sensors" Tags="&lt;arduino&gt;&lt;sensors&gt;&lt;localization&gt;&lt;wifi&gt;" AnswerCount="1" FavoriteCount="1" />
  <row Id="2263" PostTypeId="1" CreationDate="2014-01-08T09:10:29.550" Score="2" ViewCount="81" Body="&lt;p&gt;I previously thought that an accelerometer on a quadcopter is used to find the position by integrating the data got from it. After I read a lot and watched &lt;a href=&quot;http://www.youtube.com/watch?v=C7JQ7Rpwn2k&quot; rel=&quot;nofollow&quot;&gt;this Youtube video&lt;/a&gt; (specifically at time 23:20) about Sensor Fusion on Android Devices, I seem to get its use a little correct. I realized that it's hard to filter out the considerable noise, generated from error integration,  to get useful information about the position. I also realized that it is used along with the gyroscope and magnetometer to for fused information about orientation not linear translation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For outdoor flight, I thought of the GPS data to get the relative position, but is it so accurate in away that enables position measurement (with good precision)? How do commercial quadcopters measure positions (X,Y and Z)? Is it that GPS data are fused with the accelerometer data?&lt;/p&gt;&#xA;" OwnerUserId="2533" LastActivityDate="2014-01-09T01:50:59.957" Title="Quadcopter Position Measurement (Accelerometer, GPS or Both)?" Tags="&lt;quadcopter&gt;&lt;accelerometer&gt;&lt;navigation&gt;&lt;sensor-fusion&gt;" AnswerCount="3" />
  <row Id="2264" PostTypeId="1" CreationDate="2014-01-08T07:02:30.187" Score="2" ViewCount="72" Body="&lt;p&gt;I need help in differentiating between AI and Robotics. Are AI and Robotics two different fields or is robotics a subject in AI?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I want to pursue a career in AI and Robotics. So I need your valuable suggestion. I searched the web and also some universities that I want to apply and I cannot find any such thing that I am searching for.&lt;/p&gt;&#xA;" OwnerDisplayName="user1395787" LastEditorUserId="158" LastEditDate="2014-01-08T16:11:34.063" LastActivityDate="2014-01-08T16:29:16.260" Title="Are Artificial Intelligence and Robotics Different?" Tags="&lt;artificial-intelligence&gt;&lt;robotics-general&gt;" AnswerCount="3" CommentCount="6" />
  <row Id="2265" PostTypeId="2" ParentId="2264" CreationDate="2014-01-08T09:43:08.847" Score="3" Body="&lt;p&gt;AI means different things to different people and encapsulates a large number of sub-domains: vision, natural language processing, knowledge representation and engineering, machine learning, etc.  Many, if not all, areas of AI have applications to robotics; however, doing AI research does not mean that you directly, or in any way, work with robots.  Working with robots does not necessarily mean that you do artificial intelligence research, either.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Off the top of my head, here are a few good programs (my opinion, which was based off of my research and interests): &lt;a href=&quot;http://www.robotics.gatech.edu/&quot; rel=&quot;nofollow&quot;&gt;Georgia Tech&lt;/a&gt;, &lt;a href=&quot;http://www.eecs.mit.edu/&quot; rel=&quot;nofollow&quot;&gt;MIT&lt;/a&gt;, &lt;a href=&quot;http://www.ri.cmu.edu/&quot; rel=&quot;nofollow&quot;&gt;CMU&lt;/a&gt;, &lt;a href=&quot;http://ai.stanford.edu/&quot; rel=&quot;nofollow&quot;&gt;Stanford&lt;/a&gt;, &lt;a href=&quot;http://cs.brown.edu/research/areas.html&quot; rel=&quot;nofollow&quot;&gt;Brown&lt;/a&gt;, &lt;a href=&quot;https://www.lcsr.jhu.edu/Main_Page&quot; rel=&quot;nofollow&quot;&gt;Johns Hopkins&lt;/a&gt;, etc. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;NB:&lt;/strong&gt;&lt;br&gt; It may be different for a master's degree, but if you're looking to do research, you shouldn't be judging schools based off the general reputation of a particular sector of the CS department.  Instead, you should be looking for specific professors with whom you would like to conduct research.  Being at a well known school is wonderful, but if the professors aren't doing what you're interested in, then you're doing yourself a disservice.   &lt;/p&gt;&#xA;" OwnerUserId="2562" OwnerDisplayName="Steve P." LastActivityDate="2014-01-08T09:54:53.973" CommentCount="1" />
  <row Id="2266" PostTypeId="2" ParentId="2264" CreationDate="2014-01-08T13:02:19.997" Score="1" Body="&lt;p&gt;If you want to understand the difference between robotics vs AI, you can roughly think about it as creatures vs brain (more precisely, nerve system).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;First off, not all creatures have a brain. They may have nerves that allow them to act reflexively. They are equivalent to robots with no AI (note: definition of AI is not &lt;em&gt;that&lt;/em&gt; precise).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are some creatures with a brain, but a brain that is quite dumb (in the sense that it can do complex tasks, but it can't learn new ways for it). Those are robots with more complex algorithms, but still no learning, which some consider as no AI and some consider as a specific kind of AI.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The interesting ones are the ones that have brains they use to learn (e.g. humans, cats, dolphins, elephants etc). They are like robots with AI.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In summary, robotics is a whole set of sciences; mathematics, physics, mechanics, electronics, materials, control, geometry, artificial intelligence and many others. However, each of those sciences by itself goes beyond robotics.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you go after learning AI, you &lt;em&gt;may&lt;/em&gt; end up applying it in robotics or not, depending on your own decisions later. If you go after learning robotics, you &lt;em&gt;may&lt;/em&gt; end up working on its AI or not, depending on your own decisions later.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My recommendation would therefore be to think of possibilities. For example, if you are interested in AI in robotics now, what would happen if you lose interest in it in the future? If you are generally interested in algorithmic software, choose AI. If you change your mind about robotics, you still have something to focus on. If you are particularly interested in building real things, go with robotics. If you change your mind about AI later, you can still work on robots.&lt;/p&gt;&#xA;" OwnerUserId="158" LastActivityDate="2014-01-08T13:02:19.997" />
  <row Id="2267" PostTypeId="2" ParentId="2264" CreationDate="2014-01-08T16:29:16.260" Score="3" Body="&lt;p&gt;They are different.  They are often used together, but the two are not specifically related.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Artificial Intelligence is a branch of computer science that focuses on solving problems that are traditionally difficult for computers -- tasks that become exponentially or &lt;a href=&quot;http://en.wikipedia.org/wiki/Factorial&quot; rel=&quot;nofollow&quot;&gt;factorially&lt;/a&gt; more complex for each incremental increase in the input.  An example of this would be the &lt;a href=&quot;https://xkcd.com/173/&quot; rel=&quot;nofollow&quot;&gt;XKCD movie seating problem&lt;/a&gt;, which has 120 options for 5 people but 2,432,902,008,176,640,000 options for 20 people.  Another example would be processing the many thousands of points you'd see in a &lt;a href=&quot;http://en.wikipedia.org/wiki/Lidar&quot; rel=&quot;nofollow&quot;&gt;LiDAR&lt;/a&gt; image (like &lt;a href=&quot;http://www.neonnotes.org/wp-content/uploads/2012/05/manhattan-lidar092701.jpg&quot; rel=&quot;nofollow&quot;&gt;this one&lt;/a&gt;) in order to build a plan for navigating through an area.  The field of Artificial Intelligence attempts to find decent shortcuts to getting acceptable solutions to these types of problems; it would take far too long to evaluate each possible solution separately then pick the best one.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Robotic systems are simply mechanical systems that can measure and react to their environment in the pursuit of some goal.  This could be as simple as &lt;a href=&quot;http://www.youtube.com/watch?v=Hm3p3yFuS6w&quot; rel=&quot;nofollow&quot;&gt;balancing an inverted pendulum&lt;/a&gt;, which requires no AI.  Alternatively, it could be as complicated as &lt;a href=&quot;http://www.youtube.com/watch?v=gy5g33S0Gzo&quot; rel=&quot;nofollow&quot;&gt;recognizing folding towels&lt;/a&gt;, which requires AI to sort out things like &quot;which objects are towels&quot;, &quot;how do I pick them up&quot;, &quot;how do I move in order to fold them&quot;, etc.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In short, AI is one of many tools that a robotics engineer might integrate into a robotic system.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2014-01-08T16:29:16.260" />
  <row Id="2268" PostTypeId="2" ParentId="2262" CreationDate="2014-01-08T16:48:28.607" Score="0" Body="&lt;p&gt;Any WiFi system should be able to report the signal strength (in dBm), but the question will be how quickly you need it to report values and how accurate a measurement you are looking for.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The main problem with what you're suggesting is that the relationship between signal strength and distance is not necessarily linear.  Antennas produce an interference pattern which can make the strength change depending on your orientation to them.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Radiation_pattern&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Sidelobes_en.svg/200px-Sidelobes_en.svg.png&quot; alt=&quot;antenna lobes&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The second problem is that the signal strength can be affected by the environment: humidity, nearby metal, buildings, and even &lt;a href=&quot;http://www.wikihow.com/Boost-Your-Car-Remote-With-Your-Skull&quot; rel=&quot;nofollow&quot;&gt;your body&lt;/a&gt; can affect the strength of the signal (if not directly, then through interference).  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The only way to really do it is by &lt;a href=&quot;http://arstechnica.com/uncategorized/2008/01/where-gps-wont-do-wifi-triangulation-might/&quot; rel=&quot;nofollow&quot;&gt;heavily characterizing the wifi signals in the area you want to operate in&lt;/a&gt; and hoping that it doesn't change too much over time.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2014-01-08T16:48:28.607" CommentCount="0" />
  <row Id="2269" PostTypeId="2" ParentId="2263" CreationDate="2014-01-08T17:04:49.430" Score="2" Body="&lt;p&gt;Generally, for indoor flight, commercial quadcopters do not measure position. Instead, they measure the change in position so as to prevent the quadrotor from moving when it should not. So while accelerometers are not great for maintaining an estimate of the quadrotors position they can be used to stabilize the system, i.e. to determine what commands needed to be executed to maintain their current position.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Drift can still be a problem though. As such the data from the accelerometer is usually combined with other sources of information. The Kalman filter is one approach as the presenter touches on around minute 27. Another is to use a complimentary filter which are nice because they require less processing power. Some of the other sources for data for estimating the state of a quadcopter include the gyroscopes, magnometers, barometric pressure sensors, range finders (usually ultrasonic though I have seen IR sensors used), and optical flow via cameras.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;With this additional information you could arguably still use an accelerometer for position estimation. I have not seen this done so I cannot speak to its effectiveness though. I suspect other approaches would be better. One method would be to use a laser range finder to localize the robot. Another would be to use a motion capture system as many research facilities do.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As a side note, beware that GPS gives absolute position $\pm \epsilon$ where $\epsilon$ accounts for error, i.e. give or take some error, as opposed to relative position.&lt;/p&gt;&#xA;" OwnerUserId="177" LastActivityDate="2014-01-08T17:04:49.430" CommentCount="4" />
  <row Id="2270" PostTypeId="2" ParentId="2263" CreationDate="2014-01-08T19:21:29.113" Score="2" Body="&lt;blockquote&gt;&#xA;  &lt;p&gt;Is ... GPS data ... fused with the accelerometer data?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Yes, many aircraft use sensor-fusion techniques so both GPS data and accelerometer data effect the estimated X, Y, Z position.&#xA;Often they use a Kalman filter to do the data fusion.&#xA;(  &lt;a href=&quot;/questions/tagged/kalman-filter&quot; class=&quot;post-tag&quot; title=&quot;show questions tagged &amp;#39;kalman-filter&amp;#39;&quot; rel=&quot;tag&quot;&gt;kalman-filter&lt;/a&gt;; &lt;a href=&quot;http://robotics.stackexchange.com/questions/277/why-do-i-need-a-kalman-filter&quot;&gt;Why do I need a Kalman filter?&lt;/a&gt; )&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Measuring X,Y,Z accurately for each photo is important for assembling photos into an aerial photographic map. &lt;a href=&quot;http://vterrain.org/Imagery/self.html&quot; rel=&quot;nofollow&quot;&gt;(a)&lt;/a&gt; &lt;a href=&quot;http://plane.ardupilot.com/wiki/common-geotagging-images-with-mission-planner/&quot; rel=&quot;nofollow&quot;&gt;(b)&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Low-cost GPS receivers typically produce a X,Y,Z position once a second with an accuracy better than 20 meters. That is &quot;good precision&quot; for photographic mapping with a small RC aircraft or finding the destination runway in a manned aircraft. It's pretty much useless for a quadcopter flying in a room or a small field  less than 20 meters on a side.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(Some GPS receivers are available that use DGPS and other techniques to get better accuracy, or generate a position many more times per second, or both).&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;How do ... quadcopters measure positions (X,Y and Z)?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;They usually don't.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My understanding is that most quadcopters aren't doing aerial mapping or fully autonomous motion, so they don't bother calculating XYZ position. &lt;a href=&quot;http://diydrones.com/forum/topics/quadcopter-control-function-layers&quot; rel=&quot;nofollow&quot;&gt;(c)&lt;/a&gt; &lt;a href=&quot;http://diydrones.com/forum/topics/how-to-get-xyz-position-from-9dof-imu-output&quot; rel=&quot;nofollow&quot;&gt;(d)&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As you already know from that video,&#xA;quadcopters use the accelerometers to improve their estimates of the aircraft orientation (its pitch, roll, yaw).&#xA;The quadcopter needs to know the orientation in order to stay right-side-up and to avoid spinning uncontrollably.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;How do ... quadcopters measure positions (X,Y and Z)?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;The people at the &lt;a href=&quot;https://www.grasp.upenn.edu&quot; rel=&quot;nofollow&quot;&gt;GRASP lab at U Penn&lt;/a&gt; measure XYZ position of their quadcopters using lots of expensive motion capture cameras bolted to the walls. They produce lots of really impressive-looking videos.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A few cutting-edge research projects are trying to measure XYZ positions using cameras attached to the quadcopters.&#xA;&lt;a href=&quot;http://savvash.blogspot.com/2012/05/sfly-quadrotors-navigate-outdoors-all.html&quot; rel=&quot;nofollow&quot;&gt;(&quot;sFly Quadrotors Navigate Outdoors All By Themselves&quot;)&lt;/a&gt;&#xA;( &lt;a href=&quot;http://robotics.stackexchange.com/questions/1554/track-a-moving-object&quot;&gt;Track a moving object&lt;/a&gt; )&#xA;&lt;a href=&quot;http://www.acceler8or.com/tags/quadcopter/&quot; rel=&quot;nofollow&quot;&gt;(&quot;Encouraging Developments In Quadcopters (w. Lots Of Video)&quot;)&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Before GPS, commercial aircraft used airport radio beacons to &lt;del&gt;do instrument landing&lt;/del&gt; navigate.&#xA;I see some people talking about related techniques for &lt;a href=&quot;http://robotics.stackexchange.com/questions/256/quadcopter-localization-beacon&quot;&gt;radio beacon localization for quadcopters&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://robotics.stackexchange.com/users/350/ian&quot;&gt;Ian&lt;/a&gt; suggests &lt;a href=&quot;http://robotics.stackexchange.com/questions/1554/track-a-moving-object/1561#1561&quot;&gt;tagging each landmark&lt;/a&gt; with a unique &lt;a href=&quot;http://www.aforgenet.com/articles/glyph_recognition/&quot; rel=&quot;nofollow&quot;&gt;augmented reality glyph&lt;/a&gt;.&#xA;Some people find it more practical to use a camera on the quadcopter to detect and estimate relative bearing to a simple red rectangular landing pad.&#xA;&lt;a href=&quot;http://people.ece.cornell.edu/land/courses/eceprojectsland/STUDENTPROJ/2012to2013/ssm92/ssm92_report_201305171020.pdf&quot; rel=&quot;nofollow&quot;&gt;(&quot;Autonomous Quadcopter Docking System&quot;)&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="187" LastEditorUserId="187" LastEditDate="2014-01-09T01:50:59.957" LastActivityDate="2014-01-09T01:50:59.957" CommentCount="2" />
  <row Id="2271" PostTypeId="2" ParentId="2263" CreationDate="2014-01-08T20:44:26.120" Score="1" Body="&lt;p&gt;Position measurement is all about dealing with uncertainty.  Entire books have been written on how to estimate good position from uncertain data coming from several sources, so I won't try to summarize that here.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In general though, what you need will depend a lot on how accurate you need to be.  Getting GPS fixes once per second (5 times per second on some hardware) is great for something like a large boat.  However, 5 fixes per second is pretty bad when you're moving at high speeds in close quarters, like a quadcopter does -- not to mention the (roughly) 20-foot circle of uncertainty in GPS positions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are many position, velocity, and acceleration sensors that you can buy.  Only some of them are practical for any given application, and terribly few of them are good enough to be considered real-time ground-truth by themselves (either operating in tightly controlled environments, or costing you hundreds of thousands of dollars).  So, you need to pick a good mix of sensors so that each one can help keep the inaccuracies of the other sensors in check. This is entirely dependent on your robot and its application; there is no one-size-fits-all.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Typically, you'd combine a high-accuracy-low-frequency method like GPS (or other triangulation-based scheme) with a moderate-accuracy-high-frequency method like an accelerometer or gyro.  This keeps estimates from drifting too far while giving some reasonable real-time adjustments.  &lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2014-01-08T20:44:26.120" CommentCount="2" />
  <row Id="2273" PostTypeId="1" AcceptedAnswerId="2296" CreationDate="2014-01-09T01:56:50.623" Score="5" ViewCount="143" Body="&lt;p&gt;I am having difficulty sustaining a connection between my Raspberry Pi (Model B running &lt;a href=&quot;http://en.wikipedia.org/wiki/Raspbian&quot; rel=&quot;nofollow&quot;&gt;Raspbian&lt;/a&gt;) and my Arduino (&lt;a href=&quot;http://arduino.cc/en/Main/ArduinoBoardUno&quot; rel=&quot;nofollow&quot;&gt;Uno&lt;/a&gt;) while sending signals from the Raspberry Pi to a &lt;a href=&quot;http://www.pololu.com/product/2149&quot; rel=&quot;nofollow&quot; title=&quot;title here&quot;&gt;continuously rotating servo&lt;/a&gt; (PowerHD AR- 3606HB Robot Servo) via Python. I'm not sure if there is a more efficent way of sending servo instructions via Python to the Arduino to rotate the servo. I'm attempting to communicate signals from the Raspberry Pi to the Arduino via USB using what I believe is considered a &quot;digital Serial connection&quot;. My current connection:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;Wireless Xbox 360 Controller&#xA;-&amp;gt;&#xA;Wireless Xbox 360 Controller Receiver&#xA;-&amp;gt;&#xA;Raspberry Pi&#xA;-&amp;gt;&#xA;Externally Powered USB Hub&#xA;-&amp;gt;&#xA;Arduino&#xA;-&amp;gt;&#xA;Servo&lt;/code&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/u038Q.png&quot; alt=&quot;Enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;Servo connection to Arduino:&#xA;   Signal (Orange) - pin 9&#xA;   Power (Red) - +5 V&#xA;   Ground (Black) - GND&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;On the Raspberry Pi I have installed the following (although not all needed for addressing this problem):&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://github.com/Grumbel/xboxdrv&quot; rel=&quot;nofollow&quot;&gt;xboxdrv&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://pyserial.sourceforge.net/&quot; rel=&quot;nofollow&quot;&gt;pyserial&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://github.com/thearn/Python-Arduino-Command-API&quot; rel=&quot;nofollow&quot;&gt;Python-Arduino-Command-API&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.pygame.org/news.html&quot; rel=&quot;nofollow&quot;&gt;PyGame&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://github.com/zephod/lego-pi&quot; rel=&quot;nofollow&quot;&gt;lego-pi&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://arduino.cc/&quot; rel=&quot;nofollow&quot;&gt;Arduino&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The sketch I've uploaded to the Arduino Uno is the &lt;a href=&quot;https://github.com/thearn/Python-Arduino-Command-API/blob/master/sketches/prototype/prototype.ino&quot; rel=&quot;nofollow&quot;&gt;corresponding sketch&lt;/a&gt; provided with the Python-Arduino-Command-API. *Again, I'm not positive that this is the best method means of driving my servo from Python to Arduino (to the servo).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From the Raspberry Pi, I can see the Arduino is initially correctly connected via USB:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;pi@raspberrypi ~/Python-Arduino-Command-API $ dir /dev/ttyA*&#xA;/dev/ttyACM0  /dev/ttyAMA0&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;and&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;pi@raspberrypi ~/Python-Arduino-Command-API $ lsusb&#xA;Bus 001 Device 002: ID 0424:9512 Standard Microsystems Corp.&#xA;Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub&#xA;Bus 001 Device 003: ID 0424:ec00 Standard Microsystems Corp.&#xA;Bus 001 Device 004: ID 045e:0719 Microsoft Corp. Xbox 360 Wireless Adapter&#xA;Bus 001 Device 005: ID 1a40:0201 Terminus Technology Inc. FE 2.1 7-port Hub&#xA;Bus 001 Device 006: ID 0bda:8176 Realtek Semiconductor Corp. RTL8188CUS 802.11n WLAN Adapter&#xA;Bus 001 Device 007: ID 046d:c52b Logitech, Inc. Unifying Receiver&#xA;Bus 001 Device 008: ID 2341:0043 Arduino SA Uno R3 (CDC ACM)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;From the Raspberry Pi, I'm able to rotate the servo as a test clockwise for one second, counter-clockwise for one second, then stop the servo, with the following Python script:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#!/usr/bin/env python&#xA;from Arduino import Arduino&#xA;import time&#xA;&#xA;board = Arduino(9600, port='/dev/ttyACM0')&#xA;&#xA;board.Servos.attach(9) # Declare servo on pin 9&#xA;board.Servos.write(9, 0) # Move servo to full speed, clockwise&#xA;time.sleep(1) # Sleep for 1 second&#xA;print board.Servos.read(9) # Speed check (should read &quot;0&quot;)&#xA;&#xA;board.Servos.write(9, 180)&#xA;time.sleep(1)&#xA;print board.Servos.read(9) # (Should read &quot;180&quot;)&#xA;&#xA;board.Servos.write(9, 90)&#xA;print board.Servos.read(9)&#xA;board.Servos.detach(9)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;The output via the Raspberry Pi terminal reads:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;0&#xA;180&#xA;90&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Although this only performs full-speed in both direction (as well as the calibrated &quot;stop&quot; speed of 90), I have successfully alternated from a full-speed to slower speeds, for example, going from 0 up to 90 in increments of 10.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From the Raspberry Pi, I'm able to send input from my Xbox controller to drive the servo with a small custom Python script I've created along with xboxdrv (which works flawlessly with other projects I'm doing):&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;#!/usr/bin/python&#xA;&#xA;from legopi.lib import xbox_read&#xA;from Arduino import Arduino&#xA;&#xA;# To catch Ctrl+C&#xA;import signal&#xA;import sys&#xA;&#xA;# The deadzone within which we ignore inputs, approximately 1/3 of total possible input&#xA;DEADZONE = 12000&#xA;&#xA;def signal_handler(signal, frame):&#xA;    print &quot;Stopping Wrapper&quot;&#xA;    sys.exit(0)&#xA;&#xA;# Capture Ctrl+C so we can shut down nicely&#xA;signal.signal(signal.SIGINT, signal_handler)&#xA;&#xA;print &quot;Starting Wrapper&quot;&#xA;print &quot;Press Ctrl+C at any time to quit&quot;&#xA;&#xA;board = Arduino(9600, port='/dev/ttyACM0')&#xA;board.Servos.attach(9)&#xA;board.Servos.write(9, 90)&#xA;&#xA;for event in xbox_read.event_stream(deadzone=DEADZONE):&#xA;    print &quot;Xbox event: %s&quot; % (event)&#xA;&#xA;    # If the RB button it's being held, rotate the servo counter-clockwise at full-speed.&#xA;    # When the RB button is released, stop the servo.&#xA;    if(event.key=='RB'):&#xA;        if(event.value&amp;gt;0):&#xA;            board.Servos.write(9, 180)&#xA;            print board.Servos.read(9)&#xA;        else:&#xA;            board.Servos.write(9, 90)&#xA;            print board.Servos.read(9)&#xA;        continue&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;This script runs, and I'm able to control the servo using the RB button on my controller. However, &lt;strong&gt;it eventually fails&lt;/strong&gt; - sometimes after minutes, sometimes after seconds (rapid and intermittent input seemingly having no influence on expediting a crash). Input is no longer read by the script, the terminal comes to a halt, the servo freezes on whatever the last command given was (either spinning endlessly or stopped), and I'm forced to &lt;kbd&gt;Ctrl&lt;/kbd&gt; + &lt;kbd&gt;C&lt;/kbd&gt; out of the script. If I check to see if the Arduino is still connected to the Raspberry Pi, it shows that it has reconnected itself to the Raspberry Pi as &quot;ttyACM1&quot; (from /dev/ttyACM0 to /dev/ttyACM1):&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;pi@raspberrypi ~/robotarm $ dir /dev/ttyA*&#xA;/dev/ttyACM1  /dev/ttyAMA0&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Why does the Arduino reconnect itself? Is there some other way I should be processing this information? Distance to the wireless Xbox receiver is not a factor as all of these pieces are adjacent to one another for testing purposes. It will prove impossible to use this servo as a wheel for my robot if I'm constantly tending to this issue.&lt;/p&gt;&#xA;" OwnerUserId="2564" LastEditorUserId="1906" LastEditDate="2014-01-18T13:37:46.503" LastActivityDate="2014-01-18T13:37:46.503" Title="Unwanted Arduino reconnect: Servo + Arduino + Python (Raspberry Pi)" Tags="&lt;arduino&gt;&lt;raspberry-pi&gt;&lt;servos&gt;&lt;python&gt;" AnswerCount="1" CommentCount="6" />
  <row Id="2274" PostTypeId="1" AcceptedAnswerId="2275" CreationDate="2014-01-09T05:45:28.850" Score="1" ViewCount="63" Body="&lt;p&gt;I've spent quite some time researching this, but most of my Google search results have turned up academic research papers that are interesting but not very practical.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm working on a target/pattern recognition project** where a robot with a small camera attached to it will attempt to locate targets using a small wireless camera as it moves around a room. The targets will ideally be as small as possible (something like the size of a business card or smaller), but could be (less ideally) as large as 8x10 inches. The targets will be in the form of something easily printable.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The pattern recognition software needs to be able to recognize if a target (only one at a time) is in the field of vision, and needs to be able to accurately differentiate between at least 12 different target patterns, hopefully from maybe a 50x50 pixel portion of a 640x480 image.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Before playing with the camera, I had envisioned using somewhat small printed barcodes and the excellent &lt;a href=&quot;https://code.google.com/p/zxing/&quot; rel=&quot;nofollow&quot;&gt;zxing&lt;/a&gt; library to recognize the barcodes.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As it turns out, the camera's resolution is terrible - 640x480, and grainy and not well-focused. &lt;a href=&quot;http://i.imgur.com/MuPibcJ.png&quot; rel=&quot;nofollow&quot;&gt;Here is an example still image.&lt;/a&gt; It's not very well-suited for capturing barcodes, especially while moving. I think it could work with 8x10 barcodes, but that's really larger than I'm looking for. (I'm using this particular camera because it is tiny, light, cheap, and includes a battery and wi-fi.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm looking for two things: a suggestion or pointer to an optimal pattern that I could use for my targets, and a software library and/or algorithm that can help me identify these patterns from images. I have NO idea where to start with the right type of pattern so suggestions there would really help, especially if there is a project out there that does something resembling this. I've found &lt;a href=&quot;http://opencv.org/&quot; rel=&quot;nofollow&quot;&gt;OpenCV&lt;/a&gt; and &lt;a href=&quot;http://robwhess.github.io/opensift/&quot; rel=&quot;nofollow&quot;&gt;OpenSIFT&lt;/a&gt; which both seem like potential candidates for software libraries, but neither seemed to have examples of doing the type of recognition I'm talking about. I'm thinking picking the right type of pattern is the big hurdle to overcome here, so any pointers to the optimal type of pattern would be great. Being able to recognize the pattern from all different angles is a must.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So far, my idea is to use patterns that perhaps look &lt;a href=&quot;http://i.imgur.com/jWU875q.jpg&quot; rel=&quot;nofollow&quot;&gt;something like this&lt;/a&gt;, where the three concentric color rings are simply either red, green, or blue - allowing for up to 27 unique targets, or 81 if I use 4 rings. From about 2 feet, the capture of a 3x3 inch target (from my computer screen) &lt;a href=&quot;http://i.imgur.com/JQcmBdv.png&quot; rel=&quot;nofollow&quot;&gt;looks like this&lt;/a&gt; which seems like it would be suitable for analysis but I feel like there should be a better type of pattern that would be more compact and easier to recognize - maybe just a plain black and white pattern of some sort with shapes on it?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pointers to an optimal approach for this are greatly appreciated.&lt;/p&gt;&#xA;" OwnerUserId="2567" LastEditorUserId="2447" LastEditDate="2014-01-09T15:20:16.123" LastActivityDate="2014-01-09T20:08:06.483" Title="Workable low-resolution object/target recognition pattern and library?" Tags="&lt;software&gt;&lt;computer-vision&gt;&lt;artificial-intelligence&gt;" AnswerCount="1" CommentCount="4" />
  <row Id="2275" PostTypeId="2" ParentId="2274" CreationDate="2014-01-09T06:06:10.677" Score="1" Body="&lt;p&gt;Well, one of the things is that computer vision starts at light, lenses and camera, you need good ones. Its not only a question of resolution, it's also a question of sensor size, signal/noise ratio, and good lenses. There's no need for high resolution if your camera has poor optics.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So your environment is pretty challenging and there's no certainly that it will works in this way.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The 640x480 is not to low resolution. I have read a paper that proposed something like your circle, but without the spaces between the rings, so more light reflected and less wasted space, the circles are divided to represent a code of the place.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A simple circle divided into 4 segments with 4 colors would give you 256 distinct codes.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;More or less this:&lt;br&gt;&#xA;&lt;img src=&quot;http://i.stack.imgur.com/ckiCO.gif&quot; alt=&quot;robot land mark&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The lines are just for exemplification. Lets suppose you use 4 divisions with 4 colors: Red, Green, Blue and White. This would give you $ 4^4=256 $ distinct marks.&#xA;You could detect the circle with edge detect algorithms, and then you have the coordinates to get the color marks.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This needs that the orientation of the robot and the mark is always the same, if the robot or camera tilts, or you want to put the mark in any position, just add a first marker.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Adding a &lt;em&gt;redundancy check&lt;/em&gt; to it is good to, as this will help removing false-positive marks.&lt;/p&gt;&#xA;" OwnerUserId="2447" LastEditorUserId="2447" LastEditDate="2014-01-09T20:08:06.483" LastActivityDate="2014-01-09T20:08:06.483" CommentCount="2" />
  <row Id="2276" PostTypeId="2" ParentId="2261" CreationDate="2014-01-09T13:58:33.453" Score="0" Body="&lt;p&gt;I believe the term you are looking for is 'Cross sensitivity'. This term describes the effect that motion in one axis has on the measured motion of other orthogonal axes in accelerometers or gyroscopes&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Cross Sensitivity is normally stated by the manufacturer of the sensor and (depending on the quality/type of the sensor) is typically 1-5%. So, for example, a 10 rad/s rotation around the x axis might also give an output of 0.1 rad/s around the y axis and -0.2rad/s around the z axis which will lead to drift in the calculated position/angle of the device&#xA;Also, the cross-sensitivity may be different between different pairs of axes so there may be 3 values Sxy, Syz, Sxz.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In a perfect sensor the motion around one axis would not affect the others but in a real device there is always some effect.&lt;/p&gt;&#xA;" OwnerUserId="1978" LastActivityDate="2014-01-09T13:58:33.453" />
  <row Id="2277" PostTypeId="1" CreationDate="2014-01-09T21:17:09.453" Score="2" ViewCount="68" Body="&lt;p&gt;I've gone through tutorials on how to build circuits and control dc, stepper, and servo motors.  I may not understand everything about them internally, but i have a good basic foundation.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now i'm at a loss for where to go from here.  I'm more interested in learning how to make mechanical devices with them than just the electronics behind the devices.  While i know that they go hand in hand, i want to learn more about the mechanical aspects of using motors.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have in mind several ultimate goal projects that i want to work toward, like home automation, model rc vehicles, autonomous robots, etc...  But i'm sure that there is more to mechanics that i need to learn before i can jump into a project like that.  &lt;strong&gt;&lt;em&gt;He who will learn to fly one day must first learn to stand and walk.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Are there hobbyist mechanical starter kits or starter projects to learn how to make effective use of electric motors?  I don't necessarily need a specific product endorsement, but rather a general idea of what important concepts to learn and materials / projects to help me learn them.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My apologies if this question is too broad.  I can refine it if deemed necessary.&lt;/p&gt;&#xA;" OwnerUserId="2295" LastActivityDate="2014-01-10T23:41:06.013" Title="Once you understand motors, what's the next step?" Tags="&lt;motor&gt;&lt;mechanism&gt;" AnswerCount="1" CommentCount="9" ClosedDate="2014-01-11T00:57:41.267" />
  <row Id="2279" PostTypeId="1" AcceptedAnswerId="2285" CreationDate="2014-01-10T00:23:22.653" Score="2" ViewCount="71" Body="&lt;p&gt;at the moment I am creating an android program, that will steer my simple, 3 wheel (2 motors, 1 for balance) robot to move online following the path drawn by user on his screen. The robot is operated through WiFi and has 2 motors that will react on any input signals.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Imagine user drawing a path for this robot on smartphone screen. It has aquired all the points on XY axis, every time beginning with (0,0). Still I have no idea, how to somehow &quot;convert&quot; just points, into voltage input to both motors. Signals will be sent in approx. 60Hz connection, so quite fast. Maybe not every single axis point will be taken into consideration, there will be surely some skips, but that is irrelevant, since this path does not have to be done perfectly by the robot, just in reasonable error scale.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Do you have any idea on how to make the robot follow defined axis points that overall create a path?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Edit 10.01:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The voltage will be computed by the robot, so input on both is between -255 and 255 and the velocity should increase or decrease lineary in those borders.&#xA;Additionaly, I would like to solve it as if there were perfect conditions, I don't need any feedback crazy models. Let's assume that all the data is true, no sensors and additional devices. Just XY axis path and required input (ommit wheel slide too).&lt;/p&gt;&#xA;" OwnerUserId="2573" LastEditorUserId="2573" LastEditDate="2014-01-10T12:53:05.823" LastActivityDate="2014-01-10T20:07:50.503" Title="2D path following robot, converting XY axis path to input on wheels" Tags="&lt;wheeled-robot&gt;&lt;wifi&gt;&lt;two-wheeled&gt;" AnswerCount="3" />
  <row Id="2280" PostTypeId="2" ParentId="2279" CreationDate="2014-01-10T04:32:03.853" Score="1" Body="&lt;h1&gt;for the hardware&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;You don't say what type of motor you use. If it's a DC-brushed type, putting more or less voltage will not necessary linearly alter the speed, in fact if you increase the voltage the relative amount the load on the motor increase the speed won't change. To do a good control you need a feed-back of the motor or wheel speed, or an angle sensor that you can derivate the speed.&#xA;If you use this information, and correct it according to the speed you want.&lt;/p&gt;&#xA;&#xA;&lt;h1&gt;for the software&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;What you presumable want to navigation is &lt;a href=&quot;http://en.wikipedia.org/wiki/Dead_reckoning&quot; rel=&quot;nofollow&quot;&gt;Dead reckoning&lt;/a&gt;, but if one wheel slips, the position information will drift and accumulates to the point it turns unusable. So, don't expect the best results with only this.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One more &lt;em&gt;simple&lt;/em&gt; solution is to use an &lt;em&gt;electronic compass&lt;/em&gt; so you know to what direction relative to north (deviations should not be a problem), your robot is pointing. This should help at the turns and more straight path, even if some wheel slip occurs, it will close the loop by that. Wheel slip will still affect the distance traveled.&lt;/p&gt;&#xA;" OwnerUserId="2447" LastEditorUserId="2447" LastEditDate="2014-01-10T20:07:50.503" LastActivityDate="2014-01-10T20:07:50.503" CommentCount="2" />
  <row Id="2281" PostTypeId="2" ParentId="284" CreationDate="2014-01-10T05:43:59.277" Score="0" Body="&lt;p&gt;There are two more factors to consider: &lt;strong&gt;Complexity and cost.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;h1&gt;Industrial robotic arm like that&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://halcyondrives.com/images/robotic_arm.png&quot; alt=&quot;industrial robotic arm&quot;&gt;&#xA;&lt;br&gt;&lt;sup&gt;Image from &lt;a href=&quot;http://halcyondrives.com&quot; rel=&quot;nofollow&quot;&gt;http://halcyondrives.com&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;normally use torque from the gearbox to direct drive the joint, now think about the torque the gear reduction should support and the size/weight it will be? It simple huge and expensive, their materials need to support a huge torque.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Let's take your example with the arm fully horizontally extended.&#xA;Lets consider just the load of 6Kg at 1m, you have $ 600Kgf/cm $. This is not including the robot arm own weight (easily more 4Kg), and considering &lt;em&gt;just&lt;/em&gt; 1m.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Some solutions industry uses&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Strain Wave Gearing or Harmonic drive&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/commons/8/85/Harmonic_drive_animation.gif&quot; alt=&quot;Strain Wave Gearing or Harmonic drive&quot;&gt;&lt;br&gt;&#xA;&lt;sup&gt;Image from &lt;a href=&quot;http://commons.wikipedia.org&quot; rel=&quot;nofollow&quot;&gt;http://commons.wikipedia.org&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To get lighter gear reduction, with high reduction ratios, most uses &lt;a href=&quot;http://en.wikipedia.org/wiki/Harmonic_drive&quot; rel=&quot;nofollow&quot;&gt;Strain Wave Gearing or Harmonic drive&lt;/a&gt;. Its low-weight, robust, and according to wikipedia can have a reduction of $ 200:1 $ (wikipedia says more) where a planetary gear can archive $ ~ 10:1 $.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But this type of gearing is very expensive and complex.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Springs and counter-weights&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://www.globalrobots.ae/robot_guide/images/ABBIRB6400M94Amovements.jpg&quot; alt=&quot;6DOF industrial motor drawing&quot;&gt;&#xA;&lt;br&gt;&lt;sup&gt;Image from &lt;a href=&quot;http://www.globalrobots.ae&quot; rel=&quot;nofollow&quot;&gt;http://www.globalrobots.ae&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Other even simple solution is adding counter-weights like you see in the image. This has a linkage to act both on the forearm (I forget the name) and in the arm. Springs will help too, and if mounted on the same axis of the joint but a bit offset, it will put more force as the arm gets more extended.&lt;/p&gt;&#xA;&#xA;&lt;h1&gt;Low-cost and less complex solutions for the mechanical drive system&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;Now for less cost and less complex solutions, what I should think is removing the high torque at the gear drive, so you can use less expensive materials. For a pure electronic drive, this would be a &lt;em&gt;linear actuator&lt;/em&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is a variety of linear actuators. But the idea is that it will take less force (depending on what points of the arm it is attached).&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&quot;Nut&quot; and leadscrew type&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://b2bimg.bridgat.com/files/Directdrive_linear_actuator.jpg&quot; alt=&quot;lead screw linear actuator&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This type of actuator has many sub-types, and that affects efficiency, wear, force, and much more. But in general, they have a high force and a relative slow-to-medium speed (this will again depend on the type, it can be vary fast, like the ones used on some motion platform simulators).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://cfile29.uf.tistory.com/T250x250/195BAD4B4FDB0AF104C30F&quot; alt=&quot;6 dof motion platform with electric linear actuators&quot;&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Electric linear actuators are substituting hydraulic linear actuators at this application, and they need to be fast and strong, some simulators easily weight more than 2 tons.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Belt or chain drive&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;For more speed and other simple method are the belt or chain drive like that&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://images.pacific-bearing.com/images/drive-types_07.jpg&quot; alt=&quot;belt linear drive actuator&quot;&gt;&#xA;&lt;br&gt;&lt;sup&gt;Image from &lt;a href=&quot;http://images.pacific-bearing.com&quot; rel=&quot;nofollow&quot;&gt;http://images.pacific-bearing.com&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is of course an industrial made one, this is a DIY one, and it has more for the&#xA;application: (yes it has space for much improvement, but is a good form to show how fast and strong it can be even in this design).&#xA;&lt;a href=&quot;http://bffsimulation.com/linear-act.php&quot; rel=&quot;nofollow&quot;&gt;http://bffsimulation.com/linear-act.php&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This allows you to use less gearing, if a motor could output $ 50Kgf/cm $ and you use a 2 cm diameter pulley, you would get $ 50Kgf $ (not considering losses) on the full stroke.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also the bearings at this actuator will need to support most radial forces, where in a &quot;leadscrew and nut&quot; the bearing will take most axial force. So depending on the force you need to use a &lt;a href=&quot;http://en.wikipedia.org/wiki/Thrust_bearing&quot; rel=&quot;nofollow&quot;&gt;thrust ball bearing&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="2447" LastEditorUserId="2447" LastEditDate="2014-01-10T06:12:53.983" LastActivityDate="2014-01-10T06:12:53.983" />
  <row Id="2282" PostTypeId="1" CreationDate="2014-01-09T05:40:27.623" Score="1" ViewCount="25" Body="&lt;p&gt;I have read &lt;a href=&quot;http://robotics.stackexchange.com/questions/2273/unwanted-arduino-reconnect-servo-arduino-python-raspberry-pi&quot;&gt;this question&lt;/a&gt;, starting suggesting an edit to it thinking on a RC-Servomotor by the image.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But, when I read &quot;Robot Servo&quot; in the description of the product I go to the &lt;a href=&quot;http://www.pololu.com/product/2149&quot; rel=&quot;nofollow&quot;&gt;product page&lt;/a&gt; to read more, and I really get a bit confuse.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It seems a simple RC Servo motor with probably the potentiometer and any lock to full rotation removed. Then reading about the signal it says that it uses the PWM to control&#xA;the motor speed and direction, with near 0.5 pulse length being stopped.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Well, thinking again it can be a servo based on the speed, so it has the input speed signal, but does it takes the actual signal for error correction? Reading this &lt;em&gt;71 RPM (no-load)&lt;/em&gt;, seems suspect.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The &lt;a href=&quot;http://www.pololu.com/file/0J693/AR-3606HB.pdf&quot; rel=&quot;nofollow&quot;&gt;data-sheet&lt;/a&gt; only says &lt;em&gt;Control system: PWM&lt;/em&gt; and &lt;em&gt;Amplifier type: Analog Controller&lt;/em&gt;. This second statement sounds like a analog comparator to close the loop, or not as it's an analog controller, is so wide.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It seems more that the input signal PWM just control the direction and amount of current&#xA;delivered to the motor, so it has nothing to do with servo-motor, its a DC Motor with a gear-box and a driver.&lt;/p&gt;&#xA;" OwnerUserId="2447" OwnerDisplayName="Diego C Nascimento" LastEditorUserId="158" LastEditDate="2014-01-10T10:46:17.780" LastActivityDate="2014-01-10T10:46:17.780" Title="To what point this can be accepted as a servo-motor?" Tags="&lt;servomotor&gt;" />
  <row Id="2283" PostTypeId="1" CreationDate="2014-01-10T10:51:55.737" Score="0" ViewCount="33" Body="&lt;p&gt;Orrery is a clockwork model of the solar system. I am trying to emulate one in 2D. Now, to emulate, I need to know what goes on inside. Can someone please explain the basic principle behind the clockwork? Or direct me to a resource that will explain all the machinery inside a simple Orrery.&lt;/p&gt;&#xA;" OwnerUserId="2576" LastActivityDate="2014-01-10T16:23:40.077" Title="Emulation of an Orrery" Tags="&lt;motor&gt;&lt;design&gt;" AnswerCount="1" />
  <row Id="2284" PostTypeId="2" ParentId="2279" CreationDate="2014-01-10T13:55:16.753" Score="1" Body="&lt;p&gt;There are two ways you can approach this problem, open-loop and closed-loop. Open-loop approach should be easier although it will be highly inaccurate. The closed-loop is more complex but it should improve the accuracy. The decision depends on your application and how much time you can spend.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The robot has to follow a requested path drawn by the user. To do that, you &lt;strong&gt;first&lt;/strong&gt; need to track the position and orientation (state) of the robot. In the open-loop approach this is done by blindly predicting the state of the robot based on the input. So for example if you know that the robot is positioned at (0,0) facing at 0 degrees, and the input in the wheels is the same (i.e. drives &quot;straight&quot;) at 1 meter per second, you would expect that after a second, the state of the robot will be (1,0) and still facing at 0 degrees (in reality this wont be the case because of uncertainties but it is just a rough estimation). This is usually done based on a mathematical model of the robot.  For the close-loop approach you also use feedback from the robot. One way to do this is with odometry, i.e. measuring the distance traveled by each wheel and therefore estimating its state using a model, for example the Kinematic Model. State estimation is improved, since you have the model (as in the open-loop) to &quot;predict&quot; the state and then you have the feedback to correct that prediction. For later reference lets define the state estimation as $\hat{x}$.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The closed-loop approach is certainly more accurate but it mainly depends on what sensors you use. An odometry based estimation will be acceptable for short periods but after that it will diverge and be useless. As always, this depends on your application and tolerance for accuracy.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;The second step&lt;/strong&gt; is to decide what input is required to send to the motor. This decision is made based on where the robot is i.e. $\hat{x}$ and where it needs to go $x_r$. For this you need a controller that constantly tries to minimize the error $e=\hat{x}-x_r$. So for your example, $x_r$ holds the coordinates of the next point that has to be visited by the robot. A simple controller would be one that:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Rotates the robot until it faces the point $x_r$&lt;/li&gt;&#xA;&lt;li&gt;Moves the robot in a straight line until it reaches the point&lt;/li&gt;&#xA;&lt;li&gt;Load the next point in $x_r$ and go to the first step&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;There are of course more sophisticated controllers which have certain properties but the above should work for your application.&lt;/p&gt;&#xA;" OwnerUserId="1445" LastActivityDate="2014-01-10T13:55:16.753" CommentCount="7" />
  <row Id="2285" PostTypeId="2" ParentId="2279" CreationDate="2014-01-10T16:10:43.050" Score="1" Body="&lt;p&gt;You're attempting to move a robot along a predefined path without the aid of sensors, so really we just need to convert the list of points into a list of pre-scripted actions.&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Convert input points to $({\Delta}x, {\Delta}y)$ pairs&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Convert $({\Delta}x, {\Delta}y)$ pairs to $(\Delta\theta, d)$ pairs&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Convert $(\Delta\theta, d)$ pairs to $(V_{left}, V_{right}, {\Delta}t)$ tuples&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;The first step is easy -- simple subtraction.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The second step is also fairly straightforward: using the pythagorean theorem for the distance and the &lt;code&gt;atan2&lt;/code&gt; function for the angle:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://i.stack.imgur.com/m7CLt.jpg&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://i.stack.imgur.com/m7CLtm.jpg&quot; alt=&quot;Angle between 2 points&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(Then just keep track of the last $\theta$ so you can calculate $\Delta\theta$).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The last step is a little tricky.  You want to convert that set of angles and distances to the left and right wheel voltages, and the time to run them.  This will actually give you &lt;em&gt;two&lt;/em&gt; $(V_{left}, V_{right}, {\Delta}t)$ tuples for every $(\Delta\theta, d)$ pair: one to change the angle, and one to travel the distance.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;For a given width $w$ between the wheels, the change in the angle (radians) will be based on the movements of the right and left wheel:&#xA;$$&#xA;\Delta \theta = \frac{1}{w} \left( {\Delta}d_{left} - {\Delta}d_{right}\right)&#xA;$$&#xA;You'll have to decide what voltages and $\Delta t$ will produce that change in distance for your robot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Next, you'll do the same calculation for $d$.  Both motors will use the same voltage to (hopefully) travel the same distance.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;That should produce a list of times and voltages that approximate the line you drew.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2014-01-10T16:10:43.050" CommentCount="3" />
  <row Id="2286" PostTypeId="2" ParentId="2283" CreationDate="2014-01-10T16:23:40.077" Score="1" Body="&lt;p&gt;An &lt;a href=&quot;http://en.wikipedia.org/wiki/Orrery&quot; rel=&quot;nofollow&quot;&gt;orrery&lt;/a&gt; just represents the different speeds at which planets orbit the sun by careful selection of gear ratios.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://zeamon.com/wordpress/?page_id=468&quot; rel=&quot;nofollow&quot;&gt;Here is a set of plans that define the gears themselves&lt;/a&gt;, but you could calculate the necessary ratios from the &lt;a href=&quot;http://en.wikipedia.org/wiki/Orbital_period&quot; rel=&quot;nofollow&quot;&gt;orbital period&lt;/a&gt; of each planet.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In code, it would be something like:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;timestep = 0&#xA;while True:&#xA;    timestep = timestep + 1&#xA;    for each planet:&#xA;        theta = (timestep / orbital_period(planet)) % 360&#xA;        draw(planet, theta)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="350" LastActivityDate="2014-01-10T16:23:40.077" CommentCount="2" />
  <row Id="2288" PostTypeId="2" ParentId="2277" CreationDate="2014-01-10T23:41:06.013" Score="-1" Body="&lt;p&gt;so now you have a good foundation of motors and the similar electro-mechanical actuators.&#xA;You have to learn or you have to build up a concepts of all kinds of mechanical parts needed to do a project on a mechanical robotics.&#xA;see there are so many things nto thr domain of robotics but first you have to go step by step.&#xA;as you have a good knowledge about the motors then go through there ratings and emf and all the ratings stuffs and after that try to know which motors are used for which purposes.&#xA;see for robotics the purpose of using the components should be known to do a project in robotics domain.so after gathering the practical knowledge you may tend to the different parts onto them.Try to design a system especially a mechanical system that may be a simple one &lt;strong&gt;(like a robotic mechanical arm)&lt;/strong&gt; and then try to implement some &lt;strong&gt;gear related and pully related mechanical system&lt;/strong&gt; that will do a specific job for you.or you can interface these kinds of motors like a system of &lt;strong&gt;steering system of a car etc&lt;/strong&gt; or you may try something innovative generator system by using motors you have or you can interface it to a analog circuit to make a low cost mechanical system for a specific requirement.you cann try a different one like you can make an &lt;strong&gt;autonomous system using a microcontroller or microprocessor system&lt;/strong&gt; and interface it with some sensors and after sensing the environment you can control the actuators to get your requirement done!&#xA;hope the suggestions may help you.&lt;/p&gt;&#xA;" OwnerUserId="2581" LastActivityDate="2014-01-10T23:41:06.013" />
  <row Id="2289" PostTypeId="1" CreationDate="2014-01-11T14:03:55.197" Score="1" ViewCount="13" Body="&lt;p&gt;My task is to apply forces to control 3-dof parallel manipulator. Forces are applied to linear  actuators, friction is neglected.  End-effector of a robot is supposed to follow generated path; for this example, let it be a simple circle. So far I have made a simplified 3d model of robot and calculated inverse kinematics.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/L8b00Iz.png&quot; alt=&quot;3D model of robot&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Promoter of my engineering work don't really know how to do this, but he said that calculating forward dynamics is too complex and i shouldn't go that way. Could you tell me what will be the easiest way to go? &lt;/p&gt;&#xA;" OwnerUserId="2584" LastEditorUserId="350" LastEditDate="2014-01-13T00:51:18.933" LastActivityDate="2014-01-13T00:51:18.933" Title="Dynamics of parallel manipulator" Tags="&lt;force&gt;&lt;dynamics&gt;&lt;manipulator&gt;" CommentCount="1" />
  <row Id="2290" PostTypeId="1" CreationDate="2014-01-11T20:58:11.123" Score="2" ViewCount="28" Body="&lt;p&gt;I'm running a kk2.0 + 4 20A Multistar ESCs + 4 EMax GF 2215-20 motors + 4 Slow Fly Props&lt;/p&gt;&#xA;&#xA;&lt;p&gt;After about a foot off the ground, the entire quadcopter starts wobbling like crazy (no auto-level). Any ideas?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'll add some video if needed.&lt;/p&gt;&#xA;" OwnerUserId="2588" LastActivityDate="2014-01-12T16:32:55.620" Title="KK2.0 Quad Stablility" Tags="&lt;quadcopter&gt;&lt;stability&gt;" AnswerCount="2" />
  <row Id="2291" PostTypeId="2" ParentId="619" CreationDate="2014-01-12T05:07:22.150" Score="1" Body="&lt;p&gt;While my answer does not address reprogramming ESCs, which is the actual question asked, it does turn the motor the opposite direction. And it was hard for me to find a good answer on the web. Google searching can end up here, so I'm posting what I think is helpful.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For my ESCs, I have three wires coming out, and to reverse the direction of the motor, all I have to do is swap any two wires that go from the ESC to the motor. It worked for me. YMMV.&lt;/p&gt;&#xA;" OwnerUserId="2589" LastActivityDate="2014-01-12T05:07:22.150" />
  <row Id="2292" PostTypeId="2" ParentId="1209" CreationDate="2014-01-12T05:12:04.140" Score="2" Body="&lt;p&gt;Something you can do &lt;strong&gt;WRONG&lt;/strong&gt; to very easily unstabilize a quadcopter is to put the wrong propeller on the wrong motor. There are both pushers and pullers, and depending on the configuration you choose, you need the right type. Its possible you had two of them swapped. When they broke, you got the new ones on properly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://copter.ardupilot.com/wiki/connecting-your-rc-input-and-motors/&quot; rel=&quot;nofollow&quot;&gt;This page&lt;/a&gt; really helped me. &lt;a href=&quot;http://diydrones.com/forum/topics/copter-propellers-rotation-incorrect?commentId=705844%3aComment:1146618&quot; rel=&quot;nofollow&quot;&gt;This one&lt;/a&gt; has some good info too.&lt;/p&gt;&#xA;" OwnerUserId="2589" LastActivityDate="2014-01-12T05:12:04.140" />
  <row Id="2293" PostTypeId="2" ParentId="2290" CreationDate="2014-01-12T15:39:00.853" Score="3" Body="&lt;p&gt;Sounds like ground effects. When a plane or helicopter is close to the surface, the aerodynamics change. This distance is usually considered to be the same as wingspan, or rotor diameter for a helicopter. The lift/drag ratios change, the thrust efficiency changes, and the balance can be affected because you are moving on or off a bubble of pressurized air. Also the turbulence can go nuts, placing high demands on the control systems. Slower or unoptimized systems are going to struggle through this zone.&#xA;This effect is also dependent on the surface you are above, with the effect maximized on smooth hard surfaces. If the craft has the same behavior at the same height when hovering over grass or very bumpy surfaces that it does off a smooth piece of plywood on concrete, then the problem is something else. If the transition occurs at a lower height on grass, than you'll have found the problem.&#xA;Check out: &lt;a href=&quot;http://www.skybrary.aero/index.php/Ground_Effect#The_Extent_of_Ground_Effect&quot; rel=&quot;nofollow&quot;&gt;http://www.skybrary.aero/index.php/Ground_Effect#The_Extent_of_Ground_Effect&lt;/a&gt;&#xA;Here is a forum where they had this problem, and were able to reduce it via control settings.&#xA;&lt;a href=&quot;http://forums.openpilot.org/topic/7596-quad-unstable-in-ground-effect/&quot; rel=&quot;nofollow&quot;&gt;http://forums.openpilot.org/topic/7596-quad-unstable-in-ground-effect/&lt;/a&gt;&#xA;and if you want a formal discussion:&#xA;&lt;a href=&quot;http://www.seas.upenn.edu/~dmel/ISER2012_powers.pdf&quot; rel=&quot;nofollow&quot;&gt;http://www.seas.upenn.edu/~dmel/ISER2012_powers.pdf&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="2402" LastActivityDate="2014-01-12T15:39:00.853" />
  <row Id="2294" PostTypeId="2" ParentId="2290" CreationDate="2014-01-12T16:32:55.620" Score="0" Body="&lt;p&gt;Make sure you have set PIDs for your frame correctly. &lt;a href=&quot;http://www.youtube.com/watch?v=YNzqTGEl2xQ&quot; rel=&quot;nofollow&quot;&gt;Here&lt;/a&gt; is a video which explains behavior of quadrotor under various PID settings which will help you tune gains for your frame. Also Make sure your frame is well balanced with CG at center of board. ESCs must to be calibrated so that all 4 motors perform equally. Unbalanced propellers can cause significant vibration hence   make sure propeller are well balanced. Always fly quadrotor to height of more than 1m and then check behavior so that ground effects are negligible. &lt;/p&gt;&#xA;" OwnerUserId="2118" LastActivityDate="2014-01-12T16:32:55.620" />
  <row Id="2295" PostTypeId="1" CreationDate="2014-01-13T00:28:14.540" Score="0" ViewCount="9" Body="&lt;p&gt;I am in the process of creating a Power Prediction Model for the Hubo Robot. &lt;a href=&quot;http://en.wikipedia.org/wiki/HUBOas&quot; rel=&quot;nofollow&quot;&gt;http://en.wikipedia.org/wiki/HUBOas&lt;/a&gt; &#xA;The Robot has 38 Degrees of Freedom and has a computer some sensors and motor boards. The motors are powered through Motor Boards. All these boards are powered through a main power board that exists at the robots chest.&#xA;My model should be able to predict the power for any trajectory of the robot. Say for instance if the robot raises its hand from 0 degrees to 180 degrees my model should be able to predict the power.&#xA;Heres an idea I came across. My idea was to equate the electrical torque to the mechanical torque of each joint.&#xA;For instance if the Right arm pitch moves from 0 to 180 degrees I can do as follows ?&#xA;mgsin(theeta)= Kt*I&#xA;However, I am not getting a proper prediction and the current value is way off than what we can read from a software installed in the robot. I know there are losses but even then its off. I was wondering if there are any other approaches or a fault in my approach.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And after I do this I can add all the joint currents for a specific trajectory and then give a estimate for total power consumption.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any thoughts are greatly appreciated &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks&lt;/p&gt;&#xA;" OwnerUserId="2594" LastActivityDate="2014-01-13T00:28:14.540" Title="Power Model for the Hubo Robot" Tags="&lt;brushless-motor&gt;&lt;power&gt;&lt;inverse-kinematics&gt;&lt;motion-planning&gt;&lt;torque&gt;" />
  <row Id="2296" PostTypeId="2" ParentId="2273" CreationDate="2014-01-13T00:44:30.330" Score="4" Body="&lt;p&gt;I suspect that your Arduino is reseting, by the fact that the stall current of the motor by the product sheet is $800mA$, and you are using the USB power, then Arduino regulator, to supply the motor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As you are using the USB/Serial converter to make the connection to the Raspberry Pi, when it resets, it can be creating a new &quot;virtual&quot; serial port on the Raspberry Pi, like you are saying.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The USB maximum supply of current is near $500mA$ in this case, but in reality there's more&#xA;than the motor, Arduino, and so on, so its less.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To test it, just disconnect the motor and see if don't reset or create a new &quot;virtual&quot; serial port.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Being the problem (or even if its not) you should power your motor from an external supply capable of suppling the required current under the voltage you want.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The servo was attempting to draw more than 500mA over USB and was triggering the &#xA;  Arduino's USB Overcurrent Protection feature. An appropriate power supply for the &#xA;  Arduino fixed the issue. &lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;I still suggest you to use other power supply to the motor, or use the same power supply but not use the power from the Arduino to supply the motor. This is due that even with an external power supply the Arduino has an power regulator with a $1000mA$ capacity, and also this could put some noise on the ATMega supply. Of course the power supply should be in the motor voltage supply range.&lt;/p&gt;&#xA;" OwnerUserId="2447" LastEditorUserId="2447" LastEditDate="2014-01-13T00:53:29.377" LastActivityDate="2014-01-13T00:53:29.377" />
  <row Id="2297" PostTypeId="1" CreationDate="2014-01-13T12:14:10.597" Score="2" ViewCount="88" Body="&lt;p&gt;In continuation of the question I asked here: &lt;a href=&quot;http://robotics.stackexchange.com/questions/2167/quadcopter-instability-with-simple-takeoff-in-autonomous-mode&quot;&gt;Quadcopter instability with simple takeoff in autonomous mode&lt;/a&gt;&#xA;  ...I'd like to ask a few questions about implementing a basic PID for a quadrotor controlled by an APM 2.6 module. (I'm using a frame from 3DRobotics)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've stripped down the entire control system to just two PID blocks, one for controlling roll and another for controlling pitch (yaw and everything else... I'd think about them later).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm testing this setup on a rig which consists of a freely rotating beam, wherein I've tied down two of the arms of the quadrotor. The other two are free to move. So, I'm actually testing one degree of freedom (roll or pitch) at a time.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Check the image below: here A, B marks the freely rotating beam on which the setup is mounted.&#xA;&lt;img src=&quot;http://i.stack.imgur.com/CbgYO.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;With careful tuning of P and D parameters, I've managed to attain a sustained flight of about 30 seconds. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;But by 'sustained', I simple mean a test where the drone ain't toppling over to one side. Rock steady flight is still no where in sight, and more than 30 secs of flight also looks quite difficult. It wobbles from the beginning. By the time it reaches 20 - 25 seconds, it starts tilting to one side. Within 30 secs, it has tilted to one side by an unacceptable margin. Soon enough, I find it resting upside down &lt;/p&gt;&#xA;&#xA;&lt;p&gt;As for the PID code itself, I'm calculating the proportional error from a 'complimentary filter' of gyro + accelerometer data. The integral term is set to zero. The P term comes to about 0.39 and the D term is at 0.0012. (I'm not using the Arduino PID library on purpose, just want to get one of my own PIDs implemented here.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Check this video, if you want to see how it works.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.youtube.com/watch?v=LpsNBL8ydBA&amp;amp;feature=youtu.be&quot; rel=&quot;nofollow&quot;&gt;http://www.youtube.com/watch?v=LpsNBL8ydBA&amp;amp;feature=youtu.be&lt;/a&gt;&#xA;[Yeh, the setup is pretty ancient! I agree. :)]&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Please let me know what could I possibly do to improve stability at this stage.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;@Ian: Of the many tests I did with my setup, I did plot graphs for some of the tests using the reading from the serial monitor. Here is a sample reading of Roll vs 'Motor1 &amp;amp; Motor2 - PWM input' (the two motors controlling the roll):&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/rnyIi.png&quot; alt=&quot;Roll vs Motor PWM input&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As for the input/output:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Input:&lt;/strong&gt; Roll and pitch values (in degrees), as obtained by a combination of accelerometer + gyro&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Output:&lt;/strong&gt; PWM values for the motors, delivered using the Servo library's motor.write() function&lt;/p&gt;&#xA;" OwnerUserId="1949" LastEditorUserId="1949" LastEditDate="2014-01-15T10:43:54.343" LastActivityDate="2014-01-15T23:08:28.120" Title="Quadcopter PID tuning" Tags="&lt;quadcopter&gt;&lt;pid&gt;&lt;quadrotor&gt;&lt;stability&gt;" AnswerCount="3" CommentCount="6" />
  <row Id="2298" PostTypeId="1" CreationDate="2014-01-13T18:57:20.743" Score="1" ViewCount="30" Body="&lt;p&gt;Given a 12' x 12' field (4m x 4m), a reasonably cheap 3-axis gyro sensor and accelerometer, and compass, I plan to design a device capable of tracking its position to sub-centimeter accuracy for a minute of motion or so.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The device has a holonomic drive system, capable of moving any direction at a maximum of about 8mph (3.6m/s), with a maximum acceleration of about 2g's. However, there are some simplifying constraints. For one, the field is nearly flat. The floor is made of a tough foam, so there is slight sinking, but the floor is flat except for a ramp of known angle (to a few degrees). The device will, excepting collisions, not be rising above the floor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Accuracy is preferred over simplicity, so any mathematics required on the software side to improve the system would be welcomed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Before I definitively choose accelerometers as the method of position tracking, though, I would like some idea of how much accuracy I could get, and the best ways of doing it.&lt;/p&gt;&#xA;" OwnerUserId="2597" LastActivityDate="2014-01-14T17:18:06.963" Title="How much accuracy could I get position tracking with a 3-axis accelerometer and gyro sensor, and compass, and how would I do it?" Tags="&lt;kinematics&gt;&lt;accelerometer&gt;&lt;machine-learning&gt;" AnswerCount="1" CommentCount="2" />
  <row Id="2299" PostTypeId="1" CreationDate="2014-01-14T01:49:35.800" Score="1" ViewCount="46" Body="&lt;p&gt;I am a Computer Science student entering my last year of college. I'm pretty sure Robotics is what I want to eventually be doing based on my interests in AI and embedded systems. I've seen a lot of topics that covers Robotics such as: control theory, signal processing, kinematics, dynamics, 3D simulators, physics engines, AI, Big Data with machine learning. I'm hoping someone can point me in the right direction as to what I should be attempting to study in my interests of Robotics. I am not sure what other topics I have not mentioned that would be relevant. I would like to deal with the software side of Robotics, both AI and none AI.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My other question is about machine learning. I've seen researchers applying machine learning (deep learning/unsupervised learning specifically) to robotics but how do they do this? Is information and data transferred from the internals of the robot to an external computer that does the data processing? Machine learning requires a lot of data to predict. Is this the only way machine learning can be used in robotics (through an external computer)?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I hope someone can touch on some of the things I've mentioned, Thank you.&lt;/p&gt;&#xA;" OwnerUserId="2600" LastEditorUserId="158" LastEditDate="2014-01-14T13:16:32.710" LastActivityDate="2014-01-14T15:38:55.010" Title="Where to start for the software side of Robotics?" Tags="&lt;mobile-robot&gt;&lt;software&gt;&lt;artificial-intelligence&gt;&lt;programming-languages&gt;" AnswerCount="1" CommentCount="2" ClosedDate="2014-01-14T19:52:26.590" />
  <row Id="2300" PostTypeId="1" CreationDate="2014-01-14T10:15:01.610" Score="0" ViewCount="19" Body="&lt;p&gt;I need to connect an ADC with 2 lamps inputs that are connected to an Arduino. With  interrupt.. I need the program in Arduino to configure this and maintain the threshold&lt;/p&gt;&#xA;" OwnerUserId="2601" LastEditorUserId="2447" LastEditDate="2014-01-14T16:40:53.537" LastActivityDate="2014-01-14T16:40:53.537" Title="Program for interfacing ADC with inputs" Tags="&lt;arduino&gt;" CommentCount="2" />
  <row Id="2301" PostTypeId="2" ParentId="2299" CreationDate="2014-01-14T15:38:55.010" Score="0" Body="&lt;p&gt;To answer your first question: if you are looking merely into the software side of robotics, you might consider what aspect of software interests you the most considering the list you posted. One thing to remember in this regard when making a choice is to think on what platforms you could test those hypotheses you would generate while studying and how to set up an experimental verification. Generally speaking, a C language is the most common.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On your second question: machine learning is a vast subject. Personally, the global aspect of learning--leveraging, say, neural networks--is a good experience in itself. Understanding the state-of-the-art in NN programming, as well as following examples is a great start to both your questions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you have the interest to program, I would suggest keying into Google &quot;neural networks c#&quot; and visiting CodeProject for examples. C# has the shortest learning curve, I think, and has the most to offer you simply of the volume of people using it.&lt;/p&gt;&#xA;" OwnerUserId="2602" LastActivityDate="2014-01-14T15:38:55.010" />
  <row Id="2302" PostTypeId="2" ParentId="2297" CreationDate="2014-01-14T17:04:56.793" Score="1" Body="&lt;p&gt;I'd start by reading over this question: &lt;a href=&quot;http://robotics.stackexchange.com/q/167/350&quot;&gt;What are good strategies for tuning PID loops?&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If I had to guess, I'd say you have a problem in the way your complimentary filter is constructed.  With the quadcopter motors off, you should tilt the frame back and forth and see if the roll / pitch values that are reported are actually accurate.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;To me, it looks like there is a delay between the input from the accelerometer and the output of your filter -- the oscillation could be explained by late reactions to the input data.  The eventual turning over looks like a possible integration error that accumulates over time -- in other words, while your quadcopter is on its side it actually thinks it's hovering levelly.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2014-01-14T17:04:56.793" CommentCount="5" />
  <row Id="2303" PostTypeId="2" ParentId="2298" CreationDate="2014-01-14T17:18:06.963" Score="1" Body="&lt;p&gt;The mechanics of your vehicle are not extremely relevant here; I will assume that the motion your vehicle induces on the sensors will be within their specifications.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Entire volumes have been written on &quot;sensor fusion&quot;, which is the act of combining measurements from multiple sensors (e.g. your gyro, accelerometer, and compass).  Doing this 100% accurately is impossible, so the goal is always to put some known bound on the error that can accumulate with time.  You will have to research that for yourself, as the best option depends greatly on your (and your CPU's) mathematical abilities.  Here is &lt;a href=&quot;http://hkr.diva-portal.org/smash/get/diva2:475619/FULLTEXT02.pdf&quot; rel=&quot;nofollow&quot;&gt;a document that discusses the development of a sensor fusion system with gyroscope, accelerometer, and compass&lt;/a&gt; so you get an idea of what's involved.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the short term, one thing you can do is begin to characterize each of your sensors -- what is their precision and accuracy versus ground truth?  What sort of delay do you get from their measurements?  This characterization will help you more accurately combine their measurements later.  &lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2014-01-14T17:18:06.963" />
  <row Id="2304" PostTypeId="1" CreationDate="2014-01-14T20:46:01.280" Score="1" ViewCount="48" Body="&lt;p&gt;I need an app that can do live monitoring of whether each seat in an auditorium is occupied,  so visitors can load the app and see where to sit.    &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The auditorium has a relatively flat ceiling 4m high, and the seats are .5m wide. &#xA;The hardware cost per seat needs to be $5.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm looking for all solutions.  Web cams, preasure sensors, sonars, lasers, arduino, pi, intel edison, anything. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Obviously there cannot be wires that people could trip over.  Sensors on the ceiling could have wired networking.  Sensors on the seat or floor would need to have wireless communication.  sensors on the ceiling would need to consider occlusion by people sitting in the seats (think, if there is an empty spot between 2 people, can the sensor see it as empty)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the end, the data needs to be collected as a simple list of which chairs are occupied/open&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/dGKyO.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Possible solutions:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;rasberry pi's on the ceiling every 8 seats with a camera.   &lt;/li&gt;&#xA;&lt;li&gt;pressure sensors under chair legs wired to pi's gpio&lt;/li&gt;&#xA;&lt;li&gt;Drones flying around the auditorium :)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Any ideas?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Update (more constraints):&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;auditorium size is 400 seats&lt;/li&gt;&#xA;&lt;li&gt;Installation costs should average 10 chairs per hour(400/10 = 40 hours)  &lt;/li&gt;&#xA;&lt;li&gt;as the picture shows, chairs are cushioned&lt;/li&gt;&#xA;&lt;li&gt;regular maintenance should take no longer than 30 min. per 2-hour event(eg, batteries)&lt;/li&gt;&#xA;&lt;li&gt;hardware should last 100 sessions&lt;/li&gt;&#xA;&lt;li&gt;for auditorium cleaning, it should be possible to &quot;disconnect&quot; and &quot;reconnect&quot; the chairs with 4 hours of labor.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="2608" LastEditorUserId="2608" LastEditDate="2014-01-15T00:00:50.523" LastActivityDate="2014-01-15T04:29:41.507" Title="System for determining occupied seats in an auditorium" Tags="&lt;arduino&gt;&lt;sensors&gt;&lt;raspberry-pi&gt;&lt;computer-vision&gt;" AnswerCount="3" />
  <row Id="2305" PostTypeId="2" ParentId="2304" CreationDate="2014-01-14T21:47:43.680" Score="1" Body="&lt;p&gt;OK, so the hardware cost per seat is $5. But what is the total cost per seat? What's the total cost for the whole auditorium? In short, what's your budget? Who will maintain this system? What other constraints do you have?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A simple pressure switch can be made for 50 cents, but wiring it might cost $100 per seat, so you meet the hardware cost constraint, but may fail elsewhere.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;That said, with what little you've told us, the simple solution is to put a pressure plate on each seat, with sensor wires going down into the floor. Then all those sensors can be read by a single computer with a lot of input channels. That could easily be built for a cost of $200 + $5/seat, but I suspect that the installation costs will kill you.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you want wireless communication, now you have to deal with how to power the thing. Who will make sure all those batteries are working every day, or will they all be changed out at a fixed time?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you use one each of those cheap &lt;a href=&quot;https://www.sparkfun.com/products/10534&quot; rel=&quot;nofollow&quot;&gt;wireless transmitters and receivers&lt;/a&gt; in each seat and a small microcontroller to implement a poll/response mechanism, a battery, sensor and an enclosure, then you might just scrape by for $5/seat in volume.&lt;/p&gt;&#xA;" OwnerUserId="794" LastActivityDate="2014-01-14T21:47:43.680" CommentCount="2" />
  <row Id="2306" PostTypeId="2" ParentId="2304" CreationDate="2014-01-14T23:46:39.253" Score="1" Body="&lt;p&gt;Computer vision would work, but have some error margins like people putting a bag on the other chair. It may be uncomfortable to the people too to, although the cameras could be hidden.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Pressure sensors could suffers from a high weight bag too, where computer vision is more affected by area.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It's a fixed installation with a cost for that. When you can, use wires! There's then no batteries to worry, no signal problems, no RF pollution, and goes on.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As you have a relatively high number of seats, just use a small uC from Microchip, Atmel, or what you prefer, that should cost near 1,60 and a differential driver (RS-485 compliant), and use it to read lets say 4 seats sensors. Pass a bus of RS-485 (UTP with 2 pair), and poll the sensors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;EDIT&lt;/strong&gt; (as OP said that has no way to pass wires in the floor)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you go to computer vision&lt;sup&gt;&lt;strong&gt;note 2&lt;/strong&gt;&lt;/sup&gt; and you said a chair occupied by some object will in fact by considered occupied (and not the say the people to put the bag on the ground and allow space for another people), computer vision could do the job. Just think its not that cheap as you may think. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Lets take a 200,00 camera (it should be higher than this, need to check prices and options on your country), thought 20 seats, so 10,00/seat would be more than you can use. You could get a larger area depending on the height of the camera relative to the chairs, but high angle lens does not seems a good option as there will me much distortion.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Wiring would have near more or less the cost of the other option. As the cameras require each cable from the hub/switch to the camera, a bus would not be feasible like an RS-485 bus.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;sup&gt;Note 1: You mean nothing of infrastructure for wiring, if there's no way to pass wires, then yes, you should go wireless.&lt;/sup&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;sup&gt;Note 2: For computer vision the better is to use RAW cameras (without image compression) and if it's unavoidable to use compression, at least H.264. (An lossless compression would give the same uncompressed image, but that's not easy to find).&#xA;Good optics are very important too, so good focus. As you have a controlled light environment, sensor size could be less important, but not forgettable. Computer vision is not that easy, that's why some projects fails. Just putting any camera with any lens would not to the work for most of the scenarios.&lt;/sup&gt;&lt;/p&gt;&#xA;" OwnerUserId="2447" LastEditorUserId="2447" LastEditDate="2014-01-15T00:18:02.797" LastActivityDate="2014-01-15T00:18:02.797" CommentCount="6" />
  <row Id="2307" PostTypeId="2" ParentId="2304" CreationDate="2014-01-15T04:29:41.507" Score="1" Body="&lt;p&gt;You are looking for an easy cheap solution.  I doubt there is one.   Each easy solution can be fooled. A camera is going to detect a jacket of bag on a seat, a weight or pressure sensors will get tripped many times.  What if a person &quot;takes&quot; a seat them walk around.  How does your system know a seat is reserved.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I think this system will need to use multiple sensors and some &quot;rules of thumb&quot; to make guesses.   You will have to accept that the results will not be perfect.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Star  with pressure sensors.  You can wire an entire row together from seat to seat without creating any wire s on the floor.  Then you have boxes mounted on the seats nearest the isle to handle that row.  These boxes will need power.  You will need to run wire down the ales to each isle box.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would back this up with another system perhaps based on vision.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then you can also count people and cross check the totals from the count, pressure and vision systems.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;OK, one last question?  Why do you care about the cost of the seat sensors.  That will be trivial compared to the engineering and installation costs.&lt;/p&gt;&#xA;" OwnerUserId="2609" LastActivityDate="2014-01-15T04:29:41.507" CommentCount="4" />
  <row Id="2308" PostTypeId="2" ParentId="2167" CreationDate="2014-01-15T05:09:19.427" Score="1" Body="&lt;p&gt;I read the code but it looks like it is for the first attempt where you tried to hover &quot;open loop&quot;  that can't work.   So now you tried a PID control based straight off the raw IMU data.  Tha't better but you are going to need one more step between the two.   Will I say this assuming you are using a low-cost IMU, the kind that just breaks out the chip.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;First off it would be ideal if you could measure the speed of each motor, and not just assume it rotates at a speed proportionate to the commanded value.  Likely it does not.  The BEST way to to place an encoder on the motor shaft that sends a few pluses per revolution.  Then you replace &quot;motor2.write(val)&quot; with something like &quot;motor.setspeed(rotationVelocity); and the set speed method runs a PID loop just ontheat one motor's speed, sending whatever PWM value is required.   OK, lacking an encoder, get a hand held propeller tachometer.  And plot RPM vs PWM for a tried vehicle fixed to a stand at some hight from the ground.   &lt;/p&gt;&#xA;&#xA;&lt;p&gt;NEXT YOU NEED TO KNOW HOW TO RELATE RPM TO THRUST.  One problem with yourPID control is it assume PWM value (voltage) is LINEARLY related to force in the vertical direction is is NOT because &#xA;1) If the vehicle is tilted the foxed is no longer down and is smaller be the cosine of the tilt and..&#xA;2) force is NEVER linearly replaced to voltage.  It think(???) there is a cubed relationship the is power cubed = force.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;You might just kip all the math and measure the force as a function of PWM and make a lookup table.  Better to use encoders and&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You over all PID loop will work much better when have a linear relationship.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Next idea:  You CAN make a quad more stable.  What if you tilt the plane of each door inwards just a little.  Each is slightly non-horizonal, now if one side dips it will generate more lift.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Last idea:  The IMU is a noisy device.  The accelerometer has high frequency noise on it becise of random vibrations and the gyro has drift.  The &quot;standard&quot; why to address this is with a Kalman Filter.  The math is not easy but you can find MANY examples of Kalman filters on-line.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Summary:&#xA;1) Use good filter model to correct the IMU data.  The raw data is not good.&#xA;2) Create a method (function) that takes llefting force as input then sets the PWM slue as required.&lt;br&gt;&#xA;3) Used a top layer PID to drive the error to zero&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What this does is address the basic flaw of all PID controller, they don't &quot;see&quot; inside the black box.  They don't know the gyro drift and accelerometer is noisy and that PWM has a non-linear relationship to lift.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Next you get into moving flight and you need to make your aerodynamic model better to account for the fixed pitch props&lt;/p&gt;&#xA;" OwnerUserId="2609" LastActivityDate="2014-01-15T05:09:19.427" CommentCount="5" />
  <row Id="2309" PostTypeId="2" ParentId="1947" CreationDate="2014-01-15T05:28:52.263" Score="1" Body="&lt;p&gt;You can do what yu want with the standard arduino &quot;Stepper&quot; library.  You are using something called &quot;accelsteper.h&quot;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Using the standard one....&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This c-like psudocode will run a motor at some speed for 2000 steps then run and some other speed for 4000 steps and then go back an do it again.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;loop{&#xA;setspeed(speed1)&#xA;step(2000)&#xA;setspeed(speed2)&#xA;step(4000)&#xA;}&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Look here for details on the standard stepper library&#xA;&lt;a href=&quot;http://arduino.cc/en/Reference/Stepper&quot; rel=&quot;nofollow&quot;&gt;http://arduino.cc/en/Reference/Stepper&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Get this to work FIRST.  then make it nicer if you need to.  for example place a half way between speed in there like this &quot;set speed((speed1+speed2)/2). and run a few steps.&lt;/p&gt;&#xA;" OwnerUserId="2609" LastActivityDate="2014-01-15T05:28:52.263" />
  <row Id="2310" PostTypeId="2" ParentId="1927" CreationDate="2014-01-15T05:37:23.203" Score="0" Body="&lt;p&gt;Are you asking about the gyroscopic effect?  What they call &quot;gyroscopic precession&quot;.  Then Google that term &quot;gyroscopic precession&quot; and you can find some ways to calculate it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But in practical terms your 0.5Kg wheel moving at 1 rpm will show very lift of this effect unless the diameter is huge.  For normal size wheels at 1 rpm you can ignore this.&lt;/p&gt;&#xA;" OwnerUserId="2609" LastActivityDate="2014-01-15T05:37:23.203" />
  <row Id="2311" PostTypeId="1" CreationDate="2014-01-15T08:55:07.887" Score="0" ViewCount="21" Body="&lt;p&gt;I want to program a robot with an arduino that can be controlled through the internet. I am thinking of designing a web page with a few buttons and options that can be selected, and that the arduino (with a wifi shield) can access these values, and store them as variables to use in its program. Also, I hope to also have a virtual console window in the site and have the arduino print information of the sensors in it so they can be accessible to the user.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I was wondering if anyone has any experience doing a virtual control system like this, because  I think this plan should be feasible and easy to implement, but I have no idea how the coding should be to send specific values to the arduino through the internet. To simplify the question...&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How would I go about creating a virtual slider that controls the angle of a servo, and sends that information towards the arduino through wifi? How can I make my arduino print statements through wifi?&lt;/p&gt;&#xA;" OwnerUserId="2610" LastActivityDate="2014-01-15T08:55:07.887" Title="Virtual Internet Controller" Tags="&lt;arduino&gt;&lt;control&gt;&lt;wifi&gt;" CommentCount="2" />
  <row Id="2312" PostTypeId="2" ParentId="1844" CreationDate="2014-01-15T09:59:32.783" Score="2" Body="&lt;p&gt;Using a so-called optical flow sensor is the best way to help with holding the horizontal (i.e. in X-Y plane) position. I don't see any reason why you couldn't do the same for vertical control, although a sonar is probably easier and cheaper to use for this (likewise, if you are indoors, you could use 2 sonars for the horizontal position as well)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;People used to hack the sensors of optical mice to achieve this:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://makezine.com/2007/12/15/using-an-optical-mouse-for-rob/&quot; rel=&quot;nofollow&quot;&gt;http://makezine.com/2007/12/15/using-an-optical-mouse-for-rob/&lt;/a&gt;&#xA;&lt;a href=&quot;http://areciv.com/index.php?aid=18&quot; rel=&quot;nofollow&quot;&gt;http://areciv.com/index.php?aid=18&lt;/a&gt;&#xA;&lt;a href=&quot;http://home.roadrunner.com/~maccody/robotics/croms-1/croms-1.html&quot; rel=&quot;nofollow&quot;&gt;http://home.roadrunner.com/~maccody/robotics/croms-1/croms-1.html&lt;/a&gt;&#xA;&lt;a href=&quot;http://home.roadrunner.com/~maccody/robotics/mouse_hack/mouse_hack.html&quot; rel=&quot;nofollow&quot;&gt;http://home.roadrunner.com/~maccody/robotics/mouse_hack/mouse_hack.html&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some ready-made sensors are available: &lt;a href=&quot;http://www.buildyourowndrone.co.uk/Optical-Flow-Sensor-p/op-fs.htm&quot; rel=&quot;nofollow&quot;&gt;http://www.buildyourowndrone.co.uk/Optical-Flow-Sensor-p/op-fs.htm&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some explanation on how to use such device with an Arduino can be found here:&lt;a href=&quot;https://code.google.com/p/arducopter/wiki/AC2_OptFlow&quot; rel=&quot;nofollow&quot;&gt;https://code.google.com/p/arducopter/wiki/AC2_OptFlow&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Nowadays, better sensors are out there (but much more expensive) that works in low-light conditions (i.e. indoors) and are even combined with a sonar (as it makes senses to hold altitude in order to get a better/stable optical reading for XY positioning), such as this one:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/S1APo.jpg&quot; alt=&quot;px4flow&quot;&gt;&#xA;&lt;a href=&quot;http://store.3drobotics.com/products/px4flow&quot; rel=&quot;nofollow&quot;&gt;http://store.3drobotics.com/products/px4flow&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="2603" LastEditorUserId="2603" LastEditDate="2014-01-16T08:46:34.223" LastActivityDate="2014-01-16T08:46:34.223" />
  <row Id="2313" PostTypeId="2" ParentId="2297" CreationDate="2014-01-15T14:34:13.737" Score="1" Body="&lt;p&gt;Well there could be a number of things going on here...&lt;/p&gt;&#xA;&#xA;&lt;p&gt;1) Are your reported angles correct? noisy? You can easily check that by manually tilting your quad and monitoring the values coming out.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;2) your own PID implementation has a bug. You could use the trusted implementation out there to check your code.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;3) Props, motors mounted the wrong way round.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;4) ...&lt;/p&gt;&#xA;" OwnerUserId="2603" LastActivityDate="2014-01-15T14:34:13.737" CommentCount="3" />
  <row Id="2314" PostTypeId="2" ParentId="2167" CreationDate="2014-01-15T14:55:45.973" Score="1" Body="&lt;p&gt;I can see several mistakes in your approach.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The biggest red flag for me is that you are treating the motors as individually-controlled PIDs when in fact they need to work in pairs.  I'm talking about this line that you posted:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;motor1.write((int)(val + (kP * pError1) +(kI * iError1) +(kD * dError1)));  //front left&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;The output of your PID should be the desired roll or pitch force -- the correction to the current pitch or roll vs what is desired.  The desired roll or pitch force will then be translated into the thrust ratio between the 2 motors that can effect that force.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The second problem I see is that you are using a PD controller instead of a PID controller and wondering why it appears to be imbalanced.  The integral term is &lt;em&gt;precisely&lt;/em&gt; what you are missing -- it compensates for any (static) imbalance in the quadcopter itself.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The third (potential) problem that I see is that you might not be properly mapping the motor speed to the desired thrust -- that relationship may not be linear. &lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2014-01-15T14:55:45.973" CommentCount="1" />
  <row Id="2315" PostTypeId="1" CreationDate="2014-01-15T16:28:49.267" Score="2" ViewCount="36" Body="&lt;p&gt;I'm trying to get an extended Kalman Filter to work. My System Model is&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$ x = \begin{bmatrix}&#xA; lat \\&#xA; long \\&#xA; \theta&#xA;\end{bmatrix}$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;where lat and long are latitude and longitude (in degree) and $\theta$ is the current orientation of my vehicle (also in degree).&#xA;In my Prediction Step I get a reading for current speed &lt;em&gt;v&lt;/em&gt;, yaw rate $\omega$ and inclination angle $\alpha$:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$z = \begin{bmatrix}&#xA; v \\&#xA; \alpha\\&#xA; \omega &#xA; \end{bmatrix}$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I use the standard prediction for the EKF with f() being:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$&#xA;\vec{f}(\vec{x}_{u,t}, \vec{z}_t) = \vec{x}_{u,t} + &#xA; \begin{bmatrix}&#xA;  \frac{v}{f} * \cos(\theta) * \cos(\alpha) * \frac{180 °}{\pi * R_0} \\&#xA;  \frac{v}{f} * \sin(\theta) * \cos(\alpha) * \frac{180 °}{\pi * R_0} * \frac{1}{\cos(lat)} \\&#xA;  \frac{\omega}{f}&#xA; \end{bmatrix}&#xA;$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$f$ being the prediction frequency, $R_0$ being the radius of the earth (modelling the earth as a sphere)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My Jacobi Matrix looks like this:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$&#xA;C = v \cdot \Delta t \cdot cos(\alpha) \cdot \frac{180}{\pi R_0}&#xA;$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$&#xA;F_J =&#xA;\begin{pmatrix}&#xA;  1 &amp;amp; 0 &amp;amp; -C \cdot sin(\phi) \cdot \frac{1}{cos(lat)} \\&#xA;  -C \cdot sin(\phi) \cdot \frac{sin(lat)}{{cos(lat)}^2} &amp;amp; 1 &amp;amp; C \cdot cos(\phi) \cdot \frac{1}{cos(lat)}\\&#xA;  0 &amp;amp; 0 &amp;amp; 1&#xA;\end{pmatrix}&#xA;$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As I have a far higher frequency on my sensors for the prediction step, I have about 10 predictions followed by one update.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the update step I get a reading for the current gps position and calculate an orientation from the current gps position and the previous one. Thus my Update is just the standard EKF Update with $h(x) = x$ and thus the Jacobi Matrix to $h()$, $H$ being the Identity.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Trying my implementation with testdata where the GPS Track is in constant northern direction and the yaw rate constantly turns west, I expect the filter to correct my position close to the track and the orientation to 355 degrees or so. What actually happens can be seen in the image attached (Red: GPS Position Measurements, Green/blue: predicted positions): &lt;img src=&quot;http://i.stack.imgur.com/KCasT.png&quot; alt=&quot;Red: GPS Position Measurements, Green/blue: predicted positions&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have no Idea what to do about this. I'm not very experienced with the Kalman filter, so it might just be me misunderstanding something, but nothing I tried seemed to work…&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What I think:&#xA;I poked around a bit: If I set the Jacobi Matrix in the prediction to be the identity, it works really good. The Problem seems to be that $P$ (the covariance Matrix of the system model) is not zero in $P(3,1)$ and $P(3,2)$. My interpretation would be that in the prediction step the Orientation depends on the Position, which does not seem to make sense. This is due to $F_J(2,1)$ not being zero, which in turn makes sense.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can anyone give me a hint where the overcorrection may come from, or what I should look at / google for?&lt;/p&gt;&#xA;" OwnerUserId="2614" LastEditorUserId="350" LastEditDate="2014-01-16T14:47:19.227" LastActivityDate="2014-01-16T14:47:19.227" Title="Overcorrecting Kalman Filter" Tags="&lt;kalman-filter&gt;&lt;gps&gt;&lt;sensor-fusion&gt;" FavoriteCount="1" />
  <row Id="2316" PostTypeId="2" ParentId="2297" CreationDate="2014-01-15T23:08:28.120" Score="1" Body="&lt;ol&gt;&#xA;&lt;li&gt;It looks like your proportional gain is too high.&lt;/li&gt;&#xA;&lt;li&gt;You seem to be constantly increasing RPM on one motor while locking in the other one to make the system rotate.  This isn't a good control strategy as eventually those are going to both saturate and you will lose control.  Also as time increases your ability to command the system decreases.  So you need a better model of the system.&lt;/li&gt;&#xA;&lt;li&gt;If you deal with #1, and #2 you'll have a more stable system but you may not be happy with the control bandwidth.  To deal with that you need to make your system stiffer which includes getting rid of any lag on the sensor side of things and on the control side of things.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="1584" LastActivityDate="2014-01-15T23:08:28.120" />
  <row Id="2317" PostTypeId="2" ParentId="520" CreationDate="2014-01-16T08:46:21.670" Score="1" Body="&lt;p&gt;3D printing a refractive lens is possible using &quot;printoptical technology&quot; by LUXeXceL. It was developed for making perfectly smooth surfaces. With this technology there is no need for post-processing (grinding, polishing / coloring, etc.). &lt;/p&gt;&#xA;" OwnerUserId="2618" LastEditorUserId="177" LastEditDate="2014-01-16T15:26:04.110" LastActivityDate="2014-01-16T15:26:04.110" />
  <row Id="2318" PostTypeId="2" ParentId="1344" CreationDate="2014-01-16T11:30:13.913" Score="1" Body="&lt;p&gt;CF is lighter but you definitively need to know your source, many of the inexpensive tubes are quite brittle. In any case I do not recommend drilling holes in the tube use clamps.&#xA;Aluminium is somewhat heavier and will transmit vibration (balance your motors and props) but is readily available cheaper and easier to work with. For a smaller craft I would use aluminium anything over 550 quality carbon &lt;/p&gt;&#xA;" OwnerUserId="2622" LastActivityDate="2014-01-16T11:30:13.913" />
  <row Id="2319" PostTypeId="2" ParentId="520" CreationDate="2014-01-16T14:43:05.243" Score="0" Body="&lt;p&gt;One thing to watch out for is that many of the additive or extrusion-based 3D printers will leave small gaps between the beads of plastic that they lay down.  Even if you polish the surface, the interior will be very poor optically.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You may want to look at &lt;a href=&quot;http://en.wikipedia.org/wiki/Selective_laser_sintering&quot; rel=&quot;nofollow&quot;&gt;Selective Laser Sintering (SLS)&lt;/a&gt; to create a finished product that is more uniformly solid.&lt;/p&gt;&#xA;" OwnerUserId="350" LastActivityDate="2014-01-16T14:43:05.243" />
  <row Id="2320" PostTypeId="2" ParentId="1712" CreationDate="2014-01-16T22:23:22.123" Score="1" Body="&lt;p&gt;i am a electrician . inrunners and outrunners are not DC motors! they are 3 phase motors like in industry . your speed control takes DC and uses electronics to change the DC into a pulsating DC ,in the shape of a AC 3 phase sine wave .and changes the frequency at your command .this is known as a frequency drive . &#xA;     inrunners spin about 65k rpm . after they get to a larger size they spin 40k rpm . outrunners spin 40k . outrunners put out more than twice the torque . outrunners are more efficient . this means more run time . outrunners dissipate heat faster and do not need cool down time if set up correctly .&#xA;     to pick a outrunner look for one about the same weight pick the highest KV for that frame size , pay attention to the voltage . &#xA;     now you have more than twice the torque . use it . start with twice the amount of teeth on your pinion , or change your spurr and pinion to get half the gear ratio .then go lower until the motor gets worm to the touch. NOT HOT .&#xA;     GOOD LUCK .&lt;/p&gt;&#xA;" OwnerUserId="2624" LastActivityDate="2014-01-16T22:23:22.123" CommentCount="3" />
  <row Id="2321" PostTypeId="1" CreationDate="2014-01-17T13:47:38.040" Score="0" ViewCount="27" Body="&lt;p&gt;I am using a miniature car and I want to estimate the position. We can not use GPS modules and most of the tracking systems that I saw, are using IMU senson with the GPS module. In our car we are able to find our exact correct location with image processing but for some parts that dont have enough markings we can not do this. So we want to use the IMU as backup for our positioning. so as long as the positioning is close is good for us.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And we are only interested in our 2D position since the car is on a flat ground.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am using a IMU 9DOF sensor and I want to calculate my movement. I have seen some amazing works with IMU for tracking body movements but no code or simple explanation is anywhere about it. So basically I have the reading from accelerometer, gyro and magnetometer. I also have orientation in quarternions. From the device I am getting also the linear acceleration but even when I am not moving it in any direction the values are not 0 which is really confusing.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can you please help me how to approach this?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks in advance&lt;/p&gt;&#xA;" OwnerUserId="2628" LastActivityDate="2014-01-17T18:21:26.563" Title="Tracking 2D positioning with IMU Sensor" Tags="&lt;sensors&gt;&lt;accelerometer&gt;&lt;gyroscope&gt;" AnswerCount="1" CommentCount="4" />
  <row Id="2322" PostTypeId="1" CreationDate="2014-01-17T16:21:13.917" Score="0" ViewCount="12" Body="&lt;p&gt;I want to make a quadcopter for my final year project and I am willing to use DC motors as the four rotors of the quadcopter. Can any one guide me about the ratings for proper motor selection for my job.&lt;/p&gt;&#xA;" OwnerUserId="2629" LastActivityDate="2014-01-17T16:37:29.363" Title="What can be the rating and specifications of dc motor used for making a quadcopter?" Tags="&lt;quadcopter&gt;" AnswerCount="1" />
  <row Id="2323" PostTypeId="2" ParentId="2322" CreationDate="2014-01-17T16:37:29.363" Score="0" Body="&lt;p&gt;You'll need to use brushless (as opposed to brushed) motors for a quadcopter:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;see &lt;a href=&quot;http://robotics.stackexchange.com/questions/1627/why-do-quadcopters-use-brushless-motors&quot;&gt;Why do quadcopters use brushless motors&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The motor goes hand in hand with the propellers, so you have to make sure they are compatible for your application, as you'll need to generate enough thrust to get it to fly (so it will depend on the weight):&lt;/p&gt;&#xA;&#xA;&lt;p&gt;see &lt;a href=&quot;http://robotics.stackexchange.com/questions/25/how-to-choose-the-right-propeller-motor-combination-for-a-quadcopter&quot;&gt;How to choose the right propeller/motor combination for a quadcopter?&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="2603" LastActivityDate="2014-01-17T16:37:29.363" />
  <row Id="2324" PostTypeId="1" CreationDate="2014-01-17T17:33:12.067" Score="0" ViewCount="8" Body="&lt;p&gt;I have a 4 wheeled differential drive robot, like the Pioneer 3-AT. There are only two motors, one for left wheels and one for right wheels.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I want to send velocity commands to the robot, I'm using ROS and the standard commands are: [linear_velocity, angular_velocity].&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I need to convert them into left and right velocities, from literature if I had 2 wheels I should do this:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;v_l = linear_v - omega * |r|&lt;/p&gt;&#xA;&#xA;&lt;p&gt;v_r = linear_v + omega * |r|&lt;/p&gt;&#xA;&#xA;&lt;p&gt;where |r| is the absolute value of the distance from the wheels to the robot &quot;center&quot;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How should I take into account that I have 4 wheels?&lt;/p&gt;&#xA;" OwnerUserId="1777" LastEditorUserId="1777" LastEditDate="2014-01-17T17:43:12.737" LastActivityDate="2014-01-17T17:43:12.737" Title="Kinematics of a 4 wheeled differential drive robots" Tags="&lt;wheeled-robot&gt;&lt;inverse-kinematics&gt;&lt;wheel&gt;" />
  <row Id="2325" PostTypeId="2" ParentId="2321" CreationDate="2014-01-17T18:00:16.240" Score="2" Body="&lt;p&gt;An IMU as any sensor is not perfect and it is affected by errors.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In IMUs case there are some accelerometers and gyros. They should be orthogonal each other but for construction constraints they can't really be.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Expensive IMUs come with a calibration matrix which is &quot;personal&quot; for each device, and here is why of the extra costs. So someone should calibrate it before use it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;IMUs are affected by many others things like magnetic fields as example.&#xA;This is another reason for why you won't never read a zero value if the IMU is not moving.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;All these error affect the pose estimation since they read accelerations you have to perform a double integration of the value to reach a pose. Double integration of an error make it error^2 (for a simple constant error due to bad calibration).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I can suggest you to search the web for &quot;pose estimation algorithm&quot; as keywords or go to &lt;a href=&quot;http://wiki.ros.org/Sensors/Pose%20Estimation&quot; rel=&quot;nofollow&quot;&gt;ROS&lt;/a&gt; that maybe have something ready for your IMU.&lt;/p&gt;&#xA;" OwnerUserId="1777" LastEditorUserId="1777" LastEditDate="2014-01-17T18:21:26.563" LastActivityDate="2014-01-17T18:21:26.563" />
  <row Id="2326" PostTypeId="1" CreationDate="2014-01-18T08:25:38.050" Score="0" ViewCount="11" Body="&lt;p&gt;I'm simulating a sensor in 3D. The sensor should determine ($p, \theta, \phi$) from the origin  where $\theta$ is the rotation about z-axis and $\phi$ is the rotation about x-axis. The sensor is given position of a point($x, y, z$). This is what I did&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;    p = sqrt(x^2 + y^2 + z^2);&#xA;theta = acos(z/p);   &amp;lt;---- I'm guessing the problem here&#xA;  phi = atan2(y,x);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Now I need to get the Cartesian coordinates ($x',y',z'$). This is what I did&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;    [p theta phi] = getmeasurement(x, y, z);&#xA;    x' = p*cos(theta)*sin(phi);&#xA;    y' = p*sin(theta)*sin(phi);&#xA;    z' = p*cos(phi); &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;The sensor is working fine at the beginning but at a particular point it behaves strangely. I have the state vector to compare it with the measurement. I'm guessing that $\theta$ might be the problem. &lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Edit: &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm sorry for this mistake. The aforementioned calculations based on the following picture&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;http://i.stack.imgur.com/BYMzR.png&quot; alt=&quot;spherical Coordinates&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, the point will rotate first about z-axis ($\theta$) and then rotate about x-axis ($\phi$)&lt;/p&gt;&#xA;" OwnerUserId="2155" LastEditorUserId="2155" LastEditDate="2014-01-18T23:36:43.700" LastActivityDate="2014-01-18T23:36:43.700" Title="problem with simulated sensor in Matlab?" Tags="&lt;sensors&gt;&lt;sensor-error&gt;" AnswerCount="1" />
  <row Id="2327" PostTypeId="2" ParentId="2326" CreationDate="2014-01-18T23:04:50.330" Score="0" Body="&lt;p&gt;Your first set of formulas are calculating the spherical coordinates for the sensor which are different from the angles of rotation around the x-axis (which you have called $\phi$) and the y-axis (which you have called $\theta$)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When using the formulas for converting cartesian coordinates to spherical coordinates you  end up with $\phi$ as the rotation about the x-axis and $\theta$ as the angle between the vector to the x,y,z location and the z-axis (the polar angle)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So the calculation with $\theta$ is correct it just isn't calculating what you thought.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The problem you have isn't with any of that though, it is with the calculation of z', the formula should be&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;z' = p*cos(theta);    &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="1978" LastActivityDate="2014-01-18T23:04:50.330" CommentCount="1" />
</posts>